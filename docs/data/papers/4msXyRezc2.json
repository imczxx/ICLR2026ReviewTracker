{"id": "4msXyRezc2", "number": 15039, "cdate": 1758247140604, "mdate": 1759897333957, "content": {"title": "Adaptive Code Watermarking Through Reinforcement Learning", "abstract": "Protecting intellectual property on LLM-generated code necessitates effective watermarking systems that can operate within code's highly structured, syntactically constrained nature. In this work, we introduce CodeTracer, an innovative adaptive code watermarking framework underpinned by a novel reinforcement learning training paradigm. At its core, CodeTracer features a policy-driven approach that utilizes a parameterized model to intelligently bias token choices during next-token prediction. This strategy ensures that embedded watermarks maintain code functionality while exhibiting subtle yet statistically detectable deviations from typical token distributions. To facilitate policy learning, we devise a comprehensive reward system that seamlessly integrates execution feedback with watermark embedding signals, balancing process-level and outcome-level rewards. Additionally, we employ Gumbel Top-k reparameterization to enable gradient-based optimization of discrete watermarking decisions. Extensive comparative evaluations demonstrate CodeTracer's significant superiority over state-of-the-art baselines in both watermark detectability and the preservation of generated code's functionality. Our code is available at https://anonymous.4open.science/r/CodeTracer-B8EE.", "tldr": "We use reinforcement learning to train a watermark model that can effectively embed watermarks in LLM-generated code while preserving code functionality.", "keywords": ["Large Language Model", "LLM Watermarking", "Code Watermarking"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2d1e1c8112c5ce8b6532501c4ad140bd844cd1af.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes CodeTracer, a code watermarking method based on reinforcement learning. CodeTracer trains a watermarking model that embeds a green-red-list-based watermark at appropriate positions, guided by a reward policy. Extensive experiments demonstrate that CodeTracer achieves a superior trade-off between functionality and detectability compared to existing code watermarking methods."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well written, with clear motivation and a well-structured presentation of the method.\n\n2. The experimental evaluation is comprehensive and provides convincing evidence of effectiveness.\n\n3. Integrating RL with watermarking is a sound and innovative idea, particularly relevant to code generation tasks. The design of the reward function is thoughtful and well explained."}, "weaknesses": {"value": "I do not have major concerns, but I would appreciate further clarification on the following points:\n\n1. Could the authors elaborate on why CodeTracer achieves a substantially higher true positive rate than other active watermarking baselines? Both WLLM and SWEET also rely on green–red lists and employ similar statistical hypothesis testing procedures for watermark detection. A discussion on what specifically drives CodeTracer’s improvement would be helpful.\n\n2. Have the authors explored balancing the three reward terms? For example, if a higher weight is assigned to $R_1$, one might expect improved functionality (e.g., higher Pass@k) at the cost of reduced AUC-ROC. It would be interesting to include an analysis or discussion of this trade-off and the sensitivity to such hyperparameter settings."}, "questions": {"value": "Please see Weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "x4by2OHKHL", "forum": "4msXyRezc2", "replyto": "4msXyRezc2", "signatures": ["ICLR.cc/2026/Conference/Submission15039/Reviewer_xiZC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15039/Reviewer_xiZC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761694132375, "cdate": 1761694132375, "tmdate": 1762925363806, "mdate": 1762925363806, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CodeTracer, an adaptive code watermarking framework designed to protect intellectual property in code generated by Large Language Models (LLMs). The core innovation is a policy-driven approach that utilizes a lightweight, parameterized watermark model to intelligently bias next-token choices during autoregressive generation. This model is trained using a novel reinforcement learning (RL) paradigm based on Group Relative Policy Optimization (GRPO). The training employs a dual-component reward system that integrates execution feedback (to preserve code functionality) with dual watermark embedding signals (process-level and outcome-level). To enable end-to-end gradient-based optimization of discrete watermarking decisions, the authors employ Gumbel Top-k reparameterization and Straight-Through Estimation. Extensive experiments demonstrate that CodeTracer generally outperforms state-of-the-art baselines in both watermark detectability and the preservation of generated code's functionality, and exhibits transferability to larger LLMs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* **Technical Novelty and Execution:** The introduction of an RL pipeline using GRPO to train a dedicated watermark policy is a robust and novel way to solve the code watermarking problem, especially in implicitly handling complex syntactic and semantic constraints.\n* **Performance Balance:** CodeTracer successfully mitigates the functionality-detectability trade-off. It achieves the highest Pass@1 scores among watermarking baselines while maintaining superior detection performance (AUROC) on HumanEval and MBPP.\n* **Practicality and Efficiency:** The watermark model operates as a lightweight, plug-in module ( $<10\\%$ parameter increase, $<0.02\\%$ inference delay), which enables efficient deployment and transferability to larger, frozen LLMs without retraining the base model."}, "weaknesses": {"value": "* **Fairness of SWEET Comparison:** The authors note that the original SWEET requires access to the full generation history and the original LLM for entropy calculation, which is impractical. They adapt SWEET to use fixed context windows for a \"fair\" comparison. This necessary adaptation may not reflect SWEET's optimal capabilities and warrants clearer discussion on its exact performance impact.\n* **Lack of Hyperparameter Sensitivity Analysis:** Key design choices in the reward function, specifically the saturation threshold for the z-score in $R_2$ and the asymmetric penalty parameter $\\alpha$ in $R_3$, are critical for the functionality-detectability trade-off. The lack of a sensitivity analysis on these specific parameters leaves their optimal choice and robustness less well-supported.\n* **Context Window Justification:** The watermark policy network uses a very small context window of 2 tokens. Given the potential for long-range syntactic dependencies in code (e.g., matching brackets, variable scope), a window size of 2 seems intuitively restrictive. While efficient, the paper lacks an ablation study or a stronger justification for this specific value, particularly how it adequately captures the necessary code structure for adaptive decision-making."}, "questions": {"value": "1.  **SWEET Baseline Clarity:** Could the authors elaborate on the results of the adapted SWEET baseline? Specifically, is there a way to quantify how the performance of the fixed-context SWEET baseline relates to the performance curve originally reported in the SWEET paper (if available), to ensure the community has a clear understanding of the 'fairness' of this comparison?\n2.  **Reward Parameter Sensitivity:** Please provide a more detailed justification or sensitivity analysis for the critical reward parameters: the z-score saturation threshold in $R_2$ (set at 4.0) and the asymmetric penalty $\\alpha$ in $R_3$ (set to 2-5). How do small variations in these values impact the final trade-off between Pass@1 and AUROC?\n3.  **Context Window Ablation:** The watermark policy uses a minimal context window size $c=2$. Please justify this choice in detail, or ideally, include an ablation study exploring the performance and efficiency trade-offs of using larger context windows (e.g., $c=1, 2, 4, 8$ tokens). How does $c=2$ adequately capture the syntactic dependencies required for robust watermarking?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3wkJmFjj6r", "forum": "4msXyRezc2", "replyto": "4msXyRezc2", "signatures": ["ICLR.cc/2026/Conference/Submission15039/Reviewer_WGkr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15039/Reviewer_WGkr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834986063, "cdate": 1761834986063, "tmdate": 1762925363276, "mdate": 1762925363276, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes CodeTracer, an adaptive code watermarking framework underpinned by a reinforcement learning training paradigm.\n\nIn general, the method in this work differs from existing code watermarking solutions and presents better results than existing baselines.\n\nIn addition, the paper is well-written and easy to follow."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The strength of this work is as follows.\n\n(1) This work applies reinforcement learning to train the watermarking model, which successfully embeds and detects code watermarks, while maintaining code functionality.\n\n(2) The watermarking model is lightweight and achieves promising efficiency, presenting the potential to be applied in practice.\n\n(3) The method has the potential to be transferred across different LLMs (although CodeTracer is not evaluated based on different types of LLMs)."}, "weaknesses": {"value": "Based on the experiments presented in the paper, I consider the proposed method is not effective enough for the code watermarking task, as follows.\n\n(1) The False Positive Rate (FPR) is not reported in the experiments, that is, the false alarms of CodeTracer on human-written code are doubtful.\n\n(2) The utilized LLM achieves low pass rates on MBPP and HumanEval. In this case, it is hard to know the quality impact of CodeTracer on code that inherently fails the tests.\n\n(3) Although CodeTracer presents higher TPR and AUROC results than other baseline methods, in Table 1, the highest TPR of CodeTracer is only 32.32%, which is even lower than a 50% random guess, raising concerns about the effectiveness of CodeTracer.\n\n(4) The backbone LLM in the experiments is only 1.5B, which is hard to generate normal code for proper model training, which may result in the outcome reward being significantly lower compared to larger-scale code generation LLMs.\n\n(5) Why are the results reported in Table 4 higher than the other main experimental results? Under what conditions are the results in this table obtained?\n\n(6) Some watermarked code samples are necessary, for the demonstrating the watermarking effect of CodeTracer."}, "questions": {"value": "In general, I consider the proposed method lacks effectiveness and the experiments are unconvincing.\n\nPlease respond to the concerns 1 to 6 proposed in the above Weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "W39QM7fs5O", "forum": "4msXyRezc2", "replyto": "4msXyRezc2", "signatures": ["ICLR.cc/2026/Conference/Submission15039/Reviewer_TwGi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15039/Reviewer_TwGi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761913407464, "cdate": 1761913407464, "tmdate": 1762925362857, "mdate": 1762925362857, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The CodeTracer paper proposes an adaptive code watermarking framework that employs reinforcement learning to dynamically decide where and how to embed watermarks in generated code. Instead of using fixed token rules, it trains a policy model to adjust token probabilities based on context and entropy, balancing functionality and watermark detectability. The method combines supervised fine-tuning with GRPO-based reinforcement learning and achieves higher robustness against code modification attacks (e.g., DIPPER, Rename) compared with prior works such as WLLM. The paper is clear and systematic in describing its design and training process, making its technical logic easy to follow. However, it relies on access to model logits, limiting applicability to fully closed-source APIs, and provides little analysis of computational overhead or the theoretical basis for token partitioning. Overall, CodeTracer represents a well-engineered step toward more adaptive and robust code watermarking."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Compared with recent approaches such as SWEET, CodeTracer achieves a slight improvement in code functionality (Pass@1) while also enhancing watermark detection accuracy.\n\n2. Unlike previous rule-based red–green watermarking methods, it introduces a learning-based adaptive watermarking mechanism that determines token selection through reinforcement learning.\n\n3. The paper is clearly written and presents a coherent technical design, making the overall methodology and rationale easy to understand.\n\n4. The proposed framework shows good generality, as a trained reinforcement learning policy can be transferred to other base models without retraining.\n\n5. The experimental evaluation is comprehensive, covering multiple benchmarks and attack scenarios to validate robustness and effectiveness.\n\n\n6. The method demonstrates effective multilingual capability without language-specific retraining. This is achieved by leveraging the multilingual nature of the base model and a language-agnostic reinforcement learning policy that operates on token probability distributions rather than language syntax, enabling consistent watermark embedding across different programming languages."}, "weaknesses": {"value": "1. The definition of the indicator function `is_code(s_t)` in Equation (11) is ambiguous. While the paper states that a binary mask is applied to eliminate advantage values for non-code tokens, it does not specify how code tokens are identified in practice—whether through syntactic parsing, token classification, or language-specific heuristics. This lack of implementation detail hinders reproducibility and limits interpretability of the reported masking mechanism.\n   \n2.  Table 1 lacks comparison with several recent baselines, such as Yang et al. (2024)’s *Towards Code Watermarking with Dual-Channel Transformations* (IEEE S&P 2024) and Lin et al. (2024)’s *Decomposition then Watermarking: Enhancing Code Traceability with Dual-Channel Code Watermarking* and Li, Boquan, Zirui Fu, Mengdi Zhang, Peixin Zhang, Jun Sun, and Xingmei Wang. *\"Efficient and Universal Watermarking for LLM-Generated Code Detection.\"* 2024. Including these would provide a more comprehensive evaluation against state-of-the-art watermarking frameworks.\n\n3.  Figures 2 and 3, as well as Table 3, lack direct comparison with SWEET, a more code-specific watermarking baseline. Since SWEET represents one of the most relevant LLM watermarking approaches for program synthesis, the omission of this comparison limits the fairness and completeness of the experimental evaluation."}, "questions": {"value": "Could the authors include additional baselines mention above, in Tables 3 and Figures 2–3 for a more comprehensive comparison? As these baselines is code-oriented watermarking methods, including it would strengthen the experimental fairness and highlight CodeTracer’s relative advantages more clearly."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FOA2JjDB7T", "forum": "4msXyRezc2", "replyto": "4msXyRezc2", "signatures": ["ICLR.cc/2026/Conference/Submission15039/Reviewer_6U76"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15039/Reviewer_6U76"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15039/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991246360, "cdate": 1761991246360, "tmdate": 1762925362446, "mdate": 1762925362446, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}