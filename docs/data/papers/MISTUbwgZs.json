{"id": "MISTUbwgZs", "number": 13492, "cdate": 1758218567278, "mdate": 1762944588608, "content": {"title": "Remove360: Benchmarking Residuals After Object Removal in 3D Gaussian Splatting", "abstract": "Understanding what semantic information persists after object removal is critical for privacy-preserving 3D reconstruction and editable scene representations. In this work, we introduce a novel benchmark and evaluation framework to measure semantic residuals—the unintended semantic traces left behind—after object removal in 3D Gaussian Splatting. We conduct experiments across a diverse set of indoor and outdoor scenes, showing that current methods can preserve semantic information despite the absence of visual geometry. We also release Remove360, a dataset of pre/post-removal RGB images and object-level masks captured in real-world environments. While prior datasets have focused on isolated object instances, Remove360 covers a broader and more complex range of indoor and outdoor scenes, enabling evaluation of object removal in the context of full-scene representations. Given ground truth images of a scene before and after object removal, we assess whether we can truly eliminate semantic presence, and if downstream models can still infer what was removed. Our findings reveal critical limitations in current 3D object removal techniques and underscore the need for more robust solutions capable of handling real-world complexity.", "tldr": "This work introduces a benchmark and dataset to evaluate traces after 3D object removal, revealing limitations in current editing methods.", "keywords": ["Neural 3D Reconstruction", "Computer Vision", "Semantic Segmentation"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/073f43588567c08428537dc4586cedbebed40002.pdf", "supplementary_material": "/attachment/93a3c08b4db3312262725f355b3adec12ae7d4f9.pdf"}, "replies": [{"content": {"summary": {"value": "The paper introduces a new benchmark and evaluation framework for assessing the effectiveness of object removal techniques in 3D Gaussian Splatting, focusing on whether semantic residuals remain after the removal process. It presents Remove360, a dataset of real-world indoor and outdoor scenes with pre- and post-removal RGB images and object masks.  The paper evaluates several existing object removal methods using a combination of semantic, segmentation, and depth-based metrics to quantify the presence of unintended semantic traces after object removal. The findings highlight limitations in current 3D object removal techniques and emphasize the need for more robust solutions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "-The paper addresses a critical and previously underexplored aspect of 3D scene editing – the presence of semantic residuals after object removal, particularly relevant for privacy-preserving applications.\n-The proposed evaluation framework combines multiple complementary metrics (semantic, segmentation, and depth-based) to provide a thorough assessment of object removal effectiveness.\n-The Remove360 dataset fills a gap by providing a diverse set of real-world indoor and outdoor scenes with pre/post-removal captures and object masks, better reflecting real-world complexities than existing datasets."}, "weaknesses": {"value": "-The evaluation metrics rely on off-the-shelf semantic segmentation models, which may introduce errors and limit the robustness of the evaluation. The paper acknowledges this but could benefit from further discussion of potential biases and limitations.\n\n-Limited Analysis of Failure Cases: While the paper mentions failure cases (residual artifacts, incomplete removal, over-smoothing), a more detailed analysis of specific failure modes would be valuable."}, "questions": {"value": "-How sensitive are the evaluation metrics to errors in the ground-truth object masks or the predictions of the off-the-shelf semantic segmentation models? Can you provide quantitative results on this sensitivity?\n\n-The paper mentions combining metrics but doesn't provide details on how this is done. Are the metrics equally weighted, or is there a more sophisticated combination strategy? What is the justification for the chosen combination method?\n\n-Can you provide a more detailed analysis of specific failure cases observed in the experiments, including potential reasons for these failures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BFmFR1sAI1", "forum": "MISTUbwgZs", "replyto": "MISTUbwgZs", "signatures": ["ICLR.cc/2026/Conference/Submission13492/Reviewer_8dHo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13492/Reviewer_8dHo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13492/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761373174509, "cdate": 1761373174509, "tmdate": 1762924108708, "mdate": 1762924108708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "wED7udDnWq", "forum": "MISTUbwgZs", "replyto": "MISTUbwgZs", "signatures": ["ICLR.cc/2026/Conference/Submission13492/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13492/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762944587783, "cdate": 1762944587783, "tmdate": 1762944587783, "mdate": 1762944587783, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the persistence of semantic information after object removal in 3D scene reconstruction, with a particular focus on privacy-preserving 3D Gaussian Splatting. The authors introduce Remove360, a new benchmark dataset containing real-world indoor and outdoor scenes with paired pre- and post-removal RGB images and object masks. In addition, they propose a set of four quantitative metrics based on semantic segmentation drop, recognition accuracy, instance mask similarity, and depth change to evaluate how much semantic information remains after object removal. Using five state-of-the-art 3DGS-based methods, the authors show that all existing approaches leave detectable semantic residuals, even when removed objects are visually absent. The work highlights key limitations in current 3D editing pipelines and provides a valuable benchmark for developing future privacy-aware scene manipulation methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. A new dataset is released to measure the object removal, containing indoor and outdoor scene, which boosts the community.\n2. This paper is well-written and the measurement method is easy to understand."}, "weaknesses": {"value": "1. In the introduction, the definition of semantic residuals is unclear and lacks a rigorous mathematical or task-based formulation, which is critical for understanding and designing the subsequent evaluation metrics.\n\n2. Although semantic residuals in 3DGS have been visualized, a deeper analysis is required to understand their underlying causes.\n\n3. In the related work section, the authors only discuss 3D reconstruction and semantics in privacy protection applications. Object removal, however, is a subcategory of 3D scene editing, such as NeRF-based or 3DGS-based editing, and the relationships between these relevant studies and the current work should be discussed in more depth.\n\n4. The authors mention privacy challenges across different domains, but a systematic discussion of how existing methods protect privacy is missing.\n\n5. In the metric definition, the authors propose using semantic object recognition to measure the mIoU drop for identifying semantic residuals. However, segmentation performance is highly dependent on the chosen model, and altering the segmentation model could lead to inconsistent score drops, thereby introducing bias into the proposed metric.\n\n6. Some important statistics, such as the number of objects in the dataset, are not provided.\n\n7. While the experiments are comprehensive, they are entirely built upon existing techniques, with no newly designed method to demonstrate the authors’ own contribution.\n\n8. The ablation studies are insufficient. In the metric definition, the authors employ several hyperparameters, yet key ones, such as the depth threshold, are not analyzed, which raises concerns about the robustness of the proposed metric.\n\n9. The paper states that “operating on the 3D model offers privacy at a reasonable computational cost and better reconstruction quality.” However, a quantitative comparison of computational costs between the proposed 3D method and image-based editing is not provided.\n\n10. In the discussion section, the authors mention that semantic residuals are difficult to eliminate, but no potential solutions or future directions are suggested."}, "questions": {"value": "1. The definition of semantic residuals is not clear.\n2. This work only compares among existing methods, no technique novelty.\n3. The introduction of the proposed method are incomplete .\n4. This work requires more ablation studies."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "cdso98QqEm", "forum": "MISTUbwgZs", "replyto": "MISTUbwgZs", "signatures": ["ICLR.cc/2026/Conference/Submission13492/Reviewer_CQoP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13492/Reviewer_CQoP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13492/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830319018, "cdate": 1761830319018, "tmdate": 1762924108445, "mdate": 1762924108445, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to quantify the semantic traces remaining after object removal in 3D Gaussian Splatting. The core argument is that even when an object is visually removed successfully, invisible \"semantic residuals\" may still persist in the scene data. To address this challenge, the research introduces an evaluation framework and releases the Remove360 dataset, which contains pre-/post-removal RGB images and object-level masks from real-world scenes."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper focuses on the critical issue of invisible \"semantic residuals\" that may persist in scene data after 3D removal. To this end, it proposes a comprehensive evaluation from multiple dimensions, including semantics and segmentation.   \n2. The paper releases the Remove360 dataset, which includes pre-/post-removal RGB images and object-level masks from real-world scenes. Providing these scenes after physical object removal to serve as ground truth offers a solid basis for evaluating removal capabilities. It is also noteworthy that the dataset has garnered significant attention, with over 2,600 downloads in the last month."}, "weaknesses": {"value": "1. The paper lacks a comparison with previous evaluation metrics such as PSNR, SSIM, and LPIPS. It would strengthen the paper's argument to demonstrate cases where the difference lies between these traditional metrics and the proposed metrics.\n2. Regarding the paper's assertion that \"the model can detect residual information invisible to the human eye\": It is possible that the inpainted shape is similar to the original, or that artifacts introduced during the removal and inpainting process coincidentally trigger erroneous recognition by the segmentation model. These issues may stem from errors in the segmentation model itself, rather than flaws in the removal algorithm.   \n3. Concerning post-removal recognizability: If the removed area were replaced entirely with noise, it would also be unrecognizable. In such a scenario, the reliability of metrics like IoU_drop and sim_SAM would be questionable, as they might not distinguish a successful, context-aware inpainting from simple noise filling."}, "questions": {"value": "My main questions concern the reliability of IoU_drop and sim_SAM, and the comparison with previous pixel-level metrics like PSNR, SSIM, and LPIPS. Please refer to the weaknesses for details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0F7nECWeRf", "forum": "MISTUbwgZs", "replyto": "MISTUbwgZs", "signatures": ["ICLR.cc/2026/Conference/Submission13492/Reviewer_NHx4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13492/Reviewer_NHx4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13492/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900866981, "cdate": 1761900866981, "tmdate": 1762924107976, "mdate": 1762924107976, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new dataset and a suite of metrics for evaluating the quality of object removal in 3D Gaussian Splatting. It emphasizes the importance of achieving high-quality, privacy-preserving object removal by examining whether a removed object is truly eliminated or leaves behind semantic residuals that reveal its presence. The proposed metrics jointly assess both low-level visual signals (depth) and high-level semantic consistency, providing a holistic evaluation of removal fidelity. The newly released Remove360 dataset, comprising 11 diverse indoor and outdoor scenes, serves as a comprehensive benchmark for assessing and comparing existing 3DGS-based object removal methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Remove360\n\nThe paper comes with a real world dataset for object removal, i.e., Remove360. The dataset provides a diverse collection of both indoor and outdoor scenes under different lightings with objects pre- and post- removal. It also comes with GT annotations of objects being removed. Remove360 focuses on the multi-object removal scenario which is a better match for its everyday usage. The dataset could serve as a baseline benchmarking dataset for future works.\n\n- Low and high level metrics\n\nThe paper proposes several metrics for object removal evaluation. These metrics cover a wide range of quality assessments, from low level depth consistency to high level semantic labelings. Specifically, it evaluates the segmentation accuracy, semantic accuracy, and depth accuracy. Together, it provides a comprehensive, multi-level evaluation framework for quantifying the quality of 3D object removal."}, "weaknesses": {"value": "- Regions Outside the Object\n\nA common issue in object removal is that shadows, reflections, or indirect effects of the removed objects often remain in the scene. These residual pixels lie outside the object’s mask, yet can still reveal visual or semantic cues about what was removed. The paper’s proposed metrics primarily focus on evaluating changes within the masked region, without explicitly considering these contextual regions outside the mask. Such unaddressed residuals may still compromise privacy or expose identifiable traces. For instance, as shown in Figure 2, leftover shadows remain visible but are not penalized by the current evaluation framework.\n\n- Focus Limited to 3DGS-Based Methods\n\nThe paper’s evaluation framework and experiments concentrate exclusively on 3DGS–based object removal techniques. While this focus provides depth and clarity, it overlooks alternative paradigms such as 3D inpainting or neural field completion methods, which also play an important role in 3D scene editing and privacy-preserving reconstruction. 3D inpainting method, e.g., Inpaint3D, takes advantage of diffusion-based priors to fill in missing regions and handle long-range dependencies such as shadows or reflections. Although 3D consistency is not guaranteed, these two types of methods are on the different ends of the spectrum and should both be evaluated."}, "questions": {"value": "Overall the paper comes with a nice collection of metrics and dataset for 3D object removal benchmarking. I have some questions to be answered:\n\n- How do the authors plan to handle shadows, reflections, and indirect lighting effects that remain outside the object mask after removal?\n- Have the authors considered extending their metrics to include contextual regions beyond the mask to better capture these residual cues?\n- How does 3D inpainting or neural field completion approaches perform in the benchmark?\n- Have the authors conducted any human studies to assess whether semantic residuals are perceptually noticeable in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QcpvUVZRTR", "forum": "MISTUbwgZs", "replyto": "MISTUbwgZs", "signatures": ["ICLR.cc/2026/Conference/Submission13492/Reviewer_mkkv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13492/Reviewer_mkkv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13492/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762130442284, "cdate": 1762130442284, "tmdate": 1762924107650, "mdate": 1762924107650, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}