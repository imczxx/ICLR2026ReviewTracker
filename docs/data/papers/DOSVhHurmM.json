{"id": "DOSVhHurmM", "number": 20299, "cdate": 1758304538977, "mdate": 1759896985321, "content": {"title": "Selective Risk Certification for LLM Outputs via Information-Lift Statistics: PAC-Bayes, Robustness, and Skeleton Design", "abstract": "Large language models frequently generate confident but incorrect outputs, requiring formal uncertainty quantification with abstention guarantees. We develop information-lift certificates that compare model probabilities to a skeleton baseline, accumulating evidence into sub-gamma PAC-Bayes bounds valid under heavy-tailed distributions. Across eight datasets, our method achieves $77.2$\\% coverage at $2$\\% risk, outperforming recent 2023-2024 baselines by 8.6-15.1 percentage points, while blocking $96$\\% of critical errors in high-stakes scenarios vs $18-31$\\% for entropy methods. Limitations include skeleton dependence and frequency-only (not severity-aware) risk control, though performance degrades gracefully under corruption.", "tldr": "", "keywords": ["LLM risk"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/318c730ea56bded356dedcbf1e191370a7896919.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces an approach for selective prediction for LLMs with guarantess by comparing the model distribution to a skeleton distribution, which is a simpler distribution over tokens.\nThe authors show that their approach provides better coverage at similar risk levels than prior methods."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The improvements over baseline methods seem substantial in a well-motivated and important area"}, "weaknesses": {"value": "- Overall, the paper is quite hard to read and understand and many necessary details are left out, as specified in the next points. Altogether, this makes it hard to understand the contribution and validity of the presented results.\n\n- The description of the method itself would benefit heavily from providing intuitions: for example, why is clipping used? Does it have any theoretical or practical advantages?\n\n- The paper would also benefit from more clear introduction of notation and quantities, such as the $\\Delta(S)$ in the main theorem 2.4 of the paper, which is never formally introduced. Is it the same as the previously introduced $\\Delta$ and what are the meanings of \\hat being there or not? The definition is only found in the App. C.1. which is nevertheless also not referenced in the main text. Another example are the experiments. For example, what exactly is Figure 4 showing, which models are used, which datasets, etc? The Tables and Figures in general are never really described, only with a short caption. Also, important assumptions like the heavy-tailedness of LLM probabilities (L127-128) are only shown in the appendix and not described well in the main text.\n\n- The lift statistic defined in Def. 2.1. requires access to probabilities but the authors at the same time note that they are focussing on black-box APIs (L292-294) which usually do not give away probabilities. How is this handled? The authors mention a \"top-k\" compensation but how it works is never actually explained. This seems to be a crucial point that needs to be clarified.\n\n- The authors use a benchmark of 100 high stakes examples and show results in Table 6. The results themselves seem impressive but no details about the set are given anywhere in the main text so it is hard to understand their validity.\n\n- The discussion of related works is short in the main paper and only found in the appendix. For example, the discussion glances over works on non-exchangeability in conformal prediction like Farinhas et al. 2024 which specifically targets non-exchangeability to apply it for LLMs, which should be discussed."}, "questions": {"value": "- A citation or reference for the statement in the first paragraph of the intron would be useful\n\n- L225-226 & L292-294 are a bit awkwardly placed between two tables\n\n- Could you please specify how you created the high stakes set used for evaluation?\n\n## References\n\nFarinhas, António, et al. \"Non-exchangeable conformal risk control.\" ICLR 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "73WVPKvyRZ", "forum": "DOSVhHurmM", "replyto": "DOSVhHurmM", "signatures": ["ICLR.cc/2026/Conference/Submission20299/Reviewer_kg62"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20299/Reviewer_kg62"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761560960880, "cdate": 1761560960880, "tmdate": 1762933768743, "mdate": 1762933768743, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Information-Lift Certificates for selective risk control in large language models (LLMs). The method compares model probabilities ( P(y|x) ) against a skeleton baseline distribution ( S(y) ), defining an information lift statistic ( L = \\log P - \\log S ). Lift values are accumulated into sub-gamma PAC-Bayes bounds, providing formal guarantees even under heavy-tailed LLM token distributions. The paper also introduces a VSD algorithm for optimizing skeletons and provides robustness theory."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "+ Originality: The paper introduces a new formal certification framework that merges PAC-Bayes generalization theory with LLM uncertainty quantification. Applying sub-gamma concentration to token-level text generation is novel and well motivated.\n\n\n+ Quality: The theoretical formulation is solid, deriving sequential, anytime-valid bounds with clear assumptions.\n\n\n+ Clarity: Overall, the paper reads well and the mathematical flow is consistent.\n\n\n+ Significance: The work aims to solve an important safety problem: how to formally quantify and control LLM uncertainty in high-stakes settings. Most of all, most existing methods are heuristic."}, "weaknesses": {"value": "- Presentation: The paper is difficult to follow before Section 2. It would help to include a short background on uncertainty quantification and PAC-Bayes (currently shown in the appendix). Figure captions are too brief (e.g., Figure 1 does not explain the pipeline). Figure 3’s legends overlap and are hard to read.\n\n\n- The core motivation (Table 6) is blocking “critical errors,” but the paper did not define what constitutes one. The authors also note that their certification is frequency-based and not severity-aware. This makes the 96% result hard to interpret. Is the mechanism actually sensitive to severity, or did these errors just happen to have low information-lift?\n\n\n- The paper's claim of being a black-box method is somewhat misleading. The proposed method requires access to token probabilities (at least top-k, per Table 8). This is fundamentally different from true black-box methods that only use the final generated text (e.g., based on similarity). The paper should clarify this distinction. Or maybe rephrase the claim as “API-accessible but logit-free.”\n\n\n- The paper dismisses Conformal Prediction based on the exchangeability assumption. This critique is outdated. However, recent work already explores non-exchangeable CP variants for autoregressive text. Those should be acknowledged for fairness.\n\n\n- Although VSD improves robustness, it appears each new full model and calibration dataset needs a new optimization. This represents a significant computational and maintenance cost."}, "questions": {"value": "1. How sensitive is certification performance to the initial skeleton before VSD optimization? Would a poor initialization (e.g., random unigram) still yield valid PAC-Bayes bounds, or just weaker empirical coverage?\n2. There seems to be a theoretical tension here. The VSD objective partially optimizes for min KL(P||S). Then the lift statistic L(B) will not be a heavy-tailed distribution. This seems to undermine the whole motivation for using sub-gamma bounds. Can you clarify this? Does the empirical distribution after VSD optimization still show heavy tails?\n3. How sensitive is the optimized skeleton S to changes in the full model P? If P is fine-tuned or updated (e.g., a new version), must VSD be re-run with a new calibration set?\n4. The paper’s highlight is blocking 96% of critical errors (Table 6), yet it admits the framework is frequency-based, not severity-aware. Is there an empirical correlation between criticality and low information-lift?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "g2SefIhyoD", "forum": "DOSVhHurmM", "replyto": "DOSVhHurmM", "signatures": ["ICLR.cc/2026/Conference/Submission20299/Reviewer_H74A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20299/Reviewer_H74A"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926632423, "cdate": 1761926632423, "tmdate": 1762933767924, "mdate": 1762933767924, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work is the first to apply anytime-valid PAC-Bayes bounds to information-lift statistics for LLM certification, providing sub-gamma PAC-Bayes analysis, skeleton robustness theory, and variational skeleton design. The authors evaluate across a wide range of datasets that they show require sub-gamma lift moment assumptions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Motivation and novelty is clear\n- Well-written: only the points necessary for communicating the contributions are included. Ideas are expressed clearly and concisely\n- Strong empirical results across a wide range of benchmarks"}, "weaknesses": {"value": "- limited by skeleton design\n- novelty could be made cleared"}, "questions": {"value": "I think the main body would benefit from some discussion on the difficulties of applying \"anytime-valid PAC-Bayes bounds to information-lift statistics for LLM certification.\" To someone like me, who is unfamiliar with this literature, it is unclear how much of the theoretical contributions are novel or how much of the contributions can be viewed as a straightforward application of prior work to a new problem."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vb4HkGSOse", "forum": "DOSVhHurmM", "replyto": "DOSVhHurmM", "signatures": ["ICLR.cc/2026/Conference/Submission20299/Reviewer_HZZk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20299/Reviewer_HZZk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947448462, "cdate": 1761947448462, "tmdate": 1762933767684, "mdate": 1762933767684, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a critical gap in the safe deployment of Large Language Models (LLMs): the lack of reliable uncertainty quantification for generative tasks(sequential prediction). The authors argue that the prior works are fundamentally ill-suited for modern LLMs for two reasons.\nOne is \"Distributional Mismatch\": They rely on concentration inequalities (like Bernstein's) that assume sub-exponential tail distributions, whereas LLM token probabilities are empirically shown to be heavy-tailed, and the other is \"Task Mismatch\": They are designed for i.i.d. classification tasks, not for autoregressive, sequence-level generation.\n\nTo solve this, the paper introduces \"Information-Lift Certificates\", which instead compute the \"Information Budget\" ($\\hat{\\Delta}$) for each generated sequence.\nThis score is the cumulative sum of token-level \"Information Lifts\" ($L(y)$), which measure the log-probability gain of the full model ($P(y \\mid x)$) over a simpler baseline \"skeleton\" model ($S(y)$)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This work identifies the failure of standard sub-exponential bounds (Figure 2) and instead building a framework on sub-gamma distributions, it provides PAC-Bayes certificates that are practically reliable for LLM outputs.\n\nThis robust theoretical footing translates directly into state-of-the-art results. The VSD certificate method is shown to dominate all baselines across the entire risk-coverage curve (Figure 4). It achieves an average of 77.2% coverage at a 2% target risk, an 8.6-15.1 percentage point improvement over recent methods.\n\nThe inclusion of $\\eta$-robustness and $\\kappa$-informativeness theorems, along with the VSD optimization algorithm, provides a complete and principled framework, moving beyond simple heuristics."}, "weaknesses": {"value": "The framework's main weakness is its reliance on the \"skeleton\" distribution, $S(y)$. This introduces a significant new design choice, and as the authors note (Table 2), the optimal skeleton (e.g., temperature-smoothed prior, domain-specific unigram LM) is task-dependent. This effectively trades one set of assumptions (distributional) for another (choice of a good baseline).\n\nAlso, the method introduces several hyperparameters that require careful tuning, most notably the clipping parameter $B$ and the VSD tradeoff parameter $\\lambda$. While ablations are provided (Figure 6), this adds a layer of complexity for practitioners.\n\nFinally, The sub-gamma assumption, while more realistic, is not universal. The authors transparently state that it fails for 15% of their dataset-model pairs. For these cases, they must resort to \"conservative parameter inflation\" (Appendix H.1), which involves manually adjusting parameters. This weakens the claim of a fully dataset(task)-agnostic solution and requires a pre-check (a KS test) and potential adjustment, which could be a barrier to straightforward application."}, "questions": {"value": "* Could you clarify how the risk-coverage plot in Figure 4 was generated with the target risk? Also, why does the selective risk for the VSD certificate appear to decrease as coverage increases, which seems counter to the typical risk-coverage trade-off?\n\n* How were the baseline methods, such as Conformal Prediction and traditional Selective Classification, adapted for sequential generation tasks like QA? Given they are typically designed for classification, what was the exact mechanism used for abstention (e.g., did a single rejected token lead to rejecting the entire sequence)?\n\n* Given that the sub-gamma assumption is not met in 15% of cases and requires manual parameter inflation, does this not make the method dataset-specific? How would this approach compare to simpler SC methods in a real-world application where pre-testing and dataset-specific tuning may not be feasible?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nsIubG4A1F", "forum": "DOSVhHurmM", "replyto": "DOSVhHurmM", "signatures": ["ICLR.cc/2026/Conference/Submission20299/Reviewer_3kff"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20299/Reviewer_3kff"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762000008921, "cdate": 1762000008921, "tmdate": 1762933767220, "mdate": 1762933767220, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present an approach for estimating the probability that an LLM will output the correct answer, which is based on likelihood ratios of each generated token under the true autoregressive LLM distribution compared to a “skeleton” distribution. The average of successive token likelihood ratios serves as the criterion for answering a query or abstaining, based on a threshold."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The method is general and the theory is interesting.\n- The sequential nature of the proposed uncertainty quantification allows early exits, providing latency and cost savings in practice."}, "weaknesses": {"value": "- The paper does not distinguish between quantifying uncertainty at token level vs whole-sequence level. For some baselines, such as entropy, this distinction typically carries large performance differences and could impact the top-line results.\n- The choice of uncertainty signal (likelihood ratios between p(y|x) and a simpler \"skeleton\" distribution) doesn’t seem novel. I believe I have seen substantially similar approaches in other papers. If you disagree, please provide more extensive references to related work in the LLM hallucination prevention, uncertainty quantification, routing, and cascading literature.\n- The impact of the choice of skeleton is unclear. I see your robustness analysis but its scope appears limited to your own methodology, without studying the relative performance compared to baselines. I would welcome an analysis comparing your method against baselines under skeleton misspecification.\n- The authors' heuristic recommendations for skeleton choice based on benchmark type is not adequately supported. Each type of benchmark only has 1 or 2 representatives; no train/test split was used to ground these recommendations using held-out benchmarks."}, "questions": {"value": "- Please discuss the choice of quantifying uncertainty at the token level vs the whole-sequence level. For example, the entropy baseline can be applied both at the token and the whole-sequence level, with quite different results.\n\n- Could you clarify the risk control you achieve? It is unclear if your risk control is taking into account the finite sample errors of $\\hat{\\Delta}$ (when generalizing from the held-out calibration data to the ground truth data distribution), which lead to miscalibration of the estimated threshold $\\hat{\\tau}$.\n\n- Could you comment on the novelty of your theoretical results? I'm not very familiar with PAC Bayes bounds. It would be valuable to know if your theorems constitute independent advances vs recapitulations of known theorems in a new context.\n\n- The paper would benefit from some empirical recapitulation of the claimed heavy-tailed nature of token probabilities (including references to the literature). Would you be able to add those in?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LQRU1NzsjB", "forum": "DOSVhHurmM", "replyto": "DOSVhHurmM", "signatures": ["ICLR.cc/2026/Conference/Submission20299/Reviewer_sJZX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20299/Reviewer_sJZX"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission20299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762030937309, "cdate": 1762030937309, "tmdate": 1762933766347, "mdate": 1762933766347, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}