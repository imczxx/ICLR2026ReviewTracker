{"id": "rxvAkQFP7U", "number": 408, "cdate": 1756738554726, "mdate": 1759898262608, "content": {"title": "AwareCompiler: Agentic Context-Aware Compiler Optimization via a Synergistic Knowledge-Data Driven Framework", "abstract": "Compiler optimization is crucial for enhancing program performance by transforming the sequence of optimization passes while maintaining correctness. Despite the promising potential of large language models (LLMs)-based agent for software optimization, automating compiler optimization remains challenging due to: (1) semantic misalignment between abstract program representations and concrete optimization passes, (2) inefficient interaction mechanisms between agents and compiler environments, and (3) reward sparsity from the extensive decision-making process within large optimization spaces. This paper introduces \\textbf{AwareCompiler}, an agentic framework for compiler optimization that addresses these challenges through three key innovations: structured knowledge integration and dataset construction, knowledge-driven adaptive pass generation, and data-driven hybrid training pipeline. Experimental results on standard benchmarks demonstrate that AwareCompiler significantly outperforms existing baselines in both performance and efficiency, highlighting the effectiveness of our synergistic knowledge-data-driven approach. Our code is publicly available at https://anonymous.4open.science/r/AwareCompiler-4935.", "tldr": "", "keywords": ["Large Language Model", "Compiler Optimization", "Reinforcement Learning", "LLM-based Agents", "Pass Tuning"], "primary_area": "infrastructure, software libraries, hardware, systems, etc.", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/acfd6260d1d22a0f135f5837277d07a60a698e91.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel training pipeline of LLM-based compiler, targeting at solving an important problem of reducing generated code size, with the action space of determining the optimization pass sequences within the compiler.\nThe core contribution of this training pipeline is allowing the model to integrate human-defined domain knowledge dataset in the reasoning process. The model is trained on two stages, one SFT followed by RL.\nExperiments shows the trained models used on several compilation tasks reduces the generated code size to the human-expert level (-Oz). In some cases, it is even slightly better than human experts. Moreover, it also shows a high success rate compared to base models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Solid problem definition with a reasonable solution.\n- Strong empirical results. LLM-based methods achieves near human-expert results, sometimes even better\n- The evaluations are abundant, covering most essential parts like success rates, ablations and reward design"}, "weaknesses": {"value": "- The major goal is reducing the code size, instead of the primary target of compiler optimization, which is producing code that runs faster. Though the author mentions reducing code size **often** improves runtime efficiency, it is not always the case (e.g. -O2 runs faster than -O1, but with bigger code size, from Table 1). \n- Building on the previous point, it remains unclear how AwareCompiler affects runtime efficiency, even when code size reduction is the main optimization target. A more explicit discussion or evaluation of this trade-off would strengthen the work.\n- Generalizability: Although the results show a slight improvement over -Oz, which is manually designed, there is some concern that the trained model may primarily be distilling knowledge from existing human-designed compilers, particularly during the supervised fine-tuning (SFT) stage. It would enhance the paper’s contribution to provide evidence of transferability, such as demonstrating effectiveness on other compilers or showing that the model can adapt to new tasks with minimal human intervention."}, "questions": {"value": "- Could the authors elaborate on how the context-aware dataset is generated and how it is incorporated into the training process?\n- What level of effort is required to generate the training data? Specifically, would it be necessary to recreate the dataset from scratch—potentially with significant effort—when adapting the approach to new tasks or compilers?\n- What is the 'data' in 'w/o data' Table 2?\n- How does the proposed method affect the runtime performance of the generated code?\n- From a theoretical standpoint, could the same training pipeline be applied to optimize other compiler performance metrics, such as runtime speed, instead of code size?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gWNRn279qG", "forum": "rxvAkQFP7U", "replyto": "rxvAkQFP7U", "signatures": ["ICLR.cc/2026/Conference/Submission408/Reviewer_ZsmH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission408/Reviewer_ZsmH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission408/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724149317, "cdate": 1761724149317, "tmdate": 1762915513138, "mdate": 1762915513138, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AwareCompiler, an agentic framework for compiler optimization that leverages LLMs to generate optimal sequences of optimization passes. The work identifies key challenges in existing LLM-based approaches, namely semantic misalignment, inefficient interaction, and reward sparsity. To address these, it designs a data driven approach involving: (1) a structured compiler knowledge base and a corresponding reasoning dataset, (2) a knowledge-driven adaptive pass generation mechanism, and (3) a hybrid training pipeline combining SFT and RL. Experiments on standard benchmarks show that AwareCompiler significantly improves code size reduction compared to baselines"}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The primary strength lies in effective integration of a structured, domain-specific knowledge base with an agentic LLM framework. This grounding of the LLM's reasoning with empirical, symbolic, and negative knowledge about compiler passes is a good step beyond generic prompting. The quality of the work is good demonstrated by a thorough experimental setup with a diverse set of benchmarks and ablation studies. The work holds some potential for impact by providing a practical methodology for automated compiler optimization that can be extended to other objectives and domains."}, "weaknesses": {"value": "The paper is light on the details of constructing the crucial knowledge base and the reasoning dataset $D$. The scalability and reproducibility of the proposed framework heavily depend on the effort and expertise required to curate this knowledge. A more detailed description of this process whether it was manual, automated, or a mix would be necessary to assess the practicality of applying this method to new compilers or architectures. Furthermore, while the exclusion of ML-based baselines is somewhat justified due to non-public datasets, their complete omission leaves a gap in the evaluation. A qualitative discussion or comparison of computational overhead against prominent ML methods would strengthen the paper's positioning. Finally, the evaluation is solely focused on code size reduction, leaving its effectiveness for other critical objectives like runtime performance unexplored."}, "questions": {"value": "Could you elaborate on the construction of the knowledge base ($K_{emp}$, $K_{sym}$, $K_{neg}$)? What was the methodology for collecting this knowledge, and how much manual effort from a compiler expert was involved? How do you envision this process scaling to a different compiler (e.g., GCC) or a major new version of LLVM?\n\nThe paper mentions the reasoning dataset $D$is derived from \"expert annotations or learned heuristics.\" Could you provide more details on its size, source, and composition? Specifically, what was the ratio of expert-annotated samples to those generated by heuristics, and which heuristics were employed?\n\nThe agentic reasoning process involves multiple steps at inference time. What is the compilation time overhead introduced by AwareCompiler when compared to a standard heuristic baseline like $-Oz$? A characterization of this overhead would be important for understanding the framework's practical viability.\n\nThe current work focuses on selecting and ordering compiler passes. Many LLVM passes also accept numerical or categorical arguments (e.g., loop unroll factor, inlining thresholds). Does the AwareCompiler support the tuning of these pass parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RMKa0gJ2xn", "forum": "rxvAkQFP7U", "replyto": "rxvAkQFP7U", "signatures": ["ICLR.cc/2026/Conference/Submission408/Reviewer_n7zk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission408/Reviewer_n7zk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission408/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910531847, "cdate": 1761910531847, "tmdate": 1762915513013, "mdate": 1762915513013, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes AgentCompiler, an agent for code optimization with a multi-turn interaction training process. They show that while existing LLMs have many success in other research, compiler optimization by LLM-based agents is often inefficient due to the issues of invalid or ineffective optimization passes. To overcome this challenge, they provide three main contributions. First, they integrate structured knowledge for dataset construction. They defined three levels of categories: empirical, symbolic, and negative knowledge for context-aware dataset construction. Second, they design a knowledge-driven adaptive generation process that focuses on extracting the best code features and domain knowledge to create the most effective pass sequence. They define the best pass sequence as the one that minimizes the code size. Third, they propose a data-driven hybrid training pipeline from their constructed dataset with their assigned knowledge base,which integrates supervised fine-tuning and reinforcement learning. The SFT phase helps the agent to solve different types of compiler optimization for pass generation, while the RL phase allows the agent to choose the best optimization paths, which the agent hasn’t seen in their existing trained knowledge. In the evaluation, they perform the experiment on a diverse set of benchmark suites and compare their work with heuristic approaches, ML-based approaches, and well-known closed and open LLMs for compiler optimization. They achieve significantly improvement of code optimization in terms of code size reduction, such as GPT-5. AwareCompiler has been trained using Qwen models with 1B, 3B, and 7B parameters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The research problem is crucial for the development of smart compilers.\n- Well-presentation and writing. I give a thumbs up for Figure 2. It clearly described the workflow of the existing approaches and why their proposed compiler can be considered as a more advanced technique.\n- This work proposes a pipeline with the intuition that, as an agent for compiler optimization, its most important process, optimal pass generation, should be done by a thoroughly reasoning process. It made sense to me, since code optimization usually requires more reasoning for LLMs to get good output.\n- Proposed experiments are sound and clear. The replication package is available and can run without errors."}, "weaknesses": {"value": "- The agent was built only from Qwen. An analysis of the performance of an agent built from other models is needed. \n- Although the authors provide several analyses on the accuracy with/without different components of knowledge and data, along with reward sparsity, an experiment on different hyperparameters for AwareCompiler SFT and RL processes is recommended.\n- With AwareCompiler-7B, we have some benchmark that shows, without data, the agent is actually performing better (see Table 2, AwareCompiler-7B with blas dataset). While it is still sound, I suggest the author to pick up several cases to see the reason."}, "questions": {"value": "- In Table 2, it seems that with all AwareCompiler models, removing data didn’t significantly drop the accuracy compared to removing knowledge and both. Can you provide possible reasons for this observation?\n- In section 4.1, what is the training time for SFT and RL processes on your reported hardware configuration? \n- Will the training and inference time increase if you build AwareCompiler on bigger models, such as QwenCoder2.5-32B? If yes, what are the scales of training and inference time increased compared to your existing model?\n- Some benchmarks were very old, such as blas and ngb. Do you have any related work that proofs these datasets are still up-to-date?\nWill AwareCompiler be able to support any programming language’s optimization? If not, what are the main challenges?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5bOWjZKII4", "forum": "rxvAkQFP7U", "replyto": "rxvAkQFP7U", "signatures": ["ICLR.cc/2026/Conference/Submission408/Reviewer_k57g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission408/Reviewer_k57g"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission408/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943461019, "cdate": 1761943461019, "tmdate": 1762915512910, "mdate": 1762915512910, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Summary:\n  * Previous work in compiler optimization relies on often brittle techniques and heuristics for selecting compilation passes to convert code in a high-level language to semantically equivalent but faster code in a lower level language.\n* Recent work has attempted LLM-guided solutions for this problem that have achieved reasonable, but not groundbreaking success over heuristics.\n* The authors hypothesize that the central limitation that causes such agents to produce ineffective or invalid optimizations is inherently due to a decoupling between the agent's world model of how an optimization should behave and how it actually behaves. Specifically, the authors hypothesize that providing more nuanced context, in the form of an agent framework might yield significant benefits. They introduce four sources of additional information:\n\t* Domain specific knowledge: AwareCompiler introduces a \"cheatsheet\" hashmap that helps identify previously encountered code features and a corresponding optimal pass (or sub-optimal pass).\n\t* Context aware dataset construction: The data used to train AwareCompiler is specifically curated to ensure it's in an LLM-friendly format and contains features specifically curated for compiler optimization.\n\t* Knowledge driven adaptive pass generation: AwareCompiler incorporates a knowledge retrieval mechanism to ensure relevant information is used for the each sequence generation.\n\t* Supervised fine-tuning and RL training: Finally, AwareCompiler is trained on the dataset using the a SFT pass and a RL pass.\n* Overall, the authors find that on seven benchmarking domains, AwareCompiler significantly outperforms mature heuristic based baselines (`-O1`, `-O2`, `-O3`, `-Oz`) and many LLM assisted models (with a finetuned model that is 20% of the size of the next smallest baseline)."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "> figures and quality of writing\n\nThe paper has been a joy to read and thank you for putting in the extra work to make informative and structured figures as well as a detailed problem statement!\n\n> However, LLM-based agents often produce ineffective or invalid optimization passes due to insufficient contextual reasoning and an inability to predict the real-world effects of optimizations, leading to performance degradation or even program crashes. Addressing these shortcomings requires tackling three critical challenges: (1) semantic misalignment [...] (2) ineffective interaction [...] (3) reward sparsity.\n\nThis is the central issue in a lot of automated verification domains like theorem proving, code generation, mathematical reasoning, etc. and solutions in other communities has converged to similar solutions (which lends credence to the authors' insights)."}, "weaknesses": {"value": "*I'm not an expert in compiler optimization literature hence, this review is primarily evaluating the soundness of the evaluation mechanism from the lens of similar agents developed for code generation.*\n\n**Practicality**: The practical reason for the success of heuristic based optimizations is due to their well-understood optimization surface and determinism (in code generation; does the same hold for compiler optmizations?). I don't see any comparison in this project on the speed of such heuristic based optimizations compared to the speed of an agent-based optimization procedure on commodity hardware.\n\n**Benchmarking Scope**: This is more of a series of questions rather than true weaknesses. The most important rule of benchmarking is to ensure that the purpose of the benchmark aligns with the purpose of the algorithm. I'm not 100% sure if that is the case here:\n- **Are these benchmarks specifically geared towards testing adaptive compilers?**: Almost all the benchmarks used in this paper are _extremely_ old (Other than one exception, all were authored before 2010). While age isn't a measure of quality of a benchmark, its reasonable to assume that the *intent* of the benchmark was primarily geared towards heuristic based benchmarks. Do such benchmarks accurately capture the compiler community's current motivations?\n- To take one example, `CHStore` (https://github.com/ferrandi/CHStone) is only 12 short C-based benchmarking programs. **This seems like a terribly small dataset and an unrealistic (modern) workload** to draw conclusions from. Furthermore, this opens up the benchmark set to a lot of data leakage?\n- Proposing a new benchmark is outside the scope of this paper but we can be creative about constructing relevant tasks.\n\t- For example, one reasonable task (that I'm aware of) is optimizing CUDA kernels (e.g. [kbench](https://github.com/SakanaAI/robust-kbench) is fairly mature dataset for this). Can / if we use AwareCompiler to optimize the optimization passes for the baseline here, do we still see an improvement over baselines?\n\t- Alternatively, showing a qualitative case study that summarizes the non-triviality of the task, and traces through AwareCompiler's solution and other solutions would be extremely insightful as well.\n\n**Baseline Issues:** I'm not 100% sure if the baseline set is useful. For example, I don't see any ML-based baselines here (neural networks trained for the sequential decision making task). For example, the AutoPhase paper [mentioned](https://proceedings.mlsys.org/paper_files/paper/2020/file/5b47430e24a5a1f9fe21f0e8eb814131-Paper.pdf) seems to also introduce an RL pipeline using the same features as this algorithm. Is there a reason this wasn't a good fit for a direct comparision?\n\n**Ablation Issues:** The ablations table is slightly inconclusive. Ignoring the size of each benchmark and the lack of standard deviation information (which should be mentioned in a revised version), Table 2 seems to show that there is inconclusive evidence about which feature (knowledge or data) is more useful. It's clear that the models internal knowledge bank is unreliable (`w/ knowledge and data` rows) but the contribution of the other  rows is inconclusive for different model sizes and for different benchmarks.\n * Furthermore, given how _bad_ the internal reasoning of the model is, and the extreme likelihood of data leakage, how well does AwareCompiler extrapolate to new problems not in the training set? i.e.:  In practice, when we see a new problem not represented in the training data, it's understandable that AwareCompiler's performance will somewhat degrade. If the degradation is smaller than that of a pure LLM-assisted optimization approach, it could be a really strong result to motivate an agentic framework approach.\n\n**Overall:** I'm currently in favor of rejecting this paper because of issues in the benchmarking and evaluation procedure. However, I'm open to potentially revise my rating and I'd be more than happy to engage in further discussion with the authors to improve the quality of this paper."}, "questions": {"value": "See weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "kypA4Ow2hC", "forum": "rxvAkQFP7U", "replyto": "rxvAkQFP7U", "signatures": ["ICLR.cc/2026/Conference/Submission408/Reviewer_pY2t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission408/Reviewer_pY2t"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission408/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762118457223, "cdate": 1762118457223, "tmdate": 1762915512778, "mdate": 1762915512778, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}