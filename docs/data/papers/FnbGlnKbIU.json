{"id": "FnbGlnKbIU", "number": 6709, "cdate": 1757993041263, "mdate": 1759897899767, "content": {"title": "Two-Layer Convolutional Autoencoders Trained on Normal Data Provably Detect Unseen Anomalies", "abstract": "Anomaly detection refers to the techniques that identify (probably unseen) rare or suspicious data that deviate significantly from the pre-defined normal data (Chalapathy & Chawla, 2019; Ruff et al., 2021). Empirical studies have observed that generative models trained on normal data tend to produce larger reconstruction errors when reconstructing anomalies. Based on this observation, researchers have developed various anomaly detection methods, referred to as reconstruction-based anomaly detection (RBAD) (Lv et al., 2024; Li et al., 2024) in the literature.\n\nDespite the empirical success of RBAD, the theoretical understanding of RBAD is still limited. This paper provides a theoretical analysis of RBAD. We analyze the training dynamics of a 2-layer convolutional autoencoder and introduce the cone set of the features. We prove that the cone sets of the normal features would absorb the (convolutional) kernels of the autoencoder during training and use these absorbed kernels to reconstruct the inputs. The absorbed kernels are more aligned with the normal features, which explains the cause of the reconstruction error gap between the normal data and the anomalies. Synthesized experiments are provided to validate our theoretical findings. We also visualize the training dynamics of the autoencoder on real-world data, demonstrating our proposed cone set intuition.", "tldr": "", "keywords": ["Learning Theory"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0bae540963926802de003204519b5c9c1a6fe6c3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper addresses the insufficient theoretical understanding of reconstruction-based anomaly detection (RBAD) and proposes a new theoretical framework introducing the concept of a “cone set” to describe the dynamics of feature learning during the training of convolutional autoencoders (CAEs). Through rigorous derivations, the authors demonstrate how convolution kernel parameters are gradually attracted to the “cone set” and align with corresponding true feature directions. Overall, the theoretical contribution lies in establishing a formal analytical foundation for RBAD, filling a major gap in the literature where theoretical explanations for autoencoder-based anomaly detection were largely absent."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper’s greatest strength lies in constructing a systematic theoretical framework for RBAD. While previous works achieved strong empirical performance, they lacked a clear explanation for why reconstruction error distinguishes anomalies. Through the cone set and feature absorption mechanism, this paper is the first to explain—via gradient dynamics—why AEs tend to retain only normal features while poorly reconstructing anomalies. The discussion in VPDM [1] of the “identical shortcut” phenomenon indirectly supports this view: if a model relies excessively on raw input rather than stable feature extraction, it may reconstruct anomalies as well, leading to detection failure. The cone set theory precisely explains that models which genuinely learn features, rather than memorizing inputs, naturally exhibit poor reconstruction for anomalies.\n2. The theoretical formulation is highly structured, with well-defined assumptions, lemmas, and proofs. The use of Hilbert space representations for patches, smooth ReLU activations for differentiability, and global max pooling to avoid gradient entanglement all demonstrate careful mathematical design. \n3. The paper’s theoretical results align with long-standing community observations. For instance, it formally explains why RBAD struggles with semantic anomalies (since they may contain normal local features) and why mild overparameterization helps avoid suboptimal reconstructions. These insights transform empirical heuristics into theoretically grounded knowledge, strengthening both credibility and interpretability.\n\n[1] Li Y, Feng Y, Chen B, et al. Vague Prototype-Oriented Diffusion Model for Multi-Class Anomaly Detection"}, "weaknesses": {"value": "1. The theoretical analysis relies on several idealized assumptions. For example, the data are assumed to consist of P patches, each containing one dominant feature plus random noise. Real images are more complex, patches may not be independent and could contain multiple mixed features. Similarly, the definition of anomalies as “patch replacements” may not cover global distribution shifts or complex anomaly patterns. \n2. The paper only analyzes a two-layer convolutional autoencoder (single hidden convolutional layer + pooling). In practice, anomaly detection models are often deeper and structurally richer. The conclusions may not directly generalize to these more complex architectures, and care must be taken when extrapolating.\n3. The main limitation lies in the narrow scope of empirical validation. Although the paper includes some experiments, they are limited compared to the complexity of anomaly detection tasks. The synthetic experiments, while rigorous, remain toy settings far from real-world conditions. \n4. The paper barely discusses or compares with current state-of-the-art (SOTA) anomaly detection methods. While pure theory need not compete in performance, the omission creates a sense of detachment: the theory explains a relatively basic method, while the field’s focus has partially shifted toward more advanced ones. This gap could reduce confidence in the theory’s practical relevance."}, "questions": {"value": "1. Could the theoretical assumptions be relaxed, or could the authors discuss whether similar principles hold for other generative models (e.g., diffusion models, GANs)? Additionally, if multiple patches are replaced (non-local anomalies), would the conclusions still hold?\n2. Given the theoretical weakness of RBAD on semantic anomalies, could auxiliary tasks or regularization be introduced to enforce lower reconstruction ability for non-primary features?\n3. The experimental section should be expanded.\n4. In the revised version, clarify the relationship between this paper’s theoretical focus and existing empirical advances—emphasize that the goal is to complement, not compete with, SOTA detection methods."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3wcFTtCv9J", "forum": "FnbGlnKbIU", "replyto": "FnbGlnKbIU", "signatures": ["ICLR.cc/2026/Conference/Submission6709/Reviewer_2q5h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6709/Reviewer_2q5h"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761466521141, "cdate": 1761466521141, "tmdate": 1762919000330, "mdate": 1762919000330, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new anomaly detection method, which provides a theoretical analysis of reconstruction-based\nanomaly detection (RBAD). It constructs a two-layer convolutional autoencoder to reconstruct data and proves reconstructing normal data is easier than anomalies."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "- This paper proposes an autoencoder model to reconstruct the normal data and anomalies, which trains on normal data. And it shows that the reconstruction error of normal data is smaller than that of anomalies.\n- Theoretical analysis support the observation and conclusion of this paper.\n- Experimental results on synthesis dataset validate the theoretical findings."}, "weaknesses": {"value": "- How to use the non-semantic anomaly and semantic anomaly during training phase.\n-The organization of section 3 is a bit chaotic. It is unclear to me how this method works.\n- I am confused with the experimental results on real data. I don't know how to observe Figure 5. Please provide more explanations. \n- Why not detect anomalies directly based on the real datasets. Then we can see quantitative results of Acc and F1."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "56S2QFeAH4", "forum": "FnbGlnKbIU", "replyto": "FnbGlnKbIU", "signatures": ["ICLR.cc/2026/Conference/Submission6709/Reviewer_Vbxc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6709/Reviewer_Vbxc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724931210, "cdate": 1761724931210, "tmdate": 1762918999654, "mdate": 1762918999654, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper gives a theory for why reconstruction-based anomaly detection (RBAD) succeeds on normal data yet struggles on anomalies by analyzing a two-layer convolutional autoencoder with max pooling.\nIt introduces cone sets to show that training aligns kernels to frequent normal features.\nThis alignment yields weak activations and large reconstruction errors for non-semantic anomalies,\nwhile yields small reconstruction errors for semantic anomalies containing learned features.\nThe proposed theory is validated on both synthetic and real datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Although reconstruction-error–based anomaly detection is widely used, there has been little theoretical analysis of why normal data are well reconstructed while anomaly data are not. This paper provides a theoretical explanation for this.\n- The paper is well written and uses figures effectively to explain complex theory, making it very easy to follow."}, "weaknesses": {"value": "Please refer to the Questions section for details."}, "questions": {"value": "- While this theory analyzes autoencoders, I am curious what role it would play for variational autoencoders (VAEs).\nAs generative models, VAEs assign high likelihood to normal data and low likelihood to anomalies.\nThat is, they reconstruct normal data well and fail to reconstruct anomalies.\nHowever, as noted in [1],\nVAEs can sometimes assign higher likelihood to anomaly data than to normal data.\nSince a VAE can be viewed as a regularized autoencoder,\nI wonder whether this theory applies.\nCould this theory help explain that phenomenon?\n- Could this theory also be effective for more complex architectures, such as ResNet-based autoencoders?\n\n[1] Nalisnick, Eric, et al. \"Do deep generative models know what they don't know?.\" arXiv preprint arXiv:1810.09136 (2018)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ax1gTZzViy", "forum": "FnbGlnKbIU", "replyto": "FnbGlnKbIU", "signatures": ["ICLR.cc/2026/Conference/Submission6709/Reviewer_Po5J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6709/Reviewer_Po5J"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761783282179, "cdate": 1761783282179, "tmdate": 1762918999168, "mdate": 1762918999168, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the behavior of the convolution kernels in reconstruction-based anomaly detection (RBAD). To derive theoretical results, this paper assumes that image data can be decomposed into normal/auxiliary patch features and the model is a two-layer CNN. Under these assumptions, this paper reveals that the kernels are absorbed into the cone set oriented toward the normal feature. The paper claims that it can explain the reconstruction error of anomaly data becomes large and verifies theoretical results through synthetic/real-world data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well written except for the section of experiment.\n2. This seems the first theoretical explanation for reconstruction-based anomaly detection.\n3. The absorption into the cone-set appears to be an interesting and reasonable.\n4. Several theoretical results might inspire researchers to propose a new anomaly detection method or to improve existing one."}, "weaknesses": {"value": "1. Experiments need more explanation and discussions. Section 4 does have the explanation about Figure 4.\n\n2. Empirical evaluations seem insufficient. Which theoretical results do Fig. 4 and Fig. 5 verify?\nI suspect there some theoretical results might be verifiable. For example, since Lemma 3.1 indicates that the norm of kernel increases according to the training step, \nit can be verifiable by plotting the norm vs training steps. I think the cone set is also verifiable by investigating values of the inner product in Def.3.1.\nIf not, why is it difficult and how do Fig. 4 and Fig. 5 support theoretical results?\n\n3. Since fully-connected layers are also commonly used for anomaly detection in AE, a comparison with them might be interesting. \nFor a fully-connected layer, if the input vector contains a normal feature linearly independent of the noise component, intuitively one would expect the weight matrix to have singular vectors in the direction of the normal feature. This would result in singular values of zero for the anomaly feature, leading to large reconstruction errors.\nConsidering that convolution is a special case of a linear layer [a,b], a similar argument holds. Under such assumptions, it seems likely that the frequency components of an image would be formulated as the normal feature. The kernel visualization in Fig. 5 might also support such explanation as each kernel possesses a specific spectrum.\nDoes the proposed theory have any advantages or more reasonable insights over such approach?\n\n[a] Tsuzuku, Y., and Sato, I.  \"On the structural sensitivity of deep convolutional networks to the directions of fourier basis functions\". CVPR2019\n\n[b] Sedghi, H., and et al. \"The singular values of convolutional layers\". ICLR2018\n\n4. The contribution can be a bit weak if theoretical findings can only explalin the reactions to semantic anomalies or the magnitude of reconstruction errors for anomalies.\nThis paper would be strengthened if results can suggest directions for reconstruction-based anomaly detection researches or methods for improvement.\nCan theoretical results suggest such directions or methods?"}, "questions": {"value": "Could you read Weakness and answer the questions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "I4g0y7Mbnd", "forum": "FnbGlnKbIU", "replyto": "FnbGlnKbIU", "signatures": ["ICLR.cc/2026/Conference/Submission6709/Reviewer_HVHx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6709/Reviewer_HVHx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890799895, "cdate": 1761890799895, "tmdate": 1762918998222, "mdate": 1762918998222, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}