{"id": "SoeTEnG7tY", "number": 5093, "cdate": 1757847121717, "mdate": 1759897994902, "content": {"title": "Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms", "abstract": "The problem of combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) has been extensively studied. Prior work primarily focuses on either the online setting where an agent learns about the unknown environment through iterative interactions, or the offline setting where a policy is learned solely from logged data. However, each of these paradigms has inherent limitations: online algorithms suffer from high interaction costs and slow adaptation, while offline methods are constrained by dataset quality and lack of exploration capabilities. To address these complementary weaknesses, we propose hybrid CMAB-T, a new framework that integrates offline data with online interaction in a principled manner. Our proposed hybrid CUCB algorithm leverages offline data to guide exploration and accelerate convergence, while strategically incorporating online interactions to mitigate the insufficient coverage or distributional bias of the offline dataset. We provide theoretical guarantees on the algorithm’s regret, demonstrating that hybrid CUCB significantly outperforms purely online approaches when high-quality offline data is available, and effectively corrects the bias inherent in offline-only methods when the data is limited or misaligned.Empirical results on both synthetic and real-world datasets further demonstrate the consistent advantage of our algorithm.", "tldr": "", "keywords": ["Multi-armed bandits", "Combinatorial multi-armed bandits", "Offline-to-online", "Hybrid learning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fef72b5b04968f07598cd48425bb79036f6deb9f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) in a hybrid learning setup with access to offline data. The offline data can have biased arm means, making its utilization challenging for fast learning. They remedy this by proposing an algorithm, Hybrid (H)-CUCB, which, per arm, takes the minimum of (i) a standard online CUCB upper bound and (ii) a bias-aware hybrid UCB that mixes offline+online samples and adds a bias penalty. Under monotonicity and 1-norm TPM bounded-smoothness, the paper proves gap-dependent and gap-independent regret upper bounds with that depend on the effective, bias-adjusted offline sample sizes. Experiments on synthetic CMAB-T learning-to-rank and a small MovieLens split show H-CUCB improves over CUCB (online) and an offline baseline (CLCB)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. To the best of my knowledge, this paper provides the first hybrid (offline+online) treatment for general CMAB-T with probabilistic triggering, giving regret bounds that reduce to online CUCB when offline data are unhelpful and improve with aligned offline data.\n\n2. The decomposition of the regret clearly shows the benefit of using offline data via its effective number of samples, resulting in $O(-\\sqrt{N’_i})$ savings in Theorem 1. Discussions of Theorems 1 and 2 explain how the upper bounds on regret behave under different regimes of offline data size and quality. \n\n3. The significance resides in addressing multiple relevant applications (such as influence maximization or learning-to-rank) where offline data is common but usually biased."}, "weaknesses": {"value": "1. While the authors make connections between their general results and the edge cases with fully informative offline data and non-informative offline data, they provide no new lower bounds on the regret. This negatively impacts the significance of the work since it is mainly theoretical in nature, and related works of this kind usually have accompanying lower bounds. \n\n2. A limitation is that the algorithm requires the knowledge of an upper bound on $V$, the discrepancy of the means of online and offline data. In practice, it will be possible to estimate this discrepancy and adjust the algorithm as it runs. While this may make obtaining theoretical regret bounds challenging (the authors mention this in Remark 1), understanding the effect of online estimation of this quantity on the performance can be carried out via simulations. \n\n3. Experimental results are not comprehensive. Standard deviations of the regrets are not plotted. Sensitivity to misspecifications on the bias bound is not investigated. \n\n4. The analysis largely adapts the CMAB-T proof toolkit and tracks how offline bias enters the confidence radii. From this point of view, the technical novelty is incremental."}, "questions": {"value": "1. Uniform lower bound on $\\tau^*$ in line 414: Please elaborate on its correctness and point to the proof. \n\n2. Experiments: The figure do not demonstrate constant regret. Can you elaborate on the constant regret result?\n\n3. Can the benefit order in Theorem 1 be improved to the one in Cheung & Lyu (2024), perhaps using a different bounding technique? Shouldn't the regret terms match (at least) when the CMAB-T formulation is reduced to a standard bandit?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bHOldafPlJ", "forum": "SoeTEnG7tY", "replyto": "SoeTEnG7tY", "signatures": ["ICLR.cc/2026/Conference/Submission5093/Reviewer_CBtw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5093/Reviewer_CBtw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5093/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761413873772, "cdate": 1761413873772, "tmdate": 1762917868026, "mdate": 1762917868026, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the combinatorial multi-armed bandit problem with probabilistically triggered arms (CMAB-T), focusing on integrating the benefits of offline data and online interaction (exploration, adaptability). The authors formulate the hybrid CMAB-T (H-CMAB-T) setting, introduce a hybrid CUCB algorithm that leverages both data sources by adaptively trading off their contributions with a bias-aware dual-UCB mechanism, and provide theoretical regret guarantees. Empirical evaluations on synthetic and real-world datasets demonstrate gains over purely online and purely offline baselines, especially in regimes with limited or biased offline data."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The hybrid learning problem in CMAB-T is relevant and underexplored. This paper provides a systematic formalization, bridging existing gaps in purely online and purely offline settings.\n- Both gap-dependent (Theorem 1) and gap-independent (Theorem 2), regret bounds are derived.\n- Results in Figures 1 and 2 show consistent improvement of hybrid CUCB over CUCB (online) and CLCB (offline) across different offline data sizes and bias settings."}, "weaknesses": {"value": "1. Mostly small-scale synthetic + one real dataset; no stress tests on larger action spaces/trigger structures or runtime.\n2. The paper hypes the hybrid approach’s advantage but gives limited attention to scenarios where hybridization fails (i.e., more adverse bias structures, very small offline samples, or worst-case triggering)."}, "questions": {"value": "1. How does the proposed hybrid CUCB perform when the offline data shows significant non-uniform coverage or is adversarially biased for specific arms/actions? Is there a regime where offline data systematically degrades performance or slows learning?\n2. What is the computational overhead of hybrid CUCB relative to standard CUCB, especially in large-scale or high-dimensional action spaces? \n3. Are there settings where hybrid CUCB underperforms compared to pure online learning due to pathological offline data or wrong $V$ settings? The current discussion is mostly positive or neutral."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sEfqyLXmX0", "forum": "SoeTEnG7tY", "replyto": "SoeTEnG7tY", "signatures": ["ICLR.cc/2026/Conference/Submission5093/Reviewer_AxUf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5093/Reviewer_AxUf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5093/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990881765, "cdate": 1761990881765, "tmdate": 1762917867593, "mdate": 1762917867593, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Hybrid CMAB-T (H-CMAB-T), extending classical combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) to a hybrid learning regime. It proposes Hybrid-CUCB, which forms two arm-level UCBs, including a pure online CUCB estimate and a bias-aware hybrid estimate that pools  samples while penalizing possible offline/online mismatches via a known per-arm bias bound $V_i$. The algorithm feeds the coordinate-wise minimum of these bounds to an $(\\alpha,\\beta)$-approximation oracle over the action space. Theoretically, the paper proves both gap-dependent and gap-independent regret bounds that interpolate between pure online CMAB-T and (warm-started) hybrid learning; the savings scale with an effective amount of usable offline data that depends on the size and bias of the log. Empirically (synthetic and small-scale), Hybrid-CUCB improves over online CUCB and a one-shot offline policy, and remains robust under moderate bias."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The setting for hybrid CMAB-T is naturally and clean.\n\n2. By following prior papers and combining algorithms together, the Hybrid CUCB works naturally and well, validated both theoretically and empirically.\n\n3. The interpretations and intuitions of saving samples for terms $N_i^{\\prime}$ and $N_i^{\\prime \\prime}$ are clear and good to be understood.\n\n4. Provide both gap-dependent bound and gap-independent bound, comprehensive in the upper bound results."}, "weaknesses": {"value": "1. Lacking of lower bound: This paper provides promising upper bounds including gap dependent version and independent version. However, no lower bound is provided. In [1], lower bounds for both instance-dependent and instance-independent versions are given, and the optimality is guaranteed. I treat this part of contribution as crucial in their work since it is crucial to see how effective of these offline samples can really function as, at most, for the biased hybrid setting. By only providing the theoretical upper bounds, we can only understand how effective these offline samples are for the proposed algorithm, but not helpful for us to understand the real insight behind the problem setting (e.g., whether the hybrid CMAB-T problem theoretical results have exactly similar versions of hybrid MAB results, as [1] provides). The authors give some intuitions for it (such as from line 348-line 361), which is good. But I believe further detailed and promising interpretations and formal guarantees are really crucial for me.\n\n\n\n2. Strong assumptions on known $V_i$ : The proposed algorithm Hybrid CUCB needs the knowledge of $V_i$ for calculating the biased estimate $\\text{UCB}^{S}$, which is also the way did in [1]. However, I consider this is a really strong assumption in the works. Specifically, it is now realistic enough to know a very concrete bounded gap of bias between online and offline data, leading this to be a very strong assumption (most scenarios the gap can only be chosen to be infinity, meaning the offline data is totally useless for the online learning phase). I understand that in [1] they give an impossibility result on cases when there does not exist a bounded bias guarantee for offline and online data. Although this is not given in this paper, I believe it is trivial to prove that. However, what I am curious about is: if there exists some gap (i.e. $V_i$ ) between online and offline data, but the gap is unknown, is there any theoretical results to estimate this gap and utilize the estimated ones rather than given ones to have some further results without dependency on the known $V_i$ ? I think this should be a crucial (but currently lacking) contribution in this line of works.\n\n3. Problem novelty: Generally I treat this paper as considering the CMAB-T problem instead of MAB problem with the biased hybrid setting as [1]. To me, nothing is much special here and everything corresponds to the theoretical intuitions currently. I wonder if there is any unique challenge in CMAB-T+[1] compared to MAB+[1], and if so, the authors should clarify it more clearly. Further interpretations on technical novelty or challenges are of great importance in this paper.\n\n\n[1] Leveraging (Biased) Information: Multi-armed Bandits with Offline Data"}, "questions": {"value": "For (1) and (2) in weaknesses, Can the authors provide some further formal results? If formally proving them are technically difficult or not ready, at least some comprehensive intuitions on the lower bound and cases without knowing Vi should be given to help readers understand the whole contribution, and what is lacking now. For (3) in weaknesses, can the authors better interpret the novelty of this problem and contributions, rather than a simple CMAB-T+[1]? I would increase my score if problems (1) and (2) are answered perfectly, while (3) can be interpreted more clearly and comprehensive."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VvNVs7cXcU", "forum": "SoeTEnG7tY", "replyto": "SoeTEnG7tY", "signatures": ["ICLR.cc/2026/Conference/Submission5093/Reviewer_VxCG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5093/Reviewer_VxCG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5093/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762103749794, "cdate": 1762103749794, "tmdate": 1762917867184, "mdate": 1762917867184, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors consider a combinatorial multi-armed bandit problem with probabilistically triggered arms (CMAB-T) for which offline data is considered, but there may be a distributional shift wrt the online setting.  The authors propose a hybrid combinatorial CUCB method using bounds on the base arm biases and derive gap-dependent and gap independent bounds, in some special cases recovering results for simpler cases."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The problem appears to be novel.  CMAB-T has been studied in purely online (multiple works) and recently in purely online.  There is also work for several bandit settings using hybrid data, though before Cheung and Lyu (2024) most/all considered identically distributed environments. \n\n- The authors analyze gap-dependent and gap-independent bounds, recovering classic regret bounds for CUCB alg for CMAB-T as a special case. \n\n- The authors run experiments in both biased and unbiased settings. \n\n- Overall, I found the paper well-written and generally easy to follow.  The authors included a number of remarks throughout."}, "weaknesses": {"value": "### Major \n\n- My primary concerns are on novelty.  The algorithm H-UCB appears to be CUBC with the paired UCB estimators from Cheung and Lyu (ICML 2024). It is unclear to me how much technical novelty there is in adapting CUCB regret bounds in light of Cheung & Lyu’s prior work on adapting MAB.   \n\n   - In Section 4, the authors state “we design a hybrid confidence bound...” that is identical to Cheung and Lyu’s (their Alg 1 step 6) without acknowledgement (at least in that section). (The authors also did not clearly explain the intuition behind that particular formula (e.g. if it came from a variant of the Hoeffding bound for mixed data)) \n\n   - The authors in lines 057-066 comment on how there are differences in how the regret is analyzed for UCB in MAB vs CUCB in CMAB-T, then in lines 085-093 have discussion that makes it sound like they had to deeply rethink CMAB-T analysis and come up with new ways of integrating (possibly biased) offline data.  But given how the algorithm design ended up just being classic CUBC with Cheung and Lyu’s UCB estimators, I am skeptical of the extent of novelty claimed. \n\n \n\n- I have some concerns about motivation for the specific distributional shift in CMAB-T.  The authors did not provide a concrete example in the set up regarding what the base arm means are in relation to the triggering process and the reward function.  It is consequently unclear to be if it is well-motivated to consider that the learner would have prior knowledge on distributional shift for the base arms (including non-trivial $V_i$’s) but that there would be no shift at all on the triggering process.  Based on just the abstract problem setup, I would expect that shifts in both sources of randomness behind the super-arm rewards would be accounted for in a hybrid CMAB-T problem. \n\n \n\n### Minor \n\n- The authors only consider $[0,1]$ base arm rewards, for which the learner can trivially use mean shift bounds of $V_i=1$.  Esp. with the impossibility result of Cheung and Lyu (2024), the results cannot be widely generalized.   \n\n \n\n- The authors should explicitly mention what classes of reward functions satisfy the assumptions.  The reward model seemingly has a linearity in its expected value (line 163), monotonicity, and a bounded smoothness.  They point out this is standard in the CMAB-T works.  \n\n- line 321 the measure $\\omega_i$ is not discussed why it has the form it does, such as why it has a directionality wrt the bias – eg even with a conservative (for [0,1] rewards) bound $V_i=1$ for base arm i,  \n\n    - if the off and on means are the same (unbiased), $\\omega_i=1$ (just equal to our pessimism) \n\n    - if the bound is tight with arm i looking better offline than online, $\\omega_i=2$ \n\n    - if the bound is tight with arm i looking worse offline than online, $\\omega_i=0$ \n\n- The experiments are not particularly convincing  \n\n   - the authors only compare against purely online and purely offline methods.  The authors cited past works that considered hybrid settings without distributional shift but no baseline was used for that with comparison.  For instance, could one run CLCB and have that warm-start CUCB? \n\n   - The plots (V=0 vs V>0) are confusing to compare. I thought all 6 sub-figures were identical online environments at first.  They must be different, as CUCB performs differently in Fig 1 and 2.   This is concerning as Fig 1 showing with $N=200$ there is a huge gap in the setting without shift  \n\n   - The proposed method appears nearly identical with the purely online CUCB baseline even with small bias (V=0.2).   \n\n \n\n- “Together, these two bounds form a comprehensive characterization of the gap-independent regret in H-CMAB-T” sounds a bit exaggerated – Theorem 2 is the regret upper bound for one algorithm.  A few corner cases are checked, but there is no lower bound included for the H-CMAB-T problem. \n\n- There is no discussion of works on non-stationary bandits. I don’t know if there are any on CMAB-T specifically, and it is of course not the same as having a offline dataset, but there may be some interesting ideas from that setting that would be relevant for this problem. \n\n \n\n### Very Minor \n\n- Cheung & Lyu 2024 is cited as an arxiv preprint"}, "questions": {"value": "- Regret bound (Thm 1) \n\n    - Does it hold for any $T$? or is there some minimum $T$ (function of problem parameters) it holds for (or for which it becomes non-vacuous)? \n\n   - (minor) Is Alg 1 anytime?  As written it requires the horizon as input, though it is not clear if that is used.   \n\n \n\n \n\n- Does the triggering have any discernible impact on the regret bounds regarding the impact of base arm biases?  eg a measure $\\omega_i$ is mentioned but that only is wrt individual arm means.  I don’t know if it is an artifact of the regret analysis of CMAB-T.    \n\n- Did you run experiments where you validated if the $\\omega$ dependence on $V_i$ and the means in the regret upper-bounds was consistent with the empirical regret from experiments.  That is, if the offline $\\mu_i$’s are always better than online $\\mu_i$’s and the $V_i$ values are tight, would the algorithm’s performance be identical with Figure 1 where there is no bias (and it is known there is no bias)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gLBYHFQJjT", "forum": "SoeTEnG7tY", "replyto": "SoeTEnG7tY", "signatures": ["ICLR.cc/2026/Conference/Submission5093/Reviewer_9DtE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5093/Reviewer_9DtE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5093/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762836909143, "cdate": 1762836909143, "tmdate": 1762917866839, "mdate": 1762917866839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}