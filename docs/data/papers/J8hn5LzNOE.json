{"id": "J8hn5LzNOE", "number": 14215, "cdate": 1758230385929, "mdate": 1763490442440, "content": {"title": "Online Decision Making with Generative Action Sets", "abstract": "With advances in generative AI, decision-making agents can now dynamically create new actions during online learning, but action generation typically incurs costs that must be balanced against potential benefits. We study an online learning problem where an agent can generate new actions at any time step by paying a one-time cost, with these actions becoming permanently available for future use. The challenge lies in learning the optimal sequence of two-fold decisions: which action to take and when to generate new ones, further complicated by the triangular tradeoffs among exploitation, exploration and *creation*. To solve this problem, we propose a doubly-optimistic algorithm that employs Lower Confidence Bounds (LCB) for action selection and Upper Confidence Bounds (UCB) for action generation. Empirical evaluation on healthcare question-answering datasets demonstrates that our approach achieves favorable generation-quality trade-offs compared to baseline strategies. From theoretical perspectives, we prove that our algorithm achieves the optimal regret of $O(T^{\\frac{d}{d+2}}d^{\\frac{d}{d+2}} + d\\sqrt{T\\log T})$, providing the first sublinear regret bound for online learning with expanding action spaces.", "tldr": "We propose a doubly-optimistic online learning algorithm that learns when to generate new actions versus reuse existing ones, achieving the first sublinear regret bound.", "keywords": ["online decision making", "create-to-use"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/78bd3de4450fa59dd7a8176afe6feab10e84bf4a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies an online learning problem with an expanding action space, motivated by generative AI systems that can create new actions on demand at a cost. The authors introduce the create-to-reuse framework, in which an agent decides at each time step whether to select an existing action or pay a one-time cost to generate a new, reusable action.\nTo solve this problem, the authors propose a doubly-optimistic algorithm that employs Lower Confidence Bounds (LCB) for action selection among existing options, and Upper Confidence Bounds (UCB) for deciding whether to create new actions.\nThis approach is theoretically shown to achieve a sublinear regret bound of O\\left(T^{\\frac{d}{d+2}} d^{\\frac{d}{d+2}} + d \\sqrt{T \\log T}\\right),\nwhich matches an  Ω(T^{d/(d+2)}) lower bound—making it optimal with respect to the time horizon T.\nEmpirical validation includes both synthetic data (to confirm regret rates) and real healthcare question-answering datasets (to demonstrate tradeoffs between creation cost and response mismatch). The proposed algorithm consistently outperforms fixed-probability baselines in terms of total loss and generation-quality efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.  Introduces an important and timely extension of online decision-making- expanding the action space through generative capabilities.\n2.  The double-optimism principle (LCB for reuse, UCB for creation) is conceptually appealing and well-motivated by the underlying tradeoffs.\n3.  Provides nontrivial analysis, including tight regret bounds and a matching lower bound.\n4. The healthcare Q&A examples effectively illustrate the value of balancing creation cost with reuse benefits.\n5. Real-data results show meaningful gains and smooth generation-quality tradeoffs."}, "weaknesses": {"value": "1. The algorithm’s  worst-case complexity O(d^4 T^2) is prohibitive for high-dimensional embeddings (e.g., large language model contexts).\n   The paper proposes approximate implementations (linear or neural variants) but does not provide theoretical guarantees for them.\n\n2.  The  quadratic loss model d(x,f) = (x-f)^\\top W(x-f) may not generalize to real semantic spaces.\n  \n3.  Evaluation focuses mainly on healthcare QA; additional domains (e.g., recommendation systems or dynamic pricing) would strengthen claims of generality.\n\n4.  The probabilistic decision rule for creation (based on ( UCB/c )) could be analyzed more thoroughly-what happens if the stochastic component is removed or tuned differently?\n\n5.  Links to active learning, bandits with knapsacks, and growing action spaces (Farquhar et al., 2020) are discussed in the appendix, but not deeply integrated into the main narrative."}, "questions": {"value": "1. How critical is the quadratic assumption on mismatch loss? Would kernelized or neural distance functions maintain similar regret behavior?\n\n2. Can the proposed framework handle context-dependent creation costs c(x_t)? How would this affect the theoretical analysis?\n\n3. Could approximate nearest neighbor search or library pruning reduce complexity while preserving regret guarantees?\n\n4. The create-to-reuse tradeoff resembles selective labeling. Could active learning techniques (e.g., expected information gain) enhance the creation policy?\n\n5. How would the method extend to stochastic or partially observable generation outcomes (as in LLM-based action creation)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "M6byc4ZqYM", "forum": "J8hn5LzNOE", "replyto": "J8hn5LzNOE", "signatures": ["ICLR.cc/2026/Conference/Submission14215/Reviewer_GG79"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14215/Reviewer_GG79"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761813195655, "cdate": 1761813195655, "tmdate": 1762924673254, "mdate": 1762924673254, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies a new bandit framework where a decision maker receives at each round a context $x_t$, and decides whether to (i) pick an optimal action $\\mathcal{A}(f)$ corresponding to an already-seen context $f\\in S_t$, or (ii) incur a fixed cost $c>0$ and generate a new action $\\mathcal{A}(x_t)$ specifically tailored to $x_t$, which becomes available for future rounds. This problem is mainy motivated  by healthcare QA systems. The authors propose a doubly-optimist algorithm to  solve this problem, and derive an optimal-in-T upper bound on the regret incurred by their algorithm. They then run two sets of experiements: one exactly implements the algorithm in a small dimension synthetic data setup; the other implements an approximate version of the algorithm (where the distance is predicted linearly) one actual QA data."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1) The paper is very-well written and pedagogical. The authors did a great job presenting their setting and algorithm in a simple and intuitive way, without sacrificing mathematical soundness. \n2) The setting is interesting and is well motivated from a practical point of view (healthcare QA)\n3) The theoretical analysis is complete, thanks to a lower-bound complements the upper-bound on the regret incurred by the introduced algorithm. The convergence rate is very slow (exponential dependence on the dimension, almost linear dependence on T for large d), however this has to do with the inherent difficulty of the problem (as suggested by the lower bound)."}, "weaknesses": {"value": "1) I am not entirely convinced by the way the loss incurred by the algorithm is modeled. Indeed, the paper assumes that the loss incurred at each round is given by a (noisy) distance generated by $W$ between the actual context $x_t$ and the context chosen to generate the action. This is a quite restrictive modelling. In particular I would expect W to depend on $x_t$, so the loss would be $(x_t - f)^\\top W(x_t) (x_t -f)$. Indeed, answering to a question $f$ instead of the actual $x_t$ is likely to be more harmful when the user asks about cancer than about superficial wound for instance. By the way, this formulation would naturally arise by considering the second order Taylor expansion of the excess risk $h(x_t, \\mathcal{A}(f)) - h(x_t, \\mathcal{A}(x_t))$ for some decision loss $h$.\n2) The authors implement the algorithm for which they derive guarantees only on a very toyish example, and use a simplified version on the actiual QA dataset. Altough I understand that the dependence on $d$ makes the cost of an actual implementation prohibitive, it is quite unfortunate not to have a demonstration of the effectiveness of the algorithm on actual data, and not to have a theoretical guarantee of the simplified algorithm used in practise."}, "questions": {"value": "1) Is it possible to extend the analysis to the case where $W$ depends on the context $x_t$ ?\n2) Are there other motivations for the problem studied in this paper?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sgCjbju6mW", "forum": "J8hn5LzNOE", "replyto": "J8hn5LzNOE", "signatures": ["ICLR.cc/2026/Conference/Submission14215/Reviewer_pGC5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14215/Reviewer_pGC5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761838329449, "cdate": 1761838329449, "tmdate": 1762924672842, "mdate": 1762924672842, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors of the paper propose a method of reusing annotated actions in an online decision making framework. Specifically, the authors propose an algorithm that takes into account the cost of adding an action with cost $c$ (annotated answer in an FAQ setting) into a context library $S_t$ over reusing an already existing action which, might lead a loss due to the sub-optimal nature of the already existing answer. To reduce the overall computational complexity, the For theoretical purposes to calculate the regret bounds , the loss is approximated as a weighted squared distance, though in the empirical results, they use a squared linear model or a neural network (NN). \n\nNotation: \n- Input context variable $x_t \\in \\mathbb{R}^d$ i.e. vector embedding for questions in FAQ setting\n- $S_t:= \\{x_t, a_t\\}$ is a context library of vetted FAQs that is stored as a hash map. \n- $d(x,f)$ is the distance function which models the loss."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Strengths: \n- The paper address an important aspect of a real world problem i.e. when does one need to annotate new data vs. use existing data. Given that data annotation is a fairly laborious and expensive process, this would be a prudent approach proposed by the authors. \n- The approach is fairly simple and approachable. The algorithm in Algorithm 1 was easy to understand along with the reasoning about it's time complexity (though I'm not too convinced about using NNs to help with that). The algorithm also makes sense in having a LCB and UCB defined for the overall loss from a theoretical sense, but I might see issues here of it being practical."}, "weaknesses": {"value": "Weakness: \n- The use of a NN to approximate the distance function to reduce computational complexity seems a little counter intuitive. Typical NNs would be sufficiently large that it might render this moot. \n- There is no study on how the size of the context library might impact the algorithm (like a cold start problem). It would also be good to understand if this framework leads to long term stability of needing an oracle. \n- I did not fully evaluate the authors theoretical claims, but I think some of their empirical results are not very convincing. Its hard to gauge the performance of the algorithm from 2 real world datasets.\n- I also think that from a practical standpoint, it would be hard for practitioners to tie in the relation between the distance metric and cost (the notion of a *total loss*)"}, "questions": {"value": "Questions: \n- Section 6.2 line 432: \"cost parameter $c$ from 0 to 100 for our algorithm ...\" : Can you explain why you do this sweep across? Also, what does this cost mean from an intuitive sense? How does this tie back into the the *total loss*\n- I might have also missed this, but could you explain how you estimate/train the distance function for both the datasets in section 6 i.e. the squared liner model and NN mentioned in section 4."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "qdOnzZQjDy", "forum": "J8hn5LzNOE", "replyto": "J8hn5LzNOE", "signatures": ["ICLR.cc/2026/Conference/Submission14215/Reviewer_yeWb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14215/Reviewer_yeWb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957241325, "cdate": 1761957241325, "tmdate": 1762924672058, "mdate": 1762924672058, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a novel sequential decision-making problem, where a decision maker has to learn to either pick a previously known action (exploitation/exploration) or generate a new one by paying a fixed cost (creation). The authors provide the first (doubly-optimistic) algorithm to solve this problem that is shown to achieve sub-linear regret, under some assumptions on the loss incurred. Further, the authors evaluate the performance of their approach on both synthetic and realistic datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "_(Disclaimer: this is not exactly my area of expertise. I skimmed through the appendices and proofs, but I did not check them too deeply.)_\n\nThe paper tackles an interesting and timely problem, which I believe has several interesting ramifications and implications for several human-AI decision-making scenarios. The paper is clear in its exposition, and all the relevant assumptions are duly explained and motivated. Furthermore, the related work is described comprehensively (both in the main text and appendix), enabling a clear contextualization of the paper's proposed method. Overall, I enjoyed reading it."}, "weaknesses": {"value": "I do not see any fundamental weakness in this work, based on my limited expertise with multi-armed bandit settings. The paper is clear in explaining the weaknesses (e.g., assumptions) of the proposed approach. \n\nI can only comment that some assumption feels very synthetic. For example, the quadratic loss function $d(x_t, f_t)$, while justified for tractability, limits generality and may underrepresent practical similarity measures (e.g., cosine or kernel-based metrics). Further, context-dependent or stochastic creation costs would also be interesting. Looking at practical applications, I would expect to measure the efficacy (regret) of Algorithm 1 in solving a certain decision-making task (e.g., curing a patient). Your algorithm would be oblivious to the fact that a pre-registered question is wrong, or it does not work for a given context (the same reasoning applies to generated actions)."}, "questions": {"value": "- How would you extend your algorithm to consider more complex notions of loss? For example, a probabilistic loss dependent on the action/context pair (e.g., efficacy of a treatment for a patient $x_t$).\n- Would the regret-proof strategy still work under time- or context-dependent creation costs $c$? How do you envision your strategy to change?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "cnbuIMUYDU", "forum": "J8hn5LzNOE", "replyto": "J8hn5LzNOE", "signatures": ["ICLR.cc/2026/Conference/Submission14215/Reviewer_WJ1K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14215/Reviewer_WJ1K"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762276073539, "cdate": 1762276073539, "tmdate": 1762924671398, "mdate": 1762924671398, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces an online decision-making problem relevant to modern generative AI systems, where an agent can dynamically expand its action set. At each time step, the agent observes a context $x_t$ and faces a choice: (1) select an existing action $f$ from its library $S_t$ and incur a mismatch loss $d(x_t, f)$, or (2) pay a fixed cost $c$ to generate a new, context-specific action $\\mathcal{A}(x_t)$ which provides zero mismatch loss and is then permanently added to the library $S_{t+1}$. This frames a novel \"create-to-reuse\" problem, which the authors identify as a triangular trade-off among exploitation, exploration, and creation.\n\nTo solve this, the authors propose a **Doubly-Optimistic Algorithm**. This algorithm first identifies the best *existing* action $f_t$ by using a Lower Confidence Bound (LCB) on the mismatch loss (balancing exploitation and exploration). It then makes a stochastic decision on whether to *create* a new action based on the Upper Confidence Bound (UCB) of $f_t$'s loss, $\\hat{d}_t(x_t, f_t)$, opting to create with probability $\\min(1, \\hat{d}_t(x_t, f_t)/c)$.\n\nThe paper's main contributions are:\n1.  The \"create-to-reuse\" problem formulation.\n2.  The novel Doubly-Optimistic Algorithm.\n3.  A rigorous theoretical regret analysis, which assumes the loss $d(x,f)$ is an unknown quadratic function $d(x,f) = (x-f)^\\top W (x-f)$. The algorithm achieves an expected regret of $O(T^{\\frac{d}{d+2}}d^{\\frac{d}{d+2}} + d\\sqrt{T \\log T})$.\n4.  A matching information-theoretic lower bound of $\\Omega(T^{\\frac{d}{d+2}})$ (with respect to $T$), proving the algorithm's optimality.\n5.  Empirical validation on synthetic data (which verifies the theoretical regret rate) and on two real-world healthcare Q&A datasets (which demonstrates superior cost-quality trade-offs compared to a fixed-probability baseline)."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "* **Novel and Timely Problem:** The \"create-to-reuse\" formulation is a significant and timely contribution. It accurately models a new challenge posed by generative AI, where high-quality, custom actions (like detailed Q&A responses) are now possible to create on-the-fly, but at a non-trivial cost. This is a valuable and natural extension of the classic contextual bandit framework.\n* **Elegant Algorithm Design:** The \"doubly-optimistic\" principle is an intuitive and elegant solution to the new exploration-exploitation-creation trade-off. Using an LCB for *action selection* (to manage uncertainty among *known* actions) while using a UCB-based probability for *action creation* (to optimistically value the benefit of creating a new action) is a clever method for decomposing the problem.\n* **Strong Theoretical Results:** The paper provides a complete and rigorous theoretical analysis. Deriving the $O(T^{\\frac{d}{d+2}}d^{\\frac{d}{d+2}} + d\\sqrt{T \\log T})$ regret bound is a strong technical achievement. Proving its optimality by establishing a matching $\\Omega(T^{\\frac{d}{d+2}})$ lower bound makes the theoretical contribution self-contained and highly significant.\n* **Solid Empirical Validation:** The experiments are well-designed and provide compelling support for the claims. The synthetic experiments directly validate the theoretical regret rate $\\frac{d}{d+2}$, which is excellent. The real-world experiments on healthcare Q&A datasets convincingly demonstrate the algorithm's practical utility, showing it achieves a superior Pareto frontier for the cost-vs-mismatch-loss trade-off compared to a sensible baseline.\n* **Clarity:** The paper is exceptionally well-written. The problem is motivated clearly with concrete examples, the formal problem setup is precise, and the algorithm's intuition is explained very well."}, "weaknesses": {"value": "* **Gap Between Theory and Practical Implementation:** The strong theoretical guarantees (optimality, regret rate) are derived under the assumption of a quadratic loss $d(x,f) = (x-f)^\\top W (x-f)$. This model has $O(d^2)$ parameters and leads to an \"impractical\" $O(d^4)$ complexity per-step, as the authors note. Consequently, the real-world experiments use computationally cheaper models: a rank-1 (squared linear) model $(\\theta^\\top(x-f))^2$ or a neural network. This creates a disconnect, as the theoretical guarantees do not strictly apply to the models used in the high-dimensional, practical validation. While the empirical results are strong, the paper would be improved by discussing this limitation more directly.\n* **Scalability of the Action Library $S_t$:** The algorithm, as presented, requires computing the LCB for *every* existing context key $f \\in S_t$ at *each* time step $t$. In a long-running system, the library $S_t$ could grow very large, potentially approaching $O(T)$ in size. This implies a per-step complexity that scales at least linearly with $|S_t|$ (e.g., $O(|S_t| \\cdot D^2)$ for the NN model). The paper notes the *expected* number of created contexts is sublinear $O(T^{\\frac{d}{d+2}})$, but this is not a worst-case guarantee. The paper would benefit from a discussion on the practical scalability for very large $T$ and whether mitigation strategies (e.g., approximate nearest-neighbor search for $f_t$, pruning the library $S_t$) would be necessary.\n* **Baseline for Comparison:** The \"Fixed-P\" baseline is a reasonable \"naive\" strategy. However, it is arguably too simple. It decides to create *independently* of the context $x_t$, and when it reuses, it performs pure exploitation (picking the most similar context). A stronger baseline might involve running a standard contextual bandit algorithm (like LinUCB) on the *current* set $S_t$ (to intelligently explore/exploit *existing* actions) and pairing this with a more intelligent heuristic for creation (e.g., \"create if the LCB loss of the best existing action is still greater than $c$\"). Comparing against such a baseline would provide a clearer picture of the value added by the specific \"doubly-optimistic\" creation rule."}, "questions": {"value": "1.  **On the Theory-Practice Gap:** Could you elaborate on the theoretical guarantees for the simplified models used in the real-world experiments (the squared linear model and the neural network)? Does the $O(T^{\\frac{d}{d+2}})$ regret component (which seems related to the \"facility location\" aspect of the problem) still hold, even if the second regret term (from parameter estimation) changes from $O(d\\sqrt{T \\log T})$?\n2.  **On Scalability:** How did the algorithm's runtime scale empirically with $T$ and the library size $|S_t|$ in your Q&A experiments? The per-step complexity seems to be $O(|S_t| \\cdot \\text{dim})$. Do you foresee scalability issues as $T$ becomes very large, and do you have recommendations for mitigating this (e.g., nearest-neighbor search, action pruning)?\n3.  **On Baselines:** Could you comment on how your algorithm might compare to a baseline that uses a standard contextual bandit (like LinUCB) to select from $S_t$, paired with a deterministic creation rule like: \"create a new action if and only if $\\min_{f \\in S_t} \\tilde{d}_t(x_t, f) > c$\"? This seems like a natural alternative, and I am curious why the stochastic UCB-based rule is preferable.\n4.  **On the Oracle:** The analysis assumes the creation oracle $\\mathcal{A}(x_t)$ is \"perfect\" and provides a zero-loss action. How do you think the problem and algorithm would need to change if the oracle was imperfect, i.e., generating a new action still incurred some unknown (but hopefully small) mismatch loss $l_t(\\text{new}) > 0$, in addition to the fixed cost $c$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JIdnq6htak", "forum": "J8hn5LzNOE", "replyto": "J8hn5LzNOE", "signatures": ["ICLR.cc/2026/Conference/Submission14215/Reviewer_uKET"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14215/Reviewer_uKET"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission14215/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762446406911, "cdate": 1762446406911, "tmdate": 1762924670469, "mdate": 1762924670469, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overall Response to Reviewers"}, "comment": {"value": "We thank all reviewers for their thoughtful comments and positive feedback! We have carefully addressed each concern and made the following revisions to strengthen the paper:\n\n**1, Growth of Action Set Size (Appendix A.2):** We have added a new experiment-based discussion analyzing the growth of the action set size $|S_t|$ over the time horizon $T$ for different choices of the creation cost $c$. This demonstrates that our algorithm adaptively controls library growth—higher costs lead to slower accumulation and more reuse, validating the economic tradeoff at the core of our framework.\n\n**2, LinLCB Baseline Comparison (Appendix A.2):** We include a comparison against a LinLCB (a version of LinUCB in terms of loss minimization) baseline that uses a deterministic threshold for creation decisions (instead of our probabilistic UCB/c rule). The results show that our doubly-optimistic decision mechanism achieves superior cost-effectiveness by better balancing creation versus mismatching in expectation.\n\n**3, Neural Network Confidence Bounds (Appendix C):** We provide a formal derivation of the confidence bounds $\\Delta_t(x,f)$ for neural network distance estimators using Laplace approximation of the Gaussian posterior. This justifies the doubly-optimistic principle (LCB-reuse, UCB-creation) we adopt in our high-dimensional Healthcare Q&A experiments, bridging methodology and implementation.\n\nWe are grateful for the opportunity to improve our work based on the reviewers' suggestions and believe these additions have made the paper stronger. Thank you again for your constructive guidance!\n\n------------\nBest,\n\nSubmission 14215 Authors"}}, "id": "eiLGZXbFnC", "forum": "J8hn5LzNOE", "replyto": "J8hn5LzNOE", "signatures": ["ICLR.cc/2026/Conference/Submission14215/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14215/Authors"], "number": 11, "invitations": ["ICLR.cc/2026/Conference/Submission14215/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763493191435, "cdate": 1763493191435, "tmdate": 1763493366454, "mdate": 1763493366454, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}