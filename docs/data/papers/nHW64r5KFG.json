{"id": "nHW64r5KFG", "number": 17636, "cdate": 1758278665957, "mdate": 1763727524962, "content": {"title": "Thinking as Society: Multi-Social-Agent Self-Distillation for Multimodal Misinformation Detection", "abstract": "Multimodal Misinformation Detection (MMD) in realistic, mixed-sourced scenarios must incorporate robust reasoning capabilities to handle the social complexity and diverse types of forgeries. While MLLM-based agents are increasingly used for MMD task due to their powerful reasoning abilities, they suffer from a critical trade-off: on one hand, single-agent methods provide only the limited, single-view analysis; on the other hand, multi-agent methods introduce high computational costs and significant optimization difficulties. To address this gap, we propose a novel Multi-Social-Agent Self-Distillation framework that internalizes collective social reasoning capabilities into a unified model. Our framework consists of two core stages: (1) we simulate multi-perspective judgments from a diverse society of MLLM agents and synthesize their collective feedback into high-quality Social Chain-of-Thought (SCoT) data; (2) Building on this, we propose the Social Correction Value-Driven Preference Optimization (SCPO), a new alignment algorithm that leverages the degree of social misjudgment as a verifiable signal to dynamically focus training on the most challenging samples. Extensive experiments on the challenging MFC-Bench and MMFakeBench benchmarks demonstrate the effectiveness of our framework. Our 7B Qwen2-VL-based model significantly outperforms various MLLM baselines, multi-agent methods, and even competes or surpasses proprietary models like GPT-4o and Claude, facilitating advanced multimodal misinformation reasoning and detection via thinking as society.", "tldr": "", "keywords": ["Multimodal Misinformation Detection", "Multimodal Large Language Models", "Multi-Social-Agent Self-Distillation"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6a3c5e8e434e80f8afcea3bdd1227c66bd6b6ad5.pdf", "supplementary_material": "/attachment/6f129c728cefa80563cfceb1986da4dedca2f577.pdf"}, "replies": [{"content": {"summary": {"value": "This paper addresses multimodal misinformation detection (MMD) under realistic social media conditions. The authors argue that existing single-agent LMM-based detectors lack perspective diversity and are thus easily misled, while multi-agent systems provide multiple viewpoints but are inefficient and hard to optimize end-to-end. To resolve this trade-off, the paper proposes a “Multi-Social-Agent Self-Distillation” framework that aims to compress multi-agent social reasoning into a single model. Their SCPO-tuned 7B model achieves superior or comparable performance to larger open-source, multi-agent, and even proprietary models like GPT-4o and Claude 3.5-Sonnet on MFC-Bench and MMFakeBench under both open- and closed-prompt evaluations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper attempts to model socially diverse reasoning and then distill it into a single deployable model is conceptually compelling and practically relevant for scalable moderation systems.\n2. By coupling Social Chain-of-Thought (SCoT) data synthesis with the Social Correction Value-Driven Preference Optimization (SCPO) algorithm, the framework achieves robust reasoning performance."}, "weaknesses": {"value": "1. The paper should be more precise here: is there any real agent interaction, disagreement resolution protocol, or iterative critique loop beyond single-shot persona prompting and post-hoc summarization? Otherwise, “multi-social-agent” risks overselling standard multi-persona sampling plus LLM judging.\n2. Need for overlap analysis between source data and evaluation benchmarks.\n3. The paper should clearly states: What is the size of the original pooled dataset (before filtering)? How large is the filtered “validation set”? How many instances survive as “High-quality Training Data” after selection?\n4. The “Coordinator Agent” and “Summarizer Agent” are described as specialized components, yet their concrete implementation remains vague. Are these modules merely prompt-based LLM refiners, and if so, how do they differ functionally from standard LLM data post-processing?\n5. Table 3 shows only marginal improvement of SCPO over ORPO (67.15 vs 66.30 accuracy; 66.83 vs 66.01 F1), suggesting that performance bottlenecks may stem more from the availability and quality of CoT-style supervision data than from the SCPO weighting mechanism itself"}, "questions": {"value": "6. The paper lacks clarity regarding human supervision and quality control, including the number of annotators involved, their expertise, and the specific labeling guidelines used to ensure annotation reliability.\n7. The paper should report the proportion of samples assigned to each feedback category (correct, partially correct, incorrect), since these distributions directly influence the SCPO weighting and training balance."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "p8m9guEsYp", "forum": "nHW64r5KFG", "replyto": "nHW64r5KFG", "signatures": ["ICLR.cc/2026/Conference/Submission17636/Reviewer_NiZd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17636/Reviewer_NiZd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17636/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761645295443, "cdate": 1761645295443, "tmdate": 1762927496219, "mdate": 1762927496219, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a Multi-Social-Agent Self-Distillation framework for multimodal misinformation detection (MMD) leveraging Large Multimodal Language Models (MLLMs). The proposed approach first simulates diverse social agents to produce multiview feedback on misinformation samples, synthesizing this into Social Chain-of-Thought (SCoT) data. Building on this, the Social Correction Value-Driven Preference Optimization (SCPO) algorithm is introduced, which dynamically scales the alignment loss by the observed social misjudgment. Experiments on MFC-Bench and MMFakeBench show that this self-distilled, socially-aware Qwen2-VL-based model outperforms a variety of open-source and proprietary baselines and matches or exceeds complex multi-agent or larger-scale systems on key multimodal reasoning tasks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper tackles an important and timely challenge in MMD, seeking to integrate multi-perspective social reasoning into a single, efficient agent, thereby addressing the real-world complexity of misinformation and limitations of both single- and multi-agent systems.\n2. The methodology is clearly articulated: simulating social context via user-profiled MLLMs, aggregating their reasoning, and synthesizing collective chains of thought. The data pipeline is well-detailed, and the synthesized dataset design is a practical advance.\n3. SCPO introduces an interpretable, mathematically explicit mechanism to adjust model alignment based on task difficulty, which stands out against prior, less verifiable margin-scaling approaches.\n4. The paper is competently written and mostly clear, with methodological details in both equations and pipeline diagrams."}, "weaknesses": {"value": "1. While the diversity of simulated agents is claimed, the realism of their social perspectives is not externally validated. It remains unclear to what extent these agent-generated viewpoints transfer to true human social cognition. The manuscript omits ablation or validation against authentic crowd or expert responses, leaving the practical value of the “social” aspect somewhat speculative.\n2. Although the authors proved the range of values ​​for $sc(x)$ in the appendix, I still have doubts about its simple form as $1+ωsc(x)$ in the social correction value: Is this linear weighting sufficient to distinguish samples of different difficulties? For example, for a completely correct simple sample, its social correction value is still 1, no different from the standard ORPO. Furthermore, the results in Table 3 show that the improvement of SCPO compared to ORPO is not significant, further raising concerns about the rationality of this weighting form.\n3. During data synthesis, different large models naturally produce different responses. However, the paper does not specify which models are used for the user agents, coordinator agent, or summarizer agent, nor the rationale behind these choices. Moreover, model differences in handling long contexts (e.g., varying user_number) can substantially affect the outputs generated by the coordinator and summarizer agents, potentially introducing additional variability into the synthesized data."}, "questions": {"value": "1. How well do the simulated social agents reflect real human social cognition? Specifically, is there any quantitative or qualitative validation comparing agent-generated perspectives with real crowd or expert responses?\n\n2. Is the linear weighting $1+ωsc(x)$ sufficient and justified? Can the authors provide evidence that this formulation meaningfully differentiates sample difficulty, especially given the limited gains over ORPO in Table 3?\n\n3. Which models are used for user agents, the coordinator, and the summarizer, and why? Do different context lengths (number of user numbers) affect the model selection for coordinator and summarizer agents?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LriPOZK0eH", "forum": "nHW64r5KFG", "replyto": "nHW64r5KFG", "signatures": ["ICLR.cc/2026/Conference/Submission17636/Reviewer_7qYS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17636/Reviewer_7qYS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17636/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761817994317, "cdate": 1761817994317, "tmdate": 1762927495161, "mdate": 1762927495161, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel Multi-Social-Agent Self-Distillation framework for Multimodal Misinformation Detection (MMD), addressing the critical trade-off between the limited perspective of single-agent methods and the high computational cost of multi-agent systems. The core idea is to simulate a diverse society of MLLM agents to generate multi-perspective judgments on multimodal misinformation, synthesizing their collective feedback into high-quality Social Chain-of-Thought (SCoT) data. To effectively utilize this data, the authors introduce Social Correction Value-Driven Preference Optimization (SCPO), a new alignment algorithm. Extensive experiments on the MFC-Bench and MMFakeBench benchmarks demonstrate its effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1 The central concept of \"thinking as society\" is highly innovative and well-motivated. The framework effectively addresses a genuine dilemma in the field by internalizing the benefits of multi-agent reasoning into a single, efficient model through self-distillation.\n\n2 The paper introduces two key novel components: the generation of Social Chain-of-Thought (SCoT) data through simulated social feedback and the SCPO algorithm. \n\n3 The experimental evaluation is thorough, covering two relevant benchmarks (MFC-Bench, MMFakeBench) and a wide range of baselines, including state-of-the-art open-source and proprietary models. \n\n4 The paper is generally well-written and logically organized. The figures are effective in illustrating the core concepts and the data generation pipeline."}, "weaknesses": {"value": "1 The quality of the final model is heavily dependent on the quality and diversity of the simulated social agents. The paper relies on profile-based prompting to create diverse agents, but the actual diversity and realism of the generated reasoning are not deeply analyzed or validated. There is a risk that the simulated \"society\" could exhibit unforeseen biases or lack true cognitive diversity, limiting the benefit of the approach.\n\n2 The paper presents the full SCPO framework but lacks a crucial ablation study. It's unclear how much of the performance gain comes from the SCoT data itself versus the specific SCPO optimization algorithm. \n\n3 The paper focuses on the impressive results but provides little analysis of where the proposed model still fails. Understanding the types of multimodal misinformation that remain challenging would provide deeper insight into the method's limitations and guide future work."}, "questions": {"value": "1 Could the authors provide a more in-depth analysis or qualitative examples demonstrating the actual cognitive diversity of the reasoning generated by the different user agents? How can we be assured that the profile-based prompting doesn't lead to a homogenized or biased \"society\" that limits the effectiveness of the collective reasoning?\n\n2 To better understand the individual contributions, could the authors include an ablation study comparing the performance when the high-quality SCoT data is trained using standard DPO or SFT, versus the proposed SCPO algorithm? \n\n3 Could the authors provide an analysis of the failure cases on the benchmark datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9TZPpsx6kS", "forum": "nHW64r5KFG", "replyto": "nHW64r5KFG", "signatures": ["ICLR.cc/2026/Conference/Submission17636/Reviewer_FGcP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17636/Reviewer_FGcP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17636/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761913935355, "cdate": 1761913935355, "tmdate": 1762927494636, "mdate": 1762927494636, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel framework called Multi-Social-Agent Self-Distillation (MSA-SD) to enhance the reasoning capability and social robustness of Multimodal Misinformation Detection (MMD). Based on the Qwen2-VL-7B model, the authors simulate feedback from multiple social roles to generate Social Chain-of-Thought (SCoT) data and introduce a new preference alignment algorithm, Social Correction Value-Driven Preference Optimization (SCPO), which dynamically focuses on samples with large social cognition divergences. Experiments conducted on two multimodal fact-checking benchmarks, MFC-Bench and MMFakeBench, demonstrate that the proposed framework significantly outperforms multi-agent methods as well as various open-source and closed-source MLLM models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Innovative framework design. The paper proposes a multi-social-agent self-distillation mechanism that integrates multi-perspective social reasoning into a single model, demonstrating strong novelty.\n\n2.Introduction of the social correction value sc(x). The dynamic weighting of samples through sc(x) provides a new, verifiable optimization signal. The “thinking as society” paradigm holds potential for broad conceptual influence.\n\n3.Comprehensive and significant experimental validation. Based on Qwen2-VL, SCPO achieves a +9.9% accuracy improvement, significantly surpassing InternVL3 and Qwen2.5-VL. Using GPT-4 to evaluate reasoning quality, SCPO achieves the best performance across four dimensions—misleadingness, informativeness, logicality, and readability."}, "weaknesses": {"value": "1.Insufficient ablation and error analysis. Although multiple optimization methods are compared, the paper does not quantify how the quality of SCoT data affects performance, nor analyze the independent contributions of each module (e.g., coordinator/summarizer). In Sec. 4.2 (Table 1), results are reported without standard deviations or significance tests. The paper also fails to present performance differences across samples with varying difficulty levels (high/low sc(x)).\n\n2.Missing experimental details. The concept of “thinking as society” lacks a concrete definition or illustrative examples. Hardware environment, training duration, and batch size should be explicitly reported. Key results in tables should include ± standard deviation or t-test significance. The differences between open and closed prompts should be analyzed, along with a discussion of model generalization."}, "questions": {"value": "1.Insufficient ablation and error analysis. Although multiple optimization methods are compared, the paper does not quantify how the quality of SCoT data affects performance, nor analyze the independent contributions of each module (e.g., coordinator/summarizer). In Sec. 4.2 (Table 1), results are reported without standard deviations or significance tests. The paper also fails to present performance differences across samples with varying difficulty levels (high/low sc(x)).\n\n2.Missing experimental details. The concept of “thinking as society” lacks a concrete definition or illustrative examples. Hardware environment, training duration, and batch size should be explicitly reported. Key results in tables should include ± standard deviation or t-test significance. The differences between open and closed prompts should be analyzed, along with a discussion of model generalization."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "UcpXibuWf1", "forum": "nHW64r5KFG", "replyto": "nHW64r5KFG", "signatures": ["ICLR.cc/2026/Conference/Submission17636/Reviewer_2dcz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17636/Reviewer_2dcz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17636/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989203838, "cdate": 1761989203838, "tmdate": 1762927494035, "mdate": 1762927494035, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}