{"id": "T2I6eTlFFL", "number": 10399, "cdate": 1758169982295, "mdate": 1763029590484, "content": {"title": "LADA: Enabling Adaptation of Black-Box LLMs to Dynamic Domain Changes at Test Time", "abstract": "Test-time adaptation (TTA) for black-box large language models (LLMs) seeks to adapt models to target-domain inputs during testing, enabling them to address distribution shifts without access to model parameters. Most existing approaches rely on adapters trained with substantial target-domain data, while such data are often scarce or unreliable. Moreover, the resulting adapters are tightly coupled to the training distribution and readily degrades in effectiveness in dynamic real-world scenarios. To address this problem, we propose a novel framework that leverages a meta-trained adapter to achieve stepwise adaptation of LLMs. Specifically, the adapter is meta-trained on tasks constructed from multiple available datasets, learning transferable skills for flexible adaptation to unseen domains. At test time, it is quickly adapted with only a few target domain examples and guides the LLM stepwise toward domain-appropriate reasoning trajectories through adaptive selection. Experiments on various benchmark datasets validate the effectiveness of the proposed approach.", "tldr": "", "keywords": ["test-time adaptation", "large language model"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/c83a27816d5c013834cd161dee2fe17d750fcbeb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces LADA, a meta-learning-based framework designed to enable black-box large language models (LLMs) to adapt to dynamic domain shifts at test time. The method meta-trains an adapter across diverse datasets and error types so that, during inference, the adapter can be quickly adapted using a few target-domain examples to guide the LLM reasoning process step by step."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tAddresses the practical problem of adapting black-box LLMs without parameter access.\n2.\tPresents a clear and well-organized description of the proposed meta-learning framework.\n3.\tIncludes theoretical analysis ensuring that the adaptive selection policy does not degrade performance compared to a baseline."}, "weaknesses": {"value": "1.\tLADA test-time procedure assumes access to paired positive–negative target-domain examples for “lightweight adaptation” and evaluates on predefined full datasets/subsets rather than streaming unlabeled batches, which deviates from the canonical unsupervised, online TTA setting.\n2.\tAlthough the paper emphasizes efficiency at test time, the meta-training phase involves extensive task construction (e.g., clustering, error synthesis) and iterative inner-outer loop optimization. This process is computationally intensive and requires access to multiple datasets and a powerful oracle LLM, which may limit the practicality of LADA for resource-constrained researchers or applications.\n3.\tThe experiments are conducted only on three relatively small reasoning datasets (GSM8K, StrategyQA, and ScienceQA). To convincingly demonstrate robustness under diverse domain shifts, the authors should evaluate LADA on more challenging and large-scale benchmarks such as AIME24, MATH-500, and AdaptEval [A], which are explicitly designed to test reasoning and adaptation capabilities across domains.\n4.\tSince the paper focuses on black-box LLM test-time adaptation, it is essential to include experiments on closed-source API-based LLMs (e.g., GPT-3.5-turbo, Claude), as done in BBOX-ADAPTER [B]. Without such experiments, the practicality of LADA for real-world black-box adaptation remains unverified.\n5.\tWhy the selection of DeBERTa-v3-large as the adapter model?\n\n[A] Test-Time Learning for Large Language Models, ICML 2025.\n\n[B]  Bbox-adapter: Lightweight adapting for black-box large language models, ICML 2024."}, "questions": {"value": "see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WTeTLDFMNH", "forum": "T2I6eTlFFL", "replyto": "T2I6eTlFFL", "signatures": ["ICLR.cc/2026/Conference/Submission10399/Reviewer_H2sx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10399/Reviewer_H2sx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761032757951, "cdate": 1761032757951, "tmdate": 1762921716975, "mdate": 1762921716975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "cuL2HtjatX", "forum": "T2I6eTlFFL", "replyto": "T2I6eTlFFL", "signatures": ["ICLR.cc/2026/Conference/Submission10399/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10399/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763029589759, "cdate": 1763029589759, "tmdate": 1763029589759, "mdate": 1763029589759, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LADA, a meta-learning framework for test-time adaptation of black-box large language models (LLMs) under dynamic domain shifts. LADA trains an external adapter on a diverse set of reasoning tasks and error types, enabling few-shot adaptation at test time without modifying LLM parameters (but update the scoring function). The adapter scores step-level reasoning candidates and adaptively accepts or resamples them to improve domain robustness. The authors provide a simple theoretical guarantee of non-decreasing cumulative reward and demonstrate consistent gains across reasoning datasets (GSM8K, StrategyQA, ScienceQA) with Qwen2-7B and Mixtral-8×7B models."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Addresses a timely and practical problem which is the black-box test-time adaptation, in the context of dynamic environment.\n\n2. The integration of meta-learning with step-level reasoning control is intuitive and well-motivated. \n\n3. LADA achieves consistent improvements over strong baselines across multiple datasets and models.\n\n4. Good amount of ablations and good amount of experiments."}, "weaknesses": {"value": "1. The adapter’s meta-training relies on an oracle LLM to synthesize positive/negative reasoning pairs, not sure how well this transform in reality.\n\n2. All benchmarks are reasoning QA datasets; no experiments demonstrate domain adaptation beyond QA.\n\n3. The theoretical contribution is very limited, not sure how much section 3.3. help with the paper.\n\n4. The paper is not well written without enough intuitive explanations (too much - reads like chatgpt-ish text), an example of how adaptation change before and after in terms of reasoning trace will be very helpful.\n\n5. The “changing domain” setup (ScienceQA subsets) is a weak proxy for changing environments, not sure how much I am convinced with this setup. Maybe some visualisation of the reasoning trace under different subsection help."}, "questions": {"value": "In general, I think the idea is not bad but the paper seems to be in a very early stage and need some major revision and more experimental results. Please refer to the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jhI99fDDgt", "forum": "T2I6eTlFFL", "replyto": "T2I6eTlFFL", "signatures": ["ICLR.cc/2026/Conference/Submission10399/Reviewer_zLAd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10399/Reviewer_zLAd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761648272343, "cdate": 1761648272343, "tmdate": 1762921716610, "mdate": 1762921716610, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel framework named LADA for continuous, rapid test-time adaptation of black-box large language models (LLMs) to unseen and dynamically changing domains. LADA enables adaptation without accessing or updating the LLM parameters, a key challenge for API-served black-box models. It leverages meta-trained adapters that learn transferable adaptation skills across diverse datasets and error types. At test time, the adapter uses a few target-domain examples for lightweight task-specific adaptation and guides the LLM stepwise through adaptive selection of reliable reasoning steps, steering generation toward domain-appropriate trajectories."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem studied is important and novel.\n\n2. Leveraging meta-learning on diverse tasks teaches transferable adaptation skills, addressing the data scarcity concerns in target domain.\n\n3. Overall LADA provides a robust solution for test time adaptation to various domains."}, "weaknesses": {"value": "1. The meta training relies on the synthesized reasoning error types and clustering which might not reflect the real world scenarios very well.\n\n2. The method is computationally intensive where multiple trials for each step are made which are then verified, this makes the method computationally very heavy.\n\n3. The setup of oracle LLM is not clear, what does it look like is not specified in the paper.\n\n4. While small in size as compared to LLM, the adapter still has considerable computational overhead with 0.3 B params.\n\n5. In Eq. 2 why a sum is required when the indicator will fire only at the time when the threshold is met and as soon as the threshold is met the sampling stops. It makes the setup bit confusing."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "i5AqZWNBwL", "forum": "T2I6eTlFFL", "replyto": "T2I6eTlFFL", "signatures": ["ICLR.cc/2026/Conference/Submission10399/Reviewer_KdFQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10399/Reviewer_KdFQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761672726998, "cdate": 1761672726998, "tmdate": 1762921716141, "mdate": 1762921716141, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes LADA, a meta-learning framework to enable test-time adaptation for black-box LLMs in dynamically changing domains. LADA pre-trains an adapter on a diverse set of tasks to learn general adaptation skills, which is then rapidly fine-tuned at test time with a few examples. This adapter guides the frozen LLM's generation step-by-step, selecting reliable reasoning steps to improve performance on unseen target domains."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles a well-defined and highly relevant problem: adapting pretrained LLMs to new domains without full retraining, a critical challenge for real-world deployment. The proposed solution of using meta-learning to learn a transferable adaptation skill is well-suited for the problem of low-data domains. The methodology is clearly explained, and the experimental setup appears thorough, with multiple benchmarks, strong baselines, and insightful ablation studies. The results presented are strong and consistently demonstrate the effectiveness of the proposed method."}, "weaknesses": {"value": "- Reliance on oracle LLM for task construction: The meta-training task construction critically relies on an oracle LLM to synthesize positive-negative reasoning pairs and reasoning errors types. This dependency raises concerns about the quality, completeness, and generalizability of the meta-training data; if the oracle LLM fails to synthesize realistic or complex errors, the adapter's learned transferability might be artificially limited.\n- While LADA aims for adaptation to unseen domains, the meta-training data is drawn from a fixed set of publicly available datasets. The effectiveness of transferring skills to domains truly outside the scope and error types simulated by these source datasets remains unverified, especially in complex, real-world domain shifts.\n- Limited ablation on meta-learning components: The ablation study only broadly validates the meta-training process. A more fine-grained ablation on the inner-loop loss and the effectiveness of clustering and specific error types would provide deeper insight into which meta-training elements are most critical for transferability."}, "questions": {"value": "- How realistic is Assumption 1? In complex multi-step reasoning, an immediately \"high-reward\" (high-scoring) step might still lead to a dead end later if the oracle/adapter is locally shortsighted, raising questions about whether the assumption holds universally in practice.\n- Oracle robustness: How sensitive is the final performance of LADA to the choice and quality of the oracle LLM?\n- Domain boundaries: The paper evaluates dynamic shifts among subsets of ScienceQA. Could the authors test LADA on a sequence of TTA tasks where the target domains are fundamentally different from the meta-training sources?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "nK4zSBn3dm", "forum": "T2I6eTlFFL", "replyto": "T2I6eTlFFL", "signatures": ["ICLR.cc/2026/Conference/Submission10399/Reviewer_YSeg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10399/Reviewer_YSeg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753898217, "cdate": 1761753898217, "tmdate": 1762921715829, "mdate": 1762921715829, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}