{"id": "2I4a6qsesO", "number": 9919, "cdate": 1758149015125, "mdate": 1759897685981, "content": {"title": "Tight Bounds for Schrodinger Potential Estimation in Unpaired Data Translation", "abstract": "Modern methods of generative modelling and unpaired data translation based on Schrodinger bridges and stochastic optimal control theory aim to transform an initial density to a target one in an optimal way. In the present paper, we assume that we only have access to i.i.d. samples from initial and final distributions. This makes our setup suitable for both generative modelling and unpaired data translation. Relying on the stochastic optimal control approach, we choose an Ornstein-Uhlenbeck process as the reference one and estimate the corresponding Schrodinger potential. Introducing a risk function as the Kullback-Leibler divergence between couplings, we derive tight bounds on generalization ability of an empirical risk minimizer in a class of Schrodinger potentials including Gaussian mixtures. Thanks to the mixing properties of the Ornstein-Uhlenbeck process, we almost achieve fast rates of convergence up to some logarithmic factors in favourable scenarios. We also illustrate performance of the suggested approach with numerical experiments.", "tldr": "Sharper bounds on the accuracy of Schrodinger potential estimation with applications to generative modelling and unpaired data translation.", "keywords": ["Learning theory", "stochastic optimal control", "Schrodinger potential", "non-asymptotic bounds"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5cc1e9f1e62ce2da7c734c2d058cd4a10d4d8f86.pdf", "supplementary_material": "/attachment/8d4448c662bc9a56998db479605073cc54fd8ede.zip"}, "replies": [{"content": {"summary": {"value": "This paper studies tight generalization bounds for the empirical risk minimizer within a class of Schrödinger Bridge (SB) potentials. The authors focus on a fundamental yet widely studied setting where the risk functional is the KL divergence and the underlying dynamics follow an Ornstein–Uhlenbeck (OU) process. Under a set of explicit assumptions (Assumptions 1–5), they establish a fast convergence rate of order $O(\\log^3 (n) / n$, which significantly improves upon prior results of order ($O(1\\sqrt{n}$). As a practical instantiation, the paper adapts the LightSB algorithm to the OU reference process and presents experiments on Gaussian mixture models (GMMs) and single-cell datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The primary contribution lies in deriving a notably tighter generalization bound by adopting the OU reference process. The improved rate represents a substantial theoretical advance over previous works.\n\n- The paper is well-structured and accessible, providing clear explanations of both the strengths and limitations of the proposed analysis. The authors carefully justify each assumption, discussing its practical implications and arguing convincingly that these assumptions are reasonable or attainable in practice."}, "weaknesses": {"value": "While the theoretical contribution is valuable, my main concerns lie in the practical validation and experimental analysis.\n\n- This is my main concern. The empirical section does not quantitatively assess the gap between the empirical and ground-truth SB potentials with respect to the number of samples $n$. Such analysis would strengthen the connection between theory and practice. It would be particularly insightful to evaluate this gap in the case of Gaussian marginals, where the exact SB potential is analytically tractable. Furthermore, constraining the neural network parameters to satisfy the boundedness and growth conditions (related to constants $L$ and $M$) should be discussed or enforced. A direct comparison with the Brownian-motion-based LightSB (with fixed number of samples $n$) should be discussed. Finally, the influence of the time horizon on the convergence rate should be investigated.\n\n- In Table 2, the results focus solely on distributional alignment. It would be more comprehensive to also report transport cost metrics, as well as other measures such as the FID and transport cost in image-to-image translation tasks.\n\n- The parametrization of the exponential SB potential through a GMM may not be practical for high-dimensional or complex data. In many applications, algorithms estimate the gradient of the log potential (i.e., the control function) rather than the potential itself.\n\n\nOverall, I find the theoretical result strong and meaningful. With additional experiments addressing these points (especially the first bullet point), I would be inclined to raise my evaluation score."}, "questions": {"value": "- Could the authors discuss the practical gap between the assumptions required by the theorem and the actual behavior of the LightSB implementation?\n\n- Could the authors provide an intuitive explanation for why the OU process yields a tighter bound? Specifically, since the required time horizon  $T$ is roughly proportional to $1/b$, a larger $b$ would make the terminal reference distribution more Gaussian-like, and the joint distribution of the reference dynamics nearly independent (memoryless), as discussed in [1]. Is this correct? Could author provide the better intuition?\n\n- Is it possible to extend the theoretical discussion to convergence guarantees for the gradient of the potential function? If so, are there existing works addressing this direction?\n\nReference\n\n[1] Domingo-Enrich et al., Adjoint Matching."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NrGDzxo2u5", "forum": "2I4a6qsesO", "replyto": "2I4a6qsesO", "signatures": ["ICLR.cc/2026/Conference/Submission9919/Reviewer_Hswo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9919/Reviewer_Hswo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9919/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897124247, "cdate": 1761897124247, "tmdate": 1762921375133, "mdate": 1762921375133, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors introduce novel bounds for the estimation of the Kullback-Leibler divergence between a candidate distribution defined by its potential and the Schrodinger Bridge target. More precisely, they show that under strong assumptions on both the potential and using a Ornstein-Uhlenbeck reference dynamics they can provide a non-asymptotic upper bound on the empirical risk minimizer and the target Schrodinger Bridge. The bound is of order $O(1/n)$ where $n$ is the number of data points used in the approximation and $O(d)$ (up to logarithmic terms in both cases). Some of the technical lemmas seem to be inspired by [2]. In addition, of this main theoretical contribution, the authors consider the procedure of [1] but instead replace the Brownian reference motion by a Ornstein-Uhlenbeck process. In that case, they present experimental results on several benchmarks. \n\n[1] Korotin et al. (2024) -- Light Schrodinger bridge\n\n[2] Puchkin et al. (2025) -- Sample complexity of Schrodinger potential estimation"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper seems technical strong. In particular, there is an extensive discussion on the error bounds obtained in the literature and the ones obtained in this paper. In particular, the authors draw comparisons with [1]. \n\n* The theory on Schrodinger Bridge is still sparse and even though are extremely strong in the present work the authors derived a novel and interesting result. \n\n[1] Korotin et al. (2024) -- Light Schrodinger bridge"}, "weaknesses": {"value": "* The presentation of the paper is quite hard to follow. In particular, the introduction is extremely long and seems to merge both the contribution and the related works. In particular, while I understand that it is a choice of the authors, I found it quite hard to follow the related work section. In particular, I did not understand the discussion with [1,2]. Related to this issue, I found the related work to be quite poor. There is no mention on the impact of Schrodinger Bridge work and its application in Machine Learning. For example, Diffusion Schrodinger Bridge [3] but also Stochastic Interpolants [4] and Adversarial approaches [5] are competitive works which are not mentioned (some of them are compared with in the Numerical Experiments section but it is never mentioned why those works are relevant).\n\n* The assumptions are extremely strong. While I understand that the results obtained by the authors are new, the class of target distributions and reference potentials that is under consideration is extremely limited. This strongly limits the theoretical impact of the paper. \n\n* The methodology contribution is incremental. In the applications, the authors consider Light SB which indeed fits their framework. However, the only modification to this work is in the reference process considered. The results obtained are quite underwhelming (see Table 2 for instance where the methods is similar to Light SB in performance and not as good as OT-CFM [7]). I do appreciate however that the authors highlight the limitations of their approach \"We emphasize that these examples are not intended to suggest\nuniversal superiority but rather to showcase specific strengths of our method in certain cases.\"\n\n* In the theoretical results presented, even though this is discussed, I find the fact that the time must grow with the number of samples to be a bit concerning. Even though I agree that the doubly logarithmic dependence (which has a logarithmic effect on the regularisation due to the exponential convergence of the Ornstein-Uhlenbeck) can be mitigated, it is concerning that the time grows as the number of samples grows. I see this as one of  the main limitation of the paper. \n\n[1] Pooladian et al. (2024) -- Plug-in estimation of Schrodinger bridges\n\n[2] Tang et al. (2024) -- Simplified diffusion Schrodinger bridge\n\n[3] De Bortoli et al. (2021) -- Diffusion Schrödinger Bridge with Applications to Score-Based Generative Modeling\n\n[4] Albergo et al. (2023) -- Stochastic Interpolants: A Unifying Framework for Flows and Diffusions\n\n[5] Gushchin et al. (2024) -- Adversarial Schrödinger Bridge Matching\n\n[6] Korotin et al. (2024) -- Light Schrodinger bridge\n\n[7] Tong et al. (2023) -- Improving and generalizing flow-based generative models with minibatch optimal transport"}, "questions": {"value": "* $\\hat{\\pi}$ in Page 3 hasn't been introduced yet. \n\n* See my question above on the time dependency. \n\n* Using a Ornstein-Uhlenbeck as a reference measure for Schrodinger Bridges is not new. For instance, it was used in [1]. In addition, it can be shown quite easily that using a Ornstein-Uhlenbeck as a reference path will lead to a quadratic cost function with a regularisation parameter that grows exponentially with the time of the process. It would be good if the authors could discuss this fact in the main paper. \n\n[1] Shi et al. -- Diffusion Schrödinger Bridge Matching"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FPktdZBthd", "forum": "2I4a6qsesO", "replyto": "2I4a6qsesO", "signatures": ["ICLR.cc/2026/Conference/Submission9919/Reviewer_TRip"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9919/Reviewer_TRip"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9919/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916793041, "cdate": 1761916793041, "tmdate": 1762921374527, "mdate": 1762921374527, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "**Disclaimer**\n\n*I do not have specific expertise in quantitative generalization bound estimation. Therefore, while I provide an assessment of the clarity, motivation, and overall contribution of the paper, I will defer to other reviewers with stronger expertise in the theoretical aspects when evaluating the technical soundness of the quantitative rate derivation.*\n\n**Summary**\n\nThis paper studies the finite-sample generalization behavior of Schrödinger bridge (SB) estimation for unpaired data translation. While most prior works adopt Brownian motion as the reference process, this work introduces the Ornstein–Uhlenbeck (OU) process as the reference dynamics. The OU process exhibits exponential mixing, which enables a more stable and analytically tractable setting for sample-based SB estimation. The paper establishs the first non-asymptotic generalization bound for estimating Schrödinger potentials $\\phi$ as the empirical risk minimizer and derives a convergence rate of $O(\\log^{3} (n) / n)$ for the KL divergence between the optimal coupling $\\pi^{*}$ and the empirical risk minimizer $\\hat{\\pi}$ (when the approximation error $\\Delta$ is small). Empirically, the paper extends the Light Schrödinger Bridge framework to an OU-based version (LightSB-OU), demonstrating improved stability and translation quality in synthetic, biological (single-cell RNA), and unpaired image translation tasks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper provides a new tight finite-sample generalization bound for Schrödinger bridge (SB) estimation.\n- Replacing Brownian motion with an OU process is both theoretically novel and practically beneficial.\n- The proposed LightSB-OU algorithm effectively connects the theoretical framework to practical tasks. Notably, the OU process corresponds to the VP-SDE used in the diffusion model, while Brownian motion aligns with the VE-SDE. The experiments on both synthetic and real-world datasets demonstrate that the OU reference improves fidelity in unpaired data translation.\n- The manuscript is well organized and clearly written. The motivation, the implications of assumptions, and the meaning of theoretical results are well described."}, "weaknesses": {"value": "- Although the derived convergence rate of $O( \\log^{3} (n) / n)$ is theoretically novel, there is no experimental study showing empirical convergence as a function of sample size. Including a convergence curve or ablation study on sample size would better demonstrate the practical significance of the bound.\n- While the bound is tight in a theoretical sense, it remains unclear how much this improved rate translates into practical accuracy gains over the previous $O(n^{-1/2})$ regime established by LightSB.\n- In the image-to-image translation experiments, only selected qualitative results are presented. Providing quantitative metrics, such as FID (for fidelity to target semantics) and LPIPS (for perceptual similarity between input and output), would significantly strengthen the empirical claims."}, "questions": {"value": "- Beyond theoretical implications, are there practical improvements in unpaired translation performance (e.g., FID, MMD) that can be directly attributed to the tighter convergence rate?\n- The title emphasizes \"Unpaired Data Translation,\" but its primary contribution is theoretical. Perhaps a title that emphasizes the general results, such as \"Tight Bounds for Schrödinger Potential Estimation between Empirical Distributions\", would better reflect the scope of this paper? (Of course, this is left to the author's discretion.)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LP9xmbQTaw", "forum": "2I4a6qsesO", "replyto": "2I4a6qsesO", "signatures": ["ICLR.cc/2026/Conference/Submission9919/Reviewer_ibUA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9919/Reviewer_ibUA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9919/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966958207, "cdate": 1761966958207, "tmdate": 1762921374246, "mdate": 1762921374246, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides learning theory style high probability bounds for estimating Schrodinger bridge potentials when the reference dynamics is OU process. This is a theoretical paper where the main result is a nonasymptotic, high probability bound improving prior work."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is mathematically strong, well structured, well motivated on its own domain.\n- There are mathematical novelties, for example, the high-probability bound is novel compared to prior work.\n- The derived convergence rate is fast."}, "weaknesses": {"value": "- Some assumptions of the paper are probably unrealistic for real-world scenarios\n- The bound, while a nonasymptotic, high-probability bound, is not very clean.\n- Practical implications of the result is not clear, there's a gap between theory and why how it explains the empirical improvements."}, "questions": {"value": "- notation is dense. A short “notation table” early in the paper would help.\n- Can Theorem 1 extend to sub-Gaussian cases? Please discuss Assumption 2 and its applicability in real-world settings.\n- The authors claim the dependence of the bound to dimension is 'nearly linear'. The bound itself, however, is not clearly written. It would be great if the authors provide a corollary, perhaps cleaning up some unnecessary quantities and display the dimension dependence clearly.\n- Please provide a discussion on when $\\Delta$ can be made small (for the favourable convergence rate), i.e., for what classes of initial/target distributions, what families would make it small?\n- The theoretical analysis is elegant, but it’s not clear what it tells practitioners: (i) Does the theorem suggest a way to choose the OU drift parameter b? (ii) Does it explain why LightSB-OU performs better numerically?\n\nIt is this last point I am more keen on seeing explained -- I appreciate the paper's main contribution is theoretical but it would be still good to understand how theoretical bound would give insights for practical improvements."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "grvWh6YNjI", "forum": "2I4a6qsesO", "replyto": "2I4a6qsesO", "signatures": ["ICLR.cc/2026/Conference/Submission9919/Reviewer_BNq5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9919/Reviewer_BNq5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9919/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762011016006, "cdate": 1762011016006, "tmdate": 1762921373820, "mdate": 1762921373820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}