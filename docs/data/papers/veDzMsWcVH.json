{"id": "veDzMsWcVH", "number": 24402, "cdate": 1758356502866, "mdate": 1759896768164, "content": {"title": "Balanced Federated Clustering via Anchor-Guided Dual Label Learning", "abstract": "Although the $\\ell_{2,q}$-norm has been widely used in robust feature extraction and sparse modeling, its potential in promoting clustering balance has long been overlooked. This paper theoretically reveals the inherent ability of the $\\ell_{2,q}$-norm to encourage balanced clustering, and proposes a federated multi-view clustering framework that incorporates it as a balance-aware regularizer. While preserving data privacy, the framework employs an efficient optimization strategy to learn a single label matrix, from which both anchor and sample labels can be inferred. The anchor labels then guide sample clustering, leading to improved clustering performance and robustness.", "tldr": "", "keywords": ["Machine Learning", "Federated Multi-view Clustering", "Anchor Graph", "Balance Regularization"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b7bdedf87a2ba6d6b8473c611cdf6d4ad76af6d1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This manuscript introduces a federated multi-view clustering framework that leverages the $\\ell_{2, q}$-norm as a balance-aware regularizer. Unlike prior uses of the $\\ell_{2, q}$-norm in robust feature extraction and sparse modeling, the work provides theoretical insights into its inherent capacity to promote balanced clustering. The proposed framework achieves privacy-preserving collaborative learning across distributed data sources while jointly optimizing a shared label matrix from which both anchor and sample labels are derived. These anchor labels then guide the clustering of samples, resulting in enhanced clustering accuracy and robustness under federated settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a rigorous theoretical justification for the use of the $\\ell_{2, q}$-norm in promoting *balanced clustering*, a property previously overlooked in the literature. This theoretical contribution distinguishes the work from existing studies that primarily leverage the norm for sparsity or robustness.\n- The proposed balance-aware federated multi-view clustering framework integrates the $\\ell_{2, q}$-norm with dual-label learning and tensor-based aggregation. This design allows simultaneous optimization of anchor and sample labels, effectively addressing the non-end-to-end limitations of prior federated clustering methods.\n- Experimental results across multiple benchmark datasets (BBCSport, ORL, Yale, and HAR) demonstrate consistently superior clustering accuracy, NMI, and purity compared to a broad range of state-of-the-art baselines. The ablation studies further validate the contributions of the balance and tensor regularization components."}, "weaknesses": {"value": "- The reported perfect clustering performance (ACC = NMI = Purity = 1.0) on several datasets is highly questionable for an unsupervised and federated clustering task. Such results are statistically implausible and suggest potential issues such as overfitting, data leakage, or an overly idealized experimental setup. Moreover, the absence of variance analysis, multiple runs, or statistical significance tests severely limits the reliability of the reported outcomes. These problems cast doubt on the empirical validity of the work. Additionally, there is a typographical error in the comparison table , i.e., “TersorFMVC” should be corrected to “TensorFMVC.”\n- The experiments are restricted to a few small-scale benchmark datasets (BBCSport, ORL, Yale, HAR), most of which are low-dimensional and clean. This narrow scope fails to demonstrate the scalability, robustness, and generalization of the proposed method under realistic federated learning scenarios, which typically involve large, heterogeneous, and high-dimensional data. Without validation on more challenging or real-world datasets, the claimed advantages remain speculative.\n- Although the paper provides a theoretical complexity analysis, it lacks empirical evaluations of runtime performance, communication overhead, or convergence behavior under different system configurations. Since federated learning inherently involves distributed optimization and communication, omitting these evaluations makes it impossible to assess whether the proposed framework is computationally feasible or efficient in practice.\n- The manuscript conceptualizes the federated setting primarily as a privacy-preserving constraint, overlooking critical system-level characteristics that define federated learning. There is no consideration of non-IID data distributions, unbalanced client data sizes, communication delays, or client dropouts, i.e., all of which are essential factors affecting model performance and robustness in real federated environments. The lack of such discussions or experiments suggests that the framework has been validated only under idealized and centralized-like conditions."}, "questions": {"value": "Please refer to ```weaknesses``` section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "ez1alz1NOo", "forum": "veDzMsWcVH", "replyto": "veDzMsWcVH", "signatures": ["ICLR.cc/2026/Conference/Submission24402/Reviewer_QtwU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24402/Reviewer_QtwU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24402/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761646086582, "cdate": 1761646086582, "tmdate": 1762943072685, "mdate": 1762943072685, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work presents a privacy-preserving framework for multi-view clustering in federated settings that achieves cluster balance. The key novelty is the repurposing of the ℓ₂,q-norm, conventionally employed to enhance robustness and induce sparsity, as a regularization mechanism that enforces balance across. The authors show theoretically that maximizing this norm inherently promotes equal distribution of samples across clusters, and they embed it into a federated, end-to-end dual-label learning pipeline guided by anchors."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This work meaningfully extends both federated learning and multi-view clustering by unifying them through a balance-aware, dual-label, tensor-regularized approach.Experiment shows the method achieving perfect or near-perfect scores，outperforming baselines such as FedMVL, FMVC-IMK, and TensorFMVC."}, "weaknesses": {"value": "The paper’s idea of using the ℓ₂,q norm to encourage clustering balance is somewhat novel, but not a truly groundbreaking innovation. Although introducing this norm into a federated clustering framework is relatively uncommon, the core ideas—balance constraints via regularization, anchor-based guidance, and multi-view tensor aggregation—are continuations of prior work (e.g., FedMVC, TensorFMVC). The paper’s main contribution lies in integrating these elements into a unified framework rather than proposing an entirely new theoretical paradigm. While the appendix includes an ablation study (Table 4), the analysis is fairly superficial and does not delve into the respective contributions of the tensor regularization term and the dual-label mechanism."}, "questions": {"value": "1.The paper claims that maximizing the ℓ₂,q-norm inherently leads to balanced clusters. Can the authors provide more intuition or empirical evidence demonstrating how this theoretical property translates to real-world datasets, especially when class imbalance exists naturally?\n2.Can the authors report communication overhead and computational cost relative to simpler federated clustering baselines？\n3.On the hyperparameter issue: with the weighted nuclear norm, the number of parameters increases to five. If all are optimized using grid search, does this not incur an overly large computational cost?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "As mentioned above"}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "YiNP94YuLI", "forum": "veDzMsWcVH", "replyto": "veDzMsWcVH", "signatures": ["ICLR.cc/2026/Conference/Submission24402/Reviewer_kJk3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24402/Reviewer_kJk3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24402/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761751241863, "cdate": 1761751241863, "tmdate": 1762943072472, "mdate": 1762943072472, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a federated multi-view clustering method that leverages the $\\ell_{2,p}$-norm as a balance-aware regularizer. The authors claim that maximizing the $\\ell_{2,p}$-norm encourages balanced clustering. The method performs anchor-guided dual-label learning in a federated setting, where sample and anchor labels are jointly optimized in an end-to-end manner. The server aggregates local results via a tensor Schatten-p norm-based fusion strategy. Experiments on four multi-view datasets demonstrate the effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The method integrates balance regularization, dual-label learning, and federated tensor aggregation, and improves clustering quality under privacy constraints.\n\n2. The optimization part is clearly described."}, "weaknesses": {"value": "1. The method involves five parameters that require  fine-tuning. Having so many parameters could limit its practicality.\n\n2. There is a lack of running time comparison. \n\n3. Only four datasets are used in the experiments, which could not sufficiently validate the effectiveness of the proposed method. \n\n4. The impact of non-IID data distributions across clients is not discussed."}, "questions": {"value": "1. Could the balance regularization be adapted to other federated tasks, like classification or regression?\n\n2. How does the method compare to federated clustering approaches based on deep representation learning?\n\n3. It assumes the number of clusters c is known a priori. How would the balance regularization perform if c is not known?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zYHTHyy8yT", "forum": "veDzMsWcVH", "replyto": "veDzMsWcVH", "signatures": ["ICLR.cc/2026/Conference/Submission24402/Reviewer_pnEa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24402/Reviewer_pnEa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24402/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761801538806, "cdate": 1761801538806, "tmdate": 1762943072290, "mdate": 1762943072290, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies federated multi-view clustering and addresses limitations related to cluster imbalance and non-end-to-end optimization. The authors propose an Anchor-Guided Dual Label Learning framework that (1) introduces a balance-aware ℓ₂,q-norm regularizer with theoretical guarantees for promoting balanced clustering, (2) develops a dual-label mechanism that jointly learns anchor labels and sample labels in an end-to-end manner, and (3) applies a tensor Schatten-p norm–based global fusion strategy on the server side to ensure global consistency while preserving privacy. Experiments on four benchmark datasets demonstrate consistent improvements over state-of-the-art approaches in terms of ACC, NMI, and Purity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "（1）Provides theoretical insights into how the proposed ℓ₂,q-norm regularizer promotes balanced clustering, which is rarely explored in federated clustering frameworks.\n（2）The dual-label mechanism effectively integrates anchor-based structure learning with sample-level clustering, enabling joint end-to-end optimization, in contrast to conventional two-stage methods.\n（3）The overall design combines client-side privacy-preserving optimization with server-side tensor-based aggregation and adaptive weighting, without requiring raw data exchange.\n（4）The proposed method consistently outperforms SOTA baselines on multiple benchmarks, supporting its effectiveness."}, "weaknesses": {"value": "1.\tTable 3 contains a numerical or typographical inconsistency for the HAR dataset.\n2.\tThe paper lacks a clear semantic or intuitive explanation of how the proposed dual-label (anchor–sample) mechanism benefits clustering quality.\n3.\tFigure 2 is difficult to read due to small text and unclear annotations.\n4.\tLimited analysis of computational overhead and scalability under varying numbers of clients/views."}, "questions": {"value": "1.\tWhat are the main limitations and potential failure cases of the proposed method?\n2.\tHow were the hyperparameters selected? Please clarify tuning strategies and search ranges.\n3.\tCould the authors provide more intuitive or semantic explanations regarding how the dual-label interaction leads to more consistent clusters?\n4.\tIs the proposed framework restricted to federated settings only? If applied in non-federated scenarios, what insights or potential benefits could the dual-label mechanism and global fusion strategy offer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Z0s2YcpjlP", "forum": "veDzMsWcVH", "replyto": "veDzMsWcVH", "signatures": ["ICLR.cc/2026/Conference/Submission24402/Reviewer_JabB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24402/Reviewer_JabB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24402/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898145241, "cdate": 1761898145241, "tmdate": 1762943072071, "mdate": 1762943072071, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}