{"id": "mUqgxqe8XK", "number": 9244, "cdate": 1758116084476, "mdate": 1759897735634, "content": {"title": "BdSL-SPOTER: A Transformer-Based Framework for Bengali Sign Language Recognition with Cultural Adaptation", "abstract": "Bengali Sign Language (BdSL) recognition is under-resourced and faces challenges from limited data, signer variability, and cultural differences in signing conventions. We introduce BdSL-SPOTER, a compact pose-based transformer that combines BdSL-specific signing-space normalization, motion-aware attention biasing, and a community-derived prototype regularizer to reduce intra-class variance and improve generalization. Evaluated on the BdSLW60 corpus (9,307 videos; signer-independent 5-fold CV), BdSL-SPOTER achieves 94.2% ± 1.8% Top-1 accuracy while remaining computationally efficient (≈847K parameters, 127 FPS on A100). We provide formal definitions, ablations, signer-disjoint evaluation, and ethical/community validation to support reproducibility and responsible deployment.", "tldr": "a culturally-aware pose transformer that uses signing-space normalization, motion-aware attention, and prototype regularization to boost BdSLW60 Top-1 from ~82% to 94.2% while staying compact and fast.", "keywords": ["Bengali Sign Language", "SPOTER", "Transformer Architecture", "Sign Language Recognition", "Accessibility Technology", "Deep Learning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ffb055f24d211415064e652ba48c6500b353fc5d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work proposes a SPOTER based framework for Bengali sign language recognition. (SPOTER is a transformer-based architecture first introduced by [1].) The authors remark that many sign language recognition publications focus on specific high-resource (for sign languages,  that is) languages such as American and British Sign Language (ASL and BSL). They state that (pre-)training models on these datasets leads to cultural bias, because differences between sign languages are not accounted for. They propose to modify the SPOTER architecture to include modifiers for cultural signing bias, introducing normalization for the signing location, salience estimates to focus on \"hold\" frames (see: the movement-hold framework [2]) and a regularizer based on sign templates.\n\nThe authors claim that their model is more robust than previous methods.\n\n[1]: Boháček, Matyáš, and Marek Hrúz. \"Sign pose-based transformer for word-level sign language recognition.\" Proceedings of the IEEE/CVF winter conference on applications of computer vision. 2022.\n[2]: Johnson, Robert E., and Scott K. Liddell. \"A segmental framework for representing signs phonetically.\" Sign Language Studies 11.3 (2011): 408-463."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "Addressing cultural specifics in sign language recognition is a highly valuable task, for which the authors should be commended. The use of AI is typically focused primarily on high-resource languages, and this is also true in the field of sign language processing."}, "weaknesses": {"value": "This paper was not ready for submission to ICLR or another conference. There are significant gaps in content and exploration, references and figures are missing, and it contains sections that are incomplete, consisting of only a table and no main text. The authors do not substantiate their claims, nor provide sufficient reasoning for methodological choices. Below, I go into detail per section.\n\n1. Introduction\nThis section is relatively okay, but the authors should not list \"disclosure of LLM usage\" as a contribution.\n\n2. Related work\nThis section is severely lacking. The authors fail to cite several papers and do not properly situate their work in the field. For example, they do not give an example of how transformers are commonly used in sign language recognition with pose inputs; instead, the authors cite Dosovitskiy et al.'s work on vision transformers, which are not relevant for this paper. This section is also far too short and lacking in content.\n\n3. Methodology\n- This section does not have enough text to support the equations. It reads as an enumeration of equations, but it would be difficult to reproduce this work without more context.\n- Figure 1 is incorrect: the figure does not match the main text.\n- The choice of how to scale (equation 2) is not substantiated.\n- Variables used in equations are not properly explained in the main text. \n- Section 3.2 does not start with a complete sentence.\n- Section 3.3 would benefit from more elaboration, as it is not clear what the authors are attempting to do here at first sight.\n- Section 3.4: same comment. Please re-write to make this more clear. Use full sentences.\n\n4. Linguistic analysis and community validation\nThis section should have been included under 3. Methodology. It is too short.\n\n5. Experimental setup\nPlease use full sentences. Consider moving to 3. Methodology as well.\n\n6. Results\n- Why is table 1 under this section? It should be listed under methodology.\n- Figures are missing, e.g., section 6.5 refers to Figure ??.\n\n7. Computational efficiency\nCombine this with section 6 and discuss the table briefly in the main text.\n\n8. Discussion\nThis paragraph is misplaced. Is this copied over from a rebuttal? Was this paper submitted elsewhere first?\n\nYou include the \"References\" header twice."}, "questions": {"value": "My main question is: can the authors improve the structure and presentation of the paper (see \"Weaknesses\"). This would improve clarity, and already answer many questions about the implementation and reasoning behind it.\n\nI do have two specific questions regarding section 7.\n\n7. Computational efficiency\nWhy is your method more efficient? Why does it have fewer parameters than SPOTER?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ur7vOvFf1R", "forum": "mUqgxqe8XK", "replyto": "mUqgxqe8XK", "signatures": ["ICLR.cc/2026/Conference/Submission9244/Reviewer_NCH3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9244/Reviewer_NCH3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9244/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760951886647, "cdate": 1760951886647, "tmdate": 1762920899459, "mdate": 1762920899459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes BdSL-SPOTER, a transformer-based framework for Bengali Sign Language (BdSL) recognition with cultural adaptations. The method achieves 94.2% top-1 accuracy on the BdSLW60 dataset under strict signer-independent 5-fold cross-validation. While the core ideas of the paper show potential, the current version suffers from a severe lack of completeness, which prevents a reliable assessment of its scientific contribution."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "Originality: The Cultural adaptation approach addresses an important gap in SLR research\nSignificance: Focusing on the under-resourced Bengali Sign Language is commendable\nTechnical approach: Integration of linguistic insights with transformer architecture is innovative\nEvaluation: Strict signer-independent cross-validation is methodologically sound"}, "weaknesses": {"value": "Incomplete presentation: Missing figures undermine the credibility of claims.\nMethodological opacity: Key parameters and implementation details are unclear.\nLimited validation: Cultural adaptations need more rigorous evaluation and analysis.\nSingle-dataset evaluation: Results on only one dataset limit generalizability claims."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "yl35uVPMWP", "forum": "mUqgxqe8XK", "replyto": "mUqgxqe8XK", "signatures": ["ICLR.cc/2026/Conference/Submission9244/Reviewer_Yok1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9244/Reviewer_Yok1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9244/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761385095844, "cdate": 1761385095844, "tmdate": 1762920898450, "mdate": 1762920898450, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes BdSL-SPOTER, a pose-based Transformer for Bengali Sign Language (BdSL) recognition, with three adaptations: (1) signing-center normalization with a cultural scaling factor α, (2) motion-aware attention biasing that upweights low-motion “hold” frames, and (3) a prototype regularizer based on community-validated embedding clusters. On BdSLW60 the authors report signer-independent 5-fold CV with Top-1 = 94.2% ± 1.8%, plus ablations and a paired t-test versus SPOTER."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Competitive results and ablations. Reported Top-1, Top-5, and Macro-F1 are high relative to listed baselines, and each cultural component contributes.  \n* Method description is clear enough to reproduce. The components are specified with equations and objectives, and the training pipeline is described at a level that enables re-implementation."}, "weaknesses": {"value": "1. Causal support for “cultural” choices is limited. The α choice is motivated by a compactness gap relative to an ASL reference, but comparability across acquisition conditions is not established. A sensitivity study or a learnable α would strengthen the claim. \n2. Low-motion attention bias relies on a strong linguistic assumption. Holds can also reflect hesitation or tracking noise. The paper does not show robustness of κ, γ, ε across sign speeds or styles. \n3. Ethics statement is minimal. It notes anonymized consent but does not provide institutional approval details, recruitment and compensation, or data governance specifics. \n4. Baseline coverage is inadequate. The paper does not compare against several widely used state-of-the-art sign language recognition baselines, both pose-based and RGB-based, under the same signer-disjoint protocol. Without these comparisons, the strength of the reported gains is unclear.\n5. Lack of cross-corpus evidence. Results are shown only on BdSL. External validity remains uncertain without at least one non-BdSL benchmark or a controlled cross-dataset transfer study."}, "questions": {"value": "* **About the “undervalued BdSL” claim.** If the core issue is resource scarcity, would a larger and more diverse BdSL dataset plus standard models close the gap? In other words, **what linguistic properties of BdSL make it fundamentally different from ASL or BSL in a way that still requires a distinct task framing when a dedicated dataset is available**? The introduction hints at compact signing space and longer holds, but a controlled cross-lingual study is not shown. \n* **α selection and robustness.** Why α = 0.85, and how sensitive are results to camera distance, signer body size, and resolution? Consider a learnable or data-driven α. \n* **Attention bias parameters.** Provide ranges and ablations for κ, γ, ε. Do fast signs or weak non-manual cues suffer under this bias? \n* **Signer-disjoint folds.** Will you release exact fold files to enable leakage audits and exact replication? The appendix currently omits them."}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "* **Institutional approval for human-related research.** You report anonymized informed consent but do not state whether you obtained approval from an Institutional Review Board or a Human Research Ethics Committee. **Please confirm whether you received formal approval to conduct human-subject research, and provide the committee name, approval ID, and date.** This is critical given the use of community participants and interpreters.  \n* **Recruitment and compensation.** Describe recruitment channels, inclusion and exclusion criteria, compensation, withdrawal rights, and conflict of interest management for the 3 interpreters and 12 community participants. \n* **Data governance.** Specify license ter"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CgdWTSwJc5", "forum": "mUqgxqe8XK", "replyto": "mUqgxqe8XK", "signatures": ["ICLR.cc/2026/Conference/Submission9244/Reviewer_vJaV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9244/Reviewer_vJaV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9244/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761623420241, "cdate": 1761623420241, "tmdate": 1762920897659, "mdate": 1762920897659, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces BdSL-SPOTER, a transformer-based model for Bengali Sign Language (BdSL) recognition, with cultural adaptation. The proposed model incorporates signing-space normalization, motion-aware attention biasing, and a community-derived prototype regularizer, specifically tailored to address the unique challenges of BdSL recognition."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Cultural Adaptation: The model addresses cultural differences in BdSL through novel techniques, including cultural regularization and motion-aware attention biasing. These methods help the model better understand and adapt to BdSL’s unique signing conventions, making it culturally sensitive.\n\n2. Dataset and Experimental Design: The paper uses the BdSLW60 dataset, which contains 9,307 videos, ensuring a diverse and representative dataset. The rigorous signer-independent 5-fold cross-validation approach ensures the reliability of the experimental results and provides a strong evaluation framework.\n\n3. High Recognition Accuracy: The model achieves an impressive 94.2% Top-1 accuracy on the BdSLW60 dataset. This demonstrates significant improvement over previous methods, showcasing the model’s effectiveness in BdSL recognition tasks."}, "weaknesses": {"value": "1. Single Dataset Limitation: Although the BdSLW60 dataset is a valuable resource, the model’s evaluation is based on a single dataset. The lack of cross-dataset validation limits the generalizability of the model. Future work could benefit from expanding the model’s evaluation to multiple datasets to assess its broader applicability.\n\n2. Limited Signer Diversity: While the BdSLW60 dataset includes 18 signers, the diversity of the signers (in terms of age, gender, and regional variations) is still limited. Greater diversity in the signer population could improve the robustness and generalizability of the model.\n\n3. Cultural Adaptation Explanation: The paper introduces cultural regularization and motion-aware attention biasing as key components, but the explanation of how these mechanisms adapt to cultural differences is somewhat limited. A deeper exploration of how these adaptations work and how they reduce the impact of cultural variance would strengthen the paper.\n\n4. Limitations and Future Work: The authors acknowledge the limitations of the current work, such as the use of a single dataset and limited signer diversity. However, the paper does not provide specific solutions or directions for addressing these issues in future work. More concrete strategies for cross-dataset validation, enhancing signer diversity, and improving cross-linguistic generalization could be outlined."}, "questions": {"value": "See above **Weaknesses**."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "49bg3CW8si", "forum": "mUqgxqe8XK", "replyto": "mUqgxqe8XK", "signatures": ["ICLR.cc/2026/Conference/Submission9244/Reviewer_v8Uo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9244/Reviewer_v8Uo"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9244/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761632161467, "cdate": 1761632161467, "tmdate": 1762920897016, "mdate": 1762920897016, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}