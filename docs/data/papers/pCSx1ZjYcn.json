{"id": "pCSx1ZjYcn", "number": 2011, "cdate": 1756976301865, "mdate": 1759898174306, "content": {"title": "SpikeNet: Sparse Spike-Driven Mask Vector Transformer for Energy-Efficient and Stable Spiking Point Cloud Processing", "abstract": "The unordered nature of point cloud data poses significant challenges to %traditional analysis tasks. conventional architectures primarily designed for structured data. Spiking neural networks (SNN), by virtue of their inherent sparsity and dynamics, are particularly well-suited for processing point clouds to effectively extract meaningful features.We propose SpikeNet, a novel spiking neural network architecture for energy-efficient and robust point cloud analysis. We introduce spiking-driven sparse attention mechanism coined the Spiking Vector Mask Transformer (SVMT). By dynamically aligning the sparsity of point cloud data through binary spiking masks, SVMT eliminates the need for softmax and multiplication operations, significantly improving computational efficiency. \nWe also propose a Dynamic Sparse Spiking Residual (DSSR) structure and integrate it with SVMT to form the Spiking Neural Network (SpikeNet) for point cloud classification and segmentation. SpikeNet overcomes the trade-off between accuracy and efficiency in previous SNN methods, achieving collaborative optimization of performance and energy-efficiency. Experiments on benchmark datasets show that SpikeNet achieves state-of-the-art performance in shape classification and part segmentation tasks, comparable to artificial neural network (ANN) based methods. Our source code is in supplementary material and will be made publicly available", "tldr": "", "keywords": ["Point Cloud Processing", "Spiking neural network", "Spiking Vector Mask Transformer"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4d6af9f3df6cd850620054e59d004cf2b8efc081.pdf", "supplementary_material": "/attachment/eb5a109621d06a5c99db3751a2202029188526e5.zip"}, "replies": [{"content": {"summary": {"value": "This paper identifies the trade-off between accuracy and efficiency in existing Spiking Neural Networks (SNNs) for point cloud processing. To address this, the authors propose SpikeNet, a novel SNN architecture featuring a Spiking Vector Mask Transformer (SVMT) that uses binary spike masks to eliminate costly Softmax and multiplication operations, and a Dynamic Sparse Spiking Residual (DSSR) structure to stabilize training. Experiments show that SpikeNet achieves state-of-the-art performance among SNNs on classification and segmentation tasks, competitive with conventional Artificial Neural Networks (ANNs)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The proposed SVMT module is well-justified, as it cleverly leverages binary spiking masks to dynamically align with the native sparsity of point cloud data, providing a natural and efficient alternative to standard attention.\n\n2. This design provides a significant energy-saving advantage by fundamentally eliminating the need for the computationally intensive softmax and multiplication operations that are typical in transformer-based models."}, "weaknesses": {"value": "The main weakness of this paper is its unclear application value.\n\n1. The authors mainly compare the energy consumption in their experiments. However, in most real-world application, inference latency and memory consumption are more important. The authors should provide these results.\n\n2. How does the energy calculated? Any hardware experiments to validate its impact?\n\n3. The authors only conduct experiments on shape-level 3D analysis, which is too toy to validate the real-world application value. Shape analysis is very different from scene-level perception, so at least experiments on scene segmentation should be provided."}, "questions": {"value": "See weakness. Shape-level pointcloud analysis is a very toy experimental setting. For pointcloud analysis, scene-level perception is much closer to real application."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hDlWv3rx81", "forum": "pCSx1ZjYcn", "replyto": "pCSx1ZjYcn", "signatures": ["ICLR.cc/2026/Conference/Submission2011/Reviewer_j5DG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2011/Reviewer_j5DG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761449105199, "cdate": 1761449105199, "tmdate": 1762915989745, "mdate": 1762915989745, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SpikeNet, a spiking neural backbone for point-cloud classification and part segmentation that couples a Dynamic Sparse Spiking Residual (DSSR) module with a Spiking Vector Mask Transformer (SVMT). DSSR is designed to stabilize direct SNN training via bounded surrogate gradients and dynamic sparsity, leading to a provable attenuation of gradient amplification. SVMT replaces dot-product attention with a local per-channel Q–K difference gate and a spike-driven mask, which removes softmax and quadratic token interactions; the resulting attention scales linearly in time–channel–point dimensions and is amenable to neuromorphic implementations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed Spiking Vector Mask Transformer (SVMT) is not a trivial substitution of ReLU with spikes. It redefines attention itself in spike terms: attention weights are derived from spike-domain channelwise differences $\\tau(Q,K)=Q-K$ instead of dense dot products and softmax, and sparsification is enforced through a Spike Point Masker that gates either channels or points using binary spike statistics. \n2. The model is benchmarked on ModelNet40, ScanObjectNN, and ShapeNetPart, which together cover CAD-like clean geometry, noisy real-world scans, and fine-grained part-level segmentation. \n3. The ablations are not superficial. They analyze alternative attention operators (sum, product, etc.), masking strategies (channel vs point), and embedding dimensionality. These studies make a credible case that the final architecture is not arbitrary."}, "weaknesses": {"value": "1. DSSR’s stability argument is persuasive but qualitative. The paper does not report gradient-norm distributions across depth, training-loss curves comparing with/without DSSR, or any theorem giving a global bound across layers and timesteps. Adding a small empirical study here would turn into strong evidence.\n2. The Spike Point Masker is described in both pointwise and channelwise forms, but notation occasionally glosses over which axes are being summed (over points $N$, channels $C$, timesteps $T$). This matters because those masks drive sparsity and thus energy savings. \n3. The model has not yet been demonstrated on full outdoor LiDAR scenes, nor is there an ablation of memory scaling in that regime. S3DIS shows meaningful indoor semantics, but the overall mIoU is still behind the best ANN scene-segmentation models.\n4. A few phrases imply that SpikeNet “removes multiplications” or is “entirely neuromorphic.” The appendices clarify the nuance: SVMT avoids $QK^\\top$ dot-product attention and softmax, but linear projections and masked elementwise products still exist; the encoder/decoder are spike-friendly, but the input embedding and final FC head are still float MAC. These nuances should be stated up front."}, "questions": {"value": "1. Can you provide per-sample inference latency and measured runtime energy or power traces on any available hardware?\n2. Can you share gradient-norm vs depth, or loss-vs-epoch curves, comparing SpikeNet with and without DSSR? This would convert the qualitative stability argument into quantitative evidence.\n3. Spike Point Masker details: Please precisely state tensor layout ($T\\times C\\times N$ or equivalent) and specify along which axes you sum to get channel masks vs point masks. A short pseudocode snippet in the appendix would remove any ambiguity.\n4. You state that the encoder/decoder can in principle be mapped to spike-friendly AC-heavy hardware, while the input embedding stem and FC head remain MAC-dominated. Is the intended deployment strategy a hybrid (MAC front/back end around a spike core), or do you envision eventually replacing the stem with spike-native modules as well?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oEAuFqWc3N", "forum": "pCSx1ZjYcn", "replyto": "pCSx1ZjYcn", "signatures": ["ICLR.cc/2026/Conference/Submission2011/Reviewer_NzVp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2011/Reviewer_NzVp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841245236, "cdate": 1761841245236, "tmdate": 1762915989540, "mdate": 1762915989540, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a spiking neural network for point cloud data, named as SpikeNet, It primarily designs a spike attention mechanism on the Spiking Vector Mask Transformer (SVMT) that eliminates the need for multiplication and softmax operations, and introduces a Dynamic Sparse Spiking Residual (DSSR) structure. Experiments demonstrate the superior performance of the proposed model."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-organized and provides a detailed presentation of the methodology.  \n2. The proposed model demonstrates superior performance on both point cloud classification and segmentation tasks.  \n3. The models significantly reduce parameter count and energy consumption. The authors also provide code in the supplementary material."}, "weaknesses": {"value": "1. This work lacks stronger motivation and fails to provide valuable insights, such as those on the proposed spiking attention and DSSR module.\n\n2. In Equation 7, element-wise subtraction is employed to aggregate features S‘^{(l-1)} and E_{va}. I do not understand the rationale for using subtraction here. Both are spike features, and passing their difference through an SNN layer will result in the complete loss of information from E_{va}.\n\n3. Please explain the energy consumption calculation approach. In Table 1. SpikePointNet (ICCV23) exhibits an energy consumption of 1.6 mJ at 0.1 FLOPs, while SpikeNet-N/C consumes only 1.8 mJ at 1.9 FLOPs. This suggests potential inconsistencies in the calculation approaches."}, "questions": {"value": "The author needs to respond to the Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lzaA1JtQF3", "forum": "pCSx1ZjYcn", "replyto": "pCSx1ZjYcn", "signatures": ["ICLR.cc/2026/Conference/Submission2011/Reviewer_Fv5h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2011/Reviewer_Fv5h"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962279015, "cdate": 1761962279015, "tmdate": 1762915989373, "mdate": 1762915989373, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SpikeNet, a spiking-driven architecture for point cloud analysis. The authors designed two key modules: (1) Spiking Vector Mask Transformer (SVMT), which uses sparse spike-based queries, keys, and values to dynamically align point cloud data with a binary spike mask; (2) Dynamic Sparse Spiking Residual (DSSR), which used to stabilize SSN training while exploiting temporal sparsity. Extensive experiments on ModelNet40, ScanObjectNN and ShapeNetPart demonstrate the proposed architecture’s superior performance compared to previous SOTA."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper provides clear motivation and is well organized; the figures are readable and understandable. \n\n2. The experimental results are quite complete and adequate, and support the author's claims. \n\n3. The proposed approach is logical and technically sound."}, "weaknesses": {"value": "1. Energy advantage lacks real hardware validation. The energy efficiency results provided by the authors are estimated through operation models rather than measured on GPU or neuromorphic hardware, which weakens the “energy-efficiency” claim. \n\n2. ANN baselines could be stronger. In Table1, the authors compare with serveral ANNs, but not include strong recent baselines such as Point Transformer V3/Point-Bert/PointNeXt under the unified training protocol. \n\n3. Segmentation still cannot beat top ANN SOTAs, such as PointMamba and PCM on ShapeNet, and PointRWKV on  S3DIS dataset. For example, On the S3DIS dataset, although SNN variants are competitive in some classes, mIoU results are below best ANN methods reported in the table. \n\n4. It seems the authors manually wrote the citation, and the format fails to comply with ICLR’s citation guidance. Please review the guidance."}, "questions": {"value": "1. Could you clarify how the estimated energy correlates with the used GPU(A6000) or neuromorphic hardware measurements? Have you conducted any experiments on real devices to validate the energy advantage of SpikeNet? \n2. The authors have compared SpikeNet with recent strong SNNs and several Mamba-based models as shown in Table 1 and 2. But, not very recent ANNs such as Point Transformer V3 and PintNeXt are considered. Could the authors provide comparisons to them? \n\n3. The vector-difference operator τ plays an important role in the SVMT module. Does it capture relative geometric offsets or spike-timing discrepancies?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gIWY5DkvDM", "forum": "pCSx1ZjYcn", "replyto": "pCSx1ZjYcn", "signatures": ["ICLR.cc/2026/Conference/Submission2011/Reviewer_R7n5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2011/Reviewer_R7n5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2011/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762143271106, "cdate": 1762143271106, "tmdate": 1762915989241, "mdate": 1762915989241, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}