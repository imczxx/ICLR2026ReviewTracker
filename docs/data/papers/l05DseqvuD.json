{"id": "l05DseqvuD", "number": 3262, "cdate": 1757389318964, "mdate": 1763622050594, "content": {"title": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "abstract": "Large Language Model (LLM)-based agentic systems, often comprising multiple models, complex tool invocations, and orchestration protocols, substantially outperform monolithic agents. Yet this very sophistication amplifies their fragility, making them more prone to system failure. Pinpointing the specific agent or step responsible for an error within long execution traces defines the task of \\textbf{agentic system failure attribution}. Current state-of-the-art reasoning LLMs, however, remain strikingly inadequate for this challenge, with accuracy generally below $10\\\\%$.  To address this gap, we propose AgenTracer, the first automated framework for annotating failed multi-agent trajectories via counterfactual replay and programmed fault injection, producing the curated dataset TracerTraj. Leveraging this resource, we develop AgenTracer-8B, a lightweight failure tracer trained with multi-granular reinforcement learning, capable of efficiently diagnosing errors in verbose multi-agent interactions. On {Who\\&When} benchmark, AgenTracer-8B outperforms giant proprietary LLMs like Gemini-2.5-Pro and Claude-4-Sonnet by up $18.18\\\\%$, setting a new standard in LLM agentic failure attribution. More importantly, AgenTracer-8B delivers actionable feedback to off-the-shelf multi-agent systems like MetaGPT and MaAS with $4.8\\sim14.2\\\\%$ performance gains, empowering self-correcting and self-evolving agentic AI.", "tldr": "", "keywords": ["LLM Agent", "Agentic System", "Failure Attribution"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4ad6b1217a99a5f8e7a76d23157ebf94d0e328d6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work features two contributions for failure attribution of multi-agent systems: 1. An automated pipeline, AgenTracer, that can annotate or create failure trajectories with two strategies (counterfactual replay and fault injection). 2. A model, AgenTracer-8B, which is trained with reinforcement learning upon the curated training data. Experiments on Who&When dataset demonstrate superior or competitive failure attribution performance compared with a range of open-source or proprietary models. It is also shown that applying the feedback from AgenTracer-8B can consistently benefit the self-improvement of agentic systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The two-fold strategy for annotating agent trajectories, i.e., counterfactual replay for identifying failures from failed trajectories and fault injection for injecting failures into successful trajectories, is sound and scalable.\n2. The experiments in Section 5.3, i.e., directly leveraging the failure attributor for self-improvement of MAS, are informative and valuable proxies that demonstrate real-world applicability."}, "weaknesses": {"value": "1. The only complaint is that in Table 1, only one dataset (Who&When) is evaluated. Having at least one more benchmarks would make the evaluation more comprehensive.\n2. The reasoning or necessity behind the linear interpolation (via $\\lambda$) between the step-level and the agent-level reward in Equation (11) is not discussed or explained. Does it mean that there is an inherent trade-off between the step-level and agent-level failure attribution?"}, "questions": {"value": "Please see Weaknesses 2."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8hNGLOJogm", "forum": "l05DseqvuD", "replyto": "l05DseqvuD", "signatures": ["ICLR.cc/2026/Conference/Submission3262/Reviewer_uaBz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3262/Reviewer_uaBz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3262/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930204369, "cdate": 1761930204369, "tmdate": 1762916632412, "mdate": 1762916632412, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces AgenTracer, a framework for attributing failures in multi-agent LLM systems by identifying who (which agent) and when (which step) caused the decisive error. The core idea is to (i) generate labeled trajectories using counterfactual replay to locate the earliest decisive error and programmatic fault injection to synthesize failures from successes, producing a dataset (TracerTraj) with paired successful/failed runs; and (ii) train a specialized AgenTracer-8B model (Qwen-style backbone) with a multi-granular reward (agent-, step-, and format-level) using GRPO-like reinforcement learning. The intended scope is debugging and reliability for compound/agentic systems across coding, math, and general tasks. Reported outcomes include better Who&When attribution than strong general LLMs and modest multi-turn performance gains when AgenTracer is plugged into external agent frameworks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The decisive-error notion plus automated curation that combines counterfactual replay with programmatic fault injection is a useful addition to the toolset for diagnosing multi-agent failures, distinct from prior taxonomies that stop at coarse failure categories.\n* Training a compact attributor model with a multi-granular reward is practically valuable for plugging into agent stacks; the engineering is thoughtful and likely to see real use.\n* The plug-in demonstration is nice to see, and the integration studies show that better attribution can translate into gains in multi-turn settings, aligning with the intended way of using AgentTracer."}, "weaknesses": {"value": "* The main tables appear to be single-run point estimates with no mean±std, confidence intervals, or hypothesis tests. The number of seeds is not stated. Without dispersion and tests (ideally paired where appropriate), it’s impossible to tell whether reported gains are robust or just noise.\n* The paper introduces several design choices (multi-granular reward, dynamic clipping, removal of KL, analyzer quality, injection strength), but sensitivity is not reported. Without targeted ablations and sweeps, we can’t separate genuine attribution skill from simpler effects (e.g., a format reward just enforcing response templates).\n* Much of the training signal comes from injected errors. There is no out-of-distribution evaluation on naturally occurring failures (e.g., tool/API drift, latency-induced desync, memory/context loss) or on different agent graphs/toolchains. As a result, it’s unclear how well the attributor generalizes beyond its own synthesis process."}, "questions": {"value": "* How sensitive are results to reward weights, the dynamic clipping schedule, and the removal of KL? Please include a small grid or one-at-a-time sweeps.\n* How does performance change with weaker/stronger fault injection and with different analyzer qualities during counterfactual replay? An ablation here would help establish causal contributions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iRNzdnwk2l", "forum": "l05DseqvuD", "replyto": "l05DseqvuD", "signatures": ["ICLR.cc/2026/Conference/Submission3262/Reviewer_VBFj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3262/Reviewer_VBFj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3262/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961711431, "cdate": 1761961711431, "tmdate": 1762916632221, "mdate": 1762916632221, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces AgenTracer, a system that automatically finds and explains why agent-based systems fail. It includes AgenTracer-8B, a smaller model that uses reinforcement learning and performs better than proprietary models. It also shows improvement on self-correcting and self-evolving agentic systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The proposed automatic trajectory annotation framework appears to be both technically sound and conceptually novel. By systematically generating annotated failure trajectories, the authors establish a strong methodological foundation for analyzing and diagnosing agentic system behaviors. This approach could significantly improve the interpretability and reliability of complex multi-agent environments.\n\nThe performance of AgenTracer-8B is particularly impressive. The experiments demonstrate that this lightweight model achieves high diagnostic accuracy, outperforming even leading proprietary models. The use of multi-granular reinforcement learning is a well-motivated design choice that seems to balance efficiency and precision effectively.\n\nFinally, the empirical results showing that AgenTracer can enhance off-the-shelf agentic systems are especially promising."}, "weaknesses": {"value": "This work proposed and combined different rewards for RL training, it would be goos to see ablation over different rewards"}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "dmF89lKxGl", "forum": "l05DseqvuD", "replyto": "l05DseqvuD", "signatures": ["ICLR.cc/2026/Conference/Submission3262/Reviewer_oZRD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3262/Reviewer_oZRD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3262/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971866329, "cdate": 1761971866329, "tmdate": 1762916632011, "mdate": 1762916632011, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of fragility in MAS by introducing (1) AgenTracer, an automated data generation technique for MAS failure attribution annotation datasets, (2) TracerTraj, a dataset of 2000 annotated trajectories with it, (3) RL-training an 8B model (AgenTracer-8B) to perform failure attribution given MAS execution trace. The authors demonstrate that AgenTracer-8B outperforms even larger proprietary models (like Gemini-2.5-Pro and Claude-4-Sonnet) on the Who&When attribution benchmark. Further, the authors demonstrate boosting the performance of MAS in-deployment using Self-refine and CRITIQUE with the AgenTracer-8B generated feedback."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper tackles a highly relevant problem, of building models/systems to perform MAS error attribution\n- The paper closes the loop, It doesn't just present a diagnostic and error detection tool, but also demonstrates its practical value by demonstrating that using feedback from AgenTracer-8B, MAS can use Self-refine and CRITIQUE methods to achieve better performance."}, "weaknesses": {"value": "- The primary weakness of the proposed framework is the AgenTracer pipeline's dependency on having access to ground truth / oracle guidance. The counterfactual replay method from the paper requires knowing the correct action at a given step to identify deviation as the decisive error.\n- The above weakness limits the general applicability of the data generation method to domains where ground truth is not accessible, which includes most complex and open ended domains where MAS are being deployed (for example, AI4Science, AI4Code, AI4Math, etc.). The paper needs to discuss how this method could be adapted to domains where such an oracle is unavailable.\n- This also potentially limits the applicability of the AgenTracer-8B model, as it has been trained with data facing the mentioned limitation."}, "questions": {"value": "- Could the authors please elaborate on the limitations of the \"oracle guidance\" assumption? Are there ways this framework could be applied to more open-ended domains where a clear ground truth or oracle is not available? Is it possible, for example, to use a weaker, more readily available signal (e.g., final binary task success) to approximate the counterfactual replay? For example, in many domains, it is easier to verify if a task has been solved than to find the solution.\n- For the \"programmed fault injection\" component, could the authors provide more detail on the taxonomy of faults injected? How did they ensure these faults are representative of real-world failures in MAS, rather than just synthetic or easy-to-identify errors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Zs8lSp2xOT", "forum": "l05DseqvuD", "replyto": "l05DseqvuD", "signatures": ["ICLR.cc/2026/Conference/Submission3262/Reviewer_1gdm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3262/Reviewer_1gdm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3262/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762075208745, "cdate": 1762075208745, "tmdate": 1762916631269, "mdate": 1762916631269, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}