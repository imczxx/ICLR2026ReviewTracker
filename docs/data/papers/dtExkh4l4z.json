{"id": "dtExkh4l4z", "number": 4437, "cdate": 1757680742043, "mdate": 1763018045810, "content": {"title": "BrowserAgent: Building Web Agents with Human-Inspired Web Browsing Actions", "abstract": "Efficiently solving real-world problems with LLMs increasingly hinges on their ability to interact with dynamic web environments and autonomously acquire external information. While recent research like Search-R1 and WebDancer demonstrates strong performance in solving web tasks, they heavily rely on additional tools to convert the interactive web environment into static text content. This is in contrast to human browsing behaviors, which involve diverse interactions with the browser, such as scrolling, clicking, and typing. In this paper, we propose BrowserAgent, a more interactive agent that solves complex tasks through human-inspired browser actions. BrowserAgent operates directly on raw web pages via Playwright through a set of predefined browser actions. We adopt a two-stage training (Supervised Fine-Tuning (SFT) and Rejection Fine-Tuning (RFT)) to improve the model's generalization abilities. Despite using significantly less training data than Search-R1, BrowserAgent achieves more competitive results across different Open-QA tasks.  Additionally, we introduce an explicit memory mechanism to store key conclusions across steps, further enhancing the model's reasoning capabilities for long-horizon tasks. Notably, BrowserAgent-7B can achieve around 20\\% improvement over Search-R1 on multi-hop QA tasks like HotpotQA, 2Wiki, and Bamboogle. These results indicate that BrowserAgent can serve as a more advanced framework for more interactive and scalable web agents.", "tldr": "", "keywords": ["Brosweragent", "RFT", "LLM"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/b9d3673d5deb8b8d203884b5851ffd834873b471.pdf", "supplementary_material": "/attachment/eaad41cf4b037266779f1634daba4eabe3a94eae.zip"}, "replies": [{"content": {"summary": {"value": "They propose BrowserAgent, a novel framework for web agents that more closely mimics human browsing behavior by interacting directly with dynamic web environments. Unlike prior state-of-the-art models such as Search-R1, which depend on external tools to convert web pages into static text, BrowserAgent operates on raw web content through a predefined set of browser actions (e.g., scroll, click, type) implemented via the Playwright library.\n\nThis paradigm first employs Supervised Fine-Tuning (SFT) to teach the agent basic interaction patterns, followed by Rejection Fine-Tuning (RFT) to help it learn from suboptimal action sequences. This approach proves to be remarkably data-efficient, enabling BrowserAgent to achieve superior generalization and performance despite using significantly less training data than its predecessors.\n\nThey addresses the challenge of long-horizon tasks by incorporating an explicit memory mechanism. This module allows the agent to store key conclusions and information gathered across multiple interaction steps, substantially enhancing its multi-hop reasoning capabilities."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The most significant strength is the move away from reliance on external tools (like Jina services or GPT-4o for summarization). The agent operates directly on raw web pages via Playwright, using a set of human-inspired actions (click, scroll, type, tab management). This allows it to access more fine-grained, dynamic information and avoids the information loss that occurs when converting a web page into static text."}, "weaknesses": {"value": "* The experiments are conducted on a locally hosted, offline snapshot of Wikipedia from 2022 (using Kiwix). This is a controlled, clean, and ad-free environment with a relatively consistent structure. It is not representative of the real, \"messy\" internet, which is filled with dynamic ads, pop-ups, CAPTCHAs, complex JavaScript interactions, and diverse layouts. \n\n* The training data (5.3K trajectories) is generated by having GPT-4.1 interact with the environment. This means BrowserAgent is essentially learning to \"imitate\" the browsing strategy of GPT-4.1. This approach caps the agent's potential, as it is unlikely to discover novel strategies that surpass its teacher's capabilities. It may also inherit any biases or suboptimal behaviors of the teacher model."}, "questions": {"value": "1. The paper fails to demonstrate the performance advantages of a browser-based agent (like BrowserAgent) compared to API-based web agents. This comparison is completely missing from the manuscript.\n\n2. The baselines used for comparison are outdated. The authors should evaluate their model on more recent and comprehensive search benchmarks, such as BrowseComp, X-BENCH, or GAIA.\n\n3. The set of baselines is not only limited but also relatively weak. To better situate the paper's contributions, it is essential to compare against stronger and more relevant state-of-the-art methods, such as WebDancer, Deepdive, or WebSailor.\n\n4. The use of a memory module for context management during inference raises a concern about latency. Since the context is modified at each step, this could lead to a decreased KV cache hit rate, resulting in higher inference latency. Have the authors analyzed this potential performance trade-off?\n\n5. The methods for data synthesis and training (SFT + RFT) lack significant novelty and follow standard practices. Have the authors considered or experimented with Reinforcement Learning (RL) to further optimize the agent's policy, especially given that some competing baselines utilize it?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Mj9s6EKTqu", "forum": "dtExkh4l4z", "replyto": "dtExkh4l4z", "signatures": ["ICLR.cc/2026/Conference/Submission4437/Reviewer_K2qk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4437/Reviewer_K2qk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4437/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760595418641, "cdate": 1760595418641, "tmdate": 1762917364319, "mdate": 1762917364319, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "OgJMv1iH4C", "forum": "dtExkh4l4z", "replyto": "dtExkh4l4z", "signatures": ["ICLR.cc/2026/Conference/Submission4437/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4437/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763018045133, "cdate": 1763018045133, "tmdate": 1763018045133, "mdate": 1763018045133, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "BrowserAgent proposes a browser-native agent that operates directly on live web pages using human-like atomic actions (click, scroll, type, etc.), combined with a lightweight memory mechanism and a two-stage post-training process (SFT and Rejection Fine-Tuning). The paper claims improved reasoning efficiency and lower operational cost compared to prior web agents that depend on multi-tool pipelines or reinforcement learning. While the approach is innovative in its design simplicity and interpretable memory use, it lacks solid empirical validation, particularly regarding comparisons to true WebAgent systems, cost efficiency evidence, and the quantitative impact of its claimed advantages."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The framework’s browser-native design avoids intermediate summarizers and external APIs, resulting in a more human-like browsing behavior. This simplifies the web interaction pipeline and makes the research results closer to real-world browsing applications.\n2. By relying on SFT + RFT instead of complex RL methods like PPO or DPO, the training pipeline is reproducible and less resource-intensive. The results show its advantages on multiple QA benchmarks even without RL-training."}, "weaknesses": {"value": "1. Although the authors claim that WebAgent-style methods are expensive and less flexible, no actual webagent baseline is evaluated. This makes the cost-efficiency and interaction limitations claims speculative rather than evidence-based.\n\n2. The paper asserts that avoiding tool calls lowers cost but provides no quantitative analysis, without runtime, API call frequency, token usage, inference cost measurements. \n\n3. Search-R1 seems to be evaluated under a different environment than its original setup, leading to lower performance. The lack of detailed implementation or adaptation notes limits interpretability of the comparative results and weakens fairness claims.\n\n4. The “memory” is effectively a textual note-taking process similar to the ReAct reflection/summarization pattern, without architectural innovation."}, "questions": {"value": "1. Can the authors provide quantitative comparisons (token usage, API calls, inference time) to substantiate the claim that BrowserAgent is lower-cost than WebAgent systems?\n\n2. How are Search-R1 baselines implemented in this paper? The original results in different QA tasks are much higher than those reported in this paper. Are there implementation constraints that may disadvantage them relative to BrowserAgent?\n\n3. Why were no direct baselines of webagent included, given that the paper critiques them in the introduction?\n\n4. Will the memory mechanism bring extra inference cost? What is the difference of the proposed memory mechanism with context summarization and reflection. \n\n5. Why TriviaQA comparison is missing (only partial results in appendix) while it is a important bnehcmark for general QA in Search-R1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lNAok9sNaw", "forum": "dtExkh4l4z", "replyto": "dtExkh4l4z", "signatures": ["ICLR.cc/2026/Conference/Submission4437/Reviewer_KMVj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4437/Reviewer_KMVj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4437/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761521357866, "cdate": 1761521357866, "tmdate": 1762917363987, "mdate": 1762917363987, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces BrowserAgent, an interactive web agent designed to solve complex, real-world problems by browsing the web. Unlike previous agents that rely on external tools to convert web pages into static text, BrowserAgent operates directly on raw web pages. It uses a set of human-inspired actions—such as scrolling, clicking, and typing—to navigate and interact with dynamic web environments via the Playwright framework.\n\nTo train the agent, the authors use a lightweight two-stage training pipeline:\n1. Supervised Fine-Tuning (SFT): This initial stage teaches the base model (Qwen-7B-Instruct) basic reasoning capabilities and the correct format for its thoughts and actions.\n2. Rejection Fine-Tuning (RFT): In this second stage, the SFT model generates multiple potential reasoning paths. The system then selects the best correct answer (specifically, the one with the most reasoning steps) to further fine-tune the model, encouraging deeper and more robust reasoning.\n\nA key feature of BrowserAgent is its explicit memory mechanism. This allows the agent to store key conclusions it finds during its browsing, helping it to maintain context and reason effectively over long-horizon, multi-step tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "It proposes a framework where the agent interacts directly with raw web pages using fine-grained actions like click, scroll, and type, which is a departure from relying on static text summaries.\n\nThe paper introduces an efficient SFT and RFT training strategy that improves the model's reasoning abilities without complex reinforcement learning techniques.\n\nIt introduces a memory module that stores key findings, significantly enhancing the agent's performance on complex multi-hop reasoning tasks.\n\n BrowserAgent-7B achieves significant performance gains over strong baselines like Search-R1, notably showing around a 20% improvement on multi-hop QA tasks (such as HotpotQA, 2Wiki, and Bamboogle) while using significantly less training data."}, "weaknesses": {"value": "1. The agent operates on an \"accessibility tree\" parsed by Playwright, which is \"pure text-based\". This is a known limitation for all agents of this type. It means the agent is blind to visual layout, non-text elements (like complex JavaScript-rendered charts), and website designs that do not have a clean, descriptive accessibility tree.\n\n2. The agent uses a \"minimal yet expressive\" set of predefined actions (e.g., click, type, scroll). This fixed set may not be sufficient for more complex, dynamic web interactions like drag-and-drop, handling complex pop-up modals, or solving CAPTCHAs, which are not mentioned in the action list.\n\n3. Scalability of Training Data: While the authors developed a system to parallelize Playwright instances and improve data collection throughput, the process is still inherently complex. The training was conducted on only 5.3K trajectories, which is noted as being \"significantly less\" than baselines, but also points to the difficulty of creating this type of high-quality, browser-native data at scale."}, "questions": {"value": "Above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "cAZZsCuH7p", "forum": "dtExkh4l4z", "replyto": "dtExkh4l4z", "signatures": ["ICLR.cc/2026/Conference/Submission4437/Reviewer_CZep"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4437/Reviewer_CZep"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4437/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762342515534, "cdate": 1762342515534, "tmdate": 1762917363680, "mdate": 1762917363680, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}