{"id": "ZZPTllZac7", "number": 12515, "cdate": 1758208341297, "mdate": 1759897504631, "content": {"title": "Explainable Multimodal Regression via Information Decomposition", "abstract": "Multimodal regression aims to predict a continuous target from heterogeneous input sources and typically relies on fusion strategies such as early or late fusion. However, existing methods lack principled tools to disentangle and quantify the individual contributions of each modality and their interactions, limiting the interpretability of multimodal fusion. We propose a novel multimodal regression framework grounded in Partial Information Decomposition (PID), which decomposes modality-specific representations into unique, redundant, and synergistic components. The basic PID framework is inherently underdetermined. To resolve this, we introduce inductive biases by enforcing Gaussianity in the joint distribution of latent representations and the response variable, enabling analytical computation of PID terms. Additionally, we derive a closed-form conditional independence regularizer to promote the isolation of unique information within each modality. Experiments on six real-world datasets, including a case study on brain age prediction from multimodal neuroimaging data, demonstrate that our framework outperforms state-of-the-art methods in both predictive accuracy and interpretability, while also enabling informed modality selection and model pruning for efficient inference.", "tldr": "", "keywords": ["Partial Information Decomposition", "Multimodal Regression", "Cauchy-Schwarz Divergence", "Interpretability."], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8e44d1225d005325002eb6b1460a60a66b924e88.pdf", "supplementary_material": "/attachment/80fae16a3dbe40de54642070685b23a30f9cbfab.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces PIDReg, an explainable multimodal regression framework grounded in Partial Information Decomposition (PID). The key objective is to quantify and disentangle modality contributions—unique, redundant, and synergistic—in multimodal regression tasks. To make PID tractable for high-dimensional, continuous data, the authors enforce Gaussianity in the joint latent space of modality-specific representations and the transformed target variable. This yields a closed-form analytical decomposition."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- PIDReg provides a mathematically grounded decomposition of information flow in multimodal learning.\n\n- The Gaussian PID formulation eliminates reliance on computationally expensive variational or Monte Carlo approximations.\n\n- PID components (unique, redundant, synergy) correspond directly to measurable modality behaviors—clearly demonstrated in Table 4 and Figures 3b–c.\n\n- Six datasets spanning physics, healthcare, and affective computing show consistent gains in both RMSE and correlation metrics (Tables 1–3).\n\n- Interpretability outcomes match known domain insights (e.g., sMRI dominance in brain age prediction, vision dominance in robotics)."}, "weaknesses": {"value": "- Although practical, the Gaussian approximation may restrict performance on highly multimodal or non-linear latent distributions. An empirical robustness analysis with non-Gaussian data would strengthen the claim.\n\n- The combination of multiple regularizers (CS, Gaussianity, and conditional independence) could increase training time—though no runtime comparison is reported.\n\n- The Hadamard product captures pairwise synergy but may overlook higher-order nonlinear dependencies.\n\n- The framework involves several λ-weights (Eq. 17). A sensitivity study or adaptive weighting scheme could improve reproducibility.\n\n- While Section 3.1.1 formalizes Gaussian PID, more intuition on how union information constrains redundancy would aid accessibility for non-specialists."}, "questions": {"value": "- How sensitive is the PIDReg performance to deviations from Gaussianity? Could normalizing flows or copula-based Gaussianization improve flexibility?\n\n- How does the computational overhead of PIDReg compare to baselines like DER or CoMM?\n\n- Could the synergy modeling (Hadamard product) be replaced with more expressive neural cross-interaction layers?\n\n- Can PIDReg be adapted for classification or discrete regression tasks where mutual information is not directly differentiable?\n\n- How scalable is PIDReg to scenarios with >3 modalities and large feature dimensions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "All datasets are publicly available and ethically cleared (e.g., REST-meta-MDD and CMU-MOSEI). The method poses no ethical concerns and promotes transparency in model interpretability."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8ARNSlEBgL", "forum": "ZZPTllZac7", "replyto": "ZZPTllZac7", "signatures": ["ICLR.cc/2026/Conference/Submission12515/Reviewer_HX1r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12515/Reviewer_HX1r"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12515/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761086134911, "cdate": 1761086134911, "tmdate": 1762923383746, "mdate": 1762923383746, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PIDReg, a multimodal regression framework integrating Partial Information Decomposition (PID) to address interpretability gaps. It decomposes modality-specific info into unique (U), redundant (R), and synergistic (S) components, enforces Gaussianity on latent distributions for analytical PID computation, and designs CS divergence/CMI regularizers. Experiments on 6 datasets (healthcare, physics, etc.) show it outperforms SOTA in accuracy and interpretability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe paper innovatively integrates Partial Information Decomposition (PID) into multimodal regression, solving PID’s underdeterminacy via Gaussianity enforcement on latent distributions (enabling analytical PID computation) and combining CS divergence/CMI regularizers—overcoming prior limitations of PID in high-dimensional continuous data. It also proposes a two-stage optimization for stable fusion weight learning, a creative combination of interpretability and regression.\n\n2.\tTheoretically rigorous (e.g., closed-form CMI estimator, Gaussian PID derivation); experimentally comprehensive (6 cross-domain datasets, synthetic data validation, ablation studies for regularizers/bottleneck) to confirm reliability; results align with domain knowledge (e.g., sMRI dominance in brain age prediction).\n\n3.\tWell-structured (abstract→method→experiments→conclusion); key terms (PID components, CS divergence) defined clearly; appendices detail proofs/experimental setups; tables/figures (e.g., PID estimates, ablation results) intuitively support claims.\n\n4.\tFills multimodal interpretability gaps (intrinsic vs. post-hoc XAI); yields domain insights (e.g., Vision+Text synergy in sentiment analysis); scalable to multi-modality; aids practical tasks (modality selection for efficient inference), with value for healthcare/robotics."}, "weaknesses": {"value": "1.\tLacks validation on data with inherently non-Gaussian latents (e.g., discrete event-based robotics data). No experiments on scenarios where latent non-Gaussianity (e.g., multi-modal signals) might bias PID decomposition, missing supplementary tests (e.g., bimodal MNIST) to quantify impact.\n\n2.\tCritical params (PID convergence $K=5/\\delta^t<0.01$, regularization $\\lambda_1=\\lambda_2=\\lambda_3=0.1$) lack sensitivity analysis. No comparison of performance across param values (e.g., $K=3$ or $\\lambda=0.01$) to confirm robustness, hindering reproducibility.\n\n3.\tHigher training time (4.64s/epoch vs. DER’s 1.76s) lacks optimization exploration (e.g., mini-batch covariance estimation). No data on scalability to large datasets (100k+ samples) or high-dimensional latents ($d>256$), limiting real-world adoption.\n\n4.\tThe linear-noise IB ($Z_m=\\lambda_m R_m+(1-\\lambda_m)\\epsilon_m$) lacks comparison to nonlinear IB variants (e.g., adaptive noise scaling). No analysis of how $\\lambda_m$ convergence (Table 7) correlates with modality quality (e.g., noisy vs. clean modalities), missing opportunities to link bottleneck behavior to data characteristics."}, "questions": {"value": "1.\tDid you conduct ablation experiments comparing the Hadamard product to these alternatives (e.g., tensor products, 2D convolutions for interaction modeling) on datasets with known synergistic patterns? For example, in CMU-MOSEI (Section 4.2), where Vision+Text synergy aids sarcasm detection, does the Hadamard product outperform other methods in capturing this synergy (e.g., via higher S alignment with human-annotated sarcasm cases)?\n\n2.\tDid you evaluate PIDReg on a dataset with known non-Gaussian latents—e.g., a robotics dataset where latent $Z_1$ (visual) is continuous but $Z_2$ (tactile) is discrete (binary contact/no-contact)? If so, how did Gaussian enforcement impact PID decomposition (e.g., did it underestimate discrete tactile synergy) and predictive accuracy?\n\n3.\tFor a dataset like CMU-MOSI (Audio &Text), did you run a post-hoc method (e.g., kernel SHAP) on PIDReg’s predictions to quantify explanation consistency?\n\n4.\tFor datasets with already Gaussian targets (e.g., synthetic data in Section 4.1), does the transformation provide any benefit (e.g., faster PID convergence) or introduce unnecessary bias?\n\n5.\tHave you tested PIDReg on datasets where latent representations are inherently non-Gaussian? If yes, does Gaussianity enforcement lead to PID decomposition biases  or a decline in prediction accuracy? If not tested, have you considered relaxing the Gaussian assumption  to adapt to such scenarios while still ensuring the analyticity of PID computation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MirJbkzyIh", "forum": "ZZPTllZac7", "replyto": "ZZPTllZac7", "signatures": ["ICLR.cc/2026/Conference/Submission12515/Reviewer_DLax"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12515/Reviewer_DLax"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12515/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761673999056, "cdate": 1761673999056, "tmdate": 1762923383411, "mdate": 1762923383411, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PIDReg, a multimodal regression model that enforces a partial information decomposition (PID) of the learned representations. Concretely, two encoders produce latent embeddings $Z_1,Z_2$ for the two input modalities, and a fused prediction is formed as $Z = w_1Z_1 + w_2Z_2 + w_3(Z_1 \\odot Z_2)$ (where $Z_1\\odot Z_2$ is elementwise product modeling synergy). To make PID tractable in continuous, high-dimensional data, the authors force the joint distribution of $(Z_1,Z_2,Y)$ to be (approximately) Gaussian, via (1) a rank‐based inverse-normal transform on $Y$ and (2) a Shapiro–Wilk Gaussianity regularizer on $(Z_1,Z_2,Y)$. They then analytically compute Gaussian‐PID terms (redundancy $R$, unique $U_1,U_2$, synergy $S$) and incorporate a Cauchy–Schwarz divergence (CS) regularizer to encourage $Z_1$ to be independent of the other modality (and vice versa). Experimentally, PIDReg is evaluated on six tasks, where it reportedly achieves very low error and yields nontrivial modality‐level decompositions (e.g. high redundancy or synergy) aligned with domain expectations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\t**Ambitious Idea with End-to-End PID:** Embedding a partial information decomposition directly into a multimodal regression model is novel. The paper tackles the underdetermined nature of PID in continuous domains by introducing Gaussian latent constraints, which is a bold approach. As a result, PIDReg delivers intrinsic interpretability: the learned weights $(w_1,w_2,w_3)$ and computed PID terms give a clear “unique vs. redundant vs. synergistic” attribution of each modality to the prediction, rather than a black‐box fusion. This end-to-end interpretability is conceptually appealing and aligns with recent interest in multimodal interaction analysis[1].\n2.\t**Comprehensive Experiments:** The authors test PIDReg on diverse real-world datasets and a synthetic benchmark. They compare against some strong baselines. In every case, PIDReg attains the lowest error and highest correlation, suggesting it effectively uses multimodal information. The empirical section is thorough, covering both quantitative prediction metrics and qualitative PID decompositions.\n3. **Reproducibility:** The authors report implementation details in appendices. The design choices (e.g. latent size, learning rates, batch sizes) are clearly documented. This transparency is laudable and should facilitate replication.\n\n[1] Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework"}, "weaknesses": {"value": "1.\t**Strong Gaussian Assumption:** A core assumption is that $(Z_1,Z_2,Y)$ is jointly Gaussian so that PID terms admit an analytic solution. However, this assumption is very strong and typically invalid in realistic multimodal tasks. The authors attempt to enforce it via a Shapiro–Wilk test loss, but this only tests for marginal normality. Even if each of $Z_1,Z_2,Y$ is marginally Gaussian, the joint distribution may still be far from multivariate normal (as the paper itself notes). There is no guarantee that the latent $Z_i$ have Gaussian joint statistics, especially in high dimensions and under nonlinear encoders. If the Gaussianity assumption fails, the computed PID values ($R,U,S$) are not theoretically valid. \n2.\t**Target Transformation Unclear:** The authors apply a rank-based inverse-normal transform to the regression target $Y$. This makes $Y$ marginally Gaussian, but it is highly unusual in regression to alter the target scale without discussion. It is unclear whether they apply the model to the transformed $Y$ and then invert back for error metrics, or simply train on the “normal” $Y$ directly. If the latter, the reported RMSE is on a transformed scale (e.g. the CT target “axial position” became normally distributed), which may not reflect true predictive accuracy on the raw metric. Conversely, inverting predictions from the normal space back to the original scale introduces its own approximation. The paper should clarify how target transformation interacts with training and evaluation. This procedural complexity raises doubts about both the validity of the Gaussianity enforcement and the comparability of reported errors.\n3.\t**Heavy Regularization and Hyperparameters:** PIDReg introduces multiple nonstandard components: the linear‐noise IB (Eq.1), the Gaussianity loss $L_{\\text{Gauss}}$, the CS‐based conditional‐independence loss $L_{\\text{CMI}}$, and stochastic redundancy assignment. Together, these add at least three new hyperparameters ($\\lambda_1,\\lambda_2,\\lambda_3$) plus kernel width $\\sigma$ for the CS estimator (Eq.15). Although the authors claim to fix $\\lambda=0.1$ universally, it is surprising that one can balance these terms without per-task tuning. The paper gives no details on how gradients are computed through $W$ or how sensitive $W$ is to batch size. The empirical runtime (Table 11) shows PIDReg is considerably slower (4.64s/epoch vs 1.76 for DER), indicating nontrivial computational overhead. In summary, the method is complex and may be brittle: modest changes to any regularizer or its weight could substantially change the learned decomposition, but this is not explored.\n4.\t**Ambiguous Interpretability Claims:** The key selling point is that $(w_1,w_2,w_3)$ and the PID components give insight into modality contributions. But this interpretation relies on all assumptions holding perfectly. For example, synergy is modeled purely via $Z_1\\odot Z_2$, yet true statistical synergy could exist in other forms (e.g. one modality enabling non‐additive transformations of the other). If the learned $Z_1$ and $Z_2$ are not purely unique, the weight attribution can be misleading. The authors introduce a Bernoulli variable to randomly assign redundancy to one modality, but the impact of this design is not thoroughly analyzed. In Table 4 and Fig.3 the PID values are plausible (e.g. Text-Video having higher synergy), but without ground truth we cannot be sure these correspond to “true” causal contributions. Indeed, recent work emphasizes that there is no unique, universally agreed PID definition, and different valid definitions give different $U,R,S$ splits[11]. Thus, claiming hard explainability may overstate what the method delivers; the “interpretation” is contingent on one particular PID convention and the Gaussian proxy.\n5.\t**Limited Scope (Two Modalities):** PIDReg is explicitly derived for two modalities. Although an extension to three modalities is sketched in Appendix F, the main paper and experiments only handle bimodal cases (for the tri-modal MOSI/MOSEI they reduce to pairwise combinations). Modern multimodal problems often involve more than two modalities (e.g. vision, audio, text simultaneously). It is unclear how well the method scales to 3+ inputs. The appendix suggests a “pragmatic simplification” for three sources, but without results it is speculative.\n6.\t**Baselines and Ablations:** While the paper compares many baselines, it omits some natural ones. For example, a simple concatenation‐MLP or linear fusion baseline is not shown; it would be informative to see how much PIDReg’s fancy regularizers improve over a vanilla fusion. The ablation in D.1 reports that removing $L_{\\text{Gauss}}$ hurts performance, but we do not see ablations of $L_{\\text{CMI}}$ or the IB vs. just end‐to‐end."}, "questions": {"value": "1.\t**Joint Gaussianity:** Can you provide empirical evidence (e.g. multivariate normality tests) that $(Z_1,Z_2,Y)$ is close to Gaussian in your trained model? If not, how should one interpret the PID values?\n2.\t**Target Transformation:** How exactly do you handle the inverse-normal transform of $Y$ in training vs. evaluation? Are the reported RMSE values computed on the original scale of $Y$ or the transformed scale? Please clarify the procedure and its impact on metrics.\n3.\t**Kernel Width $\\sigma$:** How is the kernel width $\\sigma$ for the Gram matrices in Eq.(15) chosen? Is it fixed or adaptive? Did you find PIDReg sensitive to this hyperparameter?\n4.\t**Extension to >2 Modalities:** Appendix F mentions tri-modal PIDReg. Have you actually applied the method to three inputs (e.g. Audio+Visual+Text)? If so, how do you define “synergy” with three sources, and what are the results? If not, how would one generalize the weight-based fusion to more modalities?\n5.\t**PID Definition:** Which PID measure are you using for the analytic Gaussian solution (minimum‐MI PID à la Williams & Beer)? Different definitions (Broja, $I_{\\min}$, etc.) yield different synergy. Why choose this one, and have you checked consistency of your interpretations under alternative PID definitions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "The paper appears to contain no obvious ethical or societal issues."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GgP4YsL53R", "forum": "ZZPTllZac7", "replyto": "ZZPTllZac7", "signatures": ["ICLR.cc/2026/Conference/Submission12515/Reviewer_KZFk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12515/Reviewer_KZFk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12515/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761778061973, "cdate": 1761778061973, "tmdate": 1762923383046, "mdate": 1762923383046, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PIDReg, a framework for explainable multimodal regression that uses Partial Information Decomposition (PID) to quantify unique, redundant, and synergistic information from different modalities. To make the intractable PID problem solvable within a deep learning context, the authors enforce a multivariate Gaussian distribution on the joint latent space of the modality representations and the target variable. This strong inductive bias enables an analytical PID solution, which guides a feature fusion module in an end-to-end trained model. The authors claim their method achieves state-of-the-art predictive performance and provides faithful modality-level interpretations across several datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper's goal of creating an intrinsically interpretable multimodal model is appreciated. Framing modality contributions through the principled, information-theoretic lens of PID is a novel and creative approach that could provide a much richer vocabulary for model explanation.\n\n2. The evaluation is comprehensive, spanning six real-world datasets from diverse domains, which demonstrates the framework's versatility. The neuroimaging case study, where the model's interpretations align with existing clinical evidence, is particularly compelling."}, "weaknesses": {"value": "1. The framework's entire interpretability claim rests on a fragile assumption that the joint latent space can be molded into a Gaussian without destroying the true underlying information dynamics. It seems that the method does not discover the information structure. Instead, it imposes a Gaussian one and then analyzes it. Are the reported PID values a true reflection of the data's properties, or are they merely artifacts of this powerful, and likely mismatched, prior? The lack of guarantees of identifiability (of true latent variables/structures) is a critical downside, in my opinion.\n\n2. Along the same line, synergy is modeled exclusively via the Hadamard product of latent vectors. This is a highly specific, simplistic, and arbitrary choice for modeling what are likely complex, non-linear interactions. The paper offers no theoretical justification for this choice nor does it ablate any alternatives (e.g., bilinear pooling, attention).\n\n3. The paper claims state-of-the-art predictive performance but primarily compares against other Information Bottleneck (IB) based methods. This is a niche subfield. The most powerful and common multimodal architectures today rely on mechanisms like cross-attention."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VKc9wKqezN", "forum": "ZZPTllZac7", "replyto": "ZZPTllZac7", "signatures": ["ICLR.cc/2026/Conference/Submission12515/Reviewer_dZ8M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12515/Reviewer_dZ8M"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12515/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762004848615, "cdate": 1762004848615, "tmdate": 1762923382800, "mdate": 1762923382800, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}