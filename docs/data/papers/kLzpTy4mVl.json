{"id": "kLzpTy4mVl", "number": 23770, "cdate": 1758348197536, "mdate": 1759896798196, "content": {"title": "Dynamic Semantic Routing for Multimodal Sentiment Analysis", "abstract": "Multimodal sentiment analysis (MSA) aims to understand human emotions by integrating heterogeneous signals such as language, vision, and acoustic modalities. However, multimodal data often suffer from internal semantic entanglement, ambiguous cues, and inconsistent modality contributions, which limit the effectiveness of unified representations. To address these challenges, we propose a Dynamic Semantic Routing Framework (DSRF) for the MSA task. Specifically, we present a hierarchical semantic factorization module, which disentangles each modality into four functionally independent representations: primary emotion, contextual cue, ambiguity, and noise, enabling fine-grained semantic modeling. Moreover, we introduce a semantic dynamic routing interaction mechanism, which dynamically routes and aggregates the semantic factors through a capsule-inspired interaction process to reconstruct modality representations with high-order compositionality. Finally, we design an uncertainty-aware semantic fusion strategy that estimates the reliability of each semantic factor and adaptively integrates them across modalities for robust sentiment prediction under modality inconsistency. Extensive experiments on four benchmark datasets demonstrate that our framework achieves state-of-the-art performance.", "tldr": "", "keywords": ["Multimodal Sentiment Analysis", "Representation Learning", "Semantic Factorization"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1802fe6d985fb595a05828de974fe305fd5d57f3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a Dynamic Semantic Routing Framework (DSRF) for multimodal sentiment analysis. It first factorizes unimodal representations into four distinct components, then performs cross-modal interaction based on semantic routing. Finally, it explicitly estimates the uncertainty of each modality component, which guides their respective contributions during the multimodal fusion. The authors compare DSRF with recent methods and ablate the main proposed modules on several popular benchmarks. The results validate its effectiveness."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. **Reasonable Motivations and Implementations.** Factorizing unimodal representations into different functional components is intuitively beneficial for customized representation modeling and multimodal fusion. Interacting unimodal factors through the iterative agreement mechanism is also interesting, providing a fresh perspective for modeling cross-modal synergy.\n2. **Competitive Results.** DSRF outperforms recent models on four popular MSA datasets, validating its effectiveness."}, "weaknesses": {"value": "1. **Unverified Claims.** The paper claims, in line 83, that previous methods fail to accommodate missing or corrupted modalities, and in line 298, that DSRF alleviates such issues. However, there is only superficial analysis and no empirical evidence supporting this claim. Similarly, in line 107, the paper claims that previous supervisions for modality factorizing are weak or indirect, yet also adopts heuristic supervisions that are difficult to prove strong or direct.\n2. **Overcomplicated Optimization Objective.** The authors construct DSRF with three main modules, each comprising independent optimization targets. In the HSF module, the objective itself consists of four distinct terms. This naturally leads people to wonder about training stability and robustness, whose details are absent in the experiments.\n3. **Missing Comparison with Latest Models.** The paper does not compare DSRF against any 2025 methods, which limits its effectiveness.\n4. **Limited Analytical Experiments.** The only experiment besides the main comparison is a coarse-grained ablation study, which provides insufficient insights into the proposed methods. This has led to doubts regarding the effectiveness of the modules in the approach, particularly given their complexity.\n5. **Uninformative Figure.** The manuscript includes only one figure, which aims to illustrate the overall framework of the proposed method. However, this figure depicts SFR (c) and DRI (d) modules without details, which provides little help in illustrating the proposed DSRF.\n6. **Frequent Typos and Format Issues.** Some obvious mistakes are: incorrect reference format (should be \\citep instead of \\cite); misplaced caption (Table 1 and 2); misplaced \"?\" (line 50); missing \"\\\" before textit (line 186); typo: \"ous\" (line 187)."}, "questions": {"value": "1. How do you guarantee that factorization captures the intended semantics? Is there any empirical evidence to support this process?\n2. Why do you capture the noise factor, since it should not contribute to subsequent interactions? \n3. How are the weighting factors decided? What is the training dynamics of each loss component during the overall optimization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YoXdnS6BPo", "forum": "kLzpTy4mVl", "replyto": "kLzpTy4mVl", "signatures": ["ICLR.cc/2026/Conference/Submission23770/Reviewer_jG5y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23770/Reviewer_jG5y"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23770/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761292316738, "cdate": 1761292316738, "tmdate": 1762942797936, "mdate": 1762942797936, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a Dynamic Semantic Routing Framework (DSRF) for the MSA task.Framework incorporates three dedicated modules to tackle the semantic complexity, reconstruction, and inconsistency issues in multimodal emotion modeling."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Unlike existing methods that only perform modality-level factorization (e.g., separating invariant and specific features), the HSF module achieves fine-grained decomposition of modality internal semantics into four interpretable factors. \n2. The SFDR mechanism abandons static fusion operators and uses dynamic routing to model sample-specific factor interactions, which is more suitable for complex multimodal scenarios with variable factor importance. \n3. The framework integrates ideas from factorized representation learning, capsule networks, and uncertainty estimation, with detailed mathematical formulations to ensure the rigor of the method."}, "weaknesses": {"value": "1. Why disentangle each modality into four functionally independent representations—primary emotion, contextual cue, ambiguity, and noise. This seems not to be reflected in the experiments. \n2. In Figure 1,The Semantic Factor Dynamic Routing Reconstruction Mechanism is not fully reflected in the figures.\n3. Another obvious issue with this paper is the lack of sufficient explanation of the simulation results. You need to elaborate on your simulation results in detail and clarify the underlying reasons for obtaining such outcomes—for instance, by providing necessary visual analysis and performing case studies."}, "questions": {"value": "1. What is the necessity of the hierarchical nature of the hierarchical semantic factorization module proposed in the HSF? Please provide appropriate experiments to prove it.\n2. In HSF: What is the performance impact of removing a single factor (e.g., w/o ambiguity factor)? Does each factor’s constraint (e.g., orthogonality for contextual cues) actually work?\n3. The ablation study is only conducted on the MOSI dataset, and it is unclear whether the conclusions hold on other datasets . This limits the generalizability of the findings.\n4. The experiments are insufficient and lack justification for the necessity of the innovations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NrMT2RgAmG", "forum": "kLzpTy4mVl", "replyto": "kLzpTy4mVl", "signatures": ["ICLR.cc/2026/Conference/Submission23770/Reviewer_SAhi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23770/Reviewer_SAhi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23770/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808873661, "cdate": 1761808873661, "tmdate": 1762942797673, "mdate": 1762942797673, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Dynamic Semantic Routing Framework (DSRF) to address challenges in MSA, such as semantic entanglement, ambiguous cues, and modality inconsistency. The framework first decomposes each modality into four functionally independent semantic factors: primary emotion, contextual cue, ambiguity, and noise. It then employs a capsule-inspired dynamic routing mechanism to interact and reconstruct modality representations. Finally, an uncertainty-aware semantic fusion strategy adaptively integrates these factors based on their reliability. The method achieves state-of-the-art performance on multiple datasets."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.\tDisentangling modality representations into four factors sounds reasonable.\n\n2.\tAchieves good performance."}, "weaknesses": {"value": "1.\tThere are writing errors on lines 50 and 221.\n2.\tThe discussion of prior methods in Sections 2.1 and 2.2 is insufficient, and many of the most recent methods are not discussed. I provide some work [1-6] for your reference.\n3.\tIt is recommended to revise Figure 1, as parts (c) and (d) lack informativeness. I understood the specific operations of these two modules after reading the Method section.\n4.\tThe writing from lines 171-183, 248-263, and 285-299 is overly redundant. If a comparative explanation with prior methods is important, I recommend to discuss in section introduction.\n5.\tThe method disentangles each modality into four functionally independent representations sounds reasonable. However, the paper lacks sufficient evidence to demonstrate the effectiveness of the disentanglement.\n6.\tIn Equation 2, how are the labels for the context obtained?\n7.\tWhy is a contrastive loss used to guide the learning of the noise factor, while the other modules do not use it?\n8.\tCould you show some visualization experiments, such as case studies and visualizations of the distribution for each factor.\n\nOverall, I think the writing of this paper should be revised  and more experimental analyses should be added to demonstrate the effectiveness of the method. SOTA performance is not a necessary condition for publishing a paper, in-depth analysis is more important.\n\n**Reference**\n\n[1] DeepMLF: Multimodal language model with learnable tokens for deep fusion in sentiment analysis. arXiv:2504.11082.\n\n[2] Decoupled multimodal distilling for emotion recognition. CVPR 2023.\n\n[3] TCAN: Text-oriented cross attention network for multimodal sentiment analysis. Arxiv 2025.\n\n[4] Proxy-driven robust multimodal sentiment analysis with incomplete data. ACL 2025.\n\n[5] Towards robust multimodal sentiment analysis with incomplete data. NeurIPS 2024.\n\n[6] Learning language-guided adaptive hyper-modality representation for multimodal sentiment analysis. EMNLP 2023."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ed1sSbkc0R", "forum": "kLzpTy4mVl", "replyto": "kLzpTy4mVl", "signatures": ["ICLR.cc/2026/Conference/Submission23770/Reviewer_J2EV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23770/Reviewer_J2EV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23770/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931338512, "cdate": 1761931338512, "tmdate": 1762942797477, "mdate": 1762942797477, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper releases MARS-Sep, a reinforcement learning framework that reformulates separation as decision making. Instead of simply regressing ground-truth masks, MARS-Sep learns a factorized Beta mask policy that is optimized by a clipped trust-region surrogate with entropy regularization and group-relative advantage normalization. Extensive experiments on multiple benchmarks demonstrate consistent gains in Text-, Audio-, and Image-Queried separation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The algorithm proposed in the paper demonstrates innovation, clear logic, and provides a corresponding description."}, "weaknesses": {"value": "1. The paper does not provide an ablation study. It is necessary to conduct partial validation for RL and other revised modules in the proposed method.\n2. The paper introduces the mechanism of RL and mixed sound source separation based on contrastive learning separately. There should be an overall explanation of the overall loss function.\n3. The overall algorithmic structure and module information are relatively brief. It is recommended to provide detailed explanations of the network architecture and loss function settings for each module, and add subfigures for clarification when necessary."}, "questions": {"value": "1. The paper does not provide an ablation study. It is necessary to conduct partial validation for RL and other revised modules in the proposed method.\n2. The paper introduces the mechanism of RL and mixed sound source separation based on contrastive learning separately. There should be an overall explanation of the overall loss function.\n3. The overall algorithmic structure and module information are relatively brief. It is recommended to provide detailed explanations of the network architecture and loss function settings for each module, and add subfigures for clarification when necessary."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "3otaSavkoJ", "forum": "kLzpTy4mVl", "replyto": "kLzpTy4mVl", "signatures": ["ICLR.cc/2026/Conference/Submission23770/Reviewer_4rnn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23770/Reviewer_4rnn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23770/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762278308945, "cdate": 1762278308945, "tmdate": 1762942797172, "mdate": 1762942797172, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}