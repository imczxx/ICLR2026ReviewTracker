{"id": "R7M2KMeKFJ", "number": 6667, "cdate": 1757991684683, "mdate": 1759897901955, "content": {"title": "Tribe: Tri-Component Information Decomposition for Graph Out-of-Distribution Detection", "abstract": "Graph neural networks are widely used for node classification, but they remain vulnerable to out-of-distribution (OOD) shifts in node features and graph structure. Existing methods trained with standard supervised learning (SL) objectives tend to capture spurious signals from either features and/or structure, leaving the model fragile under distributional changes. To address this, we propose Tribe, a novel and effective Tri-Component Information Decomposition framework that explicitly decomposes information into feature-specific, structure-specific and joint components. Tribe aims to preserve only the label-relevant component of the joint information while filtering out spurious feature- and structure-specific information, thereby enhancing the separation between in-distribution (ID) and OOD data. Technically, we develop a novel optimisation pipeline that integrates a graph Information Bottleneck (IB) objective with carefully designed regularisations. Beyond the framework, we provide theoretical and empirical analysis showing the superiority of IB in OOD detection, with higher ID confidence and a larger entropy gap between ID and OOD data compared to the typical SL objective. Extensive experiments across seven datasets confirm the efficacy of Tribe, achieving up to 34% improvement in FPR95 over strong baselines while maintaining competitive ID accuracy. Code will be released upon acceptance.", "tldr": "", "keywords": ["graph out-of-distribution detection"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2f56962e4c039d6def0cec3ce5b2df74d0eeb229.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper approaches the problem from the perspective of the information bottleneck in information theory, aiming to train classifiers using only the information most relevant to the labels, thereby shielding the model from interference caused by redundant information and further improving its performance on the task it investigates: out-of-distribution node detection. In simple terms, the paper employs three networks: a backbone network to extract information most critical to the labels, and two branch networks designed to disentangle redundant information arising from features and structure, respectively. Overall, the paper has a natural and reasonable motivation, excellent writing, thorough experiments, and rigorous theoretical grounding, making it a high-quality contribution."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. The writing is excellent and well-structured, from which I have learned a great deal. Thank you to the authors.\n2. The motivation is natural and reasonable. Although the information bottleneck is not a novel theory, I believe its successful application to out-of-distribution detection brings significant innovation and ample room for further extension.\n3. I have reviewed the theoretical part and did not find any major issues.\n4. The experiments are comprehensive and thorough, making the results highly convincing."}, "weaknesses": {"value": "I don't have major concerns; however, although the experiments are substantial, I feel that some recent baselines are missing (even though they have been presented in the related work). If possible and feasible, including comparisons with these latest baselines, either experimentally or in the textual discussion, would further strengthen the paper."}, "questions": {"value": "See the weaknesses mentioned above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No."}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6dlbTVRKwG", "forum": "R7M2KMeKFJ", "replyto": "R7M2KMeKFJ", "signatures": ["ICLR.cc/2026/Conference/Submission6667/Reviewer_pQr9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6667/Reviewer_pQr9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6667/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761282067179, "cdate": 1761282067179, "tmdate": 1762918975664, "mdate": 1762918975664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Summary\nThis paper introduces TRIBE, a tri-component information decomposition framework for graph out-of-distribution (OOD) detection in node classification tasks. It addresses GNN vulnerabilities to feature, structure, or joint shifts by decomposing label information into feature-specific (V), structure-specific (Q), and joint (Z) components, filtering spurious individual-input correlations via an information bottleneck (IB) objective, conditional independence regularizer, and pairwise mutual information minimization. Theoretical analysis proves IB enhances ID confidence and entropy gap for better logit-based detection. Experiments on seven datasets show up to 34% FPR95 improvement over baselines like GNNSAFE, while preserving competitive ID accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear Structure: The paper follows a standard academic format (abstract, introduction, related work, preliminaries, method, theoretical insights), with smooth transitions between sections. This enhances readability and guides the reader through complex ideas, from problem motivation to theoretical proofs and implementation details.\n2. Theoretical Rigor: Provides solid proofs (e.g., on IB's superiority over SL in ID confidence and entropy separation), offering clear insights into why the framework improves detection under shifts."}, "weaknesses": {"value": "1. Unclear motivation.\n\nThe Abstract claim that “standard supervised learning (SL) objectives tend to capture spurious signals from either features and/or structure” lacks empirical evidence. Figure 1 in the Introduction suggests that SL representations mix feature-, structure-, and label-irrelevant components, but no diagnostic experiment supports this assumption. Similar claims have already been made by prior Information Bottleneck or invariant representation learning studies, so the novelty of this motivation is limited [1,2,3].\n\n2. Intrinsic conflicts in the mutual-information optimization.\n\n(a) Conflict between maximizing task relevance and minimizing redundancy:\nThe IB objectives encourage each component (Z, V, Q) to maximize its mutual information with the label Y, but the pairwise regularization (e.g., min I(Z; V)) penalizes their overlap.\nWhen features and structure are strongly correlated, these goals may compete, reducing predictive strength and optimization stability.\n\n(b) Conflict between compression and conditional independence:\nThe compression term min I(X, A; Z) aims to remove irrelevant noise, yet excessive compression may discard the necessary X–A interactions required for min I(A; X | Z)=0.\nIf X and A are intrinsically dependent, these objectives can become contradictory, leading to degenerate or unstable representations.\n\n3. Experimental limitations.\n\n(a) The paper omits comparisons with recent strong baselines such as DeGEM and GOLD, which weakens the claim of comprehensive SOTA superiority.\n\n(b) In 6.5 energy gap, while the article defines energy-based OOD detection in Section 3 and uses energy scores for inference, the visualization shows \"greater separation between ID and OOD energy scores\" without explicitly explaining how this empirical energy gap maps to or supports the theoretical \"entropy gap\" in Section 5 (Proposition 5.3). The scores are derived from logits (related to entropy), but the lack of a clear connection between mutual information-based theory and energy visualization may seem inconsistent.\n\n[1]Zhang, Ge, et al. \"Enhancing graph neural networks for out-of-distribution graph detection.\" IEEE Transactions on Neural Networks and Learning Systems (2025).\n[2] Ren, Lingfei, et al. \"Heterophilic graph invariant learning for out-of-distribution of fraud detection.\" Proceedings of the 32nd ACM International Conference on Multimedia. 2024.\n[3] Li, Zenan, et al. \"Graphde: A generative framework for debiased learning and out-of-distribution detection on graphs.\" Advances in Neural Information Processing Systems 35 (2022): 30277-30290."}, "questions": {"value": "1. Could the authors provide motivational experiments or additional evidence to justify why the tri-component decomposition is necessary, especially compared to existing IB-based or invariant learning methods that also aim to reduce spurious correlations?\n\n2. In weakness (2), how do the authors address the potential conflict during optimization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "4wIIQv0hzH", "forum": "R7M2KMeKFJ", "replyto": "R7M2KMeKFJ", "signatures": ["ICLR.cc/2026/Conference/Submission6667/Reviewer_uf9e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6667/Reviewer_uf9e"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6667/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761887759589, "cdate": 1761887759589, "tmdate": 1762918974809, "mdate": 1762918974809, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes TRIBE, a framework for graph OOD detection. The core idea is to decompose graph information into three parts — invariant, variant, and redundant components — with the goal of enhancing OOD detection by separating task-relevant and task-irrelevant information. The method leverages mutual information estimation to model the interaction among these components and integrates them into a graph representation learning framework. Experiments are conducted on several graph benchmarks to demonstrate the proposed method’s effectiveness compared with existing OOD detection baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of decomposing graph information into three components provides a new perspective for understanding and modeling graph representations.\n\n2. The proposed framework attempts to connect information-theoretic principles with graph learning, which is conceptually interesting.\n\n3. The paper includes some experimental evaluation across multiple datasets to demonstrate the general applicability of the method."}, "weaknesses": {"value": "1. The core formulation of the tri-component decomposition is not clearly explained. It is unclear how the three components are defined, separated, or optimized in practice.\n\n2. The technical novelty appears limited. The proposed framework largely combines existing concepts such as information decomposition and graph representation learning without a clear new algorithmic contribution.\n\n3. The experiments do not provide convincing empirical support for the claimed benefits. Improvements are small or inconsistent, and there is no analysis showing that the decomposition itself enhances OOD detection.\n\n4. The comparisons are incomplete. Recent and strong graph OOD detection methods  are missing, making it difficult to assess the true effectiveness of the proposed approach."}, "questions": {"value": "Please refer to the comments listed in the Weaknesses section, which highlight points that would benefit from clarification or further empirical support."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "VKJizNnWPj", "forum": "R7M2KMeKFJ", "replyto": "R7M2KMeKFJ", "signatures": ["ICLR.cc/2026/Conference/Submission6667/Reviewer_HnFV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6667/Reviewer_HnFV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6667/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998374752, "cdate": 1761998374752, "tmdate": 1762918974262, "mdate": 1762918974262, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents TRIBE, a novel framework for graph out-of-distribution (OOD) detection based on tri-component information decomposition. The authors identify that conventional supervised learning objectives in graph neural networks (GNNs) often entangle spurious correlations from node features and graph structure, resulting in poor generalization to OOD scenarios. To tackle this, TRIBE decomposes the mutual information between input (features & structure) and labels into three components: feature-specific, structure-specific, and joint-input signals. The framework incorporates an Information Bottleneck (IB) objective alongside pairwise mutual information regularization and conditional independence constraints, aiming to suppress spurious components while preserving only label-relevant joint information. Empirical evaluations across seven benchmark datasets show that TRIBE significantly improves OOD detection performance (up to 34% reduction in FPR95) while maintaining competitive in-distribution (ID) classification accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces a principled and technically sound decomposition of predictive information into three components (feature, structure, joint). This is a non-trivial extension of IB to the graph domain, which is a valuable contribution.\n2. Clear theoretical results are provided to justify why the IB objective is more suitable for OOD detection than standard supervised learning.\n3. Experiments on diverse benchmarks demonstrate consistent performance gains over both non-OOD and OOD-exposed baselines.\n4. The ablation study is thorough, showing the importance of each component to the overall performance."}, "weaknesses": {"value": "1. While the method is conceptually interesting, the paper lacks a clear visual or algorithmic description of how all the modules (Z, V, Q networks) interact during training and inference. Figure 2 helps, but further schematic detail is needed to fully grasp the flow of gradients, loss contributions, and updates.\n2. The paper relies heavily on mutual information estimators (e.g., CLUB), but does not provide sufficient detail or sensitivity analysis on the impact of approximation errors in these estimators.\n3. The objective combines several components (IB terms, CI loss, PMI regularizers) with scalar weights (e.g., λ, α₁–α₃), but their selection strategy is not transparent. \n4. While the paper compares against strong OOD baselines, it does not evaluate against decomposition-based or disentangled representation methods, which could be relevant comparators in the context of learning disentangled graph representations."}, "questions": {"value": "1. Why is the feature network implemented as an MLP and the structure network as a GCN?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lkIDRsAlOT", "forum": "R7M2KMeKFJ", "replyto": "R7M2KMeKFJ", "signatures": ["ICLR.cc/2026/Conference/Submission6667/Reviewer_bK5E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6667/Reviewer_bK5E"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6667/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762053714965, "cdate": 1762053714965, "tmdate": 1762918973862, "mdate": 1762918973862, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}