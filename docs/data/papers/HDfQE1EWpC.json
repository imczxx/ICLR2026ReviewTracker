{"id": "HDfQE1EWpC", "number": 15050, "cdate": 1758247202757, "mdate": 1759897333305, "content": {"title": "DyBBT: Dynamic Balance via Bandit-inspired Targeting for Dialogue Policy with Cognitive Dual-Systems", "abstract": "Task oriented dialog systems often rely on static exploration strategies that do not adapt to dynamic dialog contexts, leading to inefficient exploration and suboptimal performance. We propose DyBBT, a novel dialog policy learning framework that formalizes the exploration challenge through a structured cognitive state space $\\mathcal{C}$ that captures dialog progression, user uncertainty, and slot dependency. DyBBT proposes a bandit inspired meta-controller that dynamically switches between a fast intuitive inference (System 1) and a slow deliberative reasoner (System 2) based on real-time cognitive states and visitation counts. Extensive experiments on single- and multi-domain benchmarks show that DyBBT achieves state-of-the-art performance in success rate, efficiency, and generalization, with human evaluations confirming that its decisions are well aligned with expert judgment. The code is available at \\href{https://anonymous.4open.science/r/DyBBT-C6B7}{https://anonymous.4open.science/r/DyBBT-C6B7}.", "tldr": "DyBBT is a dialog policy framework that leverages a cognitive dual-system architecture and a bandit-inspired meta-controller to dynamically balance exploration and exploitation, achieving SOTA performance across multiple benchmarks.", "keywords": ["dialog policy", "dual-systems", "task-oriented dialog", "exploration strategy"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7be5ed731f690fd7cba72c0f5bdfaa2d81e3790e.pdf", "supplementary_material": "/attachment/24e095c6e94a7d1e96bb524acb790dd0e13a279e.zip"}, "replies": [{"content": {"summary": {"value": "This paper focuses on proposing a more powerful dialogue policy algorithm for current task-oriented dialogue systems. Specifically, this study concentrates on how to seamlessly switch between system I (intuitive inference) and system II (reasoning-based inference) to trade off the exploration ability and the exploitation of unknown decisions. More specifically, they design a meta controller to switch the decision to system II when it cannot fulfill the requirements."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "+ The proposed method provides a comprehensive decision for current task-oriented dialogue systems. The idea that employs two thinking patterns for the same problem is really interesting.\n\n+ They provide the intuition of how their meta-controller is derived from existing works, which is convincing.\n\n+ They have provided some experiments on task-oriented dialogue policy, which indicates the effectiveness of their policy."}, "weaknesses": {"value": "+ The organization and writing of this paper are significantly insufficient, especially in Section 3. For instance, I cannot understand and the paper does not mention how Assumption 1 in Section 3.1.2 is used in their method and also how Section 3.1.3 guides the design of their methodology. For the latter one, I suppose it is used to design the meta controller, but how and why? There is no mention or even citation of Section 3.1.2 and 3.1.3 in the subsequent method descriptions. Besides, some significant mathematical notations are not explained. For instance, what is the meaning of $T$?\n\n+ It is not reasonable for the implementation of System II shown in Section 3.2.2. In this part, complex and in-depth reasoning (what is system II) is simply implemented by an instruction-driven prompt-based inference. I think this is over-simplified. I hope authors can explain this point, and compare it with some commonly used reasoning methods, such as RL-based reasoning fine-tuning.\n\n+ In Table 1, it is unnecessary to provide the training checkpoint which is not converged. On the contrary, I'd like to see some more interesting experiments about the core idea of this algorithm. For instance, how frequently does the algorithm switch to system II? Can you provide any ablation study to exhibit the effectiveness of your system II? How are the thresholds selected in your meta-controller?"}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tpgdubOvEJ", "forum": "HDfQE1EWpC", "replyto": "HDfQE1EWpC", "signatures": ["ICLR.cc/2026/Conference/Submission15050/Reviewer_PbHc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15050/Reviewer_PbHc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15050/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803615847, "cdate": 1761803615847, "tmdate": 1762925372066, "mdate": 1762925372066, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DyBBT, a dialogue strategy learning framework inspired by dual-system cognitive theory. The model dynamically balances fast, intuitive decision-making (System 1) and slow, deliberative reasoning (System 2). A meta-controller decides when to trigger System 2 based on dialogue uncertainty and state visitation. Experiments on task-oriented dialogue benchmarks show that DyBBT improves success rate and efficiency compared with existing reinforcement learning and LLM-based baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. DyBBT adaptively switches between fast and deep reasoning, achieving a good balance between efficiency and performance.\n2. The experiments are thorough and well-designed, and the results support the paper’s main claims regarding improved performance and adaptive reasoning efficiency."}, "weaknesses": {"value": "1. The discussion in the main text draws several key conclusions based on the ablation study results presented in Table 5, yet the table itself appears only in the appendix. Since these results play a central role in supporting the paper’s main claims, it would improve readability to include Table 5 in the main body of the paper. \n2. The paper refers to DyBBT’s meta-controller as achieving a “Dynamic Exploration–Exploitation Balance.” However, this terminology may be somewhat misleading. In reinforcement learning, this balance concerns the trade-off within the action space between exploring new behaviors and exploiting known rewards. In DyBBT, however, the meta-controller switches between System 1 and System 2 based on uncertainty and visitation counts—a mechanism governing computational effort, not exploration behavior. And the paper presents no evidence that System 2 invocation increases exploratory action or exploit action. \n3. The paper introduces the variables a (action) and p (System 1 confidence), but they are not clearly defined. The only hint about the action appears in the appendix prompt example, yet it is not formally described in the main text. The computation of p is also unspecified, even though it directly determines when the controller switches to System 2."}, "questions": {"value": "1. The authors acknowledge that the framework is \"over reliant on cognitive state fidelity\" and that the handcrafted $c_{t}$ can misrepresent complex dialog dynamics, such as abrupt intent shifts, leading to suboptimal decisions. Can the authors provide more detail on the process of designing the three components $(d_{t},u_{t}, \\rho_{t})$ and if other features were considered and rejected? A clearer understanding of the feature engineering process would help assess how generalizable these specific features are, beyond the MultiWOZ and MS Dialog datasets.\n\n2. The ablation study revealed that removing the Confidence Condition (CC) causes a more substantial performance drop than removing the Exploration Condition (EC). Can the authors provide more qualitative or quantitative details on the nature of the errors prevented by the CC? For instance, are CC triggers predominantly associated with multi-domain state conflicts or complex inference steps that System 1 frequently misjudges?\n\n3. The highest performing model, DyBBT-8B/GPT-4.0, uses GPT-4.0 as System 2 and achieves SOTA results (85.3% Success on MultiWOZ) Can the authors quantify the absolute computational cost (e.g., in GPU hours or normalized inference time) of running the DyBBT-8B/GPT-4.0 system compared to the purely open-weight DyBBT-8B system (84.1% Success)? This clarification is vital for practitioners to weigh the marginal performance gain against the substantially higher cost and external API dependence of using a model like GPT-4.0 for deliberation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CbPA8esKyY", "forum": "HDfQE1EWpC", "replyto": "HDfQE1EWpC", "signatures": ["ICLR.cc/2026/Conference/Submission15050/Reviewer_G96K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15050/Reviewer_G96K"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15050/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923455805, "cdate": 1761923455805, "tmdate": 1762925371635, "mdate": 1762925371635, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DyBBT (Dynamic Balance via Bandit-inspired Targeting),  a novel dialog policy learning framework that addresses the exploration-exploitation dilemma in task-oriented dialog systems through a cognitive dual-system architecture. The framework introduces a structured cognitive state space capturing dialog progress, user uncertainty, and slot dependency, and uses a bandit-inspired meta-controller to dynamically switch between a fast System 1 (intuitive inference) and a slow System 2 (deliberative reasoning). The approach achieves state-of-the-art performance on single-domain (MS Dialog) and multi-domain (MultiWOZ 2.1) benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The formalization of dialog exploration through a cognitive state space C = [dt, ut, ρt] is theoretically motivated and provides an interpretable bridge between bandit theory and dialog policy learning. The dual-trigger mechanism (exploration condition + confidence condition) elegantly addresses both epistemic and aleatoric uncertainty, with clear theoretical motivation from UCB-style algorithms.\n\n2. The paper conducts extensive experiments across multiple benchmarks, baselines, model scales, and includes human evaluation demonstrating alignment with expert judgment (88.7% switching agreement), achieves SOTA performance with efficient resource allocation - DyBBT-8B reaches 89.52% success on Movie domain and 84.1% on MultiWOZ while maintaining computational efficiency."}, "weaknesses": {"value": "1. The cognitive state representation is manually designed and may fail to capture critical dialog nuances (in Case 3 failure analysis). The learned alternative (w/ Learned CS) performs slightly worse, questioning whether the specific design is optimal, and another issue is for potential scaling.\n\n2. Generalization conern: all experiments in the paper use simulated users (Rule Policy). Real user behavior may not conform to the structured cognitive state assumptions, potentially limiting practical applicability."}, "questions": {"value": "1. How sensitive is performance to the specific choice of cognitive state, since it is manually designed? Could this dual-system approach with cognitive state representation generalize to other sequential decision-making domains (e.g., robotic manipulation, game playing)?\n\n2. Have you conducted or planned any experiments interacting with real users? How do you expect the approach to perform when user behavior deviates from the simulated patterns?\n\n3. What proportion of dialogs exhibit the failure modes described in Section 5.5? How critical are these limitations for practical deployment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "U9rcj9mayI", "forum": "HDfQE1EWpC", "replyto": "HDfQE1EWpC", "signatures": ["ICLR.cc/2026/Conference/Submission15050/Reviewer_eteB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15050/Reviewer_eteB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15050/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954913725, "cdate": 1761954913725, "tmdate": 1762925370836, "mdate": 1762925370836, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper primarily tackles the exploration challenge in task-oriented dialog systems. A novel dialog policy learning framework, DyBBT, is proposed. DyBBT dynamically switches between a fast intuitive inference and a slow deliberative reasoner. The superior performance of the proposed method is demonstrated through experiments."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The problem is well-motivated. Exploration in dialog systems is crucial for practical applications.\n- The experiments are comprehensive, and the proposed method demonstrates better performance than prior work."}, "weaknesses": {"value": "I am not an expert in task-oriented dialog systems, so I am not sure how S2 encourages exploration. In my understanding, the major feature of S2 is that it has broader knowledge and reasoning capabilities than S1. However, it is unclear whether this feature leads to exploration. Could you clarify what “S2 activation” means in statistical terms?\n\nMoreover, I wonder how current powerful chatbots (e.g., ChatGPT or Gemini) perform on the benchmark. Do the LLM_DP results correspond to those systems?"}, "questions": {"value": "My main concerns and questions are outlined in the Weaknesses section. Additionally, I have the following question:\n\n- In Eq. (1), $T$ is not defined. Moreover, $n_t(c_t)$ is defined in the latter section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "7KJrkfPeJL", "forum": "HDfQE1EWpC", "replyto": "HDfQE1EWpC", "signatures": ["ICLR.cc/2026/Conference/Submission15050/Reviewer_D14e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15050/Reviewer_D14e"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15050/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762158150097, "cdate": 1762158150097, "tmdate": 1762925370313, "mdate": 1762925370313, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}