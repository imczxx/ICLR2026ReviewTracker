{"id": "bsokKPMJ5v", "number": 15160, "cdate": 1758248452081, "mdate": 1763401695979, "content": {"title": "STAR : Semantic-ID Token-Embedding Alignment For Generative Recommenders", "abstract": "Generative recommenders (GRs)—which directly generate the next-item semantic ID with an autoregressive model—are rapidly gaining adoption in research and large-scale production as a scalable, efficient alternative to traditional recommendation algorithms.  Yet we find a fundamental failure mode when adapting Language Models (LMs) to GRs. We identify, for the first time, a pervasive token–embedding misalignment issue: the common mean-of-vocabulary initialization places new Semantic-ID tokens on the LM manifold but collapses their distinctions, stripping item-level semantics and degrading data efficiency and retrieval quality.  We introduce **STAR**, a lightweight alignment stage that freezes the LM and updates *only* Semantic-ID embeddings via paired supervision from item titles/descriptions ↔ Semantic-ID, thereby injecting the new tokens with linguistically grounded, item-level semantics while preserving the pretrained model’s capabilities and the primary recommendation objective.  Across multiple datasets and strong baselines, **STAR** consistently improves top-*k* retrieval/search performance over mean-of-vocabulary initialization and status-quo auxiliary-task adaptation.  Ablations and analyses corroborate our claims, showing increased token-level diversity, stronger linguistic grounding, and improved sample efficiency.  **STAR** is parameter-efficient, updating only the Semantic-ID token embeddings ($|\\mathcal{V}_{\\mathrm{SemID}}|\\times D$ parameters), and integrates seamlessly with standard GR pipelines.", "tldr": "", "keywords": ["Generative Recommendation System; LLM Post-training; Semantic ID; Token Embedding"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4f28602f6cf65afa0fa7c8c6e04adf235508745e.pdf", "supplementary_material": "/attachment/80d15b7c38e174a942342aeeacd3c82d9766672e.pdf"}, "replies": [{"content": {"summary": {"value": "Aiming at the token–embedding misalignment issue of semantic indices, this work proposes STAR, a lightweight alignment stage, to provide a proper initialization for the newly introduced semantic tokens. During the proposed alignment stage, only the embedding matrix corresponding to semantic tokens is optimizable, while the other components of the backbone language model are frozen. Extensive comparison with several traditional recommenders and generative recommender on both Amazon and Yelp datasets demonstrate the effectiveness of STAR."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method is well-introduced and easy to follow.\n2. The proposed method can improve the sequential recommendation performance, compared to the leading baselines."}, "weaknesses": {"value": "1. My main concern lies in the novelty of STAR, since there is no fundamental difference between STAR and LC-Rec (which is an evaluated baseline in this work). The claimed contributions, such as freezing the backbone LM, lie more in the perspective of engineering, rather than technological innovation.\n2. The effectiveness of STAR is not sufficiently convincing. As introduced in this work, previous practices of semantic token initialization, including random embedding or mean embedding over vocabulary, are not appropriate for generative recommenders. Hence, from my perspective, STAR can be regarded as a better method to initialize embeddings of semantic tokens, which is able to combine with several different generative recommender models. By comparing the original baselines adopting random or mean initialization with the variant that adopts STAR initialization, the evaluation is more convincing when demonstrate the effectiveness.\n3. The analyses of running time and memory are missing, which is important to support the 'lightweight' characteristics of STAR.\n4. In the experiment, if LC-Rec and STAR are implemented with the same LM backbone? Moreover, an investigation on the influence of different LM backbones is recommended.\n5. Organization of this manuscript is a little chaotic, of which Figure 1 and Figure 2 lack corresponding illustration in the main text."}, "questions": {"value": "Please refer to the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "63A7NznI1T", "forum": "bsokKPMJ5v", "replyto": "bsokKPMJ5v", "signatures": ["ICLR.cc/2026/Conference/Submission15160/Reviewer_MFqC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15160/Reviewer_MFqC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15160/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761482786856, "cdate": 1761482786856, "tmdate": 1762925473160, "mdate": 1762925473160, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We sincerely thank all reviewers for their thoughtful feedback and constructive comments. We greatly appreciate the time and effort you devoted to carefully evaluating our work. Your insights have been invaluable in helping us improve the quality and clarity of our paper.\nWe would like to emphasize the core innovations of our work, which were also recognized as key strengths by all reviewers.\n- **Well-Motivated Problem Definition (45ci, zpXt)**: The paper identifies and articulates the token-embedding misalignment issue in LLM-based generative recommenders and discusses it with clarity and strong motivation.\n- **Simple and Effective Method (zpXt, 45ci, MFqC)**: The proposed STAR alignment method is simple, lightweight, and parameter-efficient, updating only a small portion of the model while delivering strong performance improvements.\n- **Foundational Insight into Embedding Misalignment (h4rs, zpXt, MFqC)**: The work raises and analyzes a core question regarding the token-embedding-space misalignment problem, highlighting a meaningful limitation of existing initialization approaches.\n- **Comprehensive Experimental Validation (h4rs, 45ci, zpXt, MFqC)**: Experiments are extensive and well-designed, covering multiple datasets and both retrieval and search tasks, consistently demonstrating the effectiveness of the proposed method.\n- **Empirical Performance Gains (45ci, MFqC)**: The proposed method shows clear improvements in top-K retrieval and search performance over strong baselines.\n- **Clear and Well-Written Presentation (h4rs, 45ci, MFqC)**: The paper is well-written, well-organized, and easy to follow, presenting the motivation, method, and results clearly."}}, "id": "SwkTRw7mOn", "forum": "bsokKPMJ5v", "replyto": "bsokKPMJ5v", "signatures": ["ICLR.cc/2026/Conference/Submission15160/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15160/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15160/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763401752889, "cdate": 1763401752889, "tmdate": 1763401752889, "mdate": 1763401752889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the token-embedding misalignment problem in generative recommender systems that adapt pre-trained language models for sequential recommendation. The authors identify that when Semantic-ID tokens (discrete identifiers produced by RQ-VAE) are integrated into a pre-trained language model's vocabulary, the common mean-of-vocabulary initialization collapses all new tokens into an undifferentiated region in the embedding space, stripping item-level semantics. To remedy this, the authors propose STAR, a lightweight alignment stage that freezes the language model backbone and updates only the Semantic-ID token embeddings through paired supervision (item descriptions → Semantic-ID sequences). Experiments on multiple datasets show consistent improvements in top-K retrieval metrics over strong baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. Well-Motivated Problem with Clear Presentation\nThe paper identifies a practical issue in adapting language models for generative recommendation and presents it clearly with effective visualizations, making the problem accessible and the solution intuitive.\n\nS2. Simple and Parameter-Efficient Method\nSTAR updates only $|V_{\\text{SemID}}| \\times D$ parameters ($\\sim$0.8M, representing $\\sim$0.13\\% of full model), making it computationally efficient and easy to integrate into existing generative recommendation pipelines without architectural modifications.\n\nS3. Comprehensive Experimental Validation\nExperiments cover 9 datasets across multiple domains (Amazon, Yelp), both retrieval and search tasks, with consistent improvements over strong baselines (13-63\\% gains). Ablation studies on data scaling and alternative designs strengthen the empirical contribution."}, "weaknesses": {"value": "W1. Weak Theoretical Foundation and Potentially Misdiagnosed Problem.\nThe paper lacks theoretical justification for why \"token-embedding misalignment\" is the fundamental problem, rather than simply insufficient content information integration.\n\nW2. Unfair Baseline Comparison and Missing Critical Ablations\nSTAR and LC-Rec are fundamentally similar—both use item descriptions to train Semantic-ID embeddings, differing mainly in training schedule (pre-train vs. joint) and parameter updates (frozen vs. full). The paper criticizes LC-Rec for \"memorizing all items\" but STAR does the same in its alignment stage.\n\nW3. Unaddressed Scalability and Practical Deployment Issues\nThe paper introduces an extra training stage but reports no wall-clock time, convergence analysis, or FLOPs comparison. Critical practical concerns are ignored: (1) What if alignment and downstream stages use different LMs (e.g., Llama vs. Qwen)? (2) How to handle new items in dynamic catalogs without full retraining? (3) Cross-model generalization (e.g., align with 0.6B, deploy with 7B)? Experiments only use small models (0.6B) and datasets (max 5K samples), limiting generalizability to industrial-scale systems with millions of items and interactions."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "p8WIVyxb2t", "forum": "bsokKPMJ5v", "replyto": "bsokKPMJ5v", "signatures": ["ICLR.cc/2026/Conference/Submission15160/Reviewer_45ci"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15160/Reviewer_45ci"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15160/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842068962, "cdate": 1761842068962, "tmdate": 1762925472746, "mdate": 1762925472746, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the initialization of semantic ID embeddings in LLM-based generative recommendation. The authors identify a key issue in existing approaches: embedding collapse in newly added semantic tokens, which prevents the recommender from fully utilizing the semantic priors of LLMs and reduces item-level distinctions. To address this, they propose a lightweight alignment method that learns token embeddings grounded in the existing vocabulary. Experiments on five real-world datasets show that the proposed method produces more informative and linguistically meaningful embeddings, improving both search and recommendation performance."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper focuses on semantic ID embedding learning, a fundamental problem in generative recommendation. The motivation is clear and relevant.\n\n2. The authors identify a concrete limitation of existing initialization methods, where semantic token embeddings collapse and lead to suboptimal results.\n\n3. The proposed lightweight alignment method is well designed and validated through experiments on five real-world datasets."}, "weaknesses": {"value": "1. The comparison between standard sequential methods and language adaptation methods is not fully convincing. Although sequential models require more data and lack explicit semantics, they typically use smaller transformers (such as TIGER) and train much faster. Stronger theoretical or empirical evidence is needed to support the claimed advantages.\n\n2. The preliminaries and diagnostic analyses overlook random embedding initialization, which could also mitigate embedding collapse.\n\n3. The paper lacks sufficient discussion or empirical comparison with textual ID–based generative recommendation methods, such as IDGenRec [1].\n\n4. The claims about generalization ability and sample efficiency are not well supported by the experiments. In addition, Figure 4 only shows distinctions among newly introduced token embeddings, which makes it difficult to verify that the aligned embeddings are linguistically grounded as claimed.\n\n[1] Tan et al., Idgenrec: Llm-recsys alignment with textual id learning. SIGIR'24"}, "questions": {"value": "1. Do all LLM-based generative recommenders in the experiments share the same backbone (e.g., Qwen3-0.6B)? Consistent backbones are necessary for a fair comparison between random or mean initialization and the proposed STAR.\n\n2. Is there any comparison of data efficiency between STAR and standard sequential models to substantiate the claimed improvement?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "042pBmFZXo", "forum": "bsokKPMJ5v", "replyto": "bsokKPMJ5v", "signatures": ["ICLR.cc/2026/Conference/Submission15160/Reviewer_zpXt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15160/Reviewer_zpXt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15160/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966286092, "cdate": 1761966286092, "tmdate": 1762925472238, "mdate": 1762925472238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a simple yet effective approach for aligning semantic-ID token embeddings with the token space of large language models. By using the learned token embeddings to initialize semantic tokens, these tokens can be readily adopted for downstream tasks. Through comprehensive evaluation, the authors demonstrate the effectiveness of their method."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-written and well-organized.\n- It poses and discusses a foundational question regarding the misalignment issue in token embedding spaces.\n- The experiments are well-designed."}, "weaknesses": {"value": "- This alignment/initialization may not be necessary for typical industrial generative recommenders, such as TIGER and OneRec, where both parameters and token embeddings are trained from scratch and no language tokens are included in the vocabulary.\n- There are some typos. For example, in Line 289, \"... we randomly pick five categories ...\", but only four are listed. Additionally, in Table 1 (Line 334), \"P5-SimID\" should be \"P5-SemID\".\n- The proposed alignment method appears to be similar to the mutual prediction alignment introduced in LC-Rec. The only apparent difference seems to be whether the model parameters are fixed or not.\n- Although the proposed alignment strategy could be model-agnostic, the experiments are conducted solely on a single language model, Qwen3-0.6B. This limits the generalizability of the method."}, "questions": {"value": "- There is a contradictory observation between this paper and the baseline LC-Rec. On one hand, this paper argues that \"the primary performance gains of semantic alignment stem from injecting linguistic semantics into the new tokens rather than from broad backbone model adaptation.\" On the other hand, LC-Rec (Table IV) shows in its ablation study that all alignment tasks contribute to performance improvement. Why do alignment tasks aimed at broad backbone model adaptation provide no contribution or even a negative impact on model performance in your experiments?\n- Why is LC-Rec inferior to P5-SemID and P5-CID in most cases in Table 1? Considering that LC-Rec uses SemanticID and applies alignment, does this observation suggest that the semantic alignment is less effective?\n- What is the maximum item sequence length used for the sequential recommendation comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1jqMgPlKbp", "forum": "bsokKPMJ5v", "replyto": "bsokKPMJ5v", "signatures": ["ICLR.cc/2026/Conference/Submission15160/Reviewer_h4rs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15160/Reviewer_h4rs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15160/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762233870798, "cdate": 1762233870798, "tmdate": 1762925471858, "mdate": 1762925471858, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}