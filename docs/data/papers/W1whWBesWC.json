{"id": "W1whWBesWC", "number": 8321, "cdate": 1758078532555, "mdate": 1763169532816, "content": {"title": "Mixture of Experts Characteristic Function Embeddings for Heterogeneous Fraud Graphs", "abstract": "Fraud detection over heterogeneous graphs requires reasoning over multiplex relations, attribute polymorphism, and structural heterophily, yet prevailing detectors entangle these orthogonal biases into monolithic pipelines assumed to generalize across domains. We address this limitation by instantiating a decouple–then–fuse representation learning that isolates structural and attribute channels before reintroducing interaction through an adaptive fusion interface. On the structural side, we encode distributional neighborhood context via characteristic-function signatures compressed through randomized spectral factorization; on the attribute side, we deploy input-adaptive Mixture-of-Experts projections that specialize each instance to role-conditioned patterns. The two views are subsequently reconciled through a Bayesian mean–difference fusion layer that models per-node consensus and discrepancy, enabling calibrated integration under heterophily and cross-modal conflict. Empirical evaluation across benchmark fraud graphs from telecom records, e-commerce reviews, and cryptocurrency transactions domains shows improved fraud node detection performance, attributable to the model’s ability to disentangle structural and attribute features and reconcile their discrepancies.", "tldr": "Decouple-then-fuse node representation learning for fraud detection", "keywords": ["Mixture-of-Experts", "Characteristic Functions", "Graph Representation Learning", "Fraud Detection", "Heterogeneous Graphs"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/146fe1721bed6d4146252331889c0a82d3d59522.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This manuscript proposes a unified framework called MoECF–AF (Mixture-of-Experts Characteristic Function Adaptive Fusion) for fraud detection on heterogeneous graphs. The study targets the core challenge of entangled inductive bias between structural and attribute information, an issue that undermines model generalization under structural heterophily. To address this, the authors introduce a “decouple-then-fuse” representation paradigm that separately encodes structure and attributes before adaptively combining them."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The strategy of decoupling and subsequently re-coupling the learning of attributes and structures is conceptually sound and theoretically capable of addressing the entangled inductive bias problem in heterogeneous graphs.\n\n- The model achieves impressive experimental performance compared to the baselines.\n\n- The experimental evaluation is thorough, including parameter sensitivity analyses and multiple ablation studies.\n\n- The introduction of MoE top-k routing and randomized SVD enhances the model’s scalability and strengthens its practical applicability."}, "weaknesses": {"value": "- The motivation for decoupling and re-coupling is not entirely clear. If existing methods perform well in both aspects, why is such a decouple-then-fuse process necessary?\n\n- The notion of inductive bias entanglement remains largely conceptual and is not empirically demonstrated. The manuscript merely infers its resolution from the superior performance of MoECF-AF across datasets.\n\n- Although the paper proposes a task-specific and meaningful fusion process, the decoupling process itself appears vague, as the model simply processes attributes and graph structures separately. Hence, the phrase “decouple-then-fuse” may be somewhat overstated.\n\n- The manuscript claims superiority in cross-domain generalization, yet the experiments seem to train and test separately on each dataset, rather than using a single model across domains. This makes the “cross-domain” claim less convincing and similar to many existing fraud detection studies that simply perform well on multiple datasets.\n\n- The Introduction section fails to clearly convey the study’s motivation and even omits the model’s name, which weakens the presentation.\n\n- The baseline literature is relatively outdated and omits recent state-of-the-art fraud detection models, which may lead to overestimating the contribution of this work.\n\n- It is recommended to add a model architecture figure to illustrate the overall design more clearly.\n\n- The content organization could be improved; some important experiments should be moved from the appendix to the main text for better visibility and narrative coherence.\n\n- The use of dashes in the manuscript appears inconsistent, please standardize their formatting."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bKYnAW7KH5", "forum": "W1whWBesWC", "replyto": "W1whWBesWC", "signatures": ["ICLR.cc/2026/Conference/Submission8321/Reviewer_CKZw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8321/Reviewer_CKZw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8321/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761662217348, "cdate": 1761662217348, "tmdate": 1762920247396, "mdate": 1762920247396, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "cQxXpihQiH", "forum": "W1whWBesWC", "replyto": "W1whWBesWC", "signatures": ["ICLR.cc/2026/Conference/Submission8321/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8321/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763169531976, "cdate": 1763169531976, "tmdate": 1763169531976, "mdate": 1763169531976, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a decouple-then-fuse representation learning framework for fraud detection on heterogeneous graphs, addressing challenges posed by relational multiplexity, attribute polymorphism, and structural heterophily. The method explicitly separates structural and attribute processing: the structural channel encodes distributional neighborhood context through characteristic-function signatures compressed via randomized spectral factorization, while the attribute channel employs MOE projections that provide input-adaptive specialization to role-conditioned patterns. Evaluating on four real-world fraud graphs demonstrates consistent improvements over baselines."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The benchmarks (Telecom, e-commerce, and cryptocurrency) provide meaningful diversity.\n2. The \"decouple-then-fuse\" paradigm is intuitive."}, "weaknesses": {"value": "1. In Eq. (4), the motivation and justification for the Fourier-like feature transformation are unclear. The connection to actual characteristic functions or Fourier analysis is never rigorously established, and no intuition is provided for why such a transformation would specifically benefit fraud detection. Most importantly, the paper lacks an ablation comparing this transformation to a simpler baseline that diffuses raw attributes directly before the SVD compression.\n2. How $\\theta_{\\max}$ and $L$ are chosen is unclear. \n3. Since cosine and sine are applied directly to raw $X$, the features are sensitive to attribute scale and units; no standardization/whitening is specified before Eq. (4), so the effective frequencies are arbitrary.\n4. The paper's training protocol is fundamentally flawed. The MoE encoder is trained with a task head and then frozen; only afterwards is fusion applied. This decoupled design can be sub-optimal because the attribute encoder never sees gradients from the fusion/mixer, limiting synergy between views.\n5. The top-k expert selection (Eq.(2)-(3)) introduces non-differentiability through hard routing (arg top-k), which zeros gradients to non-selected experts and risks expert collapse. The router computes softmax weights but then hard-selects k experts without the load-balancing or entropy regularization terms standard in MoE designs. This can lead to severe expert under-utilization.\n6. The experimental setup is outdated and incomplete. The authors only compare against classical matrix-factorization baselines, which are no longer representative of current graph learning methods. Numerous heterophily-aware GNNs, such as H2GCN, GPR-GNN, and FAGCN, have been specifically proposed to address structural heterophily and should be included for a fair evaluation. Moreover, it is a serious omission that GNN-based fraud detection approaches like CARE-GNN, PC-GNN, and BWGNN are entirely excluded. \n7. The paper does not follow the correct citation style required by the target venue. It consistently uses `\\cite{}` instead of the recommended `\\citep{}` command for parenthetical references. Besides, equations needs to be indexed.\n8. The paper does not provide any source code or implementation details for the proposed model, which severely limits reproducibility. For top-tier conferences such as ICLR, public release of code is strongly encouraged to ensure transparency."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Ziw9uhhZAr", "forum": "W1whWBesWC", "replyto": "W1whWBesWC", "signatures": ["ICLR.cc/2026/Conference/Submission8321/Reviewer_iMsJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8321/Reviewer_iMsJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8321/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761741420097, "cdate": 1761741420097, "tmdate": 1762920247065, "mdate": 1762920247065, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel decouple-then-fuse representation learning framework for fraud detection on heterophily graphs, addressing challenges like relational multiplexity, attribute polymorphism, and structural heterophily. It separates structural and attribute processing: structural embeddings use characteristic function signatures compressed via randomized spectral factorization, while attributes are handled by input-adaptive Mixture-of-Experts (MoE) projections. This paper uniquely combines MoE with characteristic functions and adaptive fusion, enhancing cross-domain generalization amid heterophily. The model outperforms baselines in fraud node detection."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "S1. The manuscript employs clear, structured academic prose with logical flow from problem motivation to method details and experiments. Sections are well-organized, with precise definitions and motivations.\n\nS2. The fusion mechanism innovatively integrates Bayesian principles with variational mixing, providing theoretical justification via ELBO-inspired objectives."}, "weaknesses": {"value": "W1: While core components are described, code availability is not mentioned, and specifics on training environments (e.g., hardware, random seeds) are absent.\n\nW2: Some sections, such as the related work, list references densely without deep critical analysis of recent 2025 advances, leading to superficial integration.\n\nW3: The adaptive λ discretization is noted but lacks justification for grid size or sensitivity analysis.\n\nW4: The experimental evaluation employs outdated baselines (with the most recent published in 2020), failing to adequately represent recent advancements (e.g., [1-4]) in heterophily-tolerant GNNs for fraud detection. This constrains the evaluation of the proposed model’s innovation.\n\nW5: The paper conflates \"heterogeneous\" with \"heterophily\" by including structural heterophily as an aspect of graph heterogeneity, which may confuse readers familiar with definitions where heterogeneous graphs refer to multi-type nodes/edges, and heterophily denotes label/feature dissimilarity in connected nodes. By subsuming heterophily under heterogeneity, the model’s robustness claims may overlook distinct challenges, such as heterophily in homogeneous subgraphs within heterogeneous graphs. This could limit theoretical depth compared to works like Hetero2Net [5], which separately address both.\n\nRefs.:\n\n[1] Xu, Fan, et al. \"Revisiting graph-based fraud detection in sight of heterophily and spectrum.\" Proceedings of the AAAI conference on artificial intelligence. 2024.\n\n[2] Gao, Yuan, et al. \"Addressing heterophily in graph anomaly detection: A perspective of graph spectrum.\" Proceedings of the ACM web conference 2023. 2023.\n\n[3] Fu, Chao, et al. \"Nowhere to H 2 IDE: Fraud Detection From Multi-Relation Graphs via Disentangled Homophily and Heterophily Identification.\" IEEE Transactions on Knowledge and Data Engineering (2024).\n\n[4] Shi, Fengzhao, et al. \"H2-fdetector: A gnn-based fraud detector with homophilic and heterophilic connections.\" Proceedings of the ACM web conference 2022. 2022.\n\n[5] Li, Jintang, et al. \"Hetero2 Net: Heterophily-aware Representation Learning on Heterogenerous Graphs.\" arXiv preprint arXiv:2310.11664 (2023)."}, "questions": {"value": "W1 and W5: Suggest providing source code for community replication and checking the use of technical terminology.\n\nW2 and W4: Discussion and experimentation (if not necessary, please explain) on the recent advancements.\n\nW3: Discussion about the impact of the adaptive λ."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GKbCcjyuA2", "forum": "W1whWBesWC", "replyto": "W1whWBesWC", "signatures": ["ICLR.cc/2026/Conference/Submission8321/Reviewer_J7gW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8321/Reviewer_J7gW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8321/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875266599, "cdate": 1761875266599, "tmdate": 1762920246667, "mdate": 1762920246667, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a \"decouple-then-fuse\" representation learning framework for fraud detection on heterogeneous graphs, which simultaneously exhibit conflicting structural patterns (heterophily) and diverse node features (attribute polymorphism). The model first encodes graph structure using characteristic-function signatures, which are robust to heterophily, and separately encodes node attributes using a Mixture-of-Experts (MoE) model to specialize in different node roles . These two distinct views are then reconciled through a Bayesian mean-difference fusion layer, which adaptively learns a per-node weight to combine the \"consensus\" and \"discrepancy\" between the structural and attribute signals . This method demonstrates improved fraud detection performance across telecom, e-commerce, and cryptocurrency datasets by effectively resolving conflicts between the two modalities."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "There are a few things I like about the paper:\n1. The paper addresses a challenging and practical problem in heterogeneous graph fraud detection.\n2. The \"decouple-then-fuse\" strategy is an interesting and well-motivated design choice. It hopes to avoid the \"premature entanglement\" of structural and attribute biases, where the authors stated that it’s the limitation of existing monolithic models..\n3. The Bayesian fusion mechanism is also interesting. It models consensus and discrepancy, and then learns a per-node weight to combine them.\n4. The authors demonstrated improvement over the baselines on multiple baselines."}, "weaknesses": {"value": "1. [Baselines]. The paper did not compare against more recent graph neural networks models specifically designed for handling heterogeneous graphs, such as R-GCN, HGT, and their more recent variations.\n2. [Complexity] The proposed pipeline is significantly complex, involving multiple distinct stages.\n3. [Hyperparameters] The full model has a large number of hyperparameters. While some sensitivity analyses are explored, the tuning process for the others is not discussed."}, "questions": {"value": "Please address the weaknesses mentioned above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mXR0wNRqND", "forum": "W1whWBesWC", "replyto": "W1whWBesWC", "signatures": ["ICLR.cc/2026/Conference/Submission8321/Reviewer_L6Ks"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8321/Reviewer_L6Ks"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8321/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762720101110, "cdate": 1762720101110, "tmdate": 1762920246251, "mdate": 1762920246251, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}