{"id": "tlYSbw5GXY", "number": 317, "cdate": 1756735096917, "mdate": 1759898267789, "content": {"title": "Closing the Safety Gap: Surgical Concept Erasure in Visual Autoregressive Models", "abstract": "The rapid progress of visual autoregressive (VAR) models has brought new opportunities for text-to-image generation, but also heightened safety concerns. Existing concept erasure techniques, primarily designed for diffusion models, fail to generalize to VARs due to their next-scale token prediction paradigm. In this paper, we first propose a novel VAR Erasure framework **VARE** that enables stable concept erasure in VAR models by leveraging auxiliary visual tokens to reduce fine-tuning intensity. Building upon this, we introduce **S-VARE**, a novel and effective concept erasure method designed for VAR, which incorporates a filtered cross entropy loss to precisely identify and minimally adjust unsafe visual tokens, along with a preservation loss to maintain semantic fidelity, addressing the issues such as language drift and reduced diversity introduce by na\\\"ive fine-tuning. Extensive experiments demonstrate that our approach achieves surgical concept erasure while preserving generation quality, thereby closing the safety gap in autoregressive text-to-image generation by earlier methods.", "tldr": "We designed a method to surgically erased the undesired concept learned in visual autoregressive models.", "keywords": ["visual autoregressive model", "concept erasure"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f745177636e97d2f5e595691a77479cef7d2d05b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a new concept erasure framework for visual autoregressive models (VAR), called VARE, and a fine-grained method S-VARE. The authors point out that existing concept erasure methods designed for diffusion models do not work well in autoregressive models due to error accumulation across scales. To solve this, they use auxiliary visual tokens during training to stabilize optimization and introduce two new loss functions: a filtered cross-entropy loss to remove only harmful tokens and a preservation loss to keep unrelated content unchanged. Experiments show strong results on NSFW, object, and style erasure tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The paper first proposes a concept erasure method specifically for VAR models.\n\n2.The use of auxiliary visual tokens during training is a practical and effective way to reduce error accumulation in autoregressive generation."}, "weaknesses": {"value": "1. The method is designed for single-concept erasure and does not support removing multiple concepts at once, which limits its applicability in real-world scenarios where multiple harmful or unwanted concepts may co-occur.\n\n2. The paper lacks a token-level interpretability analysis. It is unclear which tokens are being erased during training, at which scales, or how the filtering mechanism behaves across different types of concepts.\n\n3. The token filtering mechanism uses a fixed threshold for all tokens without considering their semantic relevance to the target concept. A more adaptive approach could improve precision by focusing only on tokens that are highly correlated with the concept to be erased.\n\n4. Missing related works: \n\n[1] Concept corrector: Erase concepts on the fly for text-to-image diffusion models\n\n[2] Dark miner: Defend against unsafe generation for text-to-image diffusion models\n\n[3] One Image is Worth a Thousand Words: A Usability Preservable Text-Image Collaborative Erasing Framework\n\n[4] Erasing More Than Intended? How Concept Erasure Degrades the Generation of Non-Target Concepts"}, "questions": {"value": "1. Can the method be extended to erase multiple concepts at the same time?\n\n2. Can this method be applied to other autoregressive models beyond Infinity?\n\n3. I’m unsure how the filtered cross-entropy loss functions in the context of erasing artistic styles. For object erasure, it makes intuitive sense to optimize the \"object-related\" visual tokens, as they directly correspond to the target object in the image. However, when it comes to styles, the token-wise loss seems to be spread across the entire image, as shown in the first row of Figure 3, where the concept of \"blue\" appears throughout the image. In such cases, how does the filtered cross-entropy loss effectively work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5DlOzF2TaG", "forum": "tlYSbw5GXY", "replyto": "tlYSbw5GXY", "signatures": ["ICLR.cc/2026/Conference/Submission317/Reviewer_TYDT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission317/Reviewer_TYDT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission317/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834757333, "cdate": 1761834757333, "tmdate": 1762915493106, "mdate": 1762915493106, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the VARE framework and its variant, S-VARE, for concept erasure in visual autoregressive models. The approach stabilizes training and achieves concept erasure through a filtered cross-entropy loss."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper introduces concept erasure into visual autoregressive models, employing auxiliary visual tokens for stable training, filtered cross-entropy for precise erasure, and retention loss to preserve image quality.\n\n2.The proposed method demonstrates effectiveness for sensitive concepts/objects/styles, with sufficient experimental support and clear comparisons against baselines, presenting a comprehensive analysis."}, "weaknesses": {"value": "Major Weakness\n\n1.In line 59, the differential prompt method should be supported with an appropriate citation. In addition, it is recommended to include comparative experiments to demonstrate the superiority of the proposed VARE framework, which leverages auxiliary target tokens, over the differential prompt method, supported by quantitative results.\n\n2.In lines 211–215, the statement \"This fundamental mismatch leads to degrading the fidelity of the main subject\" lacks citation or experimental evidence. Moreover, the claim that \" it is not directly applicable to autoregressive models\" is not reasonable, as Equation 7 is an MSE-based loss and can also be applied to VAR models. Comparative experiments between the VARE framework trained with Equation 7 and the S-VARE method should be included to demonstrate the superiority of S-VARE.\n\n3.Please further clarify how Equation 7 improves upon Equation 6. Specifically, describe the internal structure of r^{ori} _{<i}, including how tokens interact with the VAR model.\n\n4.The relationship between the cross-attention mentioned in line 203 and c^{*} should be explicitly illustrated in Figure 1.\n\n5.Line 234 mentions the \"characteristics of infinity\", followed by a proposed solution, but the concept (\"characteristics of infinity\") is not clearly defined or explained in the text. Relevant descriptions should be provided.\n\n6.Please describe the novel modifications (structure) in the VARE framework within the Methods section. For example, explain how the auxiliary target tokens are embedded into the VAR model and provide the corresponding equations.\n\nMinor weakness\n\n1.In lines 195–202, the symbols in the main text are inconsistent with those in Equation (7) and Figure 1 and need to be corrected. For example, r_{ori}^{*} and r_{ori} mentioned in line 167 do not appear in the equation, and their meaning is unclear. In line 202, the text refers to \"see left of Figure 1\", but r^{ori} is not labeled in Figure 1, and the symbol r is not explained.\n\n2.What does the subscript in r_{<I}​ represent in Equation 6? Specifically, what is the meaning of r_{<I}?\n\n3.Figure 1 presents the overall framework, the text in line 155 should be revised to \"the overall framework is shown in Figure 1\".\n\n4.Based on the text, \"VARE\" refers to a framework and \"S-VARE\" to a method. The phrase \"erasure method VARE\" in lines 78–80 should be corrected to \"erasure method S-VARE\".\n\n5.In Figure 1, replace -log1/2 with γ."}, "questions": {"value": "1.In line 188, the statement \"optimization with Eq. (6) introduces errors as illustrated in the left column of Figure 2\" means that the VAR model trained with Equation 6 fails to generate images properly, as shown in the left column of Figure 2. Furthermore, please provide a detailed description of the diffusion-based CE method, including how text is embedded into the VAR framework and whether a pre-trained model is used. Additionally, clarify in the main text the specific implementations and differences between the methods shown in Figure 2.\n\n2.How does Figure 3 support the conclusion that \"VAR maintains consistent optimization objectives across scales\"? Please further clarify the content presented in the figure."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3iZkf4WrXM", "forum": "tlYSbw5GXY", "replyto": "tlYSbw5GXY", "signatures": ["ICLR.cc/2026/Conference/Submission317/Reviewer_yGxY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission317/Reviewer_yGxY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission317/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841237414, "cdate": 1761841237414, "tmdate": 1762915492961, "mdate": 1762915492961, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript addresses a critical gap in the safety of Visual Autoregressive (VAR) models for text-to-image generation: existing Concept Erasure (CE) techniques, primarily designed for diffusion models, fail to generalize to VARs due to their next-scale token prediction paradigm. VAR models, which offer advantages in image quality and generation speed, remain vulnerable to generating sensitive content (NSFW, copyright-sensitive material) post-training, and retraining for new undesirable concepts is computationally prohibitive.\nTo solve this, the authors propose two core solutions: (1) VARE (VAR Erasure framework), which leverages auxiliary visual tokens to reduce fine-tuning intensity and mitigate cumulative errors across scales— a key limitation of directly adapting diffusion-based CE; (2) S-VARE, an enhanced method built on VARE that incorporates a filtered cross-entropy loss (L_FCE) (to precisely identify and minimally adjust unsafe tokens) and a preservation loss (L_Pre) (to maintain semantic fidelity and avoid language drift/diversity reduction). Extensive experiments show the approach erases 97% of sensitive concepts with <2% CLIP score degradation, closing the safety gap for VAR models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tTargeted Solution to a Framework-Specific Gap: The manuscript clearly identifies why diffusion-based CE methods fail for VARs and designs VARE/S-VARE to align with VAR’s intrinsic dynamics. The use of auxiliary visual tokens to counter scale-wise error accumulation directly addresses a core technical barrier.\n2.\tLoss Function Design Aligns with VAR Characteristics: The filtered cross-entropy loss (L_FCE) is tailored to VAR’s binary spherical quantization (BSQ) by measuring bit-wise discrepancies, avoiding the instability of diffusion-style MSE loss on discrete token spaces. The preservation loss (L_Pre), which uses KL divergence to align pre-trained and fine-tuned model outputs, effectively mitigates common fine-tuning side effects. \n3.\tComprehensive Experimental Coverage: The authors test S-VARE across three critical CE tasks and validate robustness using adversarial datasets and real-user prompts —a rare focus on real-world deployment risks. Quantitative results and qualitative visualizations (Figure 4) provide clear evidence of the method’s effectiveness."}, "weaknesses": {"value": "1.\tAmbiguity in Auxiliary Token Selection Logic: The manuscript states VARE uses tokens from prompts c (neutral) and c⁎ (with target concept) as auxiliary inputs but provides no details on how to handle scenarios where c and c⁎ have large semantic gaps (e.g., \"a violent car crash\" vs. \"a peaceful park\").\n2.\tLimited Generalization Across VAR Models and Data: The authors only use Infinity-2B as the base VAR model, with no validation on other VAR variants (e.g., models with different scale prediction strategies or non-BSQ quantization)."}, "questions": {"value": "1.\tRegarding Weakness 1: For semantically distant c/c⁎ pairs (e.g., \"a violent car crash\" vs. \"a peaceful park\"). How do auxiliary visual tokens avoid misaligning non-target concepts (e.g., cannot distinguish target \"violent\" and non-target \"car crash\" )? Is there quantitative data on the model’s ability to distinguish target vs. non-target tokens in such cases?\n2.\tAddressing Weakness 2: Have you tested S-VARE on VAR models with non-BSQ quantization (e.g., traditional VQ-VAE)? \n3.\tThe manuscript sets the filter ratio α in L_FCE to 25% based on Infinity’s self-correction range. For VAR models with different self-correction thresholds (e.g., 10% or 40%), what adaptive strategy would you recommend for α?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FAXhjvT5Wv", "forum": "tlYSbw5GXY", "replyto": "tlYSbw5GXY", "signatures": ["ICLR.cc/2026/Conference/Submission317/Reviewer_dr9A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission317/Reviewer_dr9A"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission317/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958730756, "cdate": 1761958730756, "tmdate": 1762915492790, "mdate": 1762915492790, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies a safety gap in modern Visual Autoregressive (VAR) text-to-image models, noting that existing concept erasure (CE) methods designed for diffusion models fail when applied to VARs due to their different (next-scale token prediction) architecture. The authors propose VARE, a foundational framework that enables stable erasure by using auxiliary tokens, and S-VARE, a specific method built upon it. S-VARE introduces two novel components: a \"filtered cross entropy loss\" (LFCE) specifically designed for the quantization-based token prediction of VARs, and a \"preservation loss\" (LPre) to prevent the fine-tuning process from degrading unrelated concepts or reducing image diversity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The introduction clearly diagnoses why diffusion-based CE methods fail—they are not designed for the \"visual token\" prediction paradigm of VARs and lead to \"cumulative errors\" and \"severe degradation.\"\n\n2. The proposed solution appears well-reasoned and specifically tailored to the VAR architecture. Instead of retrofitting a Mean Squared Error (MSE) loss (for noise), it proposes a cross-entropy-based loss (for tokens/probabilities), which seems far more appropriate for the described model.\n\n3. The inclusion of a \"preservation loss\" (LPre) is a strong point. It shows the authors are not just focused on the primary goal (erasure) but also on the critical side effects of fine-tuning, such as \"language drift\" and loss of diversity, which are common failings of naive erasure methods.\n\n4. The headline metrics (97% erasure with <2% degradation in CLIP score) are impressive and, if validated, would represent a significant achievement in closing the safety gap."}, "weaknesses": {"value": "1. The justification for the LFCE loss is heavily tied to the \"binary spherical quantization (BSQ)\" used in the Infinity model. It's not clear how generalizable this method is to other or future VAR models that might not use this specific quantization scheme.\n\n2. The paper discusses erasing \"sensitive\" or \"undesirable\" concepts. This is vague. The method's difficulty would vary greatly between erasing a simple object (e.g., a specific logo) versus a complex, abstract, or compositional concept (e.g., \"a violent action\")."}, "questions": {"value": "1. What was the range of concepts used for the erasure experiments? Did you test the method on simple objects, artistic styles, specific identities, and more abstract concepts?\n\n2. How did you balance the weights of the filtered erasure loss (LFCE) and the preservation loss (LPre)? Is there a risk that the preservation loss could \"protect\" parts of an unwanted concept, making erasure more difficult?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "a0cAI23IQL", "forum": "tlYSbw5GXY", "replyto": "tlYSbw5GXY", "signatures": ["ICLR.cc/2026/Conference/Submission317/Reviewer_9kz9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission317/Reviewer_9kz9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission317/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960802931, "cdate": 1761960802931, "tmdate": 1762915492628, "mdate": 1762915492628, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes VARE and S-VARE, the first frameworks for concept erasure in VAR text-to-image models. VARE introduces auxiliary visual tokens to stabilize optimization and mitigate cumulative errors. S-VARE integrates a filtered cross-entropy loss and a preservation loss to achieve surgical concept removal while maintaining generation quality. Experiments show that this method has certain effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper focuses on the problem of concept erasure in  VAR text-to-image models, addressing a significant gap in current research.\n2. Experiments cover various erasure tasks and multiple datasets, with visualizations further demonstrating the effectiveness of the proposed method."}, "weaknesses": {"value": "1. All experiments in this paper are conducted based on Infinity-2B. It lacks validation on other autoregressive architectures, which may limit the generalization of the results.\n2. The authors aim to use $L_{FCE}$ to promote erasure and $L_{Pre}$ to preserve the model’s alignment with the original distribution. However, these two objectives are inherently conflicting, which may lead to gradient interference. The authors should clarify how the balance between them is achieved.\n3. It remains unclear whether the proposed method can preserve the invariance of irrelevant factors in the original image during the erasure process. For example, after erasing nudity, can the method ensure that the person’s identity in the image remains unchanged?\n4. The competitors are mostly from 2024. To my knowledge, several new SOTA methods have emerged in 2025. It is recommended that the authors include comparisons with them. If such methods cannot be adapted to autoregressive architectures, this limitation should be explicitly discussed in the Related Work."}, "questions": {"value": "In addition to the issues mentioned in the Weaknesses, I have a few more concerns:\n\n1. What are the time and space complexities of the proposed method?\n2. Does erasing multiple concepts lead to cumulative negative effects, such as a decline in generation quality as the number of erased concepts increases? While I understand that there is no free lunch and that concept erasure will inevitably affect the original generation quality, I still hope the authors can provide a quantitative evaluation of this trade-off."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "KsDl7p7EMN", "forum": "tlYSbw5GXY", "replyto": "tlYSbw5GXY", "signatures": ["ICLR.cc/2026/Conference/Submission317/Reviewer_ZPfw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission317/Reviewer_ZPfw"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission317/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762150346034, "cdate": 1762150346034, "tmdate": 1762915492457, "mdate": 1762915492457, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}