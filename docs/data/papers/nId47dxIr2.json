{"id": "nId47dxIr2", "number": 20960, "cdate": 1758312035430, "mdate": 1763660282686, "content": {"title": "Rethinking Alignment in Cross-Lingual Knowledge Transfer", "abstract": "Despite LLMs' advanced performance in multilingual tasks, they usually have performance gap on the same task in dominant languages (e.g., English) and non-dominant languages (e.g., Turkish). In this paper, we analyze LLMs' capacity to transfer the task knowledge learned in the dominant language to the non-dominant language. We first formulate the cross-lingual transfer problem into a gradient alignment problem and then connect it to the representation alignment problem. We show that pre-trained LLMs with decent representation alignment ability can easily transfer knowledge from the dominant language by simple fine-tuning, while others need carefully designed training strategies.  For the latter, we propose a cross-lingual in-context prompt tuning (CL-ICP) model to enhance gradient alignment, which utilizes in-context attentions to generalize to unseen data. In addition, we apply a representation shift to enhance representation alignment between demonstration and target samples. Experiments show that CL-ICP improves cross-lingual transfer in both high and low resource scenarios.", "tldr": "", "keywords": ["Cross-Lingual Transfer; Cross-lingual Alignment; Gradient Alignment; In-Context Learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6b64cfbdb8f03e9972f00e20c96e446f049476a1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies cross-lingual transfer in LLMs via representation alignment, that is, if the LLM encodes the tokens/sentences of two languages invariantly, then training/prompting the LLM on data from one language will also makes it perform will on other languages.\n\nBased on the reviewer's reading of the paper, the authors:\n\n1. Relate transfer performance to the alignment of the loss gradient\n    - This connection is discussed in some domain generalization literature such as \"Invariant Risk Minimization\".\n2. On a toy linear regression example (where each example is a vector), show that gradient alignment is equal to the sum of the dot products between examples from one language and those from another language\n    - Perhaps a loose connection to LLM is to take each example as the penultimate layer sentence embeddings (e.g., mean-pooled)\n3. They compute and show token-level dot products between a translation pair on two LLMs in fig. 2, and show that this dot product correlates with downstream classification performance (after fine-tuning on source/dominant language only)\n4. They propose CL-ICP: on top of few-show prompting with source/dominant and target/non-dominant language examples, they perform soft prompt-tuning w.r.t. both source and target languages' labeled examples.\n5. On top of CL-ICL, they also propose modifying the intermediate pooled representation of the test (in another language) sequence to so that it is closer to the source language."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The reviewer appreciates effort on providing an (toy theoretical and empirical) analysis for justifying philosophy of representation alignment."}, "weaknesses": {"value": "1. In a nutshell, CL-ICP is multi-lingual few-shot prompting + soft prompt tuning.\n- As an empirical method, it is a relatively common and well-known technique, and by itself is not very surprising nor novel.\n- It is compared to full-parameter fine-tuning (TL/MTL).  The reviewer is curious whether the improvement is simply due to the fact that prompt-tuning is parameter efficient (better generalization properties)?  A comparison to LoRA and simple prompt-tuning would be illustrating.\n\n2. The connection from prompt-tuning to representation alignment eq. (4), to the toy example in eq. (2), to loss gradient alignment in eq. (1), then finally to transfer performance (IRM), is very tenuous.  The reviewer does not find the argument to be theoretically rigorous, nor well-supported empirically.\n- It is unclear whether CL-ICP *actually* improves transfer performance via the hypothesized mechanism, empirically.  (Given that the lack of theoretical justification, including the final link between IRM and performance).\n- Fig. 2 evaluates the correlation between representation alignment and performance AFTER fine-tuning.  By the phenomenon of \"neural collapse\", this correlation between alignment and performance is expected on trained neural models in general.  Instead, the reviewer is curious whether this correlation also holds for CL-ICP, and prompting-only (no tuning)."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ngCtUU3W2B", "forum": "nId47dxIr2", "replyto": "nId47dxIr2", "signatures": ["ICLR.cc/2026/Conference/Submission20960/Reviewer_5zwr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20960/Reviewer_5zwr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20960/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761804641286, "cdate": 1761804641286, "tmdate": 1762939057072, "mdate": 1762939057072, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a framework for analyzing cross-lingual knowledge transfer in large language models (LLMs) through the lens of gradient alignment. The authors formally connect representation alignment with gradient alignment and propose a method called CL-ICP (Cross-Lingual In-Context Prompt tuning), which combines in-context learning with soft prompt tuning and representation shift to enhance cross-lingual generalization. The method is evaluated on several cross-lingual benchmarks (XQuAD, XCOPA, XNLI) and compared against fine-tuning, multi-task learning, and other methods such as ShifCon."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The use of soft prompts in combination with in-context demonstrations and a representation shift mechanism is an effective approach to improve alignment. \n2. The experiments span diverse tasks and languages."}, "weaknesses": {"value": "1. The central theoretical framing of this paper—gradient alignment—is insufficiently motivated. While the idea is intuitively plausible, the paper does not rigorously justify why gradient alignment should be the primary lens for understanding cross-lingual transfer.\n2. The experimental setup uses a subset of available languages (e.g., only 4 languages in XQuAD/XNLI) and further restricts XNLI to just 1,000 samples without justification. These choices reduce the representativeness of the evaluation and raise concerns about the robustness and generalizability of the reported results.\n3. The paper omits comparisons to several important baselines in cross-lingual transfer, such as XLM-R or other prompt-based transfer models, which makes it harder to contextualize the improvements. (XLM-R shows impressive performance on XNLI)\n4. The three subsections in the related work (Cross-Lingual Transfer, Cross-Lingual Alignment Models, and Cross-Lingual ICL) have overlapping content. This structure leads to redundancy and makes it difficult to situate this paper clearly."}, "questions": {"value": "1. Line 64 contains a likely typo (“witn” instead of “with”).\n2. There is one formatting error (Lines 250–251) where the mathematical expression overflows the page width, violating the guideline."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5BGyixiGCs", "forum": "nId47dxIr2", "replyto": "nId47dxIr2", "signatures": ["ICLR.cc/2026/Conference/Submission20960/Reviewer_z7eL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20960/Reviewer_z7eL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20960/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898802195, "cdate": 1761898802195, "tmdate": 1762939056513, "mdate": 1762939056513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the problem of cross-lingual knowledge transfer in LLMs, particularly focusing on how to improve task performance in non-dominant languages using knowledge learned from dominant languages . The authors frame this as a gradient alignment problem, showing that successful transfer depends on the alignment of gradients and representations between languages. They propose a novel method called Cross-Lingual In-Context Prompt Tuning (CL-ICP), which uses soft prompts and representation shifts to improve alignment, especially in low-resource settings. The method is evaluated on three multilingual datasets and compared against various baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. I think the introduction of the gradient alignment perspective to cross-lingual transfer provides a fresh and insightful view. \nIt connects gradient alignment with representation alignment, offering a unifying view of why some models transfer better than others.\n2.The experiments are thorough, covering multiple tasks, languages, and model architectures (Llama 3.1, Qwen 2.5). The authors also include ablations and low-resource scenarios, which adds credibility to the claims."}, "weaknesses": {"value": "1. I feel the innovative of this paper is limited:  the proposed CL-ICP combines existing ideas (in-context learning, soft prompts, representation shifting) rather than introducing fundamentally new mechanisms. \n2. CL-ICP relies on demonstration selection and attention analysis, which may not scale well to more complex tasks or longer sequences. The paper does not discuss computational overhead or inference efficiency, which are critical for real-world deployment.\n3. The overall display of the results could be improved, most of the tables are too small to see, and some equation exceeds the width limit."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ml05oFL3Z6", "forum": "nId47dxIr2", "replyto": "nId47dxIr2", "signatures": ["ICLR.cc/2026/Conference/Submission20960/Reviewer_21p8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20960/Reviewer_21p8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20960/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927316494, "cdate": 1761927316494, "tmdate": 1762939056111, "mdate": 1762939056111, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}