{"id": "JUX7x5ync4", "number": 5478, "cdate": 1757913935743, "mdate": 1759897972031, "content": {"title": "Automated Structured Radiology Report Generation with Rich Clinical Context", "abstract": "Automated structured radiology report generation (SRRG) from chest X-ray images offers significant potential to reduce workload of radiologists by generating reports in structured formats that ensure clarity, consistency, and adherence to clinical reporting standards. While radiologists effectively utilize available clinical contexts in their diagnostic reasoning, existing SRRG systems overlook these essential elements. This fundamental gap leads to critical problems including temporal hallucinations when referencing non-existent clinical contexts. To address these limitations, we propose contextualized SRRG (C-SRRG) that comprehensively incorporates rich clinical context for SRRG. We curate C-SRRG dataset by integrating comprehensive clinical context encompassing 1) multi-view X-ray images, 2) clinical indication, 3) imaging techniques, and 4) prior studies with corresponding comparisons based on patient histories. Through extensive benchmarking with state-of-the-art multimodal large language models, we demonstrate that incorporating clinical context with the proposed C-SRRG significantly improves report generation quality. We will publicly release dataset, code, and checkpoints to facilitate future research for clinically-aligned automated RRG.", "tldr": "", "keywords": ["structured radiology report generation", "multimodal large language model", "rich clinical context"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/20d86d99ab3e9069cc96684e6af3bc72a6ece0f1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper focuses on how clinical context (such as patient history, imaging indication, technique, and prior studies) affect the performance of radiology report generation. The key contribution is a curated dataset that include several types of context. This paper conduct extensive experiments to benchmark the performance of several MLLMs and analyze how including context affect the performance of radiology report generation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Considering context information for radiology report generation is a reasonable technical design that worth exploring.\n2. Compared to previous work, this paper conducts a very comprehensive empirical analysis on how context information affect radiology report generation performance."}, "weaknesses": {"value": "1. The contribution of the newly curated datasets are limited. \n\n1.1 The dataset in this paper is primarily based on an existing resource, with only minor modifications. Most samples are drawn from MIMIC-CXR, which already contains all the context information considered by the authors. As a result, the additional effort required to construct this dataset is minimal, and the contribution in terms of dataset creation is limited.\n\n1.2 It is not a novel idea to consider context information in radiology report generation. Previous works have already extensively studied the influence of the context information considered in this paper. Or maybe you can provide some experiments on how these methods perform on the proposed benchmark datasets. \n\n1.2 There are lots of other types of context information that haven't been extensively studies by previous works that can potentially benefit report generation. For example, results of other exams or lab tests, patient's demographic information, patient's EHR. Lots of the information is actually also included in MIMIC datasets, but the authors missed them. \n\n2. For part of the samples in the new dataset, the context information is generated by GPT-4. I think there should be more detailed analysis on the quality of the generated data. \n2.1 what prompts are used to generated the synthetic samples? \n\n2.2 How the authors make sure the generated context is aligned with the content of the target radiology study  and will there be contradiction between them. \n\n2.3 What are the quality control measures? \n\n2.4 Can you provide some evaluation on the quality of the generated data?"}, "questions": {"value": "Please address my concerns in the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OBJVbpjDda", "forum": "JUX7x5ync4", "replyto": "JUX7x5ync4", "signatures": ["ICLR.cc/2026/Conference/Submission5478/Reviewer_4zws"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5478/Reviewer_4zws"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761726562065, "cdate": 1761726562065, "tmdate": 1762918086596, "mdate": 1762918086596, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces C-SRRG, a framework for contextualized structured radiology report generation that integrates multi-view X-rays, imaging indications, techniques, and prior studies into the report generation process. Authors curate C-SRRG derived from MIMIC-CXR and CheXpert Plus, providing structured radiology reports aligned with these contextual elements. They did comprehensive benchmarking with CheXagent-3B, MedGemma-4B, and Lingshu-7B, and demonstrate that incorporating clinical context improves report quality, mitigates temporal hallucinations, and yields stronger clinical accuracy, especially as model scale increases."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Strong motivation: lack of contextual grounding is a real limitation\n- Dataset design is well thought-out\n- Multiple model scales and ablations isolate the effects of each context component\n- Hallucination analysis is good as it provides a practical diagnostic for temporal reasoning failures"}, "weaknesses": {"value": "- Dataset relies partly on GPT-4–parsed elements which could introduce noise or biases\n- Evaluation limited to truncated longitudinal contexts so it's unclear how well it scales to full patient histories\n- No human expert evaluation beyond the “test-reviewed” split; a reader study would strengthen this alot"}, "questions": {"value": "- Could the authors quantify how annotation noise from GPT-4 parsing affects downstream model performance?\n- Would radiologist-in-the-loop evaluation (e.g., assessing factual correctness or usability) further validate C-SRRG’s clinical relevance?\n- Can the framework generalize to other imaging modalities?\n- How does context omission affect interpretability from a clinical perspective?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "DVerU9FMjr", "forum": "JUX7x5ync4", "replyto": "JUX7x5ync4", "signatures": ["ICLR.cc/2026/Conference/Submission5478/Reviewer_3C92"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5478/Reviewer_3C92"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959776543, "cdate": 1761959776543, "tmdate": 1762918086131, "mdate": 1762918086131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the structured radiology report generation (SRRG) task with a proposed contextualized SRRG (C-SRRG). The work contributes a new C-SRRG dataset and evaluates three state-of-the-art medical MLLMs with and without the clinical context."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Temporal hallucination is introduced nicely, and the paper shows substantial mitigation.\n- The ablation study is detailed and sound."}, "weaknesses": {"value": "- The technical novelty seems lacking.\n- The claim \"the critical importance of clinical context in scaling up MLLMs for SRRG.\" (377) is questionable due to different model families (MedGemma vs Lingshu).\n- While temporal hallucination seems problematic, it is not clearly shown how critical/large/common the issue is. Table 9 is performed on only MedGemma-4B. An experiment on the other two models would help giving a better picture of the issue."}, "questions": {"value": "- Is the \"curated\" C-SRRG dataset mostly data-processing on top of the existing SRRG dataset from [1]?\n- Does the \"training failure\" behavior on CheXagent-3B (333) exist before training as well?\n- How is the baseline performance without any fine-tuning in the evaluation?\n\n[1] Delbrouck, Jean-Benoit, et al. \"Automated Structured Radiology Report Generation.\" (2025)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1P9liiPO3w", "forum": "JUX7x5ync4", "replyto": "JUX7x5ync4", "signatures": ["ICLR.cc/2026/Conference/Submission5478/Reviewer_TNV1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5478/Reviewer_TNV1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971793739, "cdate": 1761971793739, "tmdate": 1762918085172, "mdate": 1762918085172, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents C-SRRG, a contextualized framework for structured radiology report generation that explicitly incorporates clinically relevant contextual signals including multi-view chest X-rays, imaging technique, indication, and prior studies. The authors curate a well-aligned dataset combining MIMIC-CXR and CheXpertPlus, and evaluate the proposed framework using advanced medical multimodal large language models (MLLMs), including CheXagent-3B, MedGemma-4B, and Lingshu-7B."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Clinical relevance: The paper is well-motivated from a clinical standpoint. The integration of contextual cues mirrors the diagnostic reasoning processes of radiologists and addresses a gap in current MLLM-based report generation.\n* Dataset contribution: The curated dataset, aligned with structured reporting templates, is valuable for the community. The construction pipeline is described clearly and considers temporal alignment and semantic normalization.\n* Empirical thoroughness: The experiments are comprehensive and include comparisons across multiple MLLMs, detailed ablations, and organ-level breakdowns. Results show consistent improvements in structured report generation (+2–7% F1-SRR-BERT) and a notable reduction in temporal hallucinations (12–18%), highlighting the utility of contextual signals.\n* Transparency and reproducibility: The authors provide clear methodology, ethics considerations, and reproducibility statements, which enhance the credibility of the work."}, "weaknesses": {"value": "* Synthetic supervision: A significant portion of the structured labels is generated using LLMs, which may introduce hallucinations or inaccuracies into the supervision signal. The paper would benefit from a more thorough discussion on how these potential inaccuracies affect downstream training and evaluation.\n* Model limitations: The evaluation is limited to models ≤7B parameters. While understandable for resource reasons, it raises questions about scalability and generalization to larger foundation models.\n* Limited architectural novelty: The framework primarily relies on contextual data feeding and fine-tuning, rather than proposing new architectural mechanisms for structured generation or hallucination mitigation. This may limit its novelty in some readers’ view."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["Yes, Other reasons (please specify below)"]}, "details_of_ethics_concerns": {"value": "The authors mention that structured clinical context elements are derived from free-form radiology reports using GPT-4. GPT-4 is not specifically tuned for clinical concept extraction, and may introduce inaccuracies or hallucinated outputs, especially when interpreting nuanced medical language. There is no discussion of error handling, validation, or expert review of the parsed components."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6p9xKkDlmK", "forum": "JUX7x5ync4", "replyto": "JUX7x5ync4", "signatures": ["ICLR.cc/2026/Conference/Submission5478/Reviewer_SiHb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5478/Reviewer_SiHb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5478/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762284458972, "cdate": 1762284458972, "tmdate": 1762918084817, "mdate": 1762918084817, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}