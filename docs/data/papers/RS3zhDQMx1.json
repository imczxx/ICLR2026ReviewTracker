{"id": "RS3zhDQMx1", "number": 14021, "cdate": 1758227092507, "mdate": 1763707383767, "content": {"title": "FlashResearch: Real-time Agent Orchestration for Efficient Deep Research", "abstract": "Deep research agents, which synthesize information across diverse sources, are significantly constrained by their sequential reasoning processes. This architectural bottleneck results in high latency, poor runtime adaptability, and inefficient resource allocation, making them impractical for interactive applications. To overcome this, we introduce *FlashResearch*, a novel framework for efficient deep research that transforms sequential processing into parallel, runtime orchestration by dynamically decomposing complex queries into tree-structured sub-tasks. Our core contributions are threefold: **(1)** an **adaptive planner** that dynamically allocates computational resources by determining research breadth and depth based on query complexity; **(2)** a **real-time orchestration layer** that monitors research progress and prunes redundant paths to reallocate resources and optimize efficiency; and **(3)** a **multi-dimensional parallelization framework** that enables concurrency across both research breadth and depth. Experiments show that FlashResearch consistently improves final report quality within fixed time budgets, and can deliver up to a 5x speedup while maintaining comparable quality.", "tldr": "", "keywords": ["Deep Research", "Agent Orchestration", "Runtime Efficiency"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2964ee0c8bef2e342178c8f70748feba7fc40e6e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "FlashResearch converts deep research into a tree-structured, real-time orchestrated search process, parallelizes sub-queries and prunes low-value branches under a hard time budget. An adaptive planner chooses breadth and depth per node, while an asynchronous execution engine enables speculative deepening and early termination. Evaluated on DeepResearchGym and DeepResearch Bench (though a little bit narrow), the system processes up to 4× more nodes than the GPT-Researcher baseline and yields slightly higher report scores within the same wall-clock limit."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Demonstrates measurable throughput-quality lift over a strong retrieval baseline under fixed time budgets.  \n- Provides a clean, asynchronous tree abstraction that cleanly separates planning, orchestration, and execution concerns."}, "weaknesses": {"value": "1. FlashResearch appears to focus primarily on an offline setting, where data are collected from a local corpus (for instance, the setting in Figure 1 seems to be strongly related to DeepResearchGym). However, I understand that one of the major challenges of deep research actually lies in tool selection and allocation within online web search scenarios—different task types may require different tools (e.g., some can be efficiently solved via a Wikipedia Search API, while others may benefit from Playwright-based visual browsing). Yet, I did not observe any adaptation or discussion regarding this aspect. I understand that DeepResearchGym may only require a single retriever tool, but what kinds of tools does DeepResearchBench actually provide?\n2. The paper’s survey of current state-of-the-art deep research methods is somehow insufficient. The cited works (e.g., AFlow, Flow, and EvoFlow) remain confined to traditional math or coding tasks, whereas there now exist many multi-agent approaches specifically designed for deep research, including but not limited to [1, 2, 3, 4]. I believe it is necessary to mention, cite, and even compare these works.\n3. In Line 135, the authors claim that most existing agentic workflows “lack support for real-time replanning.” This statement is inaccurate, as a number of studies have already demonstrated the ability to dynamically adjust plans in real time [5, 6]. The authors should take this into account; there is also a growing body of research on dynamically adjusting multi-agent workflows according to different task requirements/complexity, including but not limited to [7, 8].\n4. The experimental presentation seems rather rushed. At least a few aspects could be analyzed in greater depth: for example, reporting economical cost (LLM API consumption); examining whether, as task complexity increases (e.g., wrt the number of ground-truth documents related to each query), FlashResearch actually learns to allocate different search resources (e.g., varying the number of search nodes); and conducting case studies to analyze the quality of replanning when failed leaf nodes occur (Appendix B seems to omit this discussion).\n5. Regarding the utility function U(r) in Line 200, how is it concretely implemented?\n\n---\n\n\n[1] OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation  \n[2] AgentOrchestra: Orchestrating Hierarchical Multi-Agent Intelligence with the Tool-Environment-Agent(TEA) Protocol   \n[3] Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training \n[4] OAgents: An Empirical Study of Building Effective Agents    \n[5] https://github.com/ZTE-AICloud/Co-Sight \n[6] https://github.com/huggingface/smolagents   \n[7] FlowReasoner: Reinforcing Query-Level Meta-Agents   \n[8] Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors"}, "questions": {"value": "Please refer to Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sZOS3bppga", "forum": "RS3zhDQMx1", "replyto": "RS3zhDQMx1", "signatures": ["ICLR.cc/2026/Conference/Submission14021/Reviewer_YF1V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14021/Reviewer_YF1V"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14021/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761129108549, "cdate": 1761129108549, "tmdate": 1762924513895, "mdate": 1762924513895, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FlashResearch, a framework for deep research. It introduces an adaptive planner for reasoning depth, a real-time orchestration layer that dynamically adjusts compute allocation, and a multi-dimensional parallelization scheme that explores both the breadth and depth of reasoning in parallel. On benchmark datasets, the framework achieves strong accuracy while improving inference efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1: The paper is clearly written and tackles an important efficiency problem in deep research; the method and experiments are well aligned with the motivation. \n\n2: By integrating adaptive planning, real-time orchestration, and multi-dimensional parallelization, the system simultaneously boosts throughput and reduces latency, making it readily deployable in production."}, "weaknesses": {"value": "1: Both the adaptive planner and the real-time orchestration policies rely on LLM judgments to decide when to expand, deepen, or terminate paths. This makes the decision process hard to interpret. \n2: Evaluating the goal-satisfaction level and quality score of every node requires on-the-fly calls to an LLM, incurring measurable extra overhead.\n3: The choice of 2-minute and 10-minute time budgets is motivated by prior human–computer interaction findings, but the paper lacks a broader sensitivity analysis across time budgets and does not discuss external/API-induced latency that could waste the budget. This limits understanding of robustness under different deployment conditions."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "7p8YhwIleO", "forum": "RS3zhDQMx1", "replyto": "RS3zhDQMx1", "signatures": ["ICLR.cc/2026/Conference/Submission14021/Reviewer_S2LH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14021/Reviewer_S2LH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14021/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906875886, "cdate": 1761906875886, "tmdate": 1762924513488, "mdate": 1762924513488, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Given the limited runtime adaptability of existing methods for deep research tasks, this paper introduces a dynamic planner designed to adjust the breadth and depth of the research tree in real time. The planner leverages utility-guided strategies, where utility is determined by LLM-based judges. The proposed approach is evaluated across multiple deep research benchmarks, showing improved accuracy and reduced latency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The examples provided in Section 3.2 highlight the necessity and potential benefits of improving the configuration of breadth and depth.\n2. The explicit formulation of controlling the research tree's breadth and depth is both logically sound and empirically effective.\n3. The paper is well-written and easy to understand."}, "weaknesses": {"value": "1. Because the method relies on the current implementation of LLM-as-a-judge, its effectiveness depends heavily on the LLM’s ability to make accurate judgments.\n2. The evaluation is limited to a single model family (Gemini-2.5); testing with additional models, such as smaller open-source ones, would strengthen the results."}, "questions": {"value": "1. Can the proposed approach be generalized to utility models beyond LLM-as-a-judge?\n2. Given the asynchronous operations and increased number of explored nodes, does this result in higher computational or operational costs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ukUHCPPsvh", "forum": "RS3zhDQMx1", "replyto": "RS3zhDQMx1", "signatures": ["ICLR.cc/2026/Conference/Submission14021/Reviewer_Yz8E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14021/Reviewer_Yz8E"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14021/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761924607285, "cdate": 1761924607285, "tmdate": 1762924512980, "mdate": 1762924512980, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents the FlashResearch framework, designed to enable efficient and scalable deep research. The framework operates in parallel, dynamically decomposing complex queries into subtasks at runtime. An adaptive planning module determines the appropriate breadth and depth of exploration, while a real-time orchestration layer monitors progress and optimizes research pathways for maximum efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is clearly written and well-structured.\n- Demonstrates improved research quality under fixed computational budgets, achieving up to a 5× speedup."}, "weaknesses": {"value": "- The proposed framework is evaluated on only two benchmarks, with relatively small sample sizes (100 and 50 examples). The rationale for not using the full datasets is unclear. Evaluating on larger datasets or additional benchmarks would strengthen the empirical validity of the results.\n- The use of LLMs for evaluation raises concerns regarding metric reliability and potential bias. This should be discussed in greater detail.\n- Comparisons are limited to GPT-Researcher. Including experiments with additional models would improve the robustness and generalizability of the findings.\n- The performance results are mixed, and further analysis is needed to clarify the conditions under which the proposed method is most effective.\n- The paper lacks an ablation study, which would help isolate and assess the contribution of individual components within the framework."}, "questions": {"value": "Was any error analysis performed to better understand the sources of the model’s successes and failures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fosAxhF16B", "forum": "RS3zhDQMx1", "replyto": "RS3zhDQMx1", "signatures": ["ICLR.cc/2026/Conference/Submission14021/Reviewer_ZoH6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14021/Reviewer_ZoH6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14021/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969565943, "cdate": 1761969565943, "tmdate": 1762924512398, "mdate": 1762924512398, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}