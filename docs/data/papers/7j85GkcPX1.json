{"id": "7j85GkcPX1", "number": 5036, "cdate": 1757837595134, "mdate": 1763529514922, "content": {"title": "MEDSPIKEFORMER: All Neurons Matter for Medical Image Segmentation", "abstract": "Spiking self-attention (SSA) has emerged as a promising approach for medical image segmentation due to its event-driven and energy-efficient nature. However, segmentation performance still degrades in complex scenarios where salient and non-salient regions coexist. Two fundamental issues remain: i) existing SSA mechanisms rely only on activated neurons, overlooking the contextual cues carried by inactivated neurons, and ii) the binary spike representation causes distribution distortions that make spiking self-attention lag behind their ANN-based self-attention (SA) in spatial discriminability. To overcome these challenges, we propose MedSpikeFormer, a spiking transformer built on the principle that all neurons matter, both activated and inactivated. MedSpikeFormer introduces a Spike-based Decomposed Self-Attention (SDSA) that explicitly models four types of neuronal interactions: activated–activated, activated–inactivated, inactivated–activated, and inactivated–inactivated, thus recovering rich contextual dependencies ignored by conventional SSA. Furthermore, we employ a distribution alignment loss that minimizes the divergence between SDSA and ANN-based self-attention (SA), significantly closing the performance gap to improve spatial feature discriminability while maintaining the binary nature of spiking neural networks. Extensive experiments on five medical segmentation benchmarks demonstrate that MedSpikeFormer consistently outperforms 14 state-of-the-art\nmethods, achieving up to +2.4% mIoU on ISIC2018 and +8.7% on COVID-19. These results confirm that leveraging both fired and non-fired neurons is crucial for robust spike-driven medical image segmentation. Code is available at https://github.com/AnonymousPaper2026/MedSpikeFormer.", "tldr": "", "keywords": ["Medical image segmentation", "Spiking self-attention", "Self-attention", "Spike neural network"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/f71632e054f23e33e8b539ac763805c8624b854f.pdf", "supplementary_material": "/attachment/7db31e1c934e6b10befa5f070936595babf4d0d3.pdf"}, "replies": [{"content": {"summary": {"value": "To address the issues of spiking self-attention in medical image segmentation—where it only relies on activated neurons and suffers from distribution distortion due to binary spike representation, the researchers propose MedSpikeFormer, a spiking Transformer adhering to the principle that \"all neurons matter\". It explicitly models four types of neuronal interactions—A–A, A–I, I–A, and I–I—via SDSA to recover rich contextual dependencies. Additionally, a distribution alignment loss is introduced to enhance the discriminability of spatial features. Experiments on five medical segmentation benchmark datasets show that this method consistently outperforms 14 SOTA methods, achieving an mIoU improvement of up to +2.4% on ISIC2018 and +8.7% on the COVID-19 dataset. These results confirm that leveraging both activated and inactivated neurons is crucial for robust spike-driven medical image segmentation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1 The experimental section includes statistical significance tests.\n\n2 It conducts comparisons of SNN-based models at the power consumption level.\n\n3 It expands the application of SNNs in the field of medical image segmentation."}, "weaknesses": {"value": "1 Does MedSpikeFormer have an advantage in inference speed compared to other lightweight methods?\n\n2 All datasets selected in the experiments are for binary classification tasks. The authors did not validate the model’s effectiveness on multi-class segmentation tasks (e.g., Synapse dataset), which limits the scope of the comparative experiments in this paper.\n\n3 In Table 3, when the A–I interaction is removed, the mIoU decreases by only 0.16% (on ISIC2018), while removing the I–I interaction leads to a 2.06% decrease in mIoU. However, the authors did not analyze the reasons for this discrepancy—for example, whether the A–I interaction carries less information in medical images.\n\n4 In Table 3, why do the results of w/o KL and w/o L2 show exactly the same performance? This requires more in-depth analysis.\n\n5 The transition word used throughout the paper seems to be \"Plus\", but the phrase \"Plus, xxx\" is relatively uncommon.\n\n6 There may be potential unfairness in the comparative experiments. The authors claim that all models were trained and evaluated under the same experimental settings, but the optimal training parameter settings for MedSpikeFormer may not necessarily be optimal for other methods.\n\nIf the authors can address the above concerns, I am willing to raise the score."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2bJGEUkAAG", "forum": "7j85GkcPX1", "replyto": "7j85GkcPX1", "signatures": ["ICLR.cc/2026/Conference/Submission5036/Reviewer_hz6Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5036/Reviewer_hz6Z"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5036/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760542129963, "cdate": 1760542129963, "tmdate": 1762917834103, "mdate": 1762917834103, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "WJ0qLB9eZz", "forum": "7j85GkcPX1", "replyto": "7j85GkcPX1", "signatures": ["ICLR.cc/2026/Conference/Submission5036/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5036/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763529513943, "cdate": 1763529513943, "tmdate": 1763529513943, "mdate": 1763529513943, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MedSpikeFormer, a spiking transformer for medical image segmentation. It introduces Spike-based Decomposed Self-Attention (SDSA) to explicitly model interactions between activated and inactivated neurons, recovering contextual dependencies overlooked by conventional SSA. A distribution alignment loss is further designed to align SDSA with ANN-based self-attention, enhancing spatial discriminability while preserving spike efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. By enabling a more effective transfer of contextual information from ANN-based attention to SNNs, the work broadens the applicability of spiking transformers to complex medical scenarios. The proposed framework provides new insight into bridging biological plausibility and transformer-like representation learning.\n2. The overall architecture is intuitively organized, and the figures effectively illustrate how SDSA expands spike attention scope to include interactions among activated and inactivated neurons. \n3. Relative to prior SNN-based segmentation work, the paper contributes two conceptually novel elements including SDSA and a distribution-alignment scheme between SDSA and ANN-based self-attention. Together, these components effectively bridge the gap between event-driven and continuous attention, marking a meaningful step toward unifying ANN and SNN representations."}, "weaknesses": {"value": "1. The distribution-alignment loss is not defined in a fully verifiable manner. Two essential aspects remain underspecified: It is not stated whether \\hat{O}_{s} and \\hat{O}_{a} are normalized into valid probability distributions. Without an explicit normalization map (e.g., a SoftMax with temperature) and a declared normalization axis (channel / spatial / token), the KL term is not mathematically valid. Moreover, the alignment granularity (per-pixel, head, or layer) is not described, making the formulation difficult to reproduce or verify.\n2. Results are reported without standard deviations or confidence intervals. Please provide mean ± std over ≥3 random seeds for all key metrics.\n3. The reported computational efficiency values are inconsistent. In the Section 4.2, the model is described as having 2.9 M parameters and 26.87 GFLOPs, while Table 1 lists 1.7369 M parameters and 19.0929 GFLOPs for the same configuration.\nSuch numerical discrepancies undermine the credibility and reproducibility of the results.\n4. In Table 3, the results for w/o KL and w/o L2 are the same, making it impossible to observe the individual contribution of each loss component. This contradicts the claim that removing either term affects segmentation performance."}, "questions": {"value": "1. Is the ANN-based self-attention signal realistically available during training in real medical scenarios, or does it rely on additional modules or pre-trained networks that may limit scalability?\n2. Can the proposed SDSA module be integrated as a plug-in within existing SNN or ANN transformer frameworks, or is it tightly coupled to the specific MedSpikeFormer architecture?\n3. Would the proposed distribution alignment still be beneficial in non-medical domains (dynamic vision sensors, general object segmentation), or is the improvement domain-specific to medical segmentation?\n4. If the ANN-based self-attention signal used as a teacher for distribution alignment were removed, would the model still maintain competitive performance purely as an attention-augmented SNN?\n5. For the reported GFLOPs in SNNs, did the authors compute them based on a time-step–equivalent FLOPs estimation?\n6. Could the authors make all relevant runnable code, including ablation experiments, test results, and the different datasets used in this study, publicly available?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tGdUnEur9W", "forum": "7j85GkcPX1", "replyto": "7j85GkcPX1", "signatures": ["ICLR.cc/2026/Conference/Submission5036/Reviewer_VCLo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5036/Reviewer_VCLo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5036/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761464374904, "cdate": 1761464374904, "tmdate": 1762917833704, "mdate": 1762917833704, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MedSpikeFormer, a spiking transformer framework for medical image segmentation. MedSpikeFormer introduces the Spike-based Decomposed Self-Attention (SDSA) to consider inactivated neurons, thereby recovering lost contextual dependencies and a Distribution Alignment Loss to minimize the distribution gap between SDSA and ANN-based SA, preserving spike sparsity while boosting spatial discriminability. Although effective, this article still has some deficiencies in terms of novelty, motivation, experiment comparisons and Interpretability. In my view, this paper is marginally below the acceptance bar of ICLR."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. By decomposing spikes into activated and inactivated components, SDSA fills a critical gap in existing SSA (which ignores inactivated neurons).\n\n2. Comprehensive experiments show that the proposed method Outperforms 14 SOTA methods with significant gains on challenging datasets (e.g., +8.06% mIoU over MFMSA on COVID-19)."}, "weaknesses": {"value": "1. The effectiveness of the motivation in SDSA needs further verification because it involves multiple attention blocks. The gain may be merely due to the increase in the number of attention modules and parameters, rather than the development of inactivated neurons.\n\n2. Distribution alignment loss seems to be just a combination of KL and L2 losses.  At the same time, there is a lack of comparison with other distributed loss functions, which reduces the innovativeness of this module.\n\n3. There is a lack of performance comparison with existing spiking self-attention methods, such as those mentioned in the Introduction."}, "questions": {"value": "1. Does the model parameter include the parameters of the SA module?\n\n2. Why are the parameters of your model in Table 1 (1.7369) different from those in Table 2 (2.8745)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "l3noiwAasA", "forum": "7j85GkcPX1", "replyto": "7j85GkcPX1", "signatures": ["ICLR.cc/2026/Conference/Submission5036/Reviewer_5dWC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5036/Reviewer_5dWC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5036/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761726961365, "cdate": 1761726961365, "tmdate": 1762917833398, "mdate": 1762917833398, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MedSpikeFormer, a spiking transformer architecture for medical image segmentation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper identifies a limitation of existing spiking self-attention mechanisms.\n2. The paper provides extensive ablations validating each component (SDSA, each interaction type, distribution alignment loss components)."}, "weaknesses": {"value": "1. The notation [QA, QI] ⊗ [KA, KI]^T is unclear. Does this represent concatenation followed by matrix multiplication? If so, the dimensional analysis is missing. How exactly are the four interaction types computed and combined?\n2. The paper claims to preserve binary spike properties while simultaneously forcing SDSA outputs to match continuous-valued ANN attention distributions through Lalign. This fundamentally undermines the event-driven, sparse nature that makes SNNs attractive.\n3. The gradient bound ||∇Lalign||F ≤ 3 - 2ε - log ε is stated, but its practical significance is unclear. The claim that this \"guarantees convergence\" is too strong, a bounded gradient is necessary but not sufficient for convergence. Standard convergence analysis (e.g., Lipschitz continuity, convexity) is missing.\n4. The distribution alignment approach is essentially knowledge distillation from ANN to SNN, which is well-established. The combination with SDSA doesn't yield significant theoretical insight.\n5. The paper's central motivation is energy efficiency of SNNs, yet no actual energy measurements on neuromorphic hardware are provided. FLOPs comparisons with ANNs are misleading since SNNs have fundamentally different computational characteristics.\n6. \"All neurons matter\" is misleading: Standard transformers already consider all positions through attention. The framing as a novel insight is overstated, the paper is just explicitly considering the inverse of a binary mask."}, "questions": {"value": "1. Can you provide explicit matrix dimensions for Equations 8-9 and clarify how the four interaction types are computed separately vs. jointly?\n2. How does the distribution alignment loss affect spike rates? Do you measure and report actual sparsity metrics?\n3. How does performance vary with timestep T? What is the computational cost of multiple timesteps?\n4. In Table 3, removing A-I and I-A shows minimal impact. How do you explain this given your claims about their importance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yGa0LvvfMe", "forum": "7j85GkcPX1", "replyto": "7j85GkcPX1", "signatures": ["ICLR.cc/2026/Conference/Submission5036/Reviewer_kdK9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5036/Reviewer_kdK9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5036/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890356136, "cdate": 1761890356136, "tmdate": 1762917833046, "mdate": 1762917833046, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}