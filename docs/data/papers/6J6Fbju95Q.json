{"id": "6J6Fbju95Q", "number": 8056, "cdate": 1758055619491, "mdate": 1763121483427, "content": {"title": "Geometry-Aligned Tangent-Plane Diffusion Transformers for 360° Panorama Generation", "abstract": "Generating 360° panoramas from text is challenging due to the inherent difficulty of mapping a 2D diffusion process to a spherical representation without introducing visual artifacts, inconsistencies, or a lack of global coherence. We present TanDiT, a tangent-plane diffusion transformer that factorizes the sphere into locally planar patches, providing a geometry-aligned representation where a pretrained DiT backbone operates without architectural changes. A lightweight ERP-conditioned refinement stage harmonizes overlaps and improves global coherence. To better evaluate panorama quality, we introduce TangentFID and TangentIS, distortion-aware metrics that capture pole and seam degradations, and align closely with human preference. Experiments across multiple benchmarks show that TanDiT outperforms prior work in both perceptual quality and distortion-sensitive fidelity, while scaling efficiently to 4K resolution.  Ablations confirm that the main gains arise from the representational choice, establishing TanDiT as a simple and principled framework for high-fidelity panorama generation.", "tldr": "A diffusion transformer approach that aims to generate high quality panorama images by generating a grid of tangent planes and stitching them into a panorama.", "keywords": ["Generative Artificial Intelligence", "Image Generation", "Panorama Generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/945958810849b0651d054f45e687d3c241e093b1.pdf", "supplementary_material": "/attachment/3ec1f04d74b5bab771747ce580072cfba1e82302.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes TanDiT for text-to-360° panorama generation. The core idea is to factorize the sphere into tangent-plane views, arrange them as a 2D grid, and fine-tune a pretrained DiT (SD3) on this grid with conditional flow matching. A refinement stage reprojects the grid to ERP and performs SDEdit-style partial denoising with circular padding to suppress seams. The authors also introduce TangentFID/TangentIS, which compute FID/IS over tangent patches and report a 95% confidence bound to emphasize worst-region quality. On several datasets, TanDiT reports strong scores on standard and spherical metrics and includes ablations/user studies supporting its design."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Building on a large SD3 DiT and fine-tuning on tangent grids enables global coherence across views in one diffusion loop, a practical simplification compared to multi-step/tile methods. The approach benefits from long-range attention and pretraining, yielding high visual quality.\n\n- The method reports SOTA or near-SOTA across standard and panoramic metrics and includes ablation studies showing the importance of circular padding, patch-wise high-aspect-ratio denoising, latent rotation, and SR. This supports that each module contributes meaningfully to seam reduction and fidelity."}, "weaknesses": {"value": "- The pipeline concatenates views into a single grid and then solves a nontrivial permutation problem to enforce attention locality. By contrast, prior multi-view image generation works [1], [2], [3] treat each view independently and apply a shared cross-view attention to model the joint distribution in an order-invariant set formulation; although the authors claim an advantage in reusing an off-the-shelf DiT without special spherical modules, fine-tuning is required regardless, and the justification for choosing grid-concatenation instead of established multi-view attention is unclear. The paper provides neither a theoretical justification nor controlled empirical evidence showing that this design is superior to order-invariant multi-view attention.\n\n- The refinement stage applies SDEdit-style noising/denoising to ERP latents using the SD3 backbone (without ERP-specific fine-tuning). SDEdit’s rationale typically presumes the clean target lies on (or near) the denoiser’s learned data manifold; however, SD3 was not trained on ERP/panoramic images. The paper does not establish that ERP panoramas lie on SD3’s manifold or provide empirical analyses, so the theoretical basis for this refinement step remains weak despite the observed seam reduction.\n\n- The paper asserts (Sec. E.2, Sec. A.3) that cubemap edge distortion explains CubeDiff’s seam artifacts. I am not convinced by this claim. Under the pinhole camera model, all perspective views exhibit the same class of projection “distortions”. A cubemap face (≈90° FOV) is itself a standard pinhole-perspective view of the scene, no different in kind from ordinary camera photographs. The term “regular perspective image (without distortion)” is therefore ill-defined/misleading in this context. A more plausible explanation for the mild seams observed in CubeDiff is data scarcity or FOV mismatch between the conditioning image and the ≈90° cubemap faces. As written, the paper attributes a generic property of pinhole projection to a cubemap-specific failure mode; this claim should be corrected or substantially qualified.\n\n[1] Tang, S., Zhang, F., Chen, J., Wang, P., & Furukawa, Y. (2023). MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion. arXiv.\n\n[2] Shi, Y., Wang, P., Ye, J., Mai, L., Li, K., & Yang, X. (2023). MVDream: Multi-view Diffusion for 3D Generation. arXiv:2308.16512.\n\n[3] Huang, Z., Guo, Y., Wang, H., Yi, R., Ma, L., Cao, Y.P., & Sheng, L. (2024). MV-Adapter: Multi-view Consistent Image Generation Made Easy. arXiv preprint arXiv:2412.03632."}, "questions": {"value": "- Your metrics compute per-view (tangent-patch) scores and then report a 95% confidence bound (lower for IS, upper for FID). This design may favor panoramas that are uniformly average over ones that are excellent overall but contain a single localized artifact, making the metric potentially sensitive to outliers. Could you provide the per-patch mean and standard deviation for all baselines alongside the reported confidence bounds?\n\nWhile the paper leverages a modern DiT backbone to generate visually impressive $360^\\circ$ panoramas, the evidential support for its main contributions is not convincing. Key design choices—such as grid-concatenation vs. order-invariant multi-view attention, the attribution of CubeDiff seams to cubemap distortion, the design of the TangentFID/TangentIS metrics that emphasize worst-case regions, and the ERP-space refinement using an SD3 prior—remain under-justified and insufficiently validated. Consequently, I do not believe the submission meets the standards of this conference."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VWlEV0EGuK", "forum": "6J6Fbju95Q", "replyto": "6J6Fbju95Q", "signatures": ["ICLR.cc/2026/Conference/Submission8056/Reviewer_BwcN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8056/Reviewer_BwcN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761738778974, "cdate": 1761738778974, "tmdate": 1762920047797, "mdate": 1762920047797, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "Despite most of the reviewers’ concerns being directly addressable or already answered in our paper, we are choosing to withdraw this paper, given the issues with reviews we address below.\n\nWe thank the reviewers for their time and efforts. We would like to point out that many of the referenced works mentioned by the reviewers are in fact not relevant to our work. The models PanoLLaMA, SyncDiffusion, SemanticDraw, MAD, and SaFa are all wide-image perspective panorama generation methods, and do not actually generate spherical/omnidirectional images like our approach. The key difference is that the ERP versions of omnidirectional images include polar distortions caused by projecting an image on a sphere into a rectangle. Furthermore, there is the requirement that spherical images be loop-consistent (moving off of the right side of the image should seamlessly transition to the left side of the image). MVDiffusion, on the other hand, does not generate polar regions, but instead aims to generate the equatorial regions of an ERP image, which renders it not directly comparable to our work. The training process of SMGD that takes weeks for a 2 staged training which trains a VQGAN and a generator conditioned on it caused us to drop it as a baseline in order to not present an unfair comparison, as the model weights shared by the authors typically did not give reasonable results when tested in our datasets. Finally, other works like MVDream and MVAdapter are not applied on panoramic images, and all the results shown in these papers are on vastly different applications and types of data, making it a challenging comparison, and not relevant to our work.\n\nIn addition, multiple of the mentioned works like SphereDiff and CubeDiff did not have code available at the submission deadline (SphereDiff released their code on October 8th, and CubeDiff only has a non-official implementation which does not necessarily guarantee identical results or fair comparisons with the original paper, and even this non-official implementation was only released on September 28th). Expecting comparisons with models having no publicly available code at the submission deadline is unreasonable. Additionally, CubeDiff arguably solves a much easier problem, image-to-omnidirectional image, since the reference image is able to provide much more detail about the desired scene than a simple textual description.\n\nFinally, many of the other concerns mentioned by reviewers are already addressed in our paper or the supplementary. For example:\n\nReviewer ypY3 states “What would be the performance of TanDiT if trained solely on the Matterport3D dataset? Since PanFusion and UniPano were trained only on Matterport3D, the inclusion of PolyHaven and Flickr360 introduces a fairness concern that should be clarified.”. However, we explicitly stated in our paper “For fairness, we retrain all of the tested baselines on our dataset using their public implementations and recommended settings, ensuring that performance differences are attributable to model design rather than data mismatch.”, in Section 5 of the paper.\n\nReviewer HdsY states “I am confused about the motivation and the difference between cube-map projections and the proposed tangent plane design. It seems that TanDiT degenerates into a structure similar to the standard cubemap when the number of tangent planes equals 6.”. However, Section A.3.2 in the supplementary includes a detailed discussion about the differences between the cubemap and 18 tangent plane representations (including Table 4, which explicitly compares distortion levels between the two methods, showing that higher tangent planes like we use introduces less distortion when mapping between perspective images and parts of the sphere).\n\nReviewer ypY3 states “Please provide qualitative examples corresponding to high and low TangentFID/TangentIS scores. While the user study suggests quantitative alignment with human preferences, readers cannot visually interpret how these metrics reflect perceptual quality.” However, Figure 7 in the supplementary shows an example of multiple samples generated from a model getting high OmniFID but lower TangentFID/TangentIS scores. Since FID-based metrics are distribution-based and cannot be calculated on individual images, asking for specific qualitative examples is not possible.\n\nReviewer 4tuo asks “Are there cases where the refinement stage introduces new artifacts, such as duplicated objects or loss of semantic detail?”. However, Section H in the supplementary is explicitly titled Limitations, and includes a figure (Figure 20), which shows a specific example of where the refinement stage introduces duplicated objects."}}, "id": "KfTm0hKFlg", "forum": "6J6Fbju95Q", "replyto": "6J6Fbju95Q", "signatures": ["ICLR.cc/2026/Conference/Submission8056/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8056/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8056/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763121236631, "cdate": 1763121236631, "tmdate": 1763121258669, "mdate": 1763121258669, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "Please see the Official Comment below for our reasons for withdrawing."}}, "id": "jqrS9soKRd", "forum": "6J6Fbju95Q", "replyto": "6J6Fbju95Q", "signatures": ["ICLR.cc/2026/Conference/Submission8056/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8056/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763121386749, "cdate": 1763121386749, "tmdate": 1763121386749, "mdate": 1763121386749, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work introduces TanDiT, a \"tangent-plane\" diffusion model for 360° panorama generation. TanDiT argues that proper representation is the gap in generating high-quality 360° panoramas, and proposes using a factorized representation of the unit sphere into planar patches, enabling high-quality spherical panorama generation without architectural changes. After generation, using the \"ERP-conditioned refinement\", patches are refined/harmonized to resolve overlap and seams artifacts and improve global consistency. The paper also introduces two new metrics that are more aligned for 360° panoramas, TanFID and TanIS, which capture degradations at poles and seams (common sources of artifacts) and better align with human perceptual preference."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The results appears compelling, both qualitatively and quantitatively, and show good human preference as well.\n- The method is straightforward and easy to understand.\n- An elegant solution and good empirical execution.\n- The paper is well written and easy to follow."}, "weaknesses": {"value": "- **Ablating the ERP-conditioned refinement stage.** Given that the tangent-plane representation is stated as being a primary contribution and central component to the paper's argument, it is important to properly isolate it's value.\n    - D.2 shows qualitative results for the ERP-conditioned refinement, however quantitative results are missing.\n    - Cubemaps can be thought of a subset of tangent-plane projections where $|\\mathcal{G}| = 6$ and grid layout is, naturally, defined along the rules of a cubemap. Experiments showing the refinement stage applied to ERP-based methods is missing.\n- Missing qualitative results for MultiDiffusion\n- Comparison to SphereDiff is missing\n    - Given the overlap in novelty, this is important.\n    - This paper improves over SphereDiff in computational cost, and therefore that brings merit to its novelty, however this comparison is still important.\n- (minor) Comparison to U-Net architectures would be beneficial, and support the claim the DiT model spatial correlations more effectively.\n- (minor) Outlining artifacts in the panoramas would be visually useful to improve digestion of the paper. For example in Figure 9, showing the before and after, it is very difficult to see what/where improvements are made.\n- (minor) L147 typo, duplicate wording.\n- (minor) Section 3, a graphical representation of the tangent-plane projection could go a long way to help readers internalize the representation."}, "questions": {"value": "- What is the 1/2 generation in Table 1? At first this reads as \"0.5\" - later it is more clear that this may mean \"1 or 2\" (including the refinement stage?)\n- What are the known failure modes of TanDiT, especially in challenging scenes or out-of-domain prompts?\n- Are there cases where the refinement stage introduces new artifacts, such as duplicated objects or loss of semantic detail?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xUoMnSBuRe", "forum": "6J6Fbju95Q", "replyto": "6J6Fbju95Q", "signatures": ["ICLR.cc/2026/Conference/Submission8056/Reviewer_4tuo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8056/Reviewer_4tuo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761782059840, "cdate": 1761782059840, "tmdate": 1762920047034, "mdate": 1762920047034, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents TanDiT, a tangent-plane diffusion transformer for 360$\\degree$ panoramic image generation. Previous approaches using ERP and cube map projections, autoregressive strategies, and spherical operators struggle to achieve high-fidelity generation because seams and poles remain problematic. To address these issues, the authors introduce tangent-plane factorization for the pretrained SD3.5 to reduce distortion, consistency-aware refinement and grid optimization to remove seams, and distortion-aware metrics (TangentFID and TangentIS). The authors apply tangent-plane factorization from SphereDiff to fine-tune the DiT weights of SD3. Consistency-aware refinement includes ERP-conditioned latent denoising, circular padding (from Diffusion360 and PanoDiff), and a patchifying method for high-resolution generation. Grid optimization enhances the attention flow by calculating the cost of grid arrangement. During inference, a pretrained SR model (VARSR) is optionally used for high-resolution generation. The authors claim that the proposed model achieves SOTA performance in panoramic image generation, both qualitatively and quantitatively."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. By leveraging prior approaches, TanDiT achieves SOTA performance in panoramic image generation.\n2. The proposed metrics, TangentFID and TangentIS, appear to be promising indicators for evaluating distortion-aware panoramic image quality.\n3. Extensive experiments are conducted to validate the effectiveness of each proposed component."}, "weaknesses": {"value": "1. Limited novelty. Most components appear to be adapted from prior work, and the overall contribution seems largely engineering-oriented rather than conceptually new.\n2. The qualitative results do not show clear visual improvements over existing baselines. Please include zoom-in views to highlight the claimed advantages.\n3. What would be the performance of TanDiT if trained solely on the Matterport3D dataset? Since PanFusion and UniPano were trained only on Matterport3D, the inclusion of PolyHaven and Flickr360 introduces a fairness concern that should be clarified.\n4. Please specify which dataset or image set was used as the reference for computing evaluation metrics.\n5. The comparison currently includes fewer SOTA methods than expected. Please incorporate citations to recent SOTA models [1, 2, 3, 4, 5, 6]. At minimum, a quantitative and qualitative comparison with SMGD [5] and SaFa [6] should be added for completeness.\n6. Please provide qualitative examples corresponding to high and low TangentFID/TangentIS scores. While the user study suggests quantitative alignment with human preferences, readers cannot visually interpret how these metrics reflect perceptual quality.\n7. In Line 249, if the ERP latent is partitioned into 1024×1024 patches, does this correspond to a decoded resolution of 8192×8192? Please confirm or clarify.\n8. The term “Latent rotation” first appears in L446 without prior definition. Is this referring to the “grid optimization” step? Please ensure consistent terminology with the method section.\n9. Similarly, the term “Patch denoising” first appears in L449. Please ensure consistent terminology with the method section.\n\n[1] Tang et al., MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion, NeurIPS 2023\n\n[2] Lee et al., SyncDiffusion: Coherent Montage via Synchronized Joint Diffusions, NeurIPS 2023\n\n[3] Quattrini et al., Merging and Splitting Diffusion Paths for Semantically Coherent Panoramas, ECCV 2024\n\n[4] Lee et al., SemanticDraw: Towards Real-Time Interactive Content Creation from Image Diffusion Models, CVPR 2025\n\n[5] Sun et al., Spherical Manifold Guided Diffusion Model for Panoramic Image Generation. CVPR 2025\n\n[6] Dai et al., Latent Swap Joint Diffusion for 2D Long-Form Latent Generation, ICCV 2025"}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No concern."}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "8RtgUgolgH", "forum": "6J6Fbju95Q", "replyto": "6J6Fbju95Q", "signatures": ["ICLR.cc/2026/Conference/Submission8056/Reviewer_ypY3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8056/Reviewer_ypY3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986025963, "cdate": 1761986025963, "tmdate": 1762920046660, "mdate": 1762920046660, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method for synthesizing panoramic scenes by generating multiple grids of tangent-plane images and then stitching them together to create a seamless panoramic view. Post-processing steps are specifically designed to improve the quality of synthesized results, including an optional super-resolution module and re-noising operations. New distortion-aware metrics, TangentFID and TangentIS, are also proposed."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The writing is clear and easy to follow.\n\n2. Splitting panoramas into multiple tangent plane grid patches to reduce projection distortion seems reasonable."}, "weaknesses": {"value": "1. I am confused about the motivation and the difference between cube-map projections and the proposed tangent plane design. It seems that TanDiT degenerates into a structure similar to the standard cubemap when the number of tangent planes equals 6. \n\n2. This paper mentions several relevant works in Sec.1 and Sec.2. However, only a part of them are compared in Tab.2. I am curious why the authors do not compare TanDiT with related works, including CubeDiff[1], PanoLlama[2], PAR[3], and Omni2[4]. In L57, the author claims that AR-based methods suffer from slow inference. The authors are encouraged to conduct inference time comparisons with these methods, including PanoLlama[2] and PAR[3].\n\n3. In L154, the author claims that tangent patches approximate perspective images with minimal distortion for small field-of-view. However, splitting a whole panorama into too many patches harms global coherence. This concern is exacerbated at high resolutions, as the authors propose breaking down high-resolution images into multiple sub-images in L249.\n\n4. The refinement module seems tricky and brings unfair gains compared to other diffusion-based methods. Also, the heavy reliance on post-processing methods hinders the implementation of end-to-end models.\n\n5. In L310, the authors introduced a hyperparameter of 1.96 for calculating TangentIS and TangentFID, and I would like to know how this was calculated. Furthermore, it seems that performing cubemap projection and then calculating the FID separately could overcome the claimed seam and pole problem, and a similar method has already been implemented in MVDiffusion[5].\n\n6. Typos. PanoLlama in L56 and PanoLLaMA in L107 are inconsistent.\n\n[1] CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation.\n\n[2] PanoLlama: Generating Endless and Coherent Panoramas with Next-Token-Prediction LLMs.\n\n[3] Conditional Panoramic Image Generation via Masked Autoregressive Modeling.\n\n[4] Omni2: Unifying Omnidirectional Image Generation and Editing in An Omni Model.\n\n[5] MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion."}, "questions": {"value": "1. Can you explain why you chose SD3 rather than Flux, and train the model on a mixed dataset rather than a single dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "oJock2EVJJ", "forum": "6J6Fbju95Q", "replyto": "6J6Fbju95Q", "signatures": ["ICLR.cc/2026/Conference/Submission8056/Reviewer_HdsY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8056/Reviewer_HdsY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8056/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762360693825, "cdate": 1762360693825, "tmdate": 1762920046281, "mdate": 1762920046281, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}