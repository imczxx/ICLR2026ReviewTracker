{"id": "52oPWsb5a7", "number": 4472, "cdate": 1757686035595, "mdate": 1759898030882, "content": {"title": "Unravelling the Mechanisms of Manipulating Numbers in Language Models", "abstract": "Recent work has shown that different large language models (LLMs) converge on similar and accurate input embedding representations for numbers. These findings conflict with the documented propensity of LMs to produce erroneous outputs when dealing with numeric information. In this work, we aim to shed light on how language models manipulate numbers and quantify the lower bounds of accuracy of these mechanisms. \n\nWe find that despite surfacing errors, different language models learn interchangeable representations of numbers that are systematic, accurate and universal across their hidden states and the types of input contexts. This allows us to create universal probes for each LLM and to trace information --- including the causes of output errors --- to specific layers in LLMs' architecture. Our results show ways for more robust applications of probing methods and may inform future, addressed refinements of LLMs' architectures.", "tldr": "We show that language models use interchangeable, universal and systematic representation of numbers, allowing accurate tracing of information -- and its accuracy and robustness -- within their computation.", "keywords": ["interpretability", "probing", "representations", "numbers", "language models", "factuality"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0b2060f95b67c8b97f15b9215e561f108fc1c874.pdf", "supplementary_material": "/attachment/8f679e97851cfbecbc2fe1930c793920b7a14969.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a variety of observations on how LLMs represent numbers. Namely: that they utilize sinusoidal representations, that representations across nearby layers are similar, that multi-token numbers are represented in the final token, and that accurate responses to arithmetic questions can be localized within the model even when they are not reflected in its final output. To produce these observations, the authors primarily rely on a sinusoidal probe that injects a sinusoidal inductive bias into a linear classifier. They also make some use of TunedLens in the section that considers multi-token numbers."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "It is an interesting and important question to ask how LMs internally represent numbers and how they use these representations to make next token predictions. The authors present a set of findings that are broadly informative of these questions. Their exploration of multi-token numbers was particularly interesting and a novel contribution, despite my reservations about its interpretation."}, "weaknesses": {"value": "A central goal of this paper is to shed light on how LLMs manipulate numbers internally, in order to understand why they produce erroneous net token predictions in spite of their seemingly accurate number representations. I am not sure that these results have moved the needle on this question for two main reasons:\n\n1. No mechanistic claim about LLMs is complete if it relies only upon correlative evidence, e.g. probing. Since the point of this paper is to make a mechanistic argument rather than to present a probing technique, the lack of causal manipulations significantly detracts from its claims. It is entirely possible that LLMs form representations that can be picked up by a sinusoidal probes even when the underlying mechanism has nothing to do with a sinusoidal representation. Similarly, it is entirely possible that a representation for multi-token numbers can be found within the activations of a single token position even when such a representation has nothing to do with the model's actual manipulation of multi-token numbers. To make arguments about the mechanistic basis of behavior, the authors must be able to demonstrate how mechanism influences behavior.\n2. The paper ultimately doesn't say anything substantive about why LLMs make errors despite possessing apparently precise internal representations of numbers. While the broad overview of results is informative, it has not been tied together into a coherent picture of what one should really take away from the paper with respect to this motivating question.\n\nSome other notes:\n- I am surprised by the finding that the linear probe in fig 3 has almost 0% accuracy, even at the first layer. That is actually not super believable to me and some additional context there might be helpful.\n- Similarly I am confused about the sudden jump in fig 9 from 0% probing accuracy to much higher probing accuracy in a single layer. This is also somewhat suspicious.\n- The explanation of figure 7 is confusing -- is the offset the token position in the sequence, or the total token length of the number?\n- There is a claim in 4.2 that 'lower reliability in other operations may be caused by the model's divergence from sinusoidal representations'. The authors could investigate this by showing results for other probes. Generally it was not clear why the authors stopped using other probes beyond section 3, since it seems like it would be worthwhile to keep that comparison going.\n- The first sentence in section 3.2 'In subsection 3.1 we presented evidence that the input embeddings have certain properties related to how they encode numeric information such as being sinusoidal' seems inaccurate given that there is no mention of sinusoidal representations in section 3.1"}, "questions": {"value": "- What should I take away from the notion that representations could be sinusoidal? Why should I care specifically about a sinusoidal probe specifically, versus a more general nonlinear probe?\n-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "B1GA23u2Ep", "forum": "52oPWsb5a7", "replyto": "52oPWsb5a7", "signatures": ["ICLR.cc/2026/Conference/Submission4472/Reviewer_1Ro7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4472/Reviewer_1Ro7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4472/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761799691631, "cdate": 1761799691631, "tmdate": 1762917384872, "mdate": 1762917384872, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how LLMs internally represent and manipulate numeric information. The authors show that many different LLMs converge to almost identical sinusoidal representations of numbers, not only in their input embeddings but also across hidden layers and in natural-language contexts. Using sinusoidal probes, they study these representations layer by layer and demonstrate that they are highly systematic, transferable across layers, and robust across models. The paper further uses these probes to trace arithmetic computations inside the model and identify specific layers that introduce errors, even when earlier layers have already computed the correct result. The method requires no retraining and adds minimal overhead. Experiments on multiple models and numeric tasks reveal a universal structure in how LLMs encode numbers and show that many arithmetic failures originates from particular layers rather than from poor number representations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1）This work provides several findings about how LLMs represent numbers with extensive experiments across LLMs of different sizes and families. \n2）This work applies multiple analysis tools to validate the findings (e.g., RSA, probing, error tracking)."}, "weaknesses": {"value": "1）Regarding the unravelled numerical processing mechanism, I'm unclear about its practical implications. Could this understanding be leveraged to systematically improve LLMs' performance on mathematical tasks? \n2） It uses extensive experiments to demonstrate the existence of sinusoidal representations, but it‘s limited to explain why this phenomenon occurs. To further explore the inner reason behind phenomenon is essential to better understand LLMs.\n3） Do these findings extend to languages such as Chinese and Japanese, where number tokens follow very different segmentation patterns? What could explain the emergence of this phenomenon across languages with distinct tokenization schemes?"}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HA555m2EZY", "forum": "52oPWsb5a7", "replyto": "52oPWsb5a7", "signatures": ["ICLR.cc/2026/Conference/Submission4472/Reviewer_aHXX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4472/Reviewer_aHXX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4472/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761953338581, "cdate": 1761953338581, "tmdate": 1762917384529, "mdate": 1762917384529, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper extends a body of prior work showing that LLMs use sinusoidal/periodic features to represent numbers and perform arithmetic operations. They find a very high agreement between the representations learned by different models to represent numbers."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The results on generalization of probes are interesting and confirm that sinusoidal probes are more effective than other natural alternatives.\n\nSome intriguing results are presented, for example comparing probe accuracy across layers and investigating how information about multi-token numbers can be extracted."}, "weaknesses": {"value": "Overall the paper seems quite incremental. It is already known (as the paper states) that different LLMs learn the same type of number representations. This paper goes further by measuring exactly how closely the representations match, but this seems like only a small step in terms of contributing new knowledge. The findings on probe generalization, while interesting, recapitulate known findings about probes in general (e.g., https://arxiv.org/abs/2410.02707 https://arxiv.org/abs/2506.00823).\n\nOther findings are somewhat intriguing but it's not clear what the significance or takeaway is. For instance, Figure 6 (difference in probe weights) is interesting, but it is not clear what the significance of this finding is. The same goes for the multi-token and error tracking experiments--it's not clear what is gained by knowing, e.g., which types of layers contain information about previous tokens. For error tracking, ideally there would be a way to anticipate whether the model will make wrong predictions, or explain why it makes wrong predictions, but the current results fall short of this.\n\nThe consistency across layers (e.g., Line 353) is not very surprising given that the residual stream maintains a running sum."}, "questions": {"value": "I noticed that there are Zhou et al. 2024a and 2024b, but they're both for the same paper.\n\nLine 078: I don't think it's correct to say that Zhou et al. \"recast\" the observations of Kantamneni and Tegmark, since the Zhou paper appeared first. It's more correct to say that Kantamneni and Tegmark recast the observations of Zhou et al.\n\nLine 388: I was confused by why you used the 2000-3000th most common tokens, and not the top 1000 tokens. Alternatively, why not just choose all the number tokens in the vocabulary?\n\nLine 392: Instead of probing pieces of multi-token numbers, could you probe for the overall value of the multi-token number?\n\nFor error prediction, you are measuring whether the probe matches the model's final outputs. What if you instead plotted the probe's accuracy relative to the correct answer? Is it possible that for the red lines, the probe is predicting the correct answer but the model is incorrect?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ctzOwK8vx1", "forum": "52oPWsb5a7", "replyto": "52oPWsb5a7", "signatures": ["ICLR.cc/2026/Conference/Submission4472/Reviewer_uzDK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4472/Reviewer_uzDK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4472/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762013554776, "cdate": 1762013554776, "tmdate": 1762917384227, "mdate": 1762917384227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a series of experiments about properties of the embeddings and internal activations of numbers in large language models. Here is an overview of the key results:\n\n1. The paper shows that different LLMs learn input embeddings for numbers that have similar relative structures, as measured by a Representational Similarity Analysis.\n\n2. The paper shows that the PCA’d coordinates of number embeddings for different LLMs have similar highly weighted fourier frequencies.\n\n3. The paper shows that across different models, linear probes trained with a sinusoidal prior perform much better than linear probes trained with other priors at the task of predicting the number associated with network activations at all parts of the residual stream.\n\n4. The aforementioned sinusoidal probes are shown to be able to predict numbers in both natural language and numerical settings.\n\n5. The paper shows that an aforementioned sinusoidal probe trained on one layer can generalize to nearby layers.\n\n6. The paper shows that the strongest performance of sinusoidal probes comes from the residual stream, rather than intermediate attention and MLP outputs.\n\n7. The paper shows that sinusoidal probes can also be used to predict earlier number tokens from the last-token activations of a multi-token number. However, the accuracy of the probes decays as you try to predict earlier and earlier number tokens.\n\n8. The paper shows that the aforementioned sinusoidal probes can be used to predict the answer to simple arithmetic questions, and that these probes perform better when the model gets the answer correct vs. when it gets the answer wrong, and that the probes generally have better performance at later layers in the network."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "S1: The paper includes many different experiments providing insight into various aspects of number embeddings and activations in large language models.\n\nS2: The RSA experiment was a very elegant way of showing how different models have similar embedding structures.\n\nS3: The paper very clearly references prior work on top of which it builds on."}, "weaknesses": {"value": "W1: The biggest weakness is that the paper contained a lot of thematically related results, but no concrete cohesive framework to link the results together. In particular, it’s unclear if these results enable a practitioner or theorist to do anything they were previously not able to do.\n\nW2: I found the experiments a little difficult to parse and I had to infer a lot of the experimental details. I think spending more time being precise about the exact setup for the experiments would help."}, "questions": {"value": "Questions\n\n* Q1: For the sinusoidal probe experiments, which token indices did you train and test the probe on?\n\n* Q2: For the multi-token numbers experiment in section 4.1, did you train new sinusoidal probes for this task or use the ones described in previous sections?\n\n* Q3: For the linear probing experiments, the sinusoidal probe is just a special type of linear probe with a particular prior. I would expect that in the limit of infinite training data, a regular linear probe should also be able to match the performance of the sinusoidal probe. Is this true, or am I misunderstanding something? If I am not misunderstanding something, I would be curious to see some scaling laws or rough estimates of how much training data is necessary for the linear probe to come close to the performance of the sinusoidal probe.\n\nSuggestions\n\n* SU1: To address weakness W1, the authors could comment on or demonstrate concrete applications of their observations. The most compelling applications are ones that are not previously achievable without the insights gained from this work.\n\n* SU2: It would be helpful if you clarified the dimensions of the matrices in the sinusoidal probe in lines 174-178. I eventually figured out the dimensions by consulting prior work, but it would have saved time to include them in the paper.\n\n* SU3: I found it surprising in Figure 2(c) that random tokens would have high fourier frequency overlap. It would be interesting to show a version of plot 2(a) also for random tokens."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZPyrsUkHOl", "forum": "52oPWsb5a7", "replyto": "52oPWsb5a7", "signatures": ["ICLR.cc/2026/Conference/Submission4472/Reviewer_gZab"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4472/Reviewer_gZab"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4472/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762066836799, "cdate": 1762066836799, "tmdate": 1762917383807, "mdate": 1762917383807, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}