{"id": "hn03tZrTQs", "number": 14764, "cdate": 1758243242526, "mdate": 1759897350545, "content": {"title": "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations", "abstract": "Evaluating domain generalization (DG) for foundational models like CLIP is challenging, as web-scale pretraining data potentially covers many existing benchmarks. Consequently, current DG evaluation may neither be sufficiently challenging nor adequately test genuinely unseen data scenarios. To better assess the performance of CLIP on DG in-the-wild, a scenario where CLIP encounters challenging unseen data, we consider two approaches: (1) evaluating on 33 diverse datasets with quantified out-of-distribution (OOD) scores after fine-tuning CLIP on ImageNet, and (2) using unlearning to make CLIP 'forget' some domains as an approximation. We observe that CLIP's performance deteriorates significantly on more OOD datasets. To address this, we present CLIP-DCA (Disentangling Classification from enhanced domain Aware representations). Our approach is motivated by the observation that while standard domain invariance losses aim to make representations domain-invariant, this can be harmful to foundation models by forcing the discarding of domain-aware representations beneficial for generalization. We instead hypothesize that enhancing domain awareness is a prerequisite for effective domain-invariant classification in foundation models. CLIP-DCA identifies and enhances domain awareness within CLIP's encoders using a separate domain head and synthetically generated diverse domain data. Simultaneously, it encourages domain-invariant classification through disentanglement from the domain features. CLIP-DCA shows significant improvements within this challenging evaluation compared to existing methods, particularly on datasets that are more OOD.", "tldr": "Instead of forcing domain invariance which can harm foundation models like CLIP, we show that enhancing domain awareness and then separating it from the classification task leads to more robust domain generalization in CLIP.", "keywords": ["Domain generalization", "in the wild", "CLIP", "domain awareness", "domain invariance"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b7cad6adf6f34ac06b7387fe236c1105aba87d35.pdf", "supplementary_material": "/attachment/9aae0bec64d4553b889d07624a09678276be2ec1.zip"}, "replies": [{"content": {"summary": {"value": "They propose an approach for domain generalization, where they aim to achieve domain-invariant and domain-aware representation learning by using the CLIP model. To achieve it, they proposed to introduce the text2image model and MLLM to generate the images from the specified domains. Empirically, they show the performance improvements in ImageNet variants datasets compared to other domain generalization approaches."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. They show some improvements compared to the baselines they presented. \n\n2. The idea of domain-aware and invariant feature space sounds reasonable."}, "weaknesses": {"value": "1. The effectiveness of their approach is verified only on the ImageNet variants datasets. Probably, the effectiveness is limited to the domains that are easy to describe the styles with words. In addition, the proposed method must know the domain of the target during training, which might contradict the assumption of the DG setting. \n\n2. They need improvements in the presentation of their approach. According to line 196-210, almost all descriptions of their approach are described in the appendix. Since their proposed approach should be the main contribution of this submission, they need to describe it in the main paper. Describing the details in the appendix is okay, yet the authors move almost all parts of the proposed method to the appendix. \n\n3. Overall, the superiority of their approach over other approaches is not very clear. First, the ablation study for their proposed module is not provided. For example, the proposed approach relies a lot on the Stable Diffusion model. However, they do not provide any comparison to other approaches using the text2image model. Then, it is not clear which part of the proposed method contributes to the performance gain. \n\n4. The connection between the observations provided in Sec. 3 and the proposed method in Sec. 2 is not very clear due to the presentation."}, "questions": {"value": "Please respond to the comments on the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zUDIz7VBhf", "forum": "hn03tZrTQs", "replyto": "hn03tZrTQs", "signatures": ["ICLR.cc/2026/Conference/Submission14764/Reviewer_GiyH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14764/Reviewer_GiyH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14764/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911574014, "cdate": 1761911574014, "tmdate": 1762925120231, "mdate": 1762925120231, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This submission studies the challenge of domain generalization (DG) “in-the-wild” for foundation models such as CLIP, noting that existing DG benchmarks are likely contaminated by classes or distributions included in CLIP’s large-scale web pretraining, thus providing an overly optimistic view of OOD robustness. The authors propose two more challenging DG evaluation modes: (1) a broad suite of 33 diverse datasets with a multimodal OOD score and (2) a selective unlearning procedure to “forget” major DG benchmark domains in CLIP. Motivated by observations that naive domain-invariance harms pretrained models, the authors introduce CLIP-DCA: a fine-tuning method that simultaneously enhances domain awareness in the feature encoders and enforces domain-invariance only at the classification layer via disentanglement, leveraging synthetic domains constructed with diffusion models and MLLMs. Their method demonstrates consistent improvements in more challenging OOD settings against standard and robust CLIP baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses a critical and underexplored issue in evaluating DG for foundation models, raising urgent concerns about benchmark contamination and the resulting overestimation of generalization.\n- The breadth and diversity of the evaluation (33 datasets, supported by a quantitative OOD metric) is a significant step up from most prior works, providing a more rigorous setting for stress-testing OOD robustness.\n- The selective unlearning via adversarial training is a clever, tractable workaround for the impracticality of completely removing pretraining contamination, allowing for a controlled analysis of truly unseen domains."}, "weaknesses": {"value": "1.\tMany of the claims in the paper are largely empirical and insufficiently supported by theoretical analysis. For example, the statements “enforcing domain invariance could cause catastrophic forgetting” and “naively applying DG methods to foundation models like CLIP can cause catastrophic forgetting” are intuitively plausible but remain anecdotal without a formal theoretical justification or deeper analytical insights.\n2.\tThe proposed dual-head architecture (a classification head and a domain head) is a rather common design pattern. Similar ideas have been explored in prior works such as “Better Pseudo-label: Joint Domain-aware Label and Dual-classier for Semi-supervised Domain Generalization”. As a result, the architectural novelty of CLIP-DCA itself appears limited.\n3.\tThe experimental comparisons rely primarily on older baselines, and the study does not include several more recent DG approaches, even if they use different backbones. Furthermore, the introduction of an additional multimodal large language model (MLLM) component complicates direct comparison, potentially leading to unfair performance advantages relative to standard DG methods.\n4.\tThe writing is occasionally difficult to follow and introduces some unconventional terminology (e.g., “domain awareness”) without adequate explanation or formalization. Several loss functions are described only verbally; providing concise mathematical formulations would make the paper more accessible and rigorous.\n5.\tThe heavy use of CLIP ViT-B/32 as the only model also limits the generality of results."}, "questions": {"value": "The same as Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lGcoZSRQTM", "forum": "hn03tZrTQs", "replyto": "hn03tZrTQs", "signatures": ["ICLR.cc/2026/Conference/Submission14764/Reviewer_bd2c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14764/Reviewer_bd2c"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14764/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922250123, "cdate": 1761922250123, "tmdate": 1762925119781, "mdate": 1762925119781, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a gap in evaluating domain generalization (DG) for foundation models like CLIP, arguing that current benchmarks may overestimate true out-of-distribution (OOD) robustness due to potential domain contamination in web-scale pretraining data. The authors propose a more challenging evaluation framework termed \"DG in-the-wild\" consisting of: (1) evaluation on 33 diverse datasets with quantified multimodal OOD scores relative to ImageNet, and (2) unlearning to simulate genuinely unseen domains by making CLIP \"forget\" specific domains (DomainNet). To address the performance degradation OOD data, the paper introduces CLIP-DCA (Disentangling Classification from enhanced domain Aware representations), which encourages domain awareness in CLIP's encoders while promoting domain-invariant classification through disentanglement at the decision layer. The method uses synthetically generated domain-diverse images from diffusion models and multimodal LLM-generated  descriptions to train a domain head, which is then disentangled from the classification head. Experimental results demonstrate that CLIP-DCA outperforms existing  finetuning methods, particularly on datasets with higher OOD scores and after unlearning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Comprehensive Evaluation:** The experimental study is large and ambitious in scope. Evaluating on 33 diverse datasets, with a quantified multi-modal OOD score for each, provides a broad assessment of model robustness\n2. **Originality of unlearning-based evaluation in DG:** The unlearning-based evaluation protocol is innovative, providing a  proxy for assessing genuine OOD generalization without retraining from scratch.\n3. **Domain Simulation:** Leveraging diffusion-generated images and MLLM-generated style descriptions to simulate a wide variety of domains is a clever way to sidestep the lack of explicit “domain labels” in most real datasets\n4. **Clarity of Presentation:** Overall, the paper is well-organized and generally clear. The inclusion of Figure 2 (illustrating the CLIP-DCA architecture and loss components) and pseudocode snippets in the appendix make the training procedure easier to follow."}, "weaknesses": {"value": "1. **OOD Metric Misalignment with Research Objective:** The paper computes OOD scores based on divergence between the source (ImageNet) and target datasets, yet the central research question concerns the **distance between CLIP’s pretraining data and the target domains**. Although CLIP’s pretraining data are not publicly available, this current OOD metric risks measuring the wrong relationship. The authors could adopt or approximate pretraining-target alignment scores (as used in Teterwak et al. ICLR 2025) to provide a more meaningful quantification of generalization difficulty.\n2. **Questionable Justification for the Unlearning Framework:** While innovative, the “unlearning” procedure’s validity as a domain generalization (DG) evaluation strategy is debatable. It is unclear whether adversarially erasing domain information from CLIP truly mimics encountering unseen domains. More direct approaches such as retraining on a smaller surrogate dataset (e.g., ImageNet-1k) with domain-excluded data could provide a cleaner baseline. Without this justification, the realism and interpretability of the proposed evaluation setup remain uncertain.\n3. **No Comparison with Alternative Evaluation Strategies:** The proposed unlearning framework is not benchmarked against established DG evaluation methods, such as the *in-pretraining (IP)* vs *out-of-pretraining (OOP)* splits introduced in *“Is Large-Scale Pretraining the Secret to Good Domain Generalization” (Teterwak et al., 2025)*. Without such a comparison, it is difficult to see the benefits of the unlearning-based evaluation.\n4. **Scalability and Generalization of the Approach:** Unlearning is a coarse proxy for domain knowledge removal and would need to be repeated for each new target dataset. This limits scalability and makes the framework difficult to reproduce or extend. It remains unclear why this iterative, resource-intensive process is preferable to retraining-based or alignment-based evaluation strategies, especially when the latter can generalize across multiple domains with one training pass."}, "questions": {"value": "1. How would this framework generalize to multiple unseen domains? Would each new evaluation require redoing unlearning, and if so, how do you envision this process being adopted as a general benchmark or practical workflow?\n2. What is the computational overhead of the method? Generating synthetic images, querying an MLLM for style descriptions, maintaining multiple heads, and optimizing six loss terms likely introduce their own costs. It would be helpful to know for readers who want to extend your method\n3. Wouldn’t testing on these unlearned domains (DomainNet) provide stronger evidence that the model can recover or adapt after unlearning? Without assessing performance on the very domains that were “forgotten,” it is hard to verify whether unlearning improves robustness or simply damages useful representations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "k2CQPdpKLe", "forum": "hn03tZrTQs", "replyto": "hn03tZrTQs", "signatures": ["ICLR.cc/2026/Conference/Submission14764/Reviewer_VRcy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14764/Reviewer_VRcy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14764/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977830101, "cdate": 1761977830101, "tmdate": 1762925119446, "mdate": 1762925119446, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles domain generalization for on top of CLIP, arguing that current evaluation benchmarks may overestimate true out-of-distribution robustness due to web-scale pretraining contamination. The authors propose: 1. a more challenging evaluation framework using 33 diverse datasets with quantified OOD scores; 2. an unlearning-based approach to simulate truly unseen domains; 3. CLIP-DCA, a method that enhances domain awareness in encoders while enforcing domain invariance only at the classification layer through disentanglement. The core hypothesis is that domain awareness is a prerequisite for effective domain-invariant classification in foundation models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Important Problem Framing: The paper addresses a critical gap in CLIP evaluation;\n2. Comprehensive Evaluation Protocol: The use of 33 diverse datasets with multi-modal OOD scores;\n3. Practical Approach: Using diffusion models to generate synthetic domain data and MLLMs to extract domain descriptions is creative and addresses the lack of multi-domain data in single-source datasets like ImageNet;"}, "weaknesses": {"value": "1. Architectural Complexity vs. Gains: The method introduces multiple components (domain head, MLLM projector, 6 different loss terms, synthetic data generation pipeline), yet the improvements are often modest. \n2. Unlearning as Proxy is Questionable: The unlearning procedure maps DomainNet images to random noise, which is fundamentally different from preventing exposure during pretraining. This doesn't simulate \"unseen domains\" - it creates adversarially confused representations."}, "questions": {"value": "1. Ablation on Synthetic Data: How does performance change if you use only ImageNet with augmentations (e.g., style transfer, severe augmentations) instead of Stable Diffusion? This would test whether domain diversity or synthetic data itself drives improvements.\n2. Domain Head Usage: Why is the domain head discarded at inference? Could it provide calibration signals or be used for test-time adaptation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "i7Se8kYDIz", "forum": "hn03tZrTQs", "replyto": "hn03tZrTQs", "signatures": ["ICLR.cc/2026/Conference/Submission14764/Reviewer_3kJ7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14764/Reviewer_3kJ7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14764/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996673079, "cdate": 1761996673079, "tmdate": 1762925119003, "mdate": 1762925119003, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}