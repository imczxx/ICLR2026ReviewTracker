{"id": "4siOgDfJn1", "number": 10700, "cdate": 1758179938126, "mdate": 1762935111810, "content": {"title": "Decoupling Bidirectional Geometric Representations of 4D cost volume via 2D convolution", "abstract": "High-performance real-time stereo matching methods invariably rely on 3D regularization of the 4D cost volume, which is unfriendly to mobile devices.\nWhile methods based on 2D regularization of 3D cost volume struggles in ill-posed regions.\nIn this paper, we propose Decoupling  Bidirectional Geometric Representations of 4D cost volume and present a deployment-friendly network DBStereo, which is based on pure 2D convolutions. \nSpecifically, we first provide a thorough analysis of the decoupling characteristics of 4D cost volume. And design a lightweight decoupled bidirectional geometry aggregation block to capture spatial and disparity representation respectively.\nThrough decoupled learning, our approach  achieves real-time performance and impressive accuracy simultaneously.\nExtensive experiments demonstrate that our proposed DBStereo outperforms all existing aggregation-based methods in both  inference time and accuracy, even surpassing the iterative-based methods such as RAFT-Stereo and IGEV-Stereo.\nOur study breaks the empirical design of using 3D convolution for 4D cost volume and provides a simple yet strong baseline, i.e., the proposed decoupled aggregation paradigm, to facilitate further study.", "tldr": "", "keywords": ["stereo matching", "deep learning"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/6df67651f7423d4e6f2551df320c0d0ea1d6efcc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "1. A decoupled bidirectional aggregation strategy that treats spatial and disparity representations separately, with a proposed spatial aggregation module to capture local spatial context for each disparity level and a disparity aggregation module to possess a global receptive field.\n2. The proposed stereo matching baseline replaces computationally expensive 3D convolutions with lightweight 2D convolutions for processing the 4D cost volume, reducing computational complexity while effectively mitigating the multi-peak disparity prediction issue commonly caused by 3D convolutions."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Demonstrates real-time performance with significantly reduced computational cost by using a pure 2D convolution framework.\n2. Introduces the Bidirectional Geometry Aggregation (BGA) module, enabling clearer unimodal disparity distributions and sharper object boundaries.\n3. Presents a simple yet strong baseline that is highly deployable and extensible to multi-view stereo tasks."}, "weaknesses": {"value": "1. The discussion and explanation regarding multi-modal vs. unimodal disparity distributions are rather general. Apart from the illustrative example in Figure 1, the paper lacks quantitative analysis or empirical evidence to substantiate the claim that the proposed simple disparity aggregation effectively promotes unimodal disparity predictions.\n\n2. The paper does not include experiments that replace 3D convolutions with the proposed decoupled 2D convolutions within existing cost-volume-based stereo matching frameworks, which would be valuable for demonstrating the generality and robustness of the proposed approach.\n\n3. The comparison on the KITTI datasets (Table 2) is not sufficiently comprehensive, as it only includes relatively lightweight stereo matching models, without evaluation against a broader range of state-of-the-art or large-scale methods."}, "questions": {"value": "1. Generality of the proposed approach:\n   Can the authors clarify whether the proposed decoupled 2D convolution paradigm is generally applicable to other state-of-the-art cost-volume–based stereo matching networks (e.g., IGEV-Stereo or RAFT-Stereo)? Specifically, if the 3D convolution modules in these methods were replaced with the proposed 2D decoupled aggregation, would the model still achieve improved accuracy and real-time performance? Demonstrating such generality would strengthen the paper’s contribution.\n\n2. Empirical evidence for unimodal disparity distributions:\n   The paper claims that the disparity aggregation effectively promotes a unimodal disparity distribution, leading to clearer object boundaries. Could the authors provide more convincing qualitative and quantitative evidence, (e.g., statistical analysis of disparity distributions or additional visual comparison) to better support this claim?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SgyW2o6Aby", "forum": "4siOgDfJn1", "replyto": "4siOgDfJn1", "signatures": ["ICLR.cc/2026/Conference/Submission10700/Reviewer_HRyD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10700/Reviewer_HRyD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10700/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761660125496, "cdate": 1761660125496, "tmdate": 1762921940125, "mdate": 1762921940125, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "yZreGaG4hC", "forum": "4siOgDfJn1", "replyto": "4siOgDfJn1", "signatures": ["ICLR.cc/2026/Conference/Submission10700/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10700/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762934537595, "cdate": 1762934537595, "tmdate": 1762934537595, "mdate": 1762934537595, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a decoupled aggregation framework for stereo/MVS in which spatial aggregation and disparity aggregation are handled by two dedicated branches. Instead of heavy 3D convolutions on the cost volume, the method uses a spatial module to capture multi-scale image context and a disparity module to model long-range relationships along the disparity axis. This design aims to mitigate the limited receptive field and overfitting issues of 3D convs, while reducing parameters, memory, and latency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The paper clearly analyzes two drawbacks of 3D convolutions in learning-based MVS method, and proposes targeted solutions. The reasoning is sound and easy to follow.\n2.The decoupling idea (spatial vs. disparity) is simple and modular. It can be plugged into existing pipelines and should be compatible with common backbones and cost-volume designs.\n3.The writing is clear and well organized; the method pipeline is easy to understand and implement."}, "weaknesses": {"value": "1.The author claim improved efficiency, but Table 3 does not report the key metrics. Please add, for example, a full comparison between 3D aggregation and your 2D aggregation on the same hardware in terms of FPS, GPU memory, parameters (M).\n2.Table 5 better shows your advantages (please state clearly whether it is the small or large model), but the dataset coverage is too narrow (only DTU). It would be better to add results on more datasets (e.g., KITTI, ETH3D, Tanks&Temples if applicable) and provide more qualitative comparisons in the future main text or appendix.\n3.Generalization and “3D-conv overfitting” claim lack evidence.\nThe author state that “this coupled learning approach is susceptible to overfitting due to noise in the training data”, but there is no direct experimental support. Please add cross-dataset and zero-shot tests, for example: Train on KITTI and test zero-shot on DrivingStereo or Train on SceneFlow and test on KITTI (zero-shot). This will make the “better generalization” claim concrete."}, "questions": {"value": "1.What is the reason for the baseline mismatch between Table 1 and Table 2? In particular, why isn’t methods like IINet included in Table 2, and why are runtime numbers omitted there? Since BANet-3D appears stronger than DBStereo-M in Table 2 and their runtimes are similar in Table 1, could you add the missing results to Table 2?\n2.The author state that the coupled learning approach is susceptible to overfitting due to noise in the training data. Why does training-data noise lead to overfitting in this setting?\n3.In the “Extension to MVS” section, why compare only with iterative optimization–based and not with cost-volume–based methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9rDiGRFcME", "forum": "4siOgDfJn1", "replyto": "4siOgDfJn1", "signatures": ["ICLR.cc/2026/Conference/Submission10700/Reviewer_wvpG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10700/Reviewer_wvpG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10700/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902708104, "cdate": 1761902708104, "tmdate": 1762921939701, "mdate": 1762921939701, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript proposed DBStereo, which decouples the traditional 3D aggregation into spatial aggregation and disparity aggregation, and outperforms some existing methods in terms of inference time and speed."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The design is generalized to multi-view stereo and outperforms IterMVS and IGEV-MVS."}, "weaknesses": {"value": "1. The decomposition of 3D convolution has been used in stereo matching. For example, [1][2].\n2. Some recent works are missing in Tab 2. For example, [3][4][5][6].\n3. Could the disparity aggregation module be generalized to wider range of disparities during test? If yes, would it be possible to provide experiments, such as on Middlebury or ETH3D?\n\n[1] Separable Convolutions for Optimizing 3D Stereo Networks\n[2] FoundationStereo: Zero-Shot Stereo Matching\n[3] BridgeDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment\n[4] DEFOM-Stereo: Depth Foundation Model Based Stereo Matching\n[5] IGEV++: Iterative Multi-range Geometry Encoding Volumes for Stereo Matching\n[6] DS-Stereo: Deep-Shallow Information Interaction for Stereo Matching"}, "questions": {"value": "1. In Figure 1, what does reg_disp mean? Would it be possible to provide more examples to demonstrate the DBStereo could predict unimodal distribution, especially at object boundaries?\n2. In Figure 2, what does MSCA mean?\n3. Would it be possible to provide detailed configurations for  DBStereo-S,  DBStereo-M, and DBStereo-L, respectively?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0VIv0gEW4g", "forum": "4siOgDfJn1", "replyto": "4siOgDfJn1", "signatures": ["ICLR.cc/2026/Conference/Submission10700/Reviewer_9m1e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10700/Reviewer_9m1e"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10700/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964416891, "cdate": 1761964416891, "tmdate": 1762921939197, "mdate": 1762921939197, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors aim to design a lightweight cost aggregation network for real-time, high-quality stereo reconstruction. The paper analyzes the limitations of traditional 3D CNN–based aggregation methods and discusses the inherent inductive bias of the 4D cost volume. Based on these observations, a specially designed disparity–spatial 2D aggregation network is proposed to regularize the cost volume in a lightweight manner. The authors compare both performance and efficiency to demonstrate the effectiveness of their design."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is mostly well-written and easy to follow.  \n2. The authors validate the effectiveness of their method across multiple datasets and conduct comprehensive ablation studies to demonstrate the effectiveness of each module."}, "weaknesses": {"value": "- Claimed decoupling unconvincing: The authors claim that 3D CNNs overly couple spatial and disparity dimensions, and address this by reshaping the cost volume from (B, C, D, H, W) to (B, C×D, H, W) for 2D CNN processing. However, this reshaping does not actually decouple the two dimensions. Each spatial position still aggregates information from all disparity channels through 2D convolution, meaning spatial and disparity features remain mixed. The authors should clarify how their design effectively reduces such coupling. A more effective way to achieve decoupling is to merge the disparity dimension into the batch dimension and process each disparity level independently with 2D CNNs, as done in previous work such as [1].\n- Limited performance gain: In Table 3, the ablation study shows that the full model achieves only a modest improvement over the 3D CNN baseline; the performance improvement brought by the proposed design appears limited.\n- Limited novelty: Separating spatial and disparity aggregation in cost volumes has been widely studied. Although the authors report good performance, the contribution is limited.\n- Missing related work: Recent work LightStereo [2] designs lightweight aggregation networks based on 2D CNNs. The authors should compare both performance and efficiency with it.\n- Minor issues: Table 2 should include a runtime comparison similar to Table 1; the reference around L516–553 appears to be duplicated."}, "questions": {"value": "1. As mentioned above, the 2D convolution for spatial aggregation still effectively aggregates information across the entire disparity dimension. Compared to standard 3D convolution, this reshaping does not truly decouple spatial and disparity features; in fact, folding the disparity into the channel dimension may even increase the disparity receptive field (which may be the main source of the observed performance gain). The authors need to provide a clear explanation for this design choice and its effect.  \n2. It would be better to include comparisons of runtime and parameter count in Table 2. The performance gain of the proposed model over the baseline (4D cost + 3D CNN) is limited, and improvements in efficiency could help justify the proposed design."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yaflNQZkI4", "forum": "4siOgDfJn1", "replyto": "4siOgDfJn1", "signatures": ["ICLR.cc/2026/Conference/Submission10700/Reviewer_eV1t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10700/Reviewer_eV1t"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10700/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988511504, "cdate": 1761988511504, "tmdate": 1762921938771, "mdate": 1762921938771, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}