{"id": "VAgRyr8R5t", "number": 8826, "cdate": 1758099438509, "mdate": 1759897761573, "content": {"title": "From Broad Recall to Exact Distinction: Adversarial Curriculum Learning for Knowledge-Based VQA", "abstract": "Knowledge-based Visual Question Answering (KBVQA) aims to answer image-related questions by retrieving relevant facts from an external knowledge base, making the accuracy of knowledge retrieval crucial.\nHowever, a dominant bottleneck in existing systems is that inaccurate facts are fed to the answer generator.\nThis issue stems from two key deficiencies: (i) an initial retrieval stage that relies on global visual features, often overlooking fine-grained evidence, \nand (ii) a reranking stage that lacks the ability to differentiate between confusing candidates, making the correct answer a lower priority.\nTo address this, we propose the **Adv**ersarial **C**urriculum **L**earning (**Adv-CL**) framework, which tackles these two challenges sequentially. \nFirst, we design a Query-guided Multi-grained Recalling (QMR) strategy that leverages both global and query-guided local features to improve the recall quality and provide a diverse set of challenging negatives for reranker training.\nSubsequently, to enable exact distinction, we introduce an Adversarial Reranker Training (ART) paradigm, which compels the reranker to discern fine-grained distinctions among highly similar candidates.\nIt employs a minimax game where a modulator network acts as an adversary against the reranker, dynamically creating a curriculum of hard negatives by up-weighting candidates that most confuse the reranker. This forces the model to develop its discriminative capability.\nIn addition, we further introduce a Guarded Answer Generation (GAG) mechanism to mitigate the risk of retrieval failure exacerbating the system hallucination.\nExtensive experiments on public knowledge-based VQA benchmarks show that our method achieves state-of-the-art performance, validating the effectiveness and synergistic effect of broad recall and exact distinction.", "tldr": "We propose Adv-CL, a KBVQA framework whose adversarial reranker plays a minimax game with a modulator that dynamically spotlights the most confusing negatives, enabling fine-grained distinction among noisy candidates and achieving SOTA.", "keywords": ["Knowledge-based VQA", "Curriculum Learning", "Hard Negative Mining", "Adversarial Training"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dfa93ddaf43085574b9336084bd047abab95324f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Adv-CL (Adversarial Curriculum Learning) for knowledge-based visual question answering (KBVQA).\n\nAdv-CL includes three modules:\nQMR (Query-guided Multi-grained Recalling): combines global and local query-guided features to improve recall.\nART (Adversarial Reranker Training): uses a modulator network in a minimax game to dynamically generate hard negatives.\nGAG (Guarded Answer Generation): adds a check so the model can abstain when retrieved knowledge is unreliable.\n\nOn E-VQA and InfoSeek, Adv-CL achieves state-of-the-art results and improves both retrieval accuracy and answer reliability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The adversarial curriculum dynamically adapts hard negatives and improves reranker learning.\n2. Strong and consistent improvements on multiple benchmarks.\n3. Clear visualizations of query-guided features and modulator behavior."}, "weaknesses": {"value": "1. Each module builds on known techniques; the main innovation lies in the overall framework.\n2. The joint contribution of QMR, ART, and GAG is not clearly separated. There should be a more clear table showing how each module contributes to the overall improvement\n3. ART introduces an additional modulator transformer and adversarial optimization; the extra training cost and inference overhead (if any) are not clearly reported.\n4. Only E-VQA and InfoSeek are tested. It would strengthen generalizability to include other KBVQA or open-domain RAG datasets (e.g., OK-VQA).\n5. It seems that the literature review is not comprehensive. There are more works in OK-VQA (a popular KBVQA dataset as well) that should be mentioned and discussed."}, "questions": {"value": "How sensitive is ART to the λ parameter in Eq. 3?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "74NQAafiof", "forum": "VAgRyr8R5t", "replyto": "VAgRyr8R5t", "signatures": ["ICLR.cc/2026/Conference/Submission8826/Reviewer_Nd2P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8826/Reviewer_Nd2P"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8826/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761486698767, "cdate": 1761486698767, "tmdate": 1762920595224, "mdate": 1762920595224, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a three-stage framework called Adv-CL, which aims to improve the reliability and precision of KBVQA. The framework consists of three main components: Query-guided Multi-grained Recalling, Adversarial Re-ranker Training and Guarded Answer Generation.\nExperiments on E-VQA and InfoSeek show that Adv-CL achieves state-of-the-art performance without fine-tuning large language models."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Training with a small model has relatively low costs.\n2. GAG enhances the safety of the method.\n3. Clear description of the method."}, "weaknesses": {"value": "The methods seem to have no major issues, but there are several severe problems in the experiment.\n1. The authors conduct experiments on E-VQA and InfoSeek and they provided the details of the InfoSeek in A.1.1. As described, the InfoSeek dataset consists of a training set and three evaluation sets. The authors did not specify which evaluation set they used for evaluation. It seems reasonable to report the results of each evaluation set separately.\n2. ReflectiVA reports two settings on InfoSeek (28.3 and 40.1). Please clarify why your table uses 28.3 while ignoring 40.1?\n3. For mR2AG, they conducted experiments on each evaluation set of InfoSeek. Why did the authors only use the worst-performing InfoSeek-Human as the baseline result? As baselines, both ReflectiVA and EchoSight claim their results are from InfoSeek's validation set. It seems the authors should use mR2AG's validation set results as the baseline instead of results of InfoSeek-Human.\n4. The ablation study was conducted incompletely. The integration between the three modules in this article is not tight, so performing ablation on the full dataset should be relatively straightforward. An experimental setup similar to the main experiment is expected.\n5. The case study is too brief. It would be better for the examples to demonstrate the complete workflow, including adversarial training and GAG.\n\nMinor issues:\n- Citation Format: arXiv:2411.15041,2024a. & arXiv:2411.15041,2024b.\n- Typos: \"repectively\", A.1.4."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TOkIFOsUGr", "forum": "VAgRyr8R5t", "replyto": "VAgRyr8R5t", "signatures": ["ICLR.cc/2026/Conference/Submission8826/Reviewer_GUxB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8826/Reviewer_GUxB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8826/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761510085212, "cdate": 1761510085212, "tmdate": 1762920594389, "mdate": 1762920594389, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of accurate knowledge retrieval in Knowledge-based Visual Question Answering (KBVQA), where existing systems often feed incorrect facts into the answer generator. To improve both recall quality and reranking discrimination, the authors propose the Adversarial Curriculum Learning (Adv-CL) framework, composed of three components: (1) Query-guided Multi-grained Recalling (QMR), (2) Adversarial Reranker Training (ART), and (3) Guarded Answer Generation (GAG).  Experiments on two KBVQA benchmarks demonstrate improved performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides a new framework that integrates multiple stages (recall, reranking, and answer generation) into a unified training paradigm.\n2. The experiments cover two public KBVQA benchmarks and show the incremental effects over the current approach."}, "weaknesses": {"value": "1. The framework introduces three new modules (QMR, ART, and GAG) built on top of existing methods such as FAISS and EVA-CLIP. This significantly increases pipeline complexity and may amplify error propagation between stages. The benefit-to-complexity ratio is unclear.\n\n2. While the full model achieves performance gains, it is not convincingly shown whether all three modules are necessary. A simplified or modular version might achieve comparable performance. The improvement margins in Table 1 are modest and not consistently significant (ps. the best result on E-VQA is mR2AG which should be bolded other than the proposed methods).\n\n3. The paper does not isolate the specific contributions of the retriever and reranker components. It remains unclear how much each stage contributes to the final performance or whether the current paradigm is inherently limited by the capacity of the base models (i.e.,  LLM backbones).\n\n4. I'd like to see computational comparison over existing approaches, which is misleading in the current scope."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vu60ZNPayV", "forum": "VAgRyr8R5t", "replyto": "VAgRyr8R5t", "signatures": ["ICLR.cc/2026/Conference/Submission8826/Reviewer_ESKh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8826/Reviewer_ESKh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8826/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903768641, "cdate": 1761903768641, "tmdate": 1762920593783, "mdate": 1762920593783, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to Cost Analysis and Global Ablation"}, "comment": {"value": "**Table 1: Cost Analysis and Global Ablation**\n\n| QMR | ART | GAG | GFLOPS | TSpeed (it/s) | Latency(ms) | VQA Score |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| - | - | - | 14,334 | 2.12 | 2,793 | 41.8 |\n| $\\checkmark$ | - | - | 14,360 | 2.12 | 3,744 | 42.3 |\n| $\\checkmark$ | $\\checkmark$ | - | 14,360 | 1.90 | 3,744 | 46.0|\n| $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | 15,070 | 1.90 | 3,744 | 45.9 |\n| - | $\\checkmark$ | $\\checkmark$ | 15,044 | 1.90 | 2,793 | 42.5 |\n| $\\checkmark$ | - | $\\checkmark$ | 15,070 | 2.12 | 3,744 | 42.1|\n\nGFLOPS quantifies the total computational complexity of the model. TSpeed (it/s), representing Training Speed, is defined such that a larger numerical value corresponds to faster training time per iteration. Latency (ms) measures the millisecond-level delay experienced during the model's inference process."}}, "id": "g1MNtNh5pR", "forum": "VAgRyr8R5t", "replyto": "VAgRyr8R5t", "signatures": ["ICLR.cc/2026/Conference/Submission8826/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8826/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8826/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763721943493, "cdate": 1763721943493, "tmdate": 1763722139959, "mdate": 1763722139959, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies retrieval quality as the main bottleneck in knowledge-based VQA, by observing the significant gap between accuracies of a same generator with ground-truth knowledge vs. retrieved knowledge. To address this, authors propose Adv-CL which is a three-stage pipeline. At stage one, the method uses a VLM to select most relevant patches to the input image, query-guided multi-grained Recalling, combines global image features with local patch features to improve knowledge recall. At stage 2, Adversarial Reranker Training through a minimax optimization between a modulator and reranker, in which modulator tries to assign higher scores to the most challenging negative samples, while reranker learns to minimize the contrastive loss, facilitating learning from truly challenging negative examples. At stage 3, guarded answer generation mechanism, to assess reliability of the retrieved knowledge and enable abstention when evidence is not reliable. Evaluations on two datasets, shows that the proposed method achieves higher VQA accuracy and better recall quality than the state of the art."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Importance of the problem & key issues: The authors have identified a critical bottleneck in KBVQA models, where poor retrieval \nsignificantly deteriorates VQA performance. \n- Paper's motivation is sound. The paper grounds its design in three empirical observations: retrieval–generation gap, negative‑signal decay, and factual contamination\n- The proposed is a plug-and-play method with frozen VLM/LLMs, and does not require LLM fine-tuning.\n- The evaluations demonstrate that the proposed method achieves higher performance compared to baselines, and the method performances are consistent across three different LLMs."}, "weaknesses": {"value": "- The paper do not provide a cost analysis of the proposed method in terms of the retrieval latency, reranking cost, and end-to-end costs.\n- Details of the GAG stage are not provided. For example, details of the prompt inspection and discriminator are missing (this is important for reproducibility). Additionally, AP/AR/VAR are reported, but the trade‑off curve (against threshold) and its impact on final accuracy under different abstention policies aren’t shown.\n- In table 2, mR²AG shows a higher score (55.9) on E-VQA dataset, than the proposed. Additionally, the table mixes methods & generators, hence the baseline comparisons are not apple-to-apple comparisons. The paper should present the results in a way to facilitate comparison of methods on the same generator, for a fair comparison.\n- Moderate novelty: Multi‑grained retrieval and dynamic hard‑negative mining are known ideas. Paper's novelty lies in (a) operationalizing query‑guided patch features for the retrieval stage and (b) casting negative weighting as an adversarial curriculum with an entropy‑regularized budgeted modulator. Additionally, GAG abstention mechanism is pragmatic rather than novel."}, "questions": {"value": "- What is the cost and latencies of the method (end-to-end) and per component? \n- How is the prompt inspection for GAG designed? Is the abstention decision a binary decision made by LLM, or does the LLM return an abstention score?\n- Plot AP, AR, VAR trade-off curves across thresholds and show overall accuracy change under different abstention policies (e.g., fixed refusal budget)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WmJm2NMkxR", "forum": "VAgRyr8R5t", "replyto": "VAgRyr8R5t", "signatures": ["ICLR.cc/2026/Conference/Submission8826/Reviewer_iMhz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8826/Reviewer_iMhz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8826/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986705104, "cdate": 1761986705104, "tmdate": 1762920593094, "mdate": 1762920593094, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}