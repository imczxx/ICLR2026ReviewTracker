{"id": "ZijC94t2ku", "number": 7743, "cdate": 1758034436771, "mdate": 1759897835897, "content": {"title": "Bézier Meets Diffusion: Robust Generation Across Domains for Medical Image Segmentation", "abstract": "Training robust learning algorithms across different medical imaging modalities is challenging due to the large domain gap. Unsupervised domain adaptation (UDA) mitigates this problem by using annotated images from the source domain and unlabeled images from the target domain to train the deep models. Existing approaches often rely on GAN-based style transfer, but these methods struggle to capture cross-domain mappings in regions with high variability. In this paper, we propose a unified framework, Bézier Meets Diffusion, for cross-domain image generation. First, we introduce a Bézier-curve-based style transfer strategy that effectively reduces the domain gap between source and target domains. The transferred source images enable the training of a more robust segmentation model across domains. Thereafter, using pseudo-labels generated by this segmentation model on the target domain, we train a conditional diffusion model (CDM) to synthesize high-quality, labeled target-domain images. To mitigate the impact of noisy pseudo-labels, we further develop an uncertainty-guided score matching method that improves the robustness of CDM training. Extensive experiments on public datasets demonstrate that our approach generates realistic labeled images, significantly augmenting the target domain and improving segmentation performance.", "tldr": "", "keywords": ["Bézier curve", "Unsupervised domain adaptation", "Diffusion model", "Medical image segmentation"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3dbbd55f6e6a4e0bbaf1915adf8821efa3237e8a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes “Bézier Meets Diffusion,” a UDA framework for medical image segmentation that combines a Bézier-curve-based style transfer with an uncertainty-guided conditional diffusion model (CDM).\n\nBézier adaptation learns low-parameter, nonlinear intensity mappings between modalities by optimizing cubic Bézier control points.\n\nA CDM is trained on target-domain images conditioned on pseudo-labels from an initial model, with a new uncertainty-guided score matching loss that fuses Arg-Max and secondary predictions via pixel-wise confidence maps.\n\nExtensive experiments on BraTS, MM-WHS, and abdominal datasets show improved Dice and 95HD over GAN-based and recent UDA baselines, with ablations validating each component."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality: The combination of feature-optimized Bézier intensity transfer with uncertainty-weighted CDM training is novel and well-motivated, bridging deterministic style mapping and probabilistic generation. The uncertainty-guided score fusion across top-k predictions is a simple yet clever way to exploit predictive distributions without architectural changes.\n\nQuality: The experimental evaluation is thorough across three benchmarks with diverse baselines, clear ablations (components, k, thresholds, backbones), and uncertainty metrics (AURC, ECE, NLL) supporting the cold-start benefits. Methodological details (pseudo-code, hyperparameters, datasets) enable reproducibility and clarify design choices.\n\nClarity: The paper articulates the limitations of GAN transfer for sparse/heterogeneous lesions and motivates Bézier constraints and uncertainty fusion clearly with helpful figures. The training/inference distinction for CDM and the role of confidence thresholding are explained precisely.\n\nSignificance: Showing large gains in difficult cross-modality medical UDA (e.g., T2->T1CE) is impactful, and the approach is modular to integrate with existing UDA pipelines. The ability to synthesize labeled target-domain data at scale addresses a central bottleneck in medical imaging."}, "weaknesses": {"value": "Dependence on feature encoder: The feature-space optimization relies on a pretrained Stable Diffusion autoencoder; potential bias/mismatch to medical features is not deeply analyzed. An ablation comparing different medical encoders or self-supervised encoders, and sensitivity to encoder choice, would improve robustness claims.\n\nComputational cost and practicality: The uncertainty-guided CDM increases memory/time (acknowledged), but the paper lacks wall-clock comparisons against strong non-generative UDA methods under equal budgets. Providing training/inference cost-benefit analyses and lighter variants (e.g., k=2 default with memory-saving tricks, 2D vs. 3D trade-offs) would aid practical adoption.\n\nGeneralization scope: While results cover three datasets, it remains unclear how the Bézier mapping handles more complex modality shifts in 3D volumetric situation. Including evaluations on 3D medical UDA benchmark would strengthen claims."}, "questions": {"value": "How sensitive is Bézier adaptation to the choice/number of source prototypes and target matches, and could you provide guidance or an adaptive selection strategy?\n\nHave you evaluated different feature encoders (e.g., nnU-Net encoder, medical SSL models) for the Bézier optimization, and how does encoder choice affect both transfer quality and downstream segmentation?\n\nCan the uncertainty-guided CDM extend to 3D volumes with spatially consistent conditioning and does k=2 remain optimal in 3D given memory constraints?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YLR3in8vBe", "forum": "ZijC94t2ku", "replyto": "ZijC94t2ku", "signatures": ["ICLR.cc/2026/Conference/Submission7743/Reviewer_avBb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7743/Reviewer_avBb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7743/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761437035898, "cdate": 1761437035898, "tmdate": 1762919794110, "mdate": 1762919794110, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an unsupervised domain adaptation framework that combines Bézier curve style transfer and conditional diffusion models to address the issue of cross-domain robustness in medical image segmentation. \nIts main contributions are: \n1) Propose a Bézier curve style transfer method guided by feature space similarity, effectively reducing the style discrepancies between different imaging modalities.\n2) Build a new UDA segmentation framework and use CDM to generate annotated synthetic images to enhance the training on the target domain.\n3) Develop uncertainty-guided learning strategies to enhance the training of CDM.\n4) The presented framework can be combined with existing methods to improve performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "This paper innovatively combines Bézier curve style transfer with an uncertainty-guided conditional diffusion model, significantly improving the generation quality and domain adaptation performance in cross-modal medical image segmentation."}, "weaknesses": {"value": "1) Inconsistent Claims: The authors claim in Section 2 that their framework can generate \"our framework leverages the generative capacity of CDM, enabling us to generate an unlimited number of labeled target domain images, irrespective of the availability of target domain samples.\" However, as shown in Appendix C, the method still relies heavily on a large amount of target domain data, and the quantity of generated data is constrained by that of source domain data. \n2) Unclear Methodology: The training strategy and learnable parameters for the Bézier-curve-based style transfer module remain unclear. Furthermore, this paper does not clearly describe how the CDM enhances the segmentation model's training.\n3) Weak Contributions: In Table 4, the \"Mean-teacher\" baseline outperforms other methods shown in Table 1, including \"Ours-AD\" and \"Ours-GS\". This highlights the effectiveness of the employed pseudo-label framework but weakens the contributions of the proposed components.\n4) Unfair Comparison: The comparison in Table 6 is unfair since the competing methods are not integrated with the pseudo-label framework.\n5) Lack of Metrics: There are no quantitative metrics (e.g., PSNR, SSIM, and FID) to evaluate the quality of the generated images, making it impossible to assess the predictions of the proposed generative framework.\n6) Incomplete Comparison with SOTA: The experiment results lack a comparison with state-of-the-art UDA methods."}, "questions": {"value": "1) Please revise the claim in Section 2 for consistency.\n2) For clarity, please elaborate on the methodology.\n3) In Table 6, please display the results of other methods combined with the pseudo-label framework.\n4) Please select 1-2 quantitative metrics to evaluate the generation performance of the proposed method compared to other generative methods."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "l7yBZesrqV", "forum": "ZijC94t2ku", "replyto": "ZijC94t2ku", "signatures": ["ICLR.cc/2026/Conference/Submission7743/Reviewer_jYQr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7743/Reviewer_jYQr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7743/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761659303519, "cdate": 1761659303519, "tmdate": 1762919793788, "mdate": 1762919793788, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a cross-domain generative framework for medical image segmentation, which integrates Bézier curve–based style transfer with a conditional diffusion model. The overall pipeline includes three main components: (1) employing a nonlinear Bézier transformation to perform style transfer between different domains and reduce modality gaps; (2) applying confidence-based weighting to mitigate noise in pseudo labels; and (3) using the generated target-style samples to enhance the segmentation training."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed framework achieves consistently strong and impressive improvements across multiple benchmarks, showing clear effectiveness."}, "weaknesses": {"value": "The manuscript falls short on theoretical analysis, relying on performance improvements rather than mechanistic justification. This limitation reduces the amount of insight offered to readers and may make it less suitable for publication at ICLR.\n\nLack of Novelty: \n1. Bézier parameterization itself is not a new concept; several prior works have explored mapping-based domain adaptation.  It would benefit from including relevant studies like Su, Zixian, et al. \"Rethinking Data Augmentation for Single-Source Domain Generalization in Medical Image Segmentation,\" presented at the AAAI Conference on Artificial Intelligence in 2023.\n\n2. The novelty claimed largely rests on using Bézier curves for continuous and smooth mapping paths. However, there is a lack of detailed theoretical analysis or empirical validation to substantiate the effectiveness of such a differentiable parameterization. More comprehensive evidence or reasoning is needed to justify its proposed benefits.\n\n3.The paper lacks theoretical grounding for the \"uncertainty-guided conditional diffusion model\" proposed. It does not thoroughly explore whether the model adheres to the theoretical framework of conditional diffusion models, addressing key aspects such as convergence and variational lower bounds. For instance, it remains unclear if using the modified objective function ensures convergence to a meaningful data distribution or represents a well-defined, reversible stochastic differential equation.\n\nConcerns on the Experimental Section:\n1. The comparison studies do not include advancements from 2024 to 2025, failing to discuss or experiment with more recent methods. Including such comparisons would provide a more current context for the paper’s contributions.\n\n2.  As the proposed framework involves generative modeling, it lacks quantitative evaluation of the generated images, such as FID or LPIPS scores. Without these metrics, it is difficult to assess the visual quality and actual contribution of the generation module.\n\n3. Further clarification on additional hyperparameters and computational steps is needed.  Although the uncertainty-guided strategy is sophisticated, it introduces additional hyperparameters (e.g., confidence threshold \\delta in Algorithm 1) and computational steps like processing multiple predictions and confidence maps. The robustness of the approach might be overly dependent on careful tuning of these hyperparameters."}, "questions": {"value": "Authors are suggested to clarify the effectiveness of the Bézier parameterization and add the recent baselines (See weaknesses)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4YpI9yifAA", "forum": "ZijC94t2ku", "replyto": "ZijC94t2ku", "signatures": ["ICLR.cc/2026/Conference/Submission7743/Reviewer_YKJW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7743/Reviewer_YKJW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7743/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761720758374, "cdate": 1761720758374, "tmdate": 1762919793476, "mdate": 1762919793476, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the unsupervised domain adaptation (UDA) of medical image segmentation. The UDA problem in the context of medical image segmentation has been very widely explored. The main components of this paper include (1) a Bézier-curve-based style transfer method, guided by feature-space similarity, to reduce domain gaps across different imaging modalities (2)  a novel UDA segmentation framework that leverages a CDM to generate labeled synthetic images. (3) uncertainty-guided label correlation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The UDA problem in the context of medical image segmentation has been very widely explored, therefore new insights need be proposed.\n\n- The presentation of this paper is good.\n\n- The experimental results look promising."}, "weaknesses": {"value": "**Overall, I think the novelty of this paper is quite incremental, where several widely-adopted techniques, such as Bézier-curve-based style transformation, conditional diffusion model and uncertainty-based label correction, have been used by previous works.**\n\n- I think the title needs to be modified, where this term of \"Robust Generation Across Domains\" looks like a domain generalization task. I think the title can highlight this paper narrows to the UDA task.\n\n- Bézier-curve-based style transformation: this technique has been used by the paper namely \"Generalizable Cross-modality Medical Image Segmentation via Style Augmentation and Dual Normalization, CVPR, 2022\".\n\n- Conditional diffusion model of UDA-based medical image segmentation: please see this paper Y. Zhao, K. Lu, S. Wang, J. Lu and X. Jian, \"Unsupervised Domain Adaptation for Medical Image Segmentation with Conditional Diffusion Model,\" 2024 IEEE International Symposium on Biomedical Imaging (ISBI), Athens, Greece, 2024, pp. 1-5, doi: 10.1109/ISBI56570.2024.10635862.\n\n- Uncertainty-based label correction: please see this paper UPL-SFDA: Uncertainty-aware Pseudo Label Guided Source-Free Domain Adaptation for Medical Image Segmentation, TMI, 2023.\n\n- This paper combines these techniques and lacks obvious novelties to the community. It is very hard to acknowledge the contribution of this paper in a current version."}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "CAsEb7lRyZ", "forum": "ZijC94t2ku", "replyto": "ZijC94t2ku", "signatures": ["ICLR.cc/2026/Conference/Submission7743/Reviewer_ErFD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7743/Reviewer_ErFD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7743/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984155344, "cdate": 1761984155344, "tmdate": 1762919793075, "mdate": 1762919793075, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}