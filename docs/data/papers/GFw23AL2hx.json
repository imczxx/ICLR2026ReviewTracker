{"id": "GFw23AL2hx", "number": 4592, "cdate": 1757718830898, "mdate": 1763695667011, "content": {"title": "Truly Optimal Inverse Propensity Scoring for Off-Policy Evaluation with Multiple Loggers", "abstract": "We study off-policy evaluation (OPE) in contextual bandits with data collected from multiple logging policies. As highlighted by Agarwal et. al. 2017, there seemingly exists no IPS estimator that consistently outperforms the others in this setting. We resolve this dilemma by deriving an optimal IPS estimator with sample-dependent weights that minimize variance. Through a calculus-of-variations approach, we obtain closed-form optimal weights under the unbiasedness condition, yielding an estimator that is unbiased and achieves asymptotically optimal variance. Experiments on four benchmark datasets confirm this resolution in practice, showing that our optimal estimator and its doubly robust extension consistently outperform existing methods, including the estimator previously known to be optimal within a smaller class (Kallus et. al. 2021), across a wide range of logger mixtures and numbers of logging policies, whether the logging policies are known or estimated.", "tldr": "", "keywords": ["off-policy evaluation", "inverse propensity scoring", "multiple loggers", "variance reduction"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ebf57e04083af2828b9f774f50c492fd16eced7e.pdf", "supplementary_material": "/attachment/a52ba655084bdbd2c0e37e21902efa0cf00cd3b9.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses OPE in contextual bandits when logged data are collected from multiple heterogeneous logging policies. While existing IPS estimators, such as the naive, balanced, and weighted variants (Agarwal et al., 2017), each perform well under specific conditions, no single estimator has been shown to dominate in all cases.\n\nThe authors propose a novel Optimal IPS estimator (JoIPS) that derives sample-dependent weights minimizing estimator variance subject to unbiasedness. Using a calculus-of-variations approach, they characterize the optimal weights in closed form and show that they can be efficiently estimated via cross-fitting, yielding an unbiased and asymptotically optimal estimator.\n\nTheoretical contributions include proofs of unbiasedness and asymptotic optimality. Empirically, experiments on four benchmark datasets (OptDigits, SatImage, PenDigits, Letter) demonstrate that the proposed method achieves substantial reductions in relative RMSE compared to prior IPS baselines, both when logging policies are known and when they are estimated."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper offers a mathematically principled derivation of optimal sample-dependent weights for the IPS estimator under multiple logging policies.\n\nThe theoretical analysis is rigorous. Theorems 4.1–5.2 establish unbiasedness, consistency, and asymptotic efficiency clearly and are backed by formal proofs in the appendix.\n\n\nExperimental results are thorough, covering both known and estimated logging policies, multiple datasets, and a range of stratum ratios. The empirical trends are consistent with theory, showing robustness and variance reduction."}, "weaknesses": {"value": "The analysis focuses on asymptotic optimality. However, in realistic OPE tasks, finite-sample variance and bias–variance tradeoffs are critical. The paper could be strengthened by including a discussion or simulation study quantifying finite-sample deviations from the asymptotic limit.\n\nWhile the focus is within the IPS class, including DR or model-based estimators (e.g., Kallus et al., 2021) would help clarify whether the practical gains of JoIPS persist relative to the broader family of OPE estimators.\n\nThe mapping from classification datasets to contextual bandits uses deterministic classifiers and binary rewards. While common in OPE benchmarks, this setup limits the generality of conclusions for stochastic or real-world environments where reward noise and policy stochasticity interact."}, "questions": {"value": "Since Kallus et al. (2021) derived efficiency bounds for DR estimators, could the calculus-of-variations framework be extended to derive “optimal doubly robust weights”? This would strengthen the connection between JoIPS and broader semiparametric efficiency theory.\n\n\nSolving Tα = c via least squares is efficient for small K, but how does complexity scale for large numbers of loggers (e.g., K > 100)? Are there approximations or regularizations for high-dimensional logging mixtures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "w2pkEBAafE", "forum": "GFw23AL2hx", "replyto": "GFw23AL2hx", "signatures": ["ICLR.cc/2026/Conference/Submission4592/Reviewer_7rWW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4592/Reviewer_7rWW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4592/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760697423629, "cdate": 1760697423629, "tmdate": 1762917459540, "mdate": 1762917459540, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles off-policy evaluation with data from multiple logging policies. It introduces a generalized IPS family with sample-dependent weights (\\$w_i(s,a,r)\\$), derives the closed-form, variance-minimizing weights $w^\\*\\_i(s,a,r)$ within that family, and provides a feasible cross-fitted implementation. The resulting feasible estimator is unbiased, consistent, and asymptotically variance-optimal within the introduced generalized IPS family. On four UCI-to-bandit benchmarks, it consistently reduces the relative RMSE compared to related baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**S1.** Clear formulation of the multi-logger OPE problem and of the generalized weighted IPS estimator family.\n\n**S2.** Closed-form expression for the optimal sample-dependent weights.\n\n**S3.** Feasible cross-fitted implementation (Alg. 1) follows best practice of keeping estimation independent of evaluation, and enjoys properties like unbiasedness, consistency, and asymptotic variance optimality within the introduced generalized weighted IPS class.\n\n**S4.** Empirical improvements over baselines in different scenarios."}, "weaknesses": {"value": "**W1.** Optimality here is restricted to the proposed generalized weighted IPS class. In contrast, *Kallus et al. (2021)* established global semiparametric efficiency, offering stronger theoretical guarantees, while being much more efficient computationally (see below).\n\n**W2.** The proposed estimator is considerably more expensive: roughly speaking, I think *Kallus (2021)* scales as \\$O(ZN)\\$, whereas the current method scales as \\$O(ZNK + ZK^3)\\$, becoming costly as the number of loggers \\$K\\$ grows. A clock-time comparison with varying \\$K\\$ is needed to quantify this overhead and demonstrate scalability in practice.\n\n**W3.** Experiments involve only two logging policies, despite the algorithm’s complexity scaling with \\$K\\$. Experiments do not include comparisons against *Kallus (2021)*'s estimator (they only compare to *Agarwal et al. (2017)* combined with *Kallus (2021)* feasibility trick). *Kallus (2021)* should be included as it attains the global efficiency bound. I understand that the focus here is on IPS methods and *Kallus (2021)*  is doubly robust (DR), but in practice, the goal of OPE is to minimize evaluation error (e.g., RMSE) regardless of estimator family, which is why most IPS papers include DR and direct method (DM) baselines for completeness.\n\n**Missing references.** This is not a major weakness, but the paper omits key foundational IPS references such as [1, 2, 3] and some others. Additionally, while not directly addressing multiple loggers, regularized IPS represents a major variance reduction direction in off-policy evaluation research that warrants mention (see recent work on self-normalization, implicit exploration, exponential smoothing, pessimistic regularization, and many more [4, 5, 6, 7]).\n\n[1] https://www.stat.cmu.edu/~brian/905-2008/papers/Horvitz-Thompson-1952-jasa.pdf\n\n[2] https://ionides.github.io/pubs/ionides08-jcgs.pdf\n\n[3] https://arxiv.org/pdf/1503.02834\n\n[4] https://papers.nips.cc/paper_files/paper/2015/file/39027dfad5138c9ca0c474d71db915c3-Paper.pdf (NeurIPS)\n\n[5] https://proceedings.neurips.cc/paper/2021/file/4476b929e30dd0c4e8bdbcc82c6ba23a-Paper.pdf (NeurIPS)\n\n[6] https://arxiv.org/pdf/2406.03434 (UAI)\n\n[7] https://arxiv.org/pdf/2006.10460 (AISTATS)"}, "questions": {"value": "**Q1.** The paper explicitly states only one assumption, but others may be implicit (e.g., finite variance?, the optimal weights involve $1/r$, suggesting an implicit assumption that $r \\neq 0$, etc.). Since I did not read the proofs in detail, could the authors clearly list all assumptions required for the main theorems, in the same explicit manner as Assumption 5.1?\n\n**Q2.** Section 5.2 assumes the existence of a solution to $T\\alpha = c$. Could the authors discuss what conditions on the bandit environment and policies ensure the existence of such $\\alpha$?\n\n**Q3.** In line 772, the paper claims that the functional in Lemma 5.1 is convex in $w_i$. This is not immediately clear to me, could the authors eplxain why?\n\n**Q4.** Finally, could the authors please address the requests outlined in the Weaknesses section?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4DeIhKEmmH", "forum": "GFw23AL2hx", "replyto": "GFw23AL2hx", "signatures": ["ICLR.cc/2026/Conference/Submission4592/Reviewer_ykGJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4592/Reviewer_ykGJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4592/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761394674489, "cdate": 1761394674489, "tmdate": 1762917459271, "mdate": 1762917459271, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies how to reduce the variance of the inverse propensity scoring (IPS)-based off-policy evaluation (OPE) estimator when using data collected from multiple logging policies. Specifically, the paper first derives the conditions for enabling unbiased estimation and then derives the closed-form solution that minimizes the variance. The solution requires some empirical estimation as a plug-in component, and the paper also proposed a cross-fitting approach to estimate such plug-in parameters. The experiment results show that the proposed approach works better than other IPS-based OPE estimators for the multiple logging scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper presents a nice theoretical analysis and reasoning about how to reduce the variance of OPE estimators in the multiple logging situation.\n\n- A good point of the proposed method is that the closed-form solution is presented, and the necessary parameters can be estimated from data.\n\n- The experiment results demonstrate that the proposed method outperforms the baselines in the accuracy of evaluation with a varying ratio of data mixing. \n\n- Manuscript is well-written, easy to follow."}, "weaknesses": {"value": "- While the paper provides experiments with varying ratio of data from two logging policies; an eps-greedy policy (near-deterministic) and an eps-greedy policy (near uniform random), it would be useful to see the mixture of more complex policies, e.g., softmax.\n\n- Some qualitative analysis should be useful -- intuitively, how is the weight allocation different between the proposed method and others? Investigating what makes the difference in the variance can be insightful."}, "questions": {"value": "- One thing I didn't understand is that the weight of each data sample depends on the indices, which are (randomly) assigned to the data. This looks a bit weird because the sample weight may change depending on the ordering of the data, while the solution should be the variance minimizer. Would this point be clarified?\n\n- Intuitively, how can the weight allocation be different between the proposed method and others? (e.g., A toy example explaining different weight allocation can be useful.)\n\nNote: I checked the proof of unbiasedness in the Appendix, but didn't carefully check the theoretical derivation of other parts in the paper (appeared reasonable at a glance)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DCFdqdhIOg", "forum": "GFw23AL2hx", "replyto": "GFw23AL2hx", "signatures": ["ICLR.cc/2026/Conference/Submission4592/Reviewer_qjNx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4592/Reviewer_qjNx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4592/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761679326479, "cdate": 1761679326479, "tmdate": 1762917458998, "mdate": 1762917458998, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provide a optimal ips estimator for the Off-Policy Evaluation with Multiple Loggers. The weighted IPS is built upon sample-dependent weights that minimize variance, following theoretical analysis of minimizing the variance of the IPS. They also provide a feasible solution through previous work [1]. Experimental results show the effectiveness of the proposed method. \n\n[1] Optimal off-policy evaluation from multiple logging policies"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The motivation of the paper is clear and also the method is straightforward but seems effective. The theoretical analysis and sounds and the algorithm are well-connected, where the algorithm attempts to minimize the variance of the IPS estimator. Also the experimental results are promising."}, "weaknesses": {"value": "The presentation of the algorithm and theorem, maybe adding a few remark will help. It is a little bit hard to follow, especially on eq (7) which basically comes out of no where but without explaination which part means what."}, "questions": {"value": "1. Regarding the setting, do you know from which logging policy the data comes? What if you do not know that? \n\n2, just for curiosity, is it possible that this can be extended to or plug into, for example, the DR estimator or other advanced OPE methods? Does a similar property hold, or do you need to derive it from equation 12? Also, another question is that if you derive the 'optimal DR estimator' using similar technique from eq 12,  but the doubly robust estimator is already low variance estimator compared with IPS, and whether minimzing the variance  is helpfu here? \n\n3, For the experimental results, is it possible to compare with other OPE like DR? \n\n4, For the lemma 5.1, is there any intuitive explaination why the w can reduce the variance, especially which part of the variance will be reduced? \n\n5, what is the performance under large shift?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "S3e8xnNxUj", "forum": "GFw23AL2hx", "replyto": "GFw23AL2hx", "signatures": ["ICLR.cc/2026/Conference/Submission4592/Reviewer_Zykz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4592/Reviewer_Zykz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4592/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943053004, "cdate": 1761943053004, "tmdate": 1762917458577, "mdate": 1762917458577, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}