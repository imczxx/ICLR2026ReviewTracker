{"id": "9u9PfpF7Jm", "number": 4169, "cdate": 1757619567581, "mdate": 1759898049295, "content": {"title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles", "abstract": "We propose a test-time defense mechanism against adversarial attacks: imperceptible image perturbations that significantly alter the predictions of a model. Unlike existing methods that rely on feature filtering or smoothing, which can lead to information loss, we propose to \"combat noise with noise'' by leveraging stochastic resonance to enhance robustness while minimizing information loss. Our approach introduces small translational perturbations to the input image, aligns the transformed feature embeddings, and aggregates them before mapping back to the original reference image. This can be expressed in a closed-form formula, which can be deployed on diverse existing network architectures without introducing additional network modules or fine-tuning for specific attack types. The resulting method is entirely training-free, architecture-agnostic, and attack-agnostic. Empirical results show state-of-the-art robustness on image classification and, for the first time, establish a generic test-time defense for dense prediction tasks, including stereo matching and optical flow, highlighting the method’s versatility and practicality. Specifically, relative to clean (unattacked) performance, our method recovers up to 68.1% of the accuracy loss on image classification, 71.9% on stereo matching, and 29.2% on optical flow under different types of adversarial attacks.", "tldr": "We combat adversarial noise with purposeful perturbations.", "keywords": ["Adversarial Attack", "Latent Space Ensemble"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/560592b1b75b3081b026f3b3cb1827c4d85f7a01.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a training-free test-time defense mechanism based on stochastic resonance (SR) in latent feature space. The method perturbs input images with small translations, aligns the resulting embeddings, and aggregates them to improve robustness without retraining or architectural changes. Experiments on classification (CIFAR-10, ImageNet) and dense prediction tasks (stereo matching, optical flow) are provided."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea of “combat noise with noise” via stochastic resonance is conceptually novel and elegantly simple.\n\n2. The framework is easy to integrate into existing architectures and does not require retraining.\n\n3. The paper provides extensive experimental results across multiple tasks, including dense prediction, which is less explored in adversarial defense.\n\nThese strengths collectively highlight the method’s potential practical value as a lightweight and versatile test-time defense strategy."}, "weaknesses": {"value": "1. This paper lacks a rigorous theoretical foundation to support the claimed robustness improvement. While the intuition of “combating noise with noise” is interesting, no analytical explanation or formal proof is showing why the proposed stochastic resonance mechanism effectively suppresses adversarial perturbations.\n\n2. Although this method is described as training-free, architecture-agnostic, and attack-agnostic, the experimental scope is confined to same-dataset evaluations. The experiments does not include critical transfer-setting tests."}, "questions": {"value": "1. See in W1. Could the authors provide at least a theoretical analysis?\n\n2. See in W2. How would the proposed approach perform under realistic transfer settings, such as cross-dataset, cross-resolution, or cross-style experiments?\n\n3. The main schematic (Figure 1) is not referenced in the method section.\n\n4. Clarify whether the claimed robustness persists against unseen attack families.\n\nThe motivation of the article is quite reasonable, if all of my concern are addressed, I will increase my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ad4TQ98maq", "forum": "9u9PfpF7Jm", "replyto": "9u9PfpF7Jm", "signatures": ["ICLR.cc/2026/Conference/Submission4169/Reviewer_HimK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4169/Reviewer_HimK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4169/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761000765918, "cdate": 1761000765918, "tmdate": 1762917211254, "mdate": 1762917211254, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Additional Theoretical Analysis"}, "comment": {"value": "Thanks to the reviewers for the constructive comments. As requested by reviewers `YvRA` and `HimK`, we provide additional theoretical analysis for our method. We will provide the revised manuscript towards the end of the author-reviewer discussion period. Note that, the theoretical foundations of Stochastic Resonance have been long established in statistical physics, summarised for instance in https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.70.223\n. Our work applies this concept specifically to trained embeddings. \n\nIn the context of adversarial perturbations, modern deep networks often exhibit poor local Lipschitz regularity, where small input perturbations induce disproportionately large latent-space changes, exploited by adversaries.\n\nIf $x$ is a clean signal (an image in our case) and $\\tilde{x} = x + n(x)$ its adversarially perturbed counterpart. Let $\\varphi$ denote the encoder up to the SR layer. Using a discretized set of translations $ \\lbrace g_i \\rbrace^N_{i=1} \\subset G $ and their corresponding inverse $ g^{-1}_i$, the SR feature is:\n\n$$\n\\hat{\\varphi}(x)=\\frac{1}{N}\\sum_{i=1}^N g^{-1}\\_{i}\\varphi(g_i x), \\qquad \\hat{\\varphi}(\\tilde{x})=\\frac{1}{N} \\sum_{i=1}^N g^{-1}_{i}\\varphi(g_i \\tilde{x})\n$$\n\nThe first-order approximation yields:\n\n$$\n\\varphi(g_i \\tilde{x}) = \\varphi(g_i x + g_i n(x))\n\\approx \\varphi(g_i x) + J_{g_i x}[g_i n(x)],\n$$\n\nwhere $J_{g_i x}$ is the Jacobian of $\\varphi$ at $g_i x$. We have\n\n$$\n\\Delta_{\\mathrm{SR}}(x)\n=\\hat{\\varphi}(\\tilde{x})-\\hat{\\varphi}(x)\n\\approx \\frac{1}{N}\\sum_{i=1}^N g^{-1}_{i} J\\_{g_i x} [g_i n(x)].\n$$\n\nIn contrast, a standard encoder responds as:\n\n$$\n\\Delta_{\\mathrm{base}}(x)\n=\\varphi(\\tilde{x})-\\varphi(x)\n\\approx J_x n(x),\n$$\n\nwhich is dominated by the local worst-case Lipschitz direction at $x$.\n\nThe terms $g^{-1}\\_{i}J\\_{g_i x}[g_i n(x)]$ in the SR expansion are generally not aligned across $i$:\n(1) the adversarial noise $n(x)$ is crafted for a single input $x$, so under translation it is re-aliased into different patches;\n(2) the Jacobian $J_{g_i x}$ varies across $i$, so the maximally-amplifying direction at $x$ is not simultaneously amplifying for all transformed inputs;\n(3) the signal terms $\\varphi(g_i x)$ align under the inverse warp, while the Jacobian–noise terms do not.\n\nUnder mild decorrelation assumptions:\n\n$$\n\\left|\\frac{1}{N}\\sum_{i=1}^N v_i\\right|^2\n\\sim \\frac{1}{N}\\mathbb{E}[v_i^2],\n\\qquad\nv_i=g^{-1}\\_{i}J\\_{g_i x}[g_i n(x)],\n$$\n\nso the effective Lipschitz constant of the SR map decreases by approximately $1/\\sqrt{N} \\sim 1/d$ where $d$ is the SR level in our paper. Thus, SR suppresses adversarially amplified latent-space outliers while preserving coherent scene structure.\n\nThis analysis is also validated empirically. Using a pre-trained DINO encoder, we add adversarial perturbations that maximally distort the latent embedding, and then apply SR with increasing translation radii $d$. The $L_1$ distance between adversarial and clean embeddings decreases as:\n\nd = 0 (no SR defense): $L_1=12.30$\n\nd = 1: $L_1=5.29$\n\nd = 2: $L_1=3.50$\n\nd = 3: $L_1=2.64$\n\nd = 4: $L_1=2.12$\n\nwhich closely follows the expected $1/\\sqrt{N}$ decay pattern. A complete analysis of SR is beyond the scope of this paper but hopefully this analysis helps reassure the reader that the framework is sound."}}, "id": "rdrKjS89Iw", "forum": "9u9PfpF7Jm", "replyto": "9u9PfpF7Jm", "signatures": ["ICLR.cc/2026/Conference/Submission4169/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4169/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4169/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763701041504, "cdate": 1763701041504, "tmdate": 1763701990997, "mdate": 1763701990997, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper uses the concept of stochastic resonance (SR) from signal processing as a test-time defense strategy. The attacked image is translated on an integer-pixel basis and combined with SR by encoding the translated images, upsampling, and then inversely translating them. These results are then aggregated for the downstream trask prediction. This approach is applied to trained networks during inference time, with the focus on applying this technique on already adversarially trained networks. Experiments conducted on CIFAR-10 using common adversarial attacks, such as PGD-20/100, in combination with adversarially trained ResNet variants, demonstrate improved defense abilities. Additionally, this method is also used for stereo matching and optical flow defenses."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- This paper applies a classical signal processing method in a novel setting for test-time defense\n- Various settings and examples including ablation about the level of translations and which network layer to use as a feature extractor are shown\n- The proposed method is flexible to any (adversarially) pretrained network, making it eventually applicable to new types of networks and training schemes\n- The proposed method shows advancements over existing defense techniques"}, "weaknesses": {"value": "- The experiments miss comparisons to the more widely used AutoAttack (Croce and Hein, 2020).\n- Table 2 and 3 lack a comparison to other approaches that don’t use adversarial training.\n- Different layer features used as the embedding lead to different results, which makes sense, but this constraint limits the easy usage of this method. \n- This paper primarily focusses on CNNs. Is there a reason for this? Current methods often utilise transformer-based networks due to their inherent robustness from the start. Providing more information on how the proposed approach performs across different networks, while maintaining consistent strategies (such as the type of adversarial training), would better demonstrate the strengths and weaknesses of the proposed method. \n- Ukita and Kenichi, 2023 also explore feature-space stochasticity as both an adversarial attack and a defense method. Since this paper focusses explicitly on feature-space adversarial examples, it would be beneficial to include either the adversarial attack or a comparison to this defense strategy. \n- Section 3 needs improvement. It’s difficult to grasp the novelty of the paper and how SR is used. The explanation is tedious to understand.\n\n\n*Smaller points*:\n- Figure 2 is too small and hard to read\n- The captions are in an unusual style.\n\n*Missing literature*: \n- Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks, F. Croce and M. Hein,  ICML 2020\n- Boosting Adversarial Robustness with CLAT: Criticality-Leveraged Adversarial Training, B. Gopal, H. Yang,  J. Zhang,  M. Horton, Y. Chen, ICML 25\n- An automated robust fine-tuning framework, X. Xu, J. Zhang, M. Autolora Kankanhalli, ICLR 2024 \n- Adversarial attacks and  defenses using feature-space stochasticity, J. Ukita and O. Kenichi,  Neural Netw., Vol. 167, pp. 875-889, 2023"}, "questions": {"value": "- Which $L_p$ norms were used? These specifics are missing\n- How many runs were conducted?  \n- A clarification which noise distribution is used for SR is needed- Line 260f suggests that the translations are the perturbation. So, is there any noise added during SR as in SRT, as mentioned in Lao et al. (2024)? Providing more information about this would make the approach clearer.\n- How about other attacks and corruptions at test time, such as CIFAR-10-C?\n- What is the optimal layer depth for this approach? \n- In general I feel like the SR section and thus the method section itself could need more clarification, for easier accessing the novelty of this paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vCE43uqvSE", "forum": "9u9PfpF7Jm", "replyto": "9u9PfpF7Jm", "signatures": ["ICLR.cc/2026/Conference/Submission4169/Reviewer_2PRW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4169/Reviewer_2PRW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4169/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761749359265, "cdate": 1761749359265, "tmdate": 1762917209964, "mdate": 1762917209964, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a test-time defense against adversarial perturbations by latent ensembling via stochastic resonance. The defense is training-free, plug-and-play at inference, and can be easily applied to e.g., an encoder block, yielding improved robustness to multiple standard adversarial attacks. On a technical level, it averages latent embeddings of purposefully transformed inputs (small integer-pixel translations) to cancel the effect of adversarial noise. Experiments cover diverse applications and models, ranging from image classification (CIFAR-10, ImageNet; multiple backbones) and stereo matching (PSMNet) to optical flow (RAFT). The paper shows that defended method remain competitive under adaptive worst-case attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "**Originality:** Using stochastic resonance as purposeful perturbations to reduce the influence of extraneous adversarial noise is elegant and grounded in signal-processing intuition (aliasing vs. adversarial noise). The formalization and Eq. (1) are clear. It is a quite neat conceptual twist.\n\n**Quality:** The quality of the experimental evaluation is high. It covers a broad range of problems, namely classification (CIFAR-10 with AT/TRADES/MART; ImageNet with ResNet-50 and ViT-Small), stereo (PSMNet), and optical flow (RAFT), though not many models per task (see weaknesses). The proposed method outperforms strong baselines and TTE, showing consistent gains over FD/CAS/CIFS/FSR and output-space TTE. The experiments also includes a worst-case analysis demonstrating that the method remains robust under these adaptive attacks, which is technical rigorous but often overlooked step when proposing new defense mechanisms.\n\n**Clarity:** The paper is well written and easy to read, with figures and tables that support the made claims.\n\n**Significance:** The proposal of a training-free and plug-and-play defense against pixel-level attacks, which performs well across various problems, is a significant step towards defending methods from pixel-noise. The method design makes it easy to apply across different backbones and tasks (though more details would be helpful, see weaknesses), and ensembling features in shallow layers helps reduce costs. Especially the tests on stereo and optical flow are great additions to the classification problem, and demonstrate the broad applicability of the method."}, "weaknesses": {"value": "**Experiments**\n- While a few classification models were tested, only one model is tested for the stereo and optical flow problems. To demonstrate the broad applicability, it would help to report results for more methods on those domains.\n- The method and especially the group actions are introduced very generally, but most results rely on integer translations only. It would be nice to also consider broader, learned or task-symmetry-aware groups. Furthermore, for rotations, robustness degrades at higher SR levels (Table 4) and is slower due to interpolation. This undercuts the “on-demand scaling” claim as currently phrased in the discussion.\n- The compute analysis is not comprehensive enough. The paper reports a delta time (+0.06 s at SR-3 on 1080Ti), but no baseline absolute inference times or throughput (img/s) across models and SR levels, relative increase in inference time, or memory footprint analysis, and no breakdown of parallelism limits on commodity GPUs. Additional statistics on compute would be helpful.\n\n**Plug-and-Play nature of method**\n- As evidence of the method’s plug-and-play nature, I would be helpful to be more specific on how to implement the method for optical flow or stereo methods, and if this implementation would be different for individual optical flow methods.\n\n**Scope and Related Work**\n- The positioning of this work vs. prior TTE could be sharper. The paper states output-space ensembling (TTE) is a special case and less effective, but an experiment for direct comparison is only done for classification on CIFAR-10. A more detailed comparison is only hinted at in lines 417 ff.\n- There are a few more references, listed under Questions - minor comments, that appear relevant to the paper’s scope."}, "questions": {"value": "- L.451 reports +0.06 s at SR-3 on ResNet-50 (1080Ti) and 0.095 s sequentially. What are the baseline inference times ? And would it be possible to report memory usage and throughput (img/s) across SR levels?\n- L.458 contrasts inference-time cost with training time of adversarial training (6x longer than vanilla training). For a budget comparison that is relevant for deployment, what is the comparison to e.g., test-time TTE or feature-denoising methods at the same latency?\n- Regarding the claimed “on-demand scaling” (L.460): Table 4 shows monotonic gains for translations but drops for rotations at higher SR. Is there a bound when more SR helps? Also, I would appreciate clarification on the claim that “on-demand scaling” does not extend to rotations and possibly other group transformations.\n- It would be helpful to provide more details on the optical flow implementation. For the RAFT experiments, was the same integer translation applied to both frames? Where do inverse alignment and aggregation occur (pre-correlation vs post-correlation)? \n- The paper argues that PGD is stronger than localized patch attacks for optical flow. Do SR gains persist for localized patch attacks on stereo and optical flow? It would be especially interesting to see whether the method works for localized attacks as well, as it is to be expected to work better with global perturbations like PGD. As localized attacks are cases where spatial ensembling might behave differently or fail, this test might lead to interesting insights.\n\n**Minor Comments:**\n- Figure 1 is not referenced inline\n- Inline citations miss parenthesis\n- CosPGD [Agnihotri et al., ICML’24] and DistractingDownpour [Schmalfuss et al., ICCV’23] are other established attacks for optical flow\n- Static defenses have also been studied specifically for optical flow in [Scheurer et al. “Detection defenses: An empty promise against adversarial patch attacks on optical flow” WACV’24]\n- The idea of countering adversarial noise with noise was also used for action recognition in [Zhang et al. “Adversarially Robust Video Perception by Seeing Motion”, Arxiv’22]."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RnS2XPO5LJ", "forum": "9u9PfpF7Jm", "replyto": "9u9PfpF7Jm", "signatures": ["ICLR.cc/2026/Conference/Submission4169/Reviewer_6Kns"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4169/Reviewer_6Kns"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4169/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761769625895, "cdate": 1761769625895, "tmdate": 1762917209430, "mdate": 1762917209430, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel test-time defense mechanism against adversarial attacks by leveraging the principle of stochastic resonance. The core idea of \"combating noise with noise\" is innovative. The method's key strengths are its training-free, architecture-agnostic, and attack-agnostic nature. The experimental validation is particularly compelling, demonstrating state-of-the-art robustness not only in image classification but also, for the first time, providing a viable test-time defense for dense prediction tasks like stereo matching and optical flow. The following are the modification suggestions."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1.The paper introduces a novel test-time defense based on stochastic resonance, creatively applying a classical signal processing principle to adversarial robustness. It is also among the first to extend such defenses to dense prediction tasks, opening a new research avenue.\n2.The method is technically sound and well-validated through extensive experiments across datasets, architectures, and attack types. The consistent performance gains and ablation studies support the robustness and generality of the approach.\n3.The paper is clearly structured and well-written, with intuitive explanations and well-designed figures that make the underlying ideas of stochastic resonance easy to understand.\n4.The approach is training-free, architecture-agnostic, and broadly applicable, providing both practical robustness gains and conceptual insights that can inspire future research on stochastic mechanisms in machine learning."}, "weaknesses": {"value": "1.The paper lacks a formal explanation of how stochastic resonance enhances robustness; adding a theoretical model linking perturbation strength to robustness would improve clarity.\n2.The trade-off between robustness and inference time is not fully analyzed; quantitative results on computational cost would strengthen practicality claims.\n3.The paper could elaborate on deployment challenges under strict computational constraints."}, "questions": {"value": "1.Could the authors provide a clearer theoretical explanation of why stochastic resonance improves robustness, and how the resonance level ddd quantitatively relates to robustness gains?\n2.How does the transformation ensemble preserve natural image statistics while disrupting adversarial noise—can this be demonstrated or formalized?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XbVM1sSrrR", "forum": "9u9PfpF7Jm", "replyto": "9u9PfpF7Jm", "signatures": ["ICLR.cc/2026/Conference/Submission4169/Reviewer_YvRA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4169/Reviewer_YvRA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4169/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911587351, "cdate": 1761911587351, "tmdate": 1762917209164, "mdate": 1762917209164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}