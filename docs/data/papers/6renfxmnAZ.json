{"id": "6renfxmnAZ", "number": 535, "cdate": 1756744830919, "mdate": 1763135771601, "content": {"title": "Causal Representation Meets Stochastic Modeling under Generic Geometry", "abstract": "Learning meaningful causal representations from observations has emerged as a crucial task for facilitating machine learning applications and driving scientific discoveries in fields such as climate science, biology, and physics. This process involves disentangling high-level latent variables and their causal relationships from low-level observations. Previous work in this area that achieves identifiability typically focuses on cases where the observations are either i.i.d. or follow a latent discrete-time process. Nevertheless, many real-world settings require the identification of latent variables that are stochastic processes (e.g., a multivariate point process). To this end, we develop identifiable causal representation learning for continuous-time latent stochastic point processes. We study the theoretical identifiability by analyzing the geometry of the parameter space. Furthermore, based on this, we develop MUTATE, a variational autoencoder framework with a time-adaptive transition module to evaluate stochastic dynamics. Across simulated and empirical studies, we find that MUTATE has the potential to answer questions in numerous scientific fields.", "tldr": "", "keywords": ["representation learning", "geometry", "graphical models", "causality"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b83e312cee2c192ccc2a137082a49398aaafed0f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper establishes novel connections between causal representation learning (CRL) and the modeling of latent stochastic processes in dynamical systems. Specifically, it provides identifiability results for stochastic processes that can be represented as INAR processes under a weak convergence assumption, showing when the latent causal structure is recoverable.\nBuilding upon these results, the authors introduce a variational autoencoder framework (MUTATE), which features a time-adaptive transition module designed to learn causal latent variables in stochastic dynamic systems. The method is evaluated on synthetic datasets, comparing the identifiability of the recovered latent representations (measured via Mean Correlation Coefficient, MCC) against disentangled VAEs and prior temporal CRL approaches such as TDRL and PCL."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Novel theoretical framing and mathematical soundness.** The connection between causal representation learning and continuous-time stochastic processes is original and addresses a relatively unexplored intersection between CRL and stochastic process theory. The identifiability results are grounded in solid algebraic and geometric reasoning, extending prior work on discrete-time latent causal processes.\n\n2. **Clear theoretical motivation.** The use of weak convergence and INAR approximations provides a mathematically coherent bridge between continuous and discrete-time identifiability analysis."}, "weaknesses": {"value": "1. **Limited Evaluation Metrics.** The empirical assessment is restricted to the MCC metric, which captures correlation-based identifiability but does not reflect disentanglement quality or causal graph recovery. Including other identifiability metrics (e.g. [3]) or explicit measures of causal edge recovery would strengthen the validation. \n\n2. **Missing comparisons to recent CRL baselines.**\nWhile the paper compares MUTATE against Beta-VAE, SlowVAE, and TDRL, it omits comparison with more recent temporal CRL methods, such as [1, 2], which also focus on identifiable causal dynamics. \n\n3. **Synthetic-only “real-world” evaluation.** Although the authors mention testing on real-world biological data, the experiments rely on synthetic gene expression data generated by the SERGIO GRN simulator. This does not constitute a genuine real-world application and limits claims of practical relevance.\n\n4. **Unclear experimental correspondence.**\nIt is not clearly stated which simulation settings correspond to Table 1 and Table A2, making it difficult to interpret the presented results. Further clarification of the data regimes and kernel/noise configurations would improve readability and reproducibility.\n\n[1] \"Causal Representation Learning for Instantaneous and Temporal Effects in Interactive Systems\" Lippe et al. ICLR2023\n\n[2] \"Nonparametric Partial Disentanglement via Mechanism Sparsity: Sparse Actions, Interventions and Sparse Temporal Dependencies\" Lachapelle et al. 2024\n\n[3] \"The Third Pillar of Causal Analysis? A Measurement Perspective on Causal Representations.\" Yao et al. NeurIPS2025"}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "aCBGrUVkWw", "forum": "6renfxmnAZ", "replyto": "6renfxmnAZ", "signatures": ["ICLR.cc/2026/Conference/Submission535/Reviewer_8Kot"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission535/Reviewer_8Kot"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918155418, "cdate": 1761918155418, "tmdate": 1762915542202, "mdate": 1762915542202, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the problem of learning meaningful causal representations from observational data, with a particular focus on continuous-time latent stochastic point processes. It combines causal representation learning with stochastic modeling, providing theoretical identifiability guarantees and proposing a VAE-based solution framework called MUTATE. Experimental results demonstrate that MUTATE outperforms other methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper expands the scope of research on causal representation learning, extending it from traditional i.i.d. and discrete-time scenarios to continuous-time latent stochastic point processes.\n2. The authors provide the theoretical analysis that the underlying causal structure and variables can still be uniquely identified under nonlinear mixing functions."}, "weaknesses": {"value": "1. Although the theoretical framework relies on high-order cumulant tensor decomposition to achieve identifiability of causal representations, the practical solution shifts to a VAE-based generative modeling approach. This choice may lead to a disconnect between theory and practice, especially when the performance of the VAE depends on specific model assumptions or data distributions, potentially failing to fully reflect the advantages of the theoretical framework.\n2. Theorem 2 relies on first-order Taylor expansion truncation and Jacobian linearization, but the authors did not provide an approximation error bound or a probabilistic statement regarding the rank lower bound of the Jacobian.\n3. The experimental section did not include a comparison with the baseline method of directly estimating cumulants combined with CP decomposition.\n4. What is the computational complexity of the proposed method in the paper? For example, the encoder-PSD flow decomposition involves Fast Fourier Transformation (FFT) at each step, which increases the overall complexity of the method.\n5. Some statements in the paper are unclear. For instance, in the introduction, the sudden mention of \"The cumulant propagates the causal structure through nonlinear transformations...\" lacks sufficient explanation. What is the underlying insight behind this claim? How does the cumulant achieve the propagation of causal structure through nonlinear transformations?"}, "questions": {"value": "See the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qNCbP6Xr5u", "forum": "6renfxmnAZ", "replyto": "6renfxmnAZ", "signatures": ["ICLR.cc/2026/Conference/Submission535/Reviewer_Tcwq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission535/Reviewer_Tcwq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762067278385, "cdate": 1762067278385, "tmdate": 1762915542062, "mdate": 1762915542062, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies causal representation learning when the latent variables are continuous‑time multivariate point processes observed through an unknown non‑invertible mixing function. The author proves identifiability of the latent point process and its causal structure under linear mixtures (Thm. 1) and generic nonlinear mixing (Thm. 2), with necessary and sufficient conditions (Thm. 3). The author also proposes MUTATE, a VAE with a time‑adaptive transition and PSD‑whitening module to estimate the latent processes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Most identifiability results in CRL assume discrete‑time latents and invertible mixing. Treating continuous‑time point processes with generic mixing is novel and practically relevant.\n2. Although i did not look into the proof details, the theorems are intuitive and clear in a geometry view, considering identifibility as zero‑dimensionality of solution set of the system.\n3. The model components are well related to the theorem."}, "weaknesses": {"value": "Major Concerns\n\n1. Only simulation results are presented. Considering the broad motivation of the work, including real dataset with event sequence from a continuous process would greatly strengthen the paper.\n2. Adding a symbolic summary box would enhance readability, as the paper currently contains a large number of symbols such as \\bigstar and \\otimes.\n3. Assumptions A2.2 and A3.2 are not clear to me, and under what circumstance should this assumption be true? It will be better to have some illustrations or examples. Besides, is the model robust against these assumptions?\n4. The theory uses cumulants, and the algorithm instead uses a PSD whiteness prior and a time‑adaptive VAE without explicitly estimating cumulants. The connection is indirect.\n5. As for as i know, to be self-exciting, the kernel should be postive and decreasing. This seems not contrained in the model. Could the author explain more on it?\n\nMinor Concerns\n\n6. Line 348: Hamilton conjugate -> Hermitian?\n7. It will be better to have a figure or illustraion about the model pipeline to better demonstrate the model designation, and highlight the difference compared with other baseline models based on VAE."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "e5CtpmQbe4", "forum": "6renfxmnAZ", "replyto": "6renfxmnAZ", "signatures": ["ICLR.cc/2026/Conference/Submission535/Reviewer_UzGW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission535/Reviewer_UzGW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762261352732, "cdate": 1762261352732, "tmdate": 1762915541819, "mdate": 1762915541819, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles causal representation learning (CRL) for continuous-time latent point processes (Hawkes-type) under generic, potentially non-invertible mixing. It formalizes a weakly-convergent equivalence class to reconcile continuous-time dynamics with discrete observations and then proves identifiability (up to scaling/permutation or componentwise transforms) by analyzing the algebraic geometry of cumulant tensors and the associated ideals/varieties. On the algorithmic side, the authors propose MUTATE, a VAE with a time-adaptive transition and PSD-based prior decomposition to enforce independent noise and estimate latent dynamics. Simulations across several kernel families and a SERGIO-based gene-expression setting (all synthetic) show higher MCC than BetaVAE/SlowVAE/PCL/TDRL, with especially strong gains on exponential/power-law kernels (Table 1)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novelty: CRL for continuous-time latent Hawkes processes under generic (non-invertible) mixing is timely and underexplored; the weakly-convergent class neatly addresses discrete sampling vs continuous dynamics.\n- The time-adaptive transition along with PSD decomposition to enforce latent whiteness provides connects theory to practice; the ELBO is explicitly provided.\n- Empirical results show higher MCC on multiple kernel regimes vs temporal/non-temporal baselines."}, "weaknesses": {"value": "- Assumption 2 (“zero-dimensional ideal) seems hard to verify.\n- Lemmas 1–2 show convergence to a latent class but no explicit error rates are provided."}, "questions": {"value": "The paper states an iff with Assumption 2 as necessary/sufficient for identifiability (Theorem 3), is there a practical test for the “linear degeneration” in Assumption 3(2)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "fTRbRGwhno", "forum": "6renfxmnAZ", "replyto": "6renfxmnAZ", "signatures": ["ICLR.cc/2026/Conference/Submission535/Reviewer_vmtW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission535/Reviewer_vmtW"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission535/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762500373729, "cdate": 1762500373729, "tmdate": 1762915541688, "mdate": 1762915541688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}