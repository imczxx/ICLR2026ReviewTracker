{"id": "WAQIxi7ifb", "number": 1896, "cdate": 1756960328719, "mdate": 1759898180213, "content": {"title": "Learning Admissible Heuristics for A*:  Theory and Practice", "abstract": "Heuristic functions are central to the performance of search algorithms such as A*, where \\emph{admissibility}—the property of never overestimating the true shortest-path cost—guarantees solution optimality. Recent deep learning approaches often disregard full admissibility and provide limited guarantees on generalization beyond the training data. We address both of these limitations. First, we pose heuristic learning as a constrained optimization problem and introduce \\emph{Cross-Entropy Admissibility (CEA)}, a loss function that enforces admissibility during training. When evaluated on the Rubik’s Cube domain, our method yields heuristics with near-perfect admissibility and significantly stronger guidance than compressed pattern database (PDB) heuristics. On the theoretical side, we derive a new upper bound on the expected suboptimality of A*. By leveraging PDB abstractions and the structural properties of graphs such as the Rubik’s Cube, we tighten the bound on the number of training samples needed for A* to generalize to unseen states. Replacing a general hypothesis class with a ReLU neural network gives bounds that depend primarily on the network’s width and depth, rather than on graph size. Using the same network, we also provide the first generalization guarantees for \\emph{goal-dependent} heuristics.", "tldr": "This paper investigates the learning of admissible heuristics, providing both theoretical analysis and empirical validation.", "keywords": ["Admissible Heuristics", "A* Search Algorithm", "Optimal search", "Generalization Guarantees", "Rubik’s Cube"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/41aecc0417cd1369ea0a9a4d04c6ae71daf33298.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper develops theory and practice for learning admissible A* heuristics. It tightens sample-complexity bounds under equal-cost edges and gives a sharper suboptimality guarantee that bounds A*’s error by the maximum inadmissibility on the optimal path, with extensions to neural-network and goal-dependent settings.\nPractically, it introduces the Cross-Entropy Admissibility (CEA) loss, which shifts probability mass onto admissible classes and sharpens around the true class.\nOn Rubik’s-Cube PDBs, CEA-trained models achieve near-admissibility and match or exceed the average heuristic of same-size compressed PDBs"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The theory derives tighter generalization bounds that incorporate neural network width/depth and handle goal-dependent heuristics.\n* Heuristic learning is cleanly framed as a constrained optimization problem.\n* The suggested CEA loss seems to effectively encourage admissibility in the provided experimental results.\n* Overall, the paper is well written."}, "weaknesses": {"value": "* The theoretical results mostly assume equal-cost edges (Assumption 4). While this is common for toy problems like Rubik’s Cube it limits immediate transfer to domains with varied costs.\n* While the CEA loss suggested in Equation 5 seems conceptually plausible, it lacks a clear motivation why this specific function was chosen. The goal of shifting some probability mass towards admissibility could be expressed through other loss functions as well, for example by minimizing the kl divergence between the predictions and a suitably defined target distribution. Were other loss functions considered? If so, why was this specific one chosen?\n* Some details of the experimental results are vague. No details on how the data is split into train/validation/test splits is provided.\n* As the theory in section 3 derives the sample complexity for learning heuristics, an ablation study that measures the heuristics performance as a function of the training set size would strengthen the connection between the works theoretical and empirical sections.\n* The CEA loss introduces β and η as additional hyperparameters that are adjusted in stages during training, which adds complexity to the training process.\n\nWhile the theoretical results and novel CEA loss are contributions, I do think these weaknesses currently outweigh the strengths of the paper."}, "questions": {"value": "* How was the data split for the empirical study? How many samples are used for training?\n* Can the CEA loss be extended to settings with non-uniform edge weights?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zutdlOQLn1", "forum": "WAQIxi7ifb", "replyto": "WAQIxi7ifb", "signatures": ["ICLR.cc/2026/Conference/Submission1896/Reviewer_BWMp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1896/Reviewer_BWMp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761782467823, "cdate": 1761782467823, "tmdate": 1762915935351, "mdate": 1762915935351, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper extends existing theoretical analyses on the sample complexity of\nlearning admissible heuristics, then proceeds to define a new loss function\nto achieve such admissibility.\nThe contributions in this work are\n\n-   Thm2: Extension of Sakaue & Oki 2022's result on Pdim to PDB's abstracted states\n-   Thm3: a tighter suboptimality bound when A\\* with is allowed to reopen nodes &#x2013; extension of Valenzano '14,\n-   Thm4: Eq. (3) which has O(sqrt(n)) instead of O(n) in Eq (1) = Prop 1 + Sakaue & Oki 2022.\n-   Thm5: Extension of Sakaue & Oki 2022's result on Pdim to NNs, with/without PDBs\n-   Thm6: Extension of Thm5 to NNs with specific sizes\n-   Thm7: Extension of Thm6 to different goals\n-   proposing CEA loss.\n\nI have a mixed impression about this work. While the paper is tackling an important problem,\nthe paper appears to be written by two authors without a necessary organic integration,\nwhich is a common phenomenon &#x2014; one symbolic author and one machine learning author failing to understand each other, stuck in their own worldview.\nThis might be causing inconsistent math notations (e.g. log vs. lg, $\\ell$ vs. $D$),\noverlapping symbols ($W$ as cost upper bound vs parameter size),\nand an apparent disconnect between the theoretical result and the empirical result described below.\n\nThe paper did excellent work coverint the backgrond on the sample complexity analysis.\nHowever it is light on proofs, which are largely deferred to the appendix,\nand has several minor notation issues which must be fixed.\n\nI also have a bigger concern about the practical part of this paper: CEA, and the empirical evaluation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper did excellent work covering the backgrond on the sample complexity analysis."}, "weaknesses": {"value": "## Issue 1: CEA\n\nAs discussed in [Nunez-Molina 2024] cited in this work,\nthe choice of the loss function must directly correspond to the statistical representation of the output.\nCategorical target random variable yields the cross-entropy loss naturally as a negative log likelihood.\nThe proposed CEA loss does not have a corresponding distribution.\nIf the author wishes to impose some mathematical property on the prediction target,\nthe right way to design a machine learning model is to idenfity the correct representation of the target as a random variable,\nthen derive the loss function naturally from its pdf.\n\nOne such alternative as a baseline for comparison against CEA I suggest is **ordinal logistic regression** for ordinal variables.\nOrdinal regression [1] is a classical method for predicting ordinal random variables,\nwhich naturally address the lack of orders in the categorical prediction (classification).\nIf the model believes that the output is larger than k,\nthen the model architecture must hard-code the invariance that the output is also larger than k-1, k-2, and so on.\n\n[1] McCullagh, Peter (1980). \"Regression Models for Ordinal Data\"\n\nOne of its simplest implementation uses the cumulative binary logistic loss,\nwhich outputs a single scalar with a NN, subtract monotinically increasing threshold values,\napply a sigmoid, then train the output with binary cross entropy.\n\nparameters:\n\n-   A scalar output neural network $f$ (the last layer does not need the bias)\n-   A bias vector $\\mathbf{b} \\in R^k$ for prediction over $\\{0, 1, ... k\\}$\n\nhow:\n\n-   input $x$\n-   target value $h^* \\in ｛0, 1, ... k｝$\n-   binary prediction target $\\mathbf{y} \\in ｛0,1｝^k$:\n    -   $y_h = 1$ if $h > h^*$ ;\n    -   $y_h = 0.5$ if $h=h^*$ ; \n    -  0 otherwise.\n    -  For example, it looks like $[0,0,0,0,0.5,1,1,1]$ when $h^*=4$ and $k=7$.\n-   scalar logit $l = f(x)$\n-   thresholds $\\mathbf{\\theta}$\n    -   $\\theta_0 = b_0$\n    -   $\\theta_h = \\theta_{h-1} + softplus(b_h)$\n        -   This ensures $\\theta_h > \\theta_{h-1}$\n-   output: vector $\\mathbf{p}\\in [0,1]^k$, where\n    -   $p_h = \\sigma( l - \\theta_h )$\n    -   $p_h$ represents $p(h^* < h | x)$ , and this framework guarantees $p(h^* < h | x) < p(h^* < h+1 | x)$ .\n-   loss: $\\sum_h CE( y_h, p_h )$\n\nNotice that the final loss naturally penalizes the misprediction of $p(h^* < h | x)$ the further $h$ is away from $h^*$.\n\nFor example, when $h^*=4$ and $p_6$ is smaller than 0.5, the framework ensures that $p_4, p_5$ are even smaller, resulting in three times or more penalty.\nThis has a similar characteristics as the first term of the CEA, while maintaining the natural statistical interpretation.\n\nYou may however return a rebuttal: Then how do we interpret the tunable &beta; in CEA, and the fact that it only applies to the overestimation?\n\nMy answer: As cumulative binary logistic loss is a sum of losses for a series of binary predictions,\nwe can achieve the same effect by multiplying a set of coefficient to each loss.\nThis is a common practice for addressing a class imbalance (although our purpose is different)\nand it is mathematically equivalent to oversampling/undersampling a subset of the dataset.\n(Well, there may indeed be a class imbalance.\nsee the next section blow.)\nConcretely, use the loss as follows:\n\n-   loss: $\\sum_h w_h CE( y_h, p_h )$\n\nYou are free to choose any $w_h$, e.g. $w_h = g(h, h^*)$ for some formula g that increases as $h$ overestimates.\nSo, there is no ad-hoc tricks; It simply artificially increases the penalty to the overestimation.\n\n\n## Issue 2: PDB learning\n\nI found that the method section and the evaluation section is quite ambiguous about the training data.\nI struggled to discover what is the input representation to the NN, what is the taget value, and how many data points are used.\nPlease add a separate section titled \"data collection\" which details what goes in the pipeline.\nI initially had 4x2 = 8 possible interpretations:\n\n-   Input x to the NN:\n    -   Raw state representation, factored\n    -   Raw state representation, in a form of state id\n    -   PDB abstract state representation, factored (\\*)\n    -   PDB abstract state representation, abstract state id\n-   Target data:\n    -   optimal solution cost $h^*(x)$ obtained by search from x using admissible PDB\n    -   admissible heuristic $h(x)$ from the PDB &#x2014; which is an optimal path cost in the abstract state space\n-   The number of data points\n\nThe detail of the input representation is only given in the appendix.\nWhile the full detail is not necessary, the main paper must at least mention\nthat it is the factored abstract state representation of PDB.\n\nWhat's more important is the target data.\nI know you used $h^*$ in Eq.5, but I don't have a good confidence because\nthere is no mention of how it was collected.\n\nI could not find any information about the number of data points.\nDid you use the entire abstract states in the PDB without subsampling?\nIf so, the dataset is hugely imbalanced, as you pointed out in the paper.\nThe standard practice is oversampling, undersampling, and bagging. See [1].\nThese standard measures completely normalizes the number of samples per class.\n\nThe lack of mention to how the author addressed the class imbalance imply a danger that\nthe perceived improvement from the CEA loss could be just an artifact of **accidentally** somewhat addressing\nthe class imbalance in an ad-hoc way.\n(As said above, multiplying $(k/h^*)^\\beta$ to the loss is mathematically equivalent to oversampling.)\n\nThe authors also mentioned delta-PDB, which would shift h's distribution and also somewhat reduces the class imbalance,\nbut the Table 3 shows that the entire dataset still contains a massive class imbalance.\n\n[1] Wallace, Byron C., et al. \"Class imbalance, redux.\" 2011 IEEE 11th international conference on data mining. Ieee, 2011.\n\n## Issue 3: Disconnect between theoretical results vs experiments\n\nThe theoretical and the empirical results in this paper are, while individually interesting, quite disconnected.\n\n\n### theorem 4\n\nFirst, the paper does not empirically verify Theorem 4.\nI expected an experiment that estimates the LHS of eq.3 using a validation set as a surrogate or the entire (abstract) state space,\nsubtract the first term of Eq.3, then plot the remaining value to confirm that it grows $O(\\sqrt(n))$.\n\nTheroem 4 does not require factored state representation, Rubiks cube, PDBs or the CEA loss function.\nInstead, theorem 4 is a function of the graph size n and the sample size N.\n\nIn other words, while section 3.1 is by itself an interesting contribution,\nits empirical confirmation must be done separately using a state space whose size is configuratble,\ne.g., not in Rubik cube, but in artificial random graphs such as those studied by Cohen & Beck [AAAI17, AAAI18, IJCAI18]\nwhose $n$ can be configured.\n\n-   Problem Difficulty and the Phase Transition in Heuristic Search, AAAI17\n-   Local Minima, Heavy Tails, and Search Effort for GBFS, AAAI18\n-   Fat- and Heavy-Tailed Behavior in Satisficing Planning, IJCAI18\n\n\n### theorem 7\n\nAnother main theoretical results in this paper is the sample complexity in theorem 7.\nI expected that the empirical analysis verifies this by one of these experiments:\n\n-   Experiment 1: Given a fixed network, compute this upper bound Pdim(U) with\n    Thm7. Then gradually reduce the dataset size by subsampling. See what happens\n    if the dataset size goes below Pdim(U)\n-   Experiment 2: Given a fixed dataset, reduce the number of weights in NN to reduce Pdim(U).\n    See what happens if Pdim(U) goes below the dataset size.\n\n\n## Issue 4: Runtime analysis of using the NN\n\nWhile the paper claims that it tries to find a smaller NN (Eq.4),\nit does not do anything about it actually.\nThe evaluation focuses on accuracy and admissibility,\nand never compares the actual runtime or the number of node evaluations\nbetween the sota solver against A\\* guided by the heuristics learned by this method.\n\nIn other words, as is often the case with many machine learning papers,\nI suspect that this paper obtained a quite accurate heuristic that is too slow\nto compute to use in practice.\n\n\n## Minor comments and questions\n\n-   line 80 : b should be a neighbor of a?\n-   l.77-91: floor and indicator functions are not used in the paper?\n-   l.165-173: better to have a consistency in the choice of letters. H -> U?\n-   l.173: h suddenly becomes a real vector. I know this is an array from a state to R, but this is inconsistent to the previous notation h(s) of state s.\n-   l.213: $|G_v| <= n^2$ I suppose.\n-   l.215: same regarding h.\n-   l.215: add \"derived from S & Oki 2022\".\n-   l.216: same reagarding h.\n-   l.234: \"general class of performance measure\", provide examples, e.g., runtime, memory, node evals, etc.\n-   l.252: Results in Valenzano 14 holds regardless of admissibility, which is surprising.\n    Although it is not wrong not to mention it (because nothing more is not assumed than stated),\n    due to the strong association between A\\* and admissibility,\n    I strongly suggest the authors to explicitly state that the entire section 3.1 does not depend on the admissibility of h.\n-   l.268: $\\hat{H}$ undefined.\n-   l.270: lg n vs log n.\n-   l.302: sum of $w_1 \\ldots w_n$ is denoted by U. U -> W?\n-   l.305: Indeed, here the number of parameters is W.\n-   l.317: the number of output classes is $\\ell$. It was $H$ before. or $\\hat{H}$. wtf?\n-   l.326: this time the number of output classes is $D$. wtf?\n-   l.333: Rep(I) is not used at all elsewhere in the paper. maybe appendix. please remove it or move it to the appendix, if used there.\n-   l.343: $\\ell$ and $D$ used at the same time. Also, U and W are used at the same time. $\\ell'$ undefined.\n-   l.364: $|h|$ is never explicitly optimized. I doubt Eq.4 is necessary."}, "questions": {"value": "Q1. Confirm the input format is PDB abstract state representation, factored. (yes/no)\n\nQ2. Confirm the target value is really h\\* and is obtained by solving x optimally. (yes/no)\n\nQ3. Did you use the entire abstract states in the PDB without subsampling? (yes/no)\n\nQ4: The author claims that Eq.(3) is tighter than Eq.(1) with no explanation.\nI assumed O(sqrt(n)) vs O(n) is what they implied. Am I correct? (yes/no)\n\nAlso, please add a sentence that explains conceptually why this reduction is achieved.\n(E.g., in sorting literature, radix sort can run faster than O(n log n) &#x2014; why?\nit is because it can use more information than comparison sort.)\nI assume that this is in line with something like: it uses the max in Thm3,\ntherefore only one element along the path affects the error,\nwhile the first error term in Eq.(1) is essentially a double summation (sum over paths, sub over states on the path)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "epCSBXP4Sj", "forum": "WAQIxi7ifb", "replyto": "WAQIxi7ifb", "signatures": ["ICLR.cc/2026/Conference/Submission1896/Reviewer_ntxk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1896/Reviewer_ntxk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955774451, "cdate": 1761955774451, "tmdate": 1762915935031, "mdate": 1762915935031, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to learn admissible heuristics for A*, combining theoretical generalization analysis with practical training improvements. It incorporates a new loss function, called Cross-Entropy Admissibility (CEA), that enforces admissibility during training and analyzes the sample complexity of learning admissible heuristics. Experiments on the Rubik’s Cube show that CEA produces nearly admissible heuristics with very low inadmissibility rates and stronger guidance against compressed pattern databases (PDBs)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper introduces CEA as a principled loss to enforce heuristic admissibility is both theoretically sound and practically effective.\n2. It provides theoretical analysis and derives tighter generalization bounds, incorporating neural networks as the heuristic with  generalization bounds analyzed primally on network size.\n3. Experimental results demonstrates strong results on Rubik’s Cube domains, showing measurable gains over traditional PDBs."}, "weaknesses": {"value": "1. The experiments results are limited to a single domain(the Rubik's Cube). The claims of the paper would be significantly stronger if supported by results on other classic planning domains.\n2. The theoretical analysis relies on Assumption 4, while this holds for the Rubik's Cube but is not universal. How do the bounds change for graphs with variable edge costs? \n3. The proposed method is evaluated on several 3 × 3 Rubik’s Cube pattern databases, where  the performance and data requirements for larger graphs remain unclear."}, "questions": {"value": "Please refer to the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "RKoj51n9R1", "forum": "WAQIxi7ifb", "replyto": "WAQIxi7ifb", "signatures": ["ICLR.cc/2026/Conference/Submission1896/Reviewer_zAZ1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1896/Reviewer_zAZ1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974076313, "cdate": 1761974076313, "tmdate": 1762915934638, "mdate": 1762915934638, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of learning admissible heuristics for A* search. Many current deep learning approaches often do not consider admissibility but focus on predictive strength, losing theoretical guarantees on optimality. The authors propose new sample complexity bounds for learning such heuristics, that exploit graph structural properties and PDB abstraction. They also derive bounds for neural network that depend on the networks size rather than the problem size. From a practical point of view, the paper frames the heuristic learning as a constrained optimization problem and further reduce it to a classification task that uses a new loss function called cross-entropy admissibility. Empirical results show the method has low overestimation rate without sacrificing informativeness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The formalization of heuristic learning as a constrained optimization and reduce it to a classification task guided by a new loss function is novel.\n2. The tighten sample complexity bounds seem to be a good contribution.\n3. The paper addresses a gap between ML-based heuristics and rigorous admissibility requirements for optimal search.\n4. The paper is well-presented."}, "weaknesses": {"value": "I wasn't able to check the theory thoroughly, the weaknesses listed below are mainly from empirical study.\n\n1. Experiments are on Rubik’s Cube domain, it is a good benchmark but requires at least of couple more for the empirical results to be fully convincing. The practical value of CEA would be clearer if demonstrated in another admissible-heuristic domain (e.g., sliding-tile puzzle).\n2. The paper didn’t describe how the hyper parameters \\beta and \\eta are tuned, if the author could provide a principled process, it would help reproducibility. \n3. There is no runtime measurements in the experiments."}, "questions": {"value": "1. Have you quantified A* search impact in terms of running time on your test problems?\n2. Have you empirically evaluated your methods on other domains? How does it perform?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o4I11vmJxr", "forum": "WAQIxi7ifb", "replyto": "WAQIxi7ifb", "signatures": ["ICLR.cc/2026/Conference/Submission1896/Reviewer_bBv4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1896/Reviewer_bBv4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762136748475, "cdate": 1762136748475, "tmdate": 1762915934274, "mdate": 1762915934274, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles a core challenge at the intersection of machine learning and heuristic search: **how to learn powerful heuristic functions that preserve the optimality guarantees of algorithms like A***.\n\nThe authors make contributions on both theoretical and practical fronts:\n\n*   **New Loss Function:** They propose a Cross-Entropy Admissibility (CEA) loss, a new training objective designed to enforce the admissibility constraint directly.\n\n*   **Strong Empirical Performance:** Evaluated on the 3*3 Rubik's Cube, the approach demonstrates remarkable success, learning heuristics that are nearly perfectly admissible while providing stronger search guidance than traditional baselines.\n\n*   **Theoretical Analysis:** The work provides a sample complexity analysis for learning heuristics. By leveraging problem structure and abstractions like Pattern Databases, the authors derive tighter generalization bounds for A*. They also establish a theoretical guarantee for learning goal-dependent heuristics.\n\nIn summary, this work introduces a framework for learning reliable heuristics, effectively bridging data-driven learning and classical search algorithms."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Strong Empirical Validation:** The work demonstrates compelling empirical results. On the challenging benchmark of the 3x3 Rubik's Cube, it achieves near-perfect admissibility while learning a heuristic stronger than classically compressed alternatives.\n- **Noteworthy Theoretical Scope:** The paper provides a significant theoretical analysis of sample complexity. Its most original contribution is extending this framework to establish the first generalization guarantees for *goal-dependent* heuristics, moving beyond standard fixed-goal analyses."}, "weaknesses": {"value": "- **Limited Empirical Scope:** The empirical evaluation is exclusively conducted on the 3*3 Rubik's Cube. The performance and effectiveness of the proposed CEA loss on other combinatorial puzzles or planning domains remain unknown.\n- **Limitations of Theoretical Claim**: The claim that sample complexity is governed by network parameters and independent of graph size may not translate to practical advantages, as it relies on strong assumptions that may fail in real-world problems.\n- **Unvalidated Theoretical Extension:** While establishing the first theoretical guarantees for goal-dependent heuristics is a notable contribution, this significant claim is unsupported by empirical evidence. The experiments only address a fixed-goal setting."}, "questions": {"value": "- **Comparison with Standard Cross-Entropy Loss:** The paper clearly shows that the CEA loss achieves a much lower overestimation rate than the standard CE loss. However, beyond this crucial metric, did you compare the **resulting A\\* search performance** (e.g., number of node expansions, wall-clock time) when using heuristics trained with these different losses? \n- **Connection Between Theory and Experiment**: Could you share more details on how the theoretical insights guided the experimental design? For instance, did the theory influence the choice of neural network capacity or the amount of training data needed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "FNzms9mTYR", "forum": "WAQIxi7ifb", "replyto": "WAQIxi7ifb", "signatures": ["ICLR.cc/2026/Conference/Submission1896/Reviewer_1RCQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1896/Reviewer_1RCQ"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission1896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762163812075, "cdate": 1762163812075, "tmdate": 1762915933928, "mdate": 1762915933928, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a method, called cross-entropy admissibility (CEA), to learn heuristic functions which, in the context of pathfinding on a weighted directed graph, map states to an estimate of the cost-to-go to a closest goal state. CEA focuses on learning heuristic functions that are admissible, meaning they never overestimate the cost of a shortest path. CEA formulates heuristic learning as a classification task, where each possible heuristic value is treated like a class, and more emphases is put on penalizing overestimation. The paper focuses on the Rubik’s cube, where all transition costs are one and, therefore, all possible true cost-to-go values are integers. Results with neural networks on learning heuristic values from PDBs show that the proposed method learns heuristic values that have significantly fewer underestimations than regular cross entropy (CE) while having a slightly less or similar average heuristic value."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "As machine learning continues to be used to learn heuristic functions, admissibility guarantees become more important. The paper contains important theoretical analyses and proposed practical approaches for learning heuristic functions that are largely admissible.\n\nWhen compared to compressed PDBs, both the CEA and CE have higher average heuristic values while maintaining similar compression rates. However, CE, has overestimation rates on the order of 1o^-3 to 10^-2. On the other hand, CEA has compression rates on the order of 10^-7 to 10^-5. The average heuristic value of CEA when compared to CE ranges from slightly lower to having the same value."}, "weaknesses": {"value": "The paper discusses the benefits of admissibility, but it is not clear at what the cost of prioritizing admissibility on problem solving ability. If a neural network uses more of its representational capacity to prevent overfitting, then it may stand to reason that it may perform relatively poorly on higher cost-to-go values. This could make finding paths more time consuming in practice due to the lower overall heuristic value. Table 2 indicates this could be the case due to CEA having a slightly lower average heuristic value compared to CE."}, "questions": {"value": "Does the theory presented in the paper say anything about drawbacks from prioritizing admissibility?\n\nFor Table 2, has using mean-squared error been tried?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WfBlY7Is8G", "forum": "WAQIxi7ifb", "replyto": "WAQIxi7ifb", "signatures": ["ICLR.cc/2026/Conference/Submission1896/Reviewer_BkY5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1896/Reviewer_BkY5"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission1896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762190815266, "cdate": 1762190815266, "tmdate": 1762915933420, "mdate": 1762915933420, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new loss function, Cross-Entropy Admissibility (CEA), for learning A* heuristics that are both strong and nearly admissible. The authors show that CEA explicitly favors underestimation while still concentrating probability on the true heuristic value, yielding more effective heuristics than compressed pattern databases in domains such as the Rubik’s Cube. \n\nOn the theoretical side, the paper provides generalization guarantees for learned (including goal-dependent) heuristics in A*, deriving improved sample complexity bounds by analyzing inadmissibility along optimal paths. Overall, the work makes both practical and theoretical contributions to learning heuristics for search, bridging a gap between empirical performance and provable guarantees."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Novel loss function tailored to A*: The proposed CEA loss directly encodes admissibility preferences, addressing a key limitation of prior heuristic-learning approaches that treat over- and under-estimation symmetrically.\n\nStrong empirical performance: Experiments (e.g., on Rubik’s Cube) demonstrate that the learned heuristics are nearly admissible while significantly outperforming compressed PDB heuristics of equal memory footprint, showing both practical effectiveness and scalability.\n\nTheoretical contribution with improved sample complexity bounds."}, "weaknesses": {"value": "Fairness of experimental comparison could be improved: While the comparison with compressed PDBs under equal memory budget is meaningful, it overlooks other relevant dimensions such as training cost, inference time, and tuning effort. In particular, CEA models were tuned, whereas the CE baseline shares hyperparameters without comparable tuning, which may bias results in favor of CEA.\n\nCEA introduces additional tuning complexity\n\nLimited domain diversity in evaluation: Experiments focus primarily on the Rubik’s Cube domain. It remains unclear how well the method generalizes to other search domains with different structure, branching factors, or cost models."}, "questions": {"value": "The authors mention that the CE and CEA models use the same parameters. Could the authors clarify how these parameters were chosen? For a fair comparison, it may be helpful to tune both loss functions under the same hyperparameter-search budget. It would also be valuable to report the tuning ranges, the best-found values.\n\nWhile comparing the NN heuristic with a compressed PDB under an equal memory budget is a meaningful and reasonable fairness criterion, may I ask whether memory alone is sufficient to capture the trade-offs between these approaches? Would it be possible to also comment on the differences in training cost and inference time, as these aspects are often relevant for practical deployment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Ppg9iaCvwJ", "forum": "WAQIxi7ifb", "replyto": "WAQIxi7ifb", "signatures": ["ICLR.cc/2026/Conference/Submission1896/Reviewer_KNcH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1896/Reviewer_KNcH"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission1896/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762380667399, "cdate": 1762380667399, "tmdate": 1762915933208, "mdate": 1762915933208, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}