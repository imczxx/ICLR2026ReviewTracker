{"id": "7ZqFjYzInJ", "number": 9533, "cdate": 1758126379431, "mdate": 1763686643778, "content": {"title": "Learning to Solve Partial Differential Equations Constrained Optimization Problems", "abstract": "Partial differential equation (PDE)-constrained optimization arises in many scientific and engineering domains, such as energy systems, fluid dynamics, and material design. In these problems, the decision variables (e.g., control inputs or design parameters) are tightly coupled with the PDE state variables, and the feasible set is implicitly defined by the governing PDE constraints. This coupling makes the problems computationally demanding, as it requires handling high-dimensional discretizations and dynamic constraints.\nTo address these challenges, this paper introduces a learning-based framework that integrates a dynamic predictor with an optimization surrogate. The dynamic predictor, a novel time-discrete Neural Operator (Lu et al., 2021), efficiently approximates system trajectories governed by PDE dynamics, while the optimization surrogate leverages proxy optimizer techniques (Kotary et al., 2021) to approximate the associated optimal decisions. This dual-network design enables real-time approximation of optimal strategies while explicitly capturing the coupling between decisions and PDE dynamics.\nWe validate the proposed approach on benchmark PDE-constrained optimization tasks including Burgers’ equation, heat equation, and voltage regulation, and demonstrate that it achieves solution quality comparable to classical control-based algorithms such as the Direct Method and Model Predictive Control (MPC), while providing up to four orders of magnitude improvement in computational speed.", "tldr": "We introduce a novel learning-based method to solve partial differential equations constrained optimization problems in real time.", "keywords": ["Partial Differential Equations", "Constrained Optimization", "Proxy Optimizers", "Neural Operators"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fbedd514b194405d820d62cb5b136d4fd6031b60.pdf", "supplementary_material": "/attachment/73944a96b46dd008efdb993df91b2ac552ebbb6a.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes PDE-OP (Optimization Proxy), a framework for simultaneous discovery and optimal control of systems under PDE constraints. It consists of a dual-network architecture in which a dynamic predictor captures the system dynamics, while a surrogate controller approximates the optimal control actions. The authors claim the qualitative results are comparable to state-of-the-art numerical solvers, such as Model Predictive Control and the Adjoint-sensitivity method. At the same time, PDE-OP provides up to four orders of magnitude improvement in computational speed (on Burger's Equation in 1D)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) The Temperature control example helps ground the following problem. This inspired choice is very helpful, and contributes significantly to the clarity of the presentation.\n2. The dual-network architecture is a clever separation of concerns. Coupling a dynamic predictor with an optimization surrogate is a strong contribution.\n3. The computational speed-up is the most significant finding. Achieving results orders of magnitude faster than classical methods is a major practical advancement, useful to this community.\n4. The validation on standard benchmarks (Heat, Burgers') is good. Demonstrating success on both linear and nonlinear PDEs builds confidence in the approach's quality."}, "weaknesses": {"value": "1) The Related Work is limited. The paper ignores differentiable programming technologies which have emerged with deep learning libraries, e.g. review in (Nzoyem et al. 2023)\n3) Figure 1 is confusing, with unlabelled axes. It appears to show $u(t,x)$ as a function of a _single_ variable, and $y(t_0, x)$ and $y(T,x)$ as functions of _two_ variables.\n4) The ultimate optimisation process is confusing and the presentation suffers. Throughout the paper, several losses are proposed, e.g. (7) and (9). It is important to be decisive and clearly state which losses are included when.\n5) The experiments, although compelling, are all toy problems with no real-world example. In additional, the baselines against which PDE-OP is compared are significantly limited. More concerning, no experiment clearly establishes the usability of this method for _real-time_ applications, like it is repeatedly claimed.\n\n### Minor issues:\n- L160: I might misunderstand the setup, but shouldn't it be $\\mathcal{U}_{\\omega}(t,x,\\hat y)$ ? \n\n### References:\n- Nzoyem et al. \"A Comparison of Mesh-Free Differentiable Programming and Data-Driven Strategies for Optimal Control under PDE Constraints\", SuperComputing Workshop on AI4Science, 2023"}, "questions": {"value": "1) L139. Can you please provide evidence (or reference) for the NP-hardness of Problem (1)?\n2) Equations 1b and 1c are often merged into a single PDE. Is there a specific reason why the authors have decided to separate these temporal and spatial evolution terms ?\n3) It seems the authors do not want to see $\\mathcal{Y}_{\\theta}$ exposed to the full control action. As such, they feed it the basis function weights instead. This is justified by the desired to operate in a low-dimensional space, as previous work has done. But the construction of the basis function becomes a hyperparameter to tune, increasing complexity of the method. Could you provide an ablation study for this ?\n4) Could you please provide general ablation studies and more comparison with established neural network-based optimal control strategies?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pOzxE2aU98", "forum": "7ZqFjYzInJ", "replyto": "7ZqFjYzInJ", "signatures": ["ICLR.cc/2026/Conference/Submission9533/Reviewer_tffW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9533/Reviewer_tffW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9533/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761494698964, "cdate": 1761494698964, "tmdate": 1762921097039, "mdate": 1762921097039, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents PDE-OP, a two-module framework for PDE-constrained optimization. The first module is a discrete-time neural operator that predicts system trajectories under PDE dynamics. The second is a surrogate controller that outputs coefficients of a spatial basis to approximate the control. On three 1D tasks (voltage control, heat equation, viscous Burgers), the method reports large speedups over classical solvers with similar errors on smooth target profiles."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- (Clarity) The problem setup is precise: objective, PDE constraints, and IC/BC are clearly listed. The two-module design and training pipeline are easy to follow (Fig. 2)."}, "weaknesses": {"value": "- (Originality) The approach combines known ideas (DeepONet-style operator learning, surrogate optimization) rather than introducing a new operator or control formulation.\n- (Significance and quality) All experiments are 1D with smooth targets (constant/linear/sine). There are no 2D/3D tests or moving/complex boundary cases. Several plots show larger boundary errors (e.g., Fig. 3 left, Fig. 4 left) without analysis. In some simple cases, PDE-OP’s MSE is much higher than the adjoint method (e.g., voltage constant target in Table 2), with no diagnosis. Comparisons to modern operator-learning baselines are also missing."}, "questions": {"value": "- Related work on operator learning is brief and focuses on early methods. Could the authors expand this section to include newer approaches and add comparisons to these methods?\n- Current targets are simple and smooth. Could the authors add non-smooth, piecewise, or high-frequency targets and report results? Please also justify the BC choices (Neumann vs. Dirichlet) across tasks and discuss consistency. Results with more complex BCs (e.g., Robin/mixed, moving boundaries) or variable coefficients would strengthen the claims. Any 2D/3D results (e.g., 2D heat control)?\n- In Fig. 3, the Adjoint method has noticeably larger error in the first two cases. What is the cause?\n- For Burgers, PDE-OP is fastest but has higher MSE. If NMPC or the Adjoint method are tuned to match PDE-OP’s error level, how much would their runtime drop?\n- Several figures show larger boundary errors. Please analyze the causes and suggest ways to reduce them.\n- In Table 2, why is PDE-OP’s MSE (1.5e−6) much larger than the adjoint method’s (2.8e−12)? Similar results in other tables as well, could the authors provide an explanation for this gap in error performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "V3WlZzvdbp", "forum": "7ZqFjYzInJ", "replyto": "7ZqFjYzInJ", "signatures": ["ICLR.cc/2026/Conference/Submission9533/Reviewer_bV8c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9533/Reviewer_bV8c"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9533/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761617438099, "cdate": 1761617438099, "tmdate": 1762921096563, "mdate": 1762921096563, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Strengths: The paper is well-written and on the topic of PDE-constrained optimization, where ML can play a significant role. Authors use many recent developments in smart ways to show that their method solves several typical benchmark problems in this area much faster than competing methods. The selected problems vary in complexity (e.g. nonlinearity, constraint types). \n\nWeaknesses: Although there have been some recent works tackling this problem using ML-based approaches, the authors compare only with traditional PDE-constrained optimization based methods, without any ML speed-up. The authors discuss relevant work, but it is still unclear whether the methods selected for comparison are state-of-art. Also, a major gap in the paper is that the data requirements of the method are not discussed in the paper at all."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality: The key novelty is the proposal of the dual-network architecture that jointly learns PDE system dynamics and optimal control decisions. While prior work has explored neural operators for PDE surrogates and proxy optimization for control, this paper is original in explicitly coupling these two components. \n\nQuality: The paper is well-executed technically, with a carefully designed model architecture. Comparisons against classical methods reveal compelling speed-ups, which can be significant for applications requiring very fast solutions. \n\nClarity: The paper and formulations are clear and logically structured. \n\nSignificance: PDE-governed systems based control has broad applicability across domains where PDEs arise, including fluid dynamics, thermal systems, chemical and biological processes, power networks, materials design and many more."}, "weaknesses": {"value": "1. While the selected PDE benchmarks (Burgers’, heat equation, voltage regulation) are commonly used in learning-based PDE research, they remain relatively low-dimensional compared to many real engineering PDE systems. The authors mention several times in their paper that this problem is intractable but the problems they are comparing to are not intractable. Should the authors include a higher-dimensional problem or discuss limitations of their approach when scaling up, it would significantly improve the paper quality. Essentially, do the authors believe their approach can solve problems currently intractable?\n2. The paper comparative results focus only on classical optimal control methods. Although these comparisons are compelling and necessary, the paper would be strengthened by comparisons or discussion relative to recent learning-enabled PDE control methods. Some of these are mentioned in \"Related Work\", without sufficient justification on why they were not selected for comparison. I suggest either better justification on why other methods are not applicable or addition of comparison with at least one state-of-art learning-based method.\n3. Although most learning-based PDE constrained papers in the ML field show results with these benchmarks, it is true that these problems do not capture all characteristics of real problems in control (e.g.,  noisy PDE parameters, limited data to learn from and measurement uncertainty). On this, the paper provides almost no information on how much data was required to train the models in order to achieve such accuracy. This information might be hidden somewhere in the Appendix, but it is important information to be more prominently provided, along with a discussion in at least the appendix on whether real control applications would have the data quality and quantity required to replicate these results. \n4. The authors claim that other learning based methods suffer from feasibility problems and non guarantee of constraint satisfaction. Does this work not have such limitations? Theoretical conditions for success are not deeply explored (e.g.,  when will the learned surrogate preserve feasibility or approximate optimality sufficiently? Please provide theoretical discussion or bounds (even qualitative) regarding approximation error between learned and true solution maps, or articulate assumptions under which the method is expected to succeed."}, "questions": {"value": "1. Do the authors believe their approach can solve problems currently intractable? What are some intractable examples and how would the method scale to these?\n2. Can such accuracies and speed-ups be expected only for systems which are perfectly described by a known PDE with highly certain parameters, known initial/boundary conditions (?) and certain assumptions about the ability to generate enough scenarios for training? What are the conditions to guarantee such performance?\n3. What are sampling requirements and what are costs for pre-training? Is the method expected to off-load all pre-training costs offline and not expected to require any resampling and retraining in an online control setting? Under which conditions would this be true?\n4. What is most relevant learning-based method and can it be added as a baseline method to compare to?\n5. One key advantage of paper is the dual-network architecture. And presumably this increases the performance of the method because it enables information to be learned between state dynamics and optimal control which un-coupled learning techniques do not take advantage of. Can this advantage be somehow quantified however, other than the fact that the overall approach is fast? Can the authors think of a test to show a de-coupled approach, to show that there is truly something in the coupling that leads to such better results. I am not sure if this question makes sense, please correct me if I am understanding this wrong.\n6. The results plots (Figures 3-5) are not the best quality and distinguishing between the different lines is hard to see. \n7. Minor typo on row 287: \"operator\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vLMX7VSdDx", "forum": "7ZqFjYzInJ", "replyto": "7ZqFjYzInJ", "signatures": ["ICLR.cc/2026/Conference/Submission9533/Reviewer_Wb68"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9533/Reviewer_Wb68"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9533/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968357975, "cdate": 1761968357975, "tmdate": 1762921095834, "mdate": 1762921095834, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}