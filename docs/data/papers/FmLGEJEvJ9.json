{"id": "FmLGEJEvJ9", "number": 3470, "cdate": 1757439035034, "mdate": 1759898088429, "content": {"title": "On Differentially Private String Distances", "abstract": "Given a database of bit strings $A_1,\\ldots,A_m\\in \\{0,1\\}^n$, a fundamental data structure task is to estimate the distances between a given query $B\\in \\{0,1\\}^n$ with all the strings in the database. In addition, one might further want to ensure the integrity of the database by releasing these distance statistics in a secure manner. In this work, we propose differentially private (DP) data structures for this type of tasks, with a focus on Hamming and edit distance. On top of the strong privacy guarantees, our data structures are also time- and space-efficient. In particular, our data structure is $\\epsilon$-DP against any sequence of queries of arbitrary length, and for any query $B$ such that the maximum distance to any string in the database is at most $k$, we output $m$ distance estimates. Moreover,\n\n- For Hamming distance, our data structure answers any query in $\\widetilde O(mk+n)$ time and each estimate deviates from the true distance by at most $\\widetilde O(k/e^{\\epsilon/\\log k})$;\n- For edit distance, our data structure answers any query in $\\widetilde O(mk^2+n)$ time and each estimate deviates from the true distance by at most $\\widetilde O(k/e^{\\epsilon/(\\log k \\log n)})$.\n\nFor moderate $k$, both data structures support sublinear query operations in the combined size of the query and its output. We obtain these results via a novel adaptation of the randomized response technique as a bit flipping procedure, applied to the sketched strings.", "tldr": "We design the first differentially private data structures for estimating Hamming and edit distances that are both time and space efficient.", "keywords": ["edit distance", "data structure", "differential privacy"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cd0ceb12a88b05f7d84291a05eb20c51361071ce.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies the following problem: given binary strings $A_1, \\ldots, A_m$ of length $n$, efficiently compute an $\\varepsilon$-DP data structure that can take any new length $n$ binary string $B$ and approximate its distance to each of $A_1, \\ldots, A_m$. It provides time- and space-efficient solutions for both Hamming and edit distance. The Hamming distance algorithm works by incorporating randomized response into an existing algorithm [PL07] for the non-private algorithm and, given $B$ within distance $k$ of each $A_i$, outputs estimates with error $\\tilde O(k/e^{\\varepsilon/\\log(k)})$. The edit distance algorithm is only partially described in the main body and, given $B$ within distance $k$ of each $A_i$, outputs estimates with error $\\tilde O(k/e^{\\varepsilon / [\\log(k) \\log(n)]})$."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "String distance is a natural problem, and I am not aware of past work on doing it with DP. The approach for Hamming distance is intuitive."}, "weaknesses": {"value": "1) For Hamming distance, unless $\\varepsilon$ is very large, the error bound $k/e^{\\varepsilon/\\log(k)})$ is close to the (trivial) error bound $k$ baked into the theorem assumption. The same problem holds (to a greater degree) for edit distance. This might be OK with even partial lower bounds, but no lower bounds are provided. Since $\\varepsilon$-DP is a fairly meaningless privacy guarantee unless $\\varepsilon$ is a small constant (say, $\\varepsilon \\ll 10$), these are very weak utility results (and this doesn't attempt to reason about whatever constants and log factors are being hid here).\n\n2) The notion of neighboring distances is restrictive: a neighboring databases can differ in one bit of one string. Using the motivating example from the intro (~Line 58), this is record-level (whether a person has condition X) rather than person-level (whether a person is in the database) privacy.\n\n3) The Hamming distance algorithm is just a pre-existing algorithm + randomized response, and the edit distance algorithm isn't described in the main body. This means the algorithmic novelty of the main paper is low. (I also don't see why the edit algorithm has to be postponed for space -- there are many instances of unnecessary pseudocode and spacing, so I'm sure there are a few paragraphs of space to be had with some light editing.) There are also some possible technical problems (see next section).\n\n4) The discussion of boosting (Remark 3.8) doesn't observe that $\\varepsilon$ would also need to be split to maintain a fixed privacy level, and the effect of splitting on boosting success probability is unclear to me.\n\n5) I have previously been involved in two review processes for this paper. Both times, multiple reviewers asked about issues like those above (and others), and the authors silently withdrew the paper without responding to comments and resubmitted it to another conference with minor cosmetic changes. I understand that it is challenging to incorporate reviewer feedback, and not every reviewer is correct all the time, but it is disappointing to see authors just ignore many similar reviews and keep resubmitting essentially the same paper."}, "questions": {"value": "In addition to the weaknesses mentioned above, here are some more concrete questions for the authors:\n\n1) What does $A[p:q]$ mean?\n\n2) What are the base cases of $D(i, j)$? What happens when the set used to define $F(r, d)$ is empty? What are the actual domains of these functions and $EXTEND$ and $LCP$? The paper quickly writes out some recursive definitions, but base cases are glossed over."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yyLz2OzecQ", "forum": "FmLGEJEvJ9", "replyto": "FmLGEJEvJ9", "signatures": ["ICLR.cc/2026/Conference/Submission3470/Reviewer_Rzvy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3470/Reviewer_Rzvy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761162879798, "cdate": 1761162879798, "tmdate": 1762916742608, "mdate": 1762916742608, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the following problem: given a dataset of $m$ binary strings, each of length $n$, the goal is to construct a data structure that satisfies $\\epsilon$-differential privacy (under the notion where two neighboring datasets differ in a single bit of a single string). Given a query string of length $n$, the data structure should output estimated Hamming or edit distances between the query and each string in the dataset.\n\nThe paper assumes that the distance between the query string and each dataset string is at most $k$. Under this assumption, the proposed data structure can be constructed in time $\\tilde{O}(mn)$, and supports queries in $\\tilde{O}(mk + n)$ time for Hamming distance and $\\tilde{O}(mk^2 + n)$ time for edit distance. The resulting approximation error is on the order of $\\tilde{O}(k)$."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is generally well written and easy to follow.  \n\nA notable feature of the proposed data structure is that it supports an unbounded (potentially infinite) number of queries while maintaining differential privacy."}, "weaknesses": {"value": "The assumptions and resulting bounds in the paper do not appear to be meaningful (please correct me if I am mistaken).  \n\n\nLet $A_1, \\ldots, A_m$ denote the dataset strings and $B$ the query string.\n\n1. The assumption that $D(A_i, B) \\le k$ for all $i \\in [m]$ implies that $D(A_i, A_j) \\le 2k$ for all pairs $(i, j)$. \n         Consequently, all dataset strings must be highly similar to each other if $k$ is small. \n\n\n2. On page 6, the reported Hamming distance error bound is  \n   $$\n   \\frac{k \\log^3 k}{1 + e^{\\epsilon / \\log k}}.\n   $$\n   This bound is not meaningful for typical values of $\\epsilon$, e.g., $\\epsilon = O(1)$, in which case it simplifies to $\\Theta(k \\log^3 k)$.  \n\n3. In comparison, a trivial estimator that always outputs $D(A_i, B) = 0$ already incurs an error of at most $k$, which is asymptotically smaller. Moreover, this baseline requires no preprocessing and achieves $O(1)$ query time.  \n\n4. To achieve an error bound of $o(k)$, one would need $\\epsilon = \\omega((\\log k) \\cdot \\log \\log^3 k)$, which can be unrealistically large.  \n\n5. If $k \\in o(n)$, the assumption $D(A_i, B) \\le k$ implies that all dataset strings are nearly identical—differing in only an $o(n)/n = o(1)$ fraction of positions.  \n   This already covers the case where $k = \\Theta(n^c)$ for some $c \\in (0, 1)$, in which achieving meaningful accuracy requires $\\epsilon = \\Omega(\\log n)$, again much larger than typical privacy budgets.  \n   Of course, if $k = \\Omega(n)$, we also have $\\epsilon = \\Omega(\\log n)$."}, "questions": {"value": "1. I would suggest introducing the definition of the neighboring relation earlier in the paper, rather than deferring it to the preliminaries section. While reading the introduction, I was looking for this definition for a while before eventually finding it later in the paper.\n\n2. Line 262: the probability expression appears to contain a typo. It should be  \n   $$\n   \\Pr[ \\forall j \\in [M_2], |T_j| \\le 10 \\log k ]\n   $$\n   instead of  \n   $$\n   \\Pr[ \\forall j \\in [M_2], |  |T_j| \\le 10 \\log k ].\n   $$"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "U02f0L7HzX", "forum": "FmLGEJEvJ9", "replyto": "FmLGEJEvJ9", "signatures": ["ICLR.cc/2026/Conference/Submission3470/Reviewer_X4SQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3470/Reviewer_X4SQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761660418597, "cdate": 1761660418597, "tmdate": 1762916740808, "mdate": 1762916740808, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of differentially private approximating bit strings in a database. In particular, given $m$ strings datasets, the task is to output a sketch while ensuring privacy that can be used to answer any query. This is one of the most fundamental data structure problem, \n\nThe authors consider two different natural error metric: Hamming and edit distance and for each of them they provide algorithm that has error better than just using the Laplace mechanism."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "They study one of the most fundamental data structure problems, and the error metric is fine.\n\nTheir results are clearly stated, which makes it easy to understand the merit of the paper. I really want to thank the authors for that."}, "weaknesses": {"value": "The error on approximating Hamming distance between each query and database string scales as $k \\log k$ (for typical small $\\varepsilon$. I am confused as to why the algorithm's accuracy is in any way meaningful. \n\nThe algorithmic novelty for the Hamming distance data structure is unclear. It is described as an adaptation of a non-private approach, followed by the use of a randomized response."}, "questions": {"value": "Is the paper doing something more than just randomized response on non-private algorithm? \n\nWhat other notion of neighboring would make sense when studying string distance with DP? I am not from the string distance community, so this might sound naive,"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LE40xdv8Ip", "forum": "FmLGEJEvJ9", "replyto": "FmLGEJEvJ9", "signatures": ["ICLR.cc/2026/Conference/Submission3470/Reviewer_Rm64"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3470/Reviewer_Rm64"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762210904465, "cdate": 1762210904465, "tmdate": 1762916740513, "mdate": 1762916740513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers differentially private algorithms for string matching. Specifically, consider a sensitive data set that is a list of $m$ strings of length $n$. The sensitive units are individual symbols of the strings. (So I guess in a database of DNA strings, one would want to protect individual alleles/mutations.)\n\nThe paper's algorithms output a data structure that takes as input a string $B$ and outputs estimates of the Hamming or edit distance to each of the $m$ sensitive strings. More precisely, the data structure takes a promise on the maximum distance $k$ between $B$ and any string in the database; it outputs a distance estimate with additive error $\\tilde O(k/e^{\\epsilon/\\log k})$. (That is, it is gives a nontrivial accuracy guarantee for $\\eps \\gg \\log k$.)\n\nThese algorithms are fairly fast—they run in quasilinear time $\\tilde O(mn)$."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses a well-defined mathematical problem and appear to involve nontrivial analysis of perturbed versions of string sketches (e.g. LSH ouputs)."}, "weaknesses": {"value": "* Motivation: The paper does not clearly list plausible settings where this notion of privacy (and accuracy) make sense. In the DNA application, for example, the privacy protection seems very weak.\n\n* Significance: The algorithm provides nontrivial accuracy guarantees only for very large values of $\\epsilon$. I couldn't understand a setting where this guarantee would be useful/important. (The paper mentions that $\\epsilon = k \\log k$ is \"too large for most applications\". Why is $\\log k$ ok? Both are much larger than 1.)"}, "questions": {"value": "Could the utility guarantee be rephrased as a mixed additive/multiplicative error guarantee? Even having additive error larger than $k$ could be useful if the goal is to distinguish large distances from small ones."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ioxHshFECb", "forum": "FmLGEJEvJ9", "replyto": "FmLGEJEvJ9", "signatures": ["ICLR.cc/2026/Conference/Submission3470/Reviewer_aPeU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3470/Reviewer_aPeU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3470/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762625839943, "cdate": 1762625839943, "tmdate": 1762916740285, "mdate": 1762916740285, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}