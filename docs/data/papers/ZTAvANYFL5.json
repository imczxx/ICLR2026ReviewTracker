{"id": "ZTAvANYFL5", "number": 5501, "cdate": 1757916007408, "mdate": 1759897970785, "content": {"title": "NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context", "abstract": "While LLMs have demonstrated medical knowledge and conversational ability, their deployment in clinical practice raises new risks: patients may place greater trust in LLM-generated responses than in nurses' professional judgments, potentially intensifying nurse–patient conflicts. Such risks highlight the urgent need of evaluating whether LLMs align with the core nursing values upheld by human nurses. This work introduces the first benchmark for nursing value alignment, consisting of five core value dimensions distilled from international nursing codes: _Altruism_, _Human Dignity_, _Integrity_, _Justice_, and _Professionalism_. We define two-level tasks on the benchmark, considering the two characteristics of emerging nurse–patient conflicts. The **Easy-Level** dataset consists of 2,200 value-aligned and value-violating instances, which are collected through a five-month longitudinal field study across three hospitals of varying tiers; The **Hard-Level** dataset is comprised of 2,200 dialogue-based instances that embed contextual cues and subtle misleading signals, which increase adversarial complexity and better reflect the subjectivity and bias of narrators in the context of emerging nurse-patient conflicts. We evaluate a total of 23 SoTA LLMs on their ability to align with nursing values, and find that general LLMs outperform medical ones, and _Justice_ is the hardest value dimension. As the first real-world benchmark for healthcare value alignment, NurValues provides novel insights into how LLMs navigate ethical challenges in clinician–patient interactions.", "tldr": "We propose the first real-world nursing values benchmark, constructed from a five-month field study across three hospitals, aiming to help deal with the emerging nurse-patient conflicts.", "keywords": ["Large language models", "value alignment", "nursing values"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2b49e776ed09671d2e0fd27c518f9e26dd251b94.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces NurValues, a novel benchmark designed to evaluate the alignment of Large Language Models (LLMs) with core professional nursing values. The authors argue that as LLMs are integrated into clinical practice, they pose new risks, such as amplifying nurse-patient conflicts if their responses are misaligned with the ethical judgments of human nurses. To address this, the authors identified five core nursing value dimensions from international nursing codes: Altruism, Human Dignity, Integrity, Justice, and Professionalism. The benchmark is built from real-world data collected during a five-month ethnographic field study in three different-tier hospitals, resulting in 976 initial nursing behavior instances. This data was used to create a two-level benchmark. The Easy-Level dataset consists of 2,200 instances (1,100 real cases plus 1,100 LLM-generated counterfactuals) that require standard ethical judgments. Hard-level dataset consists of 2,200 dialogue-based instances derived from the Easy-level cases. These dialogues are adversarially complex, embedding contextual cues, narrator biases, and misleading signals to simulate real-world conflicts."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The benchmark's foundation in a five-month, multi-site ethnographic field study is a significant strength. This grounding in real-world nursing behaviors, rather than purely synthetic or crowdsourced scenarios, makes the dataset highly relevant and authentic.\n\n2. The paper addresses a timely and critical gap. While other benchmarks test medical knowledge (e.g., MedQA) or general morality (e.g., ValueBench), NurValues is the first to focus specifically on the professional values of nursing, which is crucial for safe human-AI interaction in clinical settings.\n\n3. The two-level (Easy/Hard) structure is very effective. The Hard-Level dataset is a particularly strong contribution, as it moves beyond simple statement evaluation to simulate the messy, subjective, and emotionally-laden narratives that LLMs will actually encounter in patient-facing applications."}, "weaknesses": {"value": "1. The authors acknowledge this limitation, but it is a significant one. All data were collected from three hospitals in mainland China. Nurse-patient dynamics, ethical priorities (e.g., autonomy vs. beneficence), and communication norms vary dramatically across cultures. This limits the \"universal\" applicability of the findings and the benchmark itself without cross-cultural validation.\n\n2. The Justice dimension, identified as the \"hardest\", is built on only 74 samples (3.36% of the dataset). While this may reflect real-world observational frequency, it is difficult to draw robust conclusions from such a small and imbalanced subset. The difficulty may be an artifact of the low sample size.\n\n3. The five chosen values are foundational, but other critical nursing values, such as patient advocacy, accountability, and confidentiality, are not included. This limits the benchmark's scope in evaluating the full spectrum of nursing ethics."}, "questions": {"value": "1. In Section 2.2 (Step 3) and Figure 2, you state you \"leverage jailbreaking techniques for LLMs\"  to create the Hard-Level dataset. Could you please elaborate on this? What specific techniques were used? How does \"jailbreaking\" (which is typically used to bypass safety filters) help in generating dialogues with \"reasoning traps, biased framing, or plausible but misleading justification\"?\n\n\n2. In Table 1, could you please clarify the computation of the metrics? Specifically, what is Ma-F1? Is this the macro-average F1 score calculated across the two classes (align vs. violate) or the macro-average F1 score across the five different value dimensions?\n\n\n3. Your finding that general LLMs outperform medical LLMs is fascinating. Your analysis in Appendix G suggests domain-knowledge fine-tuning is insufficient. Could you provide more insight here? Does this imply that current medical fine-tuning methods might inadvertently hinder ethical reasoning, or is it simply that ethical alignment is an orthogonal skill that is not being trained for?\n\n\n\n4. The \"Justice\" dimension contains only 74 samples. How confident are you that its high difficulty  is a robust finding and not an artifact of this significant data imbalance? Did you perform any analysis (e.g., bootstrapping) to check the stability of this result?\n\n\n\n5. Given that the data is exclusively from mainland China, what are your thoughts on how these results might generalize to Western healthcare systems (e.g., in the US or Europe), where communication norms and the legal emphasis on patient autonomy are different?\n\n\n6. The related work section (Appendix B) does a good job of positioning NurValues against medical knowledge and general 3H value benchmarks. To strengthen the paper's claims about ethical and moral evaluation, I suggest you also situate it within the broader literature on moral reasoning benchmarks, such as the \"MoralBench\" paper [1]. This would provide a richer context for your contribution to the evaluation of LLM moral alignment.\n\nRef:\n\n[1] Ji, Jianchao, et al. \"Moralbench: Moral evaluation of llms.\" ACM SIGKDD Explorations Newsletter 27.1 (2025): 62-71."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "obDJhXc1SZ", "forum": "ZTAvANYFL5", "replyto": "ZTAvANYFL5", "signatures": ["ICLR.cc/2026/Conference/Submission5501/Reviewer_ogr8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5501/Reviewer_ogr8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761494174133, "cdate": 1761494174133, "tmdate": 1762918096708, "mdate": 1762918096708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduce NurValues, a real-world evaluation for five nursing values (Altruism, Human Dignity, Integrity, Justice, and Professionalism). It has two tasks (Easy -- purely case description and Hard -- expanded dialogue from cases). The evaluation is to ask models to identify the values involved in the scenarios. Authors evaluate 23 LLMs in total to do pairwise comparison and performance comparisons in both levels."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "S1: Good realistic dataset relating to clinical and nursing setting.\n- Authors carefully curated a real-world and diverse dataset describing nursing events happened in different types of hospital (rural, urban etc) with five-month field observational studies and five licensed nurse experts.\n- this resources could be very useful by being seed scenarios for many follow-up evaluations in this field\n\nS2: (Claimed) First work in nursing field to explore important topic (value alignment).\n- the value alignment topic is crucial to ensure good human-AI collaboration.\n- while the benchmark is not challenging for some sota llms (e.g. claude 3.5), this benchmark is the first work exploring nursing values. this can encourage many follow-up works focusing on this topic in clinical field."}, "weaknesses": {"value": "[minor] w1 Missing procedure details for deriving nursing values from principles/rules\n- Since the study builds on the five nursing values summarized in Section 2, it is important to justify how the authors identified and distilled these values (see lines 145–146).\n- recommend authors at least providing some examples of rules for each identified value. Ideally, they would release a dataset of rules/principles mapped with values to help readers and community to better understand.\n\n[minor] w2 Lack of human validation on the context consistency between easy and hard (extended dialogue version of cases in easy)\n-  topic consistency. Appendix D does not show the prompts used to obtain the 1–10 scale. Without this, the result may not be trustworthy.\n-It remains unclear whether topic consistency alone suffices to justify that the Hard dialogue version stays on track, which is needed to justify comparing the Easy and Hard benchmarks.\n\n[important] w3 Missing some models for testing in Table 1 to better support the arguments in discussion\n- It is surprising that the hard-level benchmark is not challenging: Claude 3.5 Sonnet attains about 90%, while GPT-4o only reaches 38.05%, given that their performances are close on many benchmarks. I suggest authors can double check if models outputs have any formatting issues. If no issues, I'm curious to read some examples and error analysis on why gpt-4o did worse. Can authors specify the time version of gpt-4o they used in table 1? Also recommend authors to run a few more GPT models (e.g. latest version of GPT-4o, GPT-4.1).\n- line 337-338 \"This suggests that domain-specific fine-tuning improves clinical Q&A but not ethical reasoning,\". I think it will be very interesting to see the analysis on the current reasoning models in this benchmark as well. And have the comparison between reasoning and non reasoning models in this clinical task.\n\n[important] w4 Missing actionable insights for the community and connections to prior works on value-based evaluations\n- Authors cited a couple of benchmark references, but I strongly recommend they consider some additional works that could inspire more interesting analyses and actionable insights for the community. Potential references and follow-ups:\n- DailyDilemma (https://arxiv.org/abs/2410.02683).their system-prompt steerability experiments could be adapted to the nursing principles/rules to see if they improve model performance, enriching the CoT setting examined by authors.\n- Works in values and AI safety: Emergent values https://arxiv.org/abs/2505.14633, LitmusValues https://arxiv.org/abs/2502.08640, Values in the wild https://arxiv.org/abs/2504.15236."}, "questions": {"value": "Q1 line 108. why use openai o1 to generate\n\nQ2 line 117-118: how do authors transform the case to dialogue formats?\n\nQ3 how exactly authors identify and distill five value dimensions. can you describe the procedures of it?\n\nQ4 line 252-253: what do you mean for jailbreaking techniques\n\nQ5 Figure 2: altruism: 0; altruism: 1 -> what does it mean\n\nminor:\nline 212: avoid using \"she\" to represent the nurse expert\nline 214: further details on human annotation procedure, please see App. C. => capatalize\nline 309  receive a semantic similarity score ≥ . => what score? 9?\nline 346: Ma-F1 ==> do you mean Macro-F1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KmjWO1mXIW", "forum": "ZTAvANYFL5", "replyto": "ZTAvANYFL5", "signatures": ["ICLR.cc/2026/Conference/Submission5501/Reviewer_fibq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5501/Reviewer_fibq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895922654, "cdate": 1761895922654, "tmdate": 1762918096299, "mdate": 1762918096299, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NurValues, a bilingual benchmark designed to test whether LLMs uphold key nursing values in clinical communication. The dataset includes 7,635 Easy-Level dialogue-derived cases and 2,100 Hard-Level adversarial cases with labels across five value dimensions and three levels of ethical alignment. The authors evaluate multiple general and medical LLMs, in zero-shot and in-context learning settings, using accuracy, macro-F1 and McNemar tests. Results show sizeable gaps on adversarial items and that general LLMs often outperform medical LLMs on value-sensitive judgments."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "* Clear problem framing. The benchmark is built around established nursing codes, providing strong domain grounding and clear construct definitions.\n\n* Good quality, realistic data with adversarial challenge cases. Easy-Level cases come from real nurse–patient dialogues. Hard-Level role-play and counterfactuals probe failure modes that is often omitted in other datasets. This two-tier design improves ecological validity and adversarial robustness assessment.\n\n* Careful annotation and reliability reporting. Reported inter-annotator agreement values shows a good practice  (however, number of samples used can potentially be increased, and a stratification for each sub-category of questions) [1].\n\n* Novelty and Relevance.The work fills a gap between general-purpose benchmarks and clinical-safety datasets, expanding the landscape of value-alignment evaluation [2-4]\n\n[1] Landis, J. R., & Koch, G. G. (1977). The measurement of observer agreement for\ncategorical data. Biometrics, 33(1), 159–174. (https://academic.oup.com/biometrics/article-abstract/66/4/1185/7333578)\n[2] Ren, Y., et al. (2024). ValueBench: Towards Comprehensively Evaluating Value\nOrientations and Value Understanding in LLMs. ACL. NurValues Review 3 (https://arxiv.org/pdf/2406.04214)\n[3] Zhao, W., et al. (2024). WorldValuesBench: A Large-Scale Benchmark Dataset for Multi-Cultural Value Awareness of Language Models. LREC-COLING. (https://aclanthology.org/2024.lrec-main.1539.pdf)\n[4] Huang, K., et al. (2024). FLAMES: Benchmarking Value Alignment of LLMs in Chinese. NAACL. (https://aclanthology.org/2024.naacl-long.256.pdf)"}, "weaknesses": {"value": "* Taxonomy coverage and balance. The benchmark focuses on five nursing value dimensions but several widely used nursing codes (e.g. privacy and confidentiality, advocacy, safety) seem to be missing [1-3].\n\n* Adversarial data generation limitations. Most adversarial cases come from a single frontier model, which may introduce stylistic artefacts and attack-surface bias tied to that model (as shown by [4]). \n\n* Evaluation metrics could be richer. Accuracy and macro-F1 on imbalanced, ordinal-like labels may hide clinically relevant errors. \n\n* Limited comparisons to adjacent benchmarks. The paper cites but does not transfer-test or cross-validate on ValueBench, WorldValuesBench, FLAMES or medical-safety frameworks like MedSafetyBench. Such comparisons would clarify what NurValues uniquely captures in healthcare ethics.\n\n[1] International Council of Nurses. (2021). ICN Code of Ethics for Nurses. International Council of Nurses. (https://www.icn.ch/sites/default/files/2023-06/ICN_Code-of-Ethics_EN_Web.pdf) (accessed: during review period ICLR’26)\n[2] Nursing and Midwifery Council. (2024). The Code: Professional standards of practice and behaviour for nurses, midwives and nursing associates. NMC.(https://www.nmc.org.uk/standards/code/) (accessed: during review period\nICLR’26)\n[3] American Nurses Association. (2025). The Code of Ethics for Nurses. ANA. https://codeofethics.ana.org/ (accessed: during review period ICLR’26)\n[4] Wang, Y., et al. (2024). A survey on natural language counterfactual generation. EMNLP. (https://aclanthology.org/2024.findings-emnlp.276.pdf)"}, "questions": {"value": "1. Could you clarify the rationale for selecting only five value dimensions and omitting others commonly emphasised in nursing codes (e.g. privacy/confidentiality, advocacy, patient safety)? Would you be willing to add a brief justification or including these categories in future iterations?\n\n2. Since adversarial cases rely heavily on a single frontier model, how do you mitigate potential stylistic bias or attack-surface overfitting? Would you consider multi-model generation or human-seeded adversarial prompts to strengthen robustness?\n\n3. How does NurValues empirically differ from or complement ValueBench, WorldValuesBench, FLAMES or MedSafetyBench?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hVLlewu0Nt", "forum": "ZTAvANYFL5", "replyto": "ZTAvANYFL5", "signatures": ["ICLR.cc/2026/Conference/Submission5501/Reviewer_HQ6S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5501/Reviewer_HQ6S"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997559783, "cdate": 1761997559783, "tmdate": 1762918095718, "mdate": 1762918095718, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper explores the ability of LLMs to track nursing values from a situational summary. Authors conduct numerous evaluations on their chosen \"values\""}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors describe various ablations or slices to evaluate the performance. It is commendable that the authors collected real world data and extensively annotated."}, "weaknesses": {"value": "1. Significance:\n- Why is such a benchmark required?\n- Since all of the data situational not conversational, is the challenge different?\n\n2. Novelty:\n- There has been similar exploration (https://pmc.ncbi.nlm.nih.gov/articles/PMC12099337/, https://arxiv.org/pdf/2505.04152, https://arxiv.org/abs/2409.15188) around LLMs for care and clinician-patient interaction. Or other \nhospital agent (https://dl.acm.org/doi/10.1145/3699765, https://arxiv.org/pdf/2401.05654). Where does a benchmark like this add value? Authors could consider distinguishing the benchmark and positioning it better?\n- Implications of how others might use the benchmark needs to be better addressed\n\n3. Counterfactuls:\nThe validity of counterfactuals is unclear. For an alternate situation, did the manual coders also check for ecological validity (or practicality) of the new situation?\n\n4. Choice of models:\nThe authors focus a lot on medical LLMs. Since the task is more trait or affective, this focus needs to be further justified to even consider why medical LLMs \"may\" encode this knowledge or one might want them to.\n\n5. Metrics:\nThe annotation allows for multiple positive labels. How are the scores calculated in such cases?"}, "questions": {"value": "Included in weakness section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "F0gtWDEZJb", "forum": "ZTAvANYFL5", "replyto": "ZTAvANYFL5", "signatures": ["ICLR.cc/2026/Conference/Submission5501/Reviewer_6op4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5501/Reviewer_6op4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5501/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762059878538, "cdate": 1762059878538, "tmdate": 1762918094960, "mdate": 1762918094960, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}