{"id": "UKPDpKGXAi", "number": 4802, "cdate": 1757769763857, "mdate": 1759898012121, "content": {"title": "A widely used protocol for EEG classification experiments leads to a confound", "abstract": "A temporal confound has been previously reported in a (now widely\nused) dataset that others have tried to suggest is nonetheless\njustified.  Despite attempts to make the community aware of this\nconfound, a significant number of publications continue to use the\nconfounded dataset, thereby drawing unsupported conclusions.  We\npresent a new experiment that conclusively demonstrates that the\nidentified confound in the dataset cannot be explained away by\nrecourse to factors such as block design, session duration, number of\nsubjects, or pooling multiple subjects.  We advise caution when\ndesigning, conducting, and interpreting the results of experiments\nthat use this problematic protocol.", "tldr": "We demonstrate that the protocol used to collect about 18 datasets used in nearly 100 papers in irreparably flawed.", "keywords": ["EEG"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/718119c8a877056197a006a78cf460aae52fbc14.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper focuses on temporal drift as a confound or 'embedded clock' in prominent EEG experimental designs. In particular, correlation of stimulus class with experiment timing. Although corrected experimental designs have been suggested, Palazzo et al. 2020 and 2024 claim the original confound is acceptable on several bases. The current paper rebuts this claim and highlights that the confounder remains."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well motivated and highlights an important problem in the literature (as well as problem in the peer-review system itself). The misapplication and misinterpretation of EEG data may also carry serious ethical concerns, e.g., if deployed in critical healthcare settings. For these reasons, it is very important that all such experimental designs are well-reasoned and understood."}, "weaknesses": {"value": "I found the presentation and writing to be quite poor. On pages 2 and 3, there are huge numbers of in-text citations. It would be better to put this list in the appendix, for example, and save the limited real estate of the conference paper for more important points. On this point, the paper itself comes in at under 5 pages, with no appendices. This itself is not a showstopper for me: some of the best papers are short. However, if the quantity of content is limited, I expect the content in the main text to be information-dense and of very high quality. I do not find that it is, both in presentation and content.\n\nIn particular:\n1. The paper primarily replicates and extends prior refutation studies with minor methodological variations, offering limited new theoretical or analytical insight.\n2. Only six subjects were tested, which constrains generalisability and statistical power, especially given EEG’s high inter-subject variability.\n3. While the study controls the temporal confound, other possible sources of bias (e.g., fatigue, attention drift, order effects beyond class blocks) are acknowledged but not experimentally tested."}, "questions": {"value": "1. What anonymised information about the human participants did you record?\n2. What informed consent and data protection procedures did you put in place?"}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "There is no mention of the study's ethics board approval or an informed consent procedure for the human participants, nor of data protection procedures. This information may be in part of the content removed for anonymity -- but, if not, this presents an ethical concern, in my view."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "du0ziv7TiT", "forum": "UKPDpKGXAi", "replyto": "UKPDpKGXAi", "signatures": ["ICLR.cc/2026/Conference/Submission4802/Reviewer_TyXs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4802/Reviewer_TyXs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4802/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760468350368, "cdate": 1760468350368, "tmdate": 1762917584004, "mdate": 1762917584004, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper contains similar elements as another paper submitted to this conference."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "None"}, "weaknesses": {"value": "A similar paper has been submitted to this conference."}, "questions": {"value": "none"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "x1tloZS04V", "forum": "UKPDpKGXAi", "replyto": "UKPDpKGXAi", "signatures": ["ICLR.cc/2026/Conference/Submission4802/Reviewer_5HxH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4802/Reviewer_5HxH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4802/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761683229681, "cdate": 1761683229681, "tmdate": 1762917583516, "mdate": 1762917583516, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a replication experiment demonstrating that a widely used block-design EEG classification protocol induces a temporal confound, linking the downstream class with time. It shows that classification accuracy depends heavily on this confound rather than true neural decoding. The paper critiques the continued use of flawed datasets and protocols in the field."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The concern identified in about temporal confounds in EEG classification experiments is apt and essential to communicate to the scientific community, because such confounds fundamentally undermine the validity of a large body of published EEG decoding research, potentially misguiding future methods development and applications.\n\nAddressing this issue is critical for ensuring methodological rigor, truthful interpretation of results, and the ethical advancement of EEG-based neuroscience and brain-computer interface research.\n\nThe work is a replication of prior protocol with controlled manipulation of stimulus block order across multiple subjects, providing a thorough critique of defending arguments for block design, short sessions, and pooling subjects."}, "weaknesses": {"value": "The language is generally direct but sometimes overly assertive in tone, bordering on confrontational regarding the ongoing use of flawed datasets in the community."}, "questions": {"value": "Why have the authors not included similar analyses directly on the original datasets from Spampinato et al. or other widely used confounded datasets, to further validate the generalizability of their findings?"}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "details_of_ethics_concerns": {"value": "Agreeing with the concern raised earlier by reviewers, the articles 4793 and 4802 are very similar. The two papers strongly overlap in thematic concerns and call for randomized designs but differ in specific emphases: one paper is a detailed experimental replication and refutation targeting a widely used protocol and its dataset, while the second is a broader scope showing pervasiveness of temporal correlation across datasets and disproving filtering as a solution. Both could have been combined given the context and text including the citations are highly similar."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SJDRECd9uy", "forum": "UKPDpKGXAi", "replyto": "UKPDpKGXAi", "signatures": ["ICLR.cc/2026/Conference/Submission4802/Reviewer_C5VV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4802/Reviewer_C5VV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4802/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762002629598, "cdate": 1762002629598, "tmdate": 1762917583128, "mdate": 1762917583128, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "There seems to be a strong similarity between submissions 4793 and 4802. Both submissions point out a weakness of the experimental design of prior work studying visual stimuli decoding from EEG. While this reviewer agrees that randomized stimuli designs are critical in data collection to reduce the impact of confounding factors like temporal drifts often encountered in biosignals, it seems very likely that both articles originate from the same authors."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "N/A"}, "weaknesses": {"value": "N/A"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "details_of_ethics_concerns": {"value": "To this reviewer, it seems likely that the authors submitted essentially the same work (submission 4793 and 4802) through different channels in hopes of achieving acceptance. While the authors might have a valid scientific critique, this method of presentation is not acceptable."}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "915QssboYr", "forum": "UKPDpKGXAi", "replyto": "UKPDpKGXAi", "signatures": ["ICLR.cc/2026/Conference/Submission4802/Reviewer_pPTE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4802/Reviewer_pPTE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4802/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762466542282, "cdate": 1762466542282, "tmdate": 1762917582756, "mdate": 1762917582756, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Historical Background and Significance"}, "comment": {"value": "To understand this work's significance, consider this brief historical\noverview.\n\nSpampinato et al. (2017) introduced a block-designed dataset\n(\"Perceive\") and methods that claim to achieve extremely high accuracy\ndecoding stimulus image class from EEG recordings. This was amplified\nby follow on papers (Kavasidis et al. 2017, Palazzo et al. 2018,\n2020a, 2020b, 2021), many of which claim to do things like reconstruct\nstimulus images from EEG recordings. Further, Tirupattur (2018) does\nthis with a fresh dataset (Kumar 2018) that has the same block design.\n\nLi et al. (2021) debunked all of the above, demonstrating that the\nPerceive dataset suffers from a block confound. EEG exhibits drift,\nencoding a clock in the signal. Since Perceive was collected with all\nand only stimuli of the same class being temporally adjacent, the\nclassifier can mistakenly classify the clock/drift instead of the\nstimulus-related EEG response. Follow on papers (Ahmed et al. 2021,\n2022, Bharadwaj et al. 2023) added novel independent confirmation of\nthe results of Li et al. (2021).\n\nDespite this, Palazzo et al. (2020b, 2021, 2024) continue to argue\nthat their dataset is valid. At this point, there are over one hundred\npapers that use the Perceive dataset, the Kumar (2018) dataset, or\nother datasets that suffer from the same block confound. Many new\ndatasets have been collected with this same block confound, some of\nwhich are becoming widely used. The vast majority of these were\npublished after the confound became known (Li et al. 2021). Some of\nthese are unaware of the confound. Others are aware, but dismiss it,\noften based on the argument of Palazzo et al. (2020b, 2021, 2024).\n\nThat argument is what this manuscript refutes.\n\nThis confound has been extensively debated on blogs like reddit, yet\nthat too has not stopped the extensive publication of flawed work.\n\nThere are three distinct levels of severity of this issue, which\nprogressively support greater need for continued publication:\n\n 1. Many authors are unaware of the confound, despite the fact that it\n    was published in prominent venues (e.g., TPAMI, CVPR, NeurIPS) and\n    continue to publish flawed work\n\n 2. While many authors are aware of the confound, they nonetheless\n    ignore the warning and continue to publish flawed work.\n\n 3. Some authors dismiss the confound and actively argue for the\n    community to continue to employ flawed methods."}}, "id": "MO1alGbnOa", "forum": "UKPDpKGXAi", "replyto": "UKPDpKGXAi", "signatures": ["ICLR.cc/2026/Conference/Submission4802/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4802/Authors"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission4802/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763747730615, "cdate": 1763747730615, "tmdate": 1763747730615, "mdate": 1763747730615, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Re: Concerns about duplicate submissions"}, "comment": {"value": "We submitted five manuscripts to ICLR 2026. To summarize:\n\n  4790: Palazzo (2020b, 2021) introduces a method that claims to\n        jointly train two mappings, from EEG and images, to a common\n        embedding space. We debunk central claims about this\n        embedding. We do this both for the confounded dataset and\n        nonconfounded datasets.\n\n  4793: Palazzo et al. (2020b, 2021, 2024) claim that their dataset\n        does not suffer from drift. We show that three other datasets,\n        all collected by different people in different labs, suffer\n        from drift, demonstrating that drift is unavoidable with EEG.\n\n  4796: Palazzo et al. (2020b, 2021) produce activation maps and claim\n        that these are consistent with neuroscience knowledge. We\n        debunk this claim.\n\n  4802: Palazzo et al. (2024) further claim that their dataset is\n        valid by arguing that the experiments in Li et al. (2021),\n        Ahmed et al. (2021, 2022), and Bharadwaj (2023) were\n        improperly conducted. We repeat the experiment in Spampinato\n        et al. (2017) exactly, in a controlled fashion, where the only\n        thing varied is block order. this conclusively demonstrates\n        that Spampinato et al. (2017), Kavasidis et al. (2017),\n        Palazzo et al. (2018, 2020a, 2020b, 2021, 2024), and the one\n        hundred other papers are flawed.\n\n  4804: Palazzo et al. (2024) makes numerous false statements about\n        Li et al. (2021), Ahmed et al. (2021, 2022), and Bharadwaj (2023).\n        We correct those statements.\n\nThese are all independent. There is no duplicate substantive material\nbetween these five submissions and Li et al. (2021), Ahmed et al.\n(2021, 2022), and Bharadwaj (2023). While they all comment on the same\nbody of flawed work, they each introduce and discuss distinct\ntechnical issues and make distinct contributions.\n\nWe included §2 Significance in all five manuscript. While largely the\nsame text, this is not the technical contribution of each respective\nmanuscript. It solely serves to highlight the significance of the\nspecific technical contribution in each individual manuscript, namely\nthat each offers independent refutation of one hundred papers. This is\nimportant, because even if one were to remedy one of the flaws, many\nothers remain, and a large and growing corpus of work remains flawed.\nFurther, it is conceivable that in the future, a paper might suffer\nfrom one flaw but not the other, yet it would still be invalid."}}, "id": "YC0Vj9Zuyf", "forum": "UKPDpKGXAi", "replyto": "UKPDpKGXAi", "signatures": ["ICLR.cc/2026/Conference/Submission4802/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4802/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission4802/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763747829118, "cdate": 1763747829118, "tmdate": 1763747829118, "mdate": 1763747829118, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Re: Public debate"}, "comment": {"value": "Several reviewers commented that public debate of this issue is\ninappropriate. We realize that this may be unconventional and uncommon\nin the ML community. But it is common in most other scientific fields\n(e.g., Brain and Behavioral Science, Psycoloquy, ...). Public debate\nthrough publication is the well-established method for arriving at\nscientific truth. Schaeffer (2025) have argued that a mechanism for\npublishing critiques and refutations is sorely lacking in ML.\n\nThe vast majority of the reviews of all five of these submissions\nfocus on the fact that they are unconventional. Essentially none of\nthe reviews discuss any technical flaws in these submissions. We\nwould be happy to discuss and address any technical flaws."}}, "id": "GBMxYw8hRk", "forum": "UKPDpKGXAi", "replyto": "UKPDpKGXAi", "signatures": ["ICLR.cc/2026/Conference/Submission4802/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4802/Authors"], "number": 8, "invitations": ["ICLR.cc/2026/Conference/Submission4802/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763747890777, "cdate": 1763747890777, "tmdate": 1763747890777, "mdate": 1763747890777, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Specific relevance and significance to ICLR and the ML community"}, "comment": {"value": "It is important, if not imperative, for the community to publish this\nwork. Without it, the community continues to submit and publish more\nflawed work at a growing rate. Fifty new papers papers have been\npublished since the flaw was first reported in prominent venues: once\nin CVPR (Ahmed et al. 2021) and three times in TPAMI (Li at al. 2021,\nAhmed et al. 2022, Bharadwaj et al 2023).\n\nSome recent flawed work has been published even by the ML community in\ntop ML venues, despite awareness of the issue: Liu et al. (2024) in\nNeurIPS collects a new dataset that suffers from the block\nconfound. While the authors cite Li et al. (2021) and Ahmed et al\n(2021), they fail to appreciate (or maybe hide the fact) that their\nwork is confounded.\n\nSome recent flawed work has even been submitted to ICLR 2025 (and\napparently resubmitted to ICLR 2026 despite reviewer warnings). It\nappears that even the reviewer pool of ICLR is unaware of the severity\nof the confound.\n\nhttps://openreview.net/forum?id=ejVuTFFkl6&noteId=zafmRtlFw1\n\ncollects a new dataset that suffers from the block confound. While the\nauthors again cite Li et al. (2021), they incorrectly claim that their\ndataset does not suffer from the confound. All four of the reviewers\npoint this out. While this submission was rejected, three of the\nreviewers rated it as \"Soundness: 3: good\" and two of the reviewers\nrated it as \"Contribution: 3: good\".\n\nThe apparent resubmission (18265) to ICLR 2026 again cites Li et\nal. (2021) and again incorrectly claims that their dataset does not\nsuffer from the confound. Again, three of the four reviewers point out\nthat this work suffers from the block confound. And again, two of the\nreviewers rate this as \"Soundness: 3: good\", one of the reviewers\nrates this as \"Contribution: 3: good\", and one even rates this as\n\"Contribution: 4: excellent\" and recommends acceptance.\n\nWe have a simple question for the reviewers, area chairs, and program\nchairs: If one cannot publish refutations like this in ICLR, how else\ndo you propose we address the fact that there is a large and growing\nbody of flawed work being published?"}}, "id": "wLZOVjW2oJ", "forum": "UKPDpKGXAi", "replyto": "UKPDpKGXAi", "signatures": ["ICLR.cc/2026/Conference/Submission4802/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4802/Authors"], "number": 9, "invitations": ["ICLR.cc/2026/Conference/Submission4802/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763747926033, "cdate": 1763747926033, "tmdate": 1763747926033, "mdate": 1763747926033, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}