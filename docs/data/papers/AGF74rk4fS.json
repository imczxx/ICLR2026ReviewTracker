{"id": "AGF74rk4fS", "number": 22763, "cdate": 1758335185904, "mdate": 1759896848381, "content": {"title": "HiSin: : A Sinogram-Aware Framework for Efficient High-Resolution Inpainting", "abstract": "High-resolution sinogram inpainting is essential for computed tomography reconstruction, as missing high-frequency projections can lead to visible artifacts and diagnostic errors. Diffusion models are well-suited for this task due to their robustness and detail-preserving capabilities, but their application to high-resolution inputs is limited by excessive memory and computational demands. To address this limitation, we propose HiSin, a novel diffusion-based framework for efficient sinogram inpainting that exploits spectral sparsity and structural heterogeneity of projection data. It progressively extracts global structure at low resolution and defers high-resolution inference to small patches, enabling memory-efficient inpainting. Considering the structural features of sinograms, we incorporate frequency-aware patch skipping and structure-adaptive step allocation to reduce redundant computation. Experimental results show that HiSin reduces peak memory usage by up to 30.81% and inference time by up to 17.58% than the state-of-the-art framework, and maintains inpainting accuracy across.", "tldr": "", "keywords": ["image inpainting", "diffusion models", "tomography", "low dose", "synchrotron x-ray"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6296ecff70bc9635dc581d4e76b4b73bdfc30a31.pdf", "supplementary_material": "/attachment/4fd257fe2f2b8013a6ccca967c975081cddcfce7.pdf"}, "replies": [{"content": {"summary": {"value": "This paper tackles the challenge of applying diffusion models to high-resolution sinogram inpainting (e.g., $2048 \\times 2048$) , a task critical for CT reconstruction that is often infeasible on standard hardware due to excessive memory and computational demands.\nThe authors propose HiSin, a novel framework that requires no retraining of the base diffusion model. The framework is built on three key ideas tailored to the specific properties of sinogram data. Experiments show that HiSin enables $2048 \\times 2048$ inpainting on a 40GB A100 GPU (where baselines like RePaint fail), reducing peak memory by up to 30.81% and inference time by up to 17.58% compared to the most efficient baseline (HiDiffusion), all while maintaining comparable or better inpainting quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. High Practical Impact and Significance: The primary strength of this paper is that it solves a practical problem. Standard diffusion models cannot run on $2048 \\times 2048$ sinograms on a high-end 40GB A100 GPU. HiSin enables this, making high-resolution diffusion-based inpainting feasible.\n\n2. Inference-Time Framework (No Retraining): A major advantage is that HiSin is a collection of optimizations applied at inference time. It does not require any architectural changes or costly retraining of the underlying diffusion model.\n\n3. Strong Efficiency Gains: The method delivers clear and substantial improvements in both peak memory and inference speed. A 30.81% memory reduction and 17.58% speedup over the next-best efficient baseline (HiDiffusion) are excellent results, especially since this is achieved without a loss in quality.\n\n4. Domain-Aware Design: The authors provide a strong justification for why their method works, linking each component to specific structural properties of sinogram data (spectral sparsity, smooth backgrounds, and the fact that sinogram patches remain physically meaningful, unlike patches of a natural image, this insight is novel to me). This domain-aware design makes the solution more elegant and convincing.\n\n5. Thorough Ablation Study: The paper is supported by an excellent ablation study (Table 3). This study convincingly demonstrates that all three components (progressive inference, patch skipping, and adaptive steps) are necessary and contribute to the final result, either by preserving quality or by providing the claimed efficiency gains."}, "weaknesses": {"value": "1. Hyperparameter Sensitivity: The framework introduces several new hyperparameters that seem important for balancing quality and efficiency: the fusion weights ($\\lambda_{mid}$, $\\lambda_{high}$) , the patch skipping frequency threshold ($\\tau$) , the adaptive step range $[S_{min}, S_{max}]$ , and the sigmoid steepness ($\\beta$). It would be nice to know how robust the method is to these choices. For instance, how much does quality drop or speed increase if $\\tau$ is made more aggressive, or if $S_{min}$ is increased? Even missing the experiment, more simple discussion should be added.\n\n2. Limited Scope: The paper's strength is also its main limitation. The authors compellingly argue why this method is suited for sinograms and not for natural images (where patches lose semantic context). While this is a fair and honest assessment, it does limit the paper's scope and potential impact for the broader ICLR audience.\n\n3. Complexity of Skipped Patch Approximation: For skipped (low-frequency) patches, the output is replaced by a pre-computed approximation generated by running the diffusion model on a patch of Gaussian noise. This seems slightly complex. It's not clear why this is superior to a simpler heuristic, such as just using the upsampled output from the mid-resolution stage ($Up(\\hat{x}_{mid}^{i})$) for that patch, or a simple bilinear interpolation. The justification for this specific choice is too weak."}, "questions": {"value": "1. For the skipped patches, you use an approximation derived from running the model on Gaussian noise. Did you experiment with simpler alternatives, such as directly using the upsampled mid-resolution patch ($Up(\\hat{x}_{mid}^{i})$) or a simple interpolation? What was the benefit of using the synthetic noise patch?\n\n2.For the cosine-based patch blending, you conditionally apply it based on a gradient threshold $\\eta$ computed on the mid-resolution sinogram. What was the reasoning for using the mid-resolution image for this check instead of the high-resolution input? Was this a performance optimization, or did it provide a more robust signal for blending?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bLoRoUtn3T", "forum": "AGF74rk4fS", "replyto": "AGF74rk4fS", "signatures": ["ICLR.cc/2026/Conference/Submission22763/Reviewer_B4fy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22763/Reviewer_B4fy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760925927794, "cdate": 1760925927794, "tmdate": 1762942376471, "mdate": 1762942376471, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to use generative models, specifically diffusion-based ones, for an inpainting task on high-resolution sinograms (2048×2048).\nThe main challenge adressed in this work is how to deal with *the memory cost and the inference time* of these diffusion-based methods for large images.\nThe authors propose a strategy to accelerate these methods / manage their memory cost that leverages the structured and sparse nature of sinogram data.\nThe method is based on an adaptation of the RePaint algorithm, an inpainting approach that uses a pre-trained, task-agnostic diffusion model (but can be used with other iterative diffusion based methods). To recall, RePaint is an iterative diffusion-based sampling method that, at each step, combines information from the unmasked and masked regions of the image.\n\nThree main modifications to RePaint are proposed:\n1. **Progressive resolution refinement** The reconstruction is first done on downsampled versions of the sinogram (at low/ mid resolution) and then done patch-wise at high resolution -> it limits the memory peak.\n2. **Patch skipping** Some patches are skipped during denoising based on a score that measures high-frequence energy, it allows to skip typically patches from background -> it accelerates sampling.\n3. **Adaptative number of iterations** The number of diffusion steps per patch is adjusted according to a score that combines frequency-domain energy and pixel-wise entropy -> here again, it accelerates sampling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The main motivation of the paper is clearly identified: the focus is on reducing computational cost.\nTo this end, the ablation study is convincing and shows that each modification made achieves a good trade-off between reconstruction quality and computational efficiency. Notably, there is almost no degradation compared to the RePaint baseline.\n\n- Although the method is somewhat ad-hoc, it appears to be effective in practice and well adapted to the specific characteristics of the task."}, "weaknesses": {"value": "- The proposed approach is somewhat *engineering-oriented*. While the main modifications are quite simple, they introduce additionnal layers of complexity (a lot of hyperparameters to choose, strategy to map scores to number of iterations, handle patch boundary). \nEven if the paper explicits each of these choises, it makes the final method not so easily readable nor straightforward to reproduce.  In this regard, *releasing the code* would have helped to understand how simple is it or not to implement.\n\n- Related works focus mainly on diffusion model acceleration techniques for RGB images, which are in reality no so  related to what is done in this paper.\nA *dedicated section on CT reconstruction methods* would strengthen the paper.\nIt should clarify in which sense these methods differ, for instance which ones perform end-to-end reconstruction or only sinogram inpainting, what deep models are uses (generative or not), what are their limitations, etc.\nFor example, baselines such as SinoTx and ICT are missing from the related works and the statement in the introduction \"although end-to-end CT reconstruction has been explored…\" should be supported with citations."}, "questions": {"value": "- The experiments focus on masks that are either random or periodic. How does the proposed approach perform when large contiguous angular ranges are missing? I believe this is the setting where the generative capabilities of diffusion models should matter more.\n\n- The evaluation appears to be performed at the sinogram level only. The paper should also report results on the reconstructed images, as this is usually what matters in practice.  Moreover, the reconstruction process itself is not clearly described. What algorithm is used to obtain the reconstructed images shown in Figure 2 from the completed sinograms?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rLIl7mwUCo", "forum": "AGF74rk4fS", "replyto": "AGF74rk4fS", "signatures": ["ICLR.cc/2026/Conference/Submission22763/Reviewer_kYAh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22763/Reviewer_kYAh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761905818618, "cdate": 1761905818618, "tmdate": 1762942376147, "mdate": 1762942376147, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed a diffusion-based framework for efficient sinogram inpainting.\nThe proposed method extracts global structure at low resolution and defers high-resolution inference to small patches."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed method is memory efficient by multiscale scheme.\n\nThe spectral sparsity and structural heterogeneity of sinogram data is considered in the inference."}, "weaknesses": {"value": "1 The paper claims HiSin can be applied to existing diffusion models (e.g., RePaint) without retraining. However, does patch-wise inference with multi-scale fusion implicitly assume certain properties of the backbone model (e.g., sufficient receptive field or multi-scale training)? Would performance degrade if the backbone was trained only at low resolution (e.g., 512×512)?\n\n2 In the frequency-aware patch skipping mechanism, the authors use the FFT energy ratio \\gamma(P) combined with mask ratio to compute a skipping score. However, high-frequency information in sinograms is often concentrated in specific angular bands—does using only the outer third of the frequency spectrum sufficiently capture this directional sparsity?\n\n3 Although the low→mid→high resolution guidance preserves coarse structure, the final high-resolution stage processes patches independently and sequentially, lacking cross-patch refinement. This may cause stitching artifacts or inconsistencies—especially for fine structures spanning multiple patches under high mask ratios. The paper shows only successful cases and omits failure analysis or uncertainty quantification."}, "questions": {"value": "If it is possible to extend the method to 3D reconstruction, which is highly memory cost problem."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "H1c5xnkdf3", "forum": "AGF74rk4fS", "replyto": "AGF74rk4fS", "signatures": ["ICLR.cc/2026/Conference/Submission22763/Reviewer_CYkU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22763/Reviewer_CYkU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962219241, "cdate": 1761962219241, "tmdate": 1762942375823, "mdate": 1762942375823, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces HiSin, a framework for efficient sinogram inpainting. HiSin employs a multi-stage inference mechanism that first extracts global structures at a low resolution and then performs detail recovery at a high resolution, significantly reducing memory usage and inference time. The framework incorporates frequency-aware patch skipping and structure-adaptive step allocation strategies to minimize redundant computations. In terms of experiments, HiSin achieves performance comparable to state-of-the-art methods on the TomoBank and LoDoPaB datasets, while effectively improving memory efficiency and reducing inference time."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "### Originality\n- HiSin introduces a multi-stage inference mechanism that combines low-resolution and high-resolution processing; however, this approach is not uncommon.\n- The combination of frequency-aware patch skipping and structure-adaptive step allocation strategies is a significant enhancement to existing methods, effectively leveraging the characteristics of sinogram data to optimize computational efficiency.\n\n### Quality\n- The experimental results of HiSin are comparable to those of the Repaint technique across multiple datasets (such as TomoBank and LoDoPaB), while demonstrating improvements in memory usage and inference time.\n\n### Clarity\n- The structure of the paper is well-organized and logically coherent, effectively conveying the research objectives and results.\n\n### Significance\n- HiSin provides a novel framework for the specific task of medical image data inpainting."}, "weaknesses": {"value": "1. The quantitative experiments presented in Table 2 indicate that if the primary emphasis is solely on reducing GPU memory usage, this could significantly diminish the potential importance of the paper. Given that Repaint was developed for general image tasks and is a work from 2022 that achieves similar performance, this raises questions about whether the advancements presented by HiSin are sufficiently innovative to justify its novelty and impact.\n\n2. The paper lacks comparisons with more recent methods, which limits a comprehensive evaluation of HiSin's superior performance. In particular, I may have overlooked some of the latest image inpainting studies, such as \"Inpaint Anything\" or \"Flux Inpainting,\" which could lead to a skewed understanding of the existing work.\n\n3. A multi-stage inference mechanism is not uncommon."}, "questions": {"value": "1. Is it possible to include more recent methods, such as works from 2024 or 2025?\n2. Could you explain the necessity of comparing methods?\n3. Line 320 mentions that \"all baseline models are retrained from scratch using their official codebases.\" As far as I know, Repaint also does not require training. Can you provide details on how the comparisons with other methods were conducted?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XC3ckDhkC7", "forum": "AGF74rk4fS", "replyto": "AGF74rk4fS", "signatures": ["ICLR.cc/2026/Conference/Submission22763/Reviewer_dL3A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22763/Reviewer_dL3A"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999962261, "cdate": 1761999962261, "tmdate": 1762942375439, "mdate": 1762942375439, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}