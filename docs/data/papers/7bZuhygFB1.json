{"id": "7bZuhygFB1", "number": 3279, "cdate": 1757392557532, "mdate": 1763385934878, "content": {"title": "Understanding the Dilemma of Unlearning for Large Language Models", "abstract": "Unlearning seeks to remove specific knowledge from large language models (LLMs), but its effectiveness remains contested. On one side, \"forgotten\" knowledge can often be recovered through interventions such as light fine-tuning; on the other side, unlearning may induce catastrophic forgetting that degrades general capabilities. Despite active exploration of unlearning methods, interpretability analyses of the mechanism are scarce due to the difficulty of tracing knowledge in LLMs’ complex architectures. We address this gap by proposing unPact, an interpretable framework for unlearning via prompt attribution and contribution tracking. Typically, it quantifies each prompt token's influence on outputs, enabling pre- and post-unlearning comparisons to reveal what changes. Across six mainstream unlearning methods, three LLMs, and three benchmarks, we find that: (1) Unlearning appears to be effective by disrupting focus on keywords in prompt; (2) Much of the knowledge is not truly erased and can be recovered by simply emphasizing these keywords in prompts, without modifying the model’s weights; (3) Catastrophic forgetting arises from indiscriminate penalization of all tokens. Taken together, our results suggest an unlearning dilemma: existing methods tend either to be insufficient - knowledge remains recoverable by keyword emphasis, or overly destructive - general performance collapses due to catastrophic forgetting, still leaving a gap to reliable unlearning.", "tldr": "", "keywords": ["unlearning", "interpretability", "large language models"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/c9d5501c563bed63694c721e81d6ee6b1dedbfa6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces UNPact, an interpretable framework for analyzing unlearning in large language models (LLMs) using prompt attribution and token-level contribution tracking. \nBy quantifying the influence of individual prompt tokens, UNPact allows for the comparison of model behavior before and after unlearning, as well as the inspection of what is actually altered.\nThrough experiments on six unlearning methods, three LLMs, and three datasets, the paper evaluates why unlearning appears to work, whether knowledge is really erased or recoverable, and why catastrophic forgetting happens. \nKey findings reveal that existing unlearning approaches often disrupt focus on salient tokens but fail to irreversibly erase knowledge."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed method is straightforward and easy to understand.\n- The empirical design spans multiple unlearning methods, ensuring comprehensive evaluation.\n- The proposed framework UNPACT is simple yet powerful, allowing interpretability analysis applicable to both open- and closed-source LLMs."}, "weaknesses": {"value": "- Investigating the limitations of existing unlearning methods and the causes of catastrophic forgetting at the token level is not particularly novel. Previous studies [1,2] have already discussed these aspects in detail, which reduces the novelty of this paper.\n\n- The proposed method involves many sensitive hyperparameters for binary comparisons, which may reduce its reliability in practical applications. Moreover, the paper does not provide detailed ablation studies to show how these hyperparameters affect performance.\n\n- The framework relies heavily on perturbation-based token analysis, which may be computationally expensive and sensitive to prompt phrasing.\n\n- Some metric definitions, such as the recovery rate and destructive rate, are vague and potentially confusing.\n\n\n[1] Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models. AAAI 2025.\n\n[2] ReLearn: Unlearning via Learning for Large Language Models. ACL 2025."}, "questions": {"value": "- In lines 342–344, the authors state that “we define the recovery rate as the proportion of supposedly forgotten knowledge that can be restored.” This definition is vague, and the paper does not provide a detailed explanation of how the recovery rate is actually computed. The same issue applies to the definition of the destructive rate later in the paper.\n\n- I would like to know how the hyperparameters in Equations (3) and (4) are set, and whether the same hyperparameter values are applied to all samples in the unlearned set.\n\n- In line 357, the authors mention that “explicitly emphasizing the KEYTOKENS in the prompt elevates forgotten knowledge to the model’s Top-1 prediction.” I understand that this may increase the prediction probability of the forgotten knowledge, but does it always reach the Top-1 prediction? I am also curious whether combining FOCUSONKEY with PROBAB would further improve recovery performance.\n\n- The datasets used in the paper contain QA pairs with relatively short answers. Would the proposed method still perform well on more complex datasets with longer answers, such as the TOFU dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "43glXgDmpA", "forum": "7bZuhygFB1", "replyto": "7bZuhygFB1", "signatures": ["ICLR.cc/2026/Conference/Submission3279/Reviewer_JtCC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3279/Reviewer_JtCC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761622165827, "cdate": 1761622165827, "tmdate": 1762916644088, "mdate": 1762916644088, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "JTtEynefhM", "forum": "7bZuhygFB1", "replyto": "7bZuhygFB1", "signatures": ["ICLR.cc/2026/Conference/Submission3279/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3279/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763385924234, "cdate": 1763385924234, "tmdate": 1763385924234, "mdate": 1763385924234, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduce UNPACT, an interpretable framework for unlearning. It quantifies each prompt token’s influence on outputs, en- abling pre- and post-unlearning comparisons to reveal what changes. Experiments on six unlearning methods, three LLMs, and three benchmark show that existing methods tend either to be insufficient or destructive. However, the \"UNPACT\" framework proposed by the author is more empirical and lacks theoretical support."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The experimental setup is complete. Detailed experiments are conducted on various model structures and multiple baselines.\n- This paper shifts the research focus from studying “how to forget” to “the explainability of forgetting”.\n- The conclusions of the paper provide a clear research direction for the future."}, "weaknesses": {"value": "- Although this paper summarizes and implements the existing methods, it does not provide corresponding solutions based on the phenomena obtained.\n- Computing UNPACT requires multiple forward passes through the model, which is computationally expensive (especially for long sentences), affecting the usefulness of UNPACT as a diagnostic tool.\n- Is there an unlearning explanation for the MoE model?\n- Although the authors proposed the \"UNPACT\" framework to explain the unlearning mechanism, the entire approach is more empirical and heuristic, without providing theoretical support or mathematical proof."}, "questions": {"value": "Can you design a corresponding unlearning solution based on the conclusions you draw?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "G9U74KEkLk", "forum": "7bZuhygFB1", "replyto": "7bZuhygFB1", "signatures": ["ICLR.cc/2026/Conference/Submission3279/Reviewer_SeeX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3279/Reviewer_SeeX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761638382110, "cdate": 1761638382110, "tmdate": 1762916643918, "mdate": 1762916643918, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to reveal and understand the dilemma of unlearning for large language models. Specifically, it proposes an interpretable framework via prompt attribution and contribution tracking, and discusses three questions related to unlearning, e.g., why unlearning can work, whether knowledge is really unlearned, and why catastrophic forgetting happens, through auditing what changes before and after prompt masking."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper focuses on the LLM unlearning from the view of interpretability, which is important and of high significance to provide insights for future unlearning paradigm or other design.\n2. The visualization is great to illustrate the specific findings and observations regarding the designed mechanism.\n3. Several representative unlearning methods are considered in the experimental part to support the empirical findings and claims."}, "weaknesses": {"value": "I appreciate the authors' idea and presentation for the prompt attribution and contribution tracking in LLM unlearning, while I still have concerns and questions for the current version, which may be considered to enhance the overall quality and the rationality of the claim:\n1. Some of the presentation claims are not accurate and faithful in summarizing the current literature and questionable; please find specific questions for further discussion and revision.\n2. Although the paper presents illustrative examples (e.g., key-token analysis), it is questionable whether these examples provide generalizable or faithful insights into the unlearning mechanism. And some definitions can be further elaborated and explained.\n3. The experiments appear preliminary, as they cover a limited set of models and unlearning methods."}, "questions": {"value": "1. I'm concerned with the claim of \"interpretability analysis of the mechanism is scarce due to the difficulty of tracing knowledge in LLMs' complex architectures\", as it didn't cover a series of works on knowledge editing in LLMs, in which area there is also some methods capable of interpretability for analyzing the what changes before and after post-hoc adjustment of LLMs.\n2. The former also induces a critical question about the uniqueness of the contribution, whether it is closely related to the unlearning scenario. If not, what is the major contribution if the authors adopt some prior interpretability works to analyze the problem under LLM unlearning.\n3. There are already a series of work in unlearning and knowledge editing answers the similar question as highlighted in the paper, e.g., \"why unlearning can work\" (works like every conventional unlearning methods will analyze the working mechanism), \"Is the knowledge really unlearned\" (some previous work also explores and reveal the knowledge is not truly deleted and recoverable), \"why catastrophic forgetting happens\" (a lot of unlearning works focuses on the trade-off will also target the problem). Please consider to do a more sufficient and comprehensive literature survey to better position the current presentation, and highlight the unique contribution and different findings.\n4. Although the authors have shown a lot of great and beautiful examples of keytokens to try to answer the question of when target knowledge is forgotten, it is questionable whether the mechanism can realize the general or faithful insights for better understand the unlearning effects.\n5. In different unlearning settings or scenarios, there would be diverse and flexible definitions for achieving satisfactory unlearning. I'm curious what is the \"gap to reliable unlearning\", and how is \"reliable unlearning\" is defined in the claims related to the dilemma of unlearning illustration? As it seems to be an important concept, but need further. explanation.\n6. The experimental results didn't cover different models and more advanced unlearning methods, which seems to be preliminary and not mature to draw conclusions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "hAArKRxKuj", "forum": "7bZuhygFB1", "replyto": "7bZuhygFB1", "signatures": ["ICLR.cc/2026/Conference/Submission3279/Reviewer_4WGL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3279/Reviewer_4WGL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761847944528, "cdate": 1761847944528, "tmdate": 1762916643670, "mdate": 1762916643670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the dilemma of unlearning in LLMs: the tension between insufficient forgetting (where “forgotten” knowledge can be recovered) and catastrophic forgetting (where general capabilities collapse).\n\nThe authors propose UNPACT, an interpretable framework for analyzing unlearning from the prompt perspective. UNPACT measures each prompt token’s contribution to model outputs (via log-probability differences), identifies KEYTOKENS, and compares them before and after unlearning to interpret how attention shifts.\n\nExperiments are conducted on four training-based unlearning methods, three LLMs, and three datasets (News, Books, WMDP).\n\nKey findings include:\n\n- unlearning mainly disrupts focus on key prompt tokens;\n- forgotten knowledge can be easily recovered by emphasizing those keywords;\n- catastrophic forgetting arises from indiscriminate penalization of all tokens."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. UNPACT provides an interesting angle, applicable to both open- and closed-source LLMs.\n2. The authors systematically study four methods, multiple models, and datasets, offering a broad empirical view.\n3. The work highlights important limitations of existing unlearning methods and articulates the inherent trade-off problem."}, "weaknesses": {"value": "1. Limited methodological novelty: UNPACT is primarily an application of standard token attribution (perturb-and-measure log-prob difference). The conceptual novelty beyond existing saliency or prompt-influence methods (e.g., Captum) is minimal. How does UNPACT differ technically from prior token-level attribution or saliency approaches?\n2. Results are only on small/medium models (smaller than 14B). Claims about LLM-level unlearning generality are thus not well-supported for a pure analysis paper. More models and families should be considered to validate the analysis.\n3. “Recovery rate” and “destructive rate” are not precisely formalized or statistically analyzed.\n4. The paper lacks quantitative or conceptual comparison with existing attribution or attention-based interpretability techniques, making its unique contribution unclear.\n5. Preliminary and incomplete contribution: The paper reads more like an early-stage exploratory study of a potential key-token-based unlearning method, rather than a complete piece of research. While the observations are interesting, the work stops short of demonstrating how these insights can be effectively utilized to improve unlearning methods. As a result, the contribution feels preliminary and insufficient to meet the standard of a mature paper."}, "questions": {"value": "Please see the weakness above. And also: \n\n1. How is GPT-4o-mini’s judgment validated against human or metric-based evaluation? Why using GPT-4o-mini only? \n2. On the FOCUSONKEY recovery experiment (Tabel 2): Could emphasizing KEYTOKENS alter the task itself rather than recover forgotten knowledge? How do you ensure that recovery is not prompt leakage or external information injection?\n3. Is UNPACT intended as a new unlearning method or an interpretation tool? The current positioning oscillates between the two.\n4. Does the interaction among phrases or segments of tokens also matter? The multi-token dependencies might better reflect contextual semantics."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "t31jcMeoKH", "forum": "7bZuhygFB1", "replyto": "7bZuhygFB1", "signatures": ["ICLR.cc/2026/Conference/Submission3279/Reviewer_kMMR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3279/Reviewer_kMMR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994049996, "cdate": 1761994049996, "tmdate": 1762916643497, "mdate": 1762916643497, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}