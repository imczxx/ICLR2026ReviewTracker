{"id": "YyjjA5630A", "number": 2273, "cdate": 1757046545457, "mdate": 1759898159083, "content": {"title": "Noise reduction in BERT NER SLM models for clinical entity extraction in clinical trials", "abstract": "Precision is of utmost importance in the realm of clinical entity extraction from clinical notes and reports. Small Language Models (SLM) fine-tuned for Named Entity Recognition (NER) are an efficient choice for this purpose. We pre-trained an in-house BERT SLM over clinical data and then fine-tuned it for NER. These models performed well on recall but suffered on precision. To address this challenge, we developed a Noise Removal model that refines the output of NER. The NER model assigns token-level entity tags along with probability scores for each token. Our Noise Removal (NR) model then analyzes these probability sequences and classifies predictions as either weak or strong. One might assume that simply filtering upon lower probabilities would be sufficient to identify weak predictions. While  intuitive, this approach is not entirely reliable. Due to the limitations of the SoftMax function, transformer-based models often assign high confidence scores even to weak predictions, making them harder to distinguish. To overcome this issue we used a supervised modeling approach, where our NR models capture the effects of positional encodings in transformers and integrates them with the probability density distributions generated for each token sequence. This approach enables the model to classify predictions as weak or strong with significantly improved accuracy. With the help of these Noise Removal models we were able to reduce False Positives across various clinical NER models by 50\\% to 90\\%.", "tldr": "A light weight post processing technique applied after BERT based NER models to remove Noisy prediction to achieve high precision", "keywords": ["SLM", "NER", "Noise removal", "Density Map", "BERT", "Clinical", "Clinical Trials", "Biomedical entity"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/abf72a3b0ed1d212599f7d83a58fa2b725727878.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose to train a decision tree over various features as a form of confidence calibration over BERT models. The approach is evaluated on two medical named entity recognition datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* There is a clear need for continued work on confidence calibration.\n* The authors compare to some common calibration techniques: temperature scaling (2017) and MC-Dropout (2016)"}, "weaknesses": {"value": "Major:\n* The authors do not compare to confidence calibration algorithms newer than 2017, e.g., SoftmaxCorr (2024) in the related work, RelCal (2023) https://link.springer.com/chapter/10.1007/978-3-032-05962-8_14, etc. Given the complexity of the proposed feature set for the proposed decision tree classifier, comparisons to such recent work are essential.\n* The evaluation datasets are not well defined. No sizes are given. The main dataset is defined only as \"EMR data\", with no reference for the dataset, or if the dataset was created internally, with no information about the annotation process (e.g., agreement). The MIMIC-3 dataset has no information about inter-annotator agreement.\n* Even after looking at appendix A and appendix C, the exact feature definitions are unclear to me.  Features need to be defined formally, with a brief example to demonstrate each feature.\n* The paper spends the far too much space (roughly the first four pages) arguing in different ways that confidence calibration is important, and the presentation of the key contribution doesn't show up until Figure 1 on page 7. That content needs to be dramatically compressed, probably down to a maximum of 2 pages so that the key contribution shows up no later than page 3, and so there is room to address the other weaknesses noted here.\n\nMinor:\n* Calling BERT a small language model seems odd, given that it's millions of parameters. Consider using a different term.\n* This sentence suggests that there are only two important metrics: \"Two basic uncertainty metrics can be defined from SoftMax\" Consider either justifying the choice of only those two, or include other well-known metrics like margin sampling (best vs. second best), least confident, etc. https://burrsettles.com/pub/settles.activelearning.pdf\n* Equation (9) is incorrect; BERT uses positional embeddings, not positional sinusoidal encodings. Consider abbreviating equations 8-18, which are just repeating the standard transformer definition, with something like Z = Transformer(X)."}, "questions": {"value": "* Why K = 3 for CoNLL? Shouldn't it be larger than that since there are E>1 entity types in CoNLL, so K = 2 * E + 1 > 3?\n* Could you explain a bit more the intuition behind ProbabilityDensityMap? What is it trying to achieve and why would we expect that to be a good idea?\n* Are there triangles (mentioned in the text) in Figure 1? I don't see any.\n* Will the annotated subset of MIMIC-3 be released?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qeGZ3nu7vz", "forum": "YyjjA5630A", "replyto": "YyjjA5630A", "signatures": ["ICLR.cc/2026/Conference/Submission2273/Reviewer_acuM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2273/Reviewer_acuM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2273/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761192413810, "cdate": 1761192413810, "tmdate": 1762916169249, "mdate": 1762916169249, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to improve the precision of BERT-based small language models for clinical entity extraction task. A simple way is to directly filter out predictions of low probability. However, due to the limitation of Softmax and noise in the training process, this method cannot effectively filter out wrong predictions. This paper proposes a method to distinguish strong and weak predictions by constructing semantic and statistical features for each token position, and training a interpretable decision tree model to classify predictions. This method is lightweight and achieve consistent improvement compared with other baseline prediction filtering methods on EMR and MIMIC-III data."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method can be operated without any modifications to the original NER method or training process, which makes it practical.\n\n2. The main paper gives a detailed explanation in the related work and problem statement."}, "weaknesses": {"value": "1. Feature motivation. The paper used a case study containing two example clinical texts to illustrate the feature motivation, which is not a persuasive and reasonable way.\n\n2. Experiments. The paper does not give a comprehensive experiment to prove the model, including more comprehensive comparison methods and metrics. The experiment section could be expanded to provide more details of the datasets used, and the inference time for each method may be included to prove the efficiency of NER + NR. Also, a simple ablation study for feature construction may further improve the solidity of the experiments.\n\n3. Paper writing. The paper does not arrange the length and content of its paragraphs appropriately. For example, the results and conclusion sections are too brief, providing neither a clear description of the data used nor an adequate explanation of the comparative methods."}, "questions": {"value": "1. What do you think are the advantages and practical values of your method compared with deep learning-based and LLM-based approaches in real-world clinical NER?\n\n2. Should a discussion on the interpretability of the decision tree-based NR model be added to the main paper? Why choose exactly these features for decision tree? Though motivation of feature selection is provided in the appendix, this only provides a general idea such as the model should focus on nearby tokens, but not specific feature design.\n\n3. For the experiment section, how are the hyperparameters of baseline methods selected? Are they tuned on the same training dataset as NER + NR?\n\n4. In Table 2, For the biomarkers element, why other methods have almost no FP drop while NER + NR achieve 88% FP drop? This result seems a bit extreme."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GScGjho9xm", "forum": "YyjjA5630A", "replyto": "YyjjA5630A", "signatures": ["ICLR.cc/2026/Conference/Submission2273/Reviewer_eD5m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2273/Reviewer_eD5m"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2273/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896664267, "cdate": 1761896664267, "tmdate": 1762916169047, "mdate": 1762916169047, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents an analysis of the overconfidence problem in Medical domain adapted pretrained LM-based NER, and engineered features based on the analysis to add a noise reduction model to reduce the false positive predictions.\nContributions\n1. Analysis of overconfidence problem in medical NER\n2. a well motivated & inexpensive solution with significant improvement"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The feature design was well motivated from the probability space analysis\n2. The proposed solution works well for reducing false positives"}, "weaknesses": {"value": "presentation could be improved. I had to re-read the analysis section 4.2 and 5.1 several times to understand what the authors were trying to say.\n1. eq 21 the notation is a mess -- what does |t_anchor-t| mean? I could roughly infer from appendix but it is confusing as hell\n2. \"feature used\" section was confusing -- is 'cross-product' supposed to mean 'cartesian-product'? I had to read the appendix to clarify how it is actually used \n2. better use of space --  the authors spend almost a whole page writing out equations for transformers, and probably resulted in needing to cut out some content to fit in the page limits. I would suggest some parts can be assumed common knowledge or try to compress the space it takes up with some formatting, so you have more room to clarify e.g. your feature design? \n3. orders -- I see probability density maps & binning in section 4.2 density analysis, but did not seem to find the results for these density analysis? and section 4.3 solution overview, maybe better to move them after the feature motivations? the binning part was confusing to me until I read the appendix to see the feature design\n4. figures -- the probability space analysis figure is very small, color choices might be a little too similar so it's hard to match which is which in your text to the figure, and since the points will lie on the 2-simplex, maybe adding that triangle can help us better see where the points are in the space?"}, "questions": {"value": "1. In your embedding space analysis, you claimed there's semantic overlap for TP regions and FP regions, but this is after projecting onto 2D, are we sure there is actually overlap or could there be some separating hyperplane say if we add a dimension?\n2. I understand this might be out of scope, but in your embedding space analysis/probability space analysis, did any insights come up re improving recall?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yPgIgHZp77", "forum": "YyjjA5630A", "replyto": "YyjjA5630A", "signatures": ["ICLR.cc/2026/Conference/Submission2273/Reviewer_UJjB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2273/Reviewer_UJjB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2273/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955528487, "cdate": 1761955528487, "tmdate": 1762916168904, "mdate": 1762916168904, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper builds a simple add-on to clean up mistakes from a BERT model that extracts medical terms. Instead of retraining the model, it uses a small decision tree to spot and remove uncertain predictions by looking at token probabilities and their context. This cuts false positives while keeping recall high andimproving precision for clinical text extraction."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "the paper uses interpretable models (decision tree) and that makes it transparent and suitable for clinical settings. the paper also shows effectiveness across multiple datasets and hence the conlcusions can be taken as good generalization. additionally the results are strong (large reduction in false positives with minimal recall loss)."}, "weaknesses": {"value": "The quantitative analysis of htis study is great. my concern is that there is little insight into how the model behaves on more complex or ambiguous clinical text."}, "questions": {"value": "1. Do you plan to integrate this framework with larger or newer models (e.g., ClinicalBERT or LLaMA-based models)?\n\n2. The quantitative analysis in this study is strong, but could you provide more insight into how the model behaves on complex or ambiguous clinical text?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "jBOsWLZc9d", "forum": "YyjjA5630A", "replyto": "YyjjA5630A", "signatures": ["ICLR.cc/2026/Conference/Submission2273/Reviewer_pphB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2273/Reviewer_pphB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2273/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963414445, "cdate": 1761963414445, "tmdate": 1762916168768, "mdate": 1762916168768, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}