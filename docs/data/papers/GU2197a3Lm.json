{"id": "GU2197a3Lm", "number": 14357, "cdate": 1758233466902, "mdate": 1759897375320, "content": {"title": "Gen-DFL: Decision-Focused Generative Learning for Robust Decision Making", "abstract": "Decision-focused learning (DFL) integrates predictive models with downstream optimization, directly training machine learning models to minimize decision errors. While DFL has been shown to provide substantial advantages when compared to a counterpart that treats the predictive and prescriptive models separately, it has also been shown to struggle in high-dimensional and risk-sensitive settings, limiting its applicability in real-world settings. To address this limitation, this paper introduces Decision-Focused Generative Learning (Gen-DFL), a novel framework that leverages generative models to adaptively model uncertainty and improve decision quality. Instead of relying on fixed uncertainty sets, Gen-DFL learns a structured representation of the optimization parameters and samples from the tail regions of the learned distribution to enhance robustness against worst-case scenarios. This approach mitigates over-conservatism while capturing complex dependencies in the parameter space. The paper shows, theoretically, that Gen-DFL achieves improved worst-case performance bounds compared to traditional DFL. Empirically, it evaluates Gen-DFL on various scheduling and logistics problems, demonstrating its strong performance against existing DFL methods.", "tldr": "Our paper presents a novel decision-focused learning framework that leverages generative modeling to solve robust decision-making problems.", "keywords": ["decision focused learning", "decision making", "stochastic optimization", "generative models", "operational research"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a3a8aa8365185b5315e8823789d098cf75a3f396.pdf", "supplementary_material": "/attachment/d40a3b7b9af0486e7dc9877a0a490b1a69b9ce9d.zip"}, "replies": [{"content": {"summary": {"value": "The paper combines the advantages of Decision-focused learning (DFL) and robust optimization (RO) to propose a decision-making framework robust to model uncertainty. The authors introduce a method that uses the conditional distribution learned by generative models instead of uncertainty sets to protect the decision-making against tail regions of the distribution. This results in optimizing a Conditional Value-at-Risk objective. The paper provides theoretical results on the loss difference using an approximation of the conditional distribution and regret gap between standard DFL and their method. They validate their methods on an energy-cost aware scheduling problem and the COVID-19 resource allocation problem, along with three synthetic experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper proposes a method that addresses the faults of RO and DFL. I believe the introduction, related works, and preliminaries provide sufficient context for the paper. The method was robustly validated in experiments with a wide range of data sets and ablation studies. The method was compared against many baselines in RO and DFL. The empirical results make a strong and convincing case for using this method."}, "weaknesses": {"value": "Theorem 5.4, which is one of the two main theoretical contributions of the paper, studies the upper bound of $\\mathbb{E}_x\\left[|\\Delta R(x)|\\right]$ to characterize the factors that influence the performance gap between standard DFL and Gen-DFL. However, the authors analyze these factors to highlight the failure modes of Pred-DFL, which is reflected by $\\mathbb{E}_x\\left[\\Delta R(x)\\right]$ instead of  $\\mathbb{E}_x\\left[|\\Delta R(x)|\\right]$. While the analysis of the performance gap is interesting, it doesn’t strengthen the case made for Gen-DFL. \n\nAdditionally, it seems like the performance gap, as defined by the authors, should also have a distribution distance term between $p(c\\mid x)$ and $q(c\\mid x)$ (similar to the result in Theorem 5.1). It seems odd that the miscalibration of the generative model has no effect on the performance gap. \n\nIf a satisfactory upper bound and lower bound for $\\mathbb{E}_x\\left[\\Delta R(x)\\right]$ is provided, I would be willing to increase my score.\n\nMinor weaknesses\n* The theorem statement of Theorem 5.4 isn’t the same as Theorem A.8. \n* In lines 344-345, the authors argue that the estimation error of the predictor in Pred-DFL grows at a certain rate, but I don’t think this is immediately obvious. It would’ve been nice if there were some explanation around that statement or a reference to the original result."}, "questions": {"value": "* Why aren’t the RO baselines included in Table 1?\n* What data sets are used to produce Figure 3-7?\n* Why is the $\\beta$ hyperparameter introduced in the experiments section? Why can’t $\\gamma$ be varied in experiments instead of $\\beta$?\n* What is this “auxiliary model” in line 259? Are there two models in Gen-DFL?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "F6W6M7LpKt", "forum": "GU2197a3Lm", "replyto": "GU2197a3Lm", "signatures": ["ICLR.cc/2026/Conference/Submission14357/Reviewer_Uiro"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14357/Reviewer_Uiro"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14357/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761760577053, "cdate": 1761760577053, "tmdate": 1762924780774, "mdate": 1762924780774, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the problem of making decisions via predictive models. Specifically, this paper focuses on the end-to-end regime of decision focused learning (DFL) which has been explored in recent years. For DFL, the model often takes the form of bilevel structure with a predictive model (for the cost vector) and an inner minimization of a downstream expected objective. This paper defines gen-DFL which instead of a predictor uses a generative model that tries to predict a distribution rather than a point prediction of the cost vector. This results in improvements in high dimensional settings over baselines and the authors provide theoretical bounds on performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "It has clear empirical improvements and clear theory on generalization bounds and provides an interesting alternative method to the other formulations of DFL."}, "weaknesses": {"value": "The justification of DFL versus point-wise robust methods is not theoretically clear. First, while they provide gaps between the point-prediction methods of pred-DFL and gen-DFL, first it is unclear what the \\Delta R term really means. The differing definitions of regret for gen-DFL and pred-DFL make sense as one is with a regret realized by a singular cost value and the other is over a distribution of realizations. To then take the difference between these two terms is what seems a little strange. Later it seems that the definition of \\Delta R in appendix A.8 uses the same CvaR regret for both but doesn’t use the defined pred-DFL regret. Thus, the \\Delta R term is confusing and some clarification would help here.\n\nFurthermore, the purpose of this bound is a little unclear. If the motive is to demonstrate theoretical improvements of the gen-DFL method over pred-DFL type methods, why is it an upper-bound on the absolute residual gap? Shouldn’t it instead be a lower-bound type result on the gap without absolute difference such that the regret of pred-DFL methods is at least some quantity larger than the regret of gen-DFL? \nSo while the upper-bound is valid, it doesn’t necessarily distinguish the two methods, and perhaps a corresponding lower-bound would help.\n\nLastly, while there are many solid synthetic experiments, there are only 2 real-world data ones, for which one of them diff-DRO outperforms (admittedly by a small amount). It would be nice to include another such experiment in which the empirical performance of gen-DFL on real data is demonstrated. Additionally the results on these real world experiments seems lacking."}, "questions": {"value": "Could the computational overhead of gen-DFL be problematic under settings that require retraining under distribution shift, perhaps? Is there an equivalence in solutions between the \"right size\" of an uncertainty set for pred-DFL with robust optimization and the full tail distribution of gen-DFL?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Jz7ha2VOkb", "forum": "GU2197a3Lm", "replyto": "GU2197a3Lm", "signatures": ["ICLR.cc/2026/Conference/Submission14357/Reviewer_eGUr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14357/Reviewer_eGUr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14357/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903546277, "cdate": 1761903546277, "tmdate": 1762924780384, "mdate": 1762924780384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Gen-DFL, a “Decision-Focused Generative Learning” framework for robust decision-making under uncertainty. It extends decision-focused learning (DFL) by replacing deterministic point predictions with a conditional generative model (e.g., conditional normalizing flow) that captures the conditional distribution $p_\\theta(c|x)$ of optimization parameters. The framework combines this with a CVaR-based risk-sensitive optimization objective, forming a generate-then-optimize (GTO) paradigm. Theoretical analysis provides regret bounds suggesting that Gen-DFL performs better than traditional DFL when variance, dimensionality, or nonlinearity increases."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The topic is timely and relevant, as robust decision-making under uncertainty is a rapidly growing area at the intersection of optimization, learning, and generative modeling. The proposed framework is general and conceptually interesting—it integrates generative modeling and decision-focused optimization in a unified formulation that, in principle, could be applied across a wide range of uncertain decision-making problems. The problem setup is clearly motivated, and the generate–then–optimize structure is intuitively appealing."}, "weaknesses": {"value": "- Limited conceptual novelty: The central idea—modeling parameter uncertainty via a generative model and optimizing CVaR—is highly similar to existing work in distributionally robust DFL and end-to-end conditional robust optimization (E2E-CRO). The paper does not clearly articulate how Gen-DFL differs from or improves upon these prior methods.\n- Mathematical presentation is confusing: As noted in the comments, notation is inconsistent ($p_\\theta(c|x)$ vs. $q(c|x)$ in equation (7)); $w^\\star$ is used even though it is inaccessible; and several definitions (e.g., for CVaR-based regret) are unclear. Some derivations are incomplete or informal, lacking well-defined assumptions and proof steps; and several mathematical objects (e.g., $R(x)$ in Theorem 5.4) are never defined.\n- Lack of explanation for the surrogate loss function: A central component of the algorithm—the surrogate loss function used for training—is introduced without any explanation, justification, or derivation. Since the entire algorithm builds upon this surrogate, the omission makes the methodology difficult to follow and gives an impression of a lack of transparency, as if the authors are glossing over key technical details. This severely hurts the paper’s clarity and credibility."}, "questions": {"value": "- What is the relationship of $p_\\theta(c|x)$ and $q(c|x)$? Are they refering to the same thing?\n- Since $w^\\star$ is not observable in real-world decision-making, how is regret approximated during training and evaluation?\n- The regret definition, why is CVar positioned outside the regret difference rather than inside in equation (5)? Note that these two quantities can be different"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "f29mVsdksK", "forum": "GU2197a3Lm", "replyto": "GU2197a3Lm", "signatures": ["ICLR.cc/2026/Conference/Submission14357/Reviewer_KwJ3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14357/Reviewer_KwJ3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14357/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926453620, "cdate": 1761926453620, "tmdate": 1762924779838, "mdate": 1762924779838, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GEN-DFL, a decision-focused learning approach for contextual stochastic optimization problems that uses generative models (e.g. normalizing flows) to generate samples that are fed into sample average approximation model used to optimize a CVAR objective. In particular, in analogy to classical DFL approaches, they propose to train the generative (prediction) model using a surrogate decision-oriented loss function in order to obtain “decision-focused” samples that minimize a CVAR regret. The paper proposes a contrastive surrogate loss function for this setting, and it provides a theoretical analysis that provides an error bound for the surrogate loss function and a quantification of the improvement of the regret obtained by their model in contrast to classical (single-point-forecast-based) DFL approaches.\nIn a set of computational experiments with classical predict-then-optimize, DFL, and a robust DFL approach as baselines, it is shown that the proposed approach yields much better results in terms of a CVAR-based regret."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses a critical weakness of classical decision-focused learning approaches, namely the fact that the optimization models rely on a single point forecast, and addresses that weakness by using a SAA-based approach to compute a CVAR objective.\n\n- The paper provides a surrogate loss function that is then usable in a classical end-to-end learning pipeline, and quantifies the error introduced by the surrogate loss."}, "weaknesses": {"value": "- The paper ignores the fact that there exist many papers that deal with contextual stochastic optimization, see e.g. the survey paper Sadaba et. al (2025) (A survey of contextual optimization methods for decision-making under uncertainty, European Journal of Operational Research, https://doi.org/10.1016/j.ejor.2024.03.020), many of them using SAA-based approaches that rely on generating samples from conditional distributions that are generated by machine learning models.\n\n- Given those approaches, for me, the big (and obvious) question is: What is the benefit of training the (probabilistic) machine learning models used for generating the sample with a decision-oriented loss function instead of using classical loss functions? In other words: What is the benefit of step 2 (Model learning) in section 4.2 of the paper? This question is not answered in the computational experiments, and this is, in my opinion, the big weakness of the paper. If there is not a big benefit, why should the reader bother with the expensive DFL pipeline? Personally, I dot not think that the task-specific loss will bring a lot of advantage, but I would love to see results from experiments that show the contrary. Also, I would like to emphasize that in classical DFL, it is common to compare “predict-then-optimize” (with classically trained prediction models) to “predict-and-optimize” aka DFL. This is why I find it strange not to compare “generate-then-optimize” (for which there is a lot of literature, see section 4 of the abovementioned survey) to “generate-and-optimize” (which is obtained by using a decision-oriented loss function).\n\n- In my opinion, the experiments are also flawed in a different way as the approaches use different objective functions. This similar to a setting in which one solves a classical stochastic optimization problem with an expected value objective, and another with a CVAR-objective, and then compares their performance in terms of CVAR – it would come to no surprise that the solution of the first perfroms much worse.\n\n- The paper does not mention approaches such as the one Nathan Kallus, Xiaojie Mao (2022) Stochastic Optimization Forests. Management Science 69(4):1975-1994., which also uses a decision-focused approach to solve risk-averse objective functions involving CVAR, also using a sample-based approxiation objectives (this would also be a good benchmark approach)\n\n\nIn its present state, I find that the weaknesses sketched abive namely neglecting whole stream of relevant literature on contextual stochastic optimization and  not comparing  the decision-focused training of the generative model to a classically trained generative model using the same SAA-based CVAR loss function. If this decision-focused training is not significantly better, the main contributions of this paper are not significant enough to justify a publication at ICLR."}, "questions": {"value": "- The most important question is: In your experiments, given a fixed number of samples, how does generate-then-optimizes using a generation model trained in a classical way compare to your approach that uses a surrogate decision loss for training"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "45Mch1sSSD", "forum": "GU2197a3Lm", "replyto": "GU2197a3Lm", "signatures": ["ICLR.cc/2026/Conference/Submission14357/Reviewer_DNJQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14357/Reviewer_DNJQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14357/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991863896, "cdate": 1761991863896, "tmdate": 1762924779150, "mdate": 1762924779150, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}