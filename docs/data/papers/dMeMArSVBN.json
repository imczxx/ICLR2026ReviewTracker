{"id": "dMeMArSVBN", "number": 17397, "cdate": 1758275452592, "mdate": 1763728518013, "content": {"title": "FlowNet: A Generic Independent and Interactive Model for Streamflow Forecasting", "abstract": "Streamflow forecasting plays a crucial role in water research for flood prevention, water resource management, or climate resilience. However, it is a challenging task due to complex hydrological system interactions, human interventions and global climate change.  In this paper, we introduce FlowNet, a \\emph{unique local global interactive modeling} framework, which is capable of effectively predicting multiple hydrology stations with varied input climate features and data availability at the same time. The key idea of FlowNet is to contruct \\emph{independent} prediction models for each station from its local data and from its adjacent neighbors via a hydrological-related directed graph before letting these models to \\emph{iteratively} and \\emph{interactively} adjust each other to maximize their prediction agreements. This helps to reduce uncertainty, thus improving their accuracy. Additionally, FlowNet dynamically captures inter-station relationships via its directional and delay-aware graph reconstruction method. As a generic framework, FlowNet can be used with any existing Deep Learning (DL) backbone models such as RLinear, PatchTST or iTransformer. However, we also introduce another backbone, called Disentangled Multiscale Cross-attention Transformer (DMCT), to capture the multiscale seasonality-trend information for further performance boost. Extensive experiments on 3 large datasets, including LamaH (with 425 hydrology stations in Europe), CAMELS (672 stations in USA) and  MRB (with 26 gauge stations in the Mekong River Basin), show that FlowNet significantly outperforms 18 state-of-the-art (SOTA) prediction methods in terms of MAE, RMSE, and NSE.", "tldr": "FlowNet: A Generic Independent and Interactive Model for Streamflow Forecasting", "keywords": ["time series forecasting", "deep learning", "machine learning"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7ea836356048be22f761f0c4e0cca1a047ef8deb.pdf", "supplementary_material": "/attachment/a7a2c41558a56463e126a8d1bd34e7ab969e86df.zip"}, "replies": [{"content": {"summary": {"value": "FlowNet proposes a multi-scale framework for streamflow forecasting. The manuscript proposes to consider the spatial connection when forecasting streamflow. Rather than using a single model for all stations, first, local models are trained to each station separately. This stage is designed to handle varying available local training data. Second, using a predefined graph, the local predictions between the stations are adjusted globally and iteratively via training models. The original graph used in the global stage is refined by measuring correlations to correct the links between the stations. FlowNet is built using the proposed backbone: Disentangled Multiscale Cross-attention Transformer (DMCT), that is designed to capture the multi-scale seasonality-trend information. The manuscript evaluates the proposed framework on 3 benchmarks and compares it to other backbones."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The framework is clearly described with mathematical formulation. hyperparameters details are described.\n- Evaluation on 3 datasets is comprehensive.\n- It is promising to consider spatial connections between points for streamflow forecasting."}, "weaknesses": {"value": "- The method is highly dependent on the graph definition and it does not scale well with graph n x n (L136). In other words, the model can't work on large-scale data and it is limited to small scale dataset e.g., few hundreds of stations.\n- What actually effect the streamflow is also meteorological data in the catchment area and near the station. This is ignored by the framework. Furthermore, what is the point of connecting channel like temperature in the streamflow direction? In reality this should be bidirectional.\n- Wrong assumption about reality because streamflow cant be obtained in real time and it is used by the framework, since it relies on it heavily.\n- Per-station and cross-station models are very expensive to build (L201-202). This is counter intuitive to what we do in ML. For example, \"L210-211: we train two sets of cross-station models for each station Si, including the inflow and outflow models\", so each station will have 3 models to be trained as I understood. What we do is usually we leverage a single generalized ML model that is trained with a lot of data and let the model learn the correlations by itself rather than building different local models. You might want to look at previous works [[1](https://hess.copernicus.org/articles/28/4187/2024/hess-28-4187-2024.html)].\n- It is not clear how the baselines are trained. i.e., the description of the baselines and how they are trained and finetuned is missing.\n- State-of-the-art baselines are missing e.g., [[2](https://hess.copernicus.org/articles/23/5089/2019/hess-23-5089-2019.html), [3](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2023WR036170), [4](https://arxiv.org/abs/2505.22535), [5](https://essopenarchive.org/users/810569/articles/1227435-high-resolution-national-scale-water-modeling-is-enhanced-by-multiscale-differentiable-physics-informed-machine-learning), [6](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023WR035337)]. At least [[2](https://hess.copernicus.org/articles/23/5089/2019/hess-23-5089-2019.html)] should be included. The baselines in the manuscript should be works for streamflow forecasting following proposed methodologies in previous works rather than different ML building blocks.\n- Table 6: looking at the standard deviation and numbers, the improvement compared to some baselines with random seed is negligible. \n- Ablation study, Fig. 3: the improvement is negligible\n- Effects of different components of DMCT. The paper has some unjustified claims (L428-431). Some proposed component are redundant e.g., multi-scale (M) in Table 2. In my view, there is also no reason why the model should not work without a specific type of normalization. Most models for streamflow do not necessary use InstanceNorm."}, "questions": {"value": "- L45-49: this is not true, static features are available globally and are not hard to obtain.\n- Line140: where does the streamflow value come from? We can get them from the dataset but in reality, these values are not available in real time.\n- How does per-station forecast work? Is it in parallel? It is highly inefficient.\n- L204-205: do you finetune the parameters for each station? If yes this is high inefficient, if no this will lead to sup-optimal results. This is why we use one model usually.\n- L208: loss function like MSE is not optimal for streamflow i.e., the loss function should consider extremes to account for river flood forecasting.\n- I struggle to understand the relation between Eq. 1 and 2? $y_{inflow}$ and $y_{outflow}$ can be zero and the loss will be perfectly fine?\n- Missing literature and baselines (see weaknesses).\n\n**Minor**:\n- Line740-741: I thought the model should work with an inconsistent spatial representation.\n- L166: better to use $\\hat{y}$ as ground truth, it is more common to void confusion.\n- Eq 7 is incorrect > new variables need to be renamed.\n- L345: I see more than 8 baselines. I think you mean 18."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3xqmjp1FSs", "forum": "dMeMArSVBN", "replyto": "dMeMArSVBN", "signatures": ["ICLR.cc/2026/Conference/Submission17397/Reviewer_n4Tx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17397/Reviewer_n4Tx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761747144678, "cdate": 1761747144678, "tmdate": 1762927301658, "mdate": 1762927301658, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FlowNet, the first independent and interactive modeling framework for streamflow prediction. By employing a well-designed local-global interaction scheme and a Disentangled Multiscale Cross-attention Transformer (DMCT), the method achieves advanced performance across three large benchmark datasets, demonstrating its strong potential for real-world hydrological forecasting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The topic of flow forecasting is highly practical and relevant, as it can help mitigate uncertainty caused by climate change.\n2. The proposed framework is flexible and can be adapted to various data sources and model types.\n3. The experiments are thorough and extensive, convincingly demonstrating the effectiveness of the proposed approach."}, "weaknesses": {"value": "1. Although FlowNet is novel as a framework, the proposed DMCT appears to mainly reuse existing attention mechanisms with relatively simple adaptation and normalization.\n2. The Graph Links Reconstruction Module seems could be simplified by using weighted relationships between stations (e.g., distance-based weights) rather than binary adjacency in the downstream flow graph.\n3. The ablation study on the local-global interaction scheme shows limited improvement. For instance, most NSE gains are below 0.01, and FlowNet even underperforms the global-only setting on Phung H. and Ban D. stations. More analysis is needed to explain these results.\n4. The design of training multiple independent models for each station increases computational and memory costs, which may limit scalability.\n\nMinor Issue:\n- In line 367, the reference to “Figure 1” should be corrected to “Figure 2.”"}, "questions": {"value": "In Section 2.2, the paper defines a global loss to minimize differences between the ground truth $y^i$ and local prediction $\\hat{y}^i$, as well as between global prediction $\\hat{y}^i_{Global}$ and local prediction $\\hat{y}^i$. Why not directly minimize the difference between the global prediction $\\hat{y}^i_{Global}$ and the ground truth $y^i$? This seems more straightforward."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZYlol40VZM", "forum": "dMeMArSVBN", "replyto": "dMeMArSVBN", "signatures": ["ICLR.cc/2026/Conference/Submission17397/Reviewer_LeBJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17397/Reviewer_LeBJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761845122375, "cdate": 1761845122375, "tmdate": 1762927301261, "mdate": 1762927301261, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "FlowNet is a general framework designed for multivariate spatiotemporal runoff prediction. It introduces a local-global interactive modeling strategy, which allows individual station models to maintain their independence while mutually correcting predictions through iterative integration (Global Consensus). This approach enhances the consistency and robustness of predictions, making it particularly suitable for sets of stations with irregular input features and data lengths. Furthermore, FlowNet incorporates a directional and delay-aware graph reconstruction method to optimize the modeling of spatial relationships. Additionally, it proposes a decoupled multi-scale cross-attention Transformer (DMCT) as a backbone network for efficiently capturing temporal features."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. FlowNet natively supports the processing of irregular datasets across monitoring stations — for example, when the length of historical records or the dimensionality of input features is inconsistent. This flexibility is of considerable practical importance in hydrological applications. \n\n2. Comprehensive Baselines and Experiments: The paper employs three challenging large-scale hydrological datasets and conducts comparisons with up to 18 state-of-the-art methods of different architectures (including statistical, MLP, RNN, CNN, Transformer, and GNN approaches), demonstrating extensive empirical advantages."}, "weaknesses": {"value": "1. **Relevance and Citation of Baseline Selection:** While a substantial number of baseline models are included, some—such as Informer, Autoformer, and FEDformer—are not directly discussed in the Related Work section regarding their application or limitations in hydrological contexts. It is recommended to briefly explain the rationale for including these models in the Related Work or experimental setup, ensuring that all baselines have been referenced in hydrology or time series forecasting.\n    \n2. **Clarity of the Ablation Study:** The current ablation results are primarily presented in graphical form (e.g., Figure 3). However, due to the relatively small performance differences, visual representations may not precisely reflect the quantitative contribution of each module. To enhance rigor, it is strongly recommended to supplement with detailed ablation performance tables for the core components of FlowNet—local learning, graph reconstruction, and global interaction—across all major datasets (LamaH-CE, CAMELS, MRB). Tabular data would allow clearer and more accurate assessment of the gain from each module."}, "questions": {"value": "1. **Comparison with Large Time Series Models (TS-LLMs):** Given rapid advances in time series forecasting, large pre-trained models such as TimesFM, TimeGPT, and TabPFN have emerged as new state-of-the-art baselines. Have the authors considered including these as additional and more challenging baselines for comparison? This would further strengthen the demonstrated competitiveness of FlowNet.\n    \n2. **Computational Complexity and Efficiency:** Although FlowNet employs independent lightweight models, the global interaction phase is iterative. How does FlowNet’s actual overhead in inference time and training time compare to that of single end-to-end GNN models, such as ResGAT or AGCLSTM?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QAl1dyQlZb", "forum": "dMeMArSVBN", "replyto": "dMeMArSVBN", "signatures": ["ICLR.cc/2026/Conference/Submission17397/Reviewer_EzYW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17397/Reviewer_EzYW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762365640104, "cdate": 1762365640104, "tmdate": 1762927300749, "mdate": 1762927300749, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "**Summary**  \nThis paper proposes **FlowNet**, a flexible and generalizable framework for multivariate spatio-temporal streamflow forecasting across multiple gauge stations. It introduces an **interactive local-global modeling strategy**, where each station is modeled independently in a local phase and then iteratively refined via cross-station interactions in a global phase. A novel **DMCT (Disentangled Multiscale Cross-attention Transformer)** is also proposed as a backbone model to capture multiscale temporal patterns. The method is evaluated on three hydrological datasets and shows superior performance over 18 SOTA baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Strengths**  \n- **Extensive and convincing experiments**: The paper compares FlowNet with a wide range of strong baselines (e.g., Transformers, GNNs, LSTMs) across three datasets (LamaH, CAMELS, Mekong) and multiple horizons. Results consistently show FlowNet outperforms others in NSE, RMSE, and MAE.  \n- **Ablation studies and robustness checks**: Ablations validate the contribution of each component (local/global phases, graph reconstruction, DMCT modules), and multiple random seeds are used to ensure stability.  \n- **Handles heterogeneous data**: FlowNet accommodates varying input lengths and feature sets across stations, which is a practical advantage in real-world hydrological systems."}, "weaknesses": {"value": "**Weaknesses**  \n- **Poor readability in methodology**: The method description is overly technical and difficult to follow, with inconsistent notation and a lack of high-level intuition. Variable definitions are scattered and not unified, hindering clarity.  \n- **Limited novelty in integration**: The local/global phase learning and DMCT module feel like a straightforward combination of existing ideas (interactive learning + multiscale decomposition) rather than a deeply integrated innovation. The novelty appears incremental.  \n- **Scalability concerns**: FlowNet requires training separate per-station and cross-station models for each link in the graph. With hundreds or thousands of stations, the computational cost grows sharply, severely limiting its applicability to large-scale river networks. This is only briefly mentioned but not adequately addressed."}, "questions": {"value": "1.  **Readability:** The methodology is dense and hard to follow due to inconsistent notation. Can the authors provide a clearer, more unified presentation of variables and core concepts?\n\n2.  **Novelty & Integration:** The framework feels like a composition of a local-global scheme and a DMCT backbone. What is the key synergistic novelty beyond this combination?\n\n3.  **Scalability:** The requirement for O(N²) models seems prohibitive for large networks. What is the formal computational complexity, and what strategies are proposed for scaling to real-world, large-scale basins?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "q6aaPPvnV1", "forum": "dMeMArSVBN", "replyto": "dMeMArSVBN", "signatures": ["ICLR.cc/2026/Conference/Submission17397/Reviewer_wMmd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17397/Reviewer_wMmd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762438524721, "cdate": 1762438524721, "tmdate": 1762927300296, "mdate": 1762927300296, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "**Summary**  \nThis paper proposes **FlowNet**, a flexible and generalizable framework for multivariate spatio-temporal streamflow forecasting across multiple gauge stations. It introduces an **interactive local-global modeling strategy**, where each station is modeled independently in a local phase and then iteratively refined via cross-station interactions in a global phase. A novel **DMCT (Disentangled Multiscale Cross-attention Transformer)** is also proposed as a backbone model to capture multiscale temporal patterns. The method is evaluated on three hydrological datasets and shows superior performance over 18 SOTA baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Strengths**  \n- **Extensive and convincing experiments**: The paper compares FlowNet with a wide range of strong baselines (e.g., Transformers, GNNs, LSTMs) across three datasets (LamaH, CAMELS, Mekong) and multiple horizons. Results consistently show FlowNet outperforms others in NSE, RMSE, and MAE.  \n- **Ablation studies and robustness checks**: Ablations validate the contribution of each component (local/global phases, graph reconstruction, DMCT modules), and multiple random seeds are used to ensure stability.  \n- **Handles heterogeneous data**: FlowNet accommodates varying input lengths and feature sets across stations, which is a practical advantage in real-world hydrological systems."}, "weaknesses": {"value": "**Weaknesses**  \n- **Poor readability in methodology**: The method description is overly technical and difficult to follow, with inconsistent notation and a lack of high-level intuition. Variable definitions are scattered and not unified, hindering clarity.  \n- **Limited novelty in integration**: The local/global phase learning and DMCT module feel like a straightforward combination of existing ideas (interactive learning + multiscale decomposition) rather than a deeply integrated innovation. The novelty appears incremental.  \n- **Scalability concerns**: FlowNet requires training separate per-station and cross-station models for each link in the graph. With hundreds or thousands of stations, the computational cost grows sharply, severely limiting its applicability to large-scale river networks. This is only briefly mentioned but not adequately addressed."}, "questions": {"value": "1.  **Readability:** The methodology is dense and hard to follow due to inconsistent notation. Can the authors provide a clearer, more unified presentation of variables and core concepts?\n\n2.  **Novelty & Integration:** The framework feels like a composition of a local-global scheme and a DMCT backbone. What is the key synergistic novelty beyond this combination?\n\n3.  **Scalability:** The requirement for O(N²) models seems prohibitive for large networks. What is the formal computational complexity, and what strategies are proposed for scaling to real-world, large-scale basins?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "q6aaPPvnV1", "forum": "dMeMArSVBN", "replyto": "dMeMArSVBN", "signatures": ["ICLR.cc/2026/Conference/Submission17397/Reviewer_wMmd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17397/Reviewer_wMmd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17397/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762438524721, "cdate": 1762438524721, "tmdate": 1763094415785, "mdate": 1763094415785, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}