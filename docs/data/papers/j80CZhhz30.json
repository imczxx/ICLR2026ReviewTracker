{"id": "j80CZhhz30", "number": 4393, "cdate": 1757671480321, "mdate": 1763365282232, "content": {"title": "Towards Compact and Certified Robust DNNs Against Semantic Perturbations", "abstract": "Compactness and robustness are both critical for deploying DNN models, yet most prior work focuses on optimizing one aspect. Few efforts work on obtaining compact DNNs that maintain consistent predictions under semantic mutations, such as changes in facial expression or illumination. \nTo fill this gap, we propose $\\textbf{C}$ompression-$\\textbf{A}$ware Semantic $\\textbf{R}$obustness (CAR) training scheme. \nInspired by prior studies on model loss landscapes, we design a composite training objective that guides the pruning mask optimization toward flatter loss regions. We further explicitly incorporate certification conditions on semantically mutated data and enforce consistency between the soft mask used during training and the hard binary mask deployed at inference.\nThe pruned models obtained via CAR consistently achieve higher robustness than the baselines, with improvements of 17\\%–64\\% on CelebA-HQ and Flowers-102 across ResNet-18, GoogLeNet, and MobileNet-V2, while maintaining task accuracy comparable to the corresponding no-prune models.", "tldr": "", "keywords": ["Model Robustness", "Model Compression"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/055d349af5f37c0d73fddce2c84843fca5cf3196.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a compression-aware training scheme to obtain compact DNNs that are robust against semantic perturbations, improving certified robustness while maintaining accuracy with the corresponding no-prune models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Proposes specialized losses to explicitly enhance semantic robustness in compressed DNNs.\n\n2. Evaluation across three models and two datasets demonstrates the effectiveness of the losses.\n\n3. Ablation studies validate the contribution of each proposed loss component to the overall performance."}, "weaknesses": {"value": "1. The approach primarily integrates semantic perturbation-aware losses into an existing pruning&robustness framework (HYDRA). While this represents a valuable contribution to the semantic robustness domain, the core training scheme offers limited novelty beyond this adaptation.\n2. Comparisons are made against outdated baselines (5 years old). Recent $\\ell_p$-bounded pixel-level robustness methods could be adapted by substituting their perturbations with semantic ones.\n3. Evaluation on small-scale datasets raises concerns about scalability. How does CAR scale to CIFAR or larger datasets?\n4. The four loss components require balancing, but the paper lacks a discussion of these trade-offs."}, "questions": {"value": "1. How does CAR's prediction accuracy under semantic or $\\ell_p$ perturbations? The current evaluation of prediction accuracy appears to focus solely on unperturbed test images.\n\n2. If adapted for $\\ell_p$ robust pruning methods by replacing $X_T$ with $\\ell_p$ adversarial examples, could CAR outperform $\\ell_p$-robust pruning methods under comparable experimental settings?\n\n3. Why do most baseline methods exhibit performance degradation after introducing augmented data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Tq0KEvBoQ0", "forum": "j80CZhhz30", "replyto": "j80CZhhz30", "signatures": ["ICLR.cc/2026/Conference/Submission4393/Reviewer_9sfv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4393/Reviewer_9sfv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4393/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761728850419, "cdate": 1761728850419, "tmdate": 1762917335001, "mdate": 1762917335001, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "bMMudX1rnO", "forum": "j80CZhhz30", "replyto": "j80CZhhz30", "signatures": ["ICLR.cc/2026/Conference/Submission4393/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4393/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763365281387, "cdate": 1763365281387, "tmdate": 1763365281387, "mdate": 1763365281387, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a method, Compression-Aware Semantic Robustness, which can be used to produce sparse models that are certifiably robust to semantic perturbations. The CAR loss function involves balancing several terms, including stability, a margin ratio, and hard mask consistency. The method uses this loss to identify a non-binary mask, binarize the mask, and prune the resulting masked weights. The CAR method is used to produce pruned models (pruned to 50% and 70%) that have accuracies close to dense models and PCA (certified robustness) that exceeds the dense model. CAR also outperforms several baseline comparison methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper demonstrates relatively strong results on their tasks and models of interest. The authors provide theoretical justification for their method and experimental results, including ablation results."}, "weaknesses": {"value": "- One weakness is the lack of relevant context. There are no results on transformers or other modern architectures so the generalization of results are somewhat limited. As well, recent papers are not referenced (see [1, 2, 3, 4]).\n- It seems as if pruning is not a central part of the method. There is no discussion of efficiency, which could be a benefit if the method were shown to work on structured pruning methods. As well, there is a lack of comparison to other state of the art unstructured pruning methods. The authors could compare to the robust pruning literature (eg. see cited papers below).\n- Another weakness revolves around the type of robustness being analyzed. There is plenty of work on analyzing various types of out of distribution (non-adversarial) robustness, but the authors chose to apply adversarial robustness techniques to very custom OOD robustness tasks. I would appreciate seeing more discussion of semantic perturbations, justifications for the chosen tasks, and experiments on a larger variety of semantic perturbations. As well, I would be interested to see whether the results hold on other OOD robustness tasks. \n\n[1] https://arxiv.org/pdf/2205.12694\n[2] https://arxiv.org/pdf/2306.14306\n[3] https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/papers/Vemparala_Adversarial_Robust_Model_Compression_Using_In-Train_Pruning_CVPRW_2021_paper.pdf\n[4] https://arxiv.org/pdf/2412.14714"}, "questions": {"value": "Questions\n1. Why did the authors choose to use adversarial techniques and measures of robustness for a non-adversarial task? Certified robustness is used to provide guarantees of robustness to adversarial attacks, so I would be curious to hear more about the authors’ choice of framing for this method.\n2. How is pruning useful in this context? Unstructured pruning cannot be used for efficiency speedups and there is no discussion of ie analyzing the sparse subnetwork found by this method. \n3. Does this method offer improvement to other types of robustness tasks? Does the performance of this method hold up under other metrics, ie relative robustness ratio?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "y83h4pLjsx", "forum": "j80CZhhz30", "replyto": "j80CZhhz30", "signatures": ["ICLR.cc/2026/Conference/Submission4393/Reviewer_zXLc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4393/Reviewer_zXLc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4393/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761860363570, "cdate": 1761860363570, "tmdate": 1762917334540, "mdate": 1762917334540, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the problem of obtaining compact (compressed) and robust models to semantic perturbations. The proposed method, Compact-Aware semantic Robustness (CAR), is a regularization loss that combines several constraints: stability, soft-hard mask consistency for compression, a margin ratio constraint for robustness, and an L1 penalty. The evaluation on the CelebA-HQ and Flowers102 datasets using ResNet18, GoogleNet, and MobileNetV2 shows improvements over selected baselines. An analysis of the loss landscape is provided to show the flatness of the model obtained with CAR."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* Proposing a method for compact and robust models to semantic perturbations is important.\n\n* The paper proposes a method grounded in theory, and the loss-elicitation process is well structured."}, "weaknesses": {"value": "-   Definition scope: “Semantic (natural and adversarial) perturbations” is a broad notion and has been studied in various ways (see a few references below). The authors appear to suggest they are redefining it.\n    \n-   Weak evaluation:\n    \n    -   Datasets: Semantic perturbations come in different kinds; evaluating only on CelebA-HQ and Flowers-102 is not sufficiently comprehensive. Consider corrupted datasets (CIFAR-10-C, CIFAR-100-C, ImageNet-C).\n        \n    -   Models: GoogLeNet is too old to be informative for current evaluation. ResNet-18 and MobileNet-V2 are relatively small in parameter count; a ResNet-50, Wide-ResNet, or a transformer model would be more relevant to current research.\n        \n-   Imprecision: Imprecise definitions and equations make it difficult to understand the method and verify the proofs. \n    \n-   Some of the proofs may be incorrect, such as the first proof in Appendix A.3.\n\nReferences\n\n1] Hendrycks, Dan, and Thomas Dietterich. “Benchmarking neural network robustness to common corruptions and perturbations.” ICLR 2019. https://openreview.net/pdf?id=HJz6tiCqYm\n\n[2] Hendrycks, Dan, et al. “Natural adversarial examples.” CVPR 2021. https://arxiv.org/abs/1907.07174\n\n[3] Gowal, Sven, et al. “Achieving robustness in the wild via adversarial mixing with disentangled representations.” CVPR 2021. https://arxiv.org/abs/1912.03192\n\n[4] Ghiasi, Amin, Ali Shafahi, and Tom Goldstein. “Breaking certified defenses: Semantic adversarial examples with spoofed robustness certificates.” ICLR 2020. https://openreview.net/pdf?id=HJxdTxHYvB"}, "questions": {"value": "-   Lines 117–118, Definition (Probabilistic Robustness):\n    \n    -   The definition starts with a single sample and a single transform T, and S_T is a singleton set—this is inconsistent with the remainder of the definition and with Equation (1).\n        \n    -   The proof referenced in Appendix A.2 appears incorrect. In particular, the claim that the right-hand side of the equation is positive is not correct. Could you clarify this point?\n        \n-   Line 149, Definition (Model Pruning): Is the mask m_C​ not supposed to be the same size as the parameters?\n    \n-   Compression operator: What is the compression operator C, and from which distribution is it sampled in Lines 160–161? It was introduced as an index for compression in the definition of model pruning (Line 149) but is referred to later as a “compression instance” (Line 159) without clear specification.\n    \n-   Baselines for semantic perturbations: If you are evaluating semantic perturbations, why is classical adversarial training (Madry et al.) used as a baseline? Are there no methods that directly target robustness to semantic perturbations (e.g., data augmentation)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dDNOJ6R94e", "forum": "j80CZhhz30", "replyto": "j80CZhhz30", "signatures": ["ICLR.cc/2026/Conference/Submission4393/Reviewer_p97b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4393/Reviewer_p97b"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4393/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960210448, "cdate": 1761960210448, "tmdate": 1762917334155, "mdate": 1762917334155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a post-training compression algorithm, CAR, that performs unstructured pruning and is claimed to be robust to semantic mutations of the input. CAR is shown to provide improvements in semantic robustness on some models compared to baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Strong empirical validation of claims**:\nThe paper clearly states its claims and research questions, which are answered empirically, demonstrating the advantages of the proposed method."}, "weaknesses": {"value": "**Weak Motivation**: \nAlthough the problem the paper aims to address, compression that is robust to semantic perturbations, is interesting, there appears to be a lack of recent literature addressing this issue in the models explored in this work. One of the key references, HYDRA (2020), is relatively old, and several new algorithms for model compression have been proposed since then.\n\n**Unclear technical content**:\nThere are several statements that are difficult to follow, and some key terms are not well defined in the paper. Please define all terms when they are first introduced and provide rigorous mathematical statements when required, and provide intuition and interpretation for them afterward.\n\n**Narrow experimental scope**:\nThe experimental validation is performed only on small vision classification models (e.g., ResNet-18) trained on small datasets (<10,000 images). It is unclear whether the observed improvements over baselines would transfer to larger datasets and models.\n\n**Lack of reproducibility**:\nThe authors do not provide code or detailed algorithmic implementation details, making it difficult to reproduce the reported results. Please include code or pseudocode for the pruning procedure and specify hyperparameters to aid reproducibility."}, "questions": {"value": "1. Could the authors clarify lines 118-119 and describe what $\\mathcal{S}_{T}$ is referring to? It is unclear whether this is a singleton set or a distribution.\n\n2. Could the authors clarify lines 130-133? It is unclear how the measurements between the outputs of a model on an input and its transformed input can imply a statement about the true class label. The proof in Appendix A.2 assumes that the prediction on the true input matches the true label, which should be stated explicitly as an assumption.\n\n3. Could the other provide a formal definition for Semantic Mutation? Lines 139-143 do not present a mathematically rigorous definition.\n\n4. Could the authors clarify what ‘’$C \\sim \\mathcal{Q}_{\\phi}$’’ is, as stated in line 160? Is C sampled from a distribution parameterized by $\\phi$? If so, what is this distribution, and how is it parameterized?\n\n5. Could the authors clarify Line 189: ‘’It is isomorphic to Z expression’’? The meaning is unclear, yet it seems to be an important observation used in the algorithm.\n\n6. It is unclear what $C^*$ is referred to. Could the authors define this mask?\n\n7. In lines 243-244, is it not the case that 10% of parameters are set to values greater than or equal to one, given that no clamping is performed?\n\n8. In line 3 of Algorithm 1, it is unclear, based on the three defined loss functions, how the true label $y$ is used. The training loss appears to be independent of the true label.\n\n9. This work focuses on performing unstructured pruning, which, without specialized hardware and software, does not provide any efficiency gains. This raises questions about the practical usefulness of the proposed approach for efficient inference. Can the method be extended to structured pruning?\n\n**Looking forward to the discussion period to clarify these questions and strengthen this work.**"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3TlMLZHOfI", "forum": "j80CZhhz30", "replyto": "j80CZhhz30", "signatures": ["ICLR.cc/2026/Conference/Submission4393/Reviewer_tLxx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4393/Reviewer_tLxx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4393/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992729633, "cdate": 1761992729633, "tmdate": 1762917333876, "mdate": 1762917333876, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}