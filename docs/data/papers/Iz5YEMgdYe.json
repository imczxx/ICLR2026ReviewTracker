{"id": "Iz5YEMgdYe", "number": 20891, "cdate": 1758311485198, "mdate": 1759896953419, "content": {"title": "AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning", "abstract": "Analog and mixed-signal (AMS) integrated circuits (ICs) lie at the core of modern computing and communications systems. However, despite the continued rise in design complexity, advances in AMS automation remain limited. This reflects the central challenge in developing a generalized optimization method applicable across diverse circuit design spaces, many of which are distinct, constrained, and non-differentiable. To address this, our work casts circuit design as a graph generation problem and introduces a novel method of $\\underline{\\textbf{A}}$MS $\\underline{\\textbf{S}}$yn$\\underline{\\textbf{T}}$hesis driven by deep $\\underline{\\textbf{R}}$einforcement $\\underline{\\textbf{L}}$earning ($\\textbf{AstRL}$). Based on a policy-gradient approach, AstRL generates circuits directly optimized for user-specified targets within a simulator-embedded environment that provides ground-truth feedback during training. Through behavioral-cloning and discriminator-based similarity rewards, our method demonstrates, for the first time, an expert-aligned paradigm for generalized circuit generation validated in simulation. Importantly, the proposed approach operates at the level of individual transistors, enabling highly expressive, fine-grained topology generation. Strong inductive biases encoded in the action space and environment further drive structurally consistent and valid generation.  Experimental results for three realistic design tasks illustrate substantial improvements in conventional design metrics over state-of-the-art baselines, with 100\\% of generated designs being structurally correct and over 90\\% demonstrating required functionality.", "tldr": "A simulator-driven deep RL framework for expert-aligned generalized circuit generation.", "keywords": ["Applications of Generative Models", "Circuit Synthesis", "Electronic Design Automation", "Reinforcement Learning"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/20ad2dfc5e16b592961083eba4515e382be52ebc.pdf", "supplementary_material": "/attachment/4bebbba3e1413689c7d12459b202d7c8582dbe70.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes AstRL, a deep reinforcement learning approach for automated analog and mixed-signal (AMS) circuit design. The method formulates circuit synthesis as a sequential graph generation problem using PPO with behavioral cloning. Key features include: (1) symmetry-aware action space with structural constraints, (2) simulator-embedded training environment providing ground-truth feedback, and (3) discriminator-based similarity rewards for expert alignment. The approach is evaluated on three circuit design tasks (ring oscillator, comparator, OTA) and achieves 100% netlist validity and >90% simulation validity, outperforming LLM-based baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Well-structured paper with clear motivation\n2.  Action masking and symmetry-aware modifiers ensure 100% valid circuits by construction\n3. Combines multiple techniques (graph generation, PPO, BC, discriminator rewards) effectively"}, "weaknesses": {"value": "1. Core techniques (graph-based circuit generation, PPO+BC, discriminator rewards) are not new. Main contribution is engineering integration rather than algorithmic innovation.\n2. No training time, wall-clock time, or simulation budget reported\n3. No justification or ablation on GINE architecture"}, "questions": {"value": "1. How is the efficiency of the algorithm with the SPICE simulator in the loop?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WkrBI6UrRq", "forum": "Iz5YEMgdYe", "replyto": "Iz5YEMgdYe", "signatures": ["ICLR.cc/2026/Conference/Submission20891/Reviewer_XRPA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20891/Reviewer_XRPA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20891/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760650389685, "cdate": 1760650389685, "tmdate": 1762999999686, "mdate": 1762999999686, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AstRL, a deep reinforcement learning (RL)-driven synthesis method for analog and mixed-signal (AMS) integrated circuits (ICs), which corelies in formulating AMS circuit design as a graph generation problem. Built on a policy-gradient framework (Proximal Policy Optimization, PPO), the method leverages Graph Neural Networks (Graph Isomorphism Network with Edge Features, GINE) to enable fine-grained transistor-level topology generation of circuits. It integrates behavioral cloning (for initial expert alignment) and discriminator-based similarity rewards (for trajectory stability maintenance), while incorporating ground-truth feedback from a simulator-embedded environment to optimize circuit performance. Experiments were conducted on three representative design tasks—ring oscillator (RO), comparator, and operational transconductance amplifier (OTA)—using the Skywater 130nm process. Results demonstrate that 100% of generated circuits are structurally valid, and over 90% meet functional requirements, outperforming state-of-the-art baselines such as AnalogCoder (LLM-based) and AnalogGenie (RLHF-based) in terms of simulation validity and specification fulfillment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tNotable Originality: \nBy formulating AMS circuits as a graph generation problem and enabling transistor-level fine-grained generation via RL, the work overcomes limitations of existing LLM-based methods (which lose structural information) and RLHF-based methods (which lack real simulator feedback), establishing a dual-drive mechanism of \"expert alignment + exploratory optimization\".\n2.\tSolid Methodological Quality: \nEach module—from graph representation (GINE network) and action space (symmetric modifiers + masking) to reward design (three-stage categorized rewards)—is supported by theoretical foundations and validated through ablation studies, without \"black-box\" design. Experiments use real-world processes and standard tasks, ensuring high result reproducibility.\n3.\tStrong Domain Significance: \nIt addresses \"structural validity\" and \"functional compliance\" issues of industrial concern. The released code and datasets can drive subsequent research in the field (e.g., multi-module integration of complex AMS circuits and adaptation to larger-scale processes).\n4.\tHigh Expressive Clarity: \nFramework diagrams, formulas, and experimental tables (multi-task comparison in Table 1) complement each other. The comprehensive overview of related work not only demonstrates an understanding of the field’s history but also clarifies the paper’s positioning, reducing the comprehension burden for reviewers and readers."}, "weaknesses": {"value": "1.\tLimited Task Generalization: \nExperiments only cover three basic AMS circuits (RO, comparator, OTA) and do not validate more complex industrial-grade circuits (e.g., high-speed SERDES, phase-locked loops (PLLs)). This makes it impossible to determine the method’s adaptability to scenarios with \"multi-module coupling and high nonlinearity\", restricting the generalization of conclusions.\n2.\tLack of Mass Production Metrics: \nExisting results focus on \"functional correctness\" (e.g., frequency, delay, gain) but do not evaluate industrial-critical mass production metrics such as area, power consumption, and yield. The absence of actual tape-out test results for generated circuits makes it difficult to assess the method’s practicality in mass production.\n3.\tInsufficient Analysis of Expert Data Impact:\nBehavioral cloning relies on a dataset of 1,172 expert circuits, but the impact of \"expert data scale/diversity\" on model performance is not analyzed (e.g., whether the initialization effect of behavioral cloning degrades significantly when data volume is reduced by 50%). This hinders the method’s application in small-data scenarios.\n4.\tUnmentioned Computational Efficiency: \nNo indicators of computational efficiency—such as model training time and average time for generating a single circuit—are reported. AMS design requires rapid iteration; if generating one circuit takes several hours, the method may fail to meet industrial rapid-iteration needs, necessitating supplementary efficiency analysis.\n5.\tInsufficient related work: \nMore research for circuit synthesis such as [1] [2] should be discussed and compared in related work or experiments.\n\n[1]. Bai Y, Wang J, Chen L, et al. A Graph Enhanced Symbolic Discovery Framework For Efficient Logic Optimization. The Thirteenth International Conference on Learning Representations.\n\n[2]. Wang Z, Wang J, Yang Q, et al. Towards next-generation logic synthesis: A scalable neural circuit generation framework. Advances in Neural Information Processing Systems, 2024, 37: 99202-99231."}, "questions": {"value": "1.\tHas your team attempted to apply AstRL to more complex industrial-grade AMS circuits (e.g., PLLs, SERDES)? If not, could you analyze potential challenges (such as increased trajectory depth and sparse reward signals) that the method may face in scenarios with \"multi-module coupling and high nonlinearity\"?\n2.\tThe paper does not evaluate mass production metrics (area, power consumption, yield) of generated circuits. Do you plan to supplement tape-out tests or related simulations in the future? These metrics are critical for industrial deployment—could you explain the potential of the existing method in optimizing mass production metrics?\n3.\tFor the dataset of 1,172 expert circuits used in behavioral cloning, how do the scale and diversity of the data impact model performance? If the volume of expert data is reduced (e.g., to only 100 circuits), will the initialization effect and final performance of the model degrade significantly?\n4.\tWhen comparing with AnalogGenie, your team supplemented \"netlist conversion + Bayesian optimization\" for simulator validation. Were the parameter settings of these two steps (e.g., number of iterations and hyperparameters for Bayesian optimization) consistent with the original AnalogGenie method? If there are differences, could they affect the fairness of the comparison results?\n5.\tWhat is the computational efficiency of the model? For example, how long does it take to train the model for the three tasks on a single GPU? What is the average time required to generate an OTA circuit that meets specifications? Could you compare its efficiency with existing methods (e.g., AnalogCoder)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ej3Hfb7LEF", "forum": "Iz5YEMgdYe", "replyto": "Iz5YEMgdYe", "signatures": ["ICLR.cc/2026/Conference/Submission20891/Reviewer_VVmR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20891/Reviewer_VVmR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20891/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761532641841, "cdate": 1761532641841, "tmdate": 1763000006016, "mdate": 1763000006016, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an RL-based method to generate optimized analog circuits that meet given targets. Three downstream tasks are evaluated to show the performance of the proposed RL method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Leveraging RL to search optimal-sized circuit topologies is exciting.\n\nThe circuit-level graph modeling by considering rich domain knowledge is well presented.\n\nThe RL framework is also introduced well, with detailed reward design, which is the key to this framework."}, "weaknesses": {"value": "The scalability of the method is limited, especially when the number of devices in analog circuits increases.\n\nThe training of the method is very time-consuming. There are two searching loops in the framework. First, the RL will search topologies, and meanwhile, the reward generation needs to search for optimal device parameters. The latter could be even time-consuming. This makes the framework unlikely to be practical.\n\nEvaluations and comparisons are pretty unfair. The three circuits for evaluations are quite small compared to the circuits in Analogcoder and AnalogGenie. If you focus solely on these three circuits and conclude that your RL method achieves the state-of-the-art (SOTA), it is not convincing."}, "questions": {"value": "How is each circuit designed? Is a separate agent required to be trained to achieve this purpose?\n\nWhat do the different normal distribution curves represent in Figure 4d, e, f?\n\nWhat is the training cost? \n\nWhat is the initial starting point of each episode in your RL agent, and how do you determine the end of each episode?\n\nIf you just use this RL to achieve the given design target, why not pick up an existing topology?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A."}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "aF5CHNzmnF", "forum": "Iz5YEMgdYe", "replyto": "Iz5YEMgdYe", "signatures": ["ICLR.cc/2026/Conference/Submission20891/Reviewer_MJxH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20891/Reviewer_MJxH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20891/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761798387146, "cdate": 1761798387146, "tmdate": 1762937750367, "mdate": 1762937750367, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}