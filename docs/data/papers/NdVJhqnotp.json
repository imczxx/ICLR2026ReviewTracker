{"id": "NdVJhqnotp", "number": 22992, "cdate": 1758337889106, "mdate": 1759896837123, "content": {"title": "Bonsai Networks: Structured Pruning and Sparse Training of Foundation Models", "abstract": "The recent trend of scaling neural networks to unprecedented sizes demands efficient structured sparsity for practical deployment, yet precise control of sparsity levels and patterns for hardware acceleration remains challenging. This paper introduces the Adaptive Soft-Thresholding Algorithm (ASTRA), which achieves a target sparsity by adapting group-wise regularization strength based on computationally inexpensive sparsity characterizations. We establish ASTRA’s theoretical foundations, proving the existence of stable regularizations that realize the desired sparsity. We demonstrate sublinear and linear convergence rates for both the model parameters and the regularization weight in deterministic settings and, crucially, an almost sure $O(1/t)$ convergence rate in the practical stochastic-gradient setting. ASTRA provides a theoretically grounded method for direct, precise control over structured sparsity, enabling the pruning and fine-tuning of foundation models into Bonsai Networks: accelerator-friendly miniatures trained to match the teacher’s outputs while preserving downstream performance.", "tldr": "An adaptive regularization that finds a minimizer that has specific sparsity structure, allowing pruning of foundation models.", "keywords": ["optimization", "soft-thresholding", "sparse training", "structured sparsity"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1f31b4996c83aa4204d29e5d4f22e73804a88ae2.pdf", "supplementary_material": "/attachment/82d36079d5f8e2676a62eaaf224d8c62b5b6d102.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces ASTRA, an adaptive soft-thresholding method that tunes a group regularization weight online so a model converges to a desired structured sparsity level. The authors prove the existence of stable regularizations that achieve a target sparsity and establish convergence rates in both deterministic and stochastic settings. ASTRA extends naturally to grouped patterns for accelerator-friendly pruning via a structured sparsity algebra, and the stochastic variant SASTRA enables sparse training without dense gradient computations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+The target sparsity is cast as a scalar root-finding problem over the regularization weight, with proofs for stable regularizations and O(1/t) tracking in the stochastic setting. \n+The paper analyzes how the weight update tracks the moving optimum while the regularization follows a Robbins–Monro schedule with provable boundedness and rates.\n+The framework is a local proximal-control of several modern heuristics, opening possibilities for extensions to structured sparsity."}, "weaknesses": {"value": "-The empirical evaluation is incomplete and narrowly scoped. The LLM case study measures only one head and a single kernel, without comprehensive end-to-end metrics such as latency, throughput, and energy across kernels and hardware.\n-The classification experiments rely on ResNet-32 with CIFAR-10/100, which do not reflect large-scale behavior (e.g. ResNet-50 ImageNet).\n-The paper’s scope is narrow: results are shown only on Qwen. Please correct the typos in Qwen citations, expand evaluation to other model families and sizes (Llama, Mixtral, additional Qwen variants), and report both quality metrics on public benchmarks and system metrics (end-to-end latency, throughput, memory) across multiple sparsity targets.\n-The paper lacks comparisons with state-of-the-art methods in both LLM pruning and dynamic sparse training. In the LLM setting, it should include matched evaluations against strong pruning baselines such as Wanda, SparseGPT, and OWL-style structured pruning, using the same calibration budget and target sparsity."}, "questions": {"value": "-Can you provide end-to-end measurements on GPUs for several sparsity targets, including latency, throughput, and energy, beyond the single kernel study.\n-How robust is SASTRA to bias in the order-statistic surrogate and EMA hyperparameters, and can you report ablations showing stability and quality as these vary. \n-Can you expand the structured experiments to other block layouts and to additional model families, for example Mixtral and Llama variants, to validate generality.\n-What memory overhead is introduced by the per group or per block statistics used by ASTRA during training, and how does it scale to very large models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "G8VCG2ZSeT", "forum": "NdVJhqnotp", "replyto": "NdVJhqnotp", "signatures": ["ICLR.cc/2026/Conference/Submission22992/Reviewer_FvEY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22992/Reviewer_FvEY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22992/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761576033469, "cdate": 1761576033469, "tmdate": 1762942467692, "mdate": 1762942467692, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ASTRA, which adaptively tunes regularization during proximal gradient updates so the learned model hits a given level of sparsity. A structured version is also proposed. The paper includes extensive theory supporting the ASTRA method and experimental results comparing against multiple existing sparsification methods."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is clear and well-written.\n2. Formulating hitting a target sparsity as root-finding seems new and potentially interesting. The approach seems to unify several existing pruning methods.\n3. A structured method is also included in a natural way.\n4. The results on CIFAR seem competitive and there are multiple baselines."}, "weaknesses": {"value": "I will focus on the experimental and systems aspect here, as I have less background in the relevant theory. If other reviewers find significant merit in the theory that may outweigh my other concerns.\n\n1. The paper's focus (indeed, from the title!) is on foundation models; yet the experimental results do not bear this out. The experimental results focus on ResNet-32 and a toy test with a single LLM head form Qwen. The paper needs a much more extensive study with larger LLMs in order to demonstrate it works at scale.\n2. The experimental results in Table 1 lack error bars or other measures of statistical significance. Further, it is a mixture of results from the literature and new runs, making it hard to know whether training details differed.\n3. There are no end-to-end performance results showing throughput or latency. It is thus hard to tell whether the method can achieve significant speedups in practice for inference (although the toy test on Qwen is promising). A comparison against state-of-the-art structured pruning methods for LLMs would also be needed (e.g., vendor 2:4 sparsity and something like MaskLLM); I am not certain that the 4:16 kernel can match other structured sparsity approaches.\n4. Similarly, an evaluation of the overheads during training is missing."}, "questions": {"value": "1. Can you provide full, end-to-end results on Qwen or a similar model (e.g., Llama)?\n2. Are the results in Table 1 statistically significant?\n3. Can you provide end-to-end inference runtime results? Can you characterize the training time overheads?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pkpeb2MEkk", "forum": "NdVJhqnotp", "replyto": "NdVJhqnotp", "signatures": ["ICLR.cc/2026/Conference/Submission22992/Reviewer_JUwP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22992/Reviewer_JUwP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22992/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762156003421, "cdate": 1762156003421, "tmdate": 1762942467342, "mdate": 1762942467342, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work studies pruning and sparse training from an optimization perspective. Specifically, the central problem is minimizing the task loss under a sparsity constraint induced by L1 regularization. Because this regularizer is convex, under (strong) convexity of the loss the problem can be solved by proximal SGD methods for any regularization weight $\\lambda$. The central question of the paper is how to set $\\lambda$ to enforce a desired sparsity level ($\\lambda=0$ yields no sparsity, while $\\lambda = ||\\nabla f(0)||_{\\infty}$ gives the trivial zero solution). The paper formalizes finding the optimal regularization $\\lambda$ as a scalar root-finding problem and provides (adaptive) algorithms for approximating it and solving the L1 regularized objective. Extensions to group-wise sparsity and connections to prior methods are discussed, and some experimental results are provided."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The problem of sparse training is important and highly practical. The paper offers a principled approach for solving its surrogate L1 regularized formulation given sparsity budget.\n- The project aims to devise practically efficient algorithms, and throughout the paper exact conditions are approximated to make the methods implementable.\n- The writing is engaging and generally guides the reader through the main results, explaining and motivating the key transitions and approximations."}, "weaknesses": {"value": "Overall, technical writing is poor and correctness of claims is questionable.\n1. The equivalence stated in equation (2) regarding the optimality condition of (1) is not correct as written. The condition $||\\nabla f(w)||_{\\infty} \\le \\lambda$ is necessary but not sufficient (it represents an entire region while there is only one minimizer). This equivalence is used in the proof of Lemma 2, so the proof of Lemma 2 is not accurate as presented. However, the claim of Lemma 1 appears to be true and can be shown using the arguments used to prove Lemma 2, but the current exposition is misleading and requires correction.\n2. The equivalence in (6) is mentioned without proof. To me it appears to be of similar difficulty to the claim of Theorem 1, so it should be proven or at least justified more carefully in the main text.\n3. Several definitions are introduced inside theorem statements (e.g., the definition of “$\\phi$-stable regularization” appears in Theorem 1, the set $\\Lambda(\\psi_{\\kappa, \\alpha})$ is defined inside Theorem 2). This placement disrupts flow and makes reading awkward. Move definitions to a dedicated notation/definitions section or introduce them just before the theorems that use them.\n4. At the end of Section 3.1 the paper mentions improving the bisection idea and avoiding fully computing regularized solutions. However, the bisection method appears faster in theory. The adaptive method proposed later has sublinear convergence (even in the deterministic case), whereas a bisection scheme would require $\\mathcal{O}(\\log(1/\\epsilon))$ proximal-GD solves, each with linear convergence. What theoretical advantage does ASTRA offer over bisection? Appendix C.2 discusses a deterministic linear rate, but that result only yields linear convergence up to a neighborhood, which is not linear convergence in the usual sense.\n5. I could not find a proof of the claim $\\delta = O(\\beta_t)$ in Corollary 1. The provided proof shows $w_t$ is bounded (the first claim), but the second claim $\\delta = O(\\beta_t)$ does not seem to follow in general. For example, if $\\beta_t = 0$, then $\\delta_t$ need not be zero by the recursion in Lemma 4.\n6. The proof of Theorem 3 is also problematic. Line 1000 requires that all iterates $\\lambda_t$ remain in a neighborhood of $\\lambda_*$ as per Assumption 2, so the convergence result appears to be local only. If a good initial guess of $\\lambda_*$ is not available, it is unclear how this assumption can be satisfied. Make the locality explicit in the theorem statement and discuss how restrictive this assumption is in practice. The proof omitted the projection step $\\Pi_{[0,\\lambda_{\\max}]}$ even though equation (10) of the algorithm includes it. Furthermore, lines 1017–1020 seem to imply $V_t = O(1/t)$ based on another paper, but it is done without properly linking the assumptions or reproducing the relevant connection. Then $V_t = O(1/t)$ is used in line 1025 to derive a bound, which is subsequently (in lines 1026–1029) apparently used to re-establish $V_t = O(1/t)$. This looks circular and the argument across lines 1017–1029 does not make sence and potentially incorrect."}, "questions": {"value": "Please see \"weaknesses\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rqlpuXEflW", "forum": "NdVJhqnotp", "replyto": "NdVJhqnotp", "signatures": ["ICLR.cc/2026/Conference/Submission22992/Reviewer_9CbQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22992/Reviewer_9CbQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22992/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762161443027, "cdate": 1762161443027, "tmdate": 1762942467034, "mdate": 1762942467034, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}