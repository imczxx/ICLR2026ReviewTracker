{"id": "Els0yUtxNK", "number": 20788, "cdate": 1758310174192, "mdate": 1763362357977, "content": {"title": "DAL: A Practical Prior-Free Black-Box Framework for Non-Stationary Bandits", "abstract": "We introduce a practical, black-box framework termed Detection Augmented Learning (DAL) for the problem of non-stationary bandits without prior knowledge of the underlying non-stationarity. DAL accepts any stationary bandit algorithm as input and augments it with a change detector, enabling applicability to all common bandit variants. Extensive experimentation demonstrates that DAL consistently surpasses current state-of-the-art methods across diverse non-stationary scenarios, including synthetic benchmarks and real-world datasets, underscoring its versatility and scalability. We provide theoretical insights into DAL's strong empirical performance, complemented by thorough experimental validation.", "tldr": "", "keywords": ["non-stationary bandits", "black-box algorithms", "non-stationary reinforcement learning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c1e4f7d58ed18f882880ff4edabafbecf1b3d15d.pdf", "supplementary_material": "/attachment/4eaa9a0825e4891e8c5c8ce31a63a61247103d11.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Detection Augmented Learning (DAL), a parameter-free, black-box framework for non-stationary bandits. DAL takes a stationary bandit algorithm and a change-point detection subroutine as inputs, and, through a forced-exploration mechanism, it adapts to non-stationary environments without requiring prior information. Extensive experiments on multiple benchmarks are conducted to validate the effectiveness of the proposed framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This paper proposes a general framework for non-stationary bandits and establishes order-optimal regret guarantees in the piecewise-stationary setting. For the drifting case, the paper provides partial insights.\n- The experimental evaluation is _thorough and diverse_, covering multiple bandit setups and including realistic datasets, which enhances the practical significance of the work."}, "weaknesses": {"value": "- From a theoretical perspective, the main idea of augmenting a stationary bandit algorithm with a change-point detection module has been explored in prior work, limiting the conceptual novelty.\n    \n- Although the framework is claimed to extend naturally to contextual bandits, this case is not rigorously analyzed.\n    \n- The analysis for the drifting case remain limited, which constrains the overall contribution of the framework.\n\n- Some assumptions, such as those in Proposition 4.2, require clearer justification or guidance on how they can be verified in practice."}, "questions": {"value": "- How sensitive is DAL to the choice of covering set $A_e$ in large continuous action spaces?\n- DAL depends critically on a GLR-type change detector, but the implementation specifics are not fully described, e.g., what is the exact testing statistics and threshold used for triggering restarts? How are the false alarms controlled?\n\n\nI find the paper’s practical relevance to be stronger than its theoretical depth, and I would appreciate it if the authors could clarify the points raised above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "M7A4qofeZN", "forum": "Els0yUtxNK", "replyto": "Els0yUtxNK", "signatures": ["ICLR.cc/2026/Conference/Submission20788/Reviewer_TeBX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20788/Reviewer_TeBX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761490705711, "cdate": 1761490705711, "tmdate": 1762934972889, "mdate": 1762934972889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "For non-stationary bandits, most existing methods — such as restart, weighted/discounted, and sliding-window methods — can get good empirical performance and near-optimal regret guarantees. However, they rely on strong prior knowledge about the non-stationarity of environment. In contrast, MASTER achieves optimal regret without requiring such prior knowledge, but it is very complex: it runs many learners in parallel, which makes it hard to use in practice and often weak in experiments.\n\nThis paper focuses on the piecewise-stationary setting and proposes a black-box method that achieves (near-)optimal regret and strong empirical performance. The method keeps a small covering set of arms, occasionally pulls arms from this set to detect changes, and restarts the base learner when a change is detected. This removes the need to know the degree of non-stationarity and avoids maintaining many parallel learners."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The method provides an algorithm with theoretical guarantees that does not rely on prior knowledge of the environment, and it also shows strong empirical performance.\n2. The method is general: it acts as a black-box change detector that can be wrapped around different types of bandit algorithms, and it works across multiple bandit settings."}, "weaknesses": {"value": "1. The method does not provide theoretical guarantee for the drifting case. This is expected, because the change-detection mechanism is designed for abrupt changes, not for drifting changes. The paper only shows empirical performance on drifting, but bandits are primarily a theoretical setting, so having a matching optimal regret guarantee there is important and is currently missing.\n\n2. Compared to MASTER, this paper’s analysis in the piecewise-stationary setting relies on an extra assumption:  changes in the environment must be separated by a sufficiently long stable period. This assumption appears inside Theorem 4.4, but it is not stated clearly as its own assumption. I suggest the authors make this assumption explicit and discuss it up front. Otherwise, the comparison to prior work (MASTER) is not fair, and the assumption feels too hidden."}, "questions": {"value": "1. The paper repeatedly uses the broad term “non-stationary bandits,” but after reading the paper, the theory really only covers the piecewise-stationary case. For drifting, there is no matching theoretical analysis, but only experiments. By this standard, any prior piecewise-stationary bandit method could also run on a drifting simulation and then claim to solve “non-stationary bandits,” which would be an overclaim. Since the proposed method is not specifically designed for drifting, I believe the paper (including the title) should make it explicit that the setting is piecewise-stationary, not general non-stationary.\n\n2. Prior work on piecewise-stationary bandits already has prior-free detection-and-restart methods. It is not yet clear to me what the real difficulty is in turning those approaches into a black-box wrapper, and how this paper goes beyond that in a substantive way.\n\nI would be happy to raise my score if the authors can make the requested revisions and clarify these points."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "K4dQOpmOjC", "forum": "Els0yUtxNK", "replyto": "Els0yUtxNK", "signatures": ["ICLR.cc/2026/Conference/Submission20788/Reviewer_V4aw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20788/Reviewer_V4aw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761567202198, "cdate": 1761567202198, "tmdate": 1762934924294, "mdate": 1762934924294, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on a classical problem, that of learning in non-stationary bandits. The idea, essentially, is to augment a standard bandit algorithm with a \"change detector\". Classical bandit algorithms have their theory (and presumed applications) made under the stationarity assumption, which is not necessarily true in practice. Such changes can take the form of both abrupt and gradual changes. The authors propose a framework based on (1) detecting change of distribution by considering shifts in mean action rewards (2) forced exploration according to a schedule, forcing the bandit algorithm to essentially \"drift\" in state space. The mean-action shift is done by choosing an \"appreciable\" mean shift, exploiting some structure of the problem in deciding on which one. Some theoretical results on regret are provided."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths: this is a nice problem, and one that has been considered by many authors over the years. The approach, while fairly simple, is effective. The experiments seem to be justifiable and demonstrate the performance of the method."}, "weaknesses": {"value": "Weaknesses: the paper is not so easy to digest and understand at times. The tuning of the methods seems challenging, and the authors do not convince the reader otherwise. No details on the construction of the covering set are provided, as an instance.\n\nQuestions: what if the process contains a mix of abrupt and gradual changes? Can this method be augmented with memory, allowing to go back to previous regimes, instead of effectively starting from scratch every time?"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iB7Nbh05AB", "forum": "Els0yUtxNK", "replyto": "Els0yUtxNK", "signatures": ["ICLR.cc/2026/Conference/Submission20788/Reviewer_fy93"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20788/Reviewer_fy93"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20788/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762239744040, "cdate": 1762239744040, "tmdate": 1762934890058, "mdate": 1762934890058, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work focus on the regret minimization problem in non-stationary bandits. It proposed the DAL technique to detect unknown changes in the environment. Both numerical experiments and theoretical analysis are presented in this work."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Many related works are discussed.\n2. Numerical experiments are done in various datasets."}, "weaknesses": {"value": "This work presents a set of numerical results and a set of analytical results while neither of them fully convince me the superiority of the algorithm. I wonder what is the key contribution/focus of the work. Some key concerns are as below:\n1. Abstract: It is claimed that 'DAL accepts any stationary bandit algorithm as input' while Propositions/theorems (e.g. Theorem 4.4) come with some assumptions/conditions. It is somehow confusing.\n1. Line 28: It is claimed that 'MABs fall into ... PB, NPB, CB'. I feel maybe it is not that proper to say so. For example, contextual bandits can also be viewed as a parametric setting from some perspective.\n1. Algorithm 1: I think the algorithm is a key contribution of this work, while the pseudocode is not that easy to understand.\n  1. What is $N_e$?\n  1. When will $D( \\ldots )=\\text{detection}$ (in line 6)?\n1. Many subplots in Figures 1 and 2 present the regret/reward of only a portion of discussed algorithms? Do those missing algorithms perform better than DAL? An explanation is appreciated.\n1. Proposition 4.2: It is a bit unusal that the Lipschitz constant $BL_u$ does not affect the bound on $|V_T|$. Some explanations are appreciated.\n1. Theorem 4.4 comes many conditions/assumptions without discussions. Besides, how the regrets stated in the paragraph beginning from Line 414 is not that clear. Some explanations here are also appreciated.\n\n\nBesides, here is one minor suggestion:\n1. The algorithms should be arranged in the same order in the legend box for Figures 1 and 2."}, "questions": {"value": "See *Weaknesses* above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eBJEzWNBFE", "forum": "Els0yUtxNK", "replyto": "Els0yUtxNK", "signatures": ["ICLR.cc/2026/Conference/Submission20788/Reviewer_xZGQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20788/Reviewer_xZGQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20788/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762964089214, "cdate": 1762964089214, "tmdate": 1762964089214, "mdate": 1762964089214, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response: Revisions and Feedback"}, "comment": {"value": "We sincerely thank all reviewers for their thoughtful and constructive feedback, which has greatly improved the quality of our work. Below we summarize the revisions to our draft. The updated version (with changes in blue) and the new experimental code are provided in the latest upload and revised supplementary material.\n\n---\n\n- **Focus on PS**: As noted by Reviewer V4aw, we believe it is more appropriate to state our setting as PS rather than general non-stationary. We have therefore revised the title, abstract, and main text to explicitly reflect that our theoretical setting is PS. The broader “non-stationary” terminology is now used only for motivation and high-level descriptions.\n\n- **Detector Theory and Practice**: Reviewers xZGQ and TeBX requested more details on the non-stationarity detector. In the original submission, these were deferred to the appendix due to space constraints. We would like to highlight that the reason behind DAL's performance is not a specific detector, but rather the theoretical property that the GLR test has. To this end, we first include an additional detector, the GSR test, which satisfies the same property as the GLR test. With the additional page, we now (i) clearly state the key detector property in the (new) Property 4.1, (ii) add algorithmic implementations of the GLR and GSR tests as (new) Algorithms 2 and 3, and (iii) move the main theoretical requirements and practical details for the detector into Section 4.1. Finally, we provide the general mathematical formulations of both tests in the appendix.\n\n- **Practical Tuning and Covering Set**: Reviewers fy93 and TeBX raised concerns about the practical tuning of DAL and the construction of the covering set. In our original submission (Section 3), again, due to limited space we had to resort to deferring the details to the Appendix. In the revised version, we add a dedicated Subsection 3.2 that explains how to tune DAL in practice (detectors, base bandit algorithms, and covering sets) in accordance with our theory, while retaining further details in the appendix. In addition, following Reviewer xZGQ’s suggestion, we have revised the proposition for NS-KBs (now Proposition 4.3) to improve clarity.\n\n- **New Experiments**: To demonstrate that DAL’s performance stems from the newly stated Property 4.1 rather than the GLR test itself, we reran our experiments using the GSR detector on both synthetic and real-world benchmarks. The GSR-based DAL performs overall slightly better, supporting our claim that the framework’s success is driven by the underlying detector property. We also improved the contextual-bandit experiments: in the original version, we changed the policy set $\\\\Pi$ in each run, which led to high variance. In the revised experiments we fix $\\\\Pi$ across runs, yielding more stable and fair comparisons with the other settings.\n\n- **Clarity of Assumptions**: Reviewers xZGQ and V4aw requested clearer presentation of the assumptions underlying our main theorem. Previously, these were all embedded inside the theorem due to space limitations. We now introduce the separation assumption as a standalone assumption in the new Assumption 4.6, accompanied by Definition 4.5 and followed immediately by both existing and new explanatory text to make its role and implications explicit. We also add further discussion of the assumption on the regret of the input algorithm, including an explanatory paragraph preceding our main Theorem (now Theorem 4.8) and additional clarifications inside the theorem statement.\n\n- **Rigorous Analysis on CBs**: Reviewer TeBX raised concerns about the rigor of our analysis for contextual bandits. In response, we have added a complete, rigorous analysis and proof of our problem formulation (which is based on the contextual-bandit setting) in the appendix. While space constraints prevent us from including a full proof sketch in the main text, we believe this revision strikes a reasonable balance between readability and rigor, and we kindly  reviewers to refer to the revised proof, and we would be happy to further expand this discussion if space permits.\n\n- **Remaining Points**: All other comments and questions from the reviewers have been addressed in detail in the individual responses and incorporated into the revised manuscript to the best of our ability.\n\n---\n\nWe sincerely hope to have addressed all of the reviewers' comments to the best of our ability. We would be very happy to receive further feedback if there are additional concerns and hope the reviewers will kindly consider our clarifications and the contributions of our work."}}, "id": "3ozJPvg7hB", "forum": "Els0yUtxNK", "replyto": "Els0yUtxNK", "signatures": ["ICLR.cc/2026/Conference/Submission20788/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20788/Authors"], "number": 16, "invitations": ["ICLR.cc/2026/Conference/Submission20788/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763363973784, "cdate": 1763363973784, "tmdate": 1763363973784, "mdate": 1763363973784, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}