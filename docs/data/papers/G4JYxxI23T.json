{"id": "G4JYxxI23T", "number": 3634, "cdate": 1757489075698, "mdate": 1763697791693, "content": {"title": "Uncertainty Estimation via Hyperspherical Confidence Mapping", "abstract": "Quantifying uncertainty in neural network predictions is essential for deploying models in high-stakes domains such as autonomous driving, healthcare, and manufacturing.  While conventional approaches often depend on costly sampling or parametric distributional assumptions, we propose Hyperspherical Confidence Mapping (HCM), a simple yet principled framework for uncertainty estimation that is both sampling-free and distribution-free. HCM decomposes model outputs into a magnitude and a normalized direction vector constrained to lie on a unit hypersphere, enabling a novel interpretation of uncertainty as the degree of violation of a geometric constraint.  Grounded in this geometric constraint formulation, our method provides deterministic and interpretable uncertainty estimates applicable to both regression and classification. We validate the effectiveness of HCM across diverse benchmarks and real-world industrial tasks, demonstrating competitive or superior performance to ensemble and evidential approaches, while significantly reducing inference cost and ensuring strong confidence–error alignment. Our results highlight the value of geometric structure in uncertainty estimation and position HCM as a versatile alternative to conventional techniques.", "tldr": "", "keywords": ["uncertainty estimation", "Out-of-distribution (OOD) detection", "calibration"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ca221b42a48aa84f685b0a2e39bedd28901dad6c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In the paper, uncertainty in classification and regression is handled by transforming the target into a D-dimensional hypersphere where deviation from the norm-1 hypersphere indicates uncertainty. D is the number of classes for multi-class classification, however the way the hyperspherical target is applied to 1-dimensional regression is unclear to me, I'd like to see more details for this case.\n\nTheoretical justification and experimentation is convincing. Unfortunately, no source code is provided."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ Theoretically explained transformation of the learning process to include prediction uncertainty\n+ Detailed experimentation\n+ Well written paper"}, "weaknesses": {"value": "- the way the hyperspherical target is applied to 1-dimensional regression is unclear to me, but I may have overlooked something\n- no source code is provided\n- regression baselines might be extended"}, "questions": {"value": "Most importantly, the way the hyperspherical target is applied to 1-dimensional regression is unclear to me, I'd like to see more details for this case.\n\nPls provide source code, e.g. https://anonymous.4open.science/\n\nThe aleatoric estimator in Proposition 2 is only addressed in the case the aleatoric uncertainty is Gaussian noise. Can the proposed method handle non-Gaussian, non-unimodal, or cases when there are multiple correct answers, e.g. y=x^2(+noise)?\n\nI would like to see qualitative or quantitative comparison with approaches such as Bayesian NN [Shengyang Sun, Changyou Chen, and Lawrence Carin. Learning Structured Weight Uncertainty in Bayesian Neural Networks. AISTATS'17], or Mixture Density Networks [Yousef El-Laham, Niccolo Dalmasso, Elizabeth Fons, and Svitlana Vyetrenko. Deep gaussian mixture ensembles. In Uncertainty in Artificial Intelligence, PMLR, 2023.].\n  \nMinor: broken reference L299 We train ResNet-18 (?)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IUiz0l73vq", "forum": "G4JYxxI23T", "replyto": "G4JYxxI23T", "signatures": ["ICLR.cc/2026/Conference/Submission3634/Reviewer_mKdz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3634/Reviewer_mKdz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3634/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761378152631, "cdate": 1761378152631, "tmdate": 1762916888900, "mdate": 1762916888900, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an uncertainty quantification method based on decomposing model outputs into magnitude and direction components. During training, a unity-norm constraint is imposed on the direction component, and deviations from this constraint are penalized. These deviations later serve as the basis for uncertainty estimation: violations of the constraint are interpreted as indicators of uncertainty. The authors also show that prediction error can be lower-bounded by a function of this uncertainty measure. The method is evaluated on several regression and classification tasks, achieving empirical performance that is comparable to, and in some cases better than, established uncertainty quantification approaches."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "One of the main strengths of the paper is the simplicity and elegance of the proposed method. The idea of using deviations from a constraint as a proxy for uncertainty is both intuitive and conceptually appealing. This design makes the approach computationally efficient while still providing a meaningful signal about the reliability of model outputs.\n\nThe empirical results further reinforce the value of the method. Performance is on par with other established uncertainty quantification techniques, and the observed correlation between the proposed uncertainty scores and prediction error suggests that the method captures relevant aspects of uncertainty effectively.\n\nThe paper is also generally well written and easy to follow, which helps convey the technical content clearly."}, "weaknesses": {"value": "The theoretical motivation for the proposed method appears insufficiently developed. Most uncertainty quantification approaches are grounded in first principles, typically through statistical, Bayesian, or information-theoretic frameworks. In contrast, the paper lacks a similarly rigorous foundation. While the experiments demonstrate a correlation between prediction error and uncertainty scores, this empirical evidence may not be sufficient to justify the method on its own.\n\nThe paper attempts to motivate the approach through an analysis of aleatoric and epistemic uncertainty, but this connection is not convincing. The link to epistemic uncertainty, in particular, seems to rely primarily on empirical observations rather than theoretical grounding. Moreover, the proposed method does not enable a clear distinction between these two types of uncertainty. This is not a problem per se, since other established approaches such as conformal prediction also do not offer such separation, but it raises the question of why this conceptual framing is emphasized at all.\n\nRelated to these concerns, several aspects of the method remain unclear, as reflected in the questions below. These points suggest that the theoretical framing and practical interpretation could be articulated more clearly to strengthen the overall contribution.\n\n### Minor issues\n- In Remark 1, the authors note that \"$u(x)$ serves as a conservative and interpretable indicator of uncertainty: it\nmay underestimate error, but does not overestimate it in this regime\". I am not sure \"conservative\" is the best wording here, since underestimating the error is not typically what we associate with conservativeness. That is, I would call the method \"conservative\" it if gave an upper bound to the error instead.\n- Res-Net 18 rference missing in line 299."}, "questions": {"value": "1. **Dependence on Magnitude** I might be missing something, but why is the proposed uncertainty measure tied to the output magnitude? For example, in regression, could we arbitrarily shrink the uncertainty measure by scaling down the output space? Moreover, consider the following scenario where we have a 2D regression target with the ground-truth forming a circle around the origin. Would the proposed method assign low uncertainty to points close to the origin simply because the magnitude is low, even though these points are out of distribution?\n2. **Interpretability of the Uncertainty Score** Could you elaborate on the interpretability of the method? I agree the constraint on the output space is intuitive and easy to follow, but the uncertainty score itself does not seem meaningful in isolation. What is its scale and unit? How does it relate to established notions of uncertainty? In Section 3.3, confidence values are derived by exponentiating the uncertainty score, but the rationale for this transformation is unclear.\n3. **Dependence on Training Dynamics** In the conclusion it is said that “the uncertainty score $u(x)$ may depend on training dynamics”. Could you expand on this point? Specifically, the regularization coefficient $\\lambda_{norm}$ seems likely to play a key role in the method’s effectiveness. Have you conducted any ablation studies on this parameter, or can you provide guidelines for readers on how to set it?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ORqdPq5tkg", "forum": "G4JYxxI23T", "replyto": "G4JYxxI23T", "signatures": ["ICLR.cc/2026/Conference/Submission3634/Reviewer_caDX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3634/Reviewer_caDX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3634/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761571078304, "cdate": 1761571078304, "tmdate": 1762916888546, "mdate": 1762916888546, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a new sampling-free uncertainty quantification framework, termed Hyperspherical Confidence Mapping (HCM). The authors establish the theoretical foundations of this approach by reformulating the task as a constrained optimization problem related to prediction error. The proposed framework effectively disentangles uncertainty into its aleatoric and epistemic components. Comprehensive evaluations on both classification and regression image datasets demonstrate the superior performance of HCM in academic benchmarks and real-world semiconductor manufacturing tasks, underscoring its practical applicability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-structured and clearly presents the underlying motivation and experimental results. \n2. The authors provide a solid theoretical foundation for the proposed method, enabling the disentanglement of uncertainty into two components.\n3. The experimental evaluation demonstrates superior performance across several image classification and regression tasks, including both public datasets and industrial applications."}, "weaknesses": {"value": "1. The core idea of hyperspherical mapping, while interesting and effective, is not entirely novel. Previous work has already explored a similar concept in the context of text classification [1]. Although there are differences between the two approaches, these distinctions should be clearly articulated and supported through comparative analysis in the experimental setup.\n2. Table 1 suggests that similarity-based methods are not interpretable. However, the decisions made by such methods can, in fact, be interpreted, for example, through dimensionality reduction techniques applied to their hidden representations.\n3. Some relevant works from the similarity-based group are missing and should be included in the experimental evaluation, such as NUQ [2] and HUQ [3].\n4. The experimental evaluation could be strengthened by extending the approach to text classification tasks [1,2,3].\n5. Broken reference on line 299.\n\n[1] Gong et al. Confidence Calibration for Intent Detection via Hyperspherical Space and Rebalanced Accuracy-Uncertainty Loss. AAAI 2022.\\\n[2] Kotelevskii et al. Nonparametric Uncertainty Quantification for Single Deterministic Neural Network. NeurIPS 2022. \\\n[3] Vazhentsev et al. Hybrid Uncertainty Quantification for Selective Text Classification in Ambiguous Tasks. ACL 2023"}, "questions": {"value": "1. Are there any specific considerations or challenges when applying this approach to other domains?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "52SxFMVGKv", "forum": "G4JYxxI23T", "replyto": "G4JYxxI23T", "signatures": ["ICLR.cc/2026/Conference/Submission3634/Reviewer_X9Js"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3634/Reviewer_X9Js"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3634/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923362755, "cdate": 1761923362755, "tmdate": 1762916887911, "mdate": 1762916887911, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel approach for uncertainty estimation (UE), Hyperspherical Confidence Mapping (HCM), based on the decomposition of the output of the model on the magnitude scalar value (R) and unit-norm direction vector (d). To apply this approach, authors modify the models to predict both R and d values and decompose the original classification or regression target into two corresponding components. After that, authors define a composite loss function for training models with aforementioned changes, and quantify an uncertainty score u(x) based on predicted R and d values. Moreover, the authors also separate epistemic and aleatoric uncertainties and define a separate estimator for aleatoric uncertainty, while u(x) serves as the epistemic uncertainty score. Finally, the authors conducted thorough experiments on OOD detection on image classification, uncertainty calibration for regression for depth estimation, and uncertainty calibration for an industrial regression task. All of the experiments show the applicability of the HCM and demonstrate that HCM shows comparable performance with the other UE methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe proposed HCM approach provides a novel view on uncertainty estimation and provides theoretical foundations and interpretation for the HCM UE score.  \n2.\tThe experiments on Two Moons demonstrate the interpretability of the method, while experiments on calibration and OOD detection show that the HCM achieves comparable performance with other UE methods or outperforms them.  \n3.\tThe experiments on industrial data further strengthen the claim about HCM’s applicability and demonstrate that HCM outperforms other methods on real-world data for the calibration task."}, "weaknesses": {"value": "1.\tHCM requires additional model fine-tuning. This can limit the method’s applicability for some modern models (e. g. in a zero-shot setting). Moreover, if the presented HCM approach is used for obtaining predictions on the main task – for example, one can use R and d value to both obtain predicted class and to estimate uncertainty – it can affect the performance of the model on the main task. This topic was left unexplored during the experiments; however, it can significantly affect the applicability of the HCM.  \n2.\tLimited applicability on the OOD detection task. On the OOD detection task, HCM shows comparable performance with a much simpler MDS method, which does not require model modification – these limit the HCM applicability for OOD detection, especially in the areas where fine-tuning is rarely used (e. g. LLMs)."}, "questions": {"value": "1.\tMissed reference on line 299.  \n2.\tTypo in line 749: “gound” -> “ground”."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Emk7u7kGqO", "forum": "G4JYxxI23T", "replyto": "G4JYxxI23T", "signatures": ["ICLR.cc/2026/Conference/Submission3634/Reviewer_MWzw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3634/Reviewer_MWzw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3634/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762105680158, "cdate": 1762105680158, "tmdate": 1762916887287, "mdate": 1762916887287, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}