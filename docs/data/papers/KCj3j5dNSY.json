{"id": "KCj3j5dNSY", "number": 15006, "cdate": 1758246738553, "mdate": 1759897336019, "content": {"title": "Knowledge Exchange with Confidence: Cost-Effective LLM Integration for Reliable and Efficient Visual Question Answering", "abstract": "Recent advances in large language models (LLMs) have improved the accuracy of visual question answering (VQA) systems. However, directly applying LLMs to VQA still presents several challenges: (a) suboptimal performance when handling questions from specialized domains, (b) higher computational costs and slower inference speed due to large model sizes, and (c) the absence of a systematic approach to precisely quantify the uncertainty of LLM responses, raising concerns about their reliability in high-stakes tasks. To address these issues, we propose an UNcertainty-aware LLM-Integrated VQA model ($\\texttt{Uni-VQA}$). This model facilitates knowledge exchange between the LLM and a calibrated task specific model (\\ie \\texttt{TS-VQA}), guided by reliable confidence scores, resulting in improved VQA accuracy, reliability and inference speed. Our framework strategically leverages these confidence scores to manage the interaction between the LLM and $\\texttt{TS-VQA}$: the specialized questions are answered by the $\\texttt{TS-VQA}$ model, while general knowledge questions are handled by the LLM. For questions requiring both specialized and general knowledge, the $\\texttt{TS-VQA}$ provides candidate answers, which the LLM then combines with its internal knowledge to generate a more accurate response. Extensive experiments on VQA datasets demonstrate the theoretically justified advantages of $\\texttt{Uni-VQA}$ over using the LLM or $\\texttt{TS-VQA}$ alone.", "tldr": "", "keywords": ["visual question answering", "model calibration"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5669e469ae513df0cfa112add25c1f64a0fada3d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a calibrated, rule-based router to combine TS-VQA and LLM to balance power consumption and performance. The first step is to apply the existing DRO method to calibrate confidence. Then the calibrated confidence is used to route questions to different decision models with varying capability vs power consumption combinations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper offers a practical cost-aware collaboration between TS-VQA with an LLM to save energy consumption.\n- The motivation and trade-off framing are convincing."}, "weaknesses": {"value": "- Modest novelty. The proposed system is essentially a confidence-controlled routing. \n- There seems to be a lack of comparison between ensemble-aware fusion vs a distilled single model, to fully understand the tradeoff between reliability and latency.\n- The routing is hard-coded. There is no comparison to a learned router or agentic alternatives (that add a light verifier before calling the LLM).\n- Sustainability is a central motivation. But the benefit is not sufficiently evidenced with proper accounting.\n- The writing can be improved. For example, the DRO paragraph introduces $\\lambda$ abruptly, leaving the mechanism unclear."}, "questions": {"value": "Please give the exact form of $w$ and its dependence on $\\lambda$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XwGmzPdjLc", "forum": "KCj3j5dNSY", "replyto": "KCj3j5dNSY", "signatures": ["ICLR.cc/2026/Conference/Submission15006/Reviewer_FgQE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15006/Reviewer_FgQE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761190406798, "cdate": 1761190406798, "tmdate": 1762925336466, "mdate": 1762925336466, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Uni-VQA, a hybrid VQA framework that uses calibrated confidence scores from a task-specific VQA model to decide when and how to involve an LLM. High-confidence questions are answered locally, low-confidence ones are delegated to the LLM, and intermediate cases use candidate answers for collaboration. The approach improves accuracy while reducing reliance on costly LLM inference."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The related work section is well organized and clearly positions this framework among prior VQA, calibration, and LLM-augmented systems, making it easy to understand its practical motivation.\n\n- The theoretical derivations and more complex details are moved to the appendix, which helps maintain good readability in the main paper.\n\n\n\n- The experimental evaluation is comprehensive, including multiple backbones, datasets, and ablation studies."}, "weaknesses": {"value": "- Confidence threshold decisions could use more clarification\n  - The routing strategy depends on two confidence thresholds (ùëô,ùë¢). It would be helpful to include more explanation on how these values are selected and how sensitive the method is to different threshold settings across datasets or models.\n\n- The effectiveness of TS-VQA candidates may vary depending on the confidence level\n  - When the TS-VQA model has low confidence, its proposed candidates may negatively influence the LLM‚Äôs reasoning. The current strategy of suppressing candidates only in low-confidence cases is reasonable, but additional analysis on when candidates are beneficial vs. harmful would provide deeper insight into this interaction.\n\n- LLM output reliability is not fully addressed\n  - The reliability of LLM outputs is not modeled. Since the LLM handles the most uncertain samples, having some form of uncertainty estimation or error check on the LLM side could further improve the robustness of the overall system.\n\n- Some figures have relatively small, which affects readability. For example, Figure 3 and Figure 14.\n\n- There is no Ethics Statement or Reproducibility Statement in the paper, which are required by the ICLR submission guidelines. Authors may miss this information."}, "questions": {"value": "See weaknesses please"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6T46SED3Um", "forum": "KCj3j5dNSY", "replyto": "KCj3j5dNSY", "signatures": ["ICLR.cc/2026/Conference/Submission15006/Reviewer_nhPm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15006/Reviewer_nhPm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761412698473, "cdate": 1761412698473, "tmdate": 1762925335885, "mdate": 1762925335885, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Uni-VQA, a method employing an LLM and a task-specific VQA model to efficiently answer questions. The task-specific VQA model is calibrated to provide reliable confidence scores. With the confidence score, the framework whether the answer from the task-specific VQA model should be processed by the LLM. Extensive experiments show the effectiveness of the method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The motivation for introducing task-specific VQA model is reasonable and practical.\n2. The calibration of task-specific VQA model provide reliable confidence score, enabling the interaction between the two VQA models.\n3. Extensive experiments show the effectiveness of the method."}, "weaknesses": {"value": "1. RAG (Retrieval-Augmented Generation) methods are not discussed and compared. The task-specific VQA model serves as a role of providing specific knowledge for LLM, which is similar to external and up-to-date information in RAG methods. The advantages and disadvantages of the proposed method compared to RAG methods should be discussed and compared.\n2. The training cost of the task-specific VQA models and the distillation is not reported. It is unclear whether it would be the bottleneck of the framework."}, "questions": {"value": "1. What are the advantages and disadvantages of the proposed method compared to RAG methods?\n2. What is the training costs of the task-specific VQA models and the distillation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tCkmFZdDwf", "forum": "KCj3j5dNSY", "replyto": "KCj3j5dNSY", "signatures": ["ICLR.cc/2026/Conference/Submission15006/Reviewer_H4gC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15006/Reviewer_H4gC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842794668, "cdate": 1761842794668, "tmdate": 1762925334405, "mdate": 1762925334405, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel framework called Uni-VQA for visual question answering, aiming to address challenges in directly applying large language models to VQA, such as suboptimal performance in specialized domains, high computational costs, and lack of uncertainty quantification. The key contributions include: (1) developing a calibration technique based on a diverse ensemble to improve the reliability of confidence estimates for task-specific VQA models; (2) introducing a confidence-guided knowledge exchange mechanism that dynamically decides whether to delegate to an LLM and how to provide candidate answers based on TS-VQA confidence scores, optimizing accuracy and efficiency; and (3) validating the framework through theoretical analysis and extensive experiments on VQA-v2 and COCO-QA datasets, showing superior performance over using LLM or TS-VQA alone while significantly reducing computational overhead. The paper also explores knowledge distillation for faster inference and provides analysis on carbon emissions and latency, highlighting environmental sustainability benefits."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper novelly integrates confidence-guided mechanisms with LLM-VQA collaboration, differing from traditional model cascades or simple delegation. The dynamic candidate answer selection based on confidence intervals is a creative combination, underexplored in existing work.\n\nThe method has theoretical depth and experiments are comprehensive, covering multiple VQA modelsand datasets with consistent results. Ablation studies validate component importance. Writing is concise, and figuresintuitively explain complex concepts, with clear mathematical derivations.\n\nThe work directly targets AI scalability and sustainability, reducing LLM carbon footprint, with potential impact on high-stakes applications , aligning with green AI trends."}, "weaknesses": {"value": "While tested on VQA-v2 and COCO-QA, the paper does not include more diverse datasets (e.g., medical VQA or long-tailed distributions), potentially limiting generalizability. Also, LLM usage is limited to Mistral-7B and LLaVA, without extension to larger models , failing to fully assess scale effects.\n\nThe calibration technique relies on diverse ensembles, increasing training overhead, and although distillation mitigates this, it may affect deployment ease. \n\nComparison with recent VQA methods (e.g., Transformer-based variants) is limited; the paper focuses on traditional baselines.\n\nTheorem 4.2 relies on inverse relationship between entropy and confidence, but strict proof in multi-class settings depends on uniform distribution assumptions, which may deviate in practice."}, "questions": {"value": "1.How does Uni-VQA handle modal missingness or distribution shifts? For example, if image quality is poor or questions are out-of-distribution, does confidence calibration remain reliable? \n\n2.The paper mentions that confidence thresholds are determined using a validation set. Could you provide more specifics about the optimization process? What objective function was used to balance accuracy and efficiency during threshold selection?\n\n3.While the paper demonstrates inference efficiency, could you provide more details about the training computational costs of the diverse ensemble approach? How does the training time scale with the number of ensemble members?\n\n4.How does the framework handle concept drift or distribution shifts over time? Have you considered mechanisms for continuous adaptation of the confidence thresholds?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "oREWUGSGXP", "forum": "KCj3j5dNSY", "replyto": "KCj3j5dNSY", "signatures": ["ICLR.cc/2026/Conference/Submission15006/Reviewer_7cPv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15006/Reviewer_7cPv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15006/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876492333, "cdate": 1761876492333, "tmdate": 1762925333869, "mdate": 1762925333869, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}