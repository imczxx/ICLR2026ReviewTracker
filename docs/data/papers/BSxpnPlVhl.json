{"id": "BSxpnPlVhl", "number": 23941, "cdate": 1758350583953, "mdate": 1759896789442, "content": {"title": "TaskMixPGM: Task Mixtures via Probabilistic Graphical Modelling for Language Model Finetuning", "abstract": "The performance of fine-tuned large language models (LLMs) hinges critically\n    on the composition of the training mixture. However, selecting an optimal blend\n    of task datasets remains a largely manual, heuristic-driven process, with practitioners\n    often relying on uniform or size-based sampling strategies. We introduce\n    TaskMixPGM, a principled and scalable framework for mixture optimization\n    that selects continuous task proportions by minimizing an energy function\n    over a Markov Random Field (MRF). Task relationships are modeled using behavioral\n    divergences—such as Jensen-Shannon Divergence and Pointwise Mutual Information—computed\n    from the predictive distributions of single-task fine-tuned models. Our\n    method yields a closed-form solution under simplex constraints and provably\n    balances representativeness and diversity among tasks. We provide theoretical\n    guarantees, including weak submodularity for budgeted variants, and demonstrate\n    consistent empirical improvements on Llama-2 and Mistral across evaluation suites\n    such as MMLU and BIG-Bench-Hard. Beyond performance, TaskMixPGM offers\n    interpretable insights into task influence and mixture composition, making it\n    a powerful tool for efficient and robust LLM fine-tuning.", "tldr": "", "keywords": ["llm", "finetuning", "task mixtures", "pointwise mutual information"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8f0764b08afad98c8f2b8501cecc7a5e281ef61e.pdf", "supplementary_material": "/attachment/609c54622fc46fb5840ef37fda68e835056e31ee.pdf"}, "replies": [{"content": {"summary": {"value": "This paper introduces TaskMixPGM, a novel framework for automatically determining the optimal data mixture for fine-tuning large LLMs. The core idea is to model the set of candidate tasks as a MRF and to find the optimal mixture proportions by minimizing an energy function. This energy function is designed to balance task \"representativeness\" and \"diversity\". A key contribution is the use of behavioral divergences (JSD or PMI) to define a functional similarity metric between tasks. The authors derive a closed-form solution for the optimal mixture and provide theoretical guarantees, such as weak submodularity for budgeted task selection. Experiments on Llama-2-7B and Mistral-7B show improvements on benchmarks like MMLU over simple heuristic baselines."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Novel and Principled Formulation**: The paper proposes a novel and theoretically-grounded framework for data mixture optimization, moving beyond common heuristics. Modeling task relationships as an MRF with an energy function that balances representativeness and diversity is an elegant approach.\n\n**Insightful Similarity Metric**: The use of \"behavioral divergences\" (JSD/PMI) based on model predictions is a significant strength. This captures a deeper, functional notion of task similarity compared to superficial semantic similarity, which is more relevant to model training dynamics.\n\n**Theoretical Guarantees**: The derivation of a closed-form solution is a practical contribution, ensuring computational efficiency."}, "weaknesses": {"value": "1. **Deficiencies in Experimental Validation**: The empirical evidence presented is insufficient to support the paper's strong claims of superiority\n   - ***Lack of Transparency and Reproducibility***: The paper fails to provide crucial implementation details. There is no analysis of the learned similarity matrix S or the final mixture weights p*. Consequently, claims of interpretability are unsubstantiated, as key insights—such as which tasks are deemed most influential or how different skill domains are absent.\n   -  ***Missing Hyperparameter Analysis***: The method’s core trade-off between representativeness and diversity,  β and λ, are set to fixed values (β=20, λ=10) without any justification, ablation study.\n   - ***Critically Weak Baselines***: The performance is only compared against simplistic heuristics (Random, Uniform, EPM). The paper neglects to compare against far more relevant and stronger baselines discussed in its own related work section, such as RegMix, Doremi, or instruction-tuning specific methods like LESS and SMART. \n   - ***Potentially Outdated Experimental Setup***: While the chosen benchmarks are standard, the experiments rely on relatively older models (Llama-2, Mistral-7B). Validating the findings on more recent and capable models (e.g., Llama-3, Qwen2.5/3) would be necessary to demonstrate the method's relevance in the current fast-paced landscape.\n\n2. **Unreliable Definitions and Foundational Assumptions**: The theoretical framework is built upon several questionable assumptions that may not hold in practice\n   - ***Flawed Definition of 'Representativeness'***: The framework defines a task's representativeness by its cumulative similarity to all other tasks. This approach risks conflating importance with generality, potentially prioritizing generic, \"common-denominator\" tasks while penalizing unique and specialized ones (e.g., advanced reasoning) that are critical for expanding a model's capabilities but may be dissimilar to the majority.\n   - ***Ambiguous Definition of 'Task'***: The paper fails to provide a clear, operational definition of a \"task.\" It is unclear whether a task corresponds to an domain, entire dataset (e.g., Flan), a specific sub-task (e.g., a GLUE task), or a conceptual skill. \n   - ***Oversimplified Assumption of Learning Dynamics***: The method implicitly assumes that all data within a task dataset D_i contributes uniformly and positively to learning the associated skill. This decouples the optimization from the LLM's actual learning process, ignoring the reality that data quality is heterogeneous and that some examples can be noisy or even detrimental to training.\n\n3. **Unquantified and Potentially Prohibitive Computational Cost**: The paper claims the framework is \"scalable\" but fails to address its significant computational overhead. Constructing the similarity matrix requires O(n) independent fine-tuning runs and O(n^2) pairwise model evaluations. This upfront cost is neither quantified in the paper (e.g., additional GPU-hours) nor discussed in terms of its practical limits, making the scalability claim unsubstantiated.\n\n4. **Issues with Clarity, Overclaiming, and Incomplete Literature**\n\n   - ***Clarity and Overclaiming***: The paper's argument that an MRF \"inherently\" balances the desired criteria is an potential overstatement; Additionally, some theoretical sections are hard to follow, and the proofs for lemmas in Section 5 and 6 lack sufficient detail.\n   - ***Writing and Presentation Flaws***: The presence of a placeholder (\"X.X pp\") in the contributions list, redundant phrasing in the introduction (\"distinct advantages\" vs. \"contributions\"), and a long related work section that is disconnected from the experimental comparisons."}, "questions": {"value": "My decision could be swayed if the authors can provide convincing answers to the following critical questions:\n\n1. **Regarding Baselines**: Can you provide a strong justification for excluding state-of-the-art baselines like SMART, RegMix, or LESS from your experiments? A direct comparison is essential to properly situate your method's performance.\n\n2. **Regarding Hyperparameters**: How was the ratio β/λ=2 determined? Could you provide a sensitivity analysis to demonstrate how this crucial trade-off impacts the selected mixture and, consequently, the final model's performance across different evaluation benchmarks?\n\n3. **Regarding Computational Cost and Scalability**: Given the ambiguous definition of a \"task,\" could you provide a concrete cost analysis (e.g., in total GPU-hours) for constructing the similarity matrix in your 319-task experiment? Furthermore, how do you see the method scaling when n (the number of tasks) grows larger?\n\n4. **Regarding Interpretability**: To substantiate your claim of interpretability, could you provide a qualitative analysis of the learned task mixture? For instance, which specific tasks received the highest weights, and what does the similarity matrix reveal about the functional relationships between different task categories (e.g., reasoning vs. coding)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XXiDsFFNr4", "forum": "BSxpnPlVhl", "replyto": "BSxpnPlVhl", "signatures": ["ICLR.cc/2026/Conference/Submission23941/Reviewer_fkK8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23941/Reviewer_fkK8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761468227512, "cdate": 1761468227512, "tmdate": 1762942866045, "mdate": 1762942866045, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TaskMixPGM, a method for finding the data mixture for fine-tuning a Large Language Model. The authors argue past methods their method provides a formal way to find the optimal blend of tasks. The core idea is to minimize an energy function defined on tasks and task similarities, where the task's collective similarity is maximized (generally useful), and pairwise similarities are minimized (to enforce diversity). In order to solve this problem, the authors model the task as a minimization of pairwise similarities and maximize the unary potentials.\n\nAnother design is the definition of similarity, which is defined on how other tasks perform on models fine-tuned on every single task, captured with PMI or JSD."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Mixture optimization utilizing the task-mix structure**: This method provides a rigid and theoretically-grounded way to solve the problem of task mix. The design of the method utilizes some internal structure similarities of the tasks, which avoids the cost-prohibited two-layer optimization: optimizing the task weights, optimizing the final model performance.\n\n**Novel similarity metric design**: the similarity metric are defined on the effect of the task, instead of lexical/semantic similarity."}, "weaknesses": {"value": "**Similarity/centrality task assumption**:  \n  - One assumption of this paper is to maximize the task that is mostly similar to others (while minimizing diversity). This assumption is that any skill common to many tasks must be foundational or important. I am not sure if this assumption is valid. The common \"skill\" can be generic. \n  - On the other hand, this depends on the quality of the task pool a lot. Imagine a case where the task pool has some good tasks $(t_0, t_1, ..., t_m)$, and some bad tasks $(t_{m+1}, t_{m+2}, ..., t_{m+n})$. If $n >> m$, this method will be highly biased by the bad task pool. This thought experiment seems to show a limitation of this method.\n\n**Significant upfront cost**: One major limitation for using the method practically is the cost needed to build its similarity matrix. The method requires one to fine-tune one separate model for every single task. For hundreds of tasks, this is a huge one-time computational cost that could be impractical and will only get worse as more tasks are added.  At least, this cost should be clearly discussed and analyzed, providing readers an idea of tradeoff.\n\n**Complexity in implementation**: manage a large army of finetuning training can also be error-prone. The hyperparameter setup and training details may affect the model quality, which in turn can affect the similarity calculation hence the final data mix.\n\n**Potentially Weak Baselines**: The paper proves its method is better than simple heuristics like \"Random,\" \"Uniform,\" and \"Size-Proportional\" sampling. However, it doesn't compare against the advanced data-selection methods. This makes it hard to know ifthis method is truly state-of-the-art. The author should have compared with methods presented in the relative work section, such as RegMix. Further, a pretty relevant work (https://openreview.net/forum?id=19kqoNoc2N): Data Mixing Optimization, which also mix finetuning datasets, should have been included too.\n\n\n**Potential Incomplete Experiment/Writing on Task Discovery**: At line 455, there is a small description of the experiment of \"Task Discovery\", intends to analyze what happens when \"strong\" vs. \"weak\" tasks are added to the mix in different orders. However, I have a hard time finding the results, leaving the section feeling incomplete.\n\n**Other presentation/writing problems**: \n  - The figures in 1(a) left and 1(b) left are too small and it is unclear what are the arguments to be made there.\n  - Line 159, `subscriptsxxx` should be typos"}, "questions": {"value": "The paper defines a concept called the \"task vector\" ($\\tau(T_i)$) with an equation, but I cannot find further usage of this term again later. What's the purpose for defining this term?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zQxqlwTp8e", "forum": "BSxpnPlVhl", "replyto": "BSxpnPlVhl", "signatures": ["ICLR.cc/2026/Conference/Submission23941/Reviewer_c4AK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23941/Reviewer_c4AK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761889495805, "cdate": 1761889495805, "tmdate": 1762942865845, "mdate": 1762942865845, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a novel data mixture optimization algorithm by minimizing an energy function over a Markov Random Field (MRF). \nThe method is grounded on the energy function and MRF theory and outperform uniform and random baselines on some of the benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. the theoretical foundation of the energy function and MRF is well grounded.\n\n2. empirically, the proposed method outperform uniform and random baselines on some of the benchmarks."}, "weaknesses": {"value": "1. The computation of the Task Similarity matrix $S$ involve a retraining on each of the $k$ tasks, which introduces nontrivial computational overhead. How well the method can be scaled up with the number of tasks and model sizes?\n\n2. The proposed algorithm can be greatly depend on the constructed Task Similarity matrix $S$. How long is the model been tuned to construct a reliable $S$?\n\n3. Since the optimized data mixture can be stronly dependent on the model-specific task similarity, how well can the proxy-model based mixture transfer to larger-scale model or the model within different architecture family?\n\n4. The balance between Representativeness and Diversity is controlled by the hyperparameter $\\lambda$ and $\\beta$. While the paper lacks an ablation for selecting $\\lambda, \\beta$.\n\n5. Lack of comparison to a lot of data mixture baselines [1] [2] [3]. Can you provide comparison results to them?\n\n6. The listed \"Tasks\" for experiments are very general and coarse, mostly multitasking datasets. Why do you choose those coarse datasets instead of more fine-grained, domain specialized ones? Have you done the experiments on more fine-grained datasets?\n\n\n[1] DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining\n\n[2] DoGE: Domain Reweighting with Generalization Estimation\n\n[3] Aioli: A Unified Optimization Framework for Language Model Data Mixing\n\n\nminor: the \"X.X pp improvement\" in line 102-103 is confusing."}, "questions": {"value": "According to the attached question to each point of weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ws9rC2qoiD", "forum": "BSxpnPlVhl", "replyto": "BSxpnPlVhl", "signatures": ["ICLR.cc/2026/Conference/Submission23941/Reviewer_zJEk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23941/Reviewer_zJEk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965654661, "cdate": 1761965654661, "tmdate": 1762942865600, "mdate": 1762942865600, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies how to construct better data mixtures for SFT on multiple tasks. They propose an objective based on a MRF and a similarity matrix over the tasks, captured via Jensen-Shannon Divergence and Pointwise Mutual Information of models trained on each task. They show that this proposed method can outperform simple mixes such as uniform and random sampling."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Quality: on both Llama2-7B and Mistral-7B, the proposed method generally outperforms simple mixes such as random and uniform sampling.\n\nSignificance: Task discovery is an important and underexplored setting."}, "weaknesses": {"value": "Originality: \n- The proposed method has limited novelty. The objective in equation (1) and fine-tuning many task specific models to compute S is nearly identical to approaches like UtiliMax (https://arxiv.org/abs/2501.11747) and Skill-It (https://arxiv.org/abs/2307.14430), besides the use of JSD/PMI.\n\nQuality:\n- Since the optimization problem is constructed only over the training domains, we do not get a complete picture of evaluation with just downstream tasks; instead we should look at how the method reduces training loss and validation loss on the domains themselves. For instance, if the set of tasks were all code and we evaluated on IFEval, then even a really good mixing algorithm may not perform great, and maybe a more arbitrary mix would do well. \n- The baseline mixes in the paper do not require any additional training costs. There should also be more sophisticated mixing baselines that learn a mix, such as UtiliMax and Skill-It, and cost should be normalized across these and TaskMixPGM.  \n- The cost of the approach is unclear. For the experiments, do you fine-tune 319 separate models, one per task, and is it for a full epoch or less? How long is each of these fine-tuning runs versus the final mixing run?\n- Should include ablations on the hyperparameters $\\beta$ and $\\lambda$\n- I do not completely agree that we want a symmetric S. Intuitively, S_ij may want to capture the influence of domain i on domain j, which is not symmetric. \n\nClarity: the writing is of low quality overall. For example:\n- Typos: line 102 \"X.X\" and line 159 \"xxx\"\n- No algorithm box for the approach is mentioned in the body\n- Section 5 and 6 look incomplete and are not well-motivated."}, "questions": {"value": "1. Can the authors report training loss and/or validation loss on the tasks to better understand the performance of the approach?\n2. Can the authors compare the approach to more sophisticated baselines that learn a mixture, rather than random/uniform sampling?\n3. What is the computational cost of the approach?\n4. Can you provide ablations on the hyperparameters $\\beta$ and $\\lambda$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "9J3NcO2e9X", "forum": "BSxpnPlVhl", "replyto": "BSxpnPlVhl", "signatures": ["ICLR.cc/2026/Conference/Submission23941/Reviewer_t7xB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23941/Reviewer_t7xB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762247809966, "cdate": 1762247809966, "tmdate": 1762942865396, "mdate": 1762942865396, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "TaskMixPGM optimizes LLM fine-tuning mixtures by modeling task relationships as a Markov Random Field (MRF). It minimizes an energy function using behavioral similarity metrics to derive a closed-form solution balancing task representativeness and diversity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. It introduces a formal, energy-based optimization for task mixing, replacing common heuristics. Its closed-form solution avoids expensive iterative searches.\n2. It provides theoretical guarantees and demonstrates empirical gains over baselines on the benchmarks."}, "weaknesses": {"value": "1. The method requires fine-tuning a distinct model per task to construct the similarity matrix, which is computationally prohibitive.\n2. Consequently, the approach scales poorly to a large number of tasks. This dependency on fine-tuning also restricts its applicability to scenarios outside of this paradigm, such as pre-training.\n3. The solution's reliance on matrix inversion introduces potential numerical instability, particularly when dealing with ill-conditioned similarity matrices. It remains unclear how the method addresses or mitigates this potential issue."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "T41Sjh42rl", "forum": "BSxpnPlVhl", "replyto": "BSxpnPlVhl", "signatures": ["ICLR.cc/2026/Conference/Submission23941/Reviewer_MLAE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23941/Reviewer_MLAE"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission23941/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762748316676, "cdate": 1762748316676, "tmdate": 1762942865169, "mdate": 1762942865169, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}