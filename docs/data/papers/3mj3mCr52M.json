{"id": "3mj3mCr52M", "number": 1953, "cdate": 1756970156114, "mdate": 1763020066437, "content": {"title": "Beyond Fixed: Aligning Guidance with Diffusion Dynamics via Exponential Scaling", "abstract": "Classifier-Free Guidance (CFG) is a cornerstone of modern conditional diffusion models, yet its reliance on the fixed or heuristic dynamic guidance weight is predominantly empirical and overlooks the inherent dynamics of the diffusion process. \nIn this paper, we provide a rigorous theoretical analysis of the Classifier-Free Guidance. Specifically, we establish strict upper bounds on the score discrepancy between conditional and unconditional distributions at different timesteps based on the diffusion process.\nThis finding explains the limitations of fixed-weight strategies and establishes a principled foundation for time-dependent guidance. Motivated by this insight, we introduce **Exponential Classifier-Free Guidance (E-CFG)**, a novel, training-free method that aligns the guidance strength with the diffusion dynamics via an exponential decay schedule. Extensive experiments show that E-CFG not only enhances controllability but also demonstrates significant performance gains across various benchmarks, including conditional image and text-to-image generation.", "tldr": "", "keywords": ["Diffusion model"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/b3feec24a021ec8f1dd68c97273980681118284b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a theoretical analysis of Classifier-Free Guidance in diffusion models. The authors derive upper bounds on the score discrepancy between conditional and unconditional distributions across different timesteps, grounded in the diffusion process. Their findings reveal the limitations of fixed-weight guidance strategies and establish a principled foundation for time-dependent guidance. Building on this insight, they propose Exponential Classifier-Free Guidance (E-CFG), a training-free method that modulates guidance strength in alignment with diffusion dynamics through an exponential decay schedule. The effectiveness of E-CFG is validated on both image generation and text-to-image tasks."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The authors offer a solid theoretical understanding of the relationship between conditional and unconditional outputs in Classifier-Free Guidance (CFG), as well as the distributional dynamics across different timesteps.\n\n* Their analysis motivates a time-decaying weighting strategy for CFG, leading to the development of Exponential Classifier-Free Guidance (E-CFG). This method effectively balances conditional and unconditional signals throughout the generation process, resulting in improved output quality.\n\n* They validate their approach through comprehensive experiments across a diverse set of models, including Stable Diffusion, EDM2, U-ViT, DiT, and SiT."}, "weaknesses": {"value": "* The paper lacks an intuitive interpretation of Theorems 1–4 in the context of practical diffusion behavior. It remains unclear why the conditional and unconditional outputs behave as described during the sampling process, and how these theoretical results connect to real-world diffusion dynamics."}, "questions": {"value": "* Regarding the hyperparameters of E-CFG, \\lambda and t: do they require additional tuning effort compared to standard guidance methods?\n\n* What is the rationale behind choosing an exponential form for the E-CFG schedule? \n\n* Could E-CFG potentially inspire a new paradigm for training diffusion models, beyond its current role in guidance?\n\n* Figure 4 is particularly compelling. Have you considered comparing E-CFG with the approach proposed in Guiding a Diffusion Model with a Bad Version of Itself to further contextualize its effectiveness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XazhBGgogk", "forum": "3mj3mCr52M", "replyto": "3mj3mCr52M", "signatures": ["ICLR.cc/2026/Conference/Submission1953/Reviewer_86Pm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1953/Reviewer_86Pm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760934416625, "cdate": 1760934416625, "tmdate": 1762915967946, "mdate": 1762915967946, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "sAAJi45IVX", "forum": "3mj3mCr52M", "replyto": "3mj3mCr52M", "signatures": ["ICLR.cc/2026/Conference/Submission1953/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1953/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763020065623, "cdate": 1763020065623, "tmdate": 1763020065623, "mdate": 1763020065623, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the behavior of the conditional and unconditional scores, by raising an upper bound of the MSE between the two scores. Since the bound tends to infinity when $t$ is small and tends to zero when $t$ is large, the authors propose to design a decreasing coefficient on the guidance weights of CFG when $t$ tends to zero, which enhance the stability of the guided sampling."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The analyses are clear and straightforward, and the proposed method is intuitive and easy to implement.\n- The experiments demonstrate the efficacy of the proposed method."}, "weaknesses": {"value": "- In spite of the reported experimental improvements, there are several theoretical flaws in the paper, which severely weakens the soundness and the contribution:\n  1. Both Thms.1 and 2 discuss the upper bound of the MSE between conditional and unconditional scores, however, a large upper bound does not indicate a large MSE. For example, $x^2$ is definitely an upper bound of $-1$, which provides no approximation significance when $x$ tends to infinity. Therefore in Thms. 1 and 2, a singularity at $t=0$ might not mean any uncertainty or instability. To address this issue, the authors should give the lower bound of the MSE. Besides, the upper bound in the paper is too loose to suggest any significant information. A toy example example can be defined as below, in which the MSE is bounded by constant for any $t$:\n    $$p(x_t,t|y=1)=\\mathcal N(1,1+t),\\quad p(x_t,t|y=-1)=\\mathcal N(-1,1+t),\\quad p(x_t,t)=\\frac{1}{2}p(x_t,t|y=1)+\\frac{1}{2}p(x_t,t|y=-1)$$\n    $$\\nabla\\log p(x_t,t|y=1)=-\\frac{x_t-1}{t+1},\\quad\\nabla\\log p(x_t,t|y=-1)=-\\frac{x_t+1}{t+1},\\quad\\nabla\\log p(x_t,t)=-\\frac{1}{2}\\frac{x_t-1}{t+1}-\\frac{1}{2}\\frac{x_t+1}{t+1}$$\n    $$\\nabla\\log p(x_t,t)-\\nabla\\log p(x_t,t|y=1)=\\frac{1}{t+1}\\leqslant 1,\\forall t\\in[0,\\infty)$$\n  2. The proof of Thms.1 and 2 are wrong. Below is a counterexample:\n    $$p(c)=\\mathcal N(0,1),\\quad p(x_t,t|c)=\\mathcal N(c,1+t),\\quad p(x_t,t)=\\int p(x_t,t|c)p(c)\\mathrm dc=\\mathcal N(0,2+t)$$\n    $$\\nabla\\log p(x_t,t|c)=-\\frac{x_t-c}{t+1},\\quad\\nabla\\log p(x_t,t)=-\\frac{x_t}{t+2}$$\n    $$\\nabla\\log p(x_t,t)-\\nabla\\log p(x_t,t|c)=\\frac{x_t}{(t+1)(t+2)}+\\frac{c}{t+1}$$\n  Although real data $x_0$ is bounded, as is claimed in the proof, the noisy data $x_t$ is diffused with Gaussian and unbounded for $t>0$. So the MSE between conditional and unconditional scores at timestep $t$ cannot be bounded by a constant, which means Thms. 1 and 2 do not hold for any $x$.\n  3. Thms. 3 and 4 cannot provide any information on score functions. The relation between functions could mean nothing to their derivatives. In other words, there could be extremely small perturbation with extremely large frequency, which leads to inconspicuous value change but conspicuous derivative change.\n\n- Besides the theoretical flaws, there are some misleading notations.\n  1. $p(x_t,t)$ denotes the **joint distribution** of both $x_t$ and $t$, as is claimed in L124. Probability of $x_t$ at timestep $t$ is expected to be $p_t(x_t)$. The notation of $p(x_t,t|y)$ has similar issue.\n  2. Please use $p_t(x_t|c)$ for conditional distribution (consistent with Eq. (4)) rather than $\\tilde p$\n  3. The differential operator are in different fonts. In L176 it is $\\mathrm d$, in L186 it is $d$, and in L193 it is a bold $\\mathrm d$.\n  4. As stated in L288, the authors expect a small guidance weight then $t$ is small and large guidance weight when $t$ is large. However, $w(t)=w_0\\exp(-\\lambda t)$ **increases from $0$ to $w_0$ when $t$ goes from infinity to zero**, which conflicts with the motivation. And so is the $w(t)$ in Eq. (13). This makes all experimental results untrustworthy."}, "questions": {"value": "Please carefully correct the theory part according to the theoretical flaws in Weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "SGSk8HDLVm", "forum": "3mj3mCr52M", "replyto": "3mj3mCr52M", "signatures": ["ICLR.cc/2026/Conference/Submission1953/Reviewer_f2Jz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1953/Reviewer_f2Jz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761291177633, "cdate": 1761291177633, "tmdate": 1762915967513, "mdate": 1762915967513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies classifier-free guidance (CFG) in conditional diffusion models and argues that using a fixed guidance scale over time is theoretically suboptimal. The authors analyze the forward SDEs underlying diffusion (VP-SDE and VE-SDE), derive upper bounds on the difference between conditional and unconditional scores, and claim this difference monotonically shrinks over time. They then propose Exponential Classifier-Free Guidance (E-CFG), which replaces the constant CFG scale ω with a time-dependent exponentially decaying weight ω(t) = ω₀ exp(−λ t) (and a normalized variant), motivated by these bounds. Empirically, they report improvements on ImageNet class-conditional generation with DiT / SiT and on MS-COCO text-to-image, mostly in FID and IS."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "E-CFG does not require retraining a classifier or retraining the diffusion model. It just changes how guidance is applied at sampling time, making it lightweight and broadly usable in practice. This addresses a known pain point of classifier guidance approaches that rely on an auxiliary classifier and can be unstable or expensive to train."}, "weaknesses": {"value": "1. The central theoretical claim is: as the forward diffusion process runs, conditional and unconditional distributions become closer, so the discrepancy between their score functions decays over time; therefore, guidance strength should decay with timestep. However, the theoretical section does not derive its schedule. It only argues qualitatively that “guidance should be time-dependent,” which is well-known and actively explored in recent adaptive/interval guidance work. The actual exponential functional form remains heuristic, despite the repeated claim that the method is “theoretically grounded” rather than heuristic.\n\n2. The paper positions prior time-varying guidance approaches (interval guidance, frequency decoupling, adaptive scaling, ratio-aware guidance, etc.) as “heuristic” and “lacking principled justification,” and then claims their method is the first to ground guidance scheduling in diffusion dynamics. However, to my undderstanding, Interval guidance (apply CFG only in a mid-noise band) is already motivated by an analysis that early high-noise steps are unstable and late steps don’t need guidance because conditional gradients collapse, i.e., essentially the same intuition here: conditional vs unconditional predictions differ most in a certain window. The contribution over prior adaptive schedules feels incremental.\n\n3. The empirical evaluation is not rigorous enough to support the bold claims.\n\nThe paper claims “state-of-the-art performance across various conditional generation benchmarks,” “significant performance gains,” and “robustness across samplers.”\n\nConcerns:\n\n    a. Reported gains are often tiny. For example, SiT-XL/2(REPA, Interval) improves FID from 1.42 to 1.41 on ImageNet 256×256 SDE 250-step. That is a change of 0.01 FID, which is well within typical evaluation noise for diffusion metrics; no confidence intervals, variance across seeds, or statistical tests are provided.\n\n    b. The larger “20% improvement” claim in the introduction (1.80 → 1.41 FID) is misleading. First, 1.41 is with a different sampler configuration (“Interval guidance + Ours”), not a plain fixed-ω baseline under identical settings.\n\n    c. The COCO text-to-image results in Table 2 barely move: U-ViT FID 5.37 → 5.28, SD15 CLIP Score 31.8 → 31.9. These are marginal, single-run numbers without variance. Given how noisy CLIP-based eval can be, an 0.1 difference is not obviously meaningful.\n\n    d. Missing cost/latency analysis. They emphasize E-CFG is “training-free” and “no extra overhead,” but do not show runtime overhead, nor do they compare to RAAG’s supposed extra cost on the same hardware / same number of steps.\n\n    e. Hyperparameter tuning fairness is unclear. The proposed method introduces ω₀ and λ. The baseline lines in Table 1/2/3 have specific ω values, while “+Ours” has different ω₀ and λ — but the authors do not state how baseline ω was tuned vs how (ω₀, λ) were tuned. If we allow a 2-parameter schedule and tune it per model, of course we can usually squeeze a slightly better result. Without a controlled tuning budget comparison, the gains could just be from extra knob freedom."}, "questions": {"value": "See in the weeknesses.\n\nTYPOS: double \"the\" at line 124."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0XlHQhUS5D", "forum": "3mj3mCr52M", "replyto": "3mj3mCr52M", "signatures": ["ICLR.cc/2026/Conference/Submission1953/Reviewer_p88S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1953/Reviewer_p88S"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830036900, "cdate": 1761830036900, "tmdate": 1762915967164, "mdate": 1762915967164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a theoretical analysis of Classifier-Free Guidance (CFG) providing upper bounds on the score discrepancy between the conditional and unconditional distributions during the diffusion process. \nFollowing the theoretical analysis, the paper also proposes the exponential CFG where the static guidance weight is replaced by an exponential."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a theoretical grounding in a well-explored topic: how guidance should evolve over the diffusion process. \n\n- There are several experiments on class conditional generation."}, "weaknesses": {"value": "For me the paper has two disconnected contributions/parts, none of which is fully developed: the theoretical upper bounds and the practical proposition of the exponential CFG. \n\n1/ Scope of contribution\n\nAs the paper correctly states, dynamic CFG has been tackled for the past two years by numerous works in the community. The findings that in the beginning of the generation low guidance is required, while later on we apply higher guidance is well-explored and there are several works that have given intuitions and justifications. This significantly limits the scope of the first contribution. \n\n\n2/ Choice of exponential\n\nThe transition from theory to the final practical exponential CFG seems somewhat heuristic: the exponential approximation is not mathematically derived but chosen for smoothness. \n\n\n3/ Comparison to related work \n\n3a/ Other increasing w(t): Wang 2024 TMLR have already proposed replacing w with w(t) and have examined several basic functions, from linear to parametrized ones but not exponential. Given the previous point, the choice of exponential seems even more arbitrary, as several other functions from the ones examined in that paper (e.g. linear) could work as well as the exponential. \n\nFurthermore, there is no theoretical or experimental comparison as to why exponential will be the best choice for dynamic guidance. It would have been useful to have both. For the practical part, comparisons with the other basic and parametrized functions would be useful. \n\n3b/ While I appreciate the experiment with autoguidance in Table 5 in the supplementary (which should perhaps be in the main paper), I would have liked to see how the method compares against the Kynkäänniemi 2024 work where guidance is removed at different intervals. \n\n3c/ Besides these two works that seem the most relevant, there is a large body of works on adaptive guidance that the paper cites but does not compare against. \n\n4/ lamda\n\n4a/ Ablation of lamda\n\n\nThe proposed exponential CFG depends on the value choice of the lamda hyperparameter; yet, there is no detailed analysis on how it is chosen or how robust the method is to various λ values.\n\n4b/ lamda generatlization\n\nIt is unclear how choosing lamda for one model and dataset can transfer to another. It seems that this is a hyperparameter one needs to adjust manually; hence, introducing a grid search. \n\n5/ Additional experiments\n\nIn all experiments, the gains are at best marginal. This is an issue with class-conditional generation. \n\n5a/ It would have been useful if the authors had performed user studies to show the benefit of their work. \n\n5b/ Also, for this type of works, evaluating on the text-to-image generation setting where gains are more visible (both because benchmarks are less saturated and because there are more metrics, FID, GenEval, various aesthetic scores) may be crucial. \n\n5c/ Ablation of guidance\n\nFor the class-conditional setting, it would be useful to have FID vs IS plots against other baselines and perhaps different labda values. \n\n6/ It would be interesting to see how this work translates to different solvers."}, "questions": {"value": "Q1 (W2) It would be useful if the authors could back up their choice of exponential with a theoretical aspect. \n\nQ2 (W3) Can the authors compare their method to other guidance works or do they have any insight for the outcome of such comparison? \n\nQ3 (W4a) Can the authors provide an ablation study on the choice of lamda?\n\nQ4 (W5a) Have the authors performed any user study?\n\nQ5 (W5b) It would be interesting to see other experiments on other tasks so as to examine the generalization of the proposed method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dSMJEM8qCj", "forum": "3mj3mCr52M", "replyto": "3mj3mCr52M", "signatures": ["ICLR.cc/2026/Conference/Submission1953/Reviewer_x6Y3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1953/Reviewer_x6Y3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952076138, "cdate": 1761952076138, "tmdate": 1762915966581, "mdate": 1762915966581, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}