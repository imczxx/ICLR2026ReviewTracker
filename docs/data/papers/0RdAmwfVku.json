{"id": "0RdAmwfVku", "number": 12740, "cdate": 1758209915625, "mdate": 1763711139169, "content": {"title": "VoG: Enhancing LLM Reasoning through Stepwise Verification on Knowledge Graphs", "abstract": "Large Language Models (LLMs) excel at various reasoning tasks but still encounter challenges such as hallucination and factual inconsistency in knowledge-intensive tasks, primarily due to a lack of external knowledge and factual verification. These challenges could be mitigated by leveraging knowledge graphs (KGs) to support more reliable LLM reasoning. However, existing KG-augmented LLM frameworks still rely on static integration mechanisms that cannot adjust reasoning in response to evolving context and retrieved evidence, resulting in error propagation and incomplete reasoning. To alleviate these issues, we propose  **V**erify-**o**n-**G**raph (**VoG**), a scalable and model-agnostic framework to enhance LLM reasoning via iterative retrieval, stepwise verification, and adaptive revision. Besides performing KG retrieval guided by an initially generated reasoning plan, VoG iteratively verifies and revises the reasoning plan, correcting intermediate errors in consideration of the varying contextual conditions. During plan revision, VoG leverages a context-aware multi-armed bandit strategy, guided by reward signals that capture uncertainty and semantic consistency, to enhance the alignment between the reasoning plan and retrieved evidence in a more adaptive and reliable way. Experimental results across three benchmark datasets show that VoG consistently improves both reasoning accuracy and efficiency. Our code is available at https://anonymous.4open.science/r/VoG-132C/.", "tldr": "", "keywords": ["LLM reasoning", "Knowledge Graphs", "KG-enhanced LLM"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bed3d8e57023e8e7d1a48b6ca59dc83e4816bea7.pdf", "supplementary_material": "/attachment/fe4bed6f07d207a7b2555239dceefee6c8de9417.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes Verify-on-Graph (VoG), a framework that enhances Large Language Models' reasoning by integrating knowledge graphs for reliable inference. VoG features iterative retrieval, verification, and adaptive planning refinement to boost accuracy and efficiency. Experiments on three benchmark datasets demonstrate its effectiveness in improving reasoning performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. VoG introduces a novel framework that enables stepwise verification and planning refinement on KGs to mitigate error propagation during multi-hop reasoning.\n2. VoG proposes a KG-aware multi-armed bandit (MAB) mechanism for adaptive context selection, which is a valuable contribution for dynamically determining context information for refining reasoning plans.\n3. Experiment on three benchmark datasets shows that VoG significantly outperforms existing methods, demonstrating its effectiveness in enhancing the reasoning capabilities of LLMs."}, "weaknesses": {"value": "1. The architecture of VoG seems complex with multiple components. While each component is motivated and performance improvements are shown, the overall complexity may hinder practical adoption. The authors should provide more analysis on the trade-offs between complexity and performance gains, and possibly explore simplifications.\n2. UCB hyperparameter sensitivity is not deeply analyzed — how robust is the method to different scaling of entropy or exploration bonuses?\n3. No evaluation beyond Freebase / KGQA — unclear whether VoG generalizes to non-Freebase or domain-specialized KGs (e.g., ConceptNet , biomedical UMLS).\n4. The proposed method relies on retrieving evidence from the KG, but it is unclear how VoG handles cases where valid evidence/fact are missing from the KG."}, "questions": {"value": "1. How does VoG handle valid but missing KG facts during reasoning?\n2. How sensitive is the performance to the UCB hyperparameters?\n3. Could VoG generalize beyond Freebase, e.g., ConceptNet or domain-specific KGs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BHstSzcD7H", "forum": "0RdAmwfVku", "replyto": "0RdAmwfVku", "signatures": ["ICLR.cc/2026/Conference/Submission12740/Reviewer_YG4Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12740/Reviewer_YG4Q"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761543114547, "cdate": 1761543114547, "tmdate": 1762923560562, "mdate": 1762923560562, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes VoG (Verification-over-Generation), a reasoning framework that enhances large language models (LLMs) with structured, knowledge-grounded verification and revision. Unlike previous reasoning or retrieval-augmented methods that rely solely on planning or evidence retrieval, VoG organizes reasoning into a Plan–Retrieve–Verify–Revise loop."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The paper introduces a unified Plan–Retrieve–Verify–Revise reasoning framework, emphasizing step-wise knowledge-grounded verification. This design effectively connects planning with factual correction and hallucination suppression, offering a more systematic approach than prior single-stage (planning-only or retrieval-only) methods. Compared to ToG/PoG agents, VoG achieves lower average token consumption and fewer reasoning turns while maintaining higher accuracy, supporting the paper’s claim of being lightweight and efficient."}, "weaknesses": {"value": "The author’s efficiency analysis section is very convincing; however, I am still curious about the end-to-end latency, as its framework introduces more steps compared to ToG and PoG."}, "questions": {"value": "See weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qq6sJxT13d", "forum": "0RdAmwfVku", "replyto": "0RdAmwfVku", "signatures": ["ICLR.cc/2026/Conference/Submission12740/Reviewer_rU7C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12740/Reviewer_rU7C"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761883205598, "cdate": 1761883205598, "tmdate": 1762923559820, "mdate": 1762923559820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel Verify-on-Graph (VoG) framework, which supports dynamic and context-aware LLM reasoning over KG through iterative retrieval, verification, and adaptive refinement. To be specific, the proposed method firstly employs a plan agent to generate reasoning chains, serving as guidance for multi-hop retrieval process. Then, stepwise verification and adaptive refinement is adopted to detect reasoning inconsistencies and make sure the correctness of subsequent reasoning steps. Finally, a confidence-based reward is designed to capture uncertain information for revision. Extensive experimental results demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThis paper is well-organized and easy to follow.\n2.\tThis paper presents a VoG framework consisting of three specialized LLM agents for retrieval, verification, and revision, which address the challenges of inflexible reasoning and limited utilization of information.\n3.\tThis paper provides the source code to ensure the reproducibility of the proposed method."}, "weaknesses": {"value": "1.\tThe figures could be further refined to enhance readability. In particular, the font size in Figures 1 and 3 is quite small, and Figure 7 appears to have low resolution.\n2.\tThe paper may lack some baseline methods for comparison, such as GNN-RAG [1], SubgraphRAG [2].\n3.\tThe core idea may not be highly novel, since the retrieval–plan–verify pipeline has been adopted in prior studies.\n\n[1] Mavromatis, Costas, and George Karypis. \"Gnn-rag: Graph neural retrieval for large language model reasoning.\" arXiv preprint arXiv:2405.20139 (2024).\n[2] Li, Mufei, Siqi Miao, and Pan Li. \"Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation.\" The Thirteenth International Conference on Learning Representations."}, "questions": {"value": "Please refer to Section Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "yXxTLUSmrG", "forum": "0RdAmwfVku", "replyto": "0RdAmwfVku", "signatures": ["ICLR.cc/2026/Conference/Submission12740/Reviewer_4vgR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12740/Reviewer_4vgR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900865829, "cdate": 1761900865829, "tmdate": 1762923559436, "mdate": 1762923559436, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Verify-on-Graph (VoG), a model-agnostic framework that enhances reasoning reliability of LLMs on knowledge-intensive tasks by couping iterative retrieval, stepwise verification and revision, based on knowledge triplets retrieved from knowledge graphs. Unlike existing KG-augmented reasoning systems that follow fixed reasoning plans, VoG introduces (1) Stepwise KG verification that detects factual inconsistencies at each reasoning step. (2) Plan revision via multi-armed bandit context selection that adaptively decides which contextual scope to use for revising reasoning. Experiments on KG reasoning benchmarks show consistent improvements across backbone models of different sizes, compared to the strong agentic baselines with reduced token cost."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel verification framework for reasoning. The proposed step verification has the potential of mitigating error/hallucination propagation and improve faithful reasoning.\n\n2. Adaptive context selection.  The idea of using UCB to balance the information window in the decision making process is innovative, and has the potential to be extended to other long-reasoning tasks as well. \n\n3. Strong empirical results. Experiments show consistent gains across three benchmarks and multiple LLM sizes, which validate the approach's generality."}, "weaknesses": {"value": "Some key components, such as reward design details for UCB are located in the Appendix. They should stand out in the body of the methodology. See Questions for other technical weakness."}, "questions": {"value": "1. What is the motivation to revise the reasoning plan given the retrieved knowledge triplets? Why does the factual knowledge retrieved play a role in evaluating(verify) the reasoning sub-step? A more natural way could be to populate the retrieved knowledge when it is not sufficient to solve the reasoning sub-step. \n\n2. There is no guarantee that the prompted based verification agent would return a faithful and correct response. In Table 2, the authors conducted ablation studies to show the effect of verify/revision. However, it is not clear whether the improvement is due to the verifier, or it's a effect of parallel thinking introduced by the revision itself. A more rigorous way is to test on a dataset that has ground truth reasoning([1] for example) steps and show these models can indeed distinguish the correct reasonings from the incorrect. \n\n3. What is the benefit of having a plan first and conduct step-with verify and revise, instead of iteratively reasoning and retrieve as in [2]?\n\n4.  VoG retrieves relation and entity based on some semantic similarity score, which is similar to the retrieval approach introduced in [3], it is beneficial to include a discussion or comparison on that. \n\n5. Why the semantic similarity between the \"predicted observation\" and the input question can serve as a quality measure of reasoning, as introduced in Appendix B.2. Not every reasoning step needs to share similar semantic meaning with the question.\n\n6. All experiments in Table 1 are conducted on Freebase knowledge graph, it remains unclear whether VoG generalizes to other domains, like scientific or biomedical KGs (such as UMLS).\n\n[1] MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning\n\n[2] Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning\n\n[3] GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "knZvxqtww8", "forum": "0RdAmwfVku", "replyto": "0RdAmwfVku", "signatures": ["ICLR.cc/2026/Conference/Submission12740/Reviewer_cbkJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12740/Reviewer_cbkJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946321346, "cdate": 1761946321346, "tmdate": 1762923558924, "mdate": 1762923558924, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We thank all the reviewers for their valuable feedback, which has helped us clarify key points and improve the overall presentation of the paper.\n\n- We have made several revisions to our manuscript and highlighted changes corresponding to each reviewer using color annotations for clarity: changes addressing reviewer cbkJ are marked in blue, reviewer 4vgR in orange, reviewer rU7C in green, and reviewer YG4Q in purple. Edits that respond to concerns shared by reviewer cbkJ and YG4Q are marked in dark blue. Several figures have also been refined following the suggestions of reviewer 4vgR.\n- In addition, we expanded the manuscript by incorporating new experiments and enhancing multiple analyses, including (i) generalization to KGs beyond Freebase (cbkJ, YG4Q); (ii) a trade-off analysis between complexity and performance (YG4Q); (iii) improved efficiency study, ablation analysis, and robustness study (rU7C, cbkJ, YG4Q); and (iv) additional comparisons and discussions with further baselines (cbkJ, 4vgR).\n\nBelow, we respond to each question in its respective review."}}, "id": "H5VaGPSCw9", "forum": "0RdAmwfVku", "replyto": "0RdAmwfVku", "signatures": ["ICLR.cc/2026/Conference/Submission12740/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12740/Authors"], "number": 10, "invitations": ["ICLR.cc/2026/Conference/Submission12740/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763720342074, "cdate": 1763720342074, "tmdate": 1763720342074, "mdate": 1763720342074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}