{"id": "FVQzqSIJcC", "number": 9630, "cdate": 1758131228211, "mdate": 1759897707897, "content": {"title": "A simple mean field model of feature learning", "abstract": "Feature learning (FL), where neural networks adapt their internal representations during training, remains poorly understood. Using methods from statistical physics, we derive a tractable, self-consistent mean-field (MF) theory for the Bayesian posterior of two-layer non-linear networks trained with stochastic gradient Langevin dynamics (SGLD). At infinite width, this theory reduces to kernel ridge regression, but at finite width it predicts a symmetry breaking phase transition where networks abruptly align with target functions. While the basic MF theory provides theoretical insight into the emergence of FL in the finite-width regime,  semi-quantitatively predicting the onset of FL with noise or sample size, it substantially underestimates the improvements in generalisation after the transition. We trace this discrepancy to  a key  mechanism absent from the plain MF description: \\textit{self-reinforcing input feature selection}. Incorporating this mechanism into the MF theory allows us to quantitatively match the learning curves of SGLD-trained networks and provides mechanistic insight into FL.", "tldr": "We give a simple mean-field theory for SGLD-trained two-layer networks that predicts a symmetry-breaking transition and identifies input-feature selection as the missing mechanism to match learning curves of SGLD trained networks.", "keywords": ["Feature Learning", "Deep Learning Theory", "Mean-Field Theory", "Generalization", "Phase Transitions", "Stochastic Gradient Langevin Dynamics", "Statistical Physics", "Representation Learning", "Finite width neural networks"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/deec47cdac98fc25077a4fb93f73039f3e72fb51.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper develops a tractable mean-field (MF) theory to understand feature learning in two-layer neural networks trained with SGLD. The authors identify a two-stage feature learning process: (1) a phase transition where networks align with target functions, and (2) self-reinforcing input feature selection (IFS). This provides an extension over the recently developed MF theory. Experiments on k-sparse parity and single-index models demonstrate quantitative agreement of the theory with SGLD-trained networks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tAnalytical Tractability and Completeness: The paper provides a self-consistent Mean-Field framework for the Bayesian posterior of a two-layer network. This level of analytical derivation, together with the appropriate approximation, leads to closed-form solutions, which is a valuable result.\n2.\tExplicit Verification: The theoretical predictions are explicitly validated against SGLD simulations on the teacher-student setup, demonstrating a strong match between the Mean-Field approximation and the numerical results, particularly regarding the phase transition phenomenon."}, "weaknesses": {"value": "1.\tLimited Novelty: The main results, including the phase transition and the sparsification of neurons, are not genuinely novel. Furthermore, the phenomena of feature learning and the splitting of network behavior to different activation function were thoroughly explored by Van-Meegen-Sompolinsky Nat. Comm 2025 in earlier, comprehensive studies, which the current work fails to cite and compare there results to. The current paper does not provide key new insights beyond these existing frameworks, especially regarding the challenging question of extending these ideas to deeper neural networks.\n\n2.\tNarrow Scope and Lack of Generalization: The analysis is restricted to a single, synthetic teacher-student task (Hermite polynomials) and demonstrates results limited to this toy setting. The paper fails to provide any insights or validation on real-world data, which limits the scope and relevance of the conclusions compared to related works.\n\n3.\tThe Introduction is insufficient, failing to clearly articulate the existing literature and the specific gap the paper aims to fill, especially given the extensive prior work on mean-field feature learning."}, "questions": {"value": "1.\tContextualization and Novelty: please properly cite provide work and provide detail comparison highlighting the novelly of the current work, and how your results go beyond the established phase diagrams and insights provided in the paper by Meegen-Sompolinsky.\n\n2.\tIntroduction and MF Theory Definition: The Introduction needs complete rewriting to clearly state the problem and the specific theoretical gap. \n\n3. Line 107: Please remove the statement in Line 107 regarding the comparison between SGLD noise and SGD \"batch noise,\" as this is misleading and conceptually inaccurate.\n\n4.\tTheorem Clarity (Theorem 4.1, Eq. (16)):\n        (a)  Equation (16) uses both asymptotic notation ($\\asymp$) and asymptotic bounds ($\\Theta$). Please use only one type of notation for consistency.\n\n        (b)  Please explicitly state in the main text whether the theorem result is specifically derived for the parity model or holds more generally.\n\n       (c)  Please explicitly specify all assumptions required for the theorem to hold, including the assumptions on $\\chi_S$ and any extra assumptions currently hidden in the Appendix.\n\n5.\tGeneralization of $\\phi$: The generalization results focus heavily on the overlap $\\phi$ with the teacher function. All results both theoretical and numerical are stated for RELU. Can the authors provide more explicit results or discussion on other activation functions, and how do the phase transition and generalization error change? Is the same prior valid for all activation functions? How does it compare with existing MF theories. \n\n6.\tCan you provide examples where the sparse priors would be inappropriate?\n7.    Extension to depth: Can the ARD-MF idea apply layer-wise in deeper networks? Do you have any preliminary evidence?\n\nVan Meegen, A., & Sompolinsky, H. (2025). Coding schemes in neural networks learning classification tasks. Nature Communications, 16(1), 3354."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6fajf7ppb7", "forum": "FVQzqSIJcC", "replyto": "FVQzqSIJcC", "signatures": ["ICLR.cc/2026/Conference/Submission9630/Reviewer_mzGy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9630/Reviewer_mzGy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761044230304, "cdate": 1761044230304, "tmdate": 1762921165374, "mdate": 1762921165374, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a theoretical analysis of FL in two-layer non-linear networks trained with SGLD. The authors argue that standard MF approaches to this kind of problem, while correctly predicting the onset of FL as a phase transition, fail to capture the significant generalization improvements that follow. They attribute this failure to a FL mechanism they term Input Feature Selection (IFS). Relying on simple intuitive reasoning, the authors argue that SGLD provides a self-reinforcing dynamic where the network amplifies weights corresponding to relevant input dimensions, leading to neuronal sparsification. The authors show that such a process cannot be described by standard MF approach. To remedy this, they propose a minimal extension, MF-ARD (Automatic Relevance Determination), which incorporates a learnable, coordinate-wise variance into the weight prior to the MF derivation. This model is shown to quantitatively reproduce the learning curves of SGLD-trained ReLU networks on sparse-parity tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Clarity**: The paper is exceptionally well-written and structured. The theoretical difficulty hierarchy of SGLD $\\rightarrow$ MF $\\rightarrow$ NNGP provides a clear and effective pedagogical framework for situating the paper's contributions and understanding the different levels of theoretical approximation. The core argument is easy to follow, and the visualizations are very helpful.\n\n**Quality**: The empirical validation for the specific setting under consideration is of high quality. The quantitative agreement between the MF-ARD theory and SGLD experiments, as shown in Figures 1 and 5, is impressive and demonstrates that the proposed model accurately captures the learning dynamics in this regime. \n\n**Originality & Significance**: The use of the IFS mechanism as a simple extension to the common MF approaches discussed in the paper is a sound and valuable scientific contribution. The authors have successfully predicted an emergent mechanism of FL, which has a simple intuitive explanation."}, "weaknesses": {"value": "Despite its strengths, the paper suffers from several significant weaknesses related to its framing, the generality of its claims, and the novelty of its contribution. My primary concerns are detailed below. Other than these critical points, I think that this is a good paper, and I would be happy to raise my rating if the concerns here are appropriately addressed in the revised text. \n\n**Critical reference omission**: The paper's analysis is critically hampered by its failure to engage with the concurrent work of Van Meegen & Sompolinsky (2024) (VM&S), which provides a general framework for understanding learned representations in the feature-learning regime. Crucially, VM&S. demonstrate that the weight distribution is determined by the neuronal nonlinearity. Specifically, they show that ReLU networks produce sparse distributions as in this work, while other nonlinearities like sigmoidal, produce qualitatively different distributions. \n\n**Overstated novelties**: \n(a) It seems that the omitted reference may have led the authors to misinterpret their central finding. The paper identifies sparsification (driven by IFS) as the key mechanism that standard MF theory fails to capture, whereas following VM&S, this seems to be only an outcome of the ReLU activation function used in this work. Considering the previous point, the scope of this paper may not be quite as wide as implied by the authors. \n(b) A central claim of the authors is that they developed an interpretable MF theory, where other works involve “... complex theoretical machinery [that] often obscures the core mechanisms driving FL”.  This is not an accurate representation of existing works, where the “machinery” is solving an equation in one (Li & Sompolinsky, (2021); Pacelli et al. (2023; Ringel et al. (2025)) or two (Rubin et al. (2024)) variables. Moreover, existing frameworks produce simple, intuitive, and interpretable descriptions of FL, and make accurate predictions in various regimes. For instance, the works of Li & Sompolinsky (2021) and Pacelli et al. (2023) offer a simple rescaling explanation, Fischer et al. (2024) find interpretable structures emerging in kernels, and Rubin et al. (2024) show that weights learn to prefer relevant directions. The authors even claim that \"Our key contribution is to show that incorporating this IFS mechanism requires only a minimal,\nprincipled modification to the MF theory\". By this reasoning, the interpretability of their framework cannot be a significant improvement over MF approaches."}, "questions": {"value": "1. As far as I can tell, the MF theory provided here is identical to the one appearing in Seroussi et al. (2023), Rubin et al. (2025), and Ringel et al. (2025). However, the authors claim that one of the main contributions of this work is \"Interpretable MF theory\", which seems unjustified. In this context, I have the following questions/suggestions, and I would be happy to raise my score if they were to be answered as well:\n(a) Could the authors explicitly relate their derived mean-field equations to the MF formulations in other recent static theories (e.g., Seroussi et al., 2023; Fischer et al., 2024; Rubin et al., 2024)? Or at least some of them?\n(b) If, as I suspect, these result in the same distribution (possibly up to negligible factors of $1/N^2$), then positioning \"interpretable FL theory\" as a primary contribution is an overstatement and should be clarified in the text. \n(c) Otherwise, the explicit difference between existing approaches should be highlighted.\n\n2. The MF-ARD posterior for a single neuron (Eq. 14) has a very similar form to the plain MF posterior (Eq. 6), with the main difference being the introduction of $d$ new order parameters, the precisions $\\rho_j$. Could the authors expand on in what sense does this modification constitute a more interpretable theory of feature learning as posited in the introduction?\n\n3. Could the authors clarify the scaling of the noise parameter $\\kappa$ with the network width $N$? In some mean-field treatments, $\\kappa$ also acquires a width-dependent scaling, such as $\\kappa \\sim \\mathcal{O}(N^{\\gamma-1})$. Is such a scaling assumed here, and if not, how does its absence affect the results?\n\n4. What are the limitations\\assumptions on the MF approximation? This should be detailed explicitly in the main text.\n\n5. The paper claims that the \"homogeneity assumption\" of the MF model prevents it from capturing the effect of specializing neurons. However, MF theory is seemingly capable of capturing distributions where only a small number of neurons specialize through multimodal Gaussian distributions. Essentially, taking a distribution where there is a $1/N$ probability of being in a certain nonzero mode is equivalent to saying that one neuron is drawn from a distribution that is some nonzero Gaussian, and the remaining neurons are drawn from the other modes of the distribution. How does this picture differ from the picture provided here? Contrasting this specialization with multi-modal distributions in the paper itself would be very helpful. \n\n6. The paper's “related works” section implies that many static MF theories are restricted to the proportional limit where $P \\propto N$, where $P,N$ are sample size and network width respectively. This is not a general requirement, as shown in other works (e.g., Ringel et al. (2025) - not cited in this paper). There, other scalings of $P$ were considered, specifically taking $N\\propto d$ (where $d$ is the input dimension), but $P$ scales as $d^{3/4}$. Is taking $N\\propto d\\mapsto\\infty$ what the authors were refering to in the statement: “either in double asymptotic limits of data and width”? If so, this should be clarified in the main text."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3A6xHRpdyv", "forum": "FVQzqSIJcC", "replyto": "FVQzqSIJcC", "signatures": ["ICLR.cc/2026/Conference/Submission9630/Reviewer_dnTH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9630/Reviewer_dnTH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761780559080, "cdate": 1761780559080, "tmdate": 1762921164664, "mdate": 1762921164664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a *Mean-Field Automatic Relevance Determination* (MF-ARD) framework for two-layer Bayesian neural networks trained with SGLD. The goal is to model the “specialization transition” in fully connected networks at the interpolation regime, where just a finite subset of neurons align with the target function. Since standard mean-field theory (exact at infinite width $N\\to \\infty$ when sample $P=\\mathcal{O}(1)$) yields a fully factorized posterior, the authors introduce a coordinate-dependent Gaussian prior with Gamma-distributed precisions (inverse variances controlling per-weight decay strength), enabling anisotropic shrinkage across weight coordinates. They derive fixed-point equations for these precisions and show, through comparisons with SGLD simulations, that the resulting model resemble the qualitative emergence of neuron specialization and sparse, task-aligned representations observed in finite-width networks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper - like many recent works at the intersection of statistical physics and machine learning - addresses a relevant theoretical question: how mean-field theory can be extended beyond the infinite-width, small-data limit to capture internal feature specialization and neuron-neuron correlations in finite-width networks. The proposed MF-ARD formulation is conceptually clear and analytically tractable. The manuscript is clearly written, and the authors provide numerical comparisons between their theoretical predictions and SGLD simulations, showing qualitative agreement."}, "weaknesses": {"value": "**Theoretical inconsistency between MF-ARD and SGLD dynamics.**\n\nThis paper is meant to describe the stationary distribution of SGLD dynamics for two-layer neural networks through a mean-field approximation and **uniform** weight decay, but the proposed MF-ARD formulation fundamentally changes the underlying Bayesian model. By introducing coordinate-dependent Gaussian priors with Gamma-distributed precisions $\\rho_j$ the authors define a *different* posterior from the isotropic one actually sampled by SGLD. As a consequence, I don’t see how their “MF-ARD theory’’ can be interpreted as a faithful large $P$ limit of the true SGLD dynamics: they are effectively comparing two different models.\n\n**Imposed rather than spontaneous specialization transition in the theory.**\n\nSince the MF-ARD model introduces anisotropy explicitly through the prior rather than deriving it as a spontaneous effect of finite-width fluctuations (i.e., $\\mathcal{O}(P/N)$ corrections to mean-field theory), the “specialization transition’’ is imposed by construction and has nothing to do with the original posterior of Eq.(4) they intend to study. \n\n**Unrealistic neuron-wise sparsification.**\n\nThe transition described by the theory corresponds to a *hard sparsification*, where only a finite number of neurons acquire non-zero overlap $m_s>0$ with the teacher while the rest remain near initialization. This is fundamentally different to what happens in finite width neural networks during feature learning. In realistic dynamics, all neurons move substantially, but their updates become strongly correlated, so that the learned representation effectively spans a low-dimensional subspace.\n\n**Restrictive assumptions on data and teacher.**\n\nThe theoretical analysis relies on a sparse teacher model, where the number of nonzero coefficients $m_A$ directly determines the number of “relevant” features or basis functions contributing to the target. In practice, this means the teacher vector is assumed to have support only on a small subset of input dimensions ($k$-sparse vector). While this setup is analytically convenient, it is not representative of realistic data or high-dimensional learning tasks. In real datasets, the relevant subspace is *not known a priori* and typically spans a continuum of directions with a decaying or heavy-tailed spectrum of features.  Given that the theoretical setup strongly relies on having $k$ finite, I don't see how it can be extended to practical scenarios. \n\n**Theory describes a numerically unstable training setup.**\n\nThe proposed theory corresponds to an impractical actual training of a neural network with SGLD. Indeed, running SGLD or SGD with neuron-dependent (or coordinate-dependent) weight decay would require maintaining and updating a distinct regularization coefficient for each neuron or parameter, effectively introducing $\\mathcal{O}(N) additional hyperparameters. This would break permutation symmetry across neurons, complicates optimization dynamics, and would make training highly unstable. \n\nIn summary, the paper starts from a standard SGLD framework but then shifts to analyzing a modified Bayesian model (MF-ARD) whose dynamics and posterior differ from those of the system it aims to describe. The resulting formulation is not a faithful large $P$ limit of a mean-field theory, nor does it capture the genuine feature-learning phenomenology observed in finite-width networks. For these reasons, I believe the paper requires major conceptual revision before it could be considered for publication. Its current scope and assumptions are limited to shallow networks and restricted to sparse targets, and the theoretical insights it provides are not clearly connected to modern learning dynamics in realistic settings."}, "questions": {"value": "1.  Why did the authors choose to introduce anisotropy explicitly through the ARD prior rather than studying finite-width ($1/N$ or $P/N$) corrections to the isotropic mean-field theory that might be still tractable?\nThese corrections are known to produce neuron correlations and spontaneous anisotropy without changing the generative model.\n\n2. Can the authors clarify how they are taking the asymptotic limit (of $P$ data and $N$ width)? \nOf course these limits do not commute in practice, and to get a mean-field theory one usually takes $N\\to \\infty$ at fixed $P$, but Eqs. (6) and (7) have a population average. \n\n3. Fig.4 (b) shows that the theoretical model at small $P$ over-estimates the anisotropy of hidden neurons. Could the authors comment on that?\n\n4. In Fig. 1a, the test MSE stays flat even with increased samples $P$ before dropping sharply. Why does learning only start at such large $P$? Could the authors comment on what would happen at larger width?  \n\nMinor annotations:\n- Lines 44-45: kernel renormalization theories are in the asymptotic limits of data and width so the sentence and citation is imprecise.\n- Eq. (4) is missing a $+$ sign (typo).\n- Line 160: fully factorized posterior for mean field theory is not an approximation, it’s exact in the limit $N\\to \\infty$.\n- Line 249: $m_s$ mentioned before it has been introduced"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RsjikrXkzr", "forum": "FVQzqSIJcC", "replyto": "FVQzqSIJcC", "signatures": ["ICLR.cc/2026/Conference/Submission9630/Reviewer_s426"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9630/Reviewer_s426"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761865375239, "cdate": 1761865375239, "tmdate": 1762921164390, "mdate": 1762921164390, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Summary\n\nThe manuscripts proposes a novel form of a heuristically\ndefined mean-field theory for feature learning in single\nhidden layer networks in a setting of Bayesian inference.\nThe aim is to describe feature learning beyond previous works\nof kernel adaptation and kernel renormalization.\n\nThe main novelty is the proposal of a heterogeneous prior distribution\non the first layer's weights. Deriving mean-field equations for a set of\norder parameters, including the variances of the weights' priors, allows\nthe interpetation of the latter as a measure of relevance of input\nfeatures and describes settings where individual neurons specialize\non distinct input features.\nNumerically trained networks with Langevin gradient descent with\nweight decay show good agreement with the theory.\n\nSoundness\nMost of the manuscript is sound, in particular the first part of the\nmanuscript, until including section 3, which is equivalent to earlier\nwork on feature learning in a setting of Bayesian inference. The authors\nnicely explain the mean-field approach also in intuitive terms, yet provide\nall detail in the appendix.\n\nThe novel part starting in section 4. Here the main puzzling point to me\nis that the heterogeneous variances and the hyper-prior for the variances\nof individual neurons' weights are introduced ad-hoc. This is in contrast to\nthe first part, where the startionary distribution (Eq. (2)) is a direct\nconsequence of the applied Langevin training dynamics.\n\nPresentation\nThe presentation of the work is very good and provides excellent explanations\nthat can also be followed intuitively, even for readers who do not follow\nall mathematical details.\n\nContribution\nThe main contribution the work is to provide a simple ad-hoc (not strictly\nderived from first principles) mean-field theory that explains specialization\nof individual neurons to explain feature learning.\nA point that needs to be clarified in the rebuttal is the novelty.\n\nIn particular in the light of previous work by van Meegen & Sompolinsky 2024\n\"Coding schemes in neural networks learning classification tasks\" Nat Comm.\nThe latter work considers the same problem as the authors and derives a mean-field theory to explain the specialization of neurons on particular features.\nThe authors should, for example, look at Figure 8 of said paper. The theory\nby van Meegen and Sompolinsky performs a mean-field approach where the readout\nweights (variable \"a\" in the current manuscript) concentrate."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "I very much like the form of presentation chosen by the authors, summarizing\nmain equations in boxes and providing explanations and intuition for the appearing order parameters. Also the authors throughout provide careful comparisons between theory and numerics."}, "weaknesses": {"value": "The missing mention of van Meegen & Sompolinksy 2024 as a tightly related\nwork casts some doubts about the novelty and contribution. In case this\npoint can be clarified in the rebuttal I am happy to raise my score.\n(see section contribution in summary box)."}, "questions": {"value": "Given my concern on the novelty (see \"Contribution\"), my first concrete\nquestion to the authors is to check whether the previous theory by van\nMeegen & Sompolinsky is able to explain their numerical findings or\nwhether there is still a gap between feature learning theory and\nnumerics that their theory is able to close.\n\nMy second question is more conceptual. I understand the heuristic motivation\nof the approach. What I fail to see is why the proposed log likelihood (Eq. 14)\nis the log of the stationary distribution of the Langevin training in (Eq. 1).\nTo me this seems like the attempt to capture heuristically the observations\nfrom numerics rather than deriving this result from first principles."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vbRVqHJCeM", "forum": "FVQzqSIJcC", "replyto": "FVQzqSIJcC", "signatures": ["ICLR.cc/2026/Conference/Submission9630/Reviewer_1F6B"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9630/Reviewer_1F6B"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9630/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761903774425, "cdate": 1761903774425, "tmdate": 1762921164069, "mdate": 1762921164069, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}