{"id": "oyAmCsCe5b", "number": 7270, "cdate": 1758013742694, "mdate": 1759897862766, "content": {"title": "Gestalt Reasoning Machines: Structured Perception for Neuro-Symbolic Inference", "abstract": "This paper introduces Gestalt Reasoning Machines (GRMs), a novel neuro-symbolic framework that integrates Gestalt principles to enhance reasoning models with perception capabilities similar to human cognition. \nTraditional models, which rely on large datasets and complex computations, often overlook the crucial human cognitive function of grouping, resulting in inefficiencies when dealing with abstract concepts. GRMs address this challenge by incorporating a grouping mechanism grounded in Gestalt principles, enabling the system to recognize and reason over complex visual patterns that are otherwise difficult to capture through object-level features alone. \nThis grouping capability allows GRMs to identify higher-order structures and relational configurations that are essential for human-like reasoning. We demonstrate that GRMs outperform purely neural baselines by leveraging logic-based reasoning infused with perceptual grouping cues, offering a more interpretable and cognitively aligned approach. \nOur contributions include the design of GRMs and the empirical validation of their effectiveness in visual reasoning tasks that demand structured perception.", "tldr": "", "keywords": ["Gestalt Vision", "Logic", "Neuro-Symbolic AI"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c4b7c18ae417d2506126d81ffa75c0a09c3b8afd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper advances automated visual abstract reasoning, particularly targeting Gestalt principles such as proximity, similarity, closure, symmetry, and continuity. Due to the (to-date) failure of monolithic neural approaches, this paper takes a neuro-symbolic approach where perceptual attributes are recognized with a neural network and underlying rules are recognized and applied in the symbolic domain (first-order logic). Instead of only considering object-level descriptions, this paper advances the neuro-symbolic approach by also considering group-level descriptions, which are recognized in the neural part and further processed by symbolic reasoning. Empirically, the paper shows that adding the group-level descriptions improves the reasoning capabilities on a synthetic Gestalt dataset (ELVIS), outperforming both neuro-symbolic approaches (w/o group-level) and neural approaches (small- and large-scale foundation models)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Finding the right granularity of abstraction is key in neuro-symbolic approaches. This paper demonstrates that multi-level abstractions (object- and group-level) can enhance reasoning performance. In that regard, this well written paper advances the field of neuro-symbolic learning and reasoning."}, "weaknesses": {"value": "1.\tSupervision of perception backbone. It is not clear how the perception backbone is pretrained. Are attributes values and/or groups provided as training labels? If yes, this limitation should be clearly stated and addressed with an end-to-end learning approach. \n2.\tWeak grouping performance. As shown in Table 4, the grouping accuracy is very low. Given that the main contribution of this paper is the grouping, it should propose and validate enhancements. First, one can question if a pure neural approach (MLP) without any inductive bias is suitable for this quite involved task. Moreover, the group-level perception (Section 3.1) accumulates all embeddings from the global context into one embedding. This averaging can certainly face some capacity limit. Having a more scalable approach that allows for concatenation (e.g., a Transformer) may improve the approach. Finally, prompting foundational models (e.g., GPT-5) to perform the grouping could be considered, too. \n3.\tThe timing measurements are missing the neuro-symbolic baselines without group-level information (NEUMANN). Moreover, the hardware should be specified for the different methods. \n4.\tFinally, the evaluation is limited to only one synthetic dataset, as stated in the conclusion. While there is a pointer to another natural dataset (Visual Genome), the practical application of the proposed system is not yet justified. It would be helpful to put the work into a practical context. In which real-world applications is grouping needed?"}, "questions": {"value": "I would appreciate if the rebuttal could address the weaknesses. Besides, it would be good to specify the architectural details (neural network architecture) of GRM."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GqcTH2ARDW", "forum": "oyAmCsCe5b", "replyto": "oyAmCsCe5b", "signatures": ["ICLR.cc/2026/Conference/Submission7270/Reviewer_QuEQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7270/Reviewer_QuEQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761312061033, "cdate": 1761312061033, "tmdate": 1762919399118, "mdate": 1762919399118, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces GRMs (Gestalt Reasoning Machines), a neuro-symbolic framework inspired by human grouping nature.                    GRMs first use pretrained perception backbones to identify group structures, then perform rule learning based on logic search.                    This rule base can emerge at test-time and be applied to produce confidence-based inference on new images.                    Experiments on ELVIS, a synthetic dataset incorporating Gestalt principles, demonstrate the advantage of GRMs over few-shot learning neural networks or object-based neuron-symbolic methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Introducing object grouping into the visual reasoning model is novel and intuitively reasonable. This work claims as the first neuro-symbolic framework that integrates perceptual grouping with symbolic rule learning, demonstrating solid experimental results and offering great insights.\n2. The overall framework is efficient, the rule induction time is much less than InternVL3-78B or GPT-5.\n3. Great presentation and clear figures make it easy for the reader to follow."}, "weaknesses": {"value": "1. Lack of detail in 4.1 ‘Pretraining’. From my point of view, the performance of GRMs is largely dependent on the pretrained perception backbones. However, the paper doesn’t include sufficient details (e.g., datasets, objectives, hyperparameters) about this.\n2. Unconvincing comparison between GRMs and baselines. Based on W1, actually GRMs’ perception modules are (potentially) benefited from extensive training on images in the same distribution as the evaluation. So the experimental results in the main table cannot fully support such neural-symbolic method can outperform data-driven methods, because the evaluated VLMs may not be familiar with the test images. I would wonder whether the GRMs’ performance is still superior to VLMs after they are post-trained using the same dataset.\n3. Limited generalization potential: GRMs' framework relies on predefined predicates and simplified group patterns, and cannot be used in processing real-world images."}, "questions": {"value": "1.  Could the authors provide more reasons/evidence to support that such a neuro-symbolic method is better than large-scale data-driven training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "33yyTvKPqF", "forum": "oyAmCsCe5b", "replyto": "oyAmCsCe5b", "signatures": ["ICLR.cc/2026/Conference/Submission7270/Reviewer_cs3A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7270/Reviewer_cs3A"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761755291131, "cdate": 1761755291131, "tmdate": 1762919398717, "mdate": 1762919398717, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a Gestalt Reasoning Machine (GRM) that fuses human-like perceptual grouping with symbolic rule learning. It operationalizes Gestalt principles within a neuro-symbolic ILP pipeline. Experiments on the ELVIS benchmark show clear accuracy gains over neural and prior neuro-symbolic systems with especially strong results under increasing visual complexity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The integration of Gestalt grouping within a neuro-symbolic ILP framework is novel and well-motivated by cognitive theory. The architecture bridges perception and reasoning in a way that is both interpretable and scalable.\n\n- The explicit use of contextual embeddings in s_p(o_i,o_j,I) = \\sigma(h_p(o_i,o_j,o^*_{ij})) shows the adventage of this grouping. \n\n- The comparison against GPT-5 and InternVL3 convincingly shows that structured reasoning can outperform massive data-driven systems.\n\n- Equation in section Appendix A is not clear: how  τ = 0.99 was chosen, for instance?"}, "weaknesses": {"value": "- Evaluation remains restricted to synthetic Gestalt scenes.\n\n- The contextual affinity s_p(o_i,o_j,I) = \\sigma(h_p(o_i,o_j,o^*_{ij})) seems to be introduced without justification. What is the theoritical grounding? Any ablation on o^*_{ij} mean embedding?\n\n- Regarding the rule search procedure, what are the convergence guarantees and computational complexity ?\n\n- How sensitive the proposed freamwork to the choice of grouping thresholds s_p?\n\n- Equation in section Appendix A is not clear: how  τ = 0.99 was chosen, for instance?"}, "questions": {"value": "see Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mQ6XdrXncV", "forum": "oyAmCsCe5b", "replyto": "oyAmCsCe5b", "signatures": ["ICLR.cc/2026/Conference/Submission7270/Reviewer_J3Xd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7270/Reviewer_J3Xd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805520671, "cdate": 1761805520671, "tmdate": 1762919398353, "mdate": 1762919398353, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Compared to traditional models relied on large datasets, this paper introduces Gestalt Reasoning Machines (GRMs), which integrates Gestalt principles to enhance reasoning models with perception capabilities. This paper demonstrates that GRMs outperform purely neural baselines in visual reasoning tasks that need perception of higher-order structures. GRM processes an image through perceptual detection, symbolic abstraction, and rule learning to derive interpretable logical rules, which are then applied by an inference engine that prioritizes high-confidence, transparent reasoning for visual prediction."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tNovelty: This work systematically integrate Gestalt perceptual principles (proximity, similarity, closure, symmetry, continuity) into a neuro-symbolic reasoning framework, bridging low-level perception and symbolic reasoning.\n2.\tEmpirical Validation: Comprehensive experiments including human test on the newly proposed ELVIS benchmark demonstrate clear advantages over both neural (e.g., ViT) and large multimodal models (e.g., GPT-5, InternVL3).\n3.\tEfficiency: GRM achieves strong accuracy with significantly lower rule induction time."}, "weaknesses": {"value": "1.\tData Limitation: All experiments are conducted on the ELVIS dataset.The paper mentioned that “To our knowledge, it is the only benchmark that systematically integrates these grouping principles into a neuro-symbolic pipeline, making it uniquely suited for evaluating GRM.” While this choice is reasonable for testing Gestalt-based grouping, it also raises concerns about generalization. Since ELVIS is specifically designed around grouping-centric reasoning, GRM’s advantage may partially stem from the dataset’s alignment with its inductive bias. To fully assess its robustness and versatility, it would be valuable to evaluate GRM on visual reasoning benchmarks that do not explicitly require grouping, such as CLEVR or RAVEN, to determine whether the proposed mechanism still provides benefits in more conventional reasoning settings.\n2.\tWriting and Presentation: Page 8 appears quite dense. The discussion on future work in the figure 5 “Currently, our grouping mechanism uses relatively simple neural networks. Developing more robust and semantically informed grouping mechanisms is a promising avenue for future work”could be moved to the conclusion section. Doing so would improve the overall flow and logical structure of the paper."}, "questions": {"value": "1.\tSince ELVIS is specifically designed around Gestalt grouping principles, have you tested (or do you plan to test) GRM on visual reasoning datasets that do not require explicit grouping, such as CLEVR or RAVEN?\n2.\tI am a bit confused about Table 2 and Figure 7. Could the authors clarify how the accuracy improvements reported in Table 2 were calculated? Similarly, how was the time reported in Figure 7 measured?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vsamtXaRwg", "forum": "oyAmCsCe5b", "replyto": "oyAmCsCe5b", "signatures": ["ICLR.cc/2026/Conference/Submission7270/Reviewer_xYyP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7270/Reviewer_xYyP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7270/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900914499, "cdate": 1761900914499, "tmdate": 1762919397923, "mdate": 1762919397923, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}