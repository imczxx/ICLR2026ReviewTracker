{"id": "Vogxs8BzJS", "number": 25274, "cdate": 1758366048413, "mdate": 1759896727467, "content": {"title": "CABA: A Collusive Aggregation-Emergent Backdoor Attack in Federated Learning", "abstract": "Federated Learning (FL) has been shown to be vulnerable to backdoor attacks conducted by malicious clients. Although many studies have enhanced the stealthiness and durability of backdoors, the full potential of collusive attacks in FL remains underexplored. Existing collusive attacks typically adopt a strategy where each malicious client trains independently. These attacks inevitably embed backdoor features into the uploaded updates and make them susceptible to detection. To fully exploit the collaborative capabilities of malicious clients, we propose a novel collusive attack, named CABA (Collusive Aggregation-based Backdoor Attack), where the backdoor behavior emerges only during model aggregation. In CABA, multiple malicious clients jointly craft a set of updates that individually exhibit no backdoor characteristics, allowing them to bypass defense mechanisms. However, when aggregated, these updates manifest the backdoor in the global model. Extensive experiments demonstrate that our proposed attack can successfully bypass six state-of-the-art defense mechanisms, demonstrating superior stealth and attack efficacy compared to existing collusive approaches. Our research highlights the critical importance of developing defense mechanisms that can inspect the combined behavior of model updates after aggregation.", "tldr": "", "keywords": ["Collusive Backdoor Attack", "Federated Learning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/46e2e33e68d0e01ade1992996aca8725809aab39.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes CABA (Collusive Aggregation-based Backdoor Attack), a novel “aggregation-emergent” attack in federated learning (FL). Unlike previous collusive attacks where each malicious client independently embeds a full backdoor, CABA distributes the backdoor functionality across several malicious clients so that each individual update appears benign. The backdoor only emerges after aggregation, making it hard to detect via standard defenses. The authors conduct experiments on CIFAR-10 using ResNet-18 and evaluate against several state-of-the-art defenses (e.g., Multi-Krum, FLAME, FoolsGold, DeepSight, BackdoorIndicator), showing that CABA achieves high attack success rates and defense bypass capability. The paper claims this exposes a blind spot in existing FL defense mechanisms and calls for post-aggregation validation methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The idea of an aggregation-emergent backdoor, which activates only after global model aggregation, represents a meaningful conceptual advancement beyond prior collusive paradigms.\n- The paper compares against several strong baseline attacks (DBA, CoBA, 3DFed, Chameleon) and defenses, demonstrating empirical superiority across multiple FL settings (IID/Non-IID).\n- The proposed framework is well-organized into four phases (Data Redistribution, Benign Pre-training, Joint Trigger Tuning, and Joint Backdoor Training), offering clarity in design and reasoning."}, "weaknesses": {"value": "- The evaluation omits more recent or stronger defenses such as AlignIns (CVPR 2025). Without this, the claimed robustness may not generalize to the current defense landscape.\n- The attack presumes that the same subset of malicious clients is always selected each round and that full synchronization between them is possible. This is unrealistic in real FL settings.\n- Experiments only conducted on CIFAR-10 with ResNet-18, lacking evidence of generality across more datasets and models.\n- The framework involves multiple key hyperparameters (α, β, γ) that balance stealth, diversity, and backdoor strength. However, there is no reported study on their influence or stability.\n- CABA requires multi-client joint training, which could substantially increase communication and memory overhead. The paper lacks any runtime or memory cost analysis.\n- The method is largely heuristic. No theoretical justification or formal analysis is given to explain why distributed sub-model interactions reliably produce an emergent backdoor after aggregation.\n- No released code – Reproducibility cannot be verified.\n- Figure 4 analyzes data distribution and attacker proportion but does not clearly show CABA’s ablation results."}, "questions": {"value": "- How would CABA perform under AlignIns (CVPR 2025) or other feature-space alignment defenses? \n- Could the authors provide runtime, GPU memory, and communication overhead comparisons relative to baseline attacks, and discuss whether the multi-client joint optimization scales to larger backbones (e.g., ViT-B/16)?\n- The CABA loss combines multiple coefficients (α, β, γ). How sensitive are attack success and stealth to these parameters? Can the attack remain effective without precise tuning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ei3h4P0s7M", "forum": "Vogxs8BzJS", "replyto": "Vogxs8BzJS", "signatures": ["ICLR.cc/2026/Conference/Submission25274/Reviewer_7Dcr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25274/Reviewer_7Dcr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25274/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760694312045, "cdate": 1760694312045, "tmdate": 1762943382395, "mdate": 1762943382395, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CABA, a collusive backdoor attack in which multiple compromised clients jointly craft updates that appear benign individually, while the backdoor is implanted only after server aggregation of these updates. The pipeline comprises: (1) attacker-side data redistribution to induce diversity; (2) benign pre-training; (3) joint trigger tuning; and (4) joint backdoor training with a composite loss that embeds the backdoor signal in the aggregated model while regularizing each sub-model to remain inconspicuous. Experiments (e.g., CIFAR-10 / ResNet-18) report high attack success rate (ASR) and bypass of several server-side defenses."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- This attack studies more angle and exploits vulnerability when multiple clients are compromised, compared with previous attacks.  \n- The attack explicitly considers stealthiness, which is crucial for the security of federated learning and makes the threat model more realistic.  \n- The evaluation includes multiple robust-aggregation and behavior/property-based defenses, strengthening the contribution of this work."}, "weaknesses": {"value": "- The presentation needs a strong revision. From the current version, it is unclear how the attack is conducted, and the Joint Trigger Tuning and Joint Backdoor Training sections miss many important details. For example:  \n  1. Based on Objective (4), the trigger is optimized such that the model still classifies triggered samples correctly. If that is the case, how does the adversary finally achieve the backdoor objective?  \n  2. What are $X_k$ and $Y_k$ in Eqn. (5)? What is the relationship between Eqn. (4) and Eqn. (5)?  \n  3. It is unclear how each compromised client trains its poisoned model and trigger, how local triggers are combined, and how these clients communicate.  \n  4. The novelty appears to involve splitting the adversary’s dataset into multiple shards to create several local models, but this is vague; the paper does not clearly explain how the attack is actually performed.  \n  \n - The evaluation is limited: there is no ablation on malicious dataset size, no exploration of non-IID hyperparameters, no tests with different aggregation algorithms or model architectures, and no examples of the final optimized triggers.  \n- All evaluated defenses are from before 2022.  \n- The captions of tables and figures are not informative. For example, Figure 2 does not highlight the differences between this method and existing FL attacks, and its caption lacks useful explanation.  \n- A systematic comparison against existing attacks and clearer representations (figures and tables) are recommended to better illustrate the novelty of this work."}, "questions": {"value": "1. Define $X_k, Y_k$ vs. $\\hat{X}_k, \\hat{Y}_k$; clarify how these sets are sampled per step and how they differ from $X_b, Y_b$ used for the aggregated forward pass.  \n2. Do you alternate Eq. (4) and Eq. (5)? If so, what is the cadence, and how sensitive is ASR to this schedule and the $\\alpha, \\beta, \\gamma$ parameters?  \n3. How does each malicious client compute gradient and how do they share gradients formally, and what is the per-round communication overhead among malicious clients?  \n4. Quantify ASR under per-update clipping (different norms), Gaussian noise (DP), or more complicated aggregators such as FedProx, Scaffold."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6NTiTaB0qc", "forum": "Vogxs8BzJS", "replyto": "Vogxs8BzJS", "signatures": ["ICLR.cc/2026/Conference/Submission25274/Reviewer_LHWc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25274/Reviewer_LHWc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25274/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761865748291, "cdate": 1761865748291, "tmdate": 1762943382185, "mdate": 1762943382185, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces CABA (Collusive Aggregation-based Backdoor Attack), a new class of collusive attacks in federated learning (FL) where the backdoor behavior appears only after model aggregation — not in any single client’s update. Each malicious client uploads a harmless-looking “fragment” of the backdoor, evading detection by defenses that examine individual updates. CABA breaks traditional collusive attacks (e.g., DBA, CoBA, 3DFed) that involve training a full backdoored model by distributing the backdoor embedding process.\nThis paper benchmarks empirically on seven types of defenses and achieves better overall ASR performance while maintaining accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This paper proposes a way to distribute the backdoor embedding process instead of using classical ways of training a full backdoored one.\n- This paper is well structured with detailed definitions and respective theoretical framework."}, "weaknesses": {"value": "- The trigger in this work is designed within the joint trigger tuning process. However, it is still unclear what the trigger is like and how the trigger is simultaneously activated across clients.\n- Although the authors conduct extensive experiments to demonstrate the effectiveness of the CABA attack under various scenarios, including different defense and attack methods, the datasets and models used remain limited to only CIFAR-10 and ResNet-18.\n- The proposed method heavily depends on the assumption that the FL dataset must be accessible and redistributed before launching the attack. However, this scenario may not be practical in real-world situations, as most FL setups typically do not permit access to client-side data."}, "questions": {"value": "- Can you demonstrate the trigger more clearly with a visualization of how a trigger is optimized?\n- Also, what are the differences between untuned triggers and tuned triggers in this work?\n- Can you provide more experiments on other datasets (e.g., CIFAR-100, ImageNet) and with other models to show that the proposed method is scalable?\n- Can you point out some scenarios, like CABA, where multiple clients might need to be triggered simultaneously and updated synchronously?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HE7sIEdgip", "forum": "Vogxs8BzJS", "replyto": "Vogxs8BzJS", "signatures": ["ICLR.cc/2026/Conference/Submission25274/Reviewer_P4Gf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25274/Reviewer_P4Gf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25274/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876477520, "cdate": 1761876477520, "tmdate": 1762943381987, "mdate": 1762943381987, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a backdoor attack framework in Federated Learning (FL) that leverages the collaboration of multiple malicious clients to bypass existing defenses. The authors argue that current collusive attacks often have each malicious client independently training a full backdoor model, making their updates easily detectable by advanced defense mechanisms.\n\nTo address this, CABA (Collusive Aggregation-Based Backdoor Attack) introduces an *aggregation-emergent* paradigm, where the backdoor functionality materializes only during the server’s aggregation phase. Individual malicious clients contribute seemingly benign, fragmented updates that collectively induce a backdoor in the aggregated global model. The four-phase design—Data Redistribution, Benign Model Pre-training, Joint Trigger Tuning, and Joint Backdoor Training—ensures that no single malicious update exhibits a complete backdoor signature.\n\nExperiments on CIFAR-10 demonstrate that CABA successfully circumvents six defense mechanisms, achieving both high attack success rates (ASR) and strong stealthiness compared to existing collusive and single-client attacks. The work highlights a significant blind spot in current defense paradigms that primarily focus on inspecting individual client updates, underscoring the need for post-aggregation validation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Exposes a critical vulnerability in current defense mechanisms that only analyze individual client updates.\n2. Introduces an innovative “aggregation-emergent” backdoor design, where the malicious effect arises solely after model aggregation—making individual updates appear benign.\n3. The four-phase framework is clearly structured and effectively addresses challenges related to model diversity, trigger optimization, and update stealthiness."}, "weaknesses": {"value": "- As discussed in Appendix A, CABA’s success relies heavily on \"faithful aggregation,\" meaning its effectiveness degrades if the central server applies *any* pre-aggregation modifications (e.g., gradient clipping, differential privacy, or pruning). These are common in modern FL deployments, which significantly limits CABA’s real-world applicability.\n- The paper describes the trigger as a \"pixel pattern\" and provides coordinates in Table 5, but a visual example of trigger-embedded images would help assess perceptibility. Moreover, while Figure 6 presents erratic sub-model backdoor accuracies, a qualitative visualization showing how the *aggregated model* consistently activates the backdoor would better support the \"aggregation-emergent\" claim.\n- CABA assumes perfect coordination among malicious clients and exact aggregation of \"benign-looking fragments.\" In practical FL systems with network noise, varying client computation, or deviations in aggregation logic, this synergy may break down, weakening the emergent backdoor effect.\n- The multi-phase pipeline—requiring data redistribution, joint training, and synchronized optimization across malicious clients—introduces substantial coordination and communication overhead. This level of orchestration may be impractical for large-scale or geographically dispersed adversaries. The paper should quantify this cost and discuss its feasibility relative to single-client attacks.\n- CABA requires all malicious clients to submit their updates simultaneously each round to sustain the emergent backdoor. The paper does not examine cases where some attackers fail to participate or submit benign models, which would clarify the sensitivity of the attack to partial collaboration.\n- Non-IID settings are more representative of real-world FL but are relegated to the appendix. These results should appear in the main paper for better visibility and evaluation.\n- Table 1 shows fluctuating backdoor accuracy for CoBA under Multi-Krum and FLAME (e.g., low accuracy at round 1200 but high at 400/800). The authors should explain this behavior and specify the attack schedule—continuous or periodic—as well as justify using 20 clients per round instead of the more common 10-client setup in prior work.\n- The failure of Deepsight in Table 3 should be explicitly explained to clarify whether it stems from detection errors, instability, or incompatibility with the aggregation-emergent mechanism.\n- Experiments are confined to CIFAR-10. Evaluating CABA on more complex datasets (e.g., CIFAR-100, ImageNet) and grayscale datasets (e.g., MNIST, FashionMNIST) would better demonstrate generalizability across different data modalities and tasks."}, "questions": {"value": "Please address the aforementioned weaknesses. Specifically, clarify CABA’s robustness to aggregation modifications, discuss coordination overhead, provide trigger visualizations, explain anomalous results, and expand experiments to more datasets."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "bSiG9DICI3", "forum": "Vogxs8BzJS", "replyto": "Vogxs8BzJS", "signatures": ["ICLR.cc/2026/Conference/Submission25274/Reviewer_cswz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25274/Reviewer_cswz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25274/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935896310, "cdate": 1761935896310, "tmdate": 1762943381773, "mdate": 1762943381773, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}