{"id": "65WSbRO5Om", "number": 24517, "cdate": 1758357559985, "mdate": 1759896762141, "content": {"title": "DotMatch: Simplified Semi-Supervised Learning with the Log Dot Product Loss", "abstract": "Semi-supervised learning (SSL) algorithms typically work by generating supervisory signals for unsupervised data using the model being trained, but such supervisory signals are generally imperfect, thus various techniques have been proposed to balance the signal-to-noise ratio, such as confidence-based pseudo-labeling, consistency regularization and entropy regularization. However, these methods often require careful tuning of hyperparameters, such as the confidence threshold in pseudo-labeling and the regularization strength in regularization methods, which is often a challenging task, particularly with limited labeled data available for validation. In this paper, we introduce DotMatch, an SSL algorithm that is capable of balancing the signal-to-noise ratio without any algorithm specific hyperparameters. Specifically, we introduce a novel consistency loss on unsupervised data to replace the cross-entropy loss, called the log dot product (LDP) loss, which is simply the negative log of the dot product between the predicted label distributions of weak and strong augmented views of an input. Compared to the cross-entropy loss with soft target, the LDP loss enjoys several benefits in the context of SSL: non confident examples have low impacts on model updates, as in confidence-based pseudo-labeling methods such as SoftMatch; predictions are encouraged to have a low entropy, as in entropy-regularized methods; and interestingly, its gradient is appropriately scaled relative to the gradient of the supervised loss, thus requiring no regularization constant. We additionally combine the LDP loss with distribution alignment to ensure the distribution of predictions on unlabeled data match that of the labeled data. We provide a theoretical analysis to explain the efficacy of DotMatch from the perspective of loss gradients. Extensive experiments show that DotMatch is competitive with state-of-the-art baselines without needing to tune any algorithm-specific hyperparameters for different datasets.", "tldr": "", "keywords": ["semi-supervised learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1b333d17d6d282fbd2e5252c2b75e9f518069005.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a new method from Semi-Supervised Learning (SSL) called DotMatch.\nThe goal of this method is to simplify existing methods by removing user-specified hyper-parameters such a label confidence threshold or such as the weighting for the unlabeled (which in many method is set to 1 anyway).\nThis is achieved by replacing the cross-entropy (CE) loss $\\text{CE}(x,y)=-\\sum_i y_i\\log(x_i)$ where $y$ is the expected label probability vector and $x$ the actual label probability vector, with a new loss called Log Dot Product (LDP) loss $\\text{LDP}(x,y)=-\\log(\\sum_i x_i y_i)$.\n\n\nUsing this simple modification, the method adapts the classical unlabeled SSL loss for a neural network classifier $p(.;\\theta)$ to $$L_{u}(\\theta)=\\text{LDP}(p(s(x);\\theta),\\text{nograd}(\\text{DA}(p(w(x);\\theta))))$$ where $w,s$ are respectively weak and strong augmentations.\nHere $\\text{DA}$ stands for distribution alignement and is a reweighting of the label probability vector obtained from $w(x)$ by an approximation of the ratio $\\mathbb{E}_{y\\sim\\mathcal{L}}[y] / \\hat{p}_y=\\mathbb{E}_{x\\sim\\mathcal{U}}[p(w(x);\\theta)]$ as introduced by ReMixMatch.\n\nResults are evaluated with SotA baslines for MNIST, EMNIST, CIFAR10, CIFAR100, SVHN and STL confirming the method is competitive for various sizes of labeled subsets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The method is simple and elegant.\n2. The method uses all the unlabeled data in the batch rather than zero-ing low-confidence predicted labels unlike previous methods.\n3. The paper is well written and easy to follow for the most part."}, "weaknesses": {"value": "1. The definition for $\\texttt{sumnorm}$ (line 364) appears to be missing, I assume it must be $\\text{sumnorm}(x)=x/\\sum_i x_i$.\n2. The definition for $\\epsilon$ also appears to be missing (line 364), I assume it must be a small constant to avoid division by 0."}, "questions": {"value": "1. What value of $\\epsilon$ did you use?\n2. Is $\\epsilon$ a function of the number of classes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "FcAQMN32xj", "forum": "65WSbRO5Om", "replyto": "65WSbRO5Om", "signatures": ["ICLR.cc/2026/Conference/Submission24517/Reviewer_YaiK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24517/Reviewer_YaiK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951208566, "cdate": 1761951208566, "tmdate": 1762943111280, "mdate": 1762943111280, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DotMatch, a novel semi-supervised learning (SSL) method that omits hyperparameters, such as confidence thresholds or regularization strengths. The key contribution is the Log Dot Product (LDP) loss, a new consistency loss that replaces the traditional cross-entropy loss for learning with unlabeled data. The LDP loss simply computes the log negative dot product between predictions between weak- and strong-augmentations. Moreover, when combined with distribution alignment, DotMatch achieves competitive or superior performance to other baseline methods. Furthermore, a theoretical gradient analysis is provided to support the empirical findings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper proposed a simple and intuitive method named DotMatch that omits hyperparameter tuning, which is easy to employ and simplifies the training process.\n- This paper provides a rigorous theoretical framework to justify its method.\n- The experiments are quite extensive and show promising performance improvement."}, "weaknesses": {"value": "- While the LDP loss is formulated in a simple and elegant manner, it remains similar to standard consistency-based SSL approaches, where they simply use the prediction consistency between weak and strong augmentation to conduct SSL. As a result, consistency-based SSL either does not require hyperparameters to control the strength or threshold. Could you further justify why the DOT multiplication is different from the MSE or KLD-based consistency training loss?\n- Semi-Supervised Learning under open world and distribution shift has been an important research topic that scales SSL from traditional IID scenario to more complicated real-world applications [1], [2], and [3]. How the proposed DotMatch can be successfully employed in open world SSL is worth further discussing and investigating because there is no justification nor experiments to demonstrate the robustness.  \n[1] Saito et al., Openmatch: Open-set semi-supervised learning with open-set consistency regularization, in NeurIPS 2021.  \n[2] Huang et al., Universal semi-supervised learning, in NeurIPS 2021.  \n[3] Yu et al., Multi-task curriculum framework for open-set semi-supervised learning, in ECCV 2020."}, "questions": {"value": "- How does LDP behave when the prediction distributions are nearly orthogonal (dot product close to zero)? Is there a risk of instability in the gradient magnitude?\n- Can LDP be extended to multiview or multimodal SSL cases where prediction distributions may differ structurally? Does the proposed method remain effective if augmentations are weaker, i.e., the difference between weak and strong augmentations are small? Will LDP still be effective if the application is related to a different modality, such as Speech or Text SSL?\n- Would introducing an adaptive temperature in LDP improve generalization further? How can such a temperature affect the learning performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JKCJu3JJGA", "forum": "65WSbRO5Om", "replyto": "65WSbRO5Om", "signatures": ["ICLR.cc/2026/Conference/Submission24517/Reviewer_NEVA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24517/Reviewer_NEVA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955500645, "cdate": 1761955500645, "tmdate": 1762943111018, "mdate": 1762943111018, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DotMatch, an SSL method that replaces the usual unlabeled-data cross-entropy with a Log Dot Product (LDP) loss. Despite its simple form, LDP (i) automatically down-weights low-confidence unlabeled examples, (ii) implicitly encourages low-entropy predictions, and (iii) matches the gradient scale of supervised cross-entropy—without introducing additional algorithm-specific hyperparameters common in prior work. Experiments show that the proposed method works well on several benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is clearly written and easy to follow. \nThe LDP loss naturally (i) down-weights low-confidence unlabeled samples, (ii) encourages low-entropy predictions, and (iii) matches supervised CE’s gradient scale. This hyperparameter-light design could be practically appealing as it minimizes algorithm-specific hyperparameter tuning that many SSL methods require."}, "weaknesses": {"value": "The overall framework closely resembles FixMatch (adding DA), but with the consistency loss replaced by the proposed LDP objective. However, since similar dot-product–based losses have appeared in prior work and are here adapted to SSL, the contribution feels incrementally novel."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1OmPyFN0eT", "forum": "65WSbRO5Om", "replyto": "65WSbRO5Om", "signatures": ["ICLR.cc/2026/Conference/Submission24517/Reviewer_SFsj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24517/Reviewer_SFsj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762052950700, "cdate": 1762052950700, "tmdate": 1762943110745, "mdate": 1762943110745, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DotMatch, a semi-supervised learning (SSL) algorithm centered on a novel Log Dot Product (LDP) loss. The paper's primary and most significant contribution is its theoretical analysis of this loss function. Theorem 1 proves that the LDP loss's gradient norm is implicitly coupled with the target's confidence (entropy): high-entropy (uncertain) targets naturally produce near-zero gradients, while low-entropy (confident) targets produce large gradients. This presents an elegant, implicit mechanism for balancing signal-to-noise, contrasting with the explicit thresholding or re-weighting mechanisms of algorithms like FixMatch and SoftMatch. Empirically, DotMatch shows very strong performance in extremely low-label regimes."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "## Reasons to Accept\n\n---\n\n* **Novel Theoretical Contribution:** The paper's core strength is its theoretical analysis of the LDP loss's gradient properties. Theorem 1 provides a \"first-principles\" explanation for an implicit, confidence-based filtering mechanism that emerges from the loss function's geometry alone. This is a novel and elegant contribution to the field.\n* **Good Low-Label Performance:** DotMatch achieves state-of-the-art results in the most challenging, data-starved settings, such as EMNIST with 47 labels (~1 per class) and CIFAR-100 with 400 labels.\n* **Elegant Loss Formulation:** The LDP loss itself is a clever, unified objective. As shown in the analysis and ablations, it successfully integrates three key SSL goals into one function: consistency regularization (via weak/strong augmentation), inherent entropy minimization (driving predictions toward one-hot targets), and implicit confidence-based re-weighting.\n* **Strong Ablation Study (for LDP):** The ablation in Table 3 provides causal evidence for the LDP loss's effectiveness. It shows that LDP+DA (DotMatch) is dramatically better than using a standard Cross-Entropy loss with either hard or soft targets, confirming the LDP loss is the primary driver of the algorithm's success."}, "weaknesses": {"value": "## Reasons to Reject\n\n---\n\n* **Hyperparameters:** The paper's main claim of having \"no algorithm specific hyperparameters\" is false. The DotMatch objective (Eq 5) explicitly includes a Distribution Alignment (DA) component. As defined in Section 4.3, this DA mechanism depends on $\\hat{\\pi}_{t}$, an \"EMA of the prior,\" which is calculated using an \"EMA momentum $m$\". $m$ is algorithm-specific hyperparameter that is left un-ablated.\n* **Missing Large-Scale Benchmarks:** The paper's empirical validation is only on small, \"classic\" datasets (e.g., CIFAR, EMNIST). It lacks experiments on standard large-scale benchmarks like ImageNet or WebVision. Prior work like SoftMatch/FixMatch/FreeMatch are evaluated on these.\n* **Empirical Strength:** DotMatch is not universally better. It is significantly outperformed by FixMatch on SVHN (40 labels) and outperformed by FreeMatch and SoftMatch on CIFAR-10 (40 and 250 labels). This suggests its filtering may be an overly conservative liability on \"easier\" datasets where greedy, explicit methods (like FixMatch) are superior."}, "questions": {"value": "## Questions for the Authors\n\n---\n\n* The paper’s core premise is \"no algorithm specific hyperparameters\". Why is $m$ not considered an algorithm-specific hyperparameter, and can you provide a full ablation study for it across datasets?\n* Why were experiments on standard, large-scale benchmarks like ImageNet and WebVision omitted? SoftMatch and FreeMatch use these to prove scalability and noise robustness. Without them, it is difficult to assess the practical value of DotMatch. Could you add these results?\n* Table 2 shows that DotMatch is outperformed by FixMatch on SVHN and by FreeMatch on CIFAR-10. Does this suggest that the LDP loss’s implicit, gradual filtering is actually a disadvantage on datasets where a model can quickly become confident, and that a \"greedy\" explicit threshold (like FixMatch's) is superior in those cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "X7vGSXiRby", "forum": "65WSbRO5Om", "replyto": "65WSbRO5Om", "signatures": ["ICLR.cc/2026/Conference/Submission24517/Reviewer_MU44"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24517/Reviewer_MU44"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762232517911, "cdate": 1762232517911, "tmdate": 1762943110494, "mdate": 1762943110494, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on semi-supervised learning (SSL) and proposes DotMatch, an algorithm that leverages multi-view consistency and distribution alignment (DA) to learn from unlabeled data without algorithm-specific hyperparameters: it first introduces the Log Dot Product (LDP) loss to measure consistency between weakly and strongly augmented views of unlabeled examples, then combines it with distribution alignment to match the predicted label distribution of unlabeled data with that of labeled data; with LDP loss down-weighting low-confidence examples and implicitly minimizing entropy, the framework achieves competitive performance on standard SSL benchmarks. While it has strengths in desirable qualities of SSL, hyperparameter-free design, theoretically grounded gradient analysis, it also faces issues like reliance on lack of novelty, insufficient experimental analysis and presentation issues."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.Desirable qualities on SSL: The method proposes LDP loss with distribution alignment and achieves desirable qualities on SSL, namely consistency, entropy minimization and small gradient norms for low-confidence unlabeled examples.\n2.Hyperparameter-free design: The method is hyperparameter-free without needing to tune any algorithm-specific hyperparameters for different datasets.\n3.Theoretically grounded gradient analysis: The paper gives theoretically grounded gradient analysis and comparison of three losses (CE(hard), CE(soft) and LDP) through formula derivation and visualization."}, "weaknesses": {"value": "1.Lack of novelty: The proposed method is largely built upon established SSL paradigms. Similar forms of Log Dot Product–based losses have been discussed in prior works, and the use of distribution alignment is also a well-known strategy. \n\n2.Insufficient experimental analysis: The experiments mainly report classification test errors without deeper quantitative or qualitative analyses to support the claimed advantages, such as confidence calibration, the contribution of unlabeled samples, or training dynamics visualization. More ablation or interpretability studies would strengthen the empirical validation.\n\n3.Presentation issues: The paper suffers from inconsistent and potentially confusing notation—such as using both bold and non-bold versions of the same symbol to denote different quantities—and inconsistent symbol definitions."}, "questions": {"value": "1.LDP loss Innovation: The proposed LDP loss shares a similar structural form with the Pairwise Objective introduced in the following ICLR 2022 paper. A clearer distinction between the two should be articulated.\nOPEN-WORLD SEMI-SUPERVISED LEARNING. ICLR 2022 \n2.DA originality: DA is also a commonly used correction algorithm. It is supposed to illustrate whether it has been improved or innovated, and also explain in detail the relevant details of the DA formula and its various symbols.\n3.Limited comparison with existing methods: The comparison set in the experiments appears relatively narrow. Beyond the few mentioned baselines, the paper should consider including a broader range of semi-supervised learning methods, particularly recent state-of-the-art algorithms.\n4.Dataset-specific performance concerns: The proposed method exhibits significant performance gains primarily on the EMNIST dataset, while the improvements on other benchmarks are marginal. This raises concerns about potential dataset-specific tuning or overfitting."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Nv5XXJLKGE", "forum": "65WSbRO5Om", "replyto": "65WSbRO5Om", "signatures": ["ICLR.cc/2026/Conference/Submission24517/Reviewer_aq1g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24517/Reviewer_aq1g"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission24517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762313813675, "cdate": 1762313813675, "tmdate": 1762943110191, "mdate": 1762943110191, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the DotMatch method for semi-supervised learning (SSL) problem, with the proposed log dot product loss (LDP) loss applying to a classic form of SSL objective functions. Through optimum and gradient analysis of LDP, the authors claim that LDP has benefits that non-confident examples have a low contribution to the gradient and that the optima are encouraged to have a low entropy. These properties of LDP enable the proposed DotMatch method to be free of hyperparameter tuning. Experimental comparisons with other SSL methods on classic CV benchmarks are also conducted."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed method requires no algorithm-specific hyperparameters.\n- The proposed method is easy to understand and implement.\n- The proposed LDP loss is analyzed from both theoretical and experimental perspectives."}, "weaknesses": {"value": "- The experimental results are weak. 1) In Table 2, the proposed DotMatch method achieves the best accuracy in only 5 out of 10 cases. 2) The experiments are conducted on relatively small scale CV benchmark datasets. Results on larger datasets such as Imagenet are lacking.\n- As shown in Figure 2, when the target is close to uniform, LDP requires far more gradient steps than CE to reach the optimum. This raises my concerns about the computational efficiency of DotMatch. To address this, I think experimental comparisons on the training time of LDP with other methods should be reported.\n- Figure 1 should include DotMatch to better support the claims.\n- In Table 1, the notations $\\boldsymbol{z}$ and $p \\odot q$ are used but undefined.\n- Line 930. Table 7 should be Table 2?"}, "questions": {"value": "- I cannot find which section supports the claim in the abstract that \"its gradient is appropriately scaled relative to the gradient of the supervised loss, thus requiring no regularization constant.\" Could you specify this for me?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eYIgWu8Cob", "forum": "65WSbRO5Om", "replyto": "65WSbRO5Om", "signatures": ["ICLR.cc/2026/Conference/Submission24517/Reviewer_q8in"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24517/Reviewer_q8in"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission24517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762510998807, "cdate": 1762510998807, "tmdate": 1762943109903, "mdate": 1762943109903, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}