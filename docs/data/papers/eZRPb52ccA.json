{"id": "eZRPb52ccA", "number": 8137, "cdate": 1758068044479, "mdate": 1759897804878, "content": {"title": "DEAGLE: Token Tree with Dynamic Depth Will Further Benefit the Speculative Decoding", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in text generation, but they also suffer from high token-by-token latency due to the nature of autoregressive decoding. Speculative decoding (SD) mitigates this by using the draft-then-verify framework, making it possible to generate multiple tokens in a single LLM forward pass. However, existing state-of-the-art SD frameworks typically generate token trees with a fixed depth, which brings unnecessary computation and suboptimal speedup across diverse datasets. In this work, we introduce DEAGLE, a lightweight and training-free extension to EAGLE-3 that enables adaptive-depth speculative decoding through context-aware token-tree monitoring. We provide the first formal proof that draft model confidence serves as an unbiased estimator of token-level acceptance, generalizing empirical observations from prior EAGLE-2 work to EAGLE-3. Furthermore, we show that the product of draft confidences along a token path, the survival probability, can be a good heuristic for full-branch acceptance. Based on this insight, DEAGLE introduces a voting-based early stopping mechanism that monitors the survival probability sum of the top-k leaves, survival momentum, and the expected accept length for the whole token tree (estimated via survival probability expectation). These factors are jointly used to determine when to stop tree expansion. DEAGLE can be integrated into EAGLE-3 without retraining or architectural changes. Experiments on Vicuna 13b, Llama3-8b, and Llama3-70b demonstrate that DEAGLE achieves further speedup over EAGLE-3 and enables more robust acceleration across different datasets and token tree depths.", "tldr": "This paper proposed an approach that make the draft eagle model can generate token tree with dynamic depth based on input context.", "keywords": ["Sepculative Decoding", "Large Language Models", "Decoding Acceleration", "Eagle Decoding"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/10c482eb922422f263e7b94c1e82f85f41fc433e.pdf", "supplementary_material": "/attachment/211f61f43818d9c82569fb378a9573c2d79640d9.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a token tree with dynamic depth when using SpD to accelerate LLMs. They show that the product of draft confidences along a token path can be a good heuristic for full-branch acceptance, and introduces a voting based early stopping mechanism that monitors the survival probability sum of the top-k leaves, and the expected accept length for the whole token tree. The experimental results show the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is technically sound and easy to understand.\n\nThe theoretical proof show the usefulness of the method.\n\nThe experimental results show the effectiveness of the method."}, "weaknesses": {"value": "The experimental results in Tab.1-3 is redundant. The author should report the best speedup compared to the baseline. Using different depth should be discussed in the ablation study.\n\nThe improvement is marginal when only compare the best speedup of DEAGLE and Eagle3.\n\nThe paper focuses on generating tree structure and improve the overall MAT to speedup the large language model. However, they do not report the framework they use. Here comes a problem that the method may not have such speedup on the popular inference framework such as vLLM. In fact, HuggingFace Transformers framework does not optimize the speed of LLMs very well, which makes the ratio of the latency of tree generation process smaller. When using vLLM framework where the operations in LLMs are optimized very well, the tree generation process will take more time and reduce the speedup.\n\nThe author should verify their method on such inference frameworks to show that their method is actually useful in reality."}, "questions": {"value": "See weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "q0SqPByWxF", "forum": "eZRPb52ccA", "replyto": "eZRPb52ccA", "signatures": ["ICLR.cc/2026/Conference/Submission8137/Reviewer_B8kF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8137/Reviewer_B8kF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760602473282, "cdate": 1760602473282, "tmdate": 1762920108711, "mdate": 1762920108711, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a training-free enhancement to the EAGLE speculative decoding framework.  They show that survival probability\nexpectation is a good heuristic for the draft model to stop building the token tree, and propose DEAGLE, a dynamic depth control method. The experiments show the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is technically sound and easy to understand. \n2. Good theorical proof."}, "weaknesses": {"value": "The experiments in Table 1 and Table 2 show no significant improvement over EAGLE3."}, "questions": {"value": "See weakness above, speed improvement is important."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6dGRBgYTEv", "forum": "eZRPb52ccA", "replyto": "eZRPb52ccA", "signatures": ["ICLR.cc/2026/Conference/Submission8137/Reviewer_TXEZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8137/Reviewer_TXEZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761645280541, "cdate": 1761645280541, "tmdate": 1762920108184, "mdate": 1762920108184, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a training-free enhancement to the EAGLE speculative decoding framework.  They show that survival probability\nexpectation is a good heuristic for the draft model to stop building the token tree, and propose DEAGLE, a dynamic depth control method. The experiments show the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is technically sound and easy to understand. \n2. Good theorical proof."}, "weaknesses": {"value": "The experiments in Table 1, Table 2 and Table 3 show no significant improvement over EAGLE3. \nTable 1, for instance, reports speed-ups across depths, benchmarks, and temperatures.\nPeak values on MT-Bench at T = 0 illustrate the gap most clearly:\n- EAGLE3 peaks at 4.37× (depth 8 and 10)\n- DEALGE peaks at 4.56× (depth 12)\n\nRelative lift: 4.56 / 4.37 ≈ 1.043, < 5 %.\nFor the vast majority of settings, the improvement hovers at just 1–3 %."}, "questions": {"value": "See weakness above. Speed improvement is important, since speculative decoding is, at its core, an application-driven technique: theory must serve practice, and experiments must validate the theory."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6dGRBgYTEv", "forum": "eZRPb52ccA", "replyto": "eZRPb52ccA", "signatures": ["ICLR.cc/2026/Conference/Submission8137/Reviewer_TXEZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8137/Reviewer_TXEZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761645280541, "cdate": 1761645280541, "tmdate": 1763348086859, "mdate": 1763348086859, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "DEAGLE is a new speculative decoding framework designed as a training-free extension to EAGLE-3 to address the inefficiency of fixed-depth token trees. The paper formally proves that draft model confidence serves as an unbiased estimator for token acceptance, extending this theoretical basis from EAGLE-2 to the EAGLE-3 architecture. Based on this, DEAGLE introduces a novel voting-based early stopping mechanism that dynamically adjusts the tree expansion depth during inference. This mechanism monitors the top-k survival probability, the decay rate (momentum), and the estimated expected acceptance length of the token tree."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The work provides the first formal proof that draft confidence acts as an unbiased estimator for token-level acceptance within the EAGLE-3 framework, grounding the dynamic decoding strategy in solid theory.\n\n- DEAGLE utilizes a sophisticated three-factor voting mechanism (survival probability sum, momentum, and expected length) to effectively stop redundant branch expansion, significantly reducing unnecessary draft model forward passes."}, "weaknesses": {"value": "1. Novelty Concerns: I have some concerns regarding the novelty of this paper, as it bears considerable similarity to the previous work, DDD[1]. Both works propose using Dynamic Tree Length for EAGLE, with the distinction that DDD is based on EAGLE2 while yours is based on EAGLE3. While DDD measures the total confidence of the entire beam by performing a log-sum-exp operation, your approach calculates the cumulative product (survival probability) for each leaf node, selecting the top-k most promising paths, and further incorporating Momentum and Expectation for voting. Nevertheless, the fundamental principle in both is the utilization of the draft model's probability for each draft token. Consequently, I consider your work to be somewhat incremental. However, you have enriched their methodology and provided corresponding theoretical foundations.\n\n2. Marginal Performance Improvement: The performance gains are too marginal. For instance, in Table 1, at temperature=0, the SOTA improvement of DEAGLE over EAGLE3's SOTA is only 4.3% (4.37 to 4.56) on the MT-Bench and 3.5% (5.42 to 5.61) on the HumanEval.\n\n3. Formatting Check: I recommend the authors carefully check the paper format. For example, there appears to be a duplicate section number at Line 410, which has \"4.2\" listed twice.\n\n[1] Dynamic depth decoding: Faster speculative decoding for llms"}, "questions": {"value": "- As a suggestion for clarity, I recommend the authors add an \"Average\" column to Tables 1, 2, and 3. This column should report the average performance of EAGLE3 and DEAGLE across all four datasets. This would visually demonstrate the average performance of different methods across various depths.\n\n- Some research[2] suggests that earlier tokens are more critical. I am curious whether there would be any effect if you were to increase the weight for the earlier tokens when calculating the survival probability.\n\n- DDD shares the same goal as your work: proposing the use of a Dynamic length, but is based on EAGLE2, whereas yours is based on EAGLE3. I would like to know if you have conducted experiments to verify how their method performs when applied to EAGLE3. Specifically, would your proposed improvements be more effective than theirs when both are applied to the EAGLE3 framework?\n\n- Why have the authors chosen not to report the Mean Accepted Length ($\\tau$) in the experimental results, as was done in the EAGLE3 paper? I am keen to see the results for this metric as well.\n\nI look forward to the authors' response and will adjust my score based on your clarification.\n\n[2] Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XSHqbiHd0U", "forum": "eZRPb52ccA", "replyto": "eZRPb52ccA", "signatures": ["ICLR.cc/2026/Conference/Submission8137/Reviewer_e5E2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8137/Reviewer_e5E2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910565656, "cdate": 1761910565656, "tmdate": 1762920107780, "mdate": 1762920107780, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}