{"id": "tlA3GKpMHT", "number": 15592, "cdate": 1758252958038, "mdate": 1759897297012, "content": {"title": "Dynamical Latent Flow Matching for High-Performance Few-Shot Neural Adaptation", "abstract": "The primary objective of brain–computer interfaces (BCIs) is to establish a direct connection between neural activity and external devices. However, variability in neural recordings poses significant challenges to maintaining stable neural decoding with minimal recalibration. \nExisting neural decoding frameworks often fail to enable efficient few-shot adaptation, typically due to the constraints imposed by prior assumptions on latent variables or issues with training instability. Motivated by the flexibility and tractability of diffusion models, we propose the novel Dynamical Latent Flow Matching (DLFM) framework for high-performance few-shot neural adaptation. Our DLFM performs flow matching in dynamical latent spaces, leveraging preserved neural dynamics within the neural manifold. The probabilistic flexibility of DLFM effectively captures intrinsic features of dynamical patterns across heterogeneous sessions, significantly enhancing few-shot neural adaptation. \nThe efficiency of DLFM for few-shot adaptation is validated on the Falcon benchmark, achieving competitive performance with only 60\\% calibration trials. \nFurther experimental evaluation on the Neural Latents Benchmark 2021 demonstrates that DLFM ranks among the top two for forward prediction tasks across all web submissions. \nAdditional interpretability analysis on the Lorenz attractor model and the Falcon dataset confirms that DLFM precisely identifies the intrinsic features of neural dynamics, thus facilitating efficient few-shot neural adaptation for neural decoding.\nOur DLFM framework emerges as a promising candidate for superior few-shot neural adaptation, advancing the practicality of real-world BCI systems.", "tldr": "", "keywords": ["Dynamical Latent Space", "Flow Matching", "Neural Adaptation", "Brain-Computer Interface"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/99aecaaf4230c028168d41d50b6b8e190427bd06.pdf", "supplementary_material": "/attachment/d6c71b216cb062d67eb627af265669d8660a1444.zip"}, "replies": [{"content": {"summary": {"value": "The authors suggest a new method to learn neural dynamics by applying flow matching in latent space to learn dynamics. Through real world benchmark neural recording data and synthetic data, the author demonstrates effective latent dynamics learning by the proposed method. By freezing the flow matching module that handles stochastic, unstable components in dynamics and fine-tuning encoder and feature extraction parts, the authors empirically show that such fine-tuning can focus on stable components of dynamics and thus improve data efficiency in calibrating new sessions. However, the suggested work shows high similarity of the previously published work and several caveats elaborated in Weaknesses and Questions should be resolved."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Successful application of well accepted flow matching to latent dynamic modeling of neural recordings.\n\n* Demonstration of effective forward prediction in several datasets learned by the proposed models.\n\n* Interesting few shot adaptation strategy which is empirically validated."}, "weaknesses": {"value": "* The flow matching idea is already applied and tested for latent neural dynamics and few shot adaptation by Wang et al., 2025 [1], with a very similar approach and goal (titled \"Flow Matching for Few-Trial Neural Adaptation with Stable Latent Dynamics\"). The novelty over this prior work should be sufficiently suggested, and the difference should be thoroughly analyzed. \n\n* The evaluation scheme seems incomplete. The only forward prediction is tested for Neural Latent Benchmark while the benchmark includes official behavioral decoding tasks. For Falcon benchmark, it is unclear why H1, H2, and B1 from the original dataset are not tested.\n\n* The results are mixed with other metrics. As shown in Table S5-8, the baselines are often better in other evaluation metrics. The “fp-bps” that shows the best results for the proposed model is only presented in the main paper and other inferior results are in the supplementary. The decision for this should be sufficiently explained to provide a fair viewpoint, otherwise all metrics should be presented upfront equally.\nIt will be better to provide more rationales on why stable dynamics can be learned by flow matching.  Currently, more of technical description of definition of the ideas is majorly described, but the main key idea that how the flow matching could contribute to learning stable dynamics is not well explained. As this claim is stated multiple times, having more detailed logical explanations will benefit the readers.\n\n* The paper lacks details on the baseline model implementation, especially on Falcon benchmark in Table 2. The reason for asking is that the numbers reported in the original Falcon paper (Table 1 in Karpowicz et al.) for the baseline model, NDT2, are different from those reported by the authors. More details are needed to fairly evaluate the results.\n\n[1] Wang et al., Flow Matching for Few-Trial Neural Adaptation with Stable Latent Dynamics. ICML 2025"}, "questions": {"value": "* While parameter efficiency is claimed, the number or proportion of the parameters that are fine-tuned is not well described. \n\n* In section 3.2.1, the target dynamical latent space is obtained following Rombach et al., 2022. I was wondering how the authors are following the original paper that used VAE (either quantized or not) for autoencoders. Moreover, this was for an image which doesn’t have any temporal dynamics in it. It is not well explained how the dynamical latent is achieved. \n\n* In Section 4.5 and Figure 5, I was wondering how the model comparison looks like if the person correlation is used since qualitatively, LFADS is producing more matching dynamics in Fig 5 (b).\n\n* In Table 2, how does the model behave with 10%, 20%, and 40% of the calibration data? Also, how do the baselines perform along those ratios from 10% to 100%? \n\n* The using 60% in M1 shows severe drop in performance, thus hard to say it is competitive. More explanation is needed on this claim."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "cWHJO58TIi", "forum": "tlA3GKpMHT", "replyto": "tlA3GKpMHT", "signatures": ["ICLR.cc/2026/Conference/Submission15592/Reviewer_zBHA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15592/Reviewer_zBHA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15592/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760971248951, "cdate": 1760971248951, "tmdate": 1762925865731, "mdate": 1762925865731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors designed a new model called Dynamical Latent Flow Matching (DLFM) for consistent, long-term motor decoding. Their model operates on latent neural dynamics using a flow-matching method. They benchmarked their model against other models on two different evaluation datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The study investigates an important question in the motor-decoding field and will have great value for applications such as BCIs.\n\nUsing flow matching in latent space is novel for motor decoding.\n\nDLFM achieves top-two performance in the NLB-2021 benchmark.\n\nDLFM achieves the best performance in the FALCON benchmark."}, "weaknesses": {"value": "The improvements of DLFM over other models in the NLB-21 benchmark are very small (Table 1) and only for one metric (fp-bps, Table S5-S8). In contrast, the performance gain in the FALCON benchmark is huge (Table 2). The authors have submitted their NLB-21 results to the EvalAI platform (Figure S1). Unfortunately, they haven’t submitted their FALCON results to the same EvalAI benchmark. I will increase my score once these results are uploaded to the platform and verified."}, "questions": {"value": "Do the authors use all the training data to train their model? I would like to know how their model performs with different numbers of training days, similar to Figure 3B of the SPINT paper (Le et al., 2025)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RnnUCi4NFZ", "forum": "tlA3GKpMHT", "replyto": "tlA3GKpMHT", "signatures": ["ICLR.cc/2026/Conference/Submission15592/Reviewer_ysBq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15592/Reviewer_ysBq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15592/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878981867, "cdate": 1761878981867, "tmdate": 1762925865320, "mdate": 1762925865320, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present a method for few-shot model adaptation applied to neural data using diffusion methods. They use flow-matching in a neural latent space. They evaluate on common neural data benchmarks for BCI decoding and in simple simulations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The overall framework is outlined nicely (good Fig 2 diagram, clear equations). \n- Datasets are standard benchmarks for motor BCI tasks (Falcon, NLB) and a fair number of model comparisons were implemented.\n- Ablation studies done are good."}, "weaknesses": {"value": "- Description of the method leaves it unclear as to which parts are novel and which are established in the literature. \n- Comparison methods are a bit out of date (LFADS, NDT) compared to other possibilities (POYO, NDT2 or NDT3). \n- Figure 1 and the problems in current models are not clearly described. What is negative transfer in Fig 1b? And training instability in Fig 1d? If these are problems the paper intends to solve, I would expect later figures to also use these metrics and prove the new approach improves them. \n- Number of fine-tuning trials axis being flipped compared to fine-tuning epochs is a bit hard to read. \n- Table 1 lacks any variance estimation or statistical comparison between models. \n- Table 2 has these but do not correctly identify when there is a statistically significant difference. \n- Figure 4 in ablation studies do not seem to have significant differences in R2 but show strong differences in bps; aka no diff in fine tuning but strong diff in model variant. It is confusing to have different metrics evaluated for different models."}, "questions": {"value": "- How does this method compare to Wang, P., Qi, Y., Wang, Y., & Pan, G. Flow Matching for Few-Trial Neural Adaptation with Stable Latent Dynamics. (ICML, 2025)? \n- Why was \"few-shot adaptation performance ... evaluated using bits per spike (bps) Pillow et al. (2008) for high-dimensional spiking prediction.\"? Why was R2 used in other cases? What can be learned about the model from these different metrics?\n- 5 ms bin widths were chosen. Is this standard? Other works use much longer bins (20-30 ms). \n- How are intrinsic features captured/quantified? R2 of lorenz dynamics isn't generalization to real data. \n- Does Fig 5c show significant differences? What is the interpretation of Fig 5d? Is Figure S2 supposed to be the Falcon dataset?"}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "details_of_ethics_concerns": {"value": "This seems somewhat similar to an already published paper accepted in ICML 2025: https://openreview.net/forum?id=nKJEAQ6JCY\nIt does cover new content but it's concerning to have text replicated (abstract, intro, ...). \n\nFor example, the first sentences are \"The goal of brain-computer interfaces (BCIs) is to establish a direct connection between the brain\nand external devices, offering promising avenues for neural rehabilitation in individuals with paralysis (Willett et al., 2021; Metzger et al., 2023; Willett et al., 2023).\" (this work) and \"The aim of Brain-computer Interfaces (BCIs) is to establish a direct link between the brain and external devices, presenting great opportunities for improving neural rehabilitation in individuals with paralysis (Willett et al., 2021; 2023;\nWu et al., 2016; Wang et al., 2023a).\" (Wang, 2025). \n\nSimilar figure styles (Fig 2) indicate perhaps coming from the same lab, which could explain some of the possible-plagiarism phrasing."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "I8qceJO8bT", "forum": "tlA3GKpMHT", "replyto": "tlA3GKpMHT", "signatures": ["ICLR.cc/2026/Conference/Submission15592/Reviewer_mhBV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15592/Reviewer_mhBV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15592/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952266432, "cdate": 1761952266432, "tmdate": 1762925864698, "mdate": 1762925864698, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors proposed a framework named the Dynamical Latent Flow Matching (DLFM), which works for addressing the challenges of few-shot neural adaptation in Brain-Computer Interfaces (BCIs) due to the drastic distribution shift recorded across sessions. Existing standard neural latent variable modeling methods like LFADS and Transformer-based MtM often suffer from performance degradation as they were not naturally built to maintain the robustness across sessions. DLFM relieves this  issue by performing conditional diffusio nmodel flow matching in the dynamical neural latent space, which leverages the stable dynamical patterns preserved within the neural manifold across the pre-training sessions and the fine-tuning sessions. \n\nIn the experimental section, the effectiveness of the proposed DLFM is evaluated on the wide-adopted NLB'21 benchmark with interpretable analysis."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The overall paper is well-written and in a concrete flow, the figures in the paper are vivid and illustrates the framework clearly.\n2. I think the use of diffusion flow-matching method here is a good contribution for the few-shot learning task in across-session neural data learning. As mentioned in the paper, diffusion models get rid of the unflexible VAE priors and also provides density estimation power through the SDE/ODE flow.\n3. The experimental results in the paper are solid across simulated Lorenz data and also the NLB'21 benchmark. The baseline comparisons are abundant."}, "weaknesses": {"value": "1. Flow-matching for modeling the dynamical latent dynamics itself seems not a too novel technique at this moment, the reason of choosing it and comparisons of it with some of its variants should be further clarified.\n2. A small arrangement notice of the text would suggest the algorithm 1 to be put in the appendix while putting more experimental results to the main text."}, "questions": {"value": "1. Could you tell us what's the key intuitive/motivation that the diffusion flow-matching would work well on the few-shot learning/domain adaptation tasks?\n\nI have no other questions, other concerns please refer to my Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mUO6dXPeCd", "forum": "tlA3GKpMHT", "replyto": "tlA3GKpMHT", "signatures": ["ICLR.cc/2026/Conference/Submission15592/Reviewer_nzks"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15592/Reviewer_nzks"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15592/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971042613, "cdate": 1761971042613, "tmdate": 1762925863910, "mdate": 1762925863910, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}