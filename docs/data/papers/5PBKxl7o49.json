{"id": "5PBKxl7o49", "number": 25414, "cdate": 1758367829966, "mdate": 1759896721945, "content": {"title": "Listens like Mel: Boosting Latent Audio Diffusion with Channel Locality", "abstract": "Latent representations critically shape diffusion-based audio generation. We observe that Mel spectrograms exhibit an approximate power-law spectrum that aligns with diffusion’s coarse-to-fine denoising, whereas waveform variational autoencoder (VAE) latents are nearly equal intensity along the channel axis. We introduce channel-span masking, which in expectation behaves like a rectangular window across channels and thus a low-pass filter in the channel-frequency domain, increasing channel locality. The induced locality steepens latent spectral slopes toward a power-law distribution and leads to up to 4× faster convergence of Diffusion Transformer (DiT) training on audio generation tasks, while maintaining reconstruction fidelity and compression. Experimental results show that the model performs comparably to, or better than, competitive baselines under the same conditions. Our code and checkpoint are available at \\url{https://anonymous.4open.science/r/lafa-F2A2}.", "tldr": "Channel span masking imposes mel-like spectral bias on high-compression VAE latents by acting as a low-pass window over channels, restoring power-law structure and delivering up to 4× faster Diffusion Transformer convergence.", "keywords": ["audio generation", "variational auto-encoder", "representation learning", "self-supervised learning"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e756b36f1a434cbaf885374a85d473e8e271d7df.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper shows that the latents of waveform VAEs do not well align with the Mel-spectrogram's approximate power-law spectrum, making it not suitable for training diffusion models. Authors proposed a channel-span masking bottleneck (LAFA) to improve the VAE latents, hence speeding up the convergence of diffusion-based audio generation models.\n\nAuthors conducted experiments on audio and music generation tasks to show the effectiveness of LAFA."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- An intuitive and lightweight method of speeding up the convergence of diffusion models for audio generation."}, "weaknesses": {"value": "- The paper is difficult to follow, the presentation and writing need to be largely improved.\n\n- Potential over-claims. Authors claimed that 4x fast convergence is achieved using LAFA, but no evidences provided. According to Figure  1, LAFA is not 4x faster in terms of the number of training iterations and FD performance.\n\n- The improvements brought by LAFA seems not consistent across the evaluation tasks. LAFA mostly introduces consistent improvements on one metric (FD_openl3), while the other results are mixing (Tab1 and Tab2). This is also true when looking at the reconstruction  performance (Table 4): SAO-VAE+LAFA performs worse than SAO-VAE in general."}, "questions": {"value": "- Table 1: I feel it is unfair to compare DiT-SAO-FC-AC with other baselines like SAO, which are not finetuned on AudioCaps. Am I misunderstanding something?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QZfuDzAlDZ", "forum": "5PBKxl7o49", "replyto": "5PBKxl7o49", "signatures": ["ICLR.cc/2026/Conference/Submission25414/Reviewer_Xq35"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25414/Reviewer_Xq35"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25414/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761820884453, "cdate": 1761820884453, "tmdate": 1762943426802, "mdate": 1762943426802, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "his paper identifies that VAE latent representations, unlike Mel-spectrograms, contain excessive high-frequency energy along the channel axis, which is detrimental to diffusion model training. To resolve this, it introduces Latent Flow MAE (LAFA), a plug-in module that applies channel-span masking to the VAE latent space. The authors theorize this acts as a low-pass filter, inducing a more favorable, Mel-like spectral bias. Experiments show LAFA accelerates Diffusion Transformer convergence on audio generation tasks and improves final performance without sacrificing reconstruction fidelity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- LAFA is an intuitive and simple plug-in module that demonstrably leads to faster convergence and better generation quality. Its modularity is a significant practical advantage.\n\n- The paper provides a theoretical justification for its method, framing channel masking as a low-pass filter. This offers a helpful intuition for why the approach is effective."}, "weaknesses": {"value": "- While quantitative metrics improve over the baseline, the practical significance of these gains is questionable. The qualitative results do not demonstrate a clear perceptual advantage over existing open-source models like MusicGen. Furthermore, the output quality lags significantly behind commercial state-of-the-art models (e.g., Suno), making the overall contribution feel incremental.\n\n- All experiments are performed on a single VAE architecture (SAO-VAE). Without tests on other diverse codecs (e.g., Mel-based VAEs, Encodec), the claim of general applicability is not fully substantiated.\n\n-  The paper lacks crucial ablations. It does not empirically compare the chosen span masking against simpler uniform masking, nor does it analyze the sensitivity of the model to the mask ratio, a key hyperparameter."}, "questions": {"value": "- Have you tested LAFA on VAE architectures other than SAO-VAE, such as the one from AudioLDM or an Encodec-style model, to verify its generalizability?\n- Could you provide an empirical comparison between contiguous span masking and random uniform masking of channels to justify your design choice?\n- How does model performance vary with different mask ratios? Is there an optimal range for this hyperparameter?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nN95vI9moZ", "forum": "5PBKxl7o49", "replyto": "5PBKxl7o49", "signatures": ["ICLR.cc/2026/Conference/Submission25414/Reviewer_awW2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25414/Reviewer_awW2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25414/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761913019282, "cdate": 1761913019282, "tmdate": 1762943426506, "mdate": 1762943426506, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the property of the latent space created by audio VAEs. The observation is that, if the latent space can be properly processed or regularized, the training of the audio generative model on this latent space will converge to a target performance faster or eventually results in better performance.\nThe proposed latent space processing/regularization method is called \"LAFA\".\n\nThe paper contains some interesting visualization of the latent spaces from different audio VAEs. Evaluations show that the proposed method can lead to SOTA or close-to-SOTA performance in either audio generation or music generation tasks.\n\nOverall, the paper is interesting and presents meaningful insights to the community. However, as a reader, I do feel some missing experiments, over claiming, and some confusing paper writings.\n\nI believe the paper is in the borderline for acceptance."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Visualization of latent space properties\n- Solid proposed method and evaluation results"}, "weaknesses": {"value": "### Minor issues\n- Missing experimental results\n    - Line 240: I cannot see the visualization of Mel features in Figure 3\n    - Line 416: I cannot find related information in Appendix\n- Wrong interpretation\n    - Line 411. The authors say \"LAFA consistently improves FDOpenL3 and KLPaSST for sound generation\". However, if we check table.1, before AudioCaps finetuning, the proposed DiT-SAO has worse metrics compared the SAO\n### Major issues\n- Lack of ablation studies on the hyper-parameters of LAFA\n    - LAFA masks out a part of the latent channels and then use Flow-Matching to recover the information loss. \n    - While the final masking strategy is mentioned in the paper, we don't how this strategy is designed, we don't know how sensitive LAFA is to the hyper-parameter of masking\n- Lack of ablation study on the masking idea itself\n    - The proposed method masks out a part of the latent channels, and then process the masked features with a Transformer encoder and a Flow-matching decoder: it is a denoising auto-encoder for the latent features!\n        - For a perfect denoising auto-encoder, the target is to reconstruct the clean input. In this paper, the decoded latent features exhibit different properties from the input, so it is not designed to be a perfect auto-encoder\n            - Hereby we have a question: which one has contributed more to the get the improved latent features, the mask or the Flow-matching decoding?\n            - We need ablation studies to anwser this question\n                - Bypass flow-matching, simply use MSE to train the auto-encoder\n                - Bypass masking, simple use the current encoder + Flow-matching decoder pipeline to process the latent features\n                - Is the encoder really needed? No experiment to prove it.\n- Missing of other experiments\n    - Figure 3 reveals that the latent space of a VAE with 64dim + LAFA (proposed method) looks similar to dim32\n        - Table.4 only compared the 64dim VAE with and without LAFA.\n        - Why don't we compare dim32 with dim64 + LAFA?\n    - Will dim128 makes the training of audio generation model more difficult? If so, why not present the results for dim128 + LAFA? \n        - I am asking this, because audio generation models can be well trained on 64dim latent space without LAFA (though I agree that LAFA makes this easier). I want to know if LAFA can convert a very difficult case such as dim128 or dim256 into a trainable latent space.\n        - Such experiments can emphasize the value of LAFA"}, "questions": {"value": "Please refer to my comments above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LvZydDWm4S", "forum": "5PBKxl7o49", "replyto": "5PBKxl7o49", "signatures": ["ICLR.cc/2026/Conference/Submission25414/Reviewer_hLGW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25414/Reviewer_hLGW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25414/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956706307, "cdate": 1761956706307, "tmdate": 1762943426264, "mdate": 1762943426264, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper makes the observation that audio spectrograms exhibit certain characteristics --- specifically a power law spectrum --- that do not get appropriately generated by diffusion models primarily because the latest space of VAEs do not accurately learn this characteristic. To fix this, the paper proposes a sequence of masking techniques which results in boosting the effect of channel locality, thereby better fitting the power law spectrum behavior. A side benefit is that this also speeds up the DiT transformer without compromising reconstruction and compression. Experimental results are good."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "-- The observation that the latent space learnt by VAEs often exhibit amplified high frequency energy along the channel axis, thereby deviating from the Mel power-law bias, is certainly an interesting observation. If this observation holds, meaning that it is fundamental to any VAE and not an outcome of some hyper-parameter choice, then this is a fundamental observation and remedies to this (some of which are proposed by the paper) should be an important boost to audio generation performance. \n\n-- The masking idea is intuitive in the sense that the VAE is forced to learn a specific time-frequency bucket from the neighboring buckets, forcing locality and smoothness. Causality can also be enabled by designing the masks appropriately. \n\n-- Some parts of the paper are amazingly clear, while other parts are sort of the vice versa (and these parts seem interspersed). \n\n-- The theoretical analysis is pointing to an interesting observation but I may not have fully understood the inpainting part of the argument. I need to think more here, however, I see that authors are trying to demonstrate that the masking indeed leads to a low-pass filtering effect, which justifies why LAFA is able to preserve more energy in the lower frequencies. Is that the main point here? \n\n-- Experiment results are quite good in some settings."}, "weaknesses": {"value": "-- A point that is bothering me is why is it that VAEs are not able to learn the MEL behavior. If one designs a loss function over a spectrogram and ensures adequate weights for the reconstruction loss, the VAE should learn to invest energy in the power-law pattern. I might be missing something here. \n\n-- The paper could better motivate various design choices (or at least explain them better). All the descriptions around Fig 4 is a bit quick and unclear. Section 4.1 has many parts that are unclear. \n\n-- The paper seems to have a lot of typos. Fig 3 is referred to, where the authors probably meant Fig 2. S(f) is not defined in L192. The flow of presentation can be much better. \n\n-- The presentation of the experiment section is confusing. Between row 4 and 5, is the gain due to LAFA or due to FT-AC? If MelVAE is better, why is LAFA needed? CLAP score seems to degrade in Table 2. In several cases of Table 3, seems like the gain from LAFA is almost negligible. \n\n\n\n-- I am trying to understand why the masking technique, in the space of design choices to address the problem, is the correct one. Or at least, why did authors decide to adopt this approach? I do see that masking is bringing the VAE output closer to the MEL behavior, so I"}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "YpBEzgtqP8", "forum": "5PBKxl7o49", "replyto": "5PBKxl7o49", "signatures": ["ICLR.cc/2026/Conference/Submission25414/Reviewer_DYP6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25414/Reviewer_DYP6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25414/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958771220, "cdate": 1761958771220, "tmdate": 1762943425966, "mdate": 1762943425966, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}