{"id": "tPKzNHV07m", "number": 20261, "cdate": 1758304219004, "mdate": 1763743994120, "content": {"title": "Discovering Generalizable Governing Equations for Graph Dynamical Systems with Interpretable Neural Networks", "abstract": "The discovery of symbolic governing equations is a central goal in science; yet, it remains a formidable challenge, particularly for graph dynamical systems, where the network topology further shapes the system behavior. While artificial intelligence offers powerful tools for modeling these dynamics, the field lacks a rigorous comparative benchmark to assess the true scientific utility of the discovered laws. This work establishes the first rigorous benchmark for this task, moving beyond simple fitting metrics to evaluate discovered laws based on their long-term stability and, critically, their out-of-distribution generalization to unseen graph topologies. We introduce the Graph Kolmogorov-Arnold Network (GKAN-ODE), an architecture tailored for this domain, and propose a structure-aware symbolic regression method to leverage its inherent interpretability. Across a suite of synthetic and real-world graph dynamical systems, we demonstrate that symbolic models extracted from neural architectures, particularly our GKAN-ODE, achieve state-of-the-art performance and generalize to unseen networks, significantly surpassing existing baselines. This work presents the first systematic benchmark in this domain, clarifying the expressivity-interpretability trade-offs and offering a  pathway from observational data to fundamental physical understanding, providing a critical new tool for data-driven discovery in network science.", "tldr": "ML-driven equation discovery of graph dinamical systems, with a fair comparison and focus on interpretable models (KAN).", "keywords": ["Equation Discovery", "Kolmogorov-Arnold Networks", "Graph Dynamical System", "Interpretable AI", "Network Dynamics", "AI4Science"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e8966b4a1cf750ad0f56ced3aad6bccb5162ed83.pdf", "supplementary_material": "/attachment/5e64fb69c4b9a91815bf27994a941ce5039b27f0.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the challenge of discovering symbolic governing equations for graph dynamical systems directly from observational data. The authors propose a novel architecture, the Graph Kolmogorov-Arnold Network (GKAN-ODE), which adapts KANs for this task by modeling self-dynamics and interaction dynamics separately. The model is enhanced with internal multiplicative nodes to better capture physical interactions. To extract human-readable formulas, the paper introduces a principled, structure-aware \"Spline-Wise\" (SW) symbolic regression algorithm. The authors establish a rigorous benchmark, evaluating GKAN-ODE and other baseline methods on synthetic and real-world epidemic datasets. The core findings demonstrate that neural-based models, particularly GKAN-ODE, significantly outperform sparse regression methods in long-term stability and generalization to unseen graph topologies, successfully recovering ground-truth equations while being more parameter-efficient."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Comprehensive and Rigorous Benchmarking. The paper establishes a high-quality benchmark that addresses a clear gap in the literature.\n2. Novel and Well-Motivated Method. The proposed GKAN-ODE framework is technically sound and introduces several valuable innovations.\n3. Principled Symbolic Distillation and Interpretability Analysis. The paper offers a thoughtful approach to extracting and analyzing symbolic models."}, "weaknesses": {"value": "I am not familiar with this field, and my expertise is insufficient to critique the article or offer suggestions."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "yHfAn7Fkyc", "forum": "tPKzNHV07m", "replyto": "tPKzNHV07m", "signatures": ["ICLR.cc/2026/Conference/Submission20261/Reviewer_jmyg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20261/Reviewer_jmyg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20261/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760975198934, "cdate": 1760975198934, "tmdate": 1762933743876, "mdate": 1762933743876, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Statement"}, "comment": {"value": "We **gratefully thank** the anonymous **reviewers Usk1, K8qq, s6hu**, and **jmyg** for the time invested in reviewing our manuscript and for their insightful, constructive feedback. The reviews have been instrumental in identifying areas where we could strengthen our contribution and clarify the unique positioning of our GKAN-ODE framework.\n\nA mutual concern raised across reviews involved the **robustness of our evaluation metrics** (specifically regarding noise and derivative estimation) and the **complexity of the task** itself compared to non-graph settings. To address these points and empirically verify our claims, we have conducted extensive additional analyses and revisions:\n\n*   To quantitatively demonstrate the necessity of incorporating graph topology and to clarify the difficulty gap between graph-based and standard dynamical systems, we implemented a new **graph-agnostic baseline, MLP-ODE** (suggested by **Reviewer s6hu**). The results (updated Figure 1) show that ignoring topological information leads to a catastrophic increase in error, confirming that this task is non-trivial and requires specific graph-aware architectures like GKAN-ODE.\n*   We significantly **deepened our robustness analysis**. We implemented a **polynomial interpolation denoising** strategy following *Rudy et al. (2017)* to demonstrate stability under high noise up to 20dB (requested by **Reviewer K8qq**). Additionally, we performed an **ablation study on derivative estimation**, comparing the 5-point stencil vs. Central Finite Differences (requested by **Reviewers s6hu and K8qq**), confirming that our model rankings are stable and not artifacts of pre-processing.\n*   We improved the presentation by adding a comprehensive **framework pipeline figure** in Appendix B.2 (requested by **Reviewer K8qq**) to illustrate the information flow. We also expanded the experimental comparison to include the **original KAN symbolic algorithm** (suggested by **Reviewers s6hu and Usk1**), demonstrating that our proposed Spline-Wise method achieves a superior trade-off between accuracy and complexity.\n\nWe have marked all major revisions in the updated manuscript in $\\color{blue}\\text{blue}$. Additionally, for improved readability and to facilitate the verification of our new results, we have **integrated the Appendix directly at the end of this PDF document**, rather than keeping it as a separate supplementary file.\n\nWe believe these new experiments and clarifications provide the evidence requested by the reviewers, and we look forward to a fruitful discussion."}}, "id": "sinERFJaHO", "forum": "tPKzNHV07m", "replyto": "tPKzNHV07m", "signatures": ["ICLR.cc/2026/Conference/Submission20261/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20261/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20261/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763744321659, "cdate": 1763744321659, "tmdate": 1763744321659, "mdate": 1763744321659, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper focuses on the task of discovering governing equations in dynamical systems on networks.\nIn particular:\n- It introduces GKAN-ODE, a method based on KAN, adapted for graph data (with static topology), and where the authors introduced multiplicative nodes.\n- It introduces a symbolic regression algorithm, SW, that extracts a symbolic equation from a trained KAN.\n- It compares GKAN-ODE with other methods, namely TPSINDy, LLC, and a method based on MLPs, GMLP-ODE.\n- In doing so, it offers a benchmark to study and compare such methods.\n\nThey argue that GKAN-ODE, by exploiting the interpretability naturally inherent in the KAN, offers an accurate and transparent method for studying complex systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**Originality**\n\nAs far as I know, the new elements introduced in this paper are indeed original:\n- the GKAN network, with multiplicative nodes,\n- and the spline-wise symbolic regression algorithm to retrieve the symbolic equation from the trained model.\n\n**Quality**\n\nThe methodology and evaluation are sound, with no overemphasised claims, and good support of ablations and experiments over diverse methods and datasets.\n\n**Clarity**\n\nThis is one of the clearest papers I have read in a while: the discussion flows in a very logical way, and I haven't spotted any typos.\n\n**Significance**\n\nThe studied problem is interesting and relevant. This work offers a solid and sound overview of some state-of-the-art methods, even without considering the authors' own contribution on the topic, this element would already make it significant."}, "weaknesses": {"value": "Here I list some concerns I have, in no particular order:\n\n1. As stated already in the title, this work focuses on discovering governing equations for graph dynamical systems. I believe a better effort could have been made to clarify how much more difficult this task is compared to the case with no graph. \n2. This work tries to find a difficult balance between proposing a new method and offering a benchmark of existing ones. In some parts, one has the impression that the authors used this approach to counter the limited results achieved on their proposed method.\n3. In relation to point 2 above, it's a bit unclear what the advantage of the proposed spline-wise symbolic regression algorithm is. By looking at the results in Figure 1 (left), it's difficult to advocate for its use instead of GP. Table 2 also doesn't show encouraging results, both when compared with Table 1 and with Table 12. \n4. The authors argue that the cost above is balanced by a \"more direct\", \"more faithful\", \"granular\", \"fully transparent\" view of what the model learned. I understand that interpretability is tricky to measure, but I think these points should be better supported. In the field of discovering governing equations, it seems that the only way is to check if the discovered equations align with the ground truth, and the results seem to suggest that SW has the worst alignment. It doesn't help that the comparison to the original SR method by KAN's authors has only been included in the appendix. \n5. The addition of multiplicative nodes is justified solely via experiments."}, "questions": {"value": "Referring directly to the weaknesses listed above:\n1. Paragraph 4.2 shows that you validated the different methods also by changing the topology of the datasets. How did you do it? Could you maybe add to your benchmark methods that don't make use of the graph at all?\n3. In paragraph 5.2, you argue that the coefficients obtained with SW are \"*slightly* different\", or that you get \"additional *small*-coefficient terms\", but, given that SW achieves worse MAE, can we really say that these errors are small?\n4. Concerning the interpretability advantage of KAN+SW: \n  - I recommend expanding on why this approach improves interpretability and giving more substance to the above claims. \n  - Considering how the interpretability point was made, it seems that there is an overlap: the output of the method serves both to measure its performance and also to justify how interpretable the model itself is. Usually, in XAI, one measures the interpretability of a model by relating the output to the input. Is a similar approach viable here? For example, by linking the presence of some symbolic terms in the discovered governing equation to some features of the input?\n  - I recommend adding the results of Table 10, where they lie without a direct comparison, to Figure 1.\n5. The addition of multiplicative nodes is justified solely via experiments. Could you offer a theoretical justification too?\n\n\n\nTwo extra questions:\n\n6. You use the five-point stencil method to build the time derivative of the trajectories. Have you performed an ablation on this? Since the $\\text{MAE}_\\text{traj}$ metric depends only on the trajectory itself, not on its derivative, I was wondering how robust these methods are when changing the way to estimate the derivative.\n7. Have you considered using a KAGNN (*Bresson et al.*) in (2) instead of a simple KAN?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IHHh5StEdS", "forum": "tPKzNHV07m", "replyto": "tPKzNHV07m", "signatures": ["ICLR.cc/2026/Conference/Submission20261/Reviewer_s6hu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20261/Reviewer_s6hu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20261/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834115330, "cdate": 1761834115330, "tmdate": 1762933743295, "mdate": 1762933743295, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work focuses on graph dynamical systems (GDS) and proposes a novel GKAN-ODE framework that integrates Kolmogorov-Arnold Networks (KAN) with neural differential equations. Combined with an interpretable Spline-Wise symbolic regression pipeline, this framework enables the automated discovery of universal governing laws underlying graph-structured dynamical systems."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-By leveraging the spline-based structure of the KAN model and the white-box interpretability of the Spline-Wise mechanism, the proposed method successfully transforms deep network representations into interpretable symbolic expressions, which helps reveal the model’s internal learning dynamics.\n\n-To promote reproducibility and support open science, all code and experimental configurations associated with this work have been publicly released."}, "weaknesses": {"value": "-The current version of the paper lacks an intuitive illustration of the overall architecture. A well-structured framework figure would greatly enhance the presentation by clarifying the relationships and information flow among different components of the proposed model.\n\n-The core evaluation relies on numerical integration to obtain X^(t) and compute MAEtraj(Eqs. 5–6). Since this process is autoregressive, the accumulated error may vary with the integration step size and the choice of integrator. However, the paper does not provide an analysis of integrator robustness, leaving the stability and reliability of the results insufficiently validated.\n\n-The authors propose \"multiplicative nodes without hyperparameters\" to enhance physical interaction modeling, but they lacked a visual analysis of why it is superior to LLC/GMLP.\n\n-The noise robustness analysis is not in-depth enough. The experimental design includes noise versions of different SNRS, but the systematicness of the derivative estimation and anti-noise mechanism in the paper is relatively limited.\n\n-From the experimental results in Figure 1, it can be seen that the GKAN-ODE-SW method is not as good as GKAN-ODE-GP, failing to demonstrate the effectiveness of the proposed method in handling graph dynamical systems."}, "questions": {"value": "Q1：To what extent does the long-term rollout error depend on the choice of numerical integrator and step size? While the paper reports overall evaluation results, why are the detailed experimental settings—such as the integrator type, step size, or tolerance—omitted?\n\nQ2：Given that the primary metric MAEtraj relies on numerical integration, would different integrators (e.g., RK4, DOPRI) or step-size configurations change the ranking of model performance? Has the sensitivity of this metric to the integration method been analyzed?\n\nQ3：In the synthetic tasks, the authors use OOD sets with varying topologies and initial conditions for selecting the final symbolic expressions, whereas in the real epidemic scenario, model selection is performed only on the training set due to the lack of OOD data. Has the potential “model selection bias” between these two settings been examined? \n\nQ4: The authors emphasize that MAEtraj is independent of the ground-truth equations and, therefore, more stringent due to error accumulation. Could the authors provide a correlation analysis between MAEtraj and MAEeul to show which metric better aligns with scientific correctness when their results diverge?\n\nQ5：What is the impact of the proposed KAN architecture on the experimental results? Furthermore, please provide a detailed description of its specific implementation in the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "86XwnAPBf9", "forum": "tPKzNHV07m", "replyto": "tPKzNHV07m", "signatures": ["ICLR.cc/2026/Conference/Submission20261/Reviewer_K8qq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20261/Reviewer_K8qq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20261/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892667939, "cdate": 1761892667939, "tmdate": 1762933742982, "mdate": 1762933742982, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This is a nicely written paper that uses a multi-step learning process and new architecture to learn symbolic differential equations. They then try to extract symbolic structure from their learned network as well as a few alternative networks. They try this approach on a few symbolic ODEs on networks to define a benchmark set."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Their goal is valuable: interpretability for graph-structured ODEs. I also appreciate that they're trying fundamentally different architectures with edge nonlinearities instead of node nonlinearities. I think their tasks are reasonable targets."}, "weaknesses": {"value": "Overall I'm sympathetic to the concept but I have multiple major concerns.\n\n1) I think they overstate the importance of their benchmarks. It’s a limited set of tasks. These are fine tasks, I don’t object at all, but I would not elevate them to the level of a rigorous benchmark that makes its own contribution.\n\n2) They talk about the greater interpretability of their GKAN networks, but if I understand correctly, they are really doing a non-symbolic fit with a different architecture, then using symbolic regression to distill their model. They do the same thing for other models too, and again get symbolic expressions that have similar complexity and performance. So it’s unclear what the advantage of their approach is. Their claim is that somehow putting nonlinearities on edges rather than nodes is valuable, but I don’t see evidence for this.\n\n3) If they’re targeting symbolic nonlinearities, why not just use symbolic nonlinearities as their basis functions, instead of using splines as intermediaries?\n\n4) They explore a particular family of composition, sums and products. This is creeping toward both node nonlinearities, and toward directly fitting symbolic structure. So it seems like they’re trying to have it both ways: “let’s use edge nonlinearities instead of node nonlinearities — except for here.” And “let’s fit neural networks and then later find symbolic structure — except for here.”\n\n5) I don’t understand why their Spline-wise regression is unique to KANs. They’re just ways of fitting a symbolic function to another function, and that should work for general functions as well as for splines.\n\nOverall, this is a reasonable approach, but I’m not convinced that it’s a substantial advance. I may be mistaken about any of these points, and I’m happy to be corrected."}, "questions": {"value": "What is the main contribution here? Am I missing a substantive performance difference or improvement in interpretability from the GKAN versus the GMLP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UyURE8OPhO", "forum": "tPKzNHV07m", "replyto": "tPKzNHV07m", "signatures": ["ICLR.cc/2026/Conference/Submission20261/Reviewer_Usk1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20261/Reviewer_Usk1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20261/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916753349, "cdate": 1761916753349, "tmdate": 1762933742624, "mdate": 1762933742624, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}