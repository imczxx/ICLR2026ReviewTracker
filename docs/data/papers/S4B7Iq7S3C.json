{"id": "S4B7Iq7S3C", "number": 16716, "cdate": 1758268019878, "mdate": 1759897223153, "content": {"title": "Model-Guided Microstimulation Steers Primate Visual Behavior", "abstract": "Brain stimulation is a powerful tool for understanding cortical function and holds the promise of therapeutic interventions to treat neuropsychiatric disorders such as impaired vision. Prototypical approaches to visual prosthetics apply patterns of electric microstimulation to the early visual cortex and can evoke percepts of simple symbols such as letters. However, these approaches are limited by the number of electrodes that can be implanted in early visual regions. Instead, higher-level visual regions are known to underlie the representations of complex visual objects such as faces and scenes and thus constitute a promising target for stimulating the cortex to elicit more complex visual experience. We developed a computational framework composed of two main components to address the challenge of stimulating cortex in high-dimensional object space spanned by higher-level visual cortex: 1. a causally predictive model that predicts primate behavior from image and stimulation input via topographic models and perturbation modules. 2. a mapping procedure that translates optimal model stimulation sites to monkey cortex. Testing our approach in two macaque monkeys that perform a visual recognition task, our results suggest that model-guided microstimulation is a promising approach to steer complex visual behavior. This proof-of-principle establishes a foundation for next-generation visual prosthetics that could restore complex visual experiences by stimulating higher-level visual cortex.", "tldr": "Topographic brain models with perturbation modules predict monkey behavioral responses in a visual recognition task.", "keywords": ["causal interventions", "topographic deep artificial neural networks", "brain modeling"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5d690e0e490ee0684cc366cac72d4ab3989aa85a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors introduce a framework for guided microstimulation of the high-level visual cortex.  The authors use brain-aligned, topographic image-models as in-silico models of the brain, and prototype in-vivo microstimulation experiments based on in-silico observations.  Applying these prototype experiments in two macaque monkeys, the authors observe positive correlations between model-predicted behavior and observed monkey behavior.  The authors further report qualitative similarities between perceptions predicted by the model following microstimulation and those that have been previously reported by humans."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- Authors address an important open question in the neural engineering space: how to simulate neural stimulation of the visual cortex and perceptual outcome.\n- All in-silico modeling is grounded in realistic (at least, most realistic for current state of the art) modeling of microstimulation (current spread, etc.) and cortical organization (through TDANNs)\n- In experiment 1, positive correlations were observed between in-silico and in-vivo behavior changes with and without stimulations.  This provides evidence for the utility of such a closed-loop framework for studying perceptual effects of micro-stimulation.\n- In experiment 2, stimulation parameters that were predicted to be effective by the modeling framework contributed to greater changes in AUC.  If results like this can be replicated in more studies, current work in microstimulation for visual perception could benefit greatly from this experimentation strategy."}, "weaknesses": {"value": "- Simulating electrode placement and alignment with each model is unclear to me.  How are different positions of an array mapped onto a 512x7x7 latent space of a model?  Since each Utah array has 96/64 electrodes, does one spatial dimension of the latent space map to multiple electrodes?  What are the limitations of this?\n- Correlation between model and monkey behavior diminishes in experiment 2.  Further discussion about potential reasons for this (e.g., is it because the TDANN is failing to predict activity accurately, too much noise in the in-vivo neural signal, etc.)  would be valuable.\n- Qualitative visualizations of in-silico perceptual effects of perturbation are an interesting proof of concept but leave many open questions in terms of how perception should change with stimulation.  For example, in Figure 5, why does a second cat face appear in the picture of a cat while the single bear face enlarges in the bear picture (as opposed to the cat’s face enlarging or another face forming on the bear, for instance)?"}, "questions": {"value": "- Is it necessary that multiple models are used in the mapping procedure?  What is the variability in site predictivity between these different models?\n- What was the average predictivity (e.g., correlation) between model-simulated neural site activity and measured in-vivo activity to the passive-viewing images? How do you think results may change when using models that are less/more predictive of neural activity in the brain?  Can this be quantified post-hoc?\n- As suggested, TDANNs are seemingly critical for microstimulation modeling due to current spread to neighboring neurons.  How big of a role does this play in the models evaluated in this work?  Do non-TDANN models similarly have positive behavioral correlations with the monkeys (or with the TDANN models)? This supplemental analysis could quantitatively ground the choice for TDANN models in such a framework."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lYPY328jk4", "forum": "S4B7Iq7S3C", "replyto": "S4B7Iq7S3C", "signatures": ["ICLR.cc/2026/Conference/Submission16716/Reviewer_pN2f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16716/Reviewer_pN2f"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16716/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760992560376, "cdate": 1760992560376, "tmdate": 1762926768087, "mdate": 1762926768087, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "### Summary\n\nThe authors link the neuronal responses in monkey visual cortices to topographical ANN, and GAN latent space, and then using the in silico model to screen for effective experimental design that stimulation will have strong perceptual effect. Although the net perceptual effect of model predicted perturbations is not super strong, the model could in some case predict which image x perturbation site has stronger behavioral bias. \n\nAlthough many components of the pipelines (Topographic ANN, perturbation model, GAN visualization, linking) have been established before, this is still a nice combination of all of them, and a stress test of all the components. Overall, it is a worthy addition to the literature, esp. the behavior modulation effect, and future works can build on top of it!"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "### Strength\n\n- Predicting the perceptual effect of visual cortical stimulation is an important and hard problem in neuroscience, and one with significant translational application value.\n- Many previous model optimized stimuli study only touches on manipulation of neuron firing, but this work advanced this direction in predicting the stimulation effects on behavior.\n- The authors did a very comprehensive work with statistical rigor, and being very honest about many weaker effects and none effects. Kudos on that!"}, "weaknesses": {"value": "### Weakness\n\n- **Clarity of the method**\nI feel part of methods is too vague from the current main text.\n    - Figure 6,7,8 are very clear and informative, moving some details from them to Figure 1 and Figure 2 will be great, currently Figure 1,2 are a bit too high level, and could be compressed a bit.\n    - The topological ANN part is quite detailed in the text, maybe too detailed, but GAN, the regression method and other parts are much less so.\n    - I feel mentioning and describing the task of monkey is quite important in the main text. Otherwise i don’t understand the stimulation, the sequence and perception paradigm.\n- The behavior bias seems to be relatively small and non-robust. (Fig. 4) Although, we all know monkey behavior is very noisy and hard to get large effect size, so it is what it is."}, "questions": {"value": "### Questions\n\n- Why perform linking between CNN model and brain based on GAN images instead of natural image samples? is it because the available latent codes make the visualization easier?\n- Which GAN did you use? There seems to be no details about it in the appendix. The architecture, training data etc. of GAN are critical and worth mentioning, since those are the prior of your visualization. Are they some StyleGAN2?\n    - One reason I ask is that the latent space of many GANs have intriguing geometric structures [^0,^1], so in some cases perturbation along random ish direction could produce perceptually relevant change in images, as long as it has non zero inner product with those interpretable direction.\n    - Because of it, you may want to do some random perturbation as control for Figure 5 visualization and see if they are still this interpretable.\n\n[^0]: Voynov, & Babenko, (2020). Unsupervised discovery of interpretable directions in the gan latent space, ICML\n\n[^1]: Wang, & Ponce, (2021). The geometry of deep generative image models and its applications. ICLR\n\n- Regarding the link between GAN latents and visual neural code, i feel the authors could discuss more on the related works from the Ponce et al. threads. For example, the alignment of neuronal tuning in higher visual cortices with the latent space of different GANs (DeePSim & BigGAN), which allow the neurons to steer the latent codes of GAN and generate images that maximize their activations [^2, ^3]. I feel this is one of the bases for the GAN visualization method besides Papale 2024. In those approaches, they also found some behavioral effect of the images that optimize neuron activation in GAN space [^4].\n\n[^2] Wang, Ponce, 2024, **Neural Dynamics of Object Manifold Alignment in the Ventral Stream** https://www.biorxiv.org/content/10.1101/2024.06.20.596072v1.abstract\n\n[^3] Wang, B., & Ponce, C. R. (2022). Tuning landscapes of the ventral stream. *Cell reports* [https://www.cell.com/cell-reports/fulltext/S2211-1247(22)01460-7](https://www.cell.com/cell-reports/fulltext/S2211-1247(22)01460-7) \n\n[^4] Rose, O., Johnson, J., Wang, B., & Ponce, C. R. (2021). Visual prototypes in the ventral stream are attuned to complexity and gaze behavior. *Nature communications* \n\n- Why generating sequence of 7 images and requiring the image sequence to have monotonic effect? What’s the conceptual interpretation of it? Is that the authors are hypothesizing the effect of stimulation at various strength is equivalent to this sequence of image?\n- What do we make of the null result in Sec. 4.2? Isn’t it that more stimulation sites should make a stronger correlation?\n- Sec. 4.3 is very cool visualization, although we don’t have evidence that those are what monkeys actually perceive right? This is not an objection to the paper. \nI think Afraz lab, has more extensive work testing the perceptual effect of stimulation, and it’s quite an expensive loop to validate these prediction (c.f. Perceptogram https://www.nature.com/articles/s41467-024-47356-8).\n- Simulation of biological variability “To approximate biological variability and thus mimic trials, we therefore consider multiple GAN-generated sequences that are all optimized to modulate activity at the same monkey stimulation site. Each distinct sequence constitutes an in-silico trial, and averaging across these sequences provides a model analogue of the across-trial variability observed in the animal.”\n    - It’s curious the authors simulate the neuron and choice variability by different image sequences generated by GAN. Admittedly this is a tractable way to generate variance, what’s the interpretation of it? Why not have some drop out / stochasticity in the topographical ANN?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N.A."}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "e46VTCDohd", "forum": "S4B7Iq7S3C", "replyto": "S4B7Iq7S3C", "signatures": ["ICLR.cc/2026/Conference/Submission16716/Reviewer_cYUD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16716/Reviewer_cYUD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16716/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789217366, "cdate": 1761789217366, "tmdate": 1762926767637, "mdate": 1762926767637, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a practical pipeline for model-guided microstimulation of macaque inferior temporal (IT) cortex that links: 1) a spatially explicit perturbation module that translates microstimulation parameters to local activity changes, 2) topographic DNNs aligned to each animal’s IT array via passive-viewing data, and 3) a mapping that projects model-optimized sites back to electrodes for in-vivo testing. In Experiment 1, per-site model predictions of behavioral bias in a 2AFC recognition task correlate with stimulation-evoked shifts in both monkeys, although mean shift is not above zero. In Experiment 2, the authors observe a significant stimulation-driven bias in one monkey but the per-site correlation vanishes. They also visualize in-silico \"facephene-like\" effects by mapping perturbed model states into a GAN latent space. Together this is pitched as proof-of-principle that topographic models can steer causal interventions in higher-level vision."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Originality: Introduces a prospective, model-in-the-loop pipeline that uses animal-specific topographic alignment to guide microstimulation in IT. Integrates a spatial perturbation module with a topographic DNN and adds generative reconstructions for interpretable inspection. This combination is new in the context of causal tests in higher visual cortex.\n* Quality: Implements a clear alignment procedure on passive-viewing data, then prospectively tests model-chosen site-stimulus pairs in primates. Reports statistics transparently and separates exploratory modeling from in-vivo confirmation. The overall methodology is careful and reproducible in principle.\n* Clarity: Explains the 3-stage workflow with readable figures and step-wise descriptions. The mapping from electrodes to model units and the procedure for stimulus selection are described in sufficient detail to follow.\n* Significance: Provides a practical blueprint for using topographic models to steer causal interventions in the ventral stream. Establishes a path toward systematic, theory-driven stimulation studies."}, "weaknesses": {"value": "* The paper does not deliver both a significant mean effect and reliable per-site predictivity within the same experimental setting. This weakens the claim that the same model instance robustly predicts and drives behavior\n* The authors report r values but not R2. For the combined correlation r=0.53, the model explains about 28% of the variance in stimulation-evoked behavioral shifts. This should be stated with confidence intervals and compared to baselines. There is also no estimate of the fraction of neural variance captured by the perturbation module in IT units\n* The current-distance form is sensible, but the paper does not report sensitivity analyses over decay constants, gain factors, clipping, or non-linearities that are known to matter in IT microstimulation. Readers need to know whether the observed behavior is robust to these choices\n* Helpful for intuition, but there is no quantitative link to percept reports or neural selectivity beyond anecdotal examples\n* Stimulation of IT is unlikely to yield stable, retinotopically anchored phosphenes or letter-like percepts. At best it may bias category representations, consistent with facephene overlays, which limits near-term translatability to clinical visual prostheses that aim for placeable, compositional percepts. The paper should temper scope and clarify that this is about biasing recognition, not restoring structured visual qualia"}, "questions": {"value": "* What fraction of observed neural variance at and around the stimulated sites is captured by the perturbation module when fitted to pre-stimulation passive-viewing data?\n* How stable is the model-brain alignment across days. If the passive-viewing alignment is from 2 to 4 days prior, what is the drop in predictivity if reused without re-alignment?\n* Can you include ablations over decay constant, gain, clipping rmax, additive vs multiplicative perturbations ...? Which parameters most strongly affect predicted \\Delta AUC?\n* For Experiment 2, do you have sham-only and random-site controls matched in number of trials? Was there a pre-registered stopping rule or power analysis?\n* Please clarify the intended prosthetic use case. IT stimulation may bias recognition choices rather than evoke stable object percepts. Can you propose measurable milestones that connect this method to clinically meaningful endpoints?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "224kcwXwV4", "forum": "S4B7Iq7S3C", "replyto": "S4B7Iq7S3C", "signatures": ["ICLR.cc/2026/Conference/Submission16716/Reviewer_LktB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16716/Reviewer_LktB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16716/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761857174612, "cdate": 1761857174612, "tmdate": 1762926767080, "mdate": 1762926767080, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a model-guided microstimulation framework that combines topographic deep neural networks (TDANNs), in-silico perturbation modeling, and primate behavior testing to steer visual recognition behavior in macaques. The authors target higher-level visual cortex (IT) instead of early visual areas to evoke complex object-level percepts, bypassing the limitations of traditional retinotopy-based prosthetics. They demonstrate that model-predicted stimulation sites and image sequences can bias perceptual choices in a 2AFC task, and that simulated stimulation of face-selective sites qualitatively reproduces human-like facephenes. This is a proof-of-concept for closed-loop, model-driven neural intervention in vision."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Originality: First to use topographic ANNs to prospectively guide microstimulation in IT cortex, moving beyond retinotopy-based V1 stimulation.\n\nQuality: Rigorous model-brain alignment, GAN-based stimulus generation, and behavioral validation with correlation analysis and effect size reporting.\n\nClarity: Extremely well-structured, with intuitive visuals, clear task design, and accessible neuroscience context.\n\nSignificance: Opens a new path for next-generation visual prosthetics targeting object-level percepts, and establishes a model-in-the-loop framework for causal neural control."}, "weaknesses": {"value": "1.Sample size & signal degradation: Only 2 monkeys, with one excluded from Exp 2 due to signal loss, limiting statistical power and generalizability.\n\n2.Model correlation drops in Exp 2: While behavioral bias is induced, the per-site correlation between model and monkey behavior disappears (r = 0.09), raising questions about robustness and model generalization.\n\n3.Lack of control ablation: No random stimulation baseline or non-selective site control to rule out generic attention or arousal effects.\n\n4.Stimulation parameters fixed: Only one current level (50 μA) and single-site stimulation tested; no dose-response or multi-site exploration.\n\n5.Model variability not explored: Only one TDANN instance is used for mapping; no ensemble or uncertainty quantification across model initializations."}, "questions": {"value": "1.Why did the model-behavior correlation collapse in Exp 2? It seems that the experimental results are not satisfactory. What were the author's remedial measures?\n\n2.Was any other stimulation baseline run? The choice of the baseline of \"no stimulation\" in this article is too weak. It is insufficient to prove the effectiveness of the method proposed in this article.\n\n3.How do you rule out that the observed bias is not due to generic attention or arousal from microstimulation? Welcome the author to share their thoughts.\n\n4.Why not test multiple current levels or multi-site stimulation?\n\n5.How sensitive are results to model choice?\n\n6.Did you test other TDANN architectures or ensemble predictions to assess robustness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AEQRl9rIHB", "forum": "S4B7Iq7S3C", "replyto": "S4B7Iq7S3C", "signatures": ["ICLR.cc/2026/Conference/Submission16716/Reviewer_GiCt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16716/Reviewer_GiCt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16716/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969261400, "cdate": 1761969261400, "tmdate": 1762926766478, "mdate": 1762926766478, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}