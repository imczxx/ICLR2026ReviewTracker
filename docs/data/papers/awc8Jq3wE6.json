{"id": "awc8Jq3wE6", "number": 23236, "cdate": 1758341118895, "mdate": 1759896824918, "content": {"title": "Can Large Language Model Help Design Effective Neural Operators for Solving Partial Differential Equations?", "abstract": "Neural operators promise mesh and resolution independent surrogates for solving partial differential equations, yet building architectures that respect equation structure and train reliably still requires substantial expert effort. We ask whether a large language model can design neural operators end to end. We present a four agent pipeline with roles Theorist, Programmer, Critic, and Refiner. The Theorist selects a mathematically grounded operator for a user specified PDE and derives its formulation. The Programmer produces a self contained PyTorch implementation. The Critic performs adversarial review to expose numerical and software issues. The Refiner applies targeted corrections. An automated PDE solver completes the loop by generating data, training the synthesized model, and reporting evaluation metrics and plots. Across extensive PDE benchmark problems, the LLM designed operators consistently outperform strong baselines and prior SOTA in accuracy and sample efficiency, while remaining stable under varied discretizations and noisy initial conditions. Ablation studies show that the Critic and Refiner steps are essential for numerical stability and generalization. These results suggest that LLMs can act as principled collaborative designers of PDE operators, translating problem statements into executable and competitive architectures and moving toward automated and theory-aware scientific machine learning.", "tldr": "", "keywords": ["Neural operators", "operator learning", "partial differential equations", "large language models", "automated model design"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/102da55c58632fc7184a6d6d49ee4b7656df8432.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates whether LLMs can help design effective neural operators for solving parameterized PDEs. The authors propose a multi-agent approach, where each agent plays a specific role in translating a PDE specification into a working architecture. The Theorist provides mathematical grounding and architecture suggestions, the \"Programmer\" turns this into code, the \"Critic\" identifies weaknesses, and the \"Refiner\" integrates feedback to improve the design. The pipeline is tested across PDE datasets including Poisson, Darcy flow, Airfoil pressure prediction, and Navier-Stokes simulations. The results show that the LLM-generated designs are competitive or superior to baselines like FNO, U-Net, and other neural operator variants, in terms of relative error, parameter efficiency, and resolution generalization. The authors also include ablation studies and expert evaluation of theory quality."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1.The paper introduces a clearly structured system that turns LLM capabilities into a step-by-step process, allowing more transparent evaluation of each design stage\n2. The use of expert evaluation to assess the quality of theoretical justification adds depth to the study and moves beyond pure numerical performance"}, "weaknesses": {"value": "1. The paper does not provide a clear explanation for why GPT-4 is able to generate architectures that outperform human baselines. Since GPT-4 is not trained specifically on PDE solvers or numerical analysis literature, it is not obvious what background knowledge the model is leveraging. Is it simply matching syntax and patterns from existing repositories or does it have some internal representation of operator structure?\n\n2. The LLM prompting and system configuration are not described in enough detail to ensure reproducibility. For example, the paper does not specify the temperature, sampling strategy, system prompt, or whether any responses were filtered manually.\n\n3. The experiments mostly focus on structured grids and resolution generalization. However, generalization across boundary condition types or domain geometries is not explored. These are often more difficult challenges in operator learning"}, "questions": {"value": "1. Why do you think LLM is able to generate such effective neural operator architectures for PDE problems? What specific inductive bias or training data might be contributing to this ability?\n\n2. Can you provide the full prompts used for each agent, as well as the model parameters such as temperature, max tokens, and number of generations? Did you use any manual selection or curation when choosing between multiple outputs?\n\n3. How do the LLM-designed architectures perform under more difficult shifts, such as varying boundary conditions, different domain shapes, or noisy input data?\n\n4. How many independent expert reviewers participated in the theory assessment, and what agreement level was observed between them? Was any formal rubric used?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "4fDwLN4pWG", "forum": "awc8Jq3wE6", "replyto": "awc8Jq3wE6", "signatures": ["ICLR.cc/2026/Conference/Submission23236/Reviewer_zEVe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23236/Reviewer_zEVe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23236/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915980250, "cdate": 1761915980250, "tmdate": 1762942569688, "mdate": 1762942569688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method for automatically designing effective neural operators for solving Partial Differential Equations (PDEs) using Large Language Models (LLMs). The authors introduce a four-agent pipeline consisting of a Theorist, Programmer, Critic, and Refiner. The core idea is that the Theorist selects a mathematically grounded operator for a given PDE and derives its formulation , the Programmer implements it in PyTorch , the Critic performs an adversarial review of both the theory and the code to find issues , and the Refiner applies corrections. This \"theory-aware\" design process aims to transform neural operator design from \"an art into a science\".\n\nThe authors conduct experiments on six standard PDE benchmark datasets (e.g., Darcy Flow, Navier-Stokes, Airfoil) . The results demonstrate that the LLM-designed operators outperform state-of-the-art (SOTA) human-designed baselines, including FNO, LNO, and LaMO, on five of the six datasets. Furthermore, the LLM-designed models show significant advantages in parameter and computational efficiency (training time, GPU memory). Ablation studies confirm that the theoretical guidance from the Theorist is crucial for improving performance and generalization , and that the Critic and Refiner steps are essential for ensuring numerical stability and the quality of the final result. The authors also explore the method's limitations, finding that when asked to use \"obscure mathematical theories\" (like AFD), the LLM hallucinates and fails to understand the theory correctly, leading to performance degradation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel Paradigm and Significant Originality: The paper's primary strength is its proposal of a theory-driven, automated LLM pipeline for neural operator design. The decomposition into Theorist, Programmer, Critic, and Refiner, which couples mathematical derivation with adversarial review, is a highly original contribution that goes beyond existing work on LLMs for scientific coding.\n2. Strong Empirical Results: The LLM-designed operators outperform strong human-designed baselines on 5 out of 6 benchmarks. This proves the approach is not just conceptually novel but practically effective.\n3. Exceptional Efficiency: As shown in Figure 1, the LLM-designed models achieve this SOTA performance while being significantly more efficient in terms of parameters (2-3 orders of magnitude fewer) and computational cost (30-50% reduction in training time). This is extremely valuable in scientific computing."}, "weaknesses": {"value": "1. Omission of Design-Time Cost Analysis The paper emphasizes the run-time efficiency (e.g., training time, parameter count) of the final, generated operator. However, it omits any discussion of the design-time cost required to produce this operator. The proposed four-agent pipeline, which involves multiple iterations and feedback loops (from Theorist to Refiner, and potentially back to the Critic) , appears to be computationally expensive in terms of LLM calls. A lack of this analysis makes it difficult to assess the method's practical viability compared to human expert effort.\n2. Incomplete Experimental Baselines The experimental evaluation focuses heavily on comparing the LLM-designed operator against various human-designed PDE solvers (e.g., FNO, LNO). While this is valuable, the paper itself identifies a parallel line of work: \"fully automated LLM agents for PDEs,\" such as PINNsAgent. The paper does not include a direct comparison against these other automated agent systems, either in terms of final solution accuracy or efficiency, which would be necessary to fully contextualize its contribution.\n3. Insufficient Detail on the Theorist's Prompting Strategy Section 2 describes the Theorist's role abstractly, but it fails to provide concrete details on how the agent is prompted to \"develop clear, rigorous, and efficient mathematical formulations\". This is a critical omission, especially given the well-documented limitations of LLMs in rigorous mathematical and numerical reasoningâ€”a weakness the authors themselves confirm when the LLM fails to correctly apply \"obscure math\" like AFD. Without these prompt engineering details, the core mechanism responsible for the agent's success is not reproducible."}, "questions": {"value": "1. Regarding design cost: Could the authors quantify the \"design-time cost\" (e.g., wall time) required to generate one final, validated operator? How does this cost compare to the baselines?\n2. Regarding baseline comparisons: The paper mentions other automated LLM agents, such as PINNsAgent, in its related work. Could the authors compare your framework with these automated LLM agents for PDE?\n3. Regarding the Theorist's details: Given the known limitations of LLM mathematical reasoning, as demonstrated by the AFD failure case in Section 4.4, could the authors provide more specific details about the prompting strategy for the Theorist to ensure the robustness and reproducibility of its theoretical derivations?\n4. Regarding the standalone validation of the Theorist's output: The ablation study in Section 4.2 focuses on the performance of the full framework 'Without Theorist', which demonstrates the component's impact. However, this study does not seem to experimentally validate the correctness of the Theorist's output in isolation. The quality of this initial step is critical, as an erroneous mathematical formulation could cause subsequent computational failures or instability. Therefore, could the authors provide more direct experimental results or analysis to validate the correctness of the 'theoretical results' and neural operator architectures as initially designed by the Theorist, separate from the subsequent corrections made by the Critic and Refiner?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Dm4ShG3vDG", "forum": "awc8Jq3wE6", "replyto": "awc8Jq3wE6", "signatures": ["ICLR.cc/2026/Conference/Submission23236/Reviewer_xdJt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23236/Reviewer_xdJt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23236/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960623366, "cdate": 1761960623366, "tmdate": 1762942569275, "mdate": 1762942569275, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an automated framework using a multi-agent Large Language Model (LLM) pipeline to design neural operators for solving partial differential equations (PDEs). The pipeline consists of four distinct agents: a Theorist (to select mathematical principles), a Programmer (to generate PyTorch code), a Critic (to perform adversarial review), and a Refiner (to correct and debug). The authors evaluate this framework across six PDE benchmarks, demonstrating that the LLM-designed operators can achieve accuracy and efficiency comparable or superior to state-of-the-art (SOTA) human-designed models. Ablation studies are provided to validate the contribution of the theory-driven and critical-review components."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Ambitious and Novel Framework**: The primary strength is the ambitious vision of an end-to-end, theory-aware pipeline. This moves beyond simple LLM-based code generation or hyperparameter tuning and attempts to automate the scientific reasoning process (architecture synthesis from mathematical principles) itself.\n2. **Strong Empirical Validation**: The experimental setup is comprehensive. The authors benchmark against over 10 baselines on six diverse PDE datasets. Crucially, the ablation studies (Tables 2 & 3, Fig 2) effectively demonstrate the value of the Theorist and Critic agents, showing that theory-driven design improves accuracy and generalization.\n3. **Balanced Perspective on LLM Limitations**: The paper commendably includes a detailed analysis of a failure case (Section 4.4, Adaptive Fourier Decomposition). This honest investigation into the LLM's misunderstanding of \"obscure\" mathematics provides a valuable and balanced perspective on the current capabilities and risks of such systems."}, "weaknesses": {"value": "1. **Critical Lack of Reproducibility**: This is the most significant flaw. The paper relies heavily on proprietary, unreleased models (e.g., \"gpt-5\", \"o1\", \"o3\")1. Furthermore, it provides no details on the prompts, agent-to-agent interaction protocols, or stopping criteria, and makes no mention of code release. This makes the entire pipeline, which is the core contribution, unverifiable by the community.\n2. **Methodological Gaps in Theory-to-Architecture Mapping**: The paper is vague on how the Theorist translates high-level mathematical principles into a concrete, novel neural architecture. This \"theory-aware\" step is the most innovative part of the pipeline, but it is treated as a black box. The paper lacks even a single, clear, worked example (e.g., for the 1D Burgers' equation) showing the chain from theory -> agent output -> architectural modification -> code.\n3. **Missing SOTA Comparisons**: The claim to \"outperform strong baselines\"  is undermined by the omission of several key, recent neural operators, especially those designed for the irregular geometries that are a focus of this paper (e.g., Airfoil, Elasticity). Relevant works such as HAMLET (Bryutkin et al., 2024), Hyena Operator (Patil et al., 2023), and GNOT (Hao et al., 2023) are not compared against or even discussed in the related work section.\n4. **Incomplete Evaluation and Anecdotal Failure Analysis**: The analysis of failure on \"obscure\" math (AFD) 3 is purely anecdotal. A systematic study of what types of mathematical reasoning cause hallucinations would be much stronger. Moreover, the evaluation relies exclusively on relative $l^{2}$ error4, ignoring other critical metrics for PDE solvers like numerical stability, robustness to noisy initial conditions, or out-of-distribution generalization (beyond simple resolution changes)."}, "questions": {"value": "1. Can the authors provide a concrete end-to-end example (e.g., for 1D Burgers') showing the Theorist's output (mathematical formulation), the Programmer's initial code, and the Critic's specific feedback? This is essential for understanding the method's practical operation.\n2. Given the reliance on proprietary models (gpt-5), can the authors provide results using publicly available, high-capability models (e.g., GPT-4o, Llama 3) to demonstrate that the framework's success is not an artifact of an unreleased model?\n3. Why were recent, highly relevant SOTA operators (e.g., HAMLET, Hyena Operator, GNOT) omitted from the experimental comparison, especially given their focus on irregular geometries?\n4. How was the \"human expert review\" for theoretical correctness (mentioned in Sec 3 and 4.4 ) conducted? What was the rubric, and how many experts were involved?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LKgY1VOzMH", "forum": "awc8Jq3wE6", "replyto": "awc8Jq3wE6", "signatures": ["ICLR.cc/2026/Conference/Submission23236/Reviewer_DLM4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23236/Reviewer_DLM4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23236/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998165377, "cdate": 1761998165377, "tmdate": 1762942568988, "mdate": 1762942568988, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}