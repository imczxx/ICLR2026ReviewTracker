{"id": "F9pbcENAXv", "number": 23217, "cdate": 1758340950207, "mdate": 1759896826110, "content": {"title": "Multi-Fidelity Physics-Informed Neural Networks (PINN) with Boundary-Aware Losses for Ice-Bed Topography Prediction", "abstract": "Predicting ice dynamics and sea-level rise requires an understanding of subglacial bedrock topography; however, inversion remains a challenging task in data-sparse regions where surface observations are limited. Some conventional machine learning methods face challenges in predicting subglacial topography due to heavy reliance on purely data correlations and cannot guarantee physical consistency, especially in data-sparse regions. Physics-Informed Neural Networks (PINNs) address this limitation by embedding partial differential equation (PDE) constraints into deep learning, enabling more physically consistent predictions. However, most existing PINN formulations depend on a single fidelity of physics, and soft boundary penalties can still compromise performance. We propose a multi-fidelity PINN framework for ice-bed topography prediction that advances beyond these limitations in two ways. First, we introduce multi-fidelity residual coupling, jointly enforcing the shallow-ice approximation (SIA) and reduced-Stokes equations within a single network. This coupling improves accuracy while maintaining physics consistency, achieving strong predictive performance (e.g., Test MSE = 0.028, and $R^2$ = 0.97). Second, we design a boundary-aware weak-form loss that supports traction/flux (Neumann) and optional Dirichlet constraints, allowing flexible enforcement of margin physics. Experiments show that hard Dirichlet enforcement over-constrains the model and reduces accuracy, while soft or selective enforcement preserves predictive quality. To our knowledge, this is the first Physics-Informed Neural Network (PINN) framework for predicting ice-bed topography that unifies multi-fidelity partial differential equation (PDE) residuals with configurable boundary-aware losses, providing a practical and extensible approach to physically plausible predictions in data-sparse regimes.", "tldr": "We introduce a multi-fidelity PINN framework that leverages boundary-aware losses for more accurate PDE-constrained learning tasks, demonstrated on ice-bed topography prediction.", "keywords": ["Multi-fidelity learning", "PINNs", "boundary-aware losses", "Glacier bed inversion", "Ice dynamics"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0cf02073255bc7317e3fc6b5aa201ef578ed18b4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies the problem of estimating the bedrock topography beneath glaciers using limited radar data. The task is important because the shape of the subglacial bed affects ice flow and therefore projections of sea-level rise. Standard data-driven regression methods, such as random forests or neural networks, can predict bed elevation from surface features (e.g., surface velocity, elevation, mass balance), but they do not respect the underlying physics and typically perform poorly in areas where no direct data are available. \n\nTo address this, the paper uses PINNs, where a neural network is trained not only to fit data but also to satisfy physical equations. The authors extend a standard PINN by enforcing two PDE constraints simultaneously. One is the Shallow-Ice Approximation (SIA), a simplified diffusion-like model for ice flow:\n$$\n\\nabla \\cdot (M \\nabla \\hat{b}(x)) = 0,\n$$\nand the other is a reduced form of the Stokes momentum equation,\n$$\n-\\nu \\Delta \\hat{b}(x) - f = 0,\n$$\nwhere $\\hat{b}(x)$ is the predicted bed elevation, $\\nu$ is viscosity, and $f$ is external forcing. These two PDEs correspond to different fidelities of physical modeling: SIA is faster but less accurate, while the reduced-Stokes formulation captures more physics at higher computational cost. The paper combines them in one loss function as\n$$\nL_{\\text{phys}} = w_{\\text{SIA}}\\|r_{\\text{SIA}}\\|^2 + w_{\\text{Stokes}}\\|r_{\\text{Stokes}}\\|^2,\n$$\nwith either fixed or uncertainty-based weights. In addition, the paper introduces a “boundary-aware” component that treats the glacier margins through a weak-form loss. At boundaries, the model enforces either a Neumann (flux) condition,\n$$\nr_{\\text{Neu}} = \\nabla \\hat{b} \\cdot n - g_N,\n$$\nor an optional Dirichlet (fixed value) constraint,\n$$\nr_{\\text{Dir}} = \\hat{b} - u_D,\n$$\ndepending on the availability of data. The total loss includes data fitting and these physics terms:\n$$\nL = L_{\\text{data}} + L_{\\text{phys}} + \\lambda_{\\text{Neu}}\\|r_{\\text{Neu}}\\|^2 + \\lambda_{\\text{Dir}}\\|r_{\\text{Dir}}\\|^2.\n$$\nThe method is tested on radar measurements from Greenland’s Upernavik glacier (around 600k samples) using an 80/20 train-test split."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper clearly defines a physically meaningful target problem and integrates two existing physical formulations (SIA and reduced-Stokes) in a single learning framework. The mathematical setup is well-documented. The overall loss function is transparent and can be reproduced from the description. The authors also analyze different training configurations, including the effect of adaptive weighting between PDE terms and boundary constraints. Reporting of both conventional regression metrics (MAE, RMSE, $R^2$) and PDE residual norms $\\|r_{\\text{SIA}}\\|^2$, $\\|r_{\\text{Stokes}}\\|^2$ is useful for understanding whether the model satisfies physics as intended. The inclusion of an explicit weak-form treatment for Neumann and Dirichlet boundaries makes the approach flexible, and the observation that large Dirichlet penalties can harm learning is empirically well-supported by the ablation results."}, "weaknesses": {"value": "While the integration of two PDE fidelities is technically correct, the contribution over standard PINNs is incremental rather than conceptual. The combination of residuals $r_{\\text{SIA}}$ and $r_{\\text{Stokes}}$ is achieved through a weighted sum; the paper does not show that this coupling leads to fundamentally new behavior beyond regular multi-task loss balancing. The choice of weights ($w_{\\text{SIA}}=0.25$, $w_{\\text{Stokes}}=0.75$) or the uncertainty-based alternative is only briefly justified, and the sensitivity of results to these parameters is not explored. The reduced-Stokes and SIA equations are simplified to the extent that important aspects of ice flow (e.g., vertical shear, thermomechanical coupling) are not represented, so the resulting “physical consistency” is limited to these approximations. The experimental setup focuses on one glacier system; it is unclear whether the method generalizes to other regions or to cases with different boundary geometries. The boundary-aware formulation depends on knowing or interpolating Dirichlet targets $u_D$ from radar data, which assumes such data exist at margins; in many glaciers, this is not true. The claim that hard Dirichlet enforcement “over-constrains” the solution is qualitative and might depend on the scaling of $\\lambda_{\\text{Dir}}$ rather than an inherent property of the method. Many details such as the computational aspects, like runtime or convergence stability of the PINN relative to standard PDE solvers, are also not discussed."}, "questions": {"value": "1. The paper includes both the Shallow-Ice Approximation (SIA) and a reduced-Stokes model as residual penalties in the loss function. Could the authors provide more insight into how these interact during training? In particular, is there empirical evidence that the inclusion of both leads to improved learning dynamics (e.g., faster convergence, better generalization) compared to enforcing either alone? A comparison of gradient norms or loss curvature for each residual term would be informative. If both terms are correlated or redundant in some regions, how is this handled?\n\n2. The experiments use fixed weights (e.g., $w_{\\text{SIA}} = 0.25$, $w_{\\text{Stokes}} = 0.75$) and an uncertainty-based alternative (log-variance weighting). Could the authors clarify how sensitive the final performance is to these weights? Was a grid search or hyperparameter sweep conducted? If uncertainty weighting is used, how stable are the learned variances across runs? A plot of weight evolution or an ablation comparing adaptive vs. fixed weighting would help interpret the benefit.\n\n3. The boundary-aware loss relies partly on interpolated Dirichlet values at the glacier margins. In practice, such boundary values may not be available or may have high uncertainty. How robust is the method to incorrect or missing Dirichlet constraints? Could the authors describe what happens when only Neumann flux terms are used, and no $u_D$ is provided? Also, how were the boundary normals $n$ estimated in the Neumann residual term?\n\n4. The method is evaluated only on the Upernavik glacier system. Can the authors comment on the model’s ability to generalize to different glaciers, such as those with different bed roughness, mass balance profiles, or margin geometries? Was any transfer learning or leave-one-glacier-out evaluation attempted?\n\n5. The paper does not discuss the runtime, convergence stability, or computational challenges of training the proposed PINN with physics constraints. How do training times compare to standard data-driven baselines or traditional PDE solvers (e.g., finite element models)? \n\n6. The result that “hard Dirichlet enforcement degrades accuracy” is stated somewhat strongly. Could the authors clarify whether this is sensitive to the weight $\\lambda_{\\text{Dir}}$ or the fraction of boundary points receiving Dirichlet labels? Would softer enforcement or using learned penalties improve outcomes?\n\n7. The paper mentions that the code is available, but no link is provided in the anonymized version. For reproducibility and further analysis, will all scripts, data preprocessing steps, and hyperparameter configurations be released upon acceptance? If synthetic or simplified datasets were used during development, sharing those might also benefit future benchmarking."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "by8BNQlPVX", "forum": "F9pbcENAXv", "replyto": "F9pbcENAXv", "signatures": ["ICLR.cc/2026/Conference/Submission23217/Reviewer_QcrT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23217/Reviewer_QcrT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23217/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932089065, "cdate": 1761932089065, "tmdate": 1762942562559, "mdate": 1762942562559, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a physics-informed neural network for subglacial bed topography that couples two physics fidelities (shallow-ice approximation and a reduced-stokes surrogate) inside one PINN loss and adds a boundary-aware weak-form term that mixes Neumann traction and optional Dirichlet constraints at glacier margins. On a Greenland radar track dataset, the method reports test mse with $r^2$ and claims better physics residuals than single-fidelity or purely data-driven baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper aims to address a relevant geoscience problem where labeled data are sparse and physical constraints matter, and motivates the need for physics-guided inversion rather than black-box regression.\n2. The multi-fidelity idea is sensible: use SIA for cheap broad constraints and a higher-order residual for added fidelity, with learned or fixed weights to balance them."}, "weaknesses": {"value": "1. The “reduced-stokes” residual is specified as $r_{Stokes} = −ν\\Delta \\hat b − f$ with $ν=1$ and $f=0$, which collapses to a Poisson-like smoothness on the bed field rather than a demonstrably derived momentum balance tied to ice rheology or sliding. This risks being a hand-crafted regularizer rather than a true higher-fidelity physics term.\n2. The physical role of the predicted variable is unclear: the network maps surface features to bed elevation $\\hat b$, but the residuals are written directly on $\\hat b$ without showing how $\\hat b$ couples to velocity, thickness, or stresses in SIA/Stokes. \n3. Neumann boundary condition uses $g_N = 0$ by default, which is a strong assumption..\n4. The dataset split appears random 80/20 over track points; this can cause spatial leakage because nearby points on a flight line are strongly correlated. The text says the team ensured points were “not too similar,” but it lacks a rigorous spatial holdout protocol and distance thresholds.\n5. Metric reporting mixes “training units” and “physical units,” leading to confusing cross-model comparisons (e.g., random forest shows r²=0.987 yet huge mae/rmse due to unit scaling). \n6. The baseline shows a “weighted physics objective” of 0 while listing nonzero residuals; SIA and Stokes residuals are identical to two decimals in multiple rows. Can you explain this?\n7. The “uncertainty weighting” via Kendall log-variance is used for loss balancing, but no calibration, uncertainty evaluation, or learned weight trajectories are presented, so the “uncertainty” interpretation is not strong.\n8. Interpolated boundary labels may leak target information."}, "questions": {"value": "Please address the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "S94Ma2ARhm", "forum": "F9pbcENAXv", "replyto": "F9pbcENAXv", "signatures": ["ICLR.cc/2026/Conference/Submission23217/Reviewer_2Vt4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23217/Reviewer_2Vt4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23217/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974231458, "cdate": 1761974231458, "tmdate": 1762942562384, "mdate": 1762942562384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a multi-fidelity, boundary-aware Physics-Informed Neural Network (PINN) framework for ice-bed topography prediction. The proposed framework couples the shallow-ice approximation (SIA) and reduced-Stokes equations and integrates weak-form boundary conditions. Experimental results show that the proposed framework outperforms both the non-physics and physics-only baselines. The authors also provided the results of the variants to support the importance of each component in the proposed framework."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed multi-fidelity framework is novel to the application of ice-bed topography prediction.\n2. The experiments were conducted using the real-world dataset, which demonstrates the effectiveness of the method.\n3. The proposed framework with all the components achieved superior performance compared to the baselines."}, "weaknesses": {"value": "1. The experiments are all conducted on a single dataset. I’m not familiar with this task, but I think if more datasets are involved, the experiments would be more solid and comprehensive.\n2. The quantitative results of the baselines are provided in Table 2. However, the reported errors of these methods (including the single-fidelity PINN) are several orders of magnitudes larger than those of the proposed method and its variants. It would be better to include some qualitative results of these methods to make the results more convincing. \n3. For the single-fidelity PINN baseline, only the one that enforces SIA is covered. The baseline that enforces reduced-Stokes equations should also be included."}, "questions": {"value": "1. In Table 1, could the authors clarify what training units and physics units are?\n2. In Equation (3), could the authors further explain why $g_N=0$? Similarly, it is unclear why $\\lambda_{Dir}=0$ in the loss fuction.\n3. In Section 6.2, what is the difference between Main Multi-fidelity (uncertainty weighting) and Boundary-aware (Dirichlet optional)? What are the boundary conditions in Main Multi-fidelity? From my understanding, the Boundary-aware includes all the components. However, it underperforms Main Multi-fidelity in Table 1.\n4. How did the weights in the loss function selected? The description should be included if cross validation is employed.\n5. In Figure 3 and Figure 5, it is a little bit hard for readers to find the differences between the results. It would be better to highlight the regions for comparison.\n6. [Minor] There is no need to include parameters from codes such as “USER_UNCERTAINTY=True” or “HARD DIRICHLET=True” as they may be confusing for readers due to lack of context.\n7. [Minor] Section 3 can be merged with Section 6.1.\n8. [Minor] The caption of Figure 1 is hard to understand."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DcJQlB1lbR", "forum": "F9pbcENAXv", "replyto": "F9pbcENAXv", "signatures": ["ICLR.cc/2026/Conference/Submission23217/Reviewer_byjJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23217/Reviewer_byjJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23217/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761975871747, "cdate": 1761975871747, "tmdate": 1762942562177, "mdate": 1762942562177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}