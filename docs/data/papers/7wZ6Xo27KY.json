{"id": "7wZ6Xo27KY", "number": 8850, "cdate": 1758099929065, "mdate": 1759897759707, "content": {"title": "AnoDiT: Mask Guided DiT Inpaint Models for Anomaly Images Generation", "abstract": "Effective training of industrial anomaly detection (AD) models is persistently hindered by the scarcity and limited diversity of real anomaly samples. While generative methods have been proposed to augment anomaly data, they often struggle with a critical trade-off between generation controllability, background fidelity, and the realism of the synthesized anomalies. In this paper, we propose AnoDiT, a novel mask-guided anomaly generation framework that leverages a Diffusion Transformer (DiT) for high-fidelity inpainting. To ensure the perceptual plausibility of generated anomalies, we introduce a Laplacian Pyramid-based Texture Decomposition Module. which guides the model to learn deep texture representations of anomalous regions. Furthermore, for seamless integration of the anomaly into the pristine background, we design an Anomaly Region Focusing mechanism with Edge Weighting, which encourages the model to learn a natural transition at the defect boundary and is enhanced by a multi-round resampling process. To establish a fully automated pipeline and overcome the annotation bottleneck, we also develop a conditional diffusion model incorporating a Positional Prior to generate diverse and realistically-located anomaly masks. This dual-model pipeline not only enables fine-grained control over the anomaly's geometry and texture but also simultaneously yields pixel-perfect labels. Experiments demonstrate that data synthesized by AnoDiT significantly improves the performance of downstream anomaly inspection tasks.", "tldr": "Mask Guided DiT inpaint Models for Industrial Defect and Anomaly Synthesis", "keywords": ["Image generation", "Image Inpaint", "Diffusion model", "Diffusion Transformer", "Industrial Anomaly images Generation", "Mask generation."], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3c09c784c53635cd2b858833bebfd66b84945ca5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents a method for Anomaly Synthesis named AnoDIT. The method leverages a Diffusion Transformer to do so. The paper introduces two new modules: one for generating masks and a combination of two losses (anomaly focused and laplacian pyramid). The model performs well on MVTec AD."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Addressing the mask generation aspect is novel and important\n- In the vast majority, the paper flows nicely and is easy to read."}, "weaknesses": {"value": "- It is unclear whether a different DIT is trained for each anomaly class or a unified one. The latter would be more useful in practical terms. \n- Does the generation process generalise to different objects? E.g. training for “hole” on hazelnut and generating them on a metal nut?\n- The method fails to compare to AnomalyAny [1], which is superior in the generation quality.\n- As the mask generation is not conditioned on the input image, it might generate the anomaly mask in the wrong position (e.g. some anomaly classes in the “screw” category)\n- The method is evaluated only on one dataset, putting into question its generalizability.\n\n[1] Sun, H., Cao, Y., Dong, H., & Fink, O. (2025). Unseen Visual Anomaly Generation. In Proceedings of the Computer Vision and Pattern Recognition Conference (pp. 25508-25517)."}, "questions": {"value": "I have several questions. I have sorted them from most problematic to least problematic.\n\n1. Does training on one “Anomaly Class” transfer to novel objects?\n2. How well does the proposed method work on VisA? Or some other representative AD dataset?\n3. How often does the mask generation process fail, and what are the typical failure cases?\n4. Is there a separate model for one anomaly class or a unified one?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "usB63ZpDJ9", "forum": "7wZ6Xo27KY", "replyto": "7wZ6Xo27KY", "signatures": ["ICLR.cc/2026/Conference/Submission8850/Reviewer_2xys"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8850/Reviewer_2xys"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761510906845, "cdate": 1761510906845, "tmdate": 1762920614837, "mdate": 1762920614837, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AnoDiT, a mask-guided anomaly generation framework based on Diffusion Transformer (DiT) to address the scarcity and limited diversity of real anomaly samples in industrial anomaly detection (AD). The framework reframes anomaly synthesis as an inverted image inpainting task, integrating two core components: a DiT-based inpainting model with Laplacian Pyramid-based Texture Decomposition and Anomaly Region Focusing mechanism for high-fidelity anomaly synthesis, and a conditional diffusion model with Positional Prior for generating diverse, realistic anomaly masks. Experiments on the MVTec AD dataset demonstrate that AnoDiT outperforms existing methods in both generation quality (measured by IS and IC-LPIPS) and downstream AD performance (AUROC, AP, F₁-max), offering a fully automated pipeline that balances background fidelity, anomaly realism, and generation controllability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper proposes AnoDiT, a novel mask-guided Diffusion Transformer for industrial anomaly generation within a single diffusion framework.\n2.Experiments on industrial anomaly detection benchmarks demonstrate that synthetic data generated by AnoDiT can improve downstream anomaly detection performance.\n3.The paper is well-organized and clearly written, with a coherent motivation and structured presentation of modules."}, "weaknesses": {"value": "1. The paper mainly reports image-level AUROC as the quantitative metric, but lacks pixel-level evaluation results such as pixel-level AUROC, Average Precision (AP), or F1-max, which are standard for assessing localization performance in anomaly detection.\n\n2. There is a typo at line 218, where $M_{dil}$ appears to be incorrectly written.\n\n3. The role of the proposed Anomaly-Focused Loss is not clearly explained. It remains unclear why the supervision is not restricted to the internal mask region, which would more directly guide the model toward anomaly-relevant areas.\n\n4. The Image Completion (IC-L) performance drops significantly compared to AnomalyDiffusion, but the paper does not provide a clear explanation or analysis for this degradation.\n\n5. The ablation study is rather limited. For example, the effect of the boundary size in the Anomaly Localization (AL) module is not analyzed in detail. Similarly, the Laplacian Pyramid (LP) module lacks an investigation of the number of pyramid levels and their impact on reconstruction quality. A more thorough analysis would clarify which region sizes or pyramid configurations yield optimal performance.\n\n6. The overall methodological novelty is limited. The proposed framework primarily integrates existing components (mask guidance, Laplacian Pyramid, and transformer-based diffusion) without introducing a fundamentally new learning paradigm or theoretical insight."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pIlAr6pz1N", "forum": "7wZ6Xo27KY", "replyto": "7wZ6Xo27KY", "signatures": ["ICLR.cc/2026/Conference/Submission8850/Reviewer_y7w6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8850/Reviewer_y7w6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921524696, "cdate": 1761921524696, "tmdate": 1762920614216, "mdate": 1762920614216, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AnoDiT, a novel dual-model framework for generating realistic and diverse industrial anomalies. The framework consists of two main components: (1) A conditional Denoising Diffusion Probabilistic Model (DDPM) that generates diverse anomaly masks. This model is guided by a \"Positional Prior\", a probability map learned from the spatial distribution of ground-truth masks, ensuring that generated masks are realistically located. (2) A mask-guided Diffusion Transformer (DiT) that inpaints the anomaly onto a normal image. \nTo improve the realism of the inpainted anomaly, the authors introduce two key losses, i.e. Anomaly Region Focusing Loss and Laplacian Pyramid-based Texture Decomposition Loss. Experiment results on the MVTec AD dataset demonstrate that data synthesized by AnoDiT significantly improves the performance of downstream anomaly detection tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tNovel and Sound Framework: The authors developed a system that is both controllable and effective. This is a strong and original architectural choice.\n2.\tEffective Technical Contributions: The two novel loss components for the inpainting model are well-justified and shown to be effective.\n3.\tStrong Downstream Performance: Training a UNet segmentation model with AnoDiT-generated data yields state-of-the-art results on the MVTec AD benchmark"}, "weaknesses": {"value": "(1)\tThe description of the DDPM-based mask generation given in section 3.2 is not very clear. How many samples are used for training the DDPM model? There is no evaluation on the quality of the generated masks in the paper. Some examples of the mask generation and anomaly image generation results should be shown in the paper.\n(2)\tThe experiments compare against Crop&Paste, DFMGAN, and AnomalyDiffusion. But the Related Work section cites more recent and arguably stronger diffusion-based industrial anomaly generators such as DualAnoDiff (2025 CVPR) and AdaBLDM (2024).\n(3) In Table 2, the F1-max metric for anomaly detection using the proposed method (98.0%) is lower than that of AnomalyDiffusion (98.5%). There is no discussion on this issue. \n(4) The experiment evaluation is only performed on one dataset, i.e. MVTecAD dataset. Several SOTA methods have shown outstanding performance on MVTecAD dataset.  This experimental validation is insufficient.\n(5) The experimental evaluation should also include anomaly segmentation, i.e. pixel-based anomaly detection, metrics for comparison with other methods."}, "questions": {"value": "1. The Positional Prior for mask generation seems crucial. How sensitive is this method to the number of available ground-truth masks in the training set? The paper notes this as a challenge. How many masks per class (e.g., on MVTec) are needed to learn a prior that is useful?\n\n2. How do you evaluate the quality of the generated masks by using the proposed DDPM-based mask generation method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FIXuVH7yIf", "forum": "7wZ6Xo27KY", "replyto": "7wZ6Xo27KY", "signatures": ["ICLR.cc/2026/Conference/Submission8850/Reviewer_tnZq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8850/Reviewer_tnZq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762002642900, "cdate": 1762002642900, "tmdate": 1762920613910, "mdate": 1762920613910, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The AnoDiT paper proposes a novel framework to address the scarcity of industrial anomaly data by synthesizing high-quality, diverse defects. It reframes the problem as \"inverted inpainting,\" using a Diffusion Transformer (DiT) to \"paint\" anomalies onto pristine images, guided by masks. This is a dual-model pipeline: a separate conditional DDPM, guided by a novel \"Positional Prior,\" first generates realistic and varied anomaly masks. The DiT model then uses these masks, along with an \"Anomaly Region Focusing\" loss and a \"Laplacian Pyramid\" texture loss, to generate high-fidelity defects that blend seamlessly with the background. The authors demonstrate that this synthetically generated data significantly improves the performance of downstream anomaly detection tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Effective Dual-Pipeline Design: The method's core strength is its decoupled, dual-model architecture. By using one model (a DDPM with a \"Positional Prior\") to explicitly generate diverse and spatially realistic masks, it simplifies the task for the second model (the DiT inpainter). This allows for finer control over both the anomaly's geometry and its texture."}, "weaknesses": {"value": "- Novelty is in Integration, Not Invention: The method's core novelty is arguably more in its system design than in fundamental architectural invention. It cleverly assembles several existing, powerful components—a DiT, a DDPM, an inpainting strategy from RePaint, and classic Laplacian pyramids. While highly effective, it relies on synthesizing these known techniques rather than proposing a new, foundational generative block.\n\n - High Dependency on Initial Mask Quality: The entire pipeline's success, particularly its diversity, hinges on the quality and variety of the initial ground-truth masks. The mask generation model is trained on these masks to learn its \"Positional Prior.\" If the original training dataset contains only a few low-variety masks, the generator will be unable to produce truly novel shapes, limiting the diversity of the final synthetic data."}, "questions": {"value": "Please refer to the above weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oX9iWpEvc2", "forum": "7wZ6Xo27KY", "replyto": "7wZ6Xo27KY", "signatures": ["ICLR.cc/2026/Conference/Submission8850/Reviewer_sq8S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8850/Reviewer_sq8S"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762098224782, "cdate": 1762098224782, "tmdate": 1762920613195, "mdate": 1762920613195, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}