{"id": "0EV92jgJaZ", "number": 21809, "cdate": 1758322135358, "mdate": 1759896902012, "content": {"title": "Non-Incremental Bottom-Up Knowledge Compilation of Neuro-Answer Set Programs", "abstract": "Neuro-Probabilistic Answer Set Programming offers an intuitive and expressive framework for representing knowledge involving relations, non-determinism, logical constraints, and uncertainty-aware perception. Such a high expressivity comes at a significant computational cost. To mitigate that, Knowledge Compilation (KC) approaches translate the logic program into a logic circuit for which  inference and learning can be performed efficiently. Top-down KC approaches employ an intermediary step of translating the logic program into a CNF propositional formula, before the actual KC step. This has the drawback of requiring the use of auxiliary variables and a fixed variable ordering. Bottom-up KC approaches instead construct a circuit representation compositionally, by employing circuit operations that represent the subparts of the logic program, without the need of auxiliary variables and allowing dynamic variable ordering. However, intermediary circuits can grow quite large even when the end circuit is succinct. In this work, we develop a non-incremental bottom-up KC strategy that provably and empirically reduces the size of the intermediary representations compared to its incremental counterpart. We explore heuristics for v-tree initialization and dynamic variable reordering. Experimental results show that our method achieves state-of-the-art performance for a large class of programs.", "tldr": "We propose a non-incremental approach for Bottom-Up Knowledge Compilation of Probabilistic Answer Set programs.", "keywords": ["Probabilistic Logic Programming", "Knowledge Compilation"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8c15560d7d1761b796b890a6ed9a9cbd6b6b139a.pdf", "supplementary_material": "/attachment/a76f1ad33861acd68d7a78ec7105bdd343f6ef04.zip"}, "replies": [{"content": {"summary": {"value": "Knowledge compilation approaches in probabilistic answer set programming (PASP) can be categorised into top-down or bottom-up approaches.\nTop-down typically require a CNF as input, which generally means additional auxiliary variables are introduced to first transform the PASP program into a CNF.\nBottom-up approaches do not have this requirement as they incrementally built up the compiled representation. During this process, intermediate representations may grow exponentially large. This work \n1) develops a non-incremental bottom-up knowledge compilation strategy to reduce the size of the intermediate representations, and\n2) explores a vtree initialization heuristic with dynamic variable ordering."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The work is relatively easy to read and well structured. Only, for the part about credal and maxent semantics I wonder if this is necessary for the story as it may just convolute it; and the related work deserves to be expanded.\n\nThe studied problem and contributions are very relevant for the knowledge compilation domain. Non-incremental bottom-up compilation is about not necessarily following the input circuit structure and instead optimising its compilation process to avoid intermediate blow-up of the representation size, which is an additional challenge for bottom-up compilation as opposed to top-down approaches. The vtree heuristic is important to obtain more succinct SDD representations in general. Both contributions are likely applicable beyond the probabilistic ASP setting.\n\nThe work is sound and the empirical results appear positive."}, "weaknesses": {"value": "The paper title mentions Neuro ASP, but the contributions and experiments are not associated with neurosymbolic AI. While it is true that you could technically come up with a neurosymbolic version, this aspect is irrelevant to the contribution.\n\nMy main concern is novelty. The main contribution, to perform non-incremental compilation on rules, is not so different from non-incremental compilation on a CNF (de Colnet 2023). In both cases a set of variable disjoint components is identified and compiled separately. If such disjoint components are not present, some nodes are identified for removal such that disjoint components arise. This has parallels to variable ordering heuristics in top down compilers like D4, which favor branching on variables that would lead to independent components (Lagniez et al. 2017).\n\nThe related work discussion refers to other ASP related systems. However, the proposed vtree heuristic and the non-incremental decompositioning approach also relates to existing work, the connections of which are not discussed (e.g., minfill, mindegree, D4's branching heuristc, MINCE, ...). This is important to accurately assess novelty and position the work.\n\nThe importance and novelty of the cardinality constraint encoding, the choice atom, and disjunctive rules encoding are not clear. The latter two at least risk being trivial in the context of the existing work?\n\nThe work compares to top-down compilers, which require the introduction of auxiliary variables to obtain a CNF (cf. Tseitin procedure). However, it is worth noting that there is recent work that adapt a top-down compiler such that it does not require a CNF as input [Derkinderen et al. 2025]. They do perform a CNF translation internally, but then optimise the DPLL/CDCL search procedure to prune irrelevant artifacts that appear because of the auxiliary variables. Orthogonal but similarly, [Derkinderen 2024] proposed a post-compilation approach to again remove the auxiliary variables and irrelevant artifacts. So in terms of final representation size for top-down compilation, these works would improve the situation for top-down compilation as there are no more auxiliary variables and \\iff structures afterwards.\n\n[Derkinderen et al. 2025] Circuit-Aware d-DNNF Compilation. IJCAI 2025\n\n[Derkinderen 2024] Pruning Boolean d-DNNF Circuits Through Tseitin-Awareness"}, "questions": {"value": "Q1) Sect 4.2 does not explain how to go from an ordered list of atoms to a vtree. Is this a left linear vtree that is then optimised using dynamic optimization? What were the used parameters for the dynamic optimisation process?\n\nQ2) For top-down compilers, is the conversion to CNF part of the reported run time? And if so, how much time did this take usually? \n\n\n**Suggestions**\n\nThe abstract mentions that top-down KC approaches require a fixed variable ordering. This is inaccurate as top-down compilers like sharpSAT-TD and D4 dynamically decide the variable branching order per branching decision. This statement probably refers specifically to top down SDD compiler.\n\nSect 4.2 states that \"CNFs do no possess as well-structured relationships between their variables as is the case with Probabilistic Logic Programs (PLPs)\". The meaning of this statement is not entirely clear to me. The primal graph of a CNF, a structural representation of the relationship between the variables, is commonly used within variable ordering heuristics like minfill?\n\nThe x/y tick label fontsize for Figure 3/4 are relatively small.\n\nTypo: \n* appendix \"best choic.\"\n* appendix p16 \"Another interesting research question (call it Q4) that was not explored in the main paper is the following: Is the bottom-up compilation of loop formulas more succinct than cycle-breaking?\" -- This research question was moved to the main paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "H7Z4ziUNzg", "forum": "0EV92jgJaZ", "replyto": "0EV92jgJaZ", "signatures": ["ICLR.cc/2026/Conference/Submission21809/Reviewer_LhmE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21809/Reviewer_LhmE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761476389717, "cdate": 1761476389717, "tmdate": 1762941938227, "mdate": 1762941938227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a non-incremental bottom-up knowledge compilation (KC) strategy for probabilistic answer set programming (PASP), targeting neuro-symbolic reasoning systems. Traditional incremental bottom-up compilation suffers from large intermediate circuits even when final circuits are compact. The authors propose to partition PASP programs into variable-disjoint subcomponents, compile each separately, and conjoin the results, theoretically bounding intermediate circuit size. They also present a heuristic for V-tree initialization based on dependency graph structure, enabling dynamic variable ordering. Experiments on four PASP benchmarks (Coloring, Smokers, IRL, IRN) show improvements in memory and compilation time compared to incremental and top-down compilers (C2D, D4, SHARPSAT-TD)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The work addresses a genuine inefficiency in bottom-up PASP compilation (large intermediate circuits)."}, "weaknesses": {"value": "1. **Lack of neuro-symbolic integration.** Although framed as “Neuro-Answer Set Programs”, the paper’s experiments and formulations never demonstrate integration with neural components or end-to-end learning. \n2. **Incremental vs. non-incremental framing.** The “non-incremental” decomposition heavily depends on detecting disjoint rule subsets or vertex cuts in the dependency graph. For complex or highly connected programs, the method degrades to incremental compilation. This limitation is only briefly acknowledged and lacks more detailed evaluation.\n3. **Limited novelty relative to de Colnet (2023).** The core idea—compiling variable-disjoint components separately—seems to be directly inspired by de Colnet’s non-incremental strategy. The extension to PASP (without CNF) seems to be somewhat incremental.\n4. **Insufficient Evaluation.**\n    - Experiments are confined to small, synthetic datasets (≤17 nodes for Coloring) and classical Smokers/IRL examples. No large-scale or real neuro-symbolic applications are tested.\n    - Performance comparisons omit recent bottom-up probabilistic frameworks such as Scallop (Li et al., 2023) and dPASP (Geh et al., 2024) beyond citation.\n    - The empirical “state of the art” claim may be somewhat overstated: benchmarks are narrow and focused on circuit size, without inference accuracy etc.\n5. **Regarding efficiency.** While the paper claims better efficiency over incremental KC, in Table 3 it shows very marginal improvement of the proposed non-incremental / non-incremental with heuristic, against the incremental baseline.\n6. **Presentation issues.** The paper is somewhat hard to follow. Some sections (e.g., 4.1–4.3) read as an algorithmic sketch without pseudocode or formal definition of the decomposition algorithm, and it is not straightforward to understand which are existing techniques and which are the proposed novelty. Also, many of the result figures (Figure 3,4,6 etc.) have a somewhat unusual design and are a little hard to interpret. Also, the main theorem (L353) is stated but not proved in full detail (only a sketch at L357).\n\n### **Minor**\n\n1. I feel the background section may be too dense and verbose. I would recommend to summarize the background to involve less details and to be more straightforward, maybe within one page. The details can be moved to appendix.\n2. There are some typos. e.g. L292 repeated word \"important\", L336 \"were\" should be \"where\"."}, "questions": {"value": "1. Could the authors clarify how does the 'neural' component come in to play in the proposed framework (as the title mentions \"Neuro-ASP\")? Does the proposed non-incremental compilation approach supports differentiable or neural integration in practice?\n2. It seems the “non-incremental” approach relies on detecting variable-disjoint subprograms. If so, how does the method behave on highly connected PASP programs where such disjointness is rare?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "s3pHoGL7To", "forum": "0EV92jgJaZ", "replyto": "0EV92jgJaZ", "signatures": ["ICLR.cc/2026/Conference/Submission21809/Reviewer_Yy1K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21809/Reviewer_Yy1K"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761580904273, "cdate": 1761580904273, "tmdate": 1762941937920, "mdate": 1762941937920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper describes an approach to perform efficient knowledge compilation for probabilistic answer set programs (PASPs). The traditional approaches require conversion to CNFs which introduces many auxiliary variables and increases complexity. Further, in existing approaches, the intermediate circuits generated during incremental compilation may be too large to be handled. The proposed approach presents a heuristic for compilation as well as compiling in an incremental manner to avoid exponential blow-up of circuit size. Experiments are performed on 3 benchmark problems and compared with existing state-of-the-art showing superior performance in terms of computational efficiency and resulting circuit size."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ Seems to be a generalizable approach for compilation of PASPs with guarantees on compiled circuit size\n+ Experiments seem show show a novel insight regarding cycle breaking, where they show that using this might result in larger circuit size\n+ The results seem to show that the proposed approach performs better in terms of time/memory efficiency, intermediate and final circuit size when compared to existing methods"}, "weaknesses": {"value": "- The approach depends upon disjoint subsets in the program. In real-world scenarios do PASP programs typically have such subsets. In general, it would have been nice to show this encoding on a more realistic benchmark to show practical relevance. From the experiments it seems like the method bottoms out at nodes = 17 (table 1), is this scalable enough to be significant? \n- The statement around why CNF based bottom-up methods/benchmarks comparison was inapplicable (line 376) is not so clear. If the goal is to show the proposed approach is an improvement over existing bottom up compilation methods (including CNF based ones), would that not make for a good comparison? Maybe some explanation is needed here."}, "questions": {"value": "Why are existing bottom-up compilation methods excluded from the comparison?\nWhat is the practical viability in terms of scaling up the approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7hAdQZupYC", "forum": "0EV92jgJaZ", "replyto": "0EV92jgJaZ", "signatures": ["ICLR.cc/2026/Conference/Submission21809/Reviewer_rAAa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21809/Reviewer_rAAa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21809/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761847050353, "cdate": 1761847050353, "tmdate": 1762941937667, "mdate": 1762941937667, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}