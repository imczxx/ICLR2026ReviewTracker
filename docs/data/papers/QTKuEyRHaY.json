{"id": "QTKuEyRHaY", "number": 16653, "cdate": 1758267335812, "mdate": 1759897227196, "content": {"title": "How Much Can a Query Reveal? Structural Knowledge Stealing from Graph RAG via Traversal Reconstruction", "abstract": "Retrieval-Augmented Generation (RAG) has become a popular paradigm for enhancing large language models (LLMs) with external knowledge. Recent advances have extended this framework to structured data, leading to the emergence of Graph RAG systems that retrieve and reason over knowledge graphs. Despite their widespread applications, the privacy implications of such systems remain largely unexplored. In this work, we investigate a critical privacy vulnerability in Graph RAG systems: a significant portion of inherent structural knowledge can be easily exploited by malicious adversaries through carefully crafted queries, even under the black-box setting. We propose a query-based attack strategy that efficiently reconstructs knowledge graph including node-level and topology-level information, leveraging breadth-first traversal for untargeted attack and depth-first traversal for targeted attack. Experiments on generic and healthcare scenarios show that our method can recover over 90\\% of the original knowledge graph from representative Graph RAG systems, exposing sensitive information with high fidelity. We further evaluate the efficacy of existing defense strategies and discuss primary challenges of safeguarding Graph RAG pipelines. To the best of our knowledge, this is the first systematic study of privacy risks in Graph RAG systems. Our findings underscore the urgent need for privacy-aware mechanisms in current graph retrieval-augmented AI systems.", "tldr": "", "keywords": ["Graph Retrieval-Augmented Generation", "Privacy Attack", "Large Language Models"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3eac2c823a724f5115cd798cdd58b3e334523b49.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Researchers have proposed a query-based attack strategy to reconstruct knowledge graphs in a black-box environment. They designed two types of attacks: a non-targeted attack using BFS, aimed at recovering as much of the knowledge graph's content as possible, and a targeted attack using DFS, designed to extract information related to specific target nodes.\n\nThe researchers conducted experiments on the MIMIC-IV dataset in the medical field and the Freebase dataset in the general knowledge domain, targeting both retrieval-based and agent-based graph retrieval-augmented generation systems, in combination with three large language models: GPT-4o, DeepSeek-V3, and LLaMA3-8B.\n\nAdditionally, the paper evaluated potential defense measures. It suggested that more effective defense mechanisms could include differential privacy, real-time query monitoring, and knowledge graph structure perturbation.\n\nThe researchers noted that this is the first systematic study on the privacy risks of graph retrieval-augmented generation systems, emphasizing the urgent need to incorporate privacy protection mechanisms in such systems."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1.  The paper is the first to identify security vulnerabilities in Graph RAG, highlighting the urgent need for privacy protection mechanisms in such systems. The research perspective is novel.\n\n2.  The paper evaluates the attack methods on the MIMIC-IV dataset from the medical field and the Freebase dataset from the general knowledge domain. It uses GED, NRR and MCS to evaluate the untargeted attack, and F1, precision, and recall to evaluate the targeted attack. The use of appropriate evaluation metrics leads to strong experimental results.\n\n3.  Regarding the proposed attack method, the paper suggests corresponding defense strategies and evaluates them. It indicates that more effective defense mechanisms may include differential privacy, real-time query monitoring, and knowledge graph structure perturbation. This provides valuable guidance for the future development of RAG systems."}, "weaknesses": {"value": "I have the following concerns:\n1. Current RAG systems often involve supervised fine-tuning of generative models. The paper \"Data Extraction Attacks in Retrieval-Augmented Generation via Backdoors\" points out that after fine-tuning, large models demonstrate significantly enhanced resistance to prompt injection attacks, reducing the effectiveness of such attacks to nearly zero. Since the attack method proposed in this study essentially operates through prompt injection, I would like to know whether this approach would still be effective against RAG systems that have undergone Sft.\n\n2. In the ablation experiments, the authors compared the effectiveness of the attacks under different knowledge graph scales in Graph RAG. The authors simply divided the knowledge graph scale into ranges of 10–50, 51–100, 101–500, and above 500. The experimental results show that when the number of nodes increases to the above 500 range, the effectiveness of this attack method decreases. However, even a single novel, when constructed into a Graph RAG, can generate over 500 nodes. In practical applications of Graph RAG systems, the database contains vast amounts of data to be retrieved, and the generated nodes can number in the tens of thousands. The scale of nodes analyzed in this section is far from sufficient, and I am concerned about whether this evaluation is objective.\n\n3. The paper contains numerous formatting and typesetting errors, including but not limited to labeling Table 3 as \"Figure 3\" in line 352, and having a half-line of missing text in line 432. Although the research is impressive, I believe the researchers may not have fully prepared the manuscript for preprint release.\n\n4. Nodes and edges are two essential aspects when discussing a graph structure. In the ablation study, only the scale of nodes was examined, while edges were not considered. I would like to know whether this attack method remains effective for sparse graphs or dense graphs."}, "questions": {"value": "As highlighted in my critique of the weaknesses:\n1. Is the proposed method still effective when the number of nodes is large (e.g., >5,000)?\n\n2. How does the method perform when applied to sparse graphs versus dense graphs?\n\n3. Does the method remain effective when the generative model has undergone SFT?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HMIeIzYMz3", "forum": "QTKuEyRHaY", "replyto": "QTKuEyRHaY", "signatures": ["ICLR.cc/2026/Conference/Submission16653/Reviewer_DKmh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16653/Reviewer_DKmh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16653/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761728432328, "cdate": 1761728432328, "tmdate": 1762926714122, "mdate": 1762926714122, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the privacy and security vulnerabilities of Graph Retrieval-Augmented Generation (Graph RAG) systems. The authors propose a novel, query-based attack strategy designed to reconstruct the underlying knowledge graph (KG) from a black-box Graph RAG system . The attack methodology simulates standard graph traversal algorithms: a Breadth-First Search (BFS) approach is used for \"untargeted\" attacks to reconstruct the entire graph structure, while a Depth-First Search (DFS) approach is used for \"targeted\" attacks to extract specific, sensitive information about a particular node . The authors conduct experiments on both general-domain (Freebase) and sensitive-domain (MIMIC-IV) datasets , demonstrating that their attack can recover over 90% of the original KG's structure. Finally, the paper evaluates simple mitigation strategies, such as protective system prompts and output window restrictions, and finds them to be largely ineffective."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Clarity and Presentation: The paper is well-written, and the proposed attack mechanism is explained clearly. The use of BFS and DFS as analogies for the untargeted and targeted query strategies, respectively, is intuitive and easy to follow . Figure 2 provides a strong visual aid for understanding the iterative reconstruction process .\n\n\nSystematic Evaluation: The experimental setup is a key strength. The authors thoroughly evaluate their attack on two distinct datasets (MIMIC-IV and Freebase) and against two different types of Graph RAG systems (retrieval-based and agent-based). The use of established graph-similarity metrics (GED, MCS, and NRR) provides a quantitative and comprehensive measure of the attack's success .\n\n\n\n\n\nRelevant Domain: The paper highlights a significant potential risk, particularly by demonstrating the attack on the sensitive MIMIC-IV healthcare dataset . The case study showing the extraction of a patient's diagnosis and medication schedule is concrete and effectively illustrates the real-world privacy implications ."}, "weaknesses": {"value": "Questionable Problem Formulation (Attack vs. Use): The paper's central weakness is its framing of the \"attack.\" The RAG system, by design, is an interface for retrieving information from the knowledge graph. The proposed \"attack\" is essentially a systematic and exhaustive use of the system's intended functionality—querying for nodes and their relationships. The threat model, a black-box user issuing queries , is indistinguishable from a benign, albeit thorough, user. The vulnerability demonstrated seems to stem less from a subtle flaw in the RAG paradigm and more from a poor system design choice: deploying a RAG system that allows for the verbatim enumeration of all neighbors of a sensitive, non-anonymized graph.\n\n\nIncremental Novelty: While the paper claims to be the first systematic study of Graph RAG privacy , the general concept of extracting private data from RAG systems via querying is already established in prior work on text-based RAG . The main novelty here is the adaptation of this concept from unstructured text to structured graphs. However, the method used for this adaptation—simulating standard BFS/DFS algorithms with queries—is a relatively straightforward approach rather than a fundamentally new attack vector.\n\n\n\n\n\nWeak Mitigation Analysis: The paper evaluates two mitigation strategies: protective system prompts and output window restrictions. The finding that these simple defenses are fragile and easily bypassed  is not particularly surprising, as they are known to be weak against determined prompt injection or iterative querying. The paper would be significantly stronger if it engaged more deeply with the robust defenses it mentions in Section 5.3, such as differential privacy or structural perturbation . A discussion or preliminary experiment on why these are hard to apply to Graph RAG or what their utility-privacy trade-off would be would constitute a more significant contribution."}, "questions": {"value": "Could the authors elaborate on the distinction between their \"attack\" and the system's intended \"use\"? If the system is designed to allow graph exploration, at what point does querying become a malicious attack? Is the vulnerability simply the intent of the user, or is there a specific mechanism being exploited that is separate from normal use?\n\nThe attack's success seems to depend on the RAG system's willingness to return all 1-hop neighbors for a given node . How would the attack perform against a more common RAG setup that retrieves only the top-k semantically relevant neighbors based on the query, rather than all structurally connected neighbors? Would the BFS/DFS traversal still be possible?\n\nRegarding mitigations, the paper suggests that more robust defenses like differential privacy (DP) are a promising direction. How do the authors envision DP being implemented in this context? Would noise be added to the graph structure itself (which might harm utility for all users), or would noise be applied at query time (e.g., by randomly dropping/adding neighbors to the retrieved context)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0MGnfGGaaG", "forum": "QTKuEyRHaY", "replyto": "QTKuEyRHaY", "signatures": ["ICLR.cc/2026/Conference/Submission16653/Reviewer_ZmvG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16653/Reviewer_ZmvG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16653/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966707198, "cdate": 1761966707198, "tmdate": 1762926713701, "mdate": 1762926713701, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates structural privacy risks in Graph RAG systems under black-box access. The authors propose a traversal-based reconstruction attack that leverages structured queries to iteratively extract (node, relation) triples and rebuild large portions of the underlying knowledge graph. They design BFS- and DFS-style query strategies for untargeted and targeted attacks and evaluate them on MIMIC-IV and Freebase across different Graph RAG systems (vector vs. agent retrieval) and LLM backends. Experiments using graph similarity metrics show that a significant fraction of the original structure can be recovered, revealing serious privacy vulnerabilities in current Graph RAG pipelines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper considers an important topic on structural knowledge leakage in Graph RAG systems, and formulates it as a concrete reconstruction problem.\n\n2. The proposed traversal-based attack (BFS/DFS) is conceptually simple yet effective, demonstrating how iterative querying alone can recover large portions of an underlying graph.\n\n3. The paper is well-organized and easy to follow."}, "weaknesses": {"value": "1. The attack pipeline is largely an operational combination of prompt-driven triple extraction and standard graph traversal (BFS/DFS); as presented, the contribution is therefore limited in algorithmic novelty.\n\n2. Small extraction errors cascade: mistakes early in traversal are amplified downstream, so reconstruction quality degrades nonlinearly with depth."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "KTp1Nuo5VN", "forum": "QTKuEyRHaY", "replyto": "QTKuEyRHaY", "signatures": ["ICLR.cc/2026/Conference/Submission16653/Reviewer_Tb9L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16653/Reviewer_Tb9L"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16653/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762030064645, "cdate": 1762030064645, "tmdate": 1762926713285, "mdate": 1762926713285, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper examines the privacy risks associated with Graph RAG systems. The authors propose a \"Traversal Reconstruction\" attack to demonstrate that adversaries can steal significant portions of a graph's structure in a black-box setting. Two attack strategies are formalized based on standard graph algorithms: BFS for untargeted reconstruction and DFS for targeted extraction. The authors claim this is the first systematic study of this vulnerability and report that their method can recover over 90% of the original knowledge graph."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper studies a timely and important issue of privacy implications in emerging Graph RAG systems.\n- The proposed attack methodology is intuitive and straightforward to follow."}, "weaknesses": {"value": "- The paper's novelty claim is undermined by prior work (Liu et al., arXiv:2508.17222) that not only predates it but also provides a more robust analysis of the same problem.\n- The entire attack's viability depends on the assumption that the LLM will act as a simple data repeater. The paper fails to address or even test the LLM's default summarization behavior, which is the key defense and the main hurdle that an attacker must overcome (as shown by Sec. 4.2 of Liu et al.).\n- The motivation for the dataset selection is weak. MIMIC-IV is de-identified, making the PII risk unclear. More importantly, attacking Freebase, a publicly available general knowledge graph, does not appear to align with the stated motivation for evaluating privacy risk.\n- The paper uses computationally expensive metrics like GED and MCS but does not discuss whether they are suitable for KGs (e.g., whether they account for different relation types) or how they are practically employed.\n\n\nLiu, J., Zhang, J., & Wang, S. (2025). Exposing Privacy Risks in Graph Retrieval-Augmented Generation. arXiv preprint arXiv:2508.17222."}, "questions": {"value": "1) The untargeted attack begins from an anchor node (e.g., 'Patient_6381'). If the knowledge graph is private, how does an attacker obtain the initial node ID to initiate the BFS traversal? \n2) Could the authors clarify the dataset selection? Given MIMIC-IV is anonymized, what specific privacy harm is being evaluated? And what is the motivation for attacking a public knowledge graph like Freebase about privacy risks?\n3) Did the authors test their attack against the default behavior of modern LLMs, which is to summarize context? If so, how did the simple BFS/DFS queries overcome this? If not, why should the results be considered valid?\n4) For the NRR metric, what was the exact mechanism for matching a retrieved entity (a text string from the LLM) to a ground-truth node in the graph?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qkEdwpP1CX", "forum": "QTKuEyRHaY", "replyto": "QTKuEyRHaY", "signatures": ["ICLR.cc/2026/Conference/Submission16653/Reviewer_KeEs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16653/Reviewer_KeEs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16653/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762764958500, "cdate": 1762764958500, "tmdate": 1762926712974, "mdate": 1762926712974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}