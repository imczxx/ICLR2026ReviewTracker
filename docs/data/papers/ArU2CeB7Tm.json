{"id": "ArU2CeB7Tm", "number": 444, "cdate": 1756739990077, "mdate": 1759898260876, "content": {"title": "UniEdit-Flow: Unleashing Inversion and Editing in the Era of Flow Models", "abstract": "Flow matching models have emerged as a strong alternative to diffusion models, but existing inversion and editing methods designed for diffusion are often ineffective or inapplicable to them. The straight-line, non-crossing trajectories of flow models pose challenges for diffusion-based approaches but also open avenues for novel solutions. In this paper, we introduce a predictor-corrector-based framework for inversion and editing in flow models. First, we propose Uni-Inv, an effective inversion method designed for accurate reconstruction. Building on this, we extend the concept of delayed injection to flow models and introduce Uni-Edit, a region-aware, robust image editing approach. Our methodology is tuning-free, model-agnostic, efficient, and effective, enabling diverse edits while ensuring strong preservation of edit-irrelevant regions. Extensive experiments across various generative models demonstrate the superiority and generalizability of Uni-Inv and Uni-Edit, even under low-cost settings.", "tldr": "", "keywords": ["Image Inversion", "Image Editing", "Rectified Flow Models", "Iterative Generation Models", "Diffusion Models"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/167b7d303c3ef0820366cb1e67b6b122b414b2c2.pdf", "supplementary_material": "/attachment/0ba2f74c1713128b28b497ba3c9952e5a7d9b7bf.pdf"}, "replies": [{"content": {"summary": {"value": "The paper proposes Uni-Inv and Uni-Edit. Uni-Inv is a predictor-corrector based inversion method that achieves accurate image reconstruction from latent noise, mitigating the large reconstruction errors seen in vanilla flow inversion. Building on this, Uni-Edit is a region-aware image editing strategy that re-enables the concept of delayed injection for flow models. Both methods obtain SoTA results on inversion and editing respectively."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The logic is reasonable and the writing is good.\n2. Uni-inv and uni-edit applies the design of \"take a step back\" and \"take a step forward\", which has emperically demonstrated strong performance.\n3.  The paper provides a theoretical analysis of Uni-Inv, bounding its local error to $\\mathcal{O}(\\Delta t_{i}^{3})$, which justifies its high reconstruction quality."}, "weaknesses": {"value": "1. The reliability of the method seems to be dependent on the choice of hyper-parameter, different images might have different choices of hyper-parameter to achieven the best results. I'm pointing it out since this is a general problem for inversion based editing methods.\n2. On the application side, could Uni-Inv's accurate latent noise capture be used in conjunction with a framework like IP-Adapter, applied to the flow latent, to enable this image-conditioned editing?\n3. The region-adaptive mask m_{i} is calculated based on the difference between target and source velocities. Did the authors experiment with incorporating attention maps, as commonly done in diffusion editing, to see if an even more semantically precise mask could be generated?"}, "questions": {"value": "see weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "do7TvwKJrg", "forum": "ArU2CeB7Tm", "replyto": "ArU2CeB7Tm", "signatures": ["ICLR.cc/2026/Conference/Submission444/Reviewer_7YEx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission444/Reviewer_7YEx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission444/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761804038344, "cdate": 1761804038344, "tmdate": 1762915521797, "mdate": 1762915521797, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new method for image inversion and then editing for flow based models. Compared with previous DDIM inversion style 1st order inversion, the proposed method can be as a high order method. Results show improvement on image editing benchmark PIE-bench."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. In general, the paper is well-written and easy to follow.\n2. The results on PIE-Bench are quite good compared with previous methods."}, "weaknesses": {"value": "1. Overall the proposed inversion method seems a special type of Heun. The difference is: Heun uses the average slope (algo 1 line 3 in the \"for\" loop) while the proposed method only uses the corrector slope. \n\n2. Continue from 1, therefore, I do not fully understand why the proposed method can do better than Heun. Based on Prop 4.1 the local error is of O(t^3). Heun should have the same bound. But based on the visualizations and results from the tables, Heun is not as good as the proposed method. \n\n3. Can you explain appendix section D. Why the inversion method should be related to samplers? The purpose of inversion and inversion based editing is to find the noise given an existing real world image and we are not suppose to know how the image is generated. \n\n4. Continue from 3, what is the data you used in Table 1? Are they generated or real world data? Are they generated with a certain type of solver? \n\n5. Some of the claims are questionable. For example, the trajectory of flow models is not straight, only the conditional trajectory is straight.  \n\n6. The authors may consider to discuss some related to works for inversion in flow based models. For example [1][2]\n\n[1] inversion free image editing (ICCV 25)\n[2] text-to-image rectified flow as plug-and-play priors (ICLR 25)"}, "questions": {"value": "I include the questions in the weaknesses part. Currently I feel the performance is good but I do not fully understand the difference between the proposed method and other high-order methods (or Is it just a reuse of heun-like method for inversion?). \n\nI'll consider to increase my score if my concerns are addressed in the rebuttal."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N.A."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Pzndo0fPS1", "forum": "ArU2CeB7Tm", "replyto": "ArU2CeB7Tm", "signatures": ["ICLR.cc/2026/Conference/Submission444/Reviewer_xe1o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission444/Reviewer_xe1o"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission444/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893497091, "cdate": 1761893497091, "tmdate": 1762915521615, "mdate": 1762915521615, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This submission proposes novel inversion and editing methods specifically designed for flow-based models. For inversion, the paper introduces Uni-Inv, which incorporates an additional correction procedure prior to the inversion step. For editing, leveraging delayed injection, the paper presents Uni-Edit, featuring a predictor-corrector mechanism and a velocity fusion step to enable effective edits while preserving regions irrelevant to the desired changes. The key contributions of this work are the introduction of an extra correction procedure in both inversion and editing processes, as well as the use of velocity fusion in the editing step."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces a predictor-corrector procedure to enhance performance in both inversion and editing tasks. This approach is original and has been extensively evaluated. The method employs delayed injection, which is a widely used technique in image editing and is not an original contribution of this work. The velocity fusion technique, adapted from prior research on region-aware editing, is incorporated into the proposed method. Overall, the paper achieves a satisfactory level of originality and has the potential to inspire future research.\n\n2. The submission presents comprehensive and well-designed experiments, particularly in the Appendix, demonstrating the advantages of the proposed method over baseline approaches in both inversion and editing. Various backbone models and conditioning scenarios are considered and evaluated. In addition, the authors extend their method to video editing and diffusion models, showcasing its flexibility and generalization capabilities.\n\n3. The paper is clearly written and well organized. Figures such as Figure 3 and Figure 5 help readers better understand the algorithm through effective demonstrations and diagrams. Overall, the readability is excellent."}, "weaknesses": {"value": "1. The main concern lies in the ablation study of key components, which is crucial for verifying their effectiveness. The submission presents an ablation study in Table C.1. For unedited regions, metrics such as PSNR and SSIM appear reliable for measuring the accuracy of background preservation. However, regarding the edited regions, relying solely on CLIP similarity may be insufficient to fully demonstrate editing performance. Including human evaluation or visual results in the ablation study would provide a more comprehensive assessment.\n\n2. The implementation of “w/o Uni-Inv” is unclear. To effectively ablate Uni-Inv, experiments similar to those in Figure 4 with different velocity settings could be conducted in the evaluation.\n\n3. Additionally, velocity fusion does not appear to have a significant impact. Its removal results in only a slight decrease in PSNR and SSIM, with CLIP similarity remaining almost unchanged."}, "questions": {"value": "1. What is the difference between “m^{in Corr.}_i = 1” and “w/o Corr.” in the ablation study presented in Table C.1? Both configurations appear to represent Uni-Edit without Correction, yet they yield significantly different results in PSNR/SSIM and CLIP similarity. How can this discrepancy be explained?\n\n2. A more detailed analysis of these key components, supported by visual examples, should be provided to better elucidate the ablation study results. Specifically, it would be helpful to understand why certain metrics increase or decrease when specific components are removed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "efqxeeHc7g", "forum": "ArU2CeB7Tm", "replyto": "ArU2CeB7Tm", "signatures": ["ICLR.cc/2026/Conference/Submission444/Reviewer_aUpR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission444/Reviewer_aUpR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission444/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959513370, "cdate": 1761959513370, "tmdate": 1762915521452, "mdate": 1762915521452, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces UniEdit-Flow, a training-free, model-agnostic pipeline for flow models that tackles (i) exact inversion problem that aims to transitions from a data to the corresponding latent via a predictor–corrector scheme (Uni-Inv) that aligns an implicit-Euler step and proves an bound for error of the proposed method, , and (ii) editing method (Uni-Edit) using region-adaptive and delayed injection for locality preservation while changing the target subject."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "– Mostly well written and easy to follow. \n\n– Problem and solution are well-motivated; the design is simple yet effective. \n\n– Impressive results: consistent gains for inversion (Table 1) and editing (Table 2), with strong qualitative examples on SD3 and FLUX. \n\n– Demonstrations across varied applications suggest good generality and a principled approach."}, "weaknesses": {"value": "– The transition from §4.2 to §4.3 is hard to track. In Fig. 5 and the surrounding text, a correction step uses $v_{i}^{S}$ to move the latent to a higher-noise state, then $v_{i}^{T}$ to correct under the new prompt; however, it’s unclear which velocity is applied next—the phrase “apply the current editing velocity to move the latent to $\\tilde Z_{t_{i-1}}$ is ambiguous.\n\n– Fig. 5 introduces $v_{i}^{F}$ without prior definition; its relation to $v_{i}^{S}$ and $v_{i}^{T}$, and its role in updating $\\tilde Z_{t_{i-1}}$, are not explained at that point in the main text. I would prefer an explicit introduction in the text rather than only in the caption (as in Fig. 3)."}, "questions": {"value": "– Please define $v_{i}^{F}$ when it first appears and clarify how it\nis constructed from $v_{i}^{S}$ and $v_{i}^{T}$ (e.g., fusion rule,\nweights, timing), or at least indicate what it is and where it will\nbe specified, rather than only in the Fig. 3 caption.\n\n– Specify precisely what “current editing velocity” refers to at the step that updates $\\tilde Z_{t_{i-1}}$ and provide the explicit update equation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UVfV4zKpo5", "forum": "ArU2CeB7Tm", "replyto": "ArU2CeB7Tm", "signatures": ["ICLR.cc/2026/Conference/Submission444/Reviewer_J9uw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission444/Reviewer_J9uw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission444/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982961590, "cdate": 1761982961590, "tmdate": 1762915521298, "mdate": 1762915521298, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}