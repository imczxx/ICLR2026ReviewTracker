{"id": "HmQAAMuZWC", "number": 3172, "cdate": 1757348916796, "mdate": 1763102538869, "content": {"title": "SOPSeg: Prompt-based Small Object Instance Segmentation in Remote Sensing Imagery", "abstract": "Extracting small objects from remote sensing imagery plays a vital role in various applications, including urban planning, environmental monitoring, and disaster management. While current research primarily focuses on small object detection, instance segmentation for small objects remains underexplored, with no dedicated datasets available. This gap stems from the technical challenges and high costs of pixel-level annotation for small objects.\nWhile the Segment Anything Model (SAM) demonstrates impressive zero-shot generalization, its performance on small-object segmentation deteriorates significantly, largely due to the coarse 1/16 feature resolution that causes severe loss of fine spatial details.\nTo this end, we propose SOPSeg, a prompt-based framework specifically designed for small object segmentation in remote sensing imagery. It incorporates a region-adaptive magnification strategy to preserve fine-grained details, and employs a customized decoder that integrates edge prediction and progressive refinement for accurate boundary delineation. Moreover, we introduce a novel prompting mechanism tailored to the oriented bounding boxes widely adopted in remote sensing applications.\nSOPSeg outperforms existing methods in small object segmentation and facilitates efficient dataset construction for remote sensing tasks. We further construct a comprehensive small object instance segmentation dataset based on SODA-A, and will release both the model and dataset to support future research.", "tldr": "", "keywords": ["Segment Anything Model", "Instance Segmentation", "Small Object Imagery"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/fc510503d51895353f3fae5014959aabec90126d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper tackles the challenge of small object instance segmentation in remote sensing imagery. This task remains largely unexplored due to the lack of pixel-level annotated datasets and the difficulty of segmenting fine-scale targets. To address this, the authors propose SOPSeg (Small Object Prompted Segmentation), a prompt-based framework that adapts the Segment Anything Model (SAM) for small-object segmentation. SOPSeg introduces three key innovations:\n1)\tRegion-adaptive magnification to preserve fine spatial details lost during downsampling.\n2)\tAn edge-aware decoder that combines boundary prediction and progressive refinement for precise mask generation.\n3)\tAn oriented prompting mechanism tailored for rotated bounding boxes common in aerial imagery.\nSOPSeg achieves superior performance over SAM and other prompt-based baselines on multiple datasets, including iSAID, NWPU-VHR10, and SAT-MTB. Furthermore, it is used to construct ReSOS, the first large-scale remote sensing small object instance segmentation dataset, containing over 709,000 pixel-level annotations derived from SODA-A. Overall, the work provides both a novel model and a valuable dataset, advancing research on fine-grained small object analysis in remote sensing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is original in focusing on small object instance segmentation in remote sensing imagery, a problem that has received limited attention. It proposes a reasonable and targeted framework (SOPSeg) that extends the Segment Anything Model with region-adaptive magnification, edge-aware decoding, and oriented prompting, effectively addressing the limitations of existing methods on small targets. The technical design is sound, and the experiments on several public datasets provide convincing evidence of improvement. The construction of the ReSOS dataset also adds practical value by supporting future research. Overall, the paper is clearly presented."}, "weaknesses": {"value": "1)\tDataset construction lacks transparency.\nWhile the ReSOS dataset is an important contribution, the paper provides limited information on annotation quality control and manual filtering criteria. Details such as the number of annotators, inter-annotator agreement, or filtering ratio would improve reproducibility and trust in dataset quality.\n2)\tGeneralization evaluation could be expanded.\nThe model is validated on iSAID, NWPU-VHR10, and SAT-MTB, which share similar imaging styles and object categories. Testing on datasets with different sensors or resolutions (e.g., DOTA or FAIR1M) would better demonstrate robustness across varying data domains.\n3)\t Computational efficiency discussion is limited.\nAlthough the paper reports GFLOPs, there is no analysis of runtime or memory consumption under different region magnification settings. Since SOPSeg involves region extraction and multi-scale refinement, efficiency and scalability to large scenes remain unclear.\nOverall, the work is technically solid and practically useful, but the dataset transparency, and analytical depth could be further improved to strengthen its scientific contribution."}, "questions": {"value": "On the region-adaptive magnification strategy:\n1)\tWould it be possible to learn these parameters dynamically through a lightweight network or reinforcement signal rather than using a predefined rule?\nOn the oriented prompting mechanism:\n1)\tThe method selects the object center and two midpoints of the short edges as prompts. How sensitive is the segmentation performance to the exact location or number of these points?\n2)\tIn cluttered scenes where objects overlap, how does the prompting mechanism avoid interference between nearby instances?\nOn the edge-aware decoder and refinement process:\n1)\tCould the authors clarify how the edge branch interacts with the main mask branch during multi-scale refinement? Is there any feature sharing or fusion between them?\n2)\tWhat is the computational overhead introduced by the edge prediction and iterative refinement steps compared with the original SAM decoder?\n3)\tHave the authors visualized intermediate feature maps or edge activations to show how the refinement improves small-object boundaries?\nOn the ReSOS dataset construction:\n1)\tThe dataset creation pipeline mentions automatic mask generation followed by manual filtering. Could the authors provide more details on the filtering process—such as the proportion of removed masks, annotator consistency, or validation criteria?\n2)\tHow is annotation quality verified? Were any quality metrics (e.g., IoU between annotators, random spot checks) used?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9UA4Chm9bj", "forum": "HmQAAMuZWC", "replyto": "HmQAAMuZWC", "signatures": ["ICLR.cc/2026/Conference/Submission3172/Reviewer_Umos"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3172/Reviewer_Umos"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3172/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893100280, "cdate": 1761893100280, "tmdate": 1762916582817, "mdate": 1762916582817, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "AxZj2WxtaJ", "forum": "HmQAAMuZWC", "replyto": "HmQAAMuZWC", "signatures": ["ICLR.cc/2026/Conference/Submission3172/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3172/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763102538117, "cdate": 1763102538117, "tmdate": 1763102538117, "mdate": 1763102538117, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenging and underexplored task of small object instance segmentation in remote sensing imagery. The authors identify a key limitation in existing models like SAM: their coarse feature resolution leads to a significant loss of detail, hampering performance on small objects.\nTo overcome this, the paper introduces SOPSeg, a prompt-based framework with three main contributions:\n\n1.**A novel model architecture:** It incorporates a region-adaptive magnification strategy to preserve fine-grained details and a customized decoder that uses edge prediction and progressive refinement for accurate boundaries.\n\n2.**A tailored prompting mechanism:** It is designed to work with oriented bounding boxes, which are prevalent in remote sensing applications.\n\n3.**A new public resource:** The authors construct and will release SODA-A-seg, a dataset for small object instance segmentation, addressing a resource gap in this domain."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper's main merit lies in identifying and tackling a significant and challenging problem: instance segmentation of small objects in remote sensing imagery. This is an important, practical area where foundational models like SAM are known to struggle, so the motivation is strong and well-founded.\n\nThe commitment to construct and release a new dataset, SODA-A-seg, is a laudable goal. The community lacks such a dedicated resource for small object instance segmentation, and if executed well, this could become a valuable contribution. Creating new benchmarks is a critical service to the field.\n\nConceptually, some of the proposed architectural ideas are sound. The region-adaptive magnification strategy is a logical approach to address the loss of fine-grained details for small objects, which is a known limitation of standard Vision Transformer backbones. Similarly, adapting the prompt mechanism to handle oriented bounding boxes (OBBs) demonstrates an awareness of the specific needs of the remote sensing domain."}, "weaknesses": {"value": "While the paper addresses an important problem, its current execution suffers from several major weaknesses that undermine its contributions and call its conclusions into question.\n\n1.**Insufficient Empirical Support for Core Claims:** The paper's central motivation—that SAM's failure on small objects is primarily due to its coarse 1/16 feature resolution—is presented as a fact but is never experimentally verified. A rigorous paper would include an analysis or ablation study to support this claim. For instance, the authors could have evaluated features from earlier, higher-resolution stages of SAM's encoder or compared its performance on small versus large objects within the same dataset to quantify the performance degradation.\n\n2.**Inadequate Experimental Comparisons:** The baseline coverage is too narrow, as the main table compares almost exclusively with SAM series (SAM/HQ-SAM/ROS-SAM) and UGBS, lacking comparisons with non-SAM prompt-based frameworks. This narrow scope weakens the generality claim and raises fairness concerns around prompts; to substantiate generality, include strong non-SAM baselines (e.g., Mask2Former, MaskDINO, SparseInst).\n\n3.**The Dataset Contribution is Unverifiable:** The paper claims the new SODA-A-seg dataset as a major contribution, yet it provides almost no details about it. The text explicitly defers these crucial details—such as dataset size, object categories, object size distribution, annotation protocol, and quality control measures—to an appendix that is not provided with the submission. This is a critical omission. Without this information, it is impossible for reviewers to assess the quality, scale, or significance of this claimed contribution. A contribution that cannot be reviewed is, for all practical purposes, non-existent in the context of this submission.\n\n4.**Poor Presentation Quality and Lack of Clarity:** The overall presentation of the paper falls short of the standards expected at ICLR. There are numerous issues with the layout and formatting, such as the misalignment of Figure 4 and Table 5, which disrupt the flow and suggest a lack of careful preparation. Beyond aesthetics, many figures are poorly explained, lack detailed captions, and are difficult to interpret. This lack of clarity is not merely cosmetic."}, "questions": {"value": "**Q1.** ReSOS masks are generated by SOPSeg then filtered manually. How did you quantify and mitigate method-induced bias/circularity—e.g., percent masks edited/rejected, cross-model re-annotation, and impact on non-SOPSeg methods’ rankings? \n\n**Q2.** When compared with SAM/HQ-SAM/ROS-SAM/UGBS, are identical oriented prompts (OBB + keypoints) provided for all baselines? If not, please report the results after adding equivalent prompts to isolate the OPM gain and ensure fairness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gRcxbegVqu", "forum": "HmQAAMuZWC", "replyto": "HmQAAMuZWC", "signatures": ["ICLR.cc/2026/Conference/Submission3172/Reviewer_i7qd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3172/Reviewer_i7qd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3172/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907860914, "cdate": 1761907860914, "tmdate": 1762916582672, "mdate": 1762916582672, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a SAM-style instance segmentation framework for small objects in high-resolution remote sensing images. The proposed framework also extends a previous object detection samples to a new datasets with masks. The experiments on several datasets verified the effectiveness of the additional information extraction and support for the proposed framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is easy-to-follow. The explanations on the proposed modules are clear. The experiments report the key metrics of instance segmentation work."}, "weaknesses": {"value": "I have several questions and comments on this paper.\n\n1. Why did the authors select 7 out of 15 categories? Are these categories are all small objects? How about the others? I cannot find a clear definition on the 'small' concept. The missing information probably makes it unclear for readers.\n2. How is the generated data quality based on the SOPSeg framework? The authors claimed that they did the manual filtering to refine the samples. However, I cannot find any information about the details regarding the quality and filtering.\n3. The authors pointed out previous works cannot handle diverse small objects. However, in the settings from this paper. the categories only cover 7 types. We cannot know the real performance when facing multiple and diverse small objects in remote sensing domain, e.g., panel, window, flag. or road sign.\n4. From my understanding, the region-adaptive magnification strategy rely on the coarse bounding box annotation for the precise localization, then it's not fair to directly compare the results with other models as it has additional information fed into the network. Moreover, finding a small object from remote sensing images is not easy, either. which makes the motivation not so convincing.\n5. The two prompt points are generated based on the bounding boxes, while the orientation of a object is not always consistent with its mask prediction. They are not 100% correct for a complex object.\n6. What is the motivation of the evaluation 4.4? We can know the coarse performance of the popular models on the proposed dataset. However, we don't know the low performance is caused by the data complexity or the restriction of the models on the remote sensing images, or the correctness of the data.\n7. The proposed strategies are not new in remote sensing domain, e.g., local cropping, point-orientation, and the progressive refinement."}, "questions": {"value": "See weaknesses above."}, "flag_for_ethics_review": {"value": ["Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)"]}, "details_of_ethics_concerns": {"value": "The previous datasets modified in this paper."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YHkaR5UDvD", "forum": "HmQAAMuZWC", "replyto": "HmQAAMuZWC", "signatures": ["ICLR.cc/2026/Conference/Submission3172/Reviewer_Mjck"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3172/Reviewer_Mjck"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3172/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926064901, "cdate": 1761926064901, "tmdate": 1762916582486, "mdate": 1762916582486, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new model named SOPSeg for small object instance segmentation of remote sensing images, and produces a new large-scale remote sensing small object instance segmentation dataset ReSOS. Based on the original architecture of SAM, the model introduces an edge-aware decoder, adds a parallel edge prediction branch, and gradually refines the prediction results of the model by combining multi-scale features to improve the instance segmentation effect of small objects. In order to cope with the loss of small object information caused by the downsampling operation in the image encoder, the Region-adaptive magnification(RAM) strategy increases the size of the small object in the input image by cropping and amplifying the size of the region where the small object is located. At the same time, the oriented prompting mechanism(OPM) is used to give the model directional point prompts to cope with the rotating bounding box in the aerial image. Experiments show that the method achieves sota performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The SOPSeg proposed by the author has achieved the best performance compared with other prompt-based methods on multiple datasets. \n2.Sufficient ablation experiments verified the performance improvement brought by each module. \n3.The author has constructed a new remote sensing image small target instance segmentation data set to provide support for subsequent research on related tasks."}, "weaknesses": {"value": "1.This paper only compared the model performance with the prompt-based model in the experiment of model performance comparison. \n2.The performance improvement of the SOPSeg mainly comes from the technical processing operations of the two modules of RAM and OPM, rather than the innovation of the model."}, "questions": {"value": "1.The author seems to have only compared the model performance with the prompt-based model in the experiment. Can you consider adding some non-this type of model for performance comparison? \n2.In the region adaptive amplification strategy, how to select the object for the cropping and amplification of the small target dense region? \n3.In the region adaptive amplification strategy, if the complete target object in the original image appears incomplete at the edge of the cropping region, how to solve the adverse effects on the model?\n4.When the target is no longer an elongated object such as a vehicle and a ship, but an object with an irregular shape, can the midpoint of the short-edge in the oriented prompting mechanism still provide accurate object direction guidance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "daBx0h8qyr", "forum": "HmQAAMuZWC", "replyto": "HmQAAMuZWC", "signatures": ["ICLR.cc/2026/Conference/Submission3172/Reviewer_Q44A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3172/Reviewer_Q44A"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3172/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762142402579, "cdate": 1762142402579, "tmdate": 1762916582317, "mdate": 1762916582317, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}