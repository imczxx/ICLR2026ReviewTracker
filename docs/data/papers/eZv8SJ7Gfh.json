{"id": "eZv8SJ7Gfh", "number": 17911, "cdate": 1758281949320, "mdate": 1762928257385, "content": {"title": "Anti-Adapter Armor: A Universal and Authentication-Integrated Framework for Preventing Unauthorized Zero-Shot Image-to-Image Generation", "abstract": "With the advancement of diffusion models, image generation has entered an era of zero-shot image-to-image synthesis, where highly similar facial identities or artistic styles can be produced using only a single portrait or artwork as input, without requiring any model parameter fine-tuning. However, while these technologies offer significant benefits to artistic creation, they simultaneously introduce non-negligible risks associated with right infringement, such as the unauthorized forgery of facial identities and the plagiarism of artistic styles. To address these risks, this paper proposes Anti-Adapter Armor, the first universal and authentication-integrated framework designed to protect personal images against unauthorized zero-shot image-to-image generation. We begin by analyzing how existing zero-shot image-to-image methods utilize image encoders to convert input images into embeddings, which are injected into the diffusion model's UNet via cross-attention. Based on this, we develop a reversible encryption framework that transforms original image embeddings into diverse encrypted forms based on different passwords. Authorized users can recover the original embeddings using the decryptor and correct passwords for normal image generation. To achieve protection, we propose a multi-targeted adversarial attack that transfers the original image embeddings into the encrypted forms by adding adversarial perturbation. Therefore, the protected images are equipped with a protective coating that restricts unauthorized users to generating encrypted content exclusively. Extensive experiments show that our approach outperforms state-of-the-art protection methods in preventing unauthorized zero-shot image-to-image generation, while enabling adaptable and secure authentication for authorized users.", "tldr": "", "keywords": ["copyright protection; data poisoning; diffusion model"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/183c65e174f388984fde660cd777d0d469e2350d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces Anti-Adapter Armor, a purported universal, authentication-integrated framework to protect images against unauthorized zero-shot image-to-image (I2I) generation. It combines embedding encryption with adversarial perturbations (“protective coating”). Experiments are conducted on facial identity protection and artwork anti-plagiarism tasks, claiming superiority over existing baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Addresses an important and timely problem of protecting personal images from unauthorized zero-shot I2I generation.  \n2. Proposes a practical framework combining embedding encryption with adversarial perturbations.  \n3. Provides initial experimental validation on both facial identity protection and style plagiarism tasks."}, "weaknesses": {"value": "**1. Limited Novelty**\n\n* The paper combines adversarial perturbations with password-conditioned embedding transformations. Both ideas are established in the literature, and while the integration is interesting, it may not represent a substantial conceptual advance.\n* The claim of being the “first universal and authentication-integrated framework” seems somewhat overstated. Prior work on adversarial cloaking, de-identification, and watermarking has explored similar directions. The contribution, while practical, feels incremental.\n\n**2. Technical Soundness and Clarity**\n\n* The encryption/decryption modules are described at a high level, but the design choice (attention-based architecture) is not fully justified. It would help to clarify why this approach is preferable to simpler baselines (e.g., projection + password mixing).\n* The loss formulation appears to be a combination of multiple cosine-similarity terms with heuristic weights. More explanation or theoretical motivation for how these terms interact would strengthen the work.\n* The security-related claims (e.g., low wrong decryption rate, password robustness) may give the impression of cryptographic guarantees, which the current framework does not provide. Clarifying the security assumptions and limitations would improve credibility.\n\n**3. Experimental Limitations**\n\n* Experiments are performed on relatively small subsets of CelebA, FFHQ, and WikiArt. The test sets (200 faces, 50 paintings) make it difficult to draw strong conclusions about universality.\n* Only two I2I methods per task are tested. Given the diversity of zero-shot generation approaches (ControlNet, fine-tuned diffusion, hybrid encoders), additional coverage would make the evaluation more convincing.\n* The evaluation relies on cosine similarity, AFR, and PSNR, but omits user studies or perceptual evaluations. Moreover, robustness to adaptive adversaries and purification strategies is not examined, which is important for a protection framework.\n\n**4. Missing Threat Model**\n\n* A clear definition of the threat model is essential but absent. It is not specified whether attackers are assumed to have white-box, black-box, or gray-box access, nor what their goals and resources are. Without this, the scope of protection is unclear.\n\n**5. Suggested Additional Experiments**\n\n* **Adaptive white-box attacks**: Direct optimization against the encryption/perturbation objective.\n* **Black-box query-based attacks**: Gradient-free or query-efficient methods to approximate embeddings.\n* **Purification-based attacks**: Denoising, diffusion-based reconstruction, or JPEG recompression.\n* **Cross-encoder transfer**: Testing recovery using unseen encoders to assess generalization of protection."}, "questions": {"value": "W1, W2, W4"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NimpiUInyP", "forum": "eZv8SJ7Gfh", "replyto": "eZv8SJ7Gfh", "signatures": ["ICLR.cc/2026/Conference/Submission17911/Reviewer_ED7f"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17911/Reviewer_ED7f"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17911/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760493601982, "cdate": 1760493601982, "tmdate": 1762927731692, "mdate": 1762927731692, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "cCVLqWTCAl", "forum": "eZv8SJ7Gfh", "replyto": "eZv8SJ7Gfh", "signatures": ["ICLR.cc/2026/Conference/Submission17911/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17911/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762928256321, "cdate": 1762928256321, "tmdate": 1762928256321, "mdate": 1762928256321, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a framework called \"Anti-Adapter Armor,\" which aims to prevent unauthorized face forgery or art style mimicry by AI models by adding a password-protected adversarial \"coating\" to images. The core mechanism is that this coating misleads the AI model into extracting an encrypted, incorrect image feature, thus generating distorted content. Authorized users, however, can use the correct password with a decryptor to recover the correct feature for normal use.\n\nThe idea behind this work is very interesting. However, its core contribution is more a clever integration of existing technologies than a fundamental methodological or theoretical breakthrough. This makes it a less suitable fit for ICLR."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Importance and Practical Value of the Problem: This paper addresses a critical and pressing real-world issue in the era of AI-generated content (AIGC)—how to protect individuals' portrait rights and artists' intellectual property. This represents a research direction with significant practical value.\n- Comprehensive Framework Design: The proposed framework demonstrates thorough consideration, with its integrated “authentication mechanism” standing out as a key highlight. Compared to previous irreversible protection methods, cryptography-based authorized usage significantly enhances the scheme's flexibility and practicality.\n- Thorough Experimental Evaluation: The authors conducted comprehensive experiments covering two major scenarios—facial identity protection and artistic style anti-plagiarism—and compared their framework with multiple existing methods. This validated the framework's effectiveness and versatility."}, "weaknesses": {"value": "- Limited Novelty for ICLR: The primary weakness is the work's limited methodological novelty for a venue like ICLR. While the framework is a clever and valuable application, it primarily combines existing techniques (adversarial attacks, attention networks) rather than introducing a fundamental algorithmic breakthrough in machine learning.\n\n- Lossy Encryption Mechanism: The proposed \"encryption-decryption\" cycle is inherently lossy, as its objective is to maximize cosine similarity rather than achieve perfect, bit-for-bit reconstruction. This functional reversibility, while practical, differs fundamentally from true cryptographic invertibility and may not be suitable for all use cases.\n\n- Limited Robustness: The framework's robustness against common image transformations is a significant concern. The authors explicitly acknowledge its vulnerability to JPEG compression, a ubiquitous format online. Furthermore, the paper lacks evaluation against more sophisticated adversarial purification techniques, leaving its resilience in a practical threat landscape an open question."}, "questions": {"value": "- Could the authors clarify what constitutes the core algorithmic innovation, beyond the integration of established components?\n\n- The proposed “encryption–decryption” cycle appears inherently lossy, as it aims to maximize cosine similarity rather than achieve exact reconstruction. How do the authors reconcile this with the notion of encryption, which typically implies perfect invertibility?\n\n- The authors acknowledge vulnerability to JPEG compression—a common transformation in online environments. How might the proposed framework be adapted to handle such lossy compression while preserving privacy effectiveness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rlHuTxLDgA", "forum": "eZv8SJ7Gfh", "replyto": "eZv8SJ7Gfh", "signatures": ["ICLR.cc/2026/Conference/Submission17911/Reviewer_BHeY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17911/Reviewer_BHeY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17911/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760632421298, "cdate": 1760632421298, "tmdate": 1762927731280, "mdate": 1762927731280, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Anti-Adapter Armor, a framework that adds imperceptible perturbations to protects images against ID-preserving generation or image plagiarism. At the center of the method is a multi-target adversarial attack. The protection is also associated with a password, which could be used by authorized users to decrypt the image embedding useful for generation. Experiment results demonstrated the effectiveness of this method in protection and decryption, robustness against certain distortions, and ablations about the encryption/decryption details."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "-\tThe method protects the content while still allowing authorized users to bypass the protection with a specific key for legitimate regeneration. This is a novel and practical design.\n-\tCompared to existing methods, the protection maintains good visual quality, introducing fewer visible artifacts.\n-\tAlthough not explicitly demonstrated by the authors, the method should have a significantly faster image processing speed than optimization-based methods."}, "weaknesses": {"value": "-\tThe writing in Section 4 (Experiments) is largely descriptive and lacks discussion. The authors present results in Tables and Figures, but do not adequately interpret them to draw clear conclusions or provide justifications. The paper would be significantly strengthened if the authors explicitly connect the results presented to the properties/advantages of the proposed method.\n-\tThe robustness evaluation is insufficient. The experiments cover common image processing distortions like noise and blur, but do not explore robustness to pixel-misaligned scenarios, such as rotation or scaling, so it remains unclear whether the protection would still be effective under these common transformations.\n-\tThe experiments are confined to InstantID and a few variants of IP-Adapter. It is unclear whether the protection would still be effective against unseen regeneration models, such as Midjourney.\n-\tSeveral factual errors:\n  - Line 77: IDProtector is not a data-poisoning method, but an adversarial attack-based method, which functions similarly to the approach in this work. Methods like Anti-Dreambooth/SimAC are data-poisoning methods. \n  - Line 81: IDProtector is an open-source method.\n  - Line 86: It is not true that protective methods are generally vulnerable to image post-processing. On the contrary, many methods (such as IDProtector) have demonstrated considerable robustness to such techniques."}, "questions": {"value": "-\tWhy artwork similarity is measured using ESM? How reliable is this metric?\n-\tThe epsilon budget for artwork protection (21/255) is very large, yet the perceptual distortion shown in the images appear minimal. What could be the reasons for this apparent inconsistency?\n-\tWhy were different similarity thresholds and epsilon budgets used for the facial identity protection and the artwork anti-plagiarism settings? Would it be possible for one image to simultaneously achieve both protections while maintaining the currently reported performance?\n-\tWhat are the epsilon budgets used for the baseline methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BLY4Ep4bG9", "forum": "eZv8SJ7Gfh", "replyto": "eZv8SJ7Gfh", "signatures": ["ICLR.cc/2026/Conference/Submission17911/Reviewer_tyLK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17911/Reviewer_tyLK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17911/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761372971485, "cdate": 1761372971485, "tmdate": 1762927730857, "mdate": 1762927730857, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Anti-Adapter Armor, a proactive protection framework against unauthorized zero-shot image-to-image generation. The method introduces (1) a reversible embedding encryption mechanism conditioned on a password, and (2) a multi-target adversarial protective coating that perturbs images. It blocks unauthorized users while allowing authorized users to use the encrypted images. Experiments show substantial protection efficacy and robustness to common distortions."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper proposes a novel framework for protecting images from unauthorized zero-shot image-to-image generation while providing an authentication mechanism that allows authorized users to generate proper images.  \n2. The paper writing is good and easy to follow. \n3. Experimental results show better protection performance compared to baselines. \n4. Various losses are designed to properly encrypt the image embedding."}, "weaknesses": {"value": "1. It seems the proposed method requires using the same image encoder as the users. What if the users use an unknown image encoder that is not considered during optimization?\n2. In Tab 3, it will be interesting to see the evaluation under more sophisticated adversarial purification methods such as DiffPure (https://arxiv.org/abs/2205.07460) in addition to simple image distortions. In addition, the results can be compared with baselines to understand the relative robustness of the proposed method. \n3. While the authors claim that authorized users can use the image for image generation, the experiment results are mainly on preventing unauthorized users, and there is no quantitative result on the image generation performance when the correct password is used for decryption. \n4. Regarding the motivation of the work, can \"Bob\" just provide \"Alice\" (the authorized user) the original unprotected image without the need for the authorization mechanism? What are the benefits of the current approach? This should be discussed in the paper."}, "questions": {"value": "See the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4lHL8xUNDo", "forum": "eZv8SJ7Gfh", "replyto": "eZv8SJ7Gfh", "signatures": ["ICLR.cc/2026/Conference/Submission17911/Reviewer_utEG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17911/Reviewer_utEG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17911/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973530041, "cdate": 1761973530041, "tmdate": 1762927730253, "mdate": 1762927730253, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}