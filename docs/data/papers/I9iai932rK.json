{"id": "I9iai932rK", "number": 13551, "cdate": 1758219118150, "mdate": 1763751198016, "content": {"title": "Joint Discriminative-Generative Modeling via Dual Adversarial Training", "abstract": "Simultaneously achieving robust classification and high-fidelity generative modeling within a single framework presents a significant challenge. Hybrid approaches, such as Joint Energy-Based Models (JEM), interpret classifiers as EBMs but are often limited by the instability and poor sample quality inherent in Stochastic Gradient Langevin Dynamics (SGLD)-based training. We address these limitations by proposing a novel training framework that integrates adversarial training (AT) principles for both discriminative robustness and stable generative learning. The proposed method introduces three key innovations: (1) the replacement of SGLD-based JEM learning with a stable, AT-based approach that optimizes the energy function by discriminating between real data and Projected Gradient Descent (PGD)-generated contrastive samples using the BCE loss; (2) synergistic adversarial training for the discriminative component that enhances classification robustness while eliminating the need for explicit gradient penalties; and (3) a two-stage training strategy that addresses normalization-related instabilities and enables leveraging pretrained robust classifiers, generalizing effectively across diverse architectures. Experiments on CIFAR-10, CIFAR-100, and ImageNet demonstrate that our method substantially improves adversarial robustness over existing hybrid models while maintaining competitive generative performance. On ImageNet 256$\\times$256, our approach with ConvNeXt-Large achieves generative quality matching state-of-the-art diffusion and autoregressive models, representing the first explicit EBM to achieve such high-quality generation on complex, high-resolution datasets. Our approach addresses key stability issues that have limited JEM scaling and demonstrates that adversarial training can serve as an effective foundation for unified frameworks capable of generating and robustly classifying visual data.", "tldr": "This paper proposes a novel hybrid model that integrates adversarial training into Joint Energy-Based Models (JEM) to achieve both robust classification and high-fidelity generative modeling.", "keywords": ["Joint Modeling", "Energy-Based Models (EBMs)", "Adversarial Training", "Robust Classification", "Generative Modeling", "PGD Attacks", "explainability"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4239cfb00a0451ac94424d5f0f971ae548f383b9.pdf", "supplementary_material": "/attachment/b3f199cd5e8c3ada5949b4d8ae8c0c42fe4f006a.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents DAT (Dual Adversarial Training), a framework that integrates adversarial training into Joint Energy-Based Models (JEMs) to achieve both robust classification and high-quality image generation. The method replaces unstable SGLD-based learning with an adversarial optimization using PGD-generated samples and introduces a two-stage procedure to handle batch normalization issues. Experiments on CIFAR-10, CIFAR-100, and ImageNet show competitive robustness (similar to standard AT) and improved generative quality (FID 5.39 on ImageNet). The motivation is to bridge discriminative and generative modeling, combining the accuracy of classifiers with the data awareness of generative models. While the formulation is clean and the results promising, the practical benefits of unifying these two objectives remain somewhat unclear."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses a well-known instability in JEM training through an elegant adversarial reformulation that improves both convergence and visual quality. The proposed method removes the need for gradient penalties and achieves stable training even on ImageNet, which is impressive for EBMs. The experiments are extensive and reproducible, comparing DAT against strong hybrid and adversarial baselines. Quantitatively, DAT outperforms RATIO and JEM in both robustness and FID, and qualitatively the generated samples show fewer artifacts. Overall, this is a careful and technically strong piece of work that meaningfully advances the robustness and scalability of energy-based hybrids."}, "weaknesses": {"value": "The paper is technically competent and experimentally thorough, but the contribution feels incremental relative to prior hybrid frameworks. While the work pushes JEMs toward stability and competitive generative quality, it does not yet offer a compelling argument for hybrid modeling over modern specialized alternatives such as more recent, 2024 and beyond, diffusion models and GAN variants. Without stronger empirical evidence of unique practical benefits, the paper’s impact may be limited."}, "questions": {"value": "How does it compare in efficiency and scalability to modern diffusion and GAN models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fL7OAtbjc3", "forum": "I9iai932rK", "replyto": "I9iai932rK", "signatures": ["ICLR.cc/2026/Conference/Submission13551/Reviewer_MpyS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13551/Reviewer_MpyS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13551/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891596250, "cdate": 1761891596250, "tmdate": 1762924151088, "mdate": 1762924151088, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a hybrid framework that aims to unify discriminative robustness and generative modeling within a single network. The method replaces the JEM-style SGLD negative sampling with adversarially generated negatives (PGD) and trains the energy with a binary classification loss, while the classifier head is trained with standard adversarial training (AT). Experiments on CIFAR-10/100 and ImageNet report improved adversarial robustness relative to hybrid baselines and competitive (sometimes strong) generative quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tReplacing SGLD with PGD negatives makes the training loop simple and scalable. The two-stage BN recipe is an effective engineering fix to a well-known incompatibility in EBM-style training.\n2.\tThe dual view (AT for the classifier and contrastive/AT-style learning for energies) offers a single model that can produce robust predictions, counterfactuals, and samples.\n3.\tResults are reported up to ImageNet, suggesting attention to large-scale feasibility.\n4.\tPublic code (if complete and reproducible) increases practical impact and adoption."}, "weaknesses": {"value": "1.\tThe conceptual novelty is limited. The core idea (learn energies with adversarial negatives and train the classifier adversarially) has clear antecedents in AT-EBM/CEM/JEM++/Robust-JEM[1] lines of work that (i) use contrastive or adversarially produced negatives to shape an energy landscape, (ii) draw formal links between AT objectives and energy-based views, (iii) report stability benefits relative to SGLD, and (iv) An empirical study on AT improving JEM/JEM++.\n2.\tThe BCE-with-PGD objective likely corresponds to a contrastive density-ratio under a local worst-case neighborhood. It remains unclear what distribution is being learned and how/when this departs from MLE-style JEM; a formal treatment would strengthen the paper.\n3.\tThe paper does not provide convincing diagnostics that AT stabilizes SGLD-based JEM training (e.g., training curves, divergence/failure rates, gradient-norm statistics), beyond final performance metrics.\n4.\tThe proposed DAT is not compared head-to-head with prior AT-JEM methods (e.g., Robust-JEM) under matched backbones, budgets, and evaluation protocols, making it hard to attribute gains to the proposed ingredients rather than setup differences.\n\n[1] Korst, R., & Asadulaev, A. (2022). Adversarial training improves joint energy-based generative modelling. arXiv preprint arXiv:2207.08950."}, "questions": {"value": "1.\tPlease provide evidence that AT stabilizes SGLD-based JEM training: show training curves, failure/divergence rates, and input-gradient norm, not only final metrics.\n2.\tPlease sharpen the novelty narrative relative to AT-EBM, CEM, JEM++, and Robust-JEM: what is fundamentally new here (objective, theory, or capabilities) beyond an engineering consolidation?\n3.\tThe $l_\\infty$ is the more common norm in adversarial robustness. Why are experiments restricted to $l_2$? Please either justify this choice or add $l_\\infty$ evaluations with standard AutoAttack/RobustBench protocols. \n4.\tPlease report compute: FLOPs or wall-clock for training, plus sampling throughput (images/sec).\n5.\tWhat is the sampling procedure for generation—pure gradient-based synthesis or any MCMC steps? Please clarify the runtime and compute for each setting."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "I6urACSOuw", "forum": "I9iai932rK", "replyto": "I9iai932rK", "signatures": ["ICLR.cc/2026/Conference/Submission13551/Reviewer_feF3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13551/Reviewer_feF3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13551/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761924083400, "cdate": 1761924083400, "tmdate": 1762924150499, "mdate": 1762924150499, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework to simultaneously achieve robust classification and high-fidelity generative modeling within a single network. The key contribution is the use of a Dual Adversarial Training (DAT) strategy as an alternative to unstable sampling-based (SGLD) in Joint Energy-based Models. One AT component ensures discriminative robustness against adversarial attacks, while the other uses PGD-generated contrastive samples. A binary cross-entropy loss is used to perform a stable AI-based generative modeling approach. Experimental evaluations on standard datasets (CIFAR-10, CIFAR-100, and ImageNet) show improvement in adversarial robustness over existing hybrid models while maintaining good generative performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper addresses the major stability and scaling issues of previous Joint Energy-based Models by replacing the unstable sampling-based SGLD with adversarial training-based optimization.\n* The proposed framework improves adversarial robustness in the discriminative tasks while simultaneously maintaining generative fidelity compared to existing hybrid models.\n* The dual adversarial training setup stabilizes training compared to standard GAN frameworks as demonstrated through detailed analysis and ablation studies."}, "weaknesses": {"value": "* The dual optimization adds computational overhead, which could make the training slower and impractical for large-scale high-resolution images. Computational inefficiency is mentioned but not reported in terms of training/inference time and parameter size.\n* Experiments are performed mainly on standard image datasets (e.g., CIFAR-10/100, ImageNet), without extending to complex datasets or domains, which limits claims of broad applicability.\n* The sample selection for FID calculation needs to be better justified. \n* Performance comparison is weak as the paper shows comparisons against some old methods (mostly 2020 or earlier). The paper could have included comparisons with more recent hybrid models (e.g., diffusion-classifier hybrids or energy-based approaches) for a stronger empirical baseline.\n* Missing references: L-041 - \"Recent research .... understanding of generative models\" and L-094 - \"sample generation .... semi-supervised learning\"\n* The paper claims significant improvement without reporting any statistical significance analysis. \n* The training procedure can be dataset-specific, requiring tuning parameters and adjustments for new datasets. The current experiments are confined to image data. Extending it to other data modalities could introduce new stability challenges, making its generalizability uncertain.\n* L-365: \"Our best generative configuration ... achieves an FID of 5.39 ... requiring significantly less sampling steps.\" Not clear which dataset it's referring to.\n* The term PGD is never defined in the paper."}, "questions": {"value": "* Have the authors explored whether the joint model maintains robustness when transferring to out-of-distribution (OOD) data or cross-domain settings (e.g., different image modalities or noise conditions)?\n* Would the model’s scalability or performance differ on higher-resolution or more complex datasets?\n* How do the dual objectives interact during training? For example, does improving the generative objective always enhance discriminative performance, or are there cases where they conflict? Some insight through visualization or empirical justification would be helpful.\n* How sensitive is the DAT's performance to the relative weighting and scheduling between the discriminative and the generative AT losses?\n* Can the authors provide insight into the computational cost? Specifically, what is the training time overhead (e.g., in GPU-hours) compared to training a non-robust JEM or a standard robust classifier on CIFAR-10/100?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "afO8mfnpKF", "forum": "I9iai932rK", "replyto": "I9iai932rK", "signatures": ["ICLR.cc/2026/Conference/Submission13551/Reviewer_Y3JD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13551/Reviewer_Y3JD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13551/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998189247, "cdate": 1761998189247, "tmdate": 1762924149015, "mdate": 1762924149015, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper focusses on improving the Joint Energy Models (JEM) proposed by Grathwohl et al (2019) using techniques from Adversarial Training. They show that when such ideas are incorporated in the joint training of the generative + discriminative energy model, the training stability increases and surprisingly alleviates the need of gradient penalty regularizations, and improves the classification accuracy vs generative performance tradeoffs. Additionally, OOD detection and adversarial robustness and classifier calibration are auxiliary benefits with this approach."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The objective of improving JEM training is made clear early on for the readers to get a grasp of the problem statement.\n- The overview of Grathwohl et al. 2019 in the Method section was essential in setting up the context and mathematical notation for the problem. I thank the authors for the great job done here.\n- The fundamental idea of incorporating Adversarial Training for more than just adversarial robustness is interesting and insightful. The authors successfully convince the reader how AT objectives improve the join distribution modeling in JEMs, which is quite different from the original focus of AT objectives in improving adversarial robustness.\n- Insightful findings on stabilizing training while still having BN layers and data augmentations."}, "weaknesses": {"value": "Minor:\n- Numerous abbreviations are used before first expanding them. Example: PGD/SGLD in Abstract. PGD in the main paper before it's used in Line 63-65. \"DAT\" is used on line 249 without expanding it first.\n- Missing Citations:\n-- 1) Line 39 - \"...rarely excelling at both simultaneously.\" - Please cite?\n-- 2) Line 40 - \"...but may underperform on downstream classification tasks.\" - Please cite?\n- Misleading to say on Line 76: \"datasets of increasing complexity from CIFAR-10 to ImageNet...\" The paper only includes CIFAR-100 additionally and that is not a spectrum of datasets of increasing complexity as claimed.\n- Section 3.1 under Method: Please define Z(\\theta) before or after using it in the equations. Also, please make it clear and explicit that the Z(\\theta) used in P(x) on line 161 is not the same as the Z(\\theta) used in Eq. (2). Explicitly define them in each case with an integral etc to show the margnialized partition function.\n- Section 3.1, please also talk about how Z(\\theta) is handled in the loss function and how it is estimated.\n- Please clarify Equation 11: Are the authors only using the adversarial loss on samples x_adv for classification objective and No regular CE loss on the input samples \"x\"? Or are both losses turned on and the AT-CE loss is just an auxiliary loss to a regular CE classification loss on input samples \"x\"?\n- Unclear why OOD data is required in Line 328. Is it only for Eval? Or is it used during training too (which RATIO method requires)?\n\nMajor:\n- The *primary* focus of the paper is unclear. Is the focus on improving the discriminative-generative performance tradeoffs? Is the focus on improving the training stability of JEMs mainly? Is the focus on improving the adversarial robustness or OOD detection? It is quite confusing despite novel insights presented in the paper.\n- Continuing with the prev major weakness, the results in Table 1 are not clear to any extent where the method presented excels in relation to the other methods. For example, for CIFAR-100 hybrid models the DAT method is worse both in classification accuracy as well as FID than EGC method (sure, there is an extra benefit of Adversarial Robustness -- which comes back to the question of what aspect being the primary focus of the paper). Please BOLD the numbers of your method that you think are excelling at a certain aspect in relation to the rest of the models. \n- The datasets presented CIFAR-10/100 are not sufficient in convincing the readers of the merits of the work. These low res datasets are suited for a quick PoC run. The only substantial dataset used is ImageNet. Please consider including other datasets that compare to ImageNet in res like the LSUN dataset and/or CelebA faces etc. I think the results are insufficient to make a clear conclusion at the current form of the paper.\n- Line 195 - \"Preventing numerical overflow/ underflow\" -- Please either cite or show a toy example as evidence that this indeed happens while training. You can follow the plots used in this paper (https://openaccess.thecvf.com/content/WACV2022/papers/Bhaskara_GraN-GAN_Piecewise_Gradient_Normalization_for_Generative_Adversarial_Networks_WACV_2022_paper.pdf) where to convince that the gradient explodes, an explicit plot of the gradient norm is presented in Fig 3. \n- Line 199 \"The grad formulation stabilizes training at the cost of limiting the EBM to modeling the support of p_data....\" -- This is not clear to the reader how the cost here is limiting the EBM to modeling the support but not the full dentsity. Please include a citation or a toy experiment to prove this is true.\n- Line 215 - The paper mentions how the authors' method impoves the stability of training, however, no experiment is presented to back up this claim. For example, out of a random 10 experiments for each model, what fraction destabilize and diverge during training. Is the new method better in this quantitatively. See Fig 2 of (https://openaccess.thecvf.com/content/WACV2022/papers/Bhaskara_GraN-GAN_Piecewise_Gradient_Normalization_for_Generative_Adversarial_Networks_WACV_2022_paper.pdf) where a large FID/KID score implies training instability out of 5 random runs."}, "questions": {"value": "Please see weaknesses.\n\nAdditional Questions:\n1. - Line 319-320 - The authors say they use the RATIO pretrained models. However, they also show in Eq 13 how RATIO objective is different from their AT-CE objective. This totally changes their method fundamentally for CIFAR-10 and ImageNet models since the pretraining objective is RATIO objective which they elucidate how it's different from theirs in Eq 13. Since the datasets used in the paper are no where close to being considered large, I highly recommend the authors not use any pretrained models and train them from scratch using their proposed formulation without departure to other objectives like RATIO that makes it quite confusing to the reader on the exact proposal for training in this paper. \n2. - The weighted loss function modification in Eq (7) introduced by the authors is similar to the Focal Loss (https://arxiv.org/abs/1708.02002) albeit with gamma=1. Please compare this paper & suggest the readers why such a specific weight form is chosen (is it empirical? or is there a theoretical argument?)\n\nPlease also see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "mfxdikstCW", "forum": "I9iai932rK", "replyto": "I9iai932rK", "signatures": ["ICLR.cc/2026/Conference/Submission13551/Reviewer_WmTW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13551/Reviewer_WmTW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13551/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762193296876, "cdate": 1762193296876, "tmdate": 1762924148535, "mdate": 1762924148535, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Manuscript Updates in Response to Reviewer Feedback"}, "comment": {"value": "We sincerely thank all reviewers for their thoughtful and constructive feedback. We have substantially revised our manuscript to address your concerns. Below we highlight the major updates:\n\n**New ImageNet 256×256 results with ConvNeXt-Large (updated/new):** We have retrained our models at 256×256 resolution (previously 224×224) and added results with ConvNeXt-Large, achieving FID 3.29—matching the state-of-the-art autoregressive model VAR-d16 (FID 3.30) while maintaining strong adversarial robustness. The abstract, introduction, Section 3.5 (Two-stage training), and all ImageNet tables have been updated to reflect these results. See Table 2.\n\n**Expanded related work (updated):** Section 2 and Appendix A.1 now include enhanced comparison with AT-EBM, CEM, JEM++, Robust-JEM, and discussions of additional work connecting adversarial robustness and energy-based models (Zhu et al., 2021; Mirza et al., 2024). Table 1 adds 5 additional baseline comparisons on CIFAR-10 (JEM++, JEAT, Robust-JEM, VERA, WEAT). We now more clearly differentiate our approach (BCE+PGD) from prior SGLD-based methods.\n\n**Formal characterization of the learned distribution (Appendix A.15, new):** We provide a formal analysis with Proposition A.1 proving that our BCE-with-PGD objective learns optimal class logits $f\\_\\theta^*(x)[y] = \\log p\\_{\\text{data}}(y|x)$ on support with constant marginal energy $E\\_\\theta^\\*(x) = 0$. This creates a unified compatibility function where minimizing $E\\_\\theta(x,y)$ simultaneously performs robust classification, generation, and OOD detection.\n\n**Empirical validation of implicit $R_1$ regularization (Appendix A.13, new):** Figure 10 shows $R_1$ gradient norms during training, demonstrating that adversarial training maintains bounded gradients while standard training exhibits gradient explosion, validating our theoretical analysis.\n\n**Training stability diagnostics (Appendix A.11-A.13, updated/new):** We report zero divergences across 15 independent runs (5 seeds × 3 datasets), with mean and standard deviation demonstrating reproducibility. Figure 9 shows smooth training curves for all datasets. Additionally, Figure 10 shows $R_1$ gradient norms during training, demonstrating that adversarial training maintains bounded gradients while standard training exhibits gradient explosion.\n\n**Computational analysis (Appendix A.14, new):** We provide detailed efficiency metrics showing modest training overhead (1.42-1.57× for CIFAR, 1.06-1.42× for ImageNet) and superior inference throughput (~29× faster than ADM-G, ~5× faster than LDM-4-G). See Table 17 and Figure 11.\n\n**Analysis of discriminative-generative trade-off (Section 4.3.3, new):** We provide empirical analysis across multiple dimensions (PGD steps, loss weights, augmentation strategies) revealing an inherent trade-off between generative and discriminative performance, with insights into the underlying mechanism and practical tuning mechanisms.\n\n**Robustness to common corruptions (Appendix A.16, new):** We evaluate on CIFAR-10-C, achieving mean corruption error comparable to standard AT (19.84% vs 19.63%). See Table 18.\n\n**Notation and references:** We have added missing citations and improved clarity in mathematical formulations.\n\n---\n\nWe believe these updates substantially strengthen the paper and address the reviewers' concerns. We remain committed to further revisions based on additional feedback."}}, "id": "QzLK1pbco7", "forum": "I9iai932rK", "replyto": "I9iai932rK", "signatures": ["ICLR.cc/2026/Conference/Submission13551/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13551/Authors"], "number": 20, "invitations": ["ICLR.cc/2026/Conference/Submission13551/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763746774697, "cdate": 1763746774697, "tmdate": 1763770079562, "mdate": 1763770079562, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}