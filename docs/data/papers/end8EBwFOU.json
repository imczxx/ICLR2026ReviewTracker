{"id": "end8EBwFOU", "number": 10288, "cdate": 1758166032111, "mdate": 1759897660639, "content": {"title": "The Accumulation of Score Estimation Error in Diffusion Models", "abstract": "Diffusion models are widely used for high-quality generation, but their performance is sensitive to the accuracy of the estimated score.  Our main results are established first in the setting where the forward process is initialized from a Gaussian mixture, where we derive Wasserstein bounds by leveraging the structure of the score and its Hessian. We then extend the analysis to general data distributions, where we provide a more general but looser upper bound. Our analysis reveals how discretization steps directly shape the accumulation of score estimation error, thereby explaining previously observed empirical phenomena regarding the advantage of certain discretization schedules. In addition, we show that SDE samplers accumulate less error than ODE samplers in the small step-size regime, which explains their superior empirical performance in this setting. The results apply to both variance-preserving (VP) and variance-exploding (VE) diffusions.", "tldr": "We analyze how score estimation error accumulates in diffusion models and provide Wasserstein bounds between the final and target distributions, explaining empirical differences across discretization schedules and samplers.", "keywords": ["Diffusion models", "Score estimation error"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4b68f33843c7a912f2ec147041083b0c6504e0fa.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper analyzes the effect of score approximation error on the Wasserstein distance between a diffusion model's sample distribution and the ground truth target distribution, with a particular emphasis on its interaction with the time discretization of the reverse process. The authors first prove an exact Wasserstein bound for the simple case of a Gaussian target, which explicitly quantifies the error in the model distribution in terms of the discretization parameters, the structure of the target distribution, and the properties of the score estimation error. They then extend this exact analysis to the more representative case of a mixture-of-Gaussians target, and finally provide a looser bound on the Wasserstein error for general target distributions. The authors confirm that their bounds hold in practice by experimenting with a mixture-of-Gaussians target and show how their analysis can be used to explain the superior performance of SDE sampling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This is a well-written paper, and the authors did a good job of highlighting the important takeaways from their theorems and providing sufficient intuition.\n- The key results are correct to my knowledge. However, I did not review the proofs in the appendices in exhaustive detail, and it is possible that I missed some errors.\n- I appreciate that the authors prove results beyond the simple setting of a Gaussian target measure and consider multimodal targets such as mixtures of Gaussians. I also appreciate that the authors present Wasserstein bounds for the general case, even if these bounds are relatively loose."}, "weaknesses": {"value": "My only quibble is that the error model (independent Gaussian perturbations) is somewhat unrepresentative of the score approximation errors that one would expect to observe in practice, which are more likely to arise from the inductive biases of the score model and the optimization algorithm. However, I understand that this analysis would be significantly more involved, and do not believe that this should be an obstacle to publication."}, "questions": {"value": "- Are there plausible directions towards extending this paper's analysis to more general error models? I would be particularly interested in whether it would be possible to eventually relax the independence assumption on the score estimation error and analyze e.g. spatially-correlated errors.\n- Can one obtain tighter bounds for the general case (as in Theorem 3.4) by approximating a general measure by a mixture of Gaussians and applying the Wasserstein bound for the latter case, or would the error from approximating a general measure by mixtures of Gaussians typically drown out the improved precision of the Wasserstein bound for mixtures of Gaussians?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Azsw5QALCS", "forum": "end8EBwFOU", "replyto": "end8EBwFOU", "signatures": ["ICLR.cc/2026/Conference/Submission10288/Reviewer_sZFr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10288/Reviewer_sZFr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10288/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761329047913, "cdate": 1761329047913, "tmdate": 1762921642091, "mdate": 1762921642091, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies how estimation errors in the score function affect the terminal distribution of the discretized reverse process in diffusion models. In particular, the authors assume that instead of numerically integrating the reverse SDE/probability flow (PF) ODE using the true score, we first additively perturb the true score with independent Gaussian noise $e_t \\sim \\mathcal{N}(\\mu_t, \\Sigma_t)$ at each timestep $t$. In all results, both the variance exploding (VE), and the variance preserving (VP) variants are considered. When the forward process is initialized from a Gaussian Mixture Model (the \"data distribution\" $p_0$), the authors provide a closed form expression for the Wasserstein distance between the terminal distributions of the numerical solutions of the VP/VE reverse SDE when using the true and perturbed scores.\nHowever, since the pathwise Hessian average---a quantity required for the Wasserstein distance---is typically not accessible, the paper shows how the Wasserstein distance can still be bounded using two computationally tractable surrogates. This result is also extended to the PF-ODE.\nWhen relaxing the distributional assumption on $p_0$, the authors are still able to provide a bound on the Wasserstein distance---albeit only with conservative guarantees, as the bound becomes vacuous as $t \\to 0$.\nThe presented results are consistent with previous empirical observations regarding different discretization schedules, and the empirical advantage of SDE-based samplers over their PF-ODE counterparts."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ **Motivation.** The work is well-motivated. Understanding the effect of discretization schemes in samplers that use inexact scores is crucial in developing more efficient and robust sampling algorithms for diffusion models, which is an important line of research in contemporary generative modeling.\n+ **Presentation.** The main results are presented in a clear and unambiguous way. All assumptions are made explicit.\n+ **Theoretical Soundness.** The paper seems theoretically sound and technically correct.\n+ **Agreement with previous empirical findings.** The presented results are consistent with known empirical results, i.e., the empirical advantage of discretization schedules that are coarse at large $t$, and fine at $t \\approx 0$, and that SDE-based samplers typically produce better samples than their PF-ODE-based counterparts (in the small-step regime).\n+ **Closed Form Results.** Under the assumption that $p_0$ is Gaussian (or a GMM), the authors present exact, closed form results for the aforementioned Wasserstein distance. In practice, this distributional assumption is well justified: For example, training diffusion models on finite data (and truncating the reverse process such that the variance of the forward process is non-zero at $t=0$) gives rise to $p_0$ being a GMM (empirical, slightly smoothed data distribution)."}, "weaknesses": {"value": "+ **Practical applicability of Assumption 1**\n\t+ Since $s(x,t)$ is typically modeled with a neural network which is Lipschitz in $t$, the assumption of adding *independent* Gaussian perturbations $e_t$ seems strong. \n\t+ In practice, the score error will depend on the location $x$ (e.g., how far away $x$ is from the manifold), and will show strong temporal correlation.\n+ **Assumption 1 vs. $L^2$-bounded score assumption**\n\t+ While Assumption 1 implies $L^2$-boundedness, the reverse is not true: The assumption of $L^2$-bounded scores does make distributional assumptions, and is more general than Assumption 1. It also allows for temporal correlation, error distributions that depend on $x$, and non-Gaussian error, making it more practically relevant than Assumption 1.\n+ **Empirical Validation** \n\t+ The paper only provides a single experiment with a 1D GMM, where the score is perturbed when $t \\in [0, 0.4T]$. However, even in this controlled toy experiment where Assumption 1 is true by construction, the deviation between the magnitudes of theoretical and empirical Wasserstein distance is non-negligible. Additional experiments with different index sets $I$ and different (high-dimensional) GMMs are missing. Such experiments would strengthen the practical validity of the theoretical results.\n\t+ Experiments for non-GMM $p_0$ are missing. \n\t+ The paper lacks experiments that investigate the applicability of Assumption 1 in more practical scenarios. For example, one could train a score-based model on a known GMM, and then investigate the error distribution.\n\t\n+ **Notation & Typos**\n\t+ Notational inconsistency in Eq. 11: There's a squared $L_2$ norm around $\\\\beta_i \\\\exp(\\\\sum_{j=i+1}^{K-1} h^{\\\\leftarrow}\\_j \\\\phi_{\\\\tau_j})$ in the first sum (although this is a scalar), while in the second sum, this term is just squared. \n\t+ Eq. 11: There's a superfluous closing bracket in the subscript of the first sum\n\t+ L178: \"Eq. equation 8\", L246: \"Eq. equation 8\", L284: \"Eq. equation 12\"\n\t+ Eq. 12 overloads $K$, where $K-1$ previously denoted the number of bins in $[0, T]$ (see L115)"}, "questions": {"value": "+ How reasonable is Assumption 1 in practice? Is there empirical evidence for it when considering trained diffusion models?\n+ Can Assumption 1 be relaxed (temporal correlation, $x$-dependent error, etc.)?\n+ How sensitive are the empirical results to the choice of $I$ and the dimensionality of $x$?\n+ Are there connections between this work and Stochastic Gradient Langevin Dynamics (SGLD)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lfNbGKns9C", "forum": "end8EBwFOU", "replyto": "end8EBwFOU", "signatures": ["ICLR.cc/2026/Conference/Submission10288/Reviewer_5XYX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10288/Reviewer_5XYX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10288/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761669765809, "cdate": 1761669765809, "tmdate": 1762921641622, "mdate": 1762921641622, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides theoretical analysis on how score approximation errors in diffusion models (both VP/VE; SDE/ODE) propagates in the generation phase. Assuming time-dependent Gaussian score approximation errors, this paper quantifies the accumulation of score approximation error in Wasserstein-2 distance for data distributions that are Gaussian (Theorem 3.1), mixture of Gaussians (Theorems 3.2 and 3.3) and general distributions (Theorem 3.4).\n\nThe theoretical results can reveal known empirical findings in diffusion models, such as\n\n(1) high-quality generation prefers smaller step-size towards the end of the generation phase;\n\n(2) SDE sampler accumulates less score approximation errors than ODE sampler."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Good motivation**: the effects of the score approximation errors in diffusion models are essential. To obtain theoretical understanding of how such errors accumulate help increase the generation quality, as well as understand memorization and generalization in diffusion models.\n\n2. **Rigorous and complete analysis**: in the setting of the paper, the theoretical analysis is done rigorously from simple data distributions (Gaussian) to complicated ones (mixture of Gaussians), and to general ones."}, "weaknesses": {"value": "1. **Issues on interpretation of the theoretical Results**: \n\n    (1) *insufficient*: there are not many empirical evidences to explain the impact of the theoretical results, which makes people doubt how useful the proved theory is. The only numerical evidence in the main paper (Figure 1) is a toy example for mixture of Gaussians, which aims to illustrate that the empirical choices of small step-size at late-stage of generation can be explained by the theory. Even in this numerical example, it is not clear how the numerical errors in the right plot of Figure 1 are obtained.\n\n    (2) *inaccurate*: one of the main claims in this paper is that the theory can explain the empirical success of cosine/uniform log-SNR schedules compared to linear ones, with numerical evidence provided. However, I find the claim is inaccurate. If the authors meant to say linear schedule is bad due to large score error accumulation, it is not very accurate since the discretization error analysis [1] also dislikes the linear schedule. If the authors meant that their theory can explain that log-SNR is optimal, as illustrated in Figure 1-Right, I feel that is also inaccurate: in practice, the log-SNR schedule is not optimal if we want to optimize training, which is empirically studied in [2] and theoretically studied in [3]. \n\n2. **Questionable setting**: the theoretical setting assumes the score approximation errors are Gaussians, uniform in space. Although this setting makes the analysis work, whether it is reasonable is questionable. My concern is that in this oversimplified setting, some interpretations of the proved results might be misleading if we use it to understand diffusion models in practice. What's mentioned in Weakness-1-(2) is a concrete example reflecting my concern.  \n\n[1] Chen, Hongrui, Holden Lee, and Jianfeng Lu. \"Improved analysis of score-based generative modeling: User-friendly bounds under minimal smoothness assumptions.\" International Conference on Machine Learning. PMLR, 2023.\n\n[2] Karras, Tero, et al. \"Elucidating the design space of diffusion-based generative models.\" Advances in neural information processing systems 35 (2022): 26565-26577.\n\n[3] Wang, Yuqing, Ye He, and Molei Tao. \"Evaluating the design space of diffusion-based generative models.\" Advances in Neural Information Processing Systems 37 (2024): 19307-19352."}, "questions": {"value": "1. The SDE (2) is written in the forward time. So $Y_t\\sim p_t$ exactly. If we need $Y_t\\sim p_{T-t}$, we need to write the SDE in reverse time.\n\n2. From the theoretical results, such as (11), what's the exact optimal time schedule to minimize the $W_2$ score error accumulation? For the mixture of Gaussians case, does the optimal schedule depend on the two separation regimes?\n\n3. How are the empirical errors in Figure 1-Right obtained? Is the empirical generation training-free?\n\n4. In the section **Future Work**, the authors mentioned end-to-end error analysis of diffusion models. There are existing work doing this, and especially focusing on the optimal (time/variance/weight) schedules. See [3].\n\n[3] Wang, Yuqing, Ye He, and Molei Tao. \"Evaluating the design space of diffusion-based generative models.\" Advances in Neural Information Processing Systems 37 (2024): 19307-19352."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QsaDypvO8W", "forum": "end8EBwFOU", "replyto": "end8EBwFOU", "signatures": ["ICLR.cc/2026/Conference/Submission10288/Reviewer_DRuC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10288/Reviewer_DRuC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10288/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761786795251, "cdate": 1761786795251, "tmdate": 1762921641208, "mdate": 1762921641208, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors analyze the accumulation of score estimation error in diffusion models. The paper derives non-asymptotic Wasserstein bounds for the error between the generated distribution and a baseline distribution, assuming the score error is an independent Gaussian perturbation at each step. The analysis is first performed for data drawn from a Gaussian and Gaussian mixture (GM) distribution, yielding bounds that depend on the discretization schedule and the properties of the score's Hessian. A more general, but admittedly looser, bound is provided for arbitrary data distributions. The authors use this framework to theoretically justify the empirical success of schedules that use smaller steps near the data end ($t \\approx 0$) and to argue that SDE samplers accumulate less error than ODE samplers."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper addresses the impact of **score estimation error**, which is a significant factor in model performance but less analyzed than discretization error.\n* The analysis provides a tractable, closed-form Wasserstein error bound for the simplified case of a Gaussian initial distribution (Theorem 3.1).\n* The theoretical results, particularly for the Gaussian and GM cases, provide a formal explanation for the empirically-observed sensitivity to step-size allocation, corroborating the strategy of refining steps near the data end."}, "weaknesses": {"value": "### Weaknesses\n\n*  **Assumption 1 is fundamentally flawed and unrealistic.** The paper models the score estimation error $e_t$ as an *independent Gaussian perturbation* $\\mathcal{N}(\\mu_t, D_t D_t^\\top)$ injected at each reverse step. Formally, the sentence \"independent at each time instant\" is not meaningful, as the authors would need to consider a white noise process with a much more complex stochastic calculus machinery. Even neglecting this, the true error $s_\\theta(x,t) - \\nabla \\log p_t(x)$ is  an highly structured function of the state $x$, time $t$, and network parameters $\\theta$. Consequently, modeling it as independent additive noise invalidates any claim of practical relevance. The analysis is for a system under *external* Gaussian noise, not for a system using an *imperfect* learned function.\n\n* **Notation is inconsistent** is \\mu the mean of the error vector, or is it the mean for the other considered noise schedules? Also (referring to line 606, proof of theorem), what does it mean \"e... is the (zeroâ€“mean) score approximation error with mean ...\"?\n* **The general-distribution bound is useless.** The authors' own analysis of Theorem 3.4 admits it is \"conservative\" and \"looser\". Crucially, they state that the Hessian term $H$ \"explode[s]\" as $\\tau \\to 0$ (the data end). Given that the paper's primary conclusion is the critical importance of controlling error in this exact region , a bound that explodes there is not useful.\n* **The tractable bounds (Thm 3.1, 3.2) apply only to toy distributions.** The main \"sharp\" results rely on the data being a single Gaussian or a Gaussian Mixture. This is analytically convenient but completely unrepresentative of the high-dimensional, complex-manifold data (like images) on which diffusion models are actually used.\n* **Empirical validation is weak and self-referential.** The experiment in Figure 1  is conducted on a 1D Gaussian mixture and, most importantly, injects an artificial Gaussian error $e_t \\sim \\mathcal{N}(1,1)$. This experiment does not validate the theory on a real problem; it merely simulates the unrealistic conditions of Assumption 1. There is no evidence shown that these bounds or schedule rankings hold when using the *actual* error from a trained score network on a high-dimensional task."}, "questions": {"value": "1.  **Regarding Assumption 1:** How can you justify modeling the score error?T he true error is the function $s_\\theta(x_k, \\tau_k) - \\nabla \\log p_{\\tau_k}(x_k)$, which is highly correlated with $x_k$. Does this assumption not fundamentally misrepresent the problem?\n2.  **Regarding Theorem 3.4:** You state that the general-distribution bound relies on a Hessian term that \"explode[s]\" near the data end ($\\tau \\approx 0$) and that the bound is \"conservative\". Since your main practical insight is the need for fine-grained steps in this exact region, what is the practical value of this general bound if it fails to be informative in the most critical regime?\n3.  **Regarding Figure 1:** Your empirical test uses an *injected* Gaussian error $e_t \\sim \\mathcal{N}(1,1)$ on a 1D GMM, rather than the true error from a trained network. Can you provide any evidence that your theoretical bounds or the resulting schedule rankings (Linear vs. Cosine, etc.) hold in a realistic, high-dimensional setting using the *actual* error $s_\\theta(x,t) - \\nabla \\log p_t(x)$?\n4.  **Regarding SDE vs. ODE:** Your argument for SDE superiority rests on a comparison of linearized amplification factors. How does this simplistic comparison justify the strong claim that SDE samplers \"accumulate less error overall\"?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dBEkc1ESiw", "forum": "end8EBwFOU", "replyto": "end8EBwFOU", "signatures": ["ICLR.cc/2026/Conference/Submission10288/Reviewer_sdxG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10288/Reviewer_sdxG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10288/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761955628645, "cdate": 1761955628645, "tmdate": 1762921640582, "mdate": 1762921640582, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}