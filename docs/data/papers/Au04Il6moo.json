{"id": "Au04Il6moo", "number": 1597, "cdate": 1756895882100, "mdate": 1759898199064, "content": {"title": "Draft-and-Target Sampling for Video Generation Policy", "abstract": "Video generation models have been used as a robot policy to predict the future states of executing a task conditioned on task description and observation. Previous works ignore their high computational cost and long inference time. To address this challenge, we propose Draft-and-Target Sampling, a novel speculative decoding-like inference paradigm for video generation policy that is training-free and can improve inference efficiency. We modify the classic principle of speculative decoding design and redefine the draft and target as two complementary denoising trajectories. To further speedup generation, we introduce token chunking and progressive acceptance strategy to reduce redundant computation. Experiments on three benchmarks show that our method can achieve up to 2.1x speedup and improve the efficiency of current state-of-the-art methods with minimal compromise to the success rate. Our code is available at anonymous github.", "tldr": "We propose a speculative decoding-like and training-free framework to accelerate video generation policies,  our method achieves up to 2.1x speedup with minimal compromise to the success rate.", "keywords": ["Video Generation Policy; Video Generation for Robotics; Speculative Decoding; Inference Acceleration"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/715d7e28d9e6394d265547900e75ea6aab851de5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Draft-and-Target Sampling (DTS), a speculative decoding method for video generation policies. The approach employs large diffusion steps for the draft phase and smaller diffusion steps for the acceptance/rejection phase. To mitigate accumulation errors and improve efficiency, the paper introduces token chunking and progressive acceptance strategies. Experiments conducted on iTHOR, MetaWorld, and LIBERO demonstrate improved inference efficiency while maintaining comparable policy performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper presents a novel perspective on video generation policies, focusing on improving inference efficiency. To the best of my knowledge, the proposed strategy of combining large and small diffusion steps for speculative decoding has not been explored before.\n2. The experimental evaluation is comprehensive, covering three distinct domains, and the results show consistent and satisfactory performance."}, "weaknesses": {"value": "1. **Lack of theoretical analysis of acceleration**: \n   While the empirical study is extensive, the paper lacks theoretical discussion or quantitative analysis of the acceleration achieved:\n   - The assumption in Line 50 that video generation policies usually have low resolutions is questionable. Recent works such as Vidar [1] demonstrate a clear trend toward higher resolutions in this paradigm. The paper does not analyze how the proposed method is applicable under different resolutions (e.g., whether it is memory-bound or compute-bound).\n   - Although the paper presents detailed algorithmic formulations, it omits an analysis of time complexity, particularly regarding the impact of token chunking. This makes it difficult for readers to understand the expected acceleration ratio or to choose suitable hyperparameters\n   - If the authors claim that generation is memory-bound, then the memory cost of token chunking (e.g., the number of model parameter loads) should be examined, as it may remain similar or even increase with chunking.\n   - The sequential nature of token chunking may limit parallelism. This trade-off should be discussed explicitly.\n2. **Presentation and clarity issues**:\n   - Section 4 is overly verbose, containing many complex formulas. A clear schematic figure illustrating the overall process would greatly enhance readability.\n   - The motivation for token chunking as a way to mitigate accumulation error of draft sampling is somewhat trivial and could be summarized more concisely.\n   - The discussion in Section 4.3 about token chunking reducing accumulated error of target sampling (Line 262) is insightful but should be introduced earlier, e.g., in Section 4.2.\n   - The motivation of the Progressive Acceptance Strategy is not sufficiently explained or justified.\n   - There is considerable repetition across the three benchmark descriptions in Section 5.2 (e.g., shared hyperparameter settings), which could be consolidated to improve conciseness."}, "questions": {"value": "1. What is the motivation and intuition behind the Progressive Acceptance Strategy?\n2. How does this work compare to Accelerated Diffusion Models via Speculative Sampling [2], which also avoids training a separate draft model?\n3. Why is DDIM-10 chosen as the baseline solver for diffusion sampling instead of more advanced solvers such as DPM-Solver?\n4. Could the proposed approach be extended to general image or video generation models, beyond policy-oriented settings?\n5. On iTHOR, why does DTS improve policy performance in addition to acceleration? Were the results averaged over multiple runs to ensure statistical significance?\n\n[1] Vidar: Embodied Video Diffusion Model for Generalist Manipulation\n\n[2] Accelerated Diffusion Models via Speculative Sampling."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cgLm9Gsgjn", "forum": "Au04Il6moo", "replyto": "Au04Il6moo", "signatures": ["ICLR.cc/2026/Conference/Submission1597/Reviewer_pqge"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1597/Reviewer_pqge"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761706238215, "cdate": 1761706238215, "tmdate": 1762915828894, "mdate": 1762915828894, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors focus on efficient video generation for robot policies. One major issue with contemporary video models is their slow speed. To address this issue, the authors propose the application of Draft-and-Target sampling, with some additional tweaks (chunking and progressive acceptance strategy) to video generation. They apply their approach to three datasets. They are iThor, Meta-World, and Libero, and they show improvements when accounting for the significant speedup in computational time."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper touches on an overlooked but very important problem with the current paradigm for video generation. It is generally too slow to be useful for robotics policies and planning algorithms. This paper is a promising step in the right direction.\n\n2. The approach is simple and easy to implement.\n\n3. Quantitative performance relative to baselines is promising."}, "weaknesses": {"value": "1. The technical novelty is somewhat limited. No new models or approaches seem to be proposed in this paper. It appears that the contribution of this paper is largely an application of an existing idea to the realm of robotic control. \n\n2. While performance is promising, the speedup is generally modest (about 2x). It is not clear if this speedup outweighs the additional complexity of the approach. \n\n3. Data domain of video generation is quite constrained (robotic environments), there are no experiments on unconstrained video data (such as Kinetics-700)"}, "questions": {"value": "1. Could you please elaborate on the technical novelty of the approach? This seems to be an application paper. Are there any new methods or approaches?\n\n2. The speedup from this approach is helpful but not particularly dramatic. Are there any tweaks to the method that could lead to additional speedup (> 5x) without significant sacrifices to performance?\n\n3. Could this approach be viable for video generation on more diverse datasets beyond robotics?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MYqiVzVzgN", "forum": "Au04Il6moo", "replyto": "Au04Il6moo", "signatures": ["ICLR.cc/2026/Conference/Submission1597/Reviewer_yNA5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1597/Reviewer_yNA5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761769167231, "cdate": 1761769167231, "tmdate": 1762915828682, "mdate": 1762915828682, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a draft-and-target sampling method for video generation policy inference which achieves computational efficiency compared to prior works across benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper proposes system level optimization, e.g., token chunking, to improve the efficiency, which could offer practical values to the community. \n* Results seem to provide empirical performance and efficiency gains."}, "weaknesses": {"value": "* The core idea is the speculative decoding, which has been widely adopted in the field in LLMs. The modifications of speculative decoding in the discrete space from this paper include using large-stepsize-ODE as draft model and progressive acceptance, which are rather straightforward implementations. Therefore the contribution of the paper should be more explicitly discussed compared to prior works including but not limited to LLMs. \n* Given that the paper uses the same model as draft and target models, these models have the same FLOP count per function evaluation. Reporting NFEs in the experiments could help clarify the computation complexity of the model. \n* Baselines include AVDC (from the original paper cited) and AVDC-10 which aggressively cuts down denoising steps. More baselines with some numbers of denoising steps in between 10 and 100 should be reported, which might already achieve significant speedup compared to AVDC-100 without too much performance loss."}, "questions": {"value": "* The experiments use AVDC as the backbone. Would the proposed strategy apply to other video generation policy models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yydfX1wXgV", "forum": "Au04Il6moo", "replyto": "Au04Il6moo", "signatures": ["ICLR.cc/2026/Conference/Submission1597/Reviewer_qRTA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1597/Reviewer_qRTA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981382994, "cdate": 1761981382994, "tmdate": 1762915828529, "mdate": 1762915828529, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}