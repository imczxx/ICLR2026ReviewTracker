{"id": "difAlp151J", "number": 15593, "cdate": 1758252981704, "mdate": 1759897296881, "content": {"title": "ACLEGR-TADD: Adaptive Continual Learning for Financial Fraud Detection under Extreme Class Imbalance", "abstract": "Financial fraud detection systems face catastrophic performance degradation under adversarial concept drift and extreme class imbalance, where fraud comprises less than 0.2% of transactions. Existing continual learning methods fail as they assume balanced classes and static distributions. We propose ACLEGR-TADD, a novel framework that integrates Temporal Attention-based Drift Detection (TADD) with multi-resolution wavelet analysis, achieving a 4-fold reduction in detection delay (from 4.8h to 1.2h). Our method incorporates a Fraud-Aware Variational Memory Network (FA-VMN) that leverages class-specific variance disparities and Information-Theoretic Adaptive Consolidation (ITAC) using PAC-Bayes bounds. We provide the first catastrophic forgetting bound under extreme imbalance, proving that forgetting scales with the square root of the fraud rate over sample size. Experiments on five datasets comprising over 10 million transactions demonstrate that ACLEGR-TADD achieves 94.7% PR-AUC with sub-10ms CPU inference latency, significantly outperforming DER++ (74.7%) and FT-Transformer (78.1%). The framework satisfies differential privacy with formal guarantees while reducing false positives by 64% in production deployment.", "tldr": "We introduce ACLEGR-TADD, a continual learning framework that combines attention-based and wavelet drift detection to achieve 94.7% PR-AUC on financial fraud detection despite extreme class imbalance (0.2% fraud rate) and adversarial concept drift.", "keywords": ["continual learning", "financial fraud detection", "extreme class imbalance", "concept drift", "temporal attention", "wavelet analysis", "catastrophic forgetting", "differential privacy"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b1ccdf1ba0a9c5f7d68387d6bd75090fc44def12.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a method for continual learning for fraud detection."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "None that I could find."}, "weaknesses": {"value": "At its core, the paper seems to be an applied paper that was embellished with additional purported theoretical claims that are stated without any supporting analysis. The method is inadequately explained and the experimental setup is unconvincing and leaves many open questions.\n\nSome of the main problems are:\n1. Most claims put forward by the authors are completely unsupported. Examples are:\n    - The authors claim that fraud detection systems experience catastrophic performance degradation under adversarial context drift without any supporting evidence that such extreme drift occurs in practice.\n    - Ensemble methods requiring multiple model evaluations violate latency constraints. Random forests and gradient boosting are well established baselines used in practice in the fraud detection domain. (see for example https://stripe.com/blog/how-we-built-it-stripe-radar)\n2. Most of the numbers put forward by the authors lack any context or a supporting citation. I have no idea where these figures were pulled from. Examples:\n    - In what context are fraud rates 0.2%? Different financial institutions and use cases experience different fraud rates (even if they are indeed generally unbalanced). This number is used multiple times throughout the paper as an absolute truth.\n    - Where is the 99.8% accuracy number for models from? Accuracy is an irrelevant metric in the context of fraud detection.\n    - The authors claim that standard weighted cross-entropy with static class weights fails catastrophically, achieving only 42.3% PR-AUC after concept shift and experiencing complete forgetting within 4.8 hours as gradient updates become dominated by legitimate transactions. Again, there is no source or experimental results supporting these numbers as far as I can tell.\n3. The theoretical contributions claimed in the introduction are never supported by actual analysis:\n    - A \"catastrophic forgetting bound\" is offered in the introduction with none of the symbols appearing in the formula being defined. This bound is only mentioned again in the appendix, together with what the authors argue is a proof but is, in fact, only an arbitrary decomposition of the main term, followed by non-sensical substitution of random values into unexplained mathematical formulas.\n    - The Lyapunov stability analysis proving convergence under adaptive learning rates is never actually mentioned in the main text as far as I can tell\n    - The remaining two contributions lack a proper explanation and any supporting theoretical analysis\n4. The method is not properly explained. In many instances the authors do not properly define the symbols appearing in the equations. Rarely is the rationale for the many specific choices explained either. \n5. In the appendix, isolated code for each module is also provided but appears most of the actual work is done by calling instance methods and external functions that are never defined.\n\n## Regarding the empirical Results\n1. The choice of baselines seems arbitrary. Why do the authors choose to compare to these particular transformer baselines and not to classical baselines such as random forests or gradient boosting? Particularly given the focus on low latency for inference.\n2. It is completely unclear what the setup is with regards to drift detection.\n2. One of the benchmark datasets appears to be repeated (Kaggle Credit and European Credit Card seem to be the same dataset)\n3. In figure 2 the authors don't explain to which dataset the results pertain. The results don't seem to match the results reported in Table 1 for the proposed method.\n4. Results for all datasets seem suspiciously similar across all methods. These are quite different fraud detection datasets and in my experience it would be an incredible coincidence that the proposed method achieves PR-AUC in [0.9, 0.95] in all of them and competing baselines a PR-AUC in [0.73, 0.79].\n5. The authors never properly explain what the bounds mentioned here are:\n> Theoretical Validation. Convergence analysis (Figure 2, right panel c) shows gradient norms stabilizing at 5.5 × 10−4 within theoretical bounds. \n\nThe theoretical prediction mentioned in the following quote is only stated but never explained.\n> Forgetting scales as O( p ρ/n) under extreme imbalance (right panel d), matching our theoretical predictions and remaining below 1% for n > 104 samples\n\n6. There is a repeated section named Experimental Results"}, "questions": {"value": "1. In my experience, drift is gradual over time and not really abrupt as the authors seem to indicate. Measuring a drift detection time seems misguided and divorced from the reality of fraud detection. What real-life examples can the authors provide of such extreme sudden drifts occurring?\n2. The drift detection method and setup in the experiments is inadequately explained. Are the authors injecting artificial drift in the results presented. If not, how do the authors obtain a ground-truth of concept drift for the real datasets? As far as I know the public datasets have no such information available. \n3. What dataset are the results in Figure 2 from? Why is the proposed method's result significantly below those reported in Table 1?\n4. Where is the theoretical analysis for the many claims?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7Jflg5MWqv", "forum": "difAlp151J", "replyto": "difAlp151J", "signatures": ["ICLR.cc/2026/Conference/Submission15593/Reviewer_Mdyw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15593/Reviewer_Mdyw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761423615140, "cdate": 1761423615140, "tmdate": 1762925864890, "mdate": 1762925864890, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses two challenges in financial fraud detection: \"extreme class imbalance (fraud rate < 0.2%)\" and \"adversarial concept drift\". The authors propose ACLEGR-TADD, an integrated framework that combines four key components: 1) Temporal Attention-based Drift Detection (TADD) for capturing temporal dependencies in transaction sequences, 2) Multi-Resolution Drift Detection (MRDD) based on Daubechies-4 wavelet analysis for detecting frequency-domain anomalies, 3) Fraud-Aware Variational Memory Network (FA-VMN) that mitigates fraud sample scarcity through class-specific variance modeling, and 4) Information-Theoretic Adaptive Consolidation (ITAC) based on PAC-Bayes bounds to prevent catastrophic forgetting. \nTheoretically, this paper derives for the first time a catastrophic forgetting bound that explicitly accounts for extreme class imbalance. Empirically, the authors demonstrate the advanced performance of their algorithm on five real-world and synthetic datasets (comprising over 10 million transactions)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Originality: The work presents novel contributions, including a hybrid temporal-frequency drift detection method and a fraud-aware generative memory, supported by a theoretical analysis that incorporates the fraud rate.\n- Quality: The paper demonstrates a rigorous methodology, with comprehensive experiments on multiple datasets, detailed ablation studies, and validation across both accuracy and operational metrics.\n- Clarity: The complex framework is presented in a clear and structured manner, making the logical flow and component interactions understandable."}, "weaknesses": {"value": "- w1: Lack of Parameter Sensitivity Analysis: The proposed framework integrates multiple components, each introducing its own set of hyperparameters (e.g., the fusion parameter α in TADD-MRDD, the consolidation strength λ in ITAC, and the architectural choices in FA-VMN). However, the paper provides no discussion or analysis of the sensitivity of the results to these hyperparameters. Should these parameters require significant manual tuning across different datasets or scenarios, it would increase the engineering cost and hinder practical deployment.\n- w2: Potential \"Cumulative Burden\" in ITAC's Consolidation Logic: The paper presents results from a \"90-day production deployment,\" but financial systems are typically required to operate continuously for years. This long-term operation could lead to a growing \"consolidation burden\" for critical parameters identified by ITAC. A crucial question arises: does the framework need mechanisms to dynamically adjust the consolidation threshold over time, or to evaluate the temporal validity of historically consolidated parameters, to prevent this potential accumulation from hindering future adaptation?\n\nMinor Issues:\n- Unclear Presentation of Experimental Results: The description of the results, particularly for Figure 2, is confusing. A large number of experimental result panels are compiled together, which is not conducive to clear interpretation and mapping of textual descriptions to specific visual data.\n- Formatting Error: There appears to be a typo in the structure of Section 5. The title \"5 Experimental Results\" is immediately followed by another \"6 Experimental Results\" title on page 8. This seems to be a formatting error that should be corrected."}, "questions": {"value": "- Regarding the experimental setup for adversarial concept drift, could you please specify the exact methodology used for simulation? Was it achieved by artificially injecting pre-defined drift patterns (e.g., periodic switching between known fraud types), or through a more dynamic, adversarial simulation based on real-world data (e.g., where an adversary adapts attack strategies in response to model updates)?\n- The achievement of \"8.9ms CPU inference latency with INT8 quantization\" is a key practical result. To better facilitate the reproduction of these efficiency results and understand the computational requirements, could you provide more specific engineering details regarding the CPU hardware used? Information such as the specific model, number of cores, and operating frequency would be very helpful."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9KDkEadriH", "forum": "difAlp151J", "replyto": "difAlp151J", "signatures": ["ICLR.cc/2026/Conference/Submission15593/Reviewer_xAGp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15593/Reviewer_xAGp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761727960673, "cdate": 1761727960673, "tmdate": 1762925864367, "mdate": 1762925864367, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose ACLEGR-TADD for continual learning in detecting\nfinancial fraud under extreme class imbalance.  The approach has 4\nmain components.\n\nFirst, Temporal Attention-based Drift Detection (TADD) uses multi-head\nattention to capture temporal dependencies.  Fraudulent patterns can\nyield entropy spikes when attention weights are dispersed.  Second,\nMulti-Resolution Drift Detection (MRDD) uses Daubechies-4 wavelet to\nanalyze patterns at different frequency scales.  The wavelet\ncoefficients at different scales are compared with the baselines via\nKL divergence.  Third, to handle rare samples, Fraud-Aware Variational\nMemory Network (FA-VMN) uses a hierarchical VAE to exploit empirical\nvariance ratios between fraud and legitimate transactions.  The first\nlatent variable z1 is conditioned on x and y, while the second z2 is\nconditioned on z1 and y.  The decoder reconstructs transaction x\nconditioned on z2 and y.  Fourth, to reduce catastrophic forgetting,\nInformation-Theoretic Adaptive Consolidation (ITAC) uses Fisher\nInformation Matrix diagonal approximation.  PAC-Bayes\nframework. reducing catastrophic forgetting.  The overall loss is a\nweighted combination of the 4 components.\n\nFor evaluation, they compare 3 existing methods over 5 datasets.  The\nempirical results indicate the proposed method generally outperform\ncompared methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.  Investigating continual learning in extreme imbalance scenarios is\ninteresting.\n\n2.  The propsed compoents to consider the drift at different freqency\nscales and leveraging variance ratios are interesting."}, "weaknesses": {"value": "1.  Three of the 4 loss functions are not defined.\n\n2.  More continual learning algorithms could be used for comparison.\n\n3.  Presentation of the ideas could be improved with further\ndiscussion.  Also, the text in Figure 2 is too small to read."}, "questions": {"value": "1.  In MRDD, how are the baseline distributions established?\n\n2.  Sec 3.5: \"the expectation is approximated using representative\nsamples from the memory buffer, with importance accumulating across\ntasks to capture parameters critical for multiple fraud patterns.\"\nSec 1: \"GDPR Article 17 and PCI-DSS standards prohibit storing raw\ntransaction data beyond specified retention periods, eliminating\nmemory-based continual learning approaches.\"  Does the memory buffer\ncontain raw samples?  If so, that is inconsistent with not using\nmemory-based approaches.\n\n3.  How are the bounds in Sec. 1.2 established?\n\n4.  Eq 7: While L_ITAC is defined, the other 3 are not.\n\n\n\nComments:\n\nF_j is in Sec. 3.5 while its bounds are in Sec. 1.2.  Moving the\nbounds to Sec 3.5 would be more easier for the reader.\n\nSec. 5 is empty and has the same title as Sec. 6.\n\nTable 1: \"Best in bold\", none of the values are in bold.\n\nFigure 2: labels/words are too small to read."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "m8TZWxuuRO", "forum": "difAlp151J", "replyto": "difAlp151J", "signatures": ["ICLR.cc/2026/Conference/Submission15593/Reviewer_52fr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15593/Reviewer_52fr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15593/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761855359649, "cdate": 1761855359649, "tmdate": 1762925863908, "mdate": 1762925863908, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}