{"id": "Uft46u0GRx", "number": 14909, "cdate": 1758245441312, "mdate": 1759897341962, "content": {"title": "AsymPuzl: An asymmetric puzzle for multi-agent cooperation", "abstract": "Large Language Model (LLM) agents are increasingly studied in multi-turn, multi-agent scenarios, yet most existing setups emphasize open-ended role-play rather than controlled evaluation.\nWe introduce AsymPuzl, a minimal but expressive two-agent puzzle environment designed to isolate communication under information asymmetry.\nEach agent observes complementary but incomplete views of a symbolic puzzle and must exchange messages to solve it cooperatively.\nUsing a diverse set of current-generation and open-source LLMs, we show that (i) models such as GPT-5 and Claude-4.0 reliably solve puzzles of different sizes by sharing complete information in few turns, (ii) other models tend ignore partner messages or over-correct their hypotheses, and (iii) feedback design is non-trivial: simple self-feedback improves success rates, while detailed joint feedback can hurt performance.\nThese findings show that even in simple cooperative tasks, LLM communication strategies diverge and depend on the granularity of feedback signals.\nAsymPuzl thus provides a testbed for probing the limits of multi-turn cooperation and opens avenues for studying coordination mechanisms.", "tldr": "", "keywords": ["LLM", "Mutli-Agent Cooperation"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b8bca2b178b7bc1d9b0d82800fe3598c28dbf54c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introducing AsymPuzl, a two-agent puzzle environment designed to evaluate multi-agent cooperation and communication strategies among LLM agents. In this setup, two agents, hold complementary, partial views of a symbolic puzzle and must exchange messages to solve it collaboratively. The study explores how variables like feedback granularity, puzzle size, information ambiguity, and communication noise affect LLM performance across various models, including advanced versions like GPT-5 and Claude-4.0. Key findings indicate that while simple self-feedback generally improves success rates, highly detailed joint feedback can actually hinder performance, revealing that even in simple tasks, LLM communication strategies diverge significantly."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well-structured and clearly written, making it accessible to readers with varying levels of familiarity with multi-agent systems and LLM research. The paper provide sufficient background context and clearly articulate their research questions and methodology.\n- The AsymPuzl game design is elegant and intuitive, providing a straightforward yet effective framework for measuring cooperation and communication between two LLM agents. The puzzle's simplicity allows for controlled experimentation while still capturing essential aspects of collaborative problem-solving, such as information asymmetry and the need for effective communication protocols.\n- The proposed framework serves as a testbed for evaluating multi-turn cooperation and provides opportunities for studying coordination mechanisms"}, "weaknesses": {"value": "- From my perspective, the proposed paper does not fit well within the scope of ICLR as it primarily focuses on evaluating the capabilities of existing LLMs through prompting strategies rather than introducing novel methodologies, architectures, or learning algorithms. While the AsymPuzl environment itself is a useful contribution, the paper's core findings are largely empirical observations about how different LLMs perform under various communication conditions. The work would benefit from proposing new training techniques, communication protocols, or theoretical frameworks that could advance the field of multi-agent learning beyond benchmarking existing models.\n- The systems are only tested for a limited number of N values, and the results do not appear to converge in several cases. For example, in Table 2, the performance metrics show considerable variation, but the experiments do not extend to sufficiently large values of N to determine whether performance trends stabilize. Additional experiments with larger N would help establish whether the observed patterns are fundamental limitations of current LLMs or artifacts of the specific scale tested.\n- The system is tested exclusively with pure LLMs without incorporating additional tools, external memory, or agent-based architectures. This limitation is significant because real-world multi-agent systems often leverage specialized tools, retrieval mechanisms, or structured reasoning frameworks to enhance performance. Testing the AsymPuzl environment with augmented agents would provide valuable insights into whether the observed communication challenges are inherent to language-based coordination or can be mitigated through tool use."}, "questions": {"value": "What are relevant use cases where the evaluated puzzle soving capabilites would be relevant?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XTJyP2JCFF", "forum": "Uft46u0GRx", "replyto": "Uft46u0GRx", "signatures": ["ICLR.cc/2026/Conference/Submission14909/Reviewer_v6Uz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14909/Reviewer_v6Uz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761819507946, "cdate": 1761819507946, "tmdate": 1762925255853, "mdate": 1762925255853, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a puzzle for two agents. The puzzle is about finding the correct order and colors of different shapes. One agent is given hints about the correct order. The other is given hints about the correct colors. The paper then investigates how the two agents share information about their hints to solve the puzzle. It computes the success rate, number of turns before success, etc."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The game has a clear ground truth that allows computing baselines. It can be relatively increased in difficulty by adding more objects. It investigates a setup with distractors, such as including objects in one of the hints that are not in the ground truth."}, "weaknesses": {"value": "- Larger models such as GPT-5 consistently perform near-perfectly in most of the experiments. Since the paper mentions that one of its contributions is providing a testbed for agent coordination, this makes this testbed less likely to be useful for studying advanced models. \n\n- The puzzle does not necessarily involve sophisticated levels of multi-turn or strategic coordination and an inherent need for having more than one agent. As the paper mentioned repeatedly, the puzzle can be solved by exchanging the complete view/hints of each agent in one turn. There is nothing that strictly enforces that some parts of the hints are private, can't be shared, etc. There is also no need for repeated turns. These factors make the puzzle quite simplistic and not complex enough for any real-world scenario or for advanced models. The paper also mentions that the setup requires agents to operate under partial information, but this is not the case.\n\n- The paper introduces factors that would increase the complexity, such as inserting random characters in the communication between agents. But these factors are artificial (in the sense that they don't relate to the complexity of the puzzle itself). Also, this does not measure the coordination skills or capabilities exclusively, but rather the understanding of models and the denoising of the natural language. Even for small models, random characters can completely break the tokenization; the degradation (or the increase in the number of turns) is not directly related to a lack of coordination.\n\n- There are multiple related works on this area of LLM multi-agent coordination (see, for example, https://arxiv.org/pdf/2310.03903 NAACL 2025) that the paper does not compare to. The necessity/novelty of this particular testbed is not clearly explained."}, "questions": {"value": "- Are agents told that the communication will be adjusted? It is imaginable that in this case, the agents may try to embed the information multiple times. \n\n- Similarly, are agents told that they should optimize the number of turns or tokens?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "swLYXIBTsK", "forum": "Uft46u0GRx", "replyto": "Uft46u0GRx", "signatures": ["ICLR.cc/2026/Conference/Submission14909/Reviewer_y6Vg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14909/Reviewer_y6Vg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831825751, "cdate": 1761831825751, "tmdate": 1762925255318, "mdate": 1762925255318, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents AsymPuzl, a controlled evaluation environment for studying multi-turn cooperation between large language model agents under information asymmetry.\nMotivated by the observation that most existing multi-agent setups focus on open-ended role-play rather than measurable cooperation. the work aims to systematically examine how communication strategies and feedback mechanisms affect problem-solving when agents hold complementary but incomplete information.\n\nThe core method is a two-agent symbolic puzzle environment where each agent receives asymmetric clues and must iteratively communicate and update its hypothesis to reconstruct the full solution. The framework allows precise control over puzzle size, feedback type, clue ambiguity, and communication noise, enabling a structured analysis of coordination behaviors. The authors evaluate a diverse set of models and report how feedback granularity, message verbosity, and communication robustness influence overall success.\n\nResults show that strong models such as GPT-5 and Claude-4.0 can reliably solve puzzles through efficient information sharing in few turns, while weaker models struggle with under-communication or over-correction. Simple self-feedback improves performance, whereas overly detailed joint feedback reduces it.\nThe study concludes that in multi-agent cooperation, communication strategy is as critical as model capability. AsymPuzl serves as a foundational testbed for future work on coordination mechanisms, communication efficiency, and scalable multi-agent systems."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The puzzle task is well-designed, simple, and interpretable. It provides a quantifiable and verifiable objective, making it suitable for controlled evaluation of cooperative reasoning.\n\t\n2. The environment allows precise manipulation of task difficulty and reasoning requirements through parameters such as puzzle size, feedback type, clue ambiguity, and communication noise. This enables fine-grained analysis of agent cooperation.\n\t\n3. The authors conduct extensive evaluation across a diverse set of mainstream LLMs, offering a broad and informative comparison that strengthens the empirical validity of the results."}, "weaknesses": {"value": "1.\tThe paper lacks originality. Prior studies have already explored multi-agent cooperation under asymmetric information with a wide range of interaction mechanisms, and this work does not present any clear conceptual or methodological innovation.\n\t\n2.\tThe main contribution lies in the AsymPuzl environment for studying cooperation under asymmetric information and controlled communication. However, most findings, such as “larger puzzles are more challenging,” offer little new knowledge or insight to the community.\n\t\n3.\tThe claim that detailed feedback about another agent’s hypothesis can reduce performance is not convincing. As the authors acknowledge, this effect may stem from context fragmentation and information overload. A more complete experimental setup would strengthen the claim; as it stands, the setting feels underdeveloped and unable to robustly support any conclusion.\n\t\n4.\tMost results are purely descriptive and lack deeper analysis, for example in lines 341 to 344.\n\t\n5.\tThe AsymPuzl environment is overly simplified, which limits the generalizability of its findings to real-world multi-agent systems.\n\t\n6.\tOverall, the paper makes little substantive contribution. While AsymPuzl may serve as a tool-level addition, the asymmetric-information setup is not novel, and the analyses are too shallow to constitute meaningful scientific progress."}, "questions": {"value": "-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "U9yEXxboJ6", "forum": "Uft46u0GRx", "replyto": "Uft46u0GRx", "signatures": ["ICLR.cc/2026/Conference/Submission14909/Reviewer_BL4G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14909/Reviewer_BL4G"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904598181, "cdate": 1761904598181, "tmdate": 1762925254563, "mdate": 1762925254563, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "AsymPuzl introduces a two-agent asymmetric puzzle to study cooperation between LLMs. Each agent has partial information (order / colors) and must communicate over turns to reconstruct the full solution. Experiments with various LLMs shows that strong models share information efficiently and solve large puzzles, while weaker ones miscommunicate or over-revise (spend too much turns)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Asymmetric puzzle solving with communication is an interesting topic for LLMs and would be valuable for future multi-agent system studies. I appreciate the reseach topic.\n2. There are experiments across major open and closed LLMs. Also, there are various settings proposed, such as ambiguous / extra clues, significantly enriching the proposed benchmark."}, "weaknesses": {"value": "1. The design of AsymPuzl is not good enough. It is not a setting that naturally requires multi-round communication. In the base configuration, if both agents simply share all their information during the first communication round, the problem essentially degenerates into a single-agent puzzle-solving task. I believe the environment should introduce a more clever form of partial observability so that communication emerges naturally. Currently, adding noise to the communication channel feels like a separate topic — more about studying noisy or robust communication rather than asymmetric puzzle solving itself.\n\n2. The difficulty level also needs to be increased. Currently, GPT-5, Claude-4.0/3.5, and GPT-OSS-120B can already solve this benchmark quite well, which reduces its potential research value.\n\n3. In Figure 1, some of the text is too small to read clearly."}, "questions": {"value": "1. Can you also include a template-based communication baseline? For example, a simple strategy where agents share all available information in the first round.\n2. What would happen if the agents were heterogeneous — for example, one GPT-5 and one GPT-3.5?\n3. Could you provide more communication examples? They don’t need to be shown in the same format as in the appendix — a more compact table or text-box layout with multiple examples would be sufficient."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XmeInucUzb", "forum": "Uft46u0GRx", "replyto": "Uft46u0GRx", "signatures": ["ICLR.cc/2026/Conference/Submission14909/Reviewer_Wo24"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14909/Reviewer_Wo24"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966304353, "cdate": 1761966304353, "tmdate": 1762925254024, "mdate": 1762925254024, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}