{"id": "Q0ANR30XFh", "number": 7376, "cdate": 1758018576603, "mdate": 1759897856372, "content": {"title": "Rethinking Layer-wise Model Merging through Chain of Merges", "abstract": "Fine-tuning pretrained models has become a standard pathway to achieve state-of-the-art performance across a wide range of domains, leading to a proliferation of task-specific model variants. As the number of such specialized models increases, merging them into a unified model without retraining has become a critical challenge. Existing merging techniques operate at the level of individual layers, thereby overlooking the inter-layer dependencies inherent in deep networks. We show that this simplification leads to distributional mismatches, particularly in methods that rely on intermediate activations, as changes in early layers are not properly propagated to downstream layers during merging. We identify these mismatches as a form of internal covariate shift, comparable to the phenomenon encountered in the initial phases of neural networks training. To address this, we propose Chain of Merges (CoM), a layer-wise merging procedure that sequentially merges weights across layers while sequentially updating activation statistics. By explicitly accounting for inter-layer interactions, CoM mitigates covariate shift and produces a coherent merged model through a series of conditionally optimal updates. Experiments on standard benchmarks demonstrate that CoM achieves state-of-the-art performance. Codebase available in the supplementary material.", "tldr": "Model merging methodologies fails when inter-layer dependencies are ignored; our Chain of Merges (CoM) accounts for them through autoregressive updates.", "keywords": ["Model Merging", "Task Arithmetic", "Model Composition"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4287f0f3016c04379c03ac4a94120a91d010084d.pdf", "supplementary_material": "/attachment/ae50108a99586a460190608b4173daa3cdde75af.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces Chain of Merges (CoM), a new layer-wise model merging technique. The authors identify \"merging covariance shift\" (MCS) as a key problem in which merging layers independently induces activation shifts that negatively affect subsequent layers. CoM addresses this problem by merging layers sequentially, while updating activation statistics to ensure consistency."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Model merging is a critical and practical research area for making AI systems more modular.\n- The identification of MCS is an interesting conceptual contribution.\n- The paper is well-written and clear.\n- The empirical results, within the context of LoRA-finetuned models, appear strong."}, "weaknesses": {"value": "- **Misleading scope**. The paper's entire experimental validation is performed exclusively on LoRA-finetuned models. This fundamental design choice is only mentioned deep in the \"Implementation Details\" (Section 4.1). The abstract, introduction, and methodology sections all speak in general terms of merging \"fine-tuned models\" and \"task-specific checkpoints,\" which strongly implies full fine-tuning. The paper is therefore not evaluated as a general model-merging technique but as a LoRA-merging technique, and its contributions must be re-evaluated in this much narrower context.\n- **Invalid SOTA comparisons**. This LoRA-only setup invalidates the claims of \"state-of-the-art\" performance in model merging. The majority of the cited literature and the baselines themselves were developed and evaluated in the context of full-parameter fine-tuning. A clear example is TSV: the authors report ~78% normalized accuracy (on ViT-L/14), whereas the original TSV paper reports ~97% on the same benchmark (likely starting from an even higher absolute accuracy – which is not reported).\n- **No absolute accuracy**. The paper indeed reports only normalized accuracy. The omission of absolute accuracy is a critical flaw. Normalized accuracy alone can be misleading, as it may mask poor overall performance. Given the baseline discrepancies, reporting also absolute accuracy is essential for a fair comparison."}, "questions": {"value": "- What is the performance of CoM on models finetuned without adapters?\n- Can the authors provide the absolute accuracies (not just normalized) for all experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "V0wqIBnKqs", "forum": "Q0ANR30XFh", "replyto": "Q0ANR30XFh", "signatures": ["ICLR.cc/2026/Conference/Submission7376/Reviewer_SXdo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7376/Reviewer_SXdo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7376/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958302595, "cdate": 1761958302595, "tmdate": 1762919505266, "mdate": 1762919505266, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a new methodology for model merging. In particular, the paper notes that previous layer-wise merging works have neglected the well-known internal covariate shift problem, resulting in a distributional mistmatches. As such, the paper proposes a Chain of Merges (CoM) method, which sequentially merges weights layer by layer. Experimental results demonstrate that the proposed method provides very high normalized accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed idea is well-motivated, based on the internal covariate shift problem.\n- The displayed experimental results show strong performance of the proposed method.\n- The paper is well-written and easy to follow."}, "weaknesses": {"value": "- The paper does not explicitly explain the number of examples used in the method. One may guess that the number of examples is 500 based on the ablation study results in Table 4, but the performance of ViT-B/32 and Llama3-8B do not match with the main results in Table 1 and Table 2.\n- Also, the paper does not specify which set the examples come from.\n- The paper only reports the normalized accuracy, without reporting the actual performance. Considering how the proposed method is applied on LoRA-fine-tuned models, the results as is do not give a full picture as to how the proposed method actually performs in comparison on other works. \n- The paper does not show large-scale experiments (14 tasks or 20 tasks, as done so in Consensus TA (Wang et al., 2024)).\n- The paper does not compare against more recent state-of-the-art methods, such as EMR-Merging [A].\n- Some works compared in the table originally reported the results with full-fine-tuned models, to the best of the reviewer's knowledge. The comparison does not seem completely fair.\n\n\n[A] Huang et al., Emr-merging: Tuning-free high-performance model merging. NeurIPS 2024."}, "questions": {"value": "- Why is the proposed method only applied on LoRA-fine-tuned models? How is the performance when applied to full-fine-tuned models?\n- What is the actual number of examples used? \n- Do examples come from training set or test set?\n- The memory overhead seems to be very similar to TA. This is a bit confusing and surprising. If the Gram matrix is computed on at least 500 samples, wouldn't there be more memory usage? What's the actual memory usage?\n- How is the computational cost and latency compared to previous works mentioned in Table 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "v4RDMgkPNL", "forum": "Q0ANR30XFh", "replyto": "Q0ANR30XFh", "signatures": ["ICLR.cc/2026/Conference/Submission7376/Reviewer_Pa3c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7376/Reviewer_Pa3c"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7376/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968027044, "cdate": 1761968027044, "tmdate": 1762919504765, "mdate": 1762919504765, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CoM, which recursively merges the linear layer weights from first layer to last layer during model merging. It improves Regmean by addressing internal covariate shift and demonstrates good empirical performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is clearly-written and easy to understand.\n2. The method demonstrates good empirical results in both vision and NLP, including the results obtained with Llama-3."}, "weaknesses": {"value": "1. The proposed method CoM offers modest novelty. It extends Regmean by fixing the internal covariate shift problem. The novelty primarily lies in providing the inputs of the merged model rather than the individual models for Regmean merging algorithm.\n\n2. The performance of the baseline methods seem concerningly low (Table 1). The performance of most merging-based methods, including TA [1], Ties [2], DARE [3] seem to be notably lower than their reported results in the original papers. Furthermore, the methods which are designed to improve over TA, such as TIES, DARE, Consensus [4], LiNeS [5], underperform or have the same performance as TA. Furthermore, the manuscript does not provide implementation details to the compared baselines, which are needed in this case as the the baselines do not perform as expected.\n\nNote: If the reason for the baseline methods’ low performance is due to applying LoRA (which case also needs to be clarified), I suggest the authors add results for standard fine-tuning as well, following the literatures in model merging [1-5]. It is important to evaluate the performance of the proposed method in the standard fine-tuning scenario as well.\n\n3. The computational cost of TA, TIES, DARE, Consensus and LiNeS are missing in the computational cost comparison. It is unfair to omit them simply because their computational cost is negligible (Section C). The computational cost of the proposed methods need to be compared to the light-weight methods as well to clearly demonstrate the tradeoff to the viewers.\n\n4. Many important experimental details are not given. \n\n4.1 The implementation details of the baselines, as stated before.\n\n4.2 Where did the authors get the input samples for calculating the gram matrix, i.e., are they the same or different samples in the test set?\n\n4.3 How is the method merging the layers that are not linear layers (e.g., the attention layers)? Does it follow the Regmean setup to average their weights?"}, "questions": {"value": "1. For Eq. 5, even for the first linear layer, there are attention layers before the linear layers in the same residual block. As a result, shouldn’t the input still be affected by prior merging (on the attention layers in the same block, whose merging process is not explained in the paper) as well, making the notations in Eq. 5 inaccurate?\n\n[1] Editing Models with Task Arithmetic\n[2] TIES-Merging: Resolving Interference When Merging Models\n[3] Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch\n[4] Localizing Task Information for Improved Model Merging and Compression\n[5] LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances Model Merging"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Pgn38xKt3i", "forum": "Q0ANR30XFh", "replyto": "Q0ANR30XFh", "signatures": ["ICLR.cc/2026/Conference/Submission7376/Reviewer_1dpG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7376/Reviewer_1dpG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7376/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994109564, "cdate": 1761994109564, "tmdate": 1762919504435, "mdate": 1762919504435, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an algorithm to perform model merging on transformer based models fine-tuned on different tasks. The main contribution proposed is to take into account the order of the merging to avoid error propagation throughout the layers, identified as covariance shift in feature space by the authors. The proposed solution is to merge one layer at a time from the initial layer to the last, instead of considering merging each layer independently and in parallel. The merging strategy is based on (Jin et al 2022) where preactivation features on each task (i.e. inner products between weights and features)  are approximated by a shared weight matrix on feature space, which has a closed form solution. The author propose further to weight the contribution of each task using gram matrix statistics of the features. Experiments are performed on vision and text benchmarks, showing good improvements on tested dataset."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Simple and effective contribution** Taking into account the propagation of error throughout layers in the merging, is a simple, well justified by the and very effective modification according to the result presented. \n\n- **Strong measured performance**: performance on the models and datasets tested is consistently stronger with respect to the baselines tested.\n\n- **Comprehensive experiments**: the paper compares with 10+ baselines on the vision and text domain in the merging experiments, showing strong performance and good coverage , with the only exception of few unmentioned works (see weakness section)\n\n- **Ablations**: ablations experiments are useful to characterize the contribution of each component of the method proposed, showing the large impact of correcting the covariate shift between layers."}, "weaknesses": {"value": "- **Task similarity coefficient**: according to what written in the paper the task similarity coefficient is computed on the normalized Gram   $XX^T$ matrices, by counting the magnitude of the off-diagonal elements. The authors support this choice claiming that larger correlations between features indicate higher distance to the pretrained features Gram matrix and hence, higher task complexity. It is not clear to me why this is the case: why near orthogonal samples in the fine-tuned would imply good task generalization? Distance is not directly measure w.r.t. Gram Matrices son the pretrained model as far as I understand. Moreover, isn't this meant to be computed on the covariance matrix $X^TX$, to test orthogonality of the features rather than samples? Please clarify.\n\n- **Missing related works**: I think there are some missing related works [a,b] from previous methods that take into account layerwise dependency and would matter to discuss and compare to: especially [a] which proposes to merge task adaptively by weighting the contribution of each layer, being related to the layer ordering approach considered in the paper and improving over (Jing et al 2022). \n\n\n- **Testing on out of distribution settings** I think the lack of OOD experiments is a missed opportunity to confirm the performance of the method. this could be done by simply leaving out some of the tasks and testing the accuracy them, similarly as done in (Jin et al 2022) or [a].\n\n- **Missing absolute performance of the models**. I believe the paper would benefit from reporting the absolute performances of the fine-tuned model and base models on the different task in the Appendix as a reference to understand how well these perform. \n\n\n_[a] Yang, Enneng, et al. \"Adamerging: Adaptive model merging for multi-task learning.\", ICLR 2024_\n\n_[b] Xu, Jing, Jiazheng Li, and Jingzhao Zhang. \"Scalable Model Merging with Progressive Layer-wise Distillation.”, ICML 2025_"}, "questions": {"value": "- **Task similarity coefficient ablation**: in the text of the paper authors specify that the similarity coefficient is computed on actuation of the merged model, for efficiency reason. Would the similarity coefficients computed on the finetuned models  activations be highly correlated to the one obtained on the merge models? \n\n\n- **Robustness to sampling**: I think it would be useful to get variance across different sampling for each tasks, by e.g. averaging and reporting std on the results in Table (REF TABLE) across different samplings.\n\n- **Balanced sampling across tasks**: when the tasks have different complexity, could a different number of samples be needed? \n\n- **Scalability** What's the scalability of the method as opposed to averaging based methods? could it be employed e.g. on larger LLMs?\n\n- **Merging LoRA weights ablation** Did you try to merge the LoRA parameters of the fine-tuned models instead of the original weights? (Assuming they have the same bottleneck dimensions across tasks)\n\n- **Suggestion**: I would personally move the experiment on covariate shift earlier in the paper as a motivation to introduce the approach. It would be also useful to add the same measure on the merged model accounting for the order of layers to show that the covariance shift is lower in that case."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LrAT3IKu8j", "forum": "Q0ANR30XFh", "replyto": "Q0ANR30XFh", "signatures": ["ICLR.cc/2026/Conference/Submission7376/Reviewer_qsTg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7376/Reviewer_qsTg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7376/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997970332, "cdate": 1761997970332, "tmdate": 1762919504056, "mdate": 1762919504056, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}