{"id": "FriP8PXHpY", "number": 13283, "cdate": 1758215984719, "mdate": 1759897448950, "content": {"title": "Circuit Complexity Bounds for Visual Autoregressive Model", "abstract": "Understanding the expressive ability of a specific model is essential for grasping its capacity limitations. A recent breakthrough in image generation is the introduction of Visual Autoregressive ($\\mathsf{VAR}$) Models, which employ a scalable coarse-to-fine \"next-scale prediction\" framework. We investigate the circuit complexity of the VAR model and establish a bound in this study. Our primary result demonstrates that the VAR model is equivalent to a simulation by a uniform $\\mathsf{TC}^0$ threshold circuit with hidden dimension $d$ and $\\mathrm{poly}(d)$ precision. This is the first study to rigorously highlight the limitations in the expressive power of VAR models despite their impressive performance. We believe our findings will offer valuable insights into the inherent constraints of these models and guide the development of more efficient and expressive architectures in the future.", "tldr": "", "keywords": ["generative models", "complexity"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9caa3cfa3a18c9069d87574b6c3b700aa254326a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper provides the first circuit-complexity analysis of Visual Autoregressive models, formally showing that a fixed-depth (O(1)), poly(d)-precision VAR—comprising bicubic up-interpolation, attention, MLP/LN, convolutions, and a constant-depth VQ-VAE decoder—can be simulated by a DLOGTIME-uniform TC0 threshold-circuit family of polynomial size and constant depth. By mathematically formulating VAR’s coarse-to-fine “next-scale” architecture and proving TC0 realizations for each component (including exp approximation and matrix ops), the work establishes a strong uniform TC0 upper bound on VAR’s expressive power, thereby clarifying inherent computational limitations and aligning VAR with recent TC0 bounds for Transformers and SSMs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* First circuit-complexity treatment of VAR models; clean formalization of the “next-scale” autoregressive architecture by applying the known TC0 techniques (floating-point ops, exp approximation, matrix/convolution ops, attention) to a new domain.\n* I'm not an expert in this domain, but the stage-wise proof structure makes the argument easy to follow; explicit statements of depth/size bounds and uniformity aid reproducibility."}, "weaknesses": {"value": "* The main TC0 upper bound critically relies on O(1) depth and poly(d) precision/width; the paper does not analyze how bounds change when depth scales with resolution or when precision changes, limiting relevance to large practical VARs. Provide depth-parameterized bounds or discuss thresholds where the simulation may leave TC0."}, "questions": {"value": "* Many bounds assume hm, wm ≤ poly(d). In practical VARs, d may be modest while image size grows large—how would your analysis scale if hm, wm are the primary growth parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "JMAihjJkcc", "forum": "FriP8PXHpY", "replyto": "FriP8PXHpY", "signatures": ["ICLR.cc/2026/Conference/Submission13283/Reviewer_R5cA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13283/Reviewer_R5cA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761168504316, "cdate": 1761168504316, "tmdate": 1762923956647, "mdate": 1762923956647, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes the expressiveness of visual autoregressive models using circuit complexity, formalizing VAR modules and proving they can be simulated by shallow threshold circuits under certain assumptions. The main result shows that the entire VAR pipeline can be simulated in O(1) depth and polynomial size, connecting VAR architectures to established circuit complexity classes."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper attempts to formalize the components of VAR models and provides some logical structure.\n\n- The authors reference existing circuit complexity results and applies them to the VAR setting."}, "weaknesses": {"value": "- There is substantial overlap (e.g., Figure 1) with another ICLR submission (submission 2833), both focusing on theoretical complexity of VARs and even using exactly the same figures. This strong similarity raise concerns about originality and possible being written by LLMs.\n\n- The contribution is mainly upper bounds. no lower bounds or separation results are provided, limiting theoretical novelty.\n\n- Some key assumptions (e.g., constant depth/layers) in this paper do not match real-world VAR configurations, reducing practical relevance.\n\n- Figure 1 contains unreadable symbols and overlaps. Moreover,"}, "questions": {"value": "How would the reported results change if the number of layers grows with input size, rather than being constant?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IJD4WLi2Nl", "forum": "FriP8PXHpY", "replyto": "FriP8PXHpY", "signatures": ["ICLR.cc/2026/Conference/Submission13283/Reviewer_raET"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13283/Reviewer_raET"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761616556845, "cdate": 1761616556845, "tmdate": 1762923956403, "mdate": 1762923956403, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper establishes the first circuit complexity bound for Visual AutoRegressive (VAR) models, demonstrating that they can be simulated by a DLOGTIME-uniform TC0 threshold circuit with constant depth, poly(n) size, and poly(n) precision, despite their strong empirical performance in image generation. The authors systematically analyze each component including up-interpolation blocks, attention layers, convolution blocks, and the VQ-VAE decoder to prove that all can be computed within TC0 under realistic precision assumptions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper provides a technical result that extends known TC0 bounds to VAR models."}, "weaknesses": {"value": "1. The paper largely follows existing circuit complexity analysis techniques developed for Transformers and Mamba, offering limited novel methodological or theoretical advancements.\n2. While the paper claims theoretical limitations for VAR, it fails to reconcile this with its strong empirical performance, leaving the tension between theory and practice unaddressed.\n3. What practical implications does the paper’s conclusion that VAR models lie within TC0 have for real-world modeling or algorithm design?\n4. Figure 1 is identical to that in https://openreview.net/forum?id=S3Fq8E9jb7, raising serious concerns about originality and proper attribution."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yhXshbUck5", "forum": "FriP8PXHpY", "replyto": "FriP8PXHpY", "signatures": ["ICLR.cc/2026/Conference/Submission13283/Reviewer_stB8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13283/Reviewer_stB8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761728877870, "cdate": 1761728877870, "tmdate": 1762923955964, "mdate": 1762923955964, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper conducts a comprehensive theoretical investigation into the circuit complexity bounds of Visual Autoregressive (VAR) models, which adopt a coarse-to-fine \"next-scale prediction\" framework for image generation. The core result demonstrates that VAR models (with hidden dimension d and poly(d) precision) can be simulated by DLOGTIME-uniform $TC^0$ threshold circuits with polynomial size and constant depth. These findings reveal inherent expressive limitations of VAR models despite their empirical performance advantages."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Due to significant differences between my research domain and the circuit complexity/visual autoregressive modeling field of this paper, I am unable to provide a substantive assessment of its originality, quality, clarity, and significance from a professional perspective. The paper appears to address an underexplored gap (circuit complexity analysis of VAR models) and presents a structured theoretical framework with detailed definitions and proofs, which suggests careful academic rigor. However, a precise evaluation of whether its contributions (e.g., novel formulations, complexity bounds) are impactful or original within the field requires expertise in computational complexity that I do not possess."}, "weaknesses": {"value": "See Strengths."}, "questions": {"value": "No question"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "clXJUlNMUA", "forum": "FriP8PXHpY", "replyto": "FriP8PXHpY", "signatures": ["ICLR.cc/2026/Conference/Submission13283/Reviewer_Dzt4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13283/Reviewer_Dzt4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761909676995, "cdate": 1761909676995, "tmdate": 1762923955462, "mdate": 1762923955462, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}