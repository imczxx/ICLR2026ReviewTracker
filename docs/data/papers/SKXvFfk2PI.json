{"id": "SKXvFfk2PI", "number": 6545, "cdate": 1757988462432, "mdate": 1759897908727, "content": {"title": "Boosting Image Dehazing via Elaborate Integration of Complementary Dependencies", "abstract": "Haze removal seeks to restore clear images from hazy inputs. Previous research demonstrates that short-range dependencies are effective for preserving local details, while long-range dependencies capture global context. Because both are essential to dehazing and complement each other, many approaches explicitly integrate them within dual-stream frameworks. However, the trustworthy aggregation of these dependencies remains underexplored. In this paper, to optimize the contributions of dependencies at varying ranges, we first conduct comprehensive quantitative and qualitative experiments to identify the key influencing factors. Our findings indicate that an effective aggregation strategy should jointly consider haze density and semantic information. Building on these insights, we introduce a CLIP-enhanced Dual-Path Aggregator for the class of dual-stream dehazing methods. This module first employs a shared backbone to generate fine-grained haze density and semantic maps in a computationally efficient manner, and then uses them to instruct the integration process. Extensive experiments show that the proposed aggregator significantly improves the performance of existing dual-stream methods, and our custom-built model, DehazeMatic, achieves state-of-the-art results across multiple benchmarks. As an additional contribution, we also address, for the first time, the challenge of accurately estimating haze density maps.", "tldr": "We are the first to demonstrate that effective aggregation of varying range dependencies enables robust haze removal, guided by our first-of-its-kind joint estimation of the haze density map and semantic map.", "keywords": ["Varying Range Dependencies", "Haze Density Map Estimation", "Image Dehazing"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e4bc3f392666a7d05e804caaff3ffe3cc78b3b2e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a CLIP-enhanced Dual-Path Aggregator (CedA) that adaptively fuses the two types of dependencies. Through both quantitative and qualitative analyses, the authors identify haze density and semantic information as the two key factors determining the relative importance of these dependencies. CedA leverages a pretrained CLIP model to generate pixel-level haze density and semantic maps, which guide the adaptive fusion process. Based on CedA, the authors further build a new model, DehazeMatic, which achieves state-of-the-art performance across several synthetic and real-world benchmarks with minimal computational overhead."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The proposed method generates patch-level haze density maps via CLIP, introducing a meaningful physical prior for dehazing.\n\nIt achieves consistent improvements across five major benchmarks, demonstrating the generality and robustness of the proposed module."}, "weaknesses": {"value": "In Figure 4, the authors present an “Illustration of estimated haze density maps,” yet this result appears physically unreasonable. For the Homogeneous Haze case, nearby buildings are visibly clearer, indicating lower haze density, while distant buildings are more obscured, implying higher density. However, the predicted haze density maps display a uniform distribution. Given that haze density estimation is one of the key modules, this discrepancy is concerning.\n\nTable 1 only reports “Extra Runtime” without providing model parameters or GPU memory usage, and Sec. 5.3.3 does not specify image resolution or batch size, making efficiency comparison unclear.\n\nThe paper lacks interpretability analysis of the CedA aggregation weight generator. In Eq. (2) and Fig. 3, the Aggregation Weight Generator W(H,S) is defined merely as a lightweight linear layer, without any visualization or sensitivity analysis.\n\nSince many more advanced vision-language models (VLMs) and CLIP variants have emerged, the paper should clarify why CLIP was specifically chosen instead of newer alternatives.\n\nIn Sec. 4.3.2, the authors train on synthetic “pseudo-density maps” generated by the Atmospheric Scattering Model (ASM) but never validate their correlation with real haze density. Because ASM-generated haze can differ significantly from real-world haze, the learned model may overfit statistical artifacts rather than true physical characteristics.\n\nEq. (1) lacks an explanation of the statistical assumptions and variance analysis for the expectation term; in Eq. (5), the meaning of the Softmax output channel “[:, :, 0]” is not defined; and Eqs. (6–7) introduce a joint optimization objective without any convergence or stability analysis."}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "391Aq7coCU", "forum": "SKXvFfk2PI", "replyto": "SKXvFfk2PI", "signatures": ["ICLR.cc/2026/Conference/Submission6545/Reviewer_c4TU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6545/Reviewer_c4TU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761401441614, "cdate": 1761401441614, "tmdate": 1762918892789, "mdate": 1762918892789, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel image dehazing framework that integrates short-range and long-range dependencies through a CLIP-enhanced Dual-path Aggregator. The method utilizes CLIP priors to generate semantic and haze density maps, which are used to adaptively guide feature aggregation in dual-stream architectures. The authors further build a benchmark model, DehazeMatic. The main contributions include identifying the key factors influencing dependency integration, proposing a plug-and-play aggregation module, and achieving accurate haze density estimation for the first time."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper identifies haze density and semantic information as key factors governing the balance between short-range and long-range dependencies and develops a CLIP-guided aggregation strategy, going beyond naive addition or concatenation used in prior work.\n2. This provides a new interpretable dimension for dehazing research and may inspire further method development grounded in physical properties.\n3. The paper includes extensive evaluations on synthetic and real-world datasets, ablation studies, visual comparisons, and runtime analysis, supporting both effectiveness and efficiency."}, "weaknesses": {"value": "1. Although the paper provides empirical observations, it lacks a deeper theoretical justification for why CLIP embeddings effectively guide dependency integration.\n2. The evaluation on real-world datasets does not include comparisons with diffusion-based models or large-scale foundation models, which are becoming increasingly relevant in this domain.\n3. While the authors state that CLIP introduces negligible inference cost, they do not report training time, memory usage, or FLOPs, limiting the credibility of the claimed efficiency.\n4. The contributions rely on integrating existing dual-stream architectures with CLIP-guidance rather than introducing a fundamentally new dehazing mechanism."}, "questions": {"value": "See the above parts."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SlDPjbORVT", "forum": "SKXvFfk2PI", "replyto": "SKXvFfk2PI", "signatures": ["ICLR.cc/2026/Conference/Submission6545/Reviewer_oBiT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6545/Reviewer_oBiT"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761441090529, "cdate": 1761441090529, "tmdate": 1762918892414, "mdate": 1762918892414, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how to effectively integrate short-range and long-range dependencies in dual-stream image dehazing networks. Through detailed empirical analysis, the authors reveal that both haze density and semantic information jointly determine the importance allocation between these dependencies. Based on this insight, the authors propose a CLIP-enhanced Dual-path Aggregator (CedA), which leverages a frozen CLIP image encoder with learnable prompts to generate complementary semantic and fine-grained haze density maps. These maps are then projected to produce pixel-wise weights that adaptively fuse the outputs of the short- and long-range streams. Extensive experiments on both synthetic and real-world datasets demonstrate that integrating CedA consistently boosts performance across various dual-stream frameworks, achieving state-of-the-art PSNR and SSIM results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is the first quantitatively demonstrate that haze density and semantic information are the key factors influencing the relative importance between short-range and long-range dependencies in image dehazing.\n2. By leveraging prompt tuning, the authors effectively adapt CLIP to a low-level vision task and design a plug-and-play module that can be seamlessly integrated into any existing dual-stream framework.\n3. Experimental results show that the proposed method achieves superior dehazing performance, consistently outperforming strong baselines across multiple synthetic and real-world datasets."}, "weaknesses": {"value": "1. The method relies solely on prompt tuning for adapting CLIP, which inherently limits its performance to the representational capacity of the pretrained CLIP model. The authors should further evaluate the approach on out-of-distribution or extreme scenarios that CLIP was not exposed to during pretraining.\n2. The model is trained exclusively on synthetic hazy images, raising concerns about its generalization to real-world scenes. The authors should clarify whether the synthetic-to-real gap affects performance and why real-world data were not utilized for training.\n3. The motivation and theoretical explanation behind the proposed design are not sufficiently elaborated. A deeper discussion of the underlying principles and empirical observations would make the rationale of the method more convincing."}, "questions": {"value": "Please refer to my comments on weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DpbbmPobEJ", "forum": "SKXvFfk2PI", "replyto": "SKXvFfk2PI", "signatures": ["ICLR.cc/2026/Conference/Submission6545/Reviewer_7n8T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6545/Reviewer_7n8T"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761636925744, "cdate": 1761636925744, "tmdate": 1762918892075, "mdate": 1762918892075, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- The paper’s core idea is to obtain haze density (H) via CLIP and semantics (S) via cross-attention, then perform per-token fusion (W(H,S)) to adaptively combine Short/Long streams at the pixel level.\n- Experiments replace naive aggregators in existing dual-stream backbones with CedA (plug-in) and show consistent gains; the integrated model (DehazeMatic) also reports strong overall results.\n- Prompts are trained in two stages (CE classification → synthetic regression) to predict patch-wise density, and S is formed by bidirectional cross-attention between CLIP embeddings and low-level features.\n- The framework emphasizes practicality, but the overall training objective (total loss) and gradient flow are not explicitly formalized in the main text.\n- The synthetic data pipeline is strong, so it is unclear how much of the reported gains come from CedA itself versus the pipeline."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Per-token fusion justified by H·S mitigates dual-stream limitations and improves interpretability.\n- Plug-and-play validation demonstrates backbone-independent gains.\n- Learnable prompts surpass zero-shot for density map quality; visualizations are intuitive.\n- Integration into DehazeMatic supports the work’s practical value.\n- Ablation shows performance drops when removing H/S, partially evidencing the contribution of the key components.\n- Although haze density is trained on synthetic data, the method shows consistent improvements on real datasets."}, "weaknesses": {"value": "- The total loss and gradient flow are not clearly summarized in the main paper.\n- Insufficient separation of data-pipeline effects.\nThey generate 20k non-homogeneous density maps from remote-sensing images using DCP plus smoothing for synthesis (Appendix A.2.1). This strong synthetic pipeline could substantially determine learnable prompt (H) quality. However, the main text/experiments do not assess the pipeline's sensitivity or necessity—e.g., performance without it or with alternatives."}, "questions": {"value": "Could you specify in the main text the end-to-end total loss, the H/S→W spatial alignment, and the gate activation (sigmoid/softmax, temperature)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lEOlYwBpHb", "forum": "SKXvFfk2PI", "replyto": "SKXvFfk2PI", "signatures": ["ICLR.cc/2026/Conference/Submission6545/Reviewer_ND7M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6545/Reviewer_ND7M"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6545/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988033977, "cdate": 1761988033977, "tmdate": 1762918891633, "mdate": 1762918891633, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}