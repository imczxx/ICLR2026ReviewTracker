{"id": "N5gNhO2OPB", "number": 5634, "cdate": 1757924293880, "mdate": 1759897963875, "content": {"title": "PRLS-RFF: Physically Consistent Representation Learning with Self-Supervised Pretraining for RF Fingerprinting", "abstract": "Under domain shifts and open-world conditions, reliably re-identifying radio frequency (RF) devices is essential for wireless security. As a hardware-rooted physical-layer signature, the RF fingerprint has been widely used for device re-identification. However, supervised RF fingerprint identification (RFFI) models often overfit acquisition artifacts and rely on extensive supervision, leading to sharp cross-domain performance drops and weak open-world behavior. To address these limitations, we introduce PRLS-RFF, which targets physically consistent RF fingerprint representations. We design a dual-stream Mamba-based backbone with physics-consistent, multi-view perturbations to encode representation-level invariances. Additionally, to better capture the structure of RF fingerprints (RFFs) across transient and steady-state regimes, the backbone fuses time-domain and time--frequency features using efficient long-context modeling. As a result, the learned representations are domain-robust, which can support reliable open-set recognition. To validate its robustness, we conduct extensive experiments on several public datasets and observe the performance surpassing state-of-the-art models in both cross-domain identification and open-set recognition tasks.", "tldr": "Physics-consistent multi-view self-supervised contrastive pretraining for a Mamba dual-stream RF model, learning hardware-invariant fingerprints and improving cross-domain classification & open-world detection with fewer labels.", "keywords": ["Selective State-Space Models (Mamba);Radio-Frequency Fingerprinting (RFF);Cross-Domain Generalization; Open-World Device Recognition; Wireless Security"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1ebf3c5beb2ea69c8318fccc0d95ccf018a1ca47.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes PRLS-RFF, tackling the problem of recognizing wireless devices (fingerprinting) when the environment or channel conditions change. Instead of relying on labeled data, the method uses self-supervised pretraining, with a dual-stream backbone that fuses time-domain and time-frequency signals together. The experiments show performance improvement over baseline models as well as LSTM and GRU."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper uses physics-based augmentations (noise, phase distortion, I/Q imbalance, etc.) to process the signals. This helps the learned representation be more meaningful in real-world wireless settings.\n\n2. The way of using modalities from both time domain-domain stream and time-frequency stream is novel, since some features are complimentary to each other. \n\n3. The model demonstrates cross-domain adaptation abilities. They show that (in Table 2) with few labels and under domain shifts, their method still performs well and achieves high accuracy. This is desirable in RF fingerprinting, where collecting labeled data under every possible condition is impractical."}, "weaknesses": {"value": "1. The main novelty of the paper is mainly integrative. There are papers on many individual parts of the algorithm, for instance, self-supervised learning ([1]), data augmentations ([2]), and dual-modalities ([3]).\n\n2. The dataset breath is limited in current experiments. The authors mainly used UAV RF datasets for evaluating different methods.\n\n3. The modern baseline is also limited. It seems like in Table 1, 3, 4, in addition to traditional methods (LSTM, GRU, or K-means), the authors compare only 2-3 modern baselines.\n\n4. It seems like the compute and model size are not reported in the paper.\n\n\n[1] Chen, Jun, Weng-Keen Wong, and Bechir Hamdaoui. \"Unsupervised contrastive learning for robust RF device fingerprinting under time-domain shift.\" ICC 2024-IEEE International Conference on Communications. IEEE, 2024.\n\n[2] Mohammadian, Amirhossein, and Chintha Tellambura. \"RF impairments in wireless transceivers: Phase noise, CFO, and IQ imbalance–A survey.\" IEEE access 9 (2021): 111718-111791.\n\n[3] Shen, Guanxiong, et al. \"Radio frequency fingerprint identification for LoRa using spectrogram and CNN.\" IEEE INFOCOM 2021-IEEE Conference on Computer Communications. IEEE, 2021."}, "questions": {"value": "1. Could the author please clarify which part is genuinely new in terms of algorithmic design, rather than a combination of existing methods? Please see above in Weakness 1.\n\n2. You cite Mamba and SSM models for long-sequence processing, but how does your fusion differ from prior RF Mamba?\n\n3. Most results come from a single UAV dataset and UCIHAR. How does the model behave across receivers, and longer-term drift (e.g., weeks)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wdCAX7gQwa", "forum": "N5gNhO2OPB", "replyto": "N5gNhO2OPB", "signatures": ["ICLR.cc/2026/Conference/Submission5634/Reviewer_9KV6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5634/Reviewer_9KV6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5634/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760639932273, "cdate": 1760639932273, "tmdate": 1762918168698, "mdate": 1762918168698, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a novel self-supervised joint embedding-based (bootstrap your own latent, BYOL) representation learning approach for re-identification of hardware induced radio frequency (RF) fingerprints. The method fuses time and time-frequency representations capturing transient and steady-state pattern.\nThe self-supervised pre-training utilises physically motivated augmentations to create multiple data views. The neural backbone employs selective state-space blocks for efficient long-context sequence modelling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed method is well motivated and presents a thoughtful and novel combination of existing concepts. \n- The manuscript is well written and easy to understand. \n- An extensive evaluation is performed. The proposed approach consistently outperforms the compared baselines."}, "weaknesses": {"value": "- At present, the manuscript’s methodological contribution appears limited, as many of the concepts and components employed are already well established. The work may therefore be more suitable for an application‑oriented journal or conference."}, "questions": {"value": "- The paper motivates \"unintentional physical artifacts embedded in baseband waveforms, originate in the physical layer and remain tightly coupled to individual transmitters\" and \"RF fingerprints arise from device-specific analog front-end nonidealities at the physical layer and manifest in both transient and steady-state regimes\". I was wondering if such artifacts can accurately be measured. For instance, I would think that some of the cues outlined in Section 3.2 are e.g. temperature-dependent. So what if at one day a device is detected first and the other day it is detected again but the ambient temperature is much different (having then an influence on the oscillators). Isn't this an issue?\n-  The paper motivates physical artifacts/characteristics a lot based on the internal processing of the wireless system. I was then a bit confused as the dataset that has been used targets the identification of UAVs which induce specific patterns using their flight behavior. Hence, it is rather the \"housing\" or the application that induces signal specific artifacts (at least in the dataset). This should be made clearer in the paper, or do I misunderstand something here?\n- To me it was not entirely clear how the datasets are split and arranged (using \"time-disjoint\" datasets?) and what distances are part of data#1 and data#2, respectively. In fact: it might be a good idea to define the data set a bit more (and also the wireless parameters that are relevant, i.e., waveforms, bandwidth, etc.)\n\nSmall point: many sentences end with \".\" and miss a space afterwards."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hFQ0WwqxSH", "forum": "N5gNhO2OPB", "replyto": "N5gNhO2OPB", "signatures": ["ICLR.cc/2026/Conference/Submission5634/Reviewer_rVm4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5634/Reviewer_rVm4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5634/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761231271709, "cdate": 1761231271709, "tmdate": 1762918168370, "mdate": 1762918168370, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "RLS-RFF is a self-supervised RF fingerprinting framework that learns channel-invariant, device-specific representations from raw baseband signals.\n A dual-stream Mamba encoder processes each waveform: one time-domain branch models transient I/Q features directly, while a time–frequency branch encodes CWT scalograms capturing steady-state spectral cues. The two streams are fused through stacked selective state-space (Mamba) blocks, enabling efficient long-context sequence modeling.\nDuring pretraining, the system generates two physics-consistent augmentations of each signal (e.g., SNR scaling, phase or carrier drift) and passes both through the shared encoder. Their latent embeddings are aligned via a multi-view consistency loss—encouraging invariance to channel and receiver variation while preserving device identity. Gradients update the encoder and projection head jointly.\nThe authors pair this self-supervised training with an additional final layer for downstream classification / rejection to complete their method.\nExperiments were conducted on the UAV RF fingerprint dataset and on  UV RF and  UCI HAR for  proving open-set classification robustness."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1) Physically grounded self-supervision\n The method ties representation learning directly to the physics of RF propagation. Its augmentations (SNR scaling, phase shifts, CFO, fading) are realistic and target true channel and receiver variations, giving the learned embeddings meaningful, reality-rooted invariance.\n\n2) Efficient long-context modeling with Mamba\n The selective state-space (Mamba) backbone can process entire 92 k-sample RF bursts in linear time, capturing both transient and steady-state patterns that CNNs or short RNNs typically miss. This provides genuine architectural novelty with computational efficiency.\n\n3) Empirically strong domain robustness\nMotivating results in their selected datasets."}, "weaknesses": {"value": "1. Limited dataset diversity and scale. The UAV dataset has only seven nearly identical devices collected in controlled settings (6–15 ft, single receiver). Reported 98–99 % accuracies may reflect dataset saturation rather than real-world robustness.\n\n2. Unclear tuning and training cost. The model requires 1000 epochs of pretraining and uses Mamba blocks that can be sensitive to state dimension, initialization, and learning rate. The paper does not detail hyperparameter stability or fairness of tuning against baselines.\n\n3. Cross-domain generalization partly untested. The second dataset (UCI HAR) is non-RF and lacks channel effects, so results there demonstrate open-set mechanics, not RF-specific invariance. Broader testing on heterogeneous RF environments or different hardware would better substantiate generalization claims.\n\n\nThe above ultimately limit the scope of the author's contribution. As it stands it is a very interesting step towards physics-aware representation learning but the pragmatic efficacy is not strongly proven.\n\nPrior Work\n\nThere are early prior contributions, examining the existence and identification potential of physical artifacts in a signal that stem from manufacturing imperfections. Chameleons oblivion comes to mind, as an example. Since the authors explicitly state “RF fingerprints (RFFs), unintentional physical artifacts embedded in baseband waveforms, originate in the physical layer and remain tightly coupled to individual transmitter”, that body of work and perhaps others  need to be acknoeldged among the foundational evidence base. \n\nFollowing that direction the authors should elaborate on the contribution of their approach which I believe is indeed quite interesting: they encode physical layer physical constraints to learn novel representational schemes that can reliably be matched to a signal.\nA sound juxtaposition of of their approach could also highlight their contributions which lay in the robustness and invariance of their representations rather that simple efficacy of hardware artifacts as identifiers.\n\n\nFormatting\n\nA plain conceptual overview followed by an earlier presentation of figure 1 would go, I believe, a long way towards understanding the paper.\n\nThe overall pipeline presentation is very confusing. It is hard for the reader to understand the interplay between the mamba backbone and the constraints enforcing architecture. Which happens first? What is the loss for the backbone of figure 1? Is it the loss of the constraints network of figure 2? A flowchart explicitly outlining exactly what happens is absolutely necessary."}, "questions": {"value": "1.How do you handle synchronization and normalization between the two branches?\n\n2.What was the memory footprint of the model and what was the sample size used?\n\n3.How impactful was normalization on training stability and generalization on your unseen data?\n\n4.The work is definitely an interesting concept, my worry is that the data was gathered in relatively similar conditions. How can we be certain that it would generalize well on say, open air data vs in-doors data?\n\n5.THE UIC HAR dataset is used as proof-of-concept for larger open set identification. How are you handling it? What are the I/Q components here? Is the pipeline the same across both of the datasets?\n\n6.How extensive was hyperparameter tuning? How were the parameters chosen?\n\n7.The UC RF dataset is relatively small and in very controlled conditions. How can we be sure that the accuracy presented here can generalize well in open-air, multipath heavy conditions?\n\n8.It would be quite more motivating to see per class confusion breakdowns than simple accuracy, especially in the open-set case.\n\nWhy is the green cluster on Figure 3b so much more discernible?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "N9WVjB6Mrd", "forum": "N5gNhO2OPB", "replyto": "N5gNhO2OPB", "signatures": ["ICLR.cc/2026/Conference/Submission5634/Reviewer_mELh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5634/Reviewer_mELh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5634/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937921503, "cdate": 1761937921503, "tmdate": 1762918168112, "mdate": 1762918168112, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PRLS-RFF, a framework designed to improve the robustness of Radio Frequency Fingerprint Identification (RFFI) against domain shifts (such as changes in channel, receiver distance, and time) and open-world scenarios. The authors propose a dual-stream backbone architecture that utilizes Selective State-Space Models (Mamba) to process and fuse time-domain (I/Q) and time-frequency (Continuous Wavelet Transform - CWT) representations. To train this backbone, the paper employs a self-supervised pretraining approach using a multi-view non-contrastive objective. Crucially, the views are generated using \"physics-consistent\" augmentations tailored to RF signals, including Additive White Gaussian Noise (AWGN), phase distortion, Carrier Frequency Offset (CFO), and I/Q imbalance. The goal is to learn representations that are invariant to these specific perturbations while retaining device-intrinsic signatures.\n\nEmpirical evaluations on a UAV RF fingerprint dataset demonstrate that PRLS-RFF outperforms recent baselines in cross-domain identification (varying distances), few-shot adaptation, and open-world recognition tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "I appreciate the authors' effort to apply new architectures like Mamba and self-supervised learning to the field of RF Fingerprinting: While dual-stream / dual-encoder architectures and self-supervised learning are established in other fields, their specific application here—coupling Mamba-based long-context modeling with RF-specific physical augmentations for fingerprinting—is new."}, "weaknesses": {"value": "The main weaknesses of the paper are lack of clarity and lack of motivation. A lot of things are presumed, which ultimately weakens the scientific contribution of this paper.\n\n- Architecture design in Section 3.3 and 3.4 seems ad-hoc and not well-justified in the paper. The motivation seems weak. Maybe I missed them, but there seems to be no dedicated ablation / exploration experiments on design choices of the main architecture in Figure 1 and 2 - to name a few, why Mamba block not other blocks (Transformer, CNN, RNN, etc)? how are # parameters decided for each architecture blocks?\n\n- Mamba block in Figure 1 is not clearly introduced in the paper.\n\n- Why the self-supervised loss is \"non-contrastive\"? I wonder if there is a contrastive counterpart and how it performs.\n\n- The dataset used and the evaluation metric (i.e. top1 accuracy) are not clearly introduced in the paper.\n\n- The baselines in Table one are not clearly described. For example CNN-LSTM is super unclear - there could be numerous ways of designing the architecture and altering the design choices like # parameters each layer, training loss - what we are exactly comparing against here?\n\n- typo: line 366 \"about 1 2 points\" should be \"about 1-2 points\""}, "questions": {"value": "Please see weakness for details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YNh4dBfVEx", "forum": "N5gNhO2OPB", "replyto": "N5gNhO2OPB", "signatures": ["ICLR.cc/2026/Conference/Submission5634/Reviewer_j9Bp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5634/Reviewer_j9Bp"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5634/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762150023911, "cdate": 1762150023911, "tmdate": 1762918167468, "mdate": 1762918167468, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}