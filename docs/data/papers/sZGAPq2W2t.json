{"id": "sZGAPq2W2t", "number": 8872, "cdate": 1758100658481, "mdate": 1759897757924, "content": {"title": "TS-TPR: Tensor Product Representation for Multivariate Time Series Forecasting", "abstract": "Real-world multivariate time series exhibit nonstationary inter-variable dependencies, which evolve dynamically due to external environmental shifts. While capturing these intricate dynamics is crucial for accurate forecasting, many existing methods still struggle to explicitly model these complex relationships. This motivates the need for compositional learning, which explicitly separates relational and temporal components and flexibly recombines them. Such a design allows models to adapt to time-varying inter-variable relationships and generalize to unseen patterns. To address this, we introduce TS-TPR, a novel framework that employs tensor product representations for compositional learning. Specifically, context-aware role generation identifies the most salient relationships at each time, while hierarchical filler extraction summarizes the corresponding temporal patterns. By combining these dynamically generated roles and fillers via tensor products, TS-TPR creates an explicit, structured representation that naturally scales to many variables and adapts as dependencies shift. Through experiments on diverse real-world benchmarks, we show that TS-TPR not only outperforms state-of-the-art baselines but also provides interpretable, time-varying insights into inter-series interactions.", "tldr": "We propose TS-TPR, a compositional forecasting model using tensor product representations, explicitly capturing dynamic inter-variable relationships in multivariate time series with improved accuracy and interpretability.", "keywords": ["multivariate time series forecasting", "tensor product representation", "compositional generalization", "structured representation learning", "relational learning"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/75c3f744e9e5d53ecb8f4986003e3ec105162738.pdf", "supplementary_material": "/attachment/be00a54428102880603f2b587e8d36f021017bb8.zip"}, "replies": [{"content": {"summary": {"value": "The authors address a key challenge in multivariate time series forecasting (MTSF): nonstationary inter-variable dependencies, where relationships between variables evolve dynamically. They argue that existing models often entangle these relational dynamics with temporal patterns, leading to poor performance under distribution shifts. To solve this, the authors propose TS-TPR, a novel framework based on Tensor Product Representation (TPR) for compositional learning. The core idea is to explicitly disentangle relational \"roles\" from temporal \"fillers\". To manage the $N \\times N$ complexity of variable relations, the framework learns a \"codebook\" of $K$ generalized \"relation prototypes\". At each time step, the model dynamically selects the $M$ most relevant prototypes (roles) based on the current context and uses a hierarchical attention mechanism to extract the corresponding temporal patterns (fillers). A Linear Transformer is then used to perform the TPR binding and unbinding operations to generate the final forecast. Experiments on long-term, short-term, and zero-shot forecasting benchmarks demonstrate that TS-TPR achieves state-of-the-art or competitive performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The motivation is clear and targets a critical, well-argued problem in time series: modeling nonstationary inter-variable dependencies.\n* The idea of using a learnable **codebook** to quantize the $N \\times N$ relationship space into $K$ generalized prototypes is a novel and effective method to address the combinatorial complexity problem.\n* The experimental evaluation is comprehensive, covering long-term, short-term, and zero-shot settings, and shows strong performance against robust SOTA baselines."}, "weaknesses": {"value": "* The framework's **architectural design is relatively complex**, integrating multiple sophisticated modules. This design results in significant computational overhead: empirical data (Table 7) shows that TS-TPR uses **3-5x more memory and training time** than baselines. However, there is a **cost-benefit mismatch**, as the performance gain (e.g., on the Weather dataset) is **marginal** for such a high cost, questioning its practical value.\n* The **\"zero-shot\" generalization claim is weak**. All zero-shot experiments (Table 3, 9) are conducted *within* the ETT dataset family (e.g., ETTh1 $\\rightarrow$ ETTh2). As all ETT datasets originate from the same physical source, this does not sufficiently prove cross-domain generalization.\n* The **\"interpretability\" claim (Figure 3) is overstated**. The figure effectively demonstrates *adaptability* (i.e., the model switches from codes #5, #13 to code #2 when the data pattern shifts) but not *interpretability*, as the semantic meaning of what codes $c_2, c_5, c_{13}$ actually represent is never analyzed."}, "questions": {"value": "1. Regarding the computational cost (Table 7): How do the authors justify the 3-5x increase in memory/time for the marginal (e.g., ~2.5%) MSE improvement on datasets like Weather? Is this trade-off practical for real-world deployment?\n2. The zero-shot claims (Table 3) are limited to the ETT family. Was true cross-domain generalization (e.g., training on ETT, testing on Weather) evaluated? If not, can the authors provide further justification for why the learned codebook prototypes are \"generalized\" and not just specific to the ETT domain?\n3. Regarding Figure 3, can the authors provide any semantic analysis of the learned codebook vectors (e.g., $c_2, c_5, c_{13}$)? What do these learned \"relation types\" actually *mean*? Without this, the claim is adaptability, not interpretability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "1. High empirical computational cost (memory and time) for what appears to be a marginal performance gain.\n2. Limited zero-shot evaluation, confined only to sub-datasets of the ETT family.\n3. Overstated interpretability claims; the analysis (Figure 3) demonstrates adaptability, not semantic interpretation."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RsLTBbJ6u8", "forum": "sZGAPq2W2t", "replyto": "sZGAPq2W2t", "signatures": ["ICLR.cc/2026/Conference/Submission8872/Reviewer_sGA5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8872/Reviewer_sGA5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8872/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761582348671, "cdate": 1761582348671, "tmdate": 1762920634569, "mdate": 1762920634569, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces TS-TPR, a framework for multivariate time series forecasting that leverages tensor product representations (TPRs) to explicitly disentangle relational structures from temporal features. Specifically, the role is generated from the relational attention map and the filler is constructed from a combination of relational and temporal features. The role and filler are bind and unbind to make the final prediction. Experiments on real-world datasets demonstrate that TS-TPR outperforms state-of-the-art models in both accuracy and interpretability."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The proposed framework introduces a model to separately extract inter-variable dependencies and temporal patterns, enhancing the interpretability."}, "weaknesses": {"value": "1. **Unclear motivation for introducing the Tensor Product Representation (TPR) framework.**\n   The rationale for adopting the TPR framework is confusing. In prior works cited by the authors, TPR is typically used to decompose fillers and their corresponding roles from mixture representations. However, in this paper, both roles and fillers are *predefined*. It remains unclear why the model first binds them to form mixture representations and then unbinds them to recover the fillers.\n\n2. **Limited connection between the proposed method and the TPR framework.**\n   The resulting approach does not appear to be genuinely TPR-based; instead, it merely combines relational and temporal features through several attention layers. For example, in standard TPR theory, the unbinding vector corresponds directly to the role, whereas in the proposed model, these two vectors are derived from two sources.\n\n3. **Inappropriate experimental setup.**\n   Most main experiments are conducted with a lookback window of (T = 96), which is insufficient, as some baseline models require longer lookback windows to achieve their optimal performance. The evaluation should include at least (T = 336) to ensure fairness and comprehensiveness.\n\n4. **Incorrect complexity analysis.**\n   The complexity calculation is inaccurate. Equation (3) has a complexity of $O(CL^2)$, and Equation (6) has $O(C^2L)$; therefore, the overall complexity should be at least $O(CL^2 + C^2L)$. The authors are encouraged to verify this through empirical runtime comparisons on synthetic datasets with *varying numbers of channels and input lengths*.\n\n5. **Insufficient ablation studies.**\n   More ablations are needed to validate the design choices, including:\n   (1) directly using $e^{attr}$ followed by a projection head for forecasting;\n   (2) testing alternative ways to combine $e^{attr}$ and $e^{rel}$."}, "questions": {"value": "1. What exactly does the term \"context\" refer to in the phrase \"Context-aware Role Generation\"?\n2. How does the proposed model achieve dynamic relation modeling as claimed? Based on my understanding, the relations are fixed within each input window. If the claim simply means that different inputs lead to different relation patterns, this property is not unique—many existing models can achieve the same behavior."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pKQjhM85fG", "forum": "sZGAPq2W2t", "replyto": "sZGAPq2W2t", "signatures": ["ICLR.cc/2026/Conference/Submission8872/Reviewer_2Vwu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8872/Reviewer_2Vwu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8872/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761795044777, "cdate": 1761795044777, "tmdate": 1762920633998, "mdate": 1762920633998, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TS-TPR, a multivariate time-series forecasting approach that leverages Tensor Product Representations. The core idea is to model inter-variable relations as roles and temporal attributes as fillers. The authors design a two-stage filler computation process:  \n1. Relation-aware fillers: Uses attention to query source variables with relation embeddings.  \n2. Role-aware aggregation: Employs attention to query relation instances using target-specific role embeddings, generating role-aligned fillers for each target variable.  \n\nThe forecasting mechanism relies on binding/unbinding operations implemented through linear attention, featuring a context-aware unbinding operator that considers the target's temporal context. The Role Selector utilizes a VQ codebook of relation prototypes to identify the top-M roles for each target variable. The authors demonstrate through ablation studies that both the Role Selector and the two-stage filler extraction are essential components."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Achieves state-of-the-art or near-state-of-the-art results on multiple benchmarks, with consistent gains across long-term, short-term, and zero-shot settings.  \n2. Decoupling relations (roles) from temporal attributes (fillers) and recombining them via a TPR-style binding/unbinding mechanism provides a principled way to model time-varying dependencies and explain which roles matter.  \n3. The hierarchical pipeline makes alignment between concrete relations and abstract roles explicit; ablation studies show consistent gains for the full combination.  \n4. Evaluation spans ETT, ECL, Weather, Traffic, and EPF datasets, including model complexity, training-time, and memory comparisons, strengthening the practical engineering case."}, "weaknesses": {"value": "1. Equation 5 computes \\(R_i\\) based on overall distances \\(D_{i,k}\\) without time resolution. It is unclear whether roles adapt per timestep, per window, or remain static per series. Missing time-resolved role trajectories and stability metrics.  \n2. Claims of natural scaling to many variables are only demonstrated up to \\(C=862\\). \n3. Most zero-shot transfers remain within the ETT-family; heterogeneous transfers would provide a stronger test of compositional generalization.\n4. All benchmark datasets use data collected between 2011-2020 (too old)."}, "questions": {"value": "1. Are roles selected per window or per timestep, and can time-resolved role assignment trajectories be shown?  \n2. Can you provide training/inference curves versus \\(C\\) and evaluate sparse relation approximations?  \n3. How does hard VQ-based role selection compare to soft attention over the codebook or temperature-annealed VQ?  \n4. Can heterogeneous cross-domain transfers be added with leakage-safe normalization?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "jz8K0C9nVr", "forum": "sZGAPq2W2t", "replyto": "sZGAPq2W2t", "signatures": ["ICLR.cc/2026/Conference/Submission8872/Reviewer_t4MD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8872/Reviewer_t4MD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8872/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904936725, "cdate": 1761904936725, "tmdate": 1762920633465, "mdate": 1762920633465, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses nonstationary inter-variable dependencies in multivariate forecasting by advocating a compositional approach that explicitly factorizes relational and temporal structure. It introduces TS-TPR, which uses tensor product representations: a context-aware role generator selects salient inter-series relationships at each time step, while a hierarchical filler extractor summarizes the corresponding temporal patterns; their tensor products yield explicit, structured, and scalable representations that adapt as dependencies shift. The authors claim state-of-the-art results across diverse benchmarks and highlight interpretability—via time-varying role/filler components—as a key advantage over methods that entangle relation and dynamics."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The target problem - multivariate time series forecasting is important, and it is interesting to see the proposed solution coming from the view of tensor product representation.  \n2. It's good to see that some empirical results on efficiency are provided. At the first glance, I have some doubts on how this method would affect the efficiency for both training and inference. Based on their results, I am convinced that the overhead is not significant.  \n3. The experiments include the zero-shot setting. I appreciate the results on the zero-shot setting as I believe that it can demonstrate the generalizability of the proposed method."}, "weaknesses": {"value": "1. I think it might be better to include some experiments on synthetic datasets to directly support the claim \"the framework not only adapts to new relational contexts but also provides interpretability by revealing which relationships guide each prediction\". It would greatly improve the credibility. \n2. The authors do not provide some experiments on how to balance the prediction accuracy and cookbook regularization. In Sec. 3.5, some values for $\\alpha$ and $\\beta$ are provided. However, I think it would be better to have some empirical results on the effect of different values. \n3. The datasets used in the experiments, especially for zero-shot setting. There are several more comprehensive benchmarks proposed since 2025, e.g., fev-benchmark [1] and Gift-Eval [2]. I would suggest to have some results on those benchmarks and investigate how it compare with other baselines. \n\nReferences:\n\n[1] fev-bench: A Realistic Benchmark for Time Series Forecasting\n\n[2] GIFT-Eval: A Benchmark For General Time Series Forecasting Model Evaluation"}, "questions": {"value": "1. Some typos in the manuscript. Please revise it. For example, \". urthermore,\" in Page 5. \n2. I wonder if the authors can provide some case studies on Weather dataset to show that how the proposed method can resolve the distribution shift issue. As in Figure 1, the authors show that the relationship between two vars can vary across time. I believe that might be better to show some results directly on this."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HdR01aoE2c", "forum": "sZGAPq2W2t", "replyto": "sZGAPq2W2t", "signatures": ["ICLR.cc/2026/Conference/Submission8872/Reviewer_UUF1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8872/Reviewer_UUF1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8872/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984126639, "cdate": 1761984126639, "tmdate": 1762920632918, "mdate": 1762920632918, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}