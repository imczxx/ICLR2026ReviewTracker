{"id": "EDPvNhTOLK", "number": 6295, "cdate": 1757965226307, "mdate": 1763704218114, "content": {"title": "Directional Influence Function: Estimating Training Data Influence in Constrained Learning", "abstract": "Constrained learning has been increasingly applied to various domains to ensure explicit feasibility requirements due to fairness, safety, robustness, regularization, and physics or logic constraints. Understanding how training samples influence the solution (e.g., learned parameters) of constrained learning is crucial for interpretability and robustness. The classical influence function (IF) may becomes unreliable in constrained settings: data perturbations can reshape both the objective and the feasible region, leading to estimates that violate feasibility. In response, we propose the Directional Influence Function (DIF), a new estimator that explicitly incorporates the constraints into influence estimation. DIF formulates the optimality conditions of constrained learning as a variational inequality (VI) and analyzes how perturbing training data affects this VI. We validate DIF in constrained linear regression and demonstrate that it recovers leave-one-out retraining results, whereas IF and penalty-based IF exhibit significant bias. We further apply DIF to fairness-constrained CNNs, where DIF accurately predicts test loss changes under data removal and aligns closely with actual retraining. Our results establish DIF as an efficient and reliable tool for data attribution in constrained learning.", "tldr": "directional influence function", "keywords": ["Directional Influence Function", "Constrained Learning", "Deep Learning", "Sensitivity analysis", "Variational inequality"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a72defdd210384a3a5da2a924b64f13cbe54cc4d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper extends the Influence Function (IF) framework to the setting of constrained learning. The authors first demonstrate, through a toy example, that the classical IF can fail under such constraints. To address this limitation, they formulate the problem using variational inequality (VI) theory to analyze how perturbations in the training data affect the solution, and subsequently derive the proposed Directional Influence Function (DIF) by solving a quadratic programming (QP) problem. The proposed method is evaluated on constrained linear regression and the MNIST dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper investigates Influence Functions under the setting of constrained learning, which introduces a novel and interesting aspect to the study of IF. \n2. The motivation of this work is strong, and the toy example effectively illustrates the limitations of existing Influence Functions under the constrained learning setting. \n3. This work introduces variational inequality (VI) to formulate constrained learning and analyzes how perturbations in the training data affect this VI, thereby providing a novel analytical perspective on Influence Functions."}, "weaknesses": {"value": "1. The experimental evaluation is rather limited. Specifically, the authors only conduct experiments on constrained linear regression and the MNIST dataset using a simple neural network with several convolutional layers. To more convincingly demonstrate the effectiveness of the proposed method, additional experiments on downstream tasks, such as noisy label identification and sample selection, are necessary."}, "questions": {"value": "1. Regarding the experiment on the constrained CNN, could the authors provide the results obtained by the classical IF for a clearer comparison between the proposed DIF and IF? \n2. Since the current applications of IF are primarily in deep neural networks with large-scale parameters, how computationally expensive is the proposed QP problem (Equation 18)? Could the authors provide some discussion on how this QP problem can be efficiently solved in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iM7hQoYqBX", "forum": "EDPvNhTOLK", "replyto": "EDPvNhTOLK", "signatures": ["ICLR.cc/2026/Conference/Submission6295/Reviewer_wcqU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6295/Reviewer_wcqU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760857168153, "cdate": 1760857168153, "tmdate": 1762918598984, "mdate": 1762918598984, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces the Directional Influence Function (DIF), a generalization of the classical influence function for constrained learning problems. The authors argue that standard influence functions fail in this setting because (i) they ignore feasibility preservation and (ii) the derivative of the optimal solution with respect to data perturbations becomes ill-defined near solutions with active inequality constraints. DIF resolves these issues and can be computed by solving a quadratic program for each datapoint. It reduces to the classical influence function when no constraints are active and satisfies first-order correctness, accurately predicting the effect of small data perturbations. Experiments on norm-constrained linear regression and fairness-constrained CNNs show that DIF closely matches the true influence observed through leave-one-out retraining."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "**Originality**. IF-style analysis for constrained learning is novel in ML (though precedents exist in statistics). The novel variational-inequality treatment handles non-smoothness from active constraints and yields a practical recipe: a single QP per point that, in principle, implicitly handles active-set selection after perturbation.\n\n**Quality**. The theoretical results seem sound. The empirical evidence is positive: DIF nearly matches leave-one-out on constrained linear regression and shows strong correlation on the fairness-constrained CNN.\n\n**Clarity**. The paper is decently easy to follow, and the toy constrained-regression example (Fig. 1) effectively illustrates why classical IF can fail.\n\n**Significance**. The work addresses a timely need for interpretability in constrained learning—a field of growing importance for ensuring fairness, safety, and robustness in ML systems—and provides a practical method for computing directional influence functions."}, "weaknesses": {"value": "Additional work is needed to clearly establish the paper’s limitations, substantiate its novelty, and ensure the overall scientific rigor of the submission. I am willing to increase my score if the following points are addressed.\n### Major complaints\n\n1. **Implicit Active-set Stability Assumption**. The paper argues that classical IF fails in constrained learning because removing a data point can change the active constraint set and cause non-differentiable jumps in the solution. However, the DIF derivation still fixes the current active set (binding / non-binding / inactive), applies different linearized rules to each group, and assumes that this partition continues to govern the local response under perturbation. This amounts to an implicit active-set stability assumption. The paper should state this explicitly and clarify when it may fail (e.g., when an inactive constraint is about to become active), rather than presenting the guarantees as generally applicable.\n\n\n2. **Computational cost**. The paper should analyze and compare the computational costs of IF and DIF, and report these measurements in the experimental section.\n\n\n3. **Baselines on CNNs**. The authors should include baselines such as the classical IF and penalty-IF on their CNN task experiments. As it stands, DIF’s performance looks reasonable, but without these baselines it’s impossible to quantify DIF’s relative improvement over IF/penalty-IF.\n\n\n4. **Penalty-IF tuning**. While penalty-IF is not a principled approach to constrained influence functions, the authors should ensure that its experimental setup is rigorous. The choice of the penalty coefficient for penalty-IF in Figure 3 is not reported, nor is the procedure for selecting it. This omission raises the risk that penalty-IF was under-tuned, potentially overstating DIF’s practical improvement.\n\n5. **Related Works**. The paper fails to acknowledge any prior research on influence functions for constrained estimators. However, some works along these lines exist [1, 2]. While the paper’s treatment via a Variational Inequality formulation is novel, these works should be discussed to contextualize the contribution. Moreover, the related works section (currently in Appendix A) should be moved to the main body to properly situate the paper within this existing literature and clarify what is genuinely new.\n    - [1] Abhik Ghosh. Influence function analysis of the restricted minimum divergence estimators: A general form. Electronic Journal of Statistics, 2015.\n    - [2] Klaus L.P. Vasconcellos, L.M. Zea Fernandez. Influence analysis with homogeneous linear restrictions. Computational Statistics & Data Analysis, 2009.\n\n6. **Scope of the theoretical guarantees in deep learning**. Important results depend on LICQ, SOSC and the stability of the active-set at the KKT point (see point 1). These regularity conditions are not automatically satisfied in deep networks, which often exhibit flat directions and active constraints right at activation boundaries. The paper should explicitly acknowledge this limitation and clarify that the theorems may not strictly apply to generic deep-learning models. \n\n### Minor complaints\n7. **Handling of Equality Constraints**. The paper briefly notes that equality constraints can be converted into inequalities (e.g., ($h(x)=0$) becomes ($h(x) \\le 0$) and ($-h(x) \\le 0$)). While this is correct, it doubles the number of constraints and can complicate regularity assumptions such as LICQ, which are crucial for several of the paper’s theoretical results. A more direct treatment of equality constraints within the VI framework would have been cleaner.\n\n8. **Clarity and Structure**. A few suggestions could enhance readability. The core theory in Section 4.2—particularly the “Auxiliary VI” (Eq. 15) and its proof—relies on concepts such as the “Critical Cone” (Definition 15), which are defined only in Appendix B. These definitions should be moved into the main text for clarity. In addition, the paper transitions abruptly from defining DIF as a directional derivative (Section 3) to deriving it via Variational Inequalities (Section 4) without explaining the conceptual connection or motivating why the VI framework is appropriate. Finally, Section 3 is unnecessarily long for its content, dedicating a full page to two simple definitions and a corollary; it should be condensed.\n\n9. **Presentation and Notation**. The paper would benefit from some additional polish. For instance:\n    - In Section 2.1, the text refers to an “$\\ell_1$-boundary,” while the problem itself is defined with an $\\ell_2$ norm.\n\n\n   - Equation (76) uses $\\Delta \\lambda$ (missing hat) and Equation (85) uses ($\\hat{\\lambda}$) (missing $\\Delta$).\n\n\n    - Theorem 10 uses ($w^{\\*}$) instead of the ($\\omega^{\\*}$) notation used in the QP.\n\n\n    - The proof of Proposition 12 incorrectly cites “Proposition 10” instead of Theorem 10."}, "questions": {"value": "1. Why were the standard IF and penalty-IF baselines not included in the CNN experiment? Without them, it is difficult to assess DIF’s relative improvement.\n\n\n2. In the CNN experiment, was the QP used to compute the DIF solved exactly? Given that the Hessian term is fairly high-dimensional, did you use any approximation to reduce computational cost? Which solver did you use?\n\n\n3. What were the values of the penalty coefficients used for the penalty-IF baseline in Figure 3, and how were they chosen (e.g., grid search, manually)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rVtoIC1Uyf", "forum": "EDPvNhTOLK", "replyto": "EDPvNhTOLK", "signatures": ["ICLR.cc/2026/Conference/Submission6295/Reviewer_4m1P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6295/Reviewer_4m1P"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761522164668, "cdate": 1761522164668, "tmdate": 1762918598629, "mdate": 1762918598629, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response to Reviewers"}, "comment": {"value": "We thank the reviewers for their constructive feedback. We are encouraged that all reviewers found the proposed DIF framework a meaningful advance for influence estimation under constraints. We have carefully revised the manuscript to address the raised concerns. Below, we summarize the major updates incorporated in the revised submission:\n\n\n·       Added comparisons of DIF, TracIn, and TRAK on counterfactual retraining (Section 5.2).\n\n·       Added the performance of IF and penalty-IF in constrained CNNs (Section 5.2).\n\n·       Applied DIF to machine unlearning for Physics-Informed Neural Networks (PINNs), further expanding the empirical scope (Appendix G).\n\n·       Added a detailed analysis of the computational complexity of DIF (Appendix F).\n\n·       Clarified the penalty-IF setup and provided the tuning procedure (Appendix D).\n\nAll changes have been added to the manuscript and are highlighted in blue."}}, "id": "GxdUhYxvff", "forum": "EDPvNhTOLK", "replyto": "EDPvNhTOLK", "signatures": ["ICLR.cc/2026/Conference/Submission6295/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6295/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6295/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763678486357, "cdate": 1763678486357, "tmdate": 1763678486357, "mdate": 1763678486357, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the DIF, which is a new framework for estimating how individual training samples influence model parameters in constrained learning settings, where constraints arise from fairness, safety, robustness, etc.. It shows that the classical influence function becomes unreliable because data perturbations can lead to infeasible or biased estimates. Authors formulate constrained learning as a variational inequality and derive DIF through directional sensitivity analysis, ensuring that estimated parameter updates remain within the feasible region. Experiments on constrained linear regression and fairness constrained CNNs demonstrate that DIF closely matches LOO results, outperforming both IF and penalty based IF estimators in accuracy and feasibility."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces the DIF, a principled and general framework for analyzing sample influence in constrained learning, which has not been adequately handled by classical influence functions. DIF explicitly accounts for active constraints through VI framework, ensuring that estimated parameter perturbations remain feasible, which a significant advancement over prior IF methods that often produce infeasible updates. I think it is a novel theoretical contribution. Authors also provides a clear theoretical foundation, making the approach both interpretable and well grounded.\n2. DIF offers a unified framework that can extend to many practical settings i.e., fairness, safety and robust learning. The paper also points to promising applications such as data poisoning detection, unlearning, and online constraint adaptation, indicating strong future relevance."}, "weaknesses": {"value": "1. Although DIF reduces to solving a quadratic program, solving a QP for each influence data can still be computationally expensive compared to classical IF approximations, particularly for deep networks with large amount of parameters.\n2. The baselines are primarily classical IF and penalty-based IF; some recent scalable or robust IF variants (e.g., TracIn, Hessian-free methods) are not included, limiting the completeness of the empirical comparison."}, "questions": {"value": "How does DIF scale when applied to large deep neural networks with large number of parameters and complex constraint structures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Byp5ZBi8ww", "forum": "EDPvNhTOLK", "replyto": "EDPvNhTOLK", "signatures": ["ICLR.cc/2026/Conference/Submission6295/Reviewer_DRab"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6295/Reviewer_DRab"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761801323390, "cdate": 1761801323390, "tmdate": 1762918597842, "mdate": 1762918597842, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Directional Influence Function (DIF), a novel method for estimating the influence of training data in constrained learning settings. DIF addresses the limitations of classical Influence Functions (IF), which fail to account for constraints and feasibility requirements in constrained learning problems. By reformulating the optimality conditions as a Variational Inequality (VI) and leveraging sensitivity analysis, DIF provides a feasibility-preserving and efficient approach to estimate the impact of data perturbations. The authors validate DIF on constrained linear regression and fairness-constrained CNNs, demonstrating its accuracy and reliability compared to classical IF and penalty-based IF methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper introduces DIF, a significant advancement over classical IF, specifically tailored for constrained learning problems. This is a valuable contribution to the field of machine learning interpretability and robustness. \n\n- DIF is validated on two distinct tasks—constrained linear regression and fairness-constrained CNNs. The results show that DIF closely aligns with ground-truth retraining, outperforming classical IF and penalty-based IF in terms of accuracy and feasibility.  However, I have some comments on the models in the Weaknesses.\n\n-  The paper demonstrates that DIF can be efficiently computed using Quadratic Programming (QP), making it practical for real-world applications."}, "weaknesses": {"value": "- While the paper validates DIF on constrained linear regression and fairness-constrained CNNs, the experimental scope could be expanded to include other constrained learning scenarios, such as reinforcement learning with constraints. \n\n- The paper primarily compares DIF with classical IF and penalty-based IF. It would be beneficial to include comparisons with other state-of-the-art methods for constrained learning or data attribution (e.g., TRAK).\n\n- While the theoretical and empirical results are strong, the paper could provide more discussion on the practical implications of DIF, such as computational scalability for large-scale deep learning models.\n\n- The paper briefly mentions the challenges of non-convex optimization in CNNs but does not delve deeply into how DIF handles non-convexity. A more detailed analysis would strengthen the paper."}, "questions": {"value": "This paper makes a strong contribution to the field of constrained learning by introducing DIF, a theoretically sound and empirically validated method for data attribution. The work is rigorous and addresses a critical gap in existing influence estimation methods. However, the experimental scope and practical implications are weak at this point, therefore I am leaning towards a weak reject."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7xMwBiqiFP", "forum": "EDPvNhTOLK", "replyto": "EDPvNhTOLK", "signatures": ["ICLR.cc/2026/Conference/Submission6295/Reviewer_GE37"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6295/Reviewer_GE37"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6295/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762274197964, "cdate": 1762274197964, "tmdate": 1762918597459, "mdate": 1762918597459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}