{"id": "qDg8KNq0Fm", "number": 534, "cdate": 1756744811199, "mdate": 1763100897395, "content": {"title": "MFSR: MeanFlow Distillation for One Step Real-World Image Super Resolution", "abstract": "Diffusion- and flow-based models have advanced real-world image super-resolution (Real-ISR), but their multi-step sampling makes inference slow and hard to deploy. One-step distillation alleviates the cost, yet often degrades restoration quality and removes the option to refine with more steps. We present Mean Flows for Super-Resolution (MFSR), a new distillation framework that produces photorealistic, high-fidelity results in a single step while still allowing an optional multi-step path for further improvement. Our approach uses MeanFlow as the learning target, enabling the student to approximate the mean velocity between arbitrary states of the Probability Flow ODE (PF-ODE) and effectively capture the teacher’s dynamics without explicit rollouts. To better leverage pretrained generative priors, we additionally improve original MeanFlow Classifier-Free Guidance (CFG) formulation with teacher CFG distillation strategy, which enhances restoration capability and preserves fine details. Experiments on both synthetic and real-world benchmarks demonstrate that MFSR achieves efficient, flexible, and high-quality super-resolution, delivering results on par with or better than multi-step teachers while requiring much lower computational cost.", "tldr": "We use MeanFlow Distillation to achieve one step real-world image super-resolution.", "keywords": ["Diffusion models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/5ede7a6e01b877b0857d91a59726cb1cd4f9aabd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents MFSR, which brings MeanFlow to real image super resolution. It can restore images in one step or in a few steps. The key idea is a new CFG-based MeanFlow distillation method. It uses a strong teacher model DiT4SR to guide training, giving better supervision than the original MeanFlow CFG approach."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "(i) The authors reformulate classifier-free guidance for MeanFlow [4] to a distillation regime by leveraging a pretrained teacher during training. This CFG-based MeanFlow distillation yields stronger supervision than the original MeanFlow CFG, improving one and few step restoration quality.\n\n(ii) The approach is scaled to a DiT architecture [1,2,3], using a pretrained DiT4SR [3] both as the teacher and for student initialization. This scaling to relatively big models is nontrivial and demonstrates the method’s ability to work well with larger models, where it was not clear if the method would work.\n\n(iii) Extensive empirical evaluations demonstrate that MFSR achieves competitive performance compared to existing single step super resolution approaches.\n\n[1] https://arxiv.org/abs/2403.03206 Scaling Rectified Flow Transformers for High-Resolution Image Synthesis\n\n[2] https://arxiv.org/abs/2212.09748 Scalable Diffusion Models with Transformers\n\n[3] https://arxiv.org/abs/2503.23580 DiT4SR: Taming Diffusion Transformer for Real-World Image Super-Resolution\n\n[4] https://arxiv.org/abs/2505.13447 Mean Flows for One-step Generative Modeling"}, "weaknesses": {"value": "(i) Using MeanFlow with distillation and CFG seems like a natural next step. While useful, this idea is not very new or surprising. The paper feels more like an engineering improvement than a theoretical one.\n\n(ii) The authors say metrics don’t reflect real-world SR well and use a user study to support this. However, the human evaluation compares only a few methods, so the results are not very strong. A larger study with more methods would help. Since the paper focuses on practical SR, it should compare with other strong non-diffusion models like SwinIR [5], Real-ESRGAN [6], and others [7,8,9].\n\n(iii) It’s not clear if the good results come from the method or just from using a large DiT model. The paper should compare with other distillation methods using the same setup and also show compute cost and ablations.\n\n[5] https://arxiv.org/abs/2108.10257 SwinIR: Image Restoration Using Swin Transformer \n\n[6] https://arxiv.org/abs/2107.10833 Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data \n\n[7] https://arxiv.org/abs/2503.13358 One-Step Residual Shifting Diffusion for Image Super-Resolution via Distillation \n\n[8] https://arxiv.org/abs/2411.13383 Adversarial Diffusion Compression for Real-World Image Super-Resolution \n\n[9] https://arxiv.org/abs/2103.14006 Designing a Practical Degradation Model for Deep Blind Image Super-Resolution"}, "questions": {"value": "(i) I couldn’t understand what the authors wanted to show in Appendix C. It’s not clearly mentioned in the main text. Could the authors explain its purpose and whether it supports any main claim?\n\n(ii) Why do the authors use a text extractor on the HR image during training, but on the LR image during inference? Does this difference create any bias or mismatch between training and testing?\n\n(iii) Since the student never sees the real HR image during distillation, how can it perform better than the teacher on non-reference metrics (as in Table 5)? Can the authors give some explanation or intuition for this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0wLkFY15pN", "forum": "qDg8KNq0Fm", "replyto": "qDg8KNq0Fm", "signatures": ["ICLR.cc/2026/Conference/Submission534/Reviewer_6iut"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission534/Reviewer_6iut"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760651946265, "cdate": 1760651946265, "tmdate": 1762915541691, "mdate": 1762915541691, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "UHiZbDwOzc", "forum": "qDg8KNq0Fm", "replyto": "qDg8KNq0Fm", "signatures": ["ICLR.cc/2026/Conference/Submission534/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission534/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763100896462, "cdate": 1763100896462, "tmdate": 1763100896462, "mdate": 1763100896462, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose MFSR, a one-/few-step real-world super-resolution method. It builds directly on the recently introduced Mean Flow framework, using it to distill the multi-step DiT4SR super-resolution teacher into an efficient student model. Rather than estimating the instantaneous velocity with a one-sample estimator, the student is supervised using the instantaneous velocity predicted by the teacher. Moreover, the authors enhance this supervision by applying classifier-free guidance - including strong guided and negative-prompt variants - directly to the teacher’s velocity during distillation, further improving the perceptual quality of the distilled student."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors propose a new view on Mean Flow, not as a training from scratch approach, but as a distillation approach using the instantaneous velocity predicted by the teacher instead of a one-sample estimator.\n\n2. Good quality of the resulting model."}, "weaknesses": {"value": "1. **Limited novelty and lack of SR-specific contribution.**\nWhile the method differs from the previously proposed Mean Flow approach by using instantaneous velocity provided by the teacher model, it introduces no super-resolution-specific modeling or insight. As a result, it does not meaningfully address the distinct challenges of the SR domain, and the contribution reads more as an engineering transfer rather than SR-oriented innovation.\n\n2. **Insufficient analysis and insight.**\nThe paper does not analyze why previously proposed one-step/inference-efficient SR methods fail or in which specific aspects the proposed approach succeeds. There is no principled discussion of what challenge is being solved, or what underlying mechanism makes MFSR superior in certain cases. The work remains largely observational (leaderboard-style) rather than explanatory or diagnostic.\n\n3. **Unfair and under-discussed comparison setup.**\nMany of the baseline SR methods being compared against are themselves distilled from different teacher models under different training conditions. This heterogeneity is not acknowledged or controlled for. Moreover, the authors train their own student using yet another teacher (DiT4SR) that is not aligned with the baselines. As a result, the experimental comparisons lack a fair common-teacher reference, making it unclear whether improvements stem from the proposed method or simply from a stronger teacher."}, "questions": {"value": "1. **Choice of teacher model.**\nWhy did the authors specifically choose DiT4SR as the teacher for distillation? \n\n2. **Prompt inconsistency between training and inference.**\nDuring training, prompts are extracted from the high-resolution (HR) image, whereas during inference, they are extracted from the low-resolution (LR) input. What is the rationale behind introducing this train–test mismatch? Wouldn't it be better to use the LR input on the train?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CI9W2wg6Qw", "forum": "qDg8KNq0Fm", "replyto": "qDg8KNq0Fm", "signatures": ["ICLR.cc/2026/Conference/Submission534/Reviewer_d2tE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission534/Reviewer_d2tE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761590413092, "cdate": 1761590413092, "tmdate": 1762915541456, "mdate": 1762915541456, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces MeanFlows for Super-Resolution (MFSR), a one-step or few-step image super-resolution (ISR) model for Real-World ISR task. MFSR aims to improve the efficiency of flow-based diffusion models by reducing sampling steps. The approach uses a distillation framework to transfer knowledge from a powerful multi-step teacher model (e.g. DiT4SR) into a faster student model, while also introducing improvements to the Classifier-Free Guidance (CFG) formulation. The proposed method shows promise in restoring high-fidelity images with fewer computational steps, outperforming or matching existing methods in both synthetic and real-world image benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed method, MFSR, reduces computational cost while maintaining quality. The use of the MeanFlow distillation strategy enables high-quality one-step restoration and retains flexibility for optional few-step refinement.\n\n2. The idea of leveraging a pre-trained teacher model to guide the student model in distilling knowledge is well-executed. This reduces convergence time and improves the quality of restoration, making the approach more practical for real-world applications.\n\n3. The modification of the Classifier-Free Guidance (CFG) in the distillation process enhances the model’s performance, particularly in preserving fine details and improving perceptual quality."}, "weaknesses": {"value": "1. The main difference between MFSR and MeanFlow lies in the use of teacher CFG to improve instantaneous velocity. Therefore, the technical contribution appears incremental rather than fundamentally novel.\n\n2. The quantitative results reported show limited competitiveness compared with other methods. MFSR fails to achieve state-of-the-art performance on all FR metrics. While I understand that PSNR and SSIM are less meaningful in Real-ISR, LPIPS and DISTS remain important reference indicators. Among the four real-world datasets, MFSR only outperforms others on the NR metric MANIQA. Although MFSR supports two-step sampling, it still falls short of TSDSR on most metrics."}, "questions": {"value": "1. In Section 4.3, the authors claim that the naive choice of instantaneous velocity $z_1 - z_0$ leads to inferior reconstruction results. I guess this is caused by a mismatch between the noise and the data, resulting in an incorrect estimation of the instantaneous velocity. The authors should include additional experiments using the teacher-predicted $z_0$ to compute the instantaneous velocity in order to clarify this point.\n\n2. Could the authors provide a comparison of runtime efficiency and parameter count with other methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4U6QLqY6nl", "forum": "qDg8KNq0Fm", "replyto": "qDg8KNq0Fm", "signatures": ["ICLR.cc/2026/Conference/Submission534/Reviewer_eT5Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission534/Reviewer_eT5Y"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892194915, "cdate": 1761892194915, "tmdate": 1762915541131, "mdate": 1762915541131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MFSR, a distillation framework that adapts MeanFlow to real-world image super-resolution by distilling a multi-step DiT4SR teacher into a one-step student model while maintaining the flexibility for few-step sampling. The key contribution is an improved CFG-based distillation strategy that uses the teacher's CFG-enhanced prediction as instantaneous velocity. While the paper addresses the relevant problem of reducing inference cost in Real-ISR, significant concerns remain regarding experimental validation and methodological justification. Most critically, MFSR consistently underperforms baseline methods across multiple fidelity metrics (PSNR, SSIM, LPIPS, DISTS), and the paper does not adequately address this degradation or provide sufficient evidence for the claimed superiority of the proposed approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tWell-motivated problem: The paper addresses a practical challenge in real-world super-resolution - reducing inference cost while maintaining quality. The motivation for adapting MeanFlow to SR distillation is clear and reasonable.\n2.\tFlexible inference scheme: Unlike existing one-step SR methods, MFSR preserves the ability to perform few-step sampling, providing a controllable trade-off between speed and quality. This is a valuable feature for practical deployment.\n3.\tSimplified training pipeline: The method uses only the MeanFlow distillation loss computed in latent space without backpropagating through encoder/decoder, which improves training efficiency compared to methods like OSEDiff and TSDSR."}, "weaknesses": {"value": "1.\tInconsistent and concerning quantitative results: \n(1) MFSR shows significantly lower PSNR/SSIM across all benchmarks (e.g., 21.25 vs 24.50 PSNR on DIV2K-Val for SinSR). While the authors mention perception-distortion tradeoff, the gap is substantial.\n(2) The paper dismisses these metrics as \"misaligned with human perception\" but still reports them extensively, creating confusion about which metrics to trust.\n(3) On some metrics (LPIPS, DISTS), MFSR performs worse than several baselines, contradicting the claim of superior perceptual quality.\n2.\tWhy does MFSR have such low PSNR/SSIM compared to baselines? At what point does the perception-distortion tradeoff become concerning for practical applications?\n3.\tQuestionable user study design: The instruction to select results that \"best balance realism and fidelity\" is subjective and may introduce bias toward methods favoring perceptual quality at the expense of fidelity. This potentially skews the evaluation in favor of MFSR's characteristics rather than providing an objective assessment of quality.\n4.\tMissing details about prompt extraction method, negative prompt selection, and time step sampling distribution.\n5.\tThe statement \"delivers results on par with or even better than multi-step teachers\" is not well-supported by the quantitative results shown.\n6.\tThe paper does not demonstrate why MeanFlow-based distillation is superior to directly distilling the teacher into a one-step or few-step instantaneous velocity model (standard Rectified Flow). What if the same teacher model (DiT4SR) were distilled using trajectory-based methods that predict instantaneous velocity rather than average velocity? This comparison is essential to validate the claimed advantage of MeanFlow.\n7.\tThe paper should compare with more similar recent flow-based one-step SR methods. For example, \"FlowSR: One Diffusion Step to Real-World Super-Resolution via Flow Trajectory Distillation\" also distills multi-step flow matching models and represents a highly relevant baseline."}, "questions": {"value": "Please see the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HWZwyFoGkT", "forum": "qDg8KNq0Fm", "replyto": "qDg8KNq0Fm", "signatures": ["ICLR.cc/2026/Conference/Submission534/Reviewer_LiJf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission534/Reviewer_LiJf"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762152058642, "cdate": 1762152058642, "tmdate": 1762915541008, "mdate": 1762915541008, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}