{"id": "KWMR2YfC55", "number": 4281, "cdate": 1757653938580, "mdate": 1763344992848, "content": {"title": "Ban&Pick: Ehancing Performance and Efficiency of MoE-LLMs via Smarter Routing", "abstract": "Sparse Mixture-of-Experts (MoE) has become a key architecture for scaling large language models (LLMs) efficiently. Recent fine‑grained MoE designs introduce hundreds of experts per layer, with multiple experts activated per token, enabling stronger specialization. However, during pre‑training, routers are optimized mainly for stability and robustness: they converge prematurely and enforce balanced usage, limiting the full potential of model performance and efficiency. In this work, we uncover two overlooked issues: (i) a few highly influential experts are underutilized due to premature and balanced routing decisions; and (ii) enforcing a fixed number of active experts per token introduces substantial redundancy. Instead of retraining models or redesigning MoE architectures, we introduce Ban&Pick, a post-training, plug-and-play strategy for smarter MoE routing. Pick discovers and reinforces key experts—a small group with outsized impact on performance—leading to notable accuracy gains across domains. Ban complements this by dynamically pruning redundant experts based on layer and token sensitivity, delivering faster inference with minimal accuracy loss. Experiments on fine-grained MoE-LLMs (DeepSeek, Qwen3) across math, code, and general reasoning benchmarks demonstrate that Ban\\&Pick delivers free performance gains and inference acceleration without retraining or architectural changes. For instance, on Qwen3-30B-A3B, it improves accuracy from 80.67 to 84.66 on AIME2024 and from 65.66 to 68.18 on GPQA-Diamond, while accelerating inference by 1.25× under the vLLM.", "tldr": "", "keywords": ["large language models", "mixture-of-experts", "inference"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4b62c9becef33d35bd3f1fa80bd58651109b47d2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Ban&Pick, a post-training, plug-and-play framework that improves both the performance and efficiency of fine-grained Mixture-of-Experts (MoE) large language models. The method introduces two complementary modules: Pick, which identifies and reinforces key experts with major impact on task performance, and Ban, which dynamically prunes redundant experts based on layer and token sensitivity.\n\nWithout retraining or architectural modification, the framework achieves consistent accuracy improvements and inference acceleration across multiple MoE-LLMs (DeepSeek, Qwen3) on math, code, and reasoning benchmarks. The work is technically sound and demonstrates strong engineering novelty and practical value."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Demonstrates a clever engineering insight—leveraging untapped routing inefficiencies to boost performance and efficiency simultaneously.\n\n2. Provides a lightweight, generalizable, and plug-and-play approach applicable to existing fine-grained MoE architectures.\n\n3. The empirical validation is comprehensive, spanning multiple large models and diverse domains.\n\n4. Shows clear, measurable engineering gains (up to +3% accuracy and 1.25× speedup) without any additional training cost.\n\n5. Strong potential for real-world adoption in industrial MoE inference systems (e.g., vLLM, DeepSeek)."}, "weaknesses": {"value": "1. Limited theoretical depth. The paper focuses on empirical effectiveness but does not deeply analyze the underlying mechanism of key expert influence or convergence behavior.\n\n2. Lack of comparison with more recent MoE optimization baselines, such as MoE++, adaptive gating, or mixed routing approaches (e.g., Mixtral, Soft-MoE).\n\n3. Evaluation scope is somewhat narrow, emphasizing accuracy and speedup but lacking broader system-level metrics like throughput, latency variance, or memory usage.\n\n4. Minor stylistic and formatting issues, including small typos and missing pseudocode for algorithmic clarity.\n\n5. Noticeable typographical issue: the paper title itself contains a serious typo (“EHANCING” should be “ENHANCING”), which reflects carelessness in proofreading."}, "questions": {"value": "1. Can the proposed Ban&Pick framework be combined with adaptive routing methods or reinforcement-learning-based expert selection?\n\n2. How sensitive is the method to hyperparameters (λ, Kmin) across different model scales?\n\n3. Could online or task-specific adaptation further enhance the framework’s performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gB1loRmFuM", "forum": "KWMR2YfC55", "replyto": "KWMR2YfC55", "signatures": ["ICLR.cc/2026/Conference/Submission4281/Reviewer_364k"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4281/Reviewer_364k"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4281/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761736690100, "cdate": 1761736690100, "tmdate": 1762917272700, "mdate": 1762917272700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Ban&Pick, which is a post-training, plug-and-play strategy for smarter routing for selecting expert in the modern MoE models. The Pick discovers and reinforces key experts that is a small group with outsized impact on performance, which leading to notable accuracy gains across domains. Ban further dynamically prunes redundant experts based on layer and token sensitivity, delivering faster inference with minimal accuracy loss. The author of the paper performs experiments on fine-grained MoELLMs (DeepSeek, Qwen3) across math, code, and general reasoning benchmarks demonstrate that Ban&Pick delivers free performance gains and inference acceleration without retraining or architectural changes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The findings on domain-specialized experts and the redundant expert activation is critical to the design of the Ban&Pick. The overall design of the method is very straightforward and easy to implement.\n\n2. The analysis of key expert is very thorough. The explanation is easy to understand. Same writing style is appreciated for redundant expert selection. The whole structure is clear and easy to follow.\n\n3. I believe the discovery is novel and inspiring. Although the method seems to be straightforward, the discovery can be utilized in many future research."}, "weaknesses": {"value": "1. It is not clear to me what is the key reason of failing to include of some key expert in specific domain tasks. According to the earlier discussion in the paper, the reason might come from the premature of the routing strategy during pretraining. Some of the related works also proves that. But in this paper, the author does not show the direct connection between this reason (premature) to the issue (expert selecting failure). The experiments in figure 1, 2, 3, is showing the fact that there are key experts and they are important, but the whole paper fails at showing why. The author of the paper should articulate on this and it will make the paper better by a lot.\n\n2. In order to enhancing the key experts, the author of the paper proposes 5 strategy and the author of the paper uses strategy D. But the reader would be more convincing of why the author of the paper choose such design. \n\n3. Comparing to Pick, the Ban sometimes degrade the accuracy, which is understandable. But combine with Pick, the goal of this paper would become improve the performance of the MoE model. However, the Ban&Pick results in Table 3 shows varying improve. Although the difficulty of the tasks are different, some of the tasks like Math500 has limited improvement. And within the same task like GPQA, different models adapt to the Ban&Pick differently, which shows unstable performance of the method."}, "questions": {"value": "Please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZhDG5KMN1g", "forum": "KWMR2YfC55", "replyto": "KWMR2YfC55", "signatures": ["ICLR.cc/2026/Conference/Submission4281/Reviewer_Rchp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4281/Reviewer_Rchp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4281/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761860569407, "cdate": 1761860569407, "tmdate": 1762917272477, "mdate": 1762917272477, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper claims that the routing strategies learned during pre-training cannot fully exploit this specialization, and thus proposes Pick and Ban strategies to optimizes expert utilization in inference. It improves both the accuracy and efficiency of fine-grained MoE without retraining or architectural changes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed Ban&Pick is a post-training strategy. It does not require expensive retraining of the foundation model.\n- The paper provides a thorough evaluation (Section 6) across multiple modern MoE models (DeepSeek-V2-Lite, DeepSeek-v2.5, Qwen3-30B, Qwen3-235B) and a diverse set of challenging benchmarks (AIME2024, GPQA, LiveCodeBench)"}, "weaknesses": {"value": "- Concern on generalization capability. The \"Pick\" module relies on identifying key experts for specific domains (math, code, general). This introduces a calibration step and raises questions about scalability. It's unclear how this would perform on tasks that are highly interdisciplinary or fall outside the tested domains.\n\n- Hyperparameter Sensitivity. The method introduces new hyperparameters that may require tuning."}, "questions": {"value": "How would the \"Pick\" module function on a task that intrinsically blends domains, such as writing a legal analysis (general reasoning) of a software patent (code)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9FAMMnjbkj", "forum": "KWMR2YfC55", "replyto": "KWMR2YfC55", "signatures": ["ICLR.cc/2026/Conference/Submission4281/Reviewer_2H1d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4281/Reviewer_2H1d"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4281/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928500668, "cdate": 1761928500668, "tmdate": 1762917272223, "mdate": 1762917272223, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}