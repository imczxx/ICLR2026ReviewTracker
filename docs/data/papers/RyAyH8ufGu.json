{"id": "RyAyH8ufGu", "number": 5482, "cdate": 1757914073791, "mdate": 1759897971568, "content": {"title": "Distributionally Robust Classification for Multi-source Unsupervised Domain Adaptation", "abstract": "Unsupervised domain adaptation (UDA) is a statistical learning problem when the distribution of training (source) data is different from that of test (target) data. In this setting, one has access to labeled data only from the source domain and unlabeled data from the target domain. The central objective is to leverage the source data and the unlabeled target data to build models that generalize to the target domain. Despite its potential, existing UDA approaches often struggle in practice, particularly in scenarios where the target domain offers only limited unlabeled data or spurious correlations dominate the source domain. To address these challenges, we propose a novel distributionally robust learning framework that models uncertainty in both the covariate distribution and the conditional label distribution. Our approach is motivated by the multi-source domain adaptation setting but is also directly applicable to the single-source scenario, making it versatile in practice. We develop an efficient learning algorithm that can be seamlessly integrated with existing UDA methods. Extensive experiments under various distribution shift scenarios show that our method consistently outperforms strong baselines, especially when target data are extremely scarce.", "tldr": "", "keywords": ["Unsupervised Domain Adaptation", "Distributionally Robust Learning", "Multi-source Learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ab40a5b236d108c255fa7f722dd6d9ba730dae8a.pdf", "supplementary_material": "/attachment/b7b5818471bd58eee2513db6b27676f17f275f78.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces a novel method for unsupervised domain adaption based on the framework of distributional robust optimization. The key idea is to represent the conditiona distribution $P(Y|X)$ as the mixture of empiricial conditional distribution $\\hat{P}^{(k)}(Y|X)$ from multiple sources and allows the pertubation of target input distribution over move inside a small Wasserstein ball. This method is plug-and-play, can be effectively integrated with existing UDA methods. Experiments on digits (MNIST/SVHN/USPS) and spurious-correlation suites (Waterbirds, CelebA, Colored-MNIST) show consistent gains and strong performance when target data are very limited."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is quite well-written. \n\n2. The proposed  method is quite intuitive and easy to understand, with tractable surrogate and a relatively simple algorithm.\n\n3. The algorithm integrates seamlessly with existing UDA frameworks since its neat design that the input of the algorithm is the feature mapping $z$. \n\n4. The empirical effectivness is validated on real-world datasets with non-trivial improvements."}, "weaknesses": {"value": "Currently, the largest potential issue is the lack of discussion of the grouping strategy. Specifically, it is not clear for a single soruce distribution, how do we know the number of pseudo-sources $K$? The choice of $K$ should directly influence the performance given the main idea that the target conditional distribution is the mixture of empirical conditional distribution. It will be appreicated to provide a more detailed analysis regarding the choice of $K$ (e.g., heuristics, validation criteria, stability checks), plus a short sensitivity or ablation study.\n\nI’m not an expert in UDA, so I’m unsure whether the current baselines reflect the latest methods. A quick check search leads me to two recent papers [1], [2]. Could you comment on their relevance and, if appropriate, explain why they weren’t included (e.g., different setting, data requirements, or incompatibility)? I’m completely open to your explanation.\n\nAnother potential issue the optimization objective is surrogate-based, i.e., we are always apporacing a suboptimal result. In this case, an analysis regarding the tightness of the gap will be appreciated. However, I totally understand if there have not been any since this is not the contribution of the paper. I will not change my assessment of the paper regardless of the absent of such analysis.\n\n[1] Partial Identifiability for Domain Adaptation. \n\n[2] Subspace identification for multi-source domain adaptation."}, "questions": {"value": "Most questions have been proposed in the Weakness section.\n\nA minor question:\n\nDuring the analysis of impact of radius $(\\epsilon_1, \\epsilon_2)$, I do not quite understand the content from lines 1004-1007. The aurthors argue that $\\epsilon_2$ will play a critical role when the target data is quite scarce. However, according to the Figure 5(b), the $\\epsilon_2$ provides nearly no influence for a fixed $\\epsilon_1$. Can the authors elaborate more on their arugments, or am I missing anything?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FKkiOHJLre", "forum": "RyAyH8ufGu", "replyto": "RyAyH8ufGu", "signatures": ["ICLR.cc/2026/Conference/Submission5482/Reviewer_fB8c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5482/Reviewer_fB8c"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5482/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760981422599, "cdate": 1760981422599, "tmdate": 1762918088240, "mdate": 1762918088240, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a distributionally robust optimization (DRO) framework for unsupervised domain adaptation (UDA), particularly under multi-source and target-data-scarce settings. The method defines an ambiguity set over both the covariate (input) distribution and the conditional label distribution, allowing robustness against (i) uncertainty in target inputs and (ii) uncertainty in which source conditional distributions to rely on. The framework is applicable to both multi-source and single-source UDA, using pseudo-sources generated via sub-sampling. A tractable minimax algorithm is derived (Eqs. (3)–(7); Algorithm 1), optimizing over feature perturbations, mixture weights, and classifier parameters. Experiments on digit datasets (MNIST, SVHN, USPS) and spurious-correlation benchmarks (Waterbirds, CelebA, CMNIST) demonstrate consistent performance gains over UDA and robust-learning baselines (Tables 1–2)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper identifies two overlooked issues in UDA: scarce unlabeled target data and spurious source correlations.\n2.\tThis dual modeling is theoretically elegant and practically relevant for multi-source robustness.\n3.\tThe paper is well-written and easy to read."}, "weaknesses": {"value": "1.\tD₁ (Wasserstein-∞) and D₂ (Euclidean) are chosen “for computational tractability” (Sec. 3.3) but without theoretical or empirical justification.\n2.\tHyperparameters ϵ₁, ϵ₂ are selected via a small labeled validation set (Sec. 4.1), partially violating the unsupervised setting.\n3.\tNo ablation compares using only conditional-mixing vs. only covariate-perturbation.\n4.\tThe relationship between pseudo-source construction (Sec. 3.1) and mixture weights β is not fully explained; readers may confuse stochastic sub-sampling with real domain partitioning.\n5.\tAbsence of gradient-stability discussion under joint optimization may raise reproducibility concerns.\n6.\tCompared to DRO literature [a, b], the paper’s theoretical contribution is weak.\n\n[a] Learning models with uniform performance via DRO.\n[b] Distributionally robust stochastic optimization with Wasserstein distance."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oZlSEu6W8H", "forum": "RyAyH8ufGu", "replyto": "RyAyH8ufGu", "signatures": ["ICLR.cc/2026/Conference/Submission5482/Reviewer_Lo6k"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5482/Reviewer_Lo6k"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5482/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761701644011, "cdate": 1761701644011, "tmdate": 1762918087975, "mdate": 1762918087975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel distributionally robust optimization (DRO) framework for multi-source unsupervised domain adaptation (MS-UDA). The method models both input marginal distribution shifts and label conditional distribution shifts by constructing a mixture-based ambiguity set that combines conditional distributions from multiple source domains with adaptive weighting, while allowing controlled perturbations of the target input distribution. The authors further design a minimax optimization algorithm that alternately updates feature perturbations, mixture weights, and classifier parameters. Experimentally, results on several benchmark datasets (MNIST/SVHN/USPS, Waterbirds, CelebA, CMNIST) demonstrate that this approach achieves significantly better classification performance than mainstream UDA methods such as DANN, CDAN, and STAR, particularly in scenarios with scarce target data or spurious correlations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper proposes a unified Distributionally Robust Optimization (DRO) framework that is applicable to both multi-source and single-source Unsupervised Domain Adaptation (UDA), offering flexibility across different scenarios.\n\n2. Unlike traditional approaches that typically model either input uncertainty or label distribution uncertainty in isolation, this method simultaneously accounts for both, providing a more comprehensive solution.\n\n3. The proposed algorithm is highly tractable, ensuring that it can be seamlessly integrated with existing UDA frameworks, making it easy to adopt and implement in real-world applications.\n\n4. The experimental results demonstrate the method's robust performance, especially in tasks where target data is scarce or where spurious correlations are prevalent, outperforming several strong baselines."}, "weaknesses": {"value": "1. A reliance on labeled target data for model selection moves the problem into a \"partially supervised\" or \"few-shot\" adaptation setting. While the main training uses unlabeled target data, the crucial choice of hyperparameters $\\epsilon_1$ and $\\epsilon_2$ is supervised. \n\n2. The appendix shows heatmaps of performance vs. $(\\epsilon_1, \\epsilon_2)$, which is good. However, the main paper should discuss how sensitive the method is. Is there a broad range of \"good\" hyperparameters, or does the performance collapse without precise tuning? This context is crucial.\n\n3. Although multiple standard datasets are used for testing, there is a lack of evaluation in broader domains (such as NLP or time-series data) to demonstrate the generalizability of the method.\n\n4. The conclusion section does not sufficiently discuss the limitations of the method and potential future directions for improvement. Adding these aspects would help present a more comprehensive view of the research depth."}, "questions": {"value": "1. How does the reliance on labeled target data for hyperparameter selection (specifically for $\\epsilon_1$ and $\\epsilon_2$) affect the generalization of the method in unsupervised domain adaptation? Could this be considered as a shift towards a \"partially supervised\" or \"few-shot\" adaptation setting?\n\n2. How sensitive is the proposed method to these hyperparameters?\n\n3. How does the proposed method perform on data from other modalities?\n\n4. How critical is the choice of base classifier (ERM vs. CDAN/STAR) for the final performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "e1oPtV56DA", "forum": "RyAyH8ufGu", "replyto": "RyAyH8ufGu", "signatures": ["ICLR.cc/2026/Conference/Submission5482/Reviewer_Fp6T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5482/Reviewer_Fp6T"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5482/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761707931423, "cdate": 1761707931423, "tmdate": 1762918087712, "mdate": 1762918087712, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper applies Distributionally Robust Optimization (DRO) to solve Unsupervised Domain Adaptation (UDA). It constructs ambiguity samples from the target data whose pseudolabel is the linear combination of the label from multiple source domain classifiers. The ambiguous sample is generated using a technique similar to adversarial training. The proposed method can also be viewed as a regularizer."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel extension of DRO to UDA\n2. Impressive results on target accuracy"}, "weaknesses": {"value": "1. The paper attempts to apply Distributionally Robust Optimization (DRO) to the problem of Unsupervised Domain Adaptation (UDA). The idea of applying DRO to UDA appears to be novel although some of the technical contributions are from pre-existing DRO work. The proposed approach is not technically convincing due to tedious notation and workflow. It was quite difficult and frustrating to follow the logic in explanation in the paper. \n2. Target accuracy is the only result made available. This does not give enough insight into the workings of the model.\n3. What is the intuition behind Eq. 6. Whichever subset (domain) k has the least predictive power (largest loss) it gets the largest \\beta_k. Why is this reasonable? Will this not result in negative transfer? \n4. In Eq. 5, How is Euclidean projection onto set A equivalent to minimizing the Wasserstein distance D1. What do you mean by Euclidean projection? How is the \\epsilon_1 constraint satisfied?"}, "questions": {"value": "In Eq 3. What is variable for the Expectation under \\hat{P}^{tg}_X. Is it z’ or z(X)? Likewise, in the expectation In lines 775-777 what is the difference between z(x) and z(X). How does it change to z’ in lines 781-782. There is inadequate explanation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jvp8VCyP9b", "forum": "RyAyH8ufGu", "replyto": "RyAyH8ufGu", "signatures": ["ICLR.cc/2026/Conference/Submission5482/Reviewer_nZt1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5482/Reviewer_nZt1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5482/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762153994705, "cdate": 1762153994705, "tmdate": 1762918087497, "mdate": 1762918087497, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}