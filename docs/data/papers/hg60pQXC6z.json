{"id": "hg60pQXC6z", "number": 22041, "cdate": 1758325240575, "mdate": 1759896889437, "content": {"title": "Informative Posterior Ensembles for Sequential Simulation-Based Inference", "abstract": "Approximating parameter posteriors in likelihood-free settings is a practical challenge common to many scientific disciplines. While recent advances in both computer simulation and generative modeling have paved the way for tractable inference in high-fidelity environments, they often require prohibitively large sample sizes in practice. Sequential posterior estimation methods attempt to mitigate this by iteratively producing proposal distributions that refine the inverse model, but they lack explicit selection mechanisms for reducing information overlap in proposed simulations. In this work, we introduce a mutual information-based acquisition scheme for identifying informative simulation parameters, operating on disagreement in the parameter space across a weighted posterior ensemble of atomic proposals. Our approach crucially leverages only an inverse model, making it compatible with existing direct posterior estimation procedures. We further extend this approach to the batched setting and formulate a fast approximate algorithm that preserves posterior convergence guarantees. We demonstrate the potential of this method on several common simulation-based inference (SBI) benchmark tasks, and observe performance advantages over non-ensemble counterparts in low-data regimes.", "tldr": "", "keywords": ["simulation-based inference", "generative models", "bayesian ML"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/72a721966fdb337e886a023da36c35126cb41902.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces ESNPE (Ensemble Sequential Neural Posterior Estimation), with the overall goal of improving sample-effiency in sequential simulation-based inference through:\n- Posterior ensembling (and introducing a method that does this coherently)\n- A mutual information-based candidate parameter point acquisition scheme, which grabs parameters that on average reduce model uncertainty\n- A batch acquisition algorithm (jointly select informative batches)"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Overall, rather than a single contribution this paper is a collection of technical extensions that are aimed at improving sample efficiency and information gain during SBI. \n- The ensembling makes sense and is theoretically guaranteed. Overall, compatibility is maintained with a previous approach APT's atomic proposal framework, giving asymptotic correctness\n- Mutual information as a parameter acquisition metric is solid and a nice contribution"}, "weaknesses": {"value": "- The residual MI method seems to assume every candidate parameter \\theta' will yield the observation. \\theta' ~ p(x|\\theta') produces different outputs in practice, which seems like it might violate this assumption?\n- Since the authors introduce a few different tweaks to SNPE, it seems important to understand which parts are contributing to the performance (e.g, MI-based acquisition, ensembling, etc)\n- From the results, it seems that active variants sometimes underperform compared to non-active ones, leading to the overall utility being a bit questionable (or limited to specific cases, which could be fleshed out for practitioners to understand when the method can help). It looks like fewer rounds can often be helpful in experiments, which seems surprising and maybe undermines the basic sequential aspect of the algorithm?\n- The applications are fairly simple (e.g. typical benchmarks, low-dimensional) -- it seems typical these days to ground SBI expositions with more realistic / real-world use cases"}, "questions": {"value": "Questions are primarily based on weaknesses above:\n- Is the \"residual\" MI approximation actually valid as laid out? Could it be checked with toy models where ground truth is known?\n- What are the key performance drivers -- e.g., MI-based parameter selection, ensembling, etc?\n- Why do active variants sometimes underperform (could it be the noisy MI estimates)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qBQXZqi1vg", "forum": "hg60pQXC6z", "replyto": "hg60pQXC6z", "signatures": ["ICLR.cc/2026/Conference/Submission22041/Reviewer_p85r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22041/Reviewer_p85r"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22041/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761885052404, "cdate": 1761885052404, "tmdate": 1762942031190, "mdate": 1762942031190, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel method for sequentiel neural posterior estimation, optimizing for the proposed parameter values to improve information gain for the target posteiror p(theta | x_0). I am short on time due to the semester start. Apologies if my reviews are a bit short. I am happy to engage in reviewer discussion should be concerns not be clear. And I am happy to consider increasing my score should the authors provide convincing responses to my concerns."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The new method is theoretically motivated and appears overall sound. Common issues arising in SNPE are tackled and avoid in sensible ways.\n- The writing of the paper is clear, at least to people familiar with the literature already.\n- The new method beats alternative methods in common benchmarks, although the benchmarks themselves are too simple (see below)."}, "weaknesses": {"value": "- The benchmarks used in the paper are very simply models, which continue to be reused in papers but do not reflect actually challenging SBI tasks. I don't mind using some of them as toy examples. But having no actually challenging models in the paper is insufficient in my opinion. Neither SIR nor LV are challenging models for NPE in general (nor the other 3 even more toy examples). In particular, the authors claim that their method is particularily useful for expensive simulators which only allow for very small simulation budgets, but non of the evaluated models has an expensive simulator (quite the opposite in fact). I would have liked to see at least one challenging case study with a complex, expensive simulator that really shows the benefits of the method.\n\n- Two amortized methods (FMPE and NPSE) are considered and tend to imply as good results as many of the sequential methods (an observation also made in other papers; e.g., https://arxiv.org/abs/2302.09125, not cited by the authors) — sometimes even reaching your ESNPE method in the accuracy metrics. Yet, the fact that we can reach almost as good accuracy in many cases while obtaining amortized posteriors across the whole prior space, is not addressed or discussed properly in this paper.\n\n- While, in the accuracy metrics, amortized methods are included, they do not show up in the speed comparisons? Why? I think a fair comparison would demand them to appear also there. I may have overlooked these results but at least Table 3 in the appendix didn't provide them.\n\n- The literature is cited very selectively, largely citing papers from few selective groups, an issue I continue to see in the SBI literature. This gives newcomers to the field a wrong sense of what is done by whom and leads to a fragmentation of the literature. As an example, the works of Stefan Radev are not cited even once, although he has made many relevant contributions to the field. I am seeing this selective referencing in almost every major ML conference, favoring some groups over others (not always the same groups) and it increasingly irritates me. Please cite more diverse works in your papers, not just papers from (presumably) your own group and few adjacent groups."}, "questions": {"value": "- How does the method scale with parameter dimensionality? The considered benchmarks are all very low dimensional and I wonder if there is any potential scalability issue of the new method?\n- What do you mean with (1 - 1/e - epsilon)-approximate concretely?\n- How are coupling flows performing for these examples? Likely not good for the multimodal models but for the others, the would provide a good baseline, with very high inference time speed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LPUkuZEMj2", "forum": "hg60pQXC6z", "replyto": "hg60pQXC6z", "signatures": ["ICLR.cc/2026/Conference/Submission22041/Reviewer_dTBE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22041/Reviewer_dTBE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22041/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761899767964, "cdate": 1761899767964, "tmdate": 1762942030854, "mdate": 1762942030854, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper describes an active learning method for neural posterior estimation (NPE). They propose a (weighted)) ensemble of the neural density estimator and provide an active learning rule based on the mutual information of parameters and neural network weights. They also provide a batched version of this rule. They evaluate their method on popular SBI benchmark tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The active learning rule presented here is novel (for NPE) and is theoretically grounded. The paper makes multiple advances for active learning in NPE. The figures are of high quality and aid in understanding the paper. Finally, the experiments are evaluated against a wide range of other methods."}, "weaknesses": {"value": "My main issue is with the experimental results:\n\n- the paper only evaluates the method on three (sometimes even two) observations. The used SBI benchmark provides ten observations, and it is unclear why these are not used.\n- there is basically no difference in the performance between `ESNPE` and `ENSPE (batch MI)`. For example, on Bernoulli GLM, ESNPE outperforms batch MI, and on Gaussian mixture they perform exactly the same. Yet the authors write: \"with the Batch MI acquisition generally yielding a larger performance advantage\". It is unclear to me where this claim is coming from.\n- Based on this observation, it seems to me that the only performance gain seems to come from ensembling. This, however, has been done before: For sequential NPE methods, for example, by Deistler et al., 2022. At the very least, this observation should be noted and highlighted in the paper.\n- The performance of baseline methods is much poorer than what is reported in the respective original publications. For example, for Two moons, you report a C2ST of ~0.9 for SNPE-C or TSNPE. However, the TSNPE paper reports an average of ~0.65. Did you choose the exact same hyperparameters for SNPE-C (and TSNPE) as for ESNPE? For example, which density estimator did you use?\n\nBeyond this, I find the appendix section F2 obscure:\n\n- In paragraph 1 (Järvenpää), I could not find the quote \"causing the density estimate to diverge from the true posterior.\" in the paper.\n- In paragraph 2 (Lueckmann), it is unclear to me why it \"is not compatible with arbitrary proposal distributions\". It is a likelihood-based method and should, thus, but compatible with any kind of proposal.\n- In paragraph 3 (Kourglova), you claim that they rely on Gaussian processes, but this is simply not true (and GPs are not even mentioned in the paper).\n\nThese errors are so bad that I am suspecting the paragraph to be written (unchecked) by a large-language model. I have therefore checked the corresponding LLM usage mark."}, "questions": {"value": "I sometimes find the methods section hard to follow:\n\n- is it correct that the ensemble weights are equal to exp(-loss)?\n- Line 195: `by calculating its (normalized) support under`. Why does one have to compute a support?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8mL51CRqzs", "forum": "hg60pQXC6z", "replyto": "hg60pQXC6z", "signatures": ["ICLR.cc/2026/Conference/Submission22041/Reviewer_GiCU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22041/Reviewer_GiCU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22041/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762175541539, "cdate": 1762175541539, "tmdate": 1762942030587, "mdate": 1762942030587, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this study, the authors develop a sequential method for simulation-based inference (SBI) called \"Ensemble sequential neural posterior estimation\" (ESNPE). The method leverages ensembles of density estimators and in two variants of the method, a mutual information-based aquisition function (a non-batched and a batched version). On several benchmark tasks (Two moons, Gaussian mixture, Bernoulli GLM, SIR, Lotka-Volterra), the different variants of the method are shown to perform better than state-of-the-art SBI methods as assessed with C2ST and MMD."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "### Originality\n\nTo my knowledge, this is one of the first methods in simulation-based inference that systematically uses posterior ensembles. Previous work is for the most part appropriately discussed and cited (see further comments in weaknesses).\n\n### Quality\n\nThe study is technically sound, although I have a few points I would appreciate the authors to address (see weaknesses).\n\n\n### Clarity\n\nThe manuscript is generally clearly written.\n\n\n### Significance\n\nThe results in this study suggest that the developed approach, through its acquisition function, is a valuable contribution towards scalable simulation-based inference."}, "weaknesses": {"value": "My main concerns lie in the quality of the experiments and clarity of the presentation:\n\n- Tables 1 and 2 show results for single $x_o$ values. Why not show the averaged results in Appendix G? These are likely more robust estimates of the methods' performances, so I would strongly recommend the authors to show those results instead;\n\n- Also, and related to the point above, although the methods proposed show systematic improvements in performance compared to previous methods, these improvements are often not substantial, especially taking the error bars into account. I urge the authors to replace the tables by plots, such that the reader can better assess the quality of the results;\n\n- The experiments were run for one simulation budget. In order to have a better assessement of the performance of the developed methods, it would be crucial to run analysis over different total numbers of simulations;\n\n- Regarding MI-ESNPE-batch, the reported runtime of the acquisition is negligible, even with very large batch sizes. This seems at odds with results in the literature, since most batch acquisition methods scale poorly with large batches (e.g., BatchBALD). I would urge the authors to check their results and/or provide an explanation for these results;\n\n- It is well known that the atomic loss of SNPE-C suffers from posterior leakage. Could the authors comment on that issue in their methods?\n\n- It is currently unclear whether the step of resampling and rejuvenation is really needed. It would be beneficial is the authors ran an experiment without that step;\n\n- Appendix G3 shows that increasing the number of rounds leads to worse performance. This is an important limitation of the method and should be discussed in the main sections of the manuscript.\n\n- Although there is relatively little work on ensembling in SBI, to my knowledge there are at least two previous papers that use ensembles: Hermans et al. 2022 (https://arxiv.org/abs/2110.06581), Deistler et al. 2022 (https://arxiv.org/abs/2210.04815). It would thus be important to discuss the relation to these studies.\n\n\nMinor comments on clarity:\n\n- It would be good to introduce \"D\" formally, in addition to its definition in algorithm 1;\n\n- Figure 1 is never referenced in the text;\n\n- \"in terms of its likelihood $p(\\phi|D)$\", I assume it was meant \"in terms of its posterior $p(\\phi|D)$\";\n\n- \"The shared parameter \"suggestion\" step\". The word \"suggestion\" seems confusing and not necessary;\n\n- In Appendix F2, the authors switched two references: \"In Järvenpää et al. (2019), the authors recognize explicitly...\" should be \"In Krouglova et al. (2025), the authors recognize explicitly...\" ; and \"In Krouglova et al. (2025), the authors present several means\" should be \"In Järvenpää et al. (2019), the authors present several means\""}, "questions": {"value": "- Could the authors include the averaged results (as plots) over multiple observations (as in Appendix G) in the main text? These seem more representative than single observation results.\n\n- The experiments were conducted with a single simulation budget. How does performance change across different total numbers of simulations?\n\n- The reported negligible runtime of MI-ESNPE-batch for large batch sizes seems inconsistent with prior work (e.g., BatchBALD). Could the authors clarify how they assessed runtime and check their implementation of the batch aquisition method?\n\n- What is the impact of the rejuvenation/resampling step? An ablation study would be beneficial in this respect.\n\n- Appendix G3 shows that increasing the number of rounds can degrade performance. Could the authors discuss this limitation in the main sections of the manuscript?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FU5kpwH0F6", "forum": "hg60pQXC6z", "replyto": "hg60pQXC6z", "signatures": ["ICLR.cc/2026/Conference/Submission22041/Reviewer_KpYD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22041/Reviewer_KpYD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22041/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762205700600, "cdate": 1762205700600, "tmdate": 1762942030298, "mdate": 1762942030298, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}