{"id": "4731mIqv89", "number": 16892, "cdate": 1758270025670, "mdate": 1759897212822, "content": {"title": "SPREAD: Sampling-based Pareto front Refinement via Efficient Adaptive Diffusion", "abstract": "Developing efficient multi-objective optimization methods to compute the Pareto set of optimal compromises between conflicting objectives remains a key challenge, especially for large-scale and expensive problems. To bridge this gap, we introduce SPREAD, a generative framework based on Denoising Diffusion Probabilistic Models (DDPMs). SPREAD first learns a conditional diffusion process over points sampled from the decision space and then, at each reverse diffusion step, refines candidates via a sampling scheme that uses an adaptive multiple gradient descent-inspired update for fast convergence alongside a Gaussian RBF–based repulsion term for diversity. Empirical results on multi-objective optimization benchmarks, including offline and Bayesian surrogate-based settings, show that SPREAD matches or exceeds leading baselines in efficiency, scalability, and Pareto front coverage.", "tldr": "We propose SPREAD, a diffusion-based generative framework for multi-objective optimization that couples adaptive gradient updates with a repulsion mechanism, achieving competitive efficiency, scalability, and Pareto front coverage across benchmarks.", "keywords": ["Multi-objective optimization", "Denoising Diffusion Probabilistic Models", "Multiple gradient descent", "Offline multi‑objective optimization", "Multi-objective Bayesian optimization", "Diffusion Transformer"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/46f3c42208218417547b2ebb9c5ffe921beab20d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces SPREAD, a generative framework for multi-objective optimization (MOO) built upon Denoising Diffusion Probabilistic Models (DDPMs). The central idea is to learn a conditional diffusion process over the decision space and refine candidate solutions during reverse diffusion via an adaptive guidance mechanism. This mechanism combines a Multiple Gradient Descent (MGD)-inspired update for efficient convergence and a Gaussian RBF-based repulsion term for maintaining diversity. The paper clearly motivates the use of a generative, diffusion-based formulation by highlighting the limitations of conventional MOO approaches. The main contribution lies in unifying these components into a single conditional diffusion process, applicable to online, offline, and Bayesian MOO settings. Extensive experiments on synthetic and real-world benchmarks demonstrate that SPREAD achieves competitive or superior performance in hypervolume and diversity, particularly as the number of objectives increases."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper introduces a fresh perspective on MOO by leveraging diffusion models for iterative refinement toward the Pareto front\n- The combination of MGD-based guidance and RBF repulsion is both intuitive and well-motivated, yielding a good balance between convergence and diversity.\n- The theoretical results (Theorems 1 and 2) are rigorous, supporting the conditioning and convergence properties.\n- SPREAD consistently outperforms or matches state-of-the-art methods in hypervolume and diversity metrics.\n- Ablation studies (Table 3, Figs. 6–8) are particularly informative, showing that each component—MGD alignment, repulsion, and perturbation—contributes meaningfully to performance."}, "weaknesses": {"value": "- The notation is overly dense, with multiple primes and sub-/superscripts that reduce readability. \n- The framework involves training a diffusion transformer and solving an optimization (Eq. 13) at every sampling step. Although Figure 2 shows SPREAD is faster than PMGDA, it remains slower than lighter baselines such as MOO-SVGD or HVGrad. Particularly, solving Eq. 13 not only depends on the data size $n$ but also the decision-space dimensionality. Some analysis of runtime scaling with decision-space dimensionality would strengthen the discussion.\n- SPREAD introduces two hyperparameters, $\\nu_t$ and $\\rho$. While $\\nu_t = 10$ is reported as the default, the default for $\\rho$ is unspecified. Given the cost of expensive optimization runs, hyperparameter tuning can be prohibitive. Moreover, Figures 6 and 7 indicate that performance is somewhat sensitive to these values, suggesting that robustness should be discussed in greater detail.\n- The largest tested problem (RE61) has $m = 6$ objectives. In combination with the weakness of *hyperparameter sensitivity*, it would be valuable to evaluate SPREAD's performance in higher-dimensional settings (e.g., $m \\geq 10$) to assess effectiveness of SPREAD."}, "questions": {"value": "Kindly address weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "NScWrFGutw", "forum": "4731mIqv89", "replyto": "4731mIqv89", "signatures": ["ICLR.cc/2026/Conference/Submission16892/Reviewer_rKVB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16892/Reviewer_rKVB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16892/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761322623918, "cdate": 1761322623918, "tmdate": 1762926925518, "mdate": 1762926925518, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a diffusion-based approach to multi-objective optimization. The core novel mechanism is straightforward: during training, the model learns to map from artificially worsened objectives (real objectives plus a positive shift) to designs, then at inference conditions on actual objectives to encourage improvement. At each reverse diffusion step, they apply post-processing that combines multiple gradient descent and RBF-based repulsion borrowed from existing MOO literature. The method trains a separate model per problem and is evaluated in three settings. The online setting (cheap evaluations) shows marginal gains over simpler gradient methods. The offline setting enables the model to learn from static datasets and propose new designs beyond the dataset. The Bayesian setting trains the conditional diffusion model on small datasets with data augmentation, and demonstrates promising results against some MOBO baselines like PSL-MOBO."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- I think the idea of shifting condition is interesting and new in MOO literature.\n- The algorithm is straightforward, and the idea of data augmentation that enables the method to work in Bayesian setting is interesting."}, "weaknesses": {"value": "- I find it difficult to grasp the theoretical insight that makes the method work. Here is my understanding: (1) the diffusion model learns the input-output mapping from the training data, (2) it also implicitly learns the global shift vector $\\Xi$. Then, if the diffusion model has learned the input-output mapping well and can generalize, it should be able to shift its output by conditioning on the new $C$ to infer $F$ via point 2, and thereby generate $X$ through its generalization capability. This hypothesis could be partially verified by explicitly feeding the shift vector to the conditional diffusion model (i.e., conditioning on both $C$ and $\\Xi$) to see if it gives better performance as an ablation study. However, if this is the mechanism, I cannot understand why it would work well in data-sparse settings like the online scenario wher obj is expensive .\n- The shift vector introduces a tricky hyperparameter with unclear guidance on how to properly choose it.\n- Although benchmarked across different problem settings, the claims seem somewhat overstated. I am not fully convinced this provides significant benefit in the cheap online setting. For the Bayesian setting, it may be beneficial, which is interesting but warrants deeper investigation with more ablation studies since PSL-MOBO is not a very standard baseline. Overall, I think this is more of an algorithm suited for offline settings.\n- The method trains a separate model per problem with no mechanism for transfer learning or generalization across problems. This limits scalability and requires expensive retraining (1000 epochs) for each new problem.\n- The paper lacks comparison against simpler baselines, particularly: (1) MGD+RBF with multiple random initializations (no diffusion model) in the online setting, (2) guidance-free diffusion sampling to quantify the guidance contribution, and (3) explicit vs implicit shift conditioning. Without these ablations, it is unclear whether the diffusion model provides meaningful benefit beyond the gradient-based guidance."}, "questions": {"value": "- Have the authors compared their approach against MGD+RBF without the diffusion model in all three settings?\n- As mentioned in weakness, can the authors provide ablations with explicit shift conditioning $p(x|c,\\Xi)$ versus the current implicit approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ess6MyQ31p", "forum": "4731mIqv89", "replyto": "4731mIqv89", "signatures": ["ICLR.cc/2026/Conference/Submission16892/Reviewer_CrTm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16892/Reviewer_CrTm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16892/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761655861973, "cdate": 1761655861973, "tmdate": 1762926925162, "mdate": 1762926925162, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SPREAD, a diffusion-based generative framework for multi-objective optimization (MOO).\nThe method integrates a conditional DDPM with a Multiple Gradient Descent (MGD)-inspired adaptive guidance mechanism and a Gaussian RBF repulsion term to jointly ensure convergence to Pareto optimality and coverage of the Pareto front.\nSPREAD can operate in three major settings:\nOnline optimization, directly refining decision variables;\nOffline optimization, using static datasets via surrogate functions;\nBayesian optimization, using Gaussian process surrogates under tight evaluation budgets.\n\nThe paper provides:\n- Theoretical results (Theorem 1–2) establishing that the conditional diffusion process yields Pareto-dominant samples with high probability;\n- A Transformer-based diffusion architecture (DiT-MOO);\n- Extensive experiments across online, offline, and Bayesian benchmarks (ZDT, DTLZ, RE, OffMOO-Bench, and MOBO suites).\n\nResults show that SPREAD outperforms state-of-the-art baselines (PMGDA, HVGrad, STCH, ParetoFlow, PGD-MOO, CDM-PSL) in terms of hypervolume, diversity, and scalability."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. First systematic framework unifying diffusion models and multi-objective optimization.The adaptive gradient guidance that couples DDPM sampling with MGD directions is conceptually novel and practically effective.Theoretical justification (Theorem 1 & 2) provides insight into convergence and dominance guarantees, uncommon in diffusion-based optimization works.\n2. Mathematical exposition is rigorous, with precise definitions (Pareto stationarity, dominance, MGD formulation). Algorithmic presentation (Algorithmic 1–4) is detailed enough for reproducibility. Ablation studies (Table 3) isolate the role of each design component (perturbation, repulsion, diversity), showing necessity.Extensive cross-domain experiments strengthen the claim of generality.\n3. Addresses three major MOO paradigms (online/offline/Bayesian) under a single framework. Potentially impactful for the community exploring generative optimization or diffusion-driven design. Outperforms strong baselines across different domains and scales; results are consistent and statistically robust."}, "weaknesses": {"value": "1. Theorem 1 assumes total variation (TV) distance ≤ τ between the learned conditional and the true data distribution, but τ is not quantified or empirically verified.\n2. Theorem 2 depends on νₜ = 0 for descent guarantees, which does not hold in practice (since diversity requires νₜ > 0). A stability bound for nonzero νₜ would improve rigor.\n3. Although Figures 2(a–b) show runtime comparisons, there is no formal analysis of asymptotic computational cost (e.g., O(n·T·d)) or memory scaling.\n4. All tested problems have ≤ 4 objectives; no experiments on “many-objective” problems (m ≥ 10)."}, "questions": {"value": "1. Theorem 1 assumes that the learned conditional distribution Qθ(⋅∣c) approximates the true conditional training distribution PX∣C=c within TV distance ≤ τ.\n  - How is τ estimated or controlled in practice?\n  - Can you provide empirical evidence (e.g., KL or Wasserstein estimates) showing that the learned conditional diffusion distribution indeed remains close to the true data distribution during training?\n  - If τ > 0.2, how sensitive is Theorem 1’s conclusion to this deviation?\n2. Theorem 2 assumes νₜ = 0 for all t, which guarantees a common descent direction.\n  - However, experiments rely on νₜ > 0 to ensure diversity.\n  - Could you provide an approximate convergence argument or empirical validation that Pareto dominance still holds under small νₜ > 0?\n  - How large can νₜ be before the descent guarantee breaks down?\n3. The “main direction” optimization mixes alignment and diversity terms and is solved via “a fixed number of gradient steps.”\n  - What is the typical number of inner-loop iterations and their computational cost relative to one DDPM denoising step?\n  - Does convergence of this inner optimization affect the overall sampling stability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SdrvzctalH", "forum": "4731mIqv89", "replyto": "4731mIqv89", "signatures": ["ICLR.cc/2026/Conference/Submission16892/Reviewer_uYzd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16892/Reviewer_uYzd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16892/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991964521, "cdate": 1761991964521, "tmdate": 1762926924507, "mdate": 1762926924507, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}