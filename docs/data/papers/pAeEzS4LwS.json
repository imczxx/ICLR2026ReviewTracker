{"id": "pAeEzS4LwS", "number": 18365, "cdate": 1758286883573, "mdate": 1759897108391, "content": {"title": "Catch-22: Pareto Frontier for Detectability and Robustness in LLM Watermarking", "abstract": "Large Language Models (LLMs) generate text through probabilistic token sampling, a mechanism increasingly leveraged for inference-time watermarking to verify AI-generated content. As watermarking schemes proliferate, assessing their robustness-detectability trade-off becomes essential to determine whether watermarks can survive output editing while remaining invisible to adversaries. Current evaluation relies on empirical tests lacking provable guarantees. In this work, we present the first information-theoretic framework that rigorously characterizes this fundamental trade-off. We first prove that detectability is determined solely by the sampling strategy, not the model architecture, thereby establishing a hierarchy ranging from undetectable (distribution-preserving) to highly detectable (biased sampling) schemes. Second, we demonstrate an inverse relationship: watermarks robust to text modifications are inherently more detectable by adversaries, creating an irreducible trilemma: no scheme simultaneously achieves high robustness, low detectability, and reliable verification. Motivated by these theoretical constraints, we propose a hybrid watermarking system that adaptively switches sampling strategies based on LLM output edit levels, achieving Pareto-optimal trade-offs. We show that distribution-preserving schemes provide perfect undetectability; however, they are only robust to near-zero adversarial edits. On the other hand, bias-free and biased sampling offer high robustness guarantees at 15-20\\% output editing, but with detectable output statistics. At high output editing rates, no watermarking provides robustness guarantees. Lastly, we empirically validate our theoretical trade-off claims with Llama-2 7B and Mistral 7B models under paraphrasing attacks, thereby confirming that Pareto-optimality is only achieved by a hybrid watermarking scheme. Overall, our framework provides watermark evaluation beyond empirical testing via principled design, revealing that sampling-based watermarking faces fundamental constraints rooted in information theory rather than implementation limitations.", "tldr": "This work identifies Pareto-optimal LLM watermarking solutions and establishes theoretical foundations for practical watermark designs, even when the conflicting goals of high robustness and undetectability cannot be simultaneously achieved.", "keywords": ["Watermarking", "LLM", "Undetectability", "Information Leakage", "Privacy", "Robustness"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8081c85a9769fcc20caedef2d3f8ab9787532feb.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the pareto frontier for robustness and susceptibility to detection without access to the secret key of a watermark in LLMs.  A watermark is a statistical signal hidden inside text that can be detected by anyone with access to a secret key but is intended to not distort the quality of text, thus remaining undetectable to observers without access to a secret key. Many schemes have been instantiated for autoregressive models by modifying the sampling procedure of models, with a prominent such scheme being the green list approach, where a hash function looks at the recent context and returns a pseudorandom subset of the vocabulary to upweight in generation.  This paper investigates the extent to which a watermark can be both undetectable to an observer without access to a secret key and be robust to edit-level attacks and finds that there is a fundamental tradeoff.  The authors consider three approaches to watermarking and bound the total variation distance between the watermarked and unwatermarked distributions, which controls the detectability of the watermark.  They then investigate the extent to which the considered approaches are robust to distortion and identify a tradeoff before empirically evaluating their findings."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "This paper investigates an important tradeoff between detectability and robustness of watermarks.  The existence of a pareto frontier that enforces this tradeoff is an important point and the authors do well to prove this."}, "weaknesses": {"value": "First, I am confused why the authors believe that the vocabulary size in Moitra & Golowich has to be exponential; exponential in what? That paper clearly states that the vocabulary size only has to be polynomial in the security parameter.\n\nSecond, I am somewhat skeptical of the framing of the notion of detectability. While I agree that the information theoretic notion of detectability is a strong bound on the extent to which an adversary ignorant of secret keys is capable of detecting the watermark, it seems very pessimistic for at least two reasons.  First, the approach studied in Moitra & Golowich is with respect to computational indistinguishability, which allows for TV to be large as long as witnessing this gap is computationally hard.  Second, in order to take advantage of the TV gap, the adversary would need paired watermarked and unwatermarked generations from the same prompt, which seems unlikely.  Even zooming out and allowing watermarked and unwatermarked generations from different prompts, the adversary would likely not have access to unwatermarked generations from the same model.\n\nThird, I am confused by the result in Theorem 1 for both biased and bias-free bounds.  The right hand sides of these equations seem like they are random in taht both g_t and p_t depend on the (random) history up until that point.  The left hand sides are not random.  Can the authors explain what is going on here?\n\nFourth, while I appreciate the difficulty of making rigorous the notion of robustness beyond edit-distance, I think realistic attacks consist of paraphrasing, not token-level approaches and it would be nice for the authors to comment on this.\n\nFifth, I wonder if the authors can comment on watermarks beyond the sampling approaches, such as those that imbed the watermark directly into the model weights; an example of such is *GaussMark: A Practical Approach for Structural Watermarking of Language Models*; again I am concerned that the two point hypothesis testing framework does not adequately describe the notion of detectability required.\n\nFinally, the empirical results in Figure 2(a) suggest that the theoretical results do not even qualitatively describe the empirical realities; the bounds in Theorem 1 are all concave in $T$ but the empirical trend appears to be convex in the same."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6rgr6QMJIR", "forum": "pAeEzS4LwS", "replyto": "pAeEzS4LwS", "signatures": ["ICLR.cc/2026/Conference/Submission18365/Reviewer_pLoi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18365/Reviewer_pLoi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18365/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761286868566, "cdate": 1761286868566, "tmdate": 1762928073857, "mdate": 1762928073857, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers trade-offs between LLM watermark detectability and robustness in the setting where all parties have unbounded computation."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Unfortunately I don't think I have anything to put here. Maybe I misunderstood something and the rebuttal will change my mind."}, "weaknesses": {"value": "The first result is \"We first prove that detectability is determined solely by the sampling strategy, not the model architecture.\"\nAs far as I understand it, this is less of a \"result\" and more of an obvious consequence of the way they've set things up: Of course if you embed the watermark by biasing distribution D, then the detectability is determined solely by D...\nI guess this result is formalized in Theorem 1, where they also appear to argue that any watermark which can be detected with the secret key can also be detected without. This is true information-theoretically, in the same way that encryption is impossible information-theoretically.\nIt appears to be a big misunderstanding: The whole point of using computational assumptions, as in the work of Aaronson, Christ et al., Zamir, Golowich & Moitra, etc. is that you can evade this trade-off. Appendix C.4 appears to be saying \"if you don't change the distribution then you can't detect,\" which is not even relevant.\n\nThis issue then translates to their second main result, Theorem 2, where they state a \"stealth vs robustness\" trade-off. Again, these kinds of arguments appear to be based on a fundamental misunderstanding about computational assumptions.\nAnd for the \"detectability vs robustness\" part, they're basically trying to show limits on the capacity of the edit channel. This problem has been studied before, and MUCH more is known about it than what is proven in this paper.\nFor instance, it is known how to construct error correcting codes that tolerate eps edits with rate 1 - O(eps): See https://arxiv.org/pdf/1710.09795.\n\nTheir bound says that the information rate should be at most (1-eps)^2, but it is already known that the information rate can be at most (1-H(eps)) / (1-eps), where H is the binary entropy function: https://arxiv.org/pdf/2107.01785v3. This is already a much better bound for eps < 1/2, and for larger eps it is not possible to do error correction at all."}, "questions": {"value": "The first result is \"We first prove that detectability is determined solely by the sampling strategy, not the model architecture.\"\nBut what they mean appears to be just that, if you embed a watermark by biasing the distribution at sampling time, then the only thing that matters is the distribution at sampling time. How is that not completely obvious?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Uk0VnFsNON", "forum": "pAeEzS4LwS", "replyto": "pAeEzS4LwS", "signatures": ["ICLR.cc/2026/Conference/Submission18365/Reviewer_1zUG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18365/Reviewer_1zUG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18365/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762009652250, "cdate": 1762009652250, "tmdate": 1762928073381, "mdate": 1762928073381, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a rigorous information-theoretic framework to characterize the \"Catch-22\" in LLM watermarking, a fundamental **trilemma** between **robustness**, **low detectability**, and **reliable verification**.\n\nThe authors establish a hierarchy of **detectability** (quantified by Total Variation distance) based *solely* on the sampling transformation (Theorem 1), proving scaling bounds for all four analyzed strategies: Greedy ($O(1)$), Biased ($O(|\\delta|\\sqrt{T})$), Bias-free ($O(\\sqrt{T})$), and Distribution-preserving (0).\n\n**Robustness** is then characterized using information capacity (Theorem 2). The core mechanism revealed is that the available information budget $C(\\epsilon)$ **contracts quadratically** (specifically, $C(\\epsilon) \\approx T(1-\\epsilon)^2 D_0$) with the edit rate $\\epsilon$. This mathematical mechanism proves the inverse relationship: achieving high robustness (requiring a high initial information budget $D_0$) inherently necessitates high detectability (which, per Theorem 1, also scales with the parameters that increase $D_0$).\n\nBased on these constraints, the authors derive a **Pareto-optimal hybrid watermarking scheme** (Theorem 3). This is not a simple heuristic switch, but an optimal construction derived by minimizing a **composite loss function ($\\mathfrak{L}$)** that jointly optimizes for target detection power ($1-\\beta$), stealth constraints ($\\tau, M$), and parameter amplitude.\n\nExperimental validation on Llama 2 7B and Mistral 7B using paraphrasing attacks confirms these theoretical bounds and, crucially, demonstrates that the proposed hybrid scheme **uniquely traces the Pareto-optimal frontier across all noise regimes**, outperforming any fixed scheme."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Rigorous theoretical foundation**: The information-theoretic framework with formal proofs (Theorems 1-3, Lemmas 1-5) provides principled understanding beyond empirical observations.\n\n2. **Comprehensive experimental validation**: Table 1 systematically evaluates multiple watermarking families (biased, bias-free, distribution-preserving) across two models and multiple attack scenarios, confirming theoretical predictions.\n\n3. **Breadth of analysis**: Coverage spans greedy, biased, bias-free, and distribution-preserving sampling with unified treatment.\n\n4. **Novel impossibility result**: Corollary 1 establishes fundamental limits showing the trilemma cannot be circumvented by clever engineering."}, "weaknesses": {"value": "1. **Limited attack diversity**: Only paraphrasing attacks (DIPPER, OPT-2.7B) are evaluated. Missing: synonym substitution, back-translation, model-based attacks, and adversarial prompting attacks from Liu et al. (2025) cited in the paper.\n\n2. **Independence assumption not validated**: The edit channel assumes i.i.d. token substitution (Eq. 43), but real paraphrasing introduces semantic dependencies. No empirical validation that this approximation holds or analysis of when it breaks down.\n\n3. **Incomplete hybrid scheme specification**: Theorem 3 provides allocation rules but lacks concrete algorithm for runtime edit rate estimation $\\hat{\\epsilon}$, which is critical for deployment. The paper acknowledges this (Impact Statement) but doesn't address it."}, "questions": {"value": "1. **Edit channel validity**: Can you provide empirical validation that real paraphrasing attacks approximately satisfy the i.i.d. edit assumption? What is the distribution of actual edit patterns in DIPPER outputs?\n\n3. **Multi-key scenarios**: Theorem 1 analyzes fixed-key bias-free schemes. How does detectability change if the adversary observes outputs from multiple different keys?\n\n4. **Comparison with Moitra & Golowich**: You mention their scheme requires exponential vocabulary (Section 2). Can you clarify the precise relationship between your impossibility results and theirs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "VvhX93tjEZ", "forum": "pAeEzS4LwS", "replyto": "pAeEzS4LwS", "signatures": ["ICLR.cc/2026/Conference/Submission18365/Reviewer_s5Qx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18365/Reviewer_s5Qx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18365/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762554307898, "cdate": 1762554307898, "tmdate": 1762928072976, "mdate": 1762928072976, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}