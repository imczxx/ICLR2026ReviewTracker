{"id": "tO7Je5SFF1", "number": 20699, "cdate": 1758309159660, "mdate": 1759896963420, "content": {"title": "LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems", "abstract": "Reformulating nonlinear optimization problems is largely manual and expertise-intensive, yet it remains essential for solving such problems with linear optimization solvers or applying special-purpose algorithms. We introduce \\textit{LinearizeLLM}, an agent-based framework that solves this task by leveraging Large Language Models (LLMs). The framework assigns each nonlinear pattern to a \\textit{reformulation agent} that is explicitly instructed to derive an exact linear reformulation for its nonlinearity pattern, for instance, absolute-value terms or bilinear products of decision variables. The agents then coordinate to assemble a solver-ready linear model equivalent to the original problem. To benchmark the approach, we create a dataset of 20 real-world nonlinear optimization problems derived from the established ComplexOR dataset of linear optimization problems. We evaluate our approach with several LLMs. Our results indicate that specialized LLM agents can automate linearization tasks, opening a path toward fully conversational modeling pipelines for nonlinear optimization.", "tldr": "", "keywords": ["large language models", "prompt engineering", "mixed-integer linear programming", "mixed-integer nonlinear programming", "LLM-guided optimization"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f81a6168310f5f356b23313aa290a7172e80b479.pdf", "supplementary_material": "/attachment/fc3dc35f53e7e1d18042b1834145ed697bdaa645.zip"}, "replies": [{"content": {"summary": {"value": "LinearizeLLM is a framework that uses large language models (LLMs) to automatically detect and reformulate nonlinear optimization problems into equivalent linear programming (LP) or mixed-integer linear programming (MILP) formulations.\nIt transforms nonlinear mathematical expressions into solver-ready linear models by combining multi-agent reasoning, pattern recognition, and structured prompting."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper explores an interesting intersection between large language models and mathematical optimization, showing how reasoning-based LLMs can be applied to structured, symbolic problems.  \n2. The modular multi-agent design is conceptually clear and demonstrates that LLMs can perform pattern detection and rule-based transformations in a coordinated workflow."}, "weaknesses": {"value": "###  Contrived Problem Formulation\nThe core task—detecting and reformulating nonlinear expressions into linear or MILP equivalents—is not a real bottleneck in mathematical optimization practice.  Existing modeling languages (e.g., Pyomo, JuMP, AMPL) and symbolic engines (e.g., SymPy) already handle these transformations deterministically and provably correctly.  Even if the goal is to teach non-experts how to formulate optimization models, I don't think LLM is the right tool for the task. Using a symbolic backend to give the user exact feedback is much better than using the LLM. \n\n###  Limited Novelty in Methodology\nThe paper’s core contribution, using multiple LLM “agents” for detection and reformulation, represents an engineering orchestration, not a new algorithmic insight.  Existing literature on optimization and LLM has already used similar agentic frameworks.\n\n### Evaluation Weaknesses\nThe experiments rely on small, synthetic datasets (20 problems, many artificially injected nonlinearities).  \nNo results are reported on real optimization benchmarks or solver runtime impacts, making it unclear whether the system produces usable models in practice.\n\n### Overstated Claims of Generalization\nThe paper implies broad applicability across nonlinear structures, yet all examples belong to a limited set of hand-crafted patterns ( abs, min/max, fractional). \n\n## Potential improvements \nTo make is acceptable for publication, it might be of interest to consider problems where there no existing methods in the literature to linearize. The LLM can potentially discover novel ways to reformulation the MINLP."}, "questions": {"value": "1. How does the system ensure correctness beyond heuristic validation? For example, is there any symbolic or numerical verification that the reformulated linear model preserves feasibility and optimality?  \n2. Given that existing modeling frameworks already automate many of these transformations, what unique scenarios or input formats justify the use of an LLM-based approach instead of traditional symbolic parsing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ELeWHzEJlk", "forum": "tO7Je5SFF1", "replyto": "tO7Je5SFF1", "signatures": ["ICLR.cc/2026/Conference/Submission20699/Reviewer_XAr7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20699/Reviewer_XAr7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20699/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760907664522, "cdate": 1760907664522, "tmdate": 1762934076727, "mdate": 1762934076727, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes LinearizeLLM, a multi-agent pipeline that takes a LaTeX description of a nonlinear optimization problem and iteratively detects specific nonlinearity patterns, then replaces each with an exact linear reformulation. The workflow has three stages: pattern detection, pattern-specific reformulation and iteration until no target nonlinearities remain. Experiments are conducted on 20 ComplexOR instances by injecting linearizable patterns and report different level success rates, comparing Gemini 2.5 Flash vs OpenAI o3 under the proposed agentic loop. The staged approach generally improves overall success rate over baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Reformulation of linearized optimization problem to LP or MILP is new and rarely studied systematically using LLMs. Pushing LLMs beyond \"text→model\" into model improvement is a meaningful step for OR+LLM.\n- The detect, reformulate loop is a clear, modular workflow and agent decomposition are easy to understand and plausibly extensible to more patterns.\n- The paper covers textbook transformations (epigraph for max, absolute value linearizations, Charnes–Cooper for linear fractional, big-M for binary–continuous interactions, monotone transforms with inverse for reporting), with decent diagnostics of failure modes."}, "weaknesses": {"value": "- Limited framework novelty: the proposed detect → reformulate → iterate loop resembles a conventional rule-driven rewrite pipeline already common in LLM agent systems, rewrapping standard linearization rules behind prompts without introducing new mechanisms or correctness guarantees.\n- Narrow evaluation: the benchmark consists of only 20 ComplexOR instances with injected patterns, which severely limits external validity and risks distributional overfitting to clean, non-nested patterns.\n- Baselines are limited: comparisons are only between LLMs and a one-shot prompt; deterministic rule-based rewriters (e.g., Pyomo, AMPL/CVX/YALMIP transforms) are strong baselines and should be included, along with a discussion on how the LLM-based reformulation relates to these rule-based methods.\n- Metrics lack absolute transparency: Table 2 presents relative values against baselines without absolute numbers per pattern and instance (and runtime), making it difficult to assess real-world reliability or overhead."}, "questions": {"value": "- Can machine-checked guarantees be attached for each reformulation step—for example, by generating proofs that a theorem prover (e.g., Lean) can discharge or by emitting certificates that can be verified offline? Could the LLM propose the reduction and proof sketch while a verifier certifies it before applying? See Bentkamp et al. (2023).\n- Can you add real, messy examples (e.g., from MINLPLib) and include nested patterns such as $\\max(|a^T x|, g(x))$? Please report the performance of the pipeline, including where it fails and why, and provide absolute per-pattern and per-instance scores and end-to-end runtimes for each baseline.\n- Please add deterministic, rule-based baselines (e.g., Pyomo with generalized disjunctive programming) and explain where your LLM method improves on them. A thorough discussion on the differences between AI-agent and deterministic methods would strengthen the conclusion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IdlZv9IzOq", "forum": "tO7Je5SFF1", "replyto": "tO7Je5SFF1", "signatures": ["ICLR.cc/2026/Conference/Submission20699/Reviewer_nhht"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20699/Reviewer_nhht"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20699/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761548281981, "cdate": 1761548281981, "tmdate": 1762934076118, "mdate": 1762934076118, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents LinearizeLLM, an agent-based LLM framework that automatically converts nonlinear optimization problems (NLPs) into algebraically equivalent linear (LP/MILP) forms.\nEach nonlinear pattern (e.g., bilinear terms, |·|, min/max, linear fractional, monotone transformations) is handled by a dedicated reformulation agent that applies exact linearization techniques. The framework iteratively detects, reformulates, and verifies nonlinear patterns until a solver-ready linear model is obtained.\nA new benchmark of 20 real-world nonlinear problems (derived from ComplexOR) is released to evaluate the method. Experiments with Gemini 2.5 Flash and OpenAI o3 show that LinearizeLLM significantly outperforms one-shot and non-agent baselines—achieving up to 107% improvement in overall success rate (OSR) and near-perfect detection/reformulation success on several nonlinear patterns."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Innovative agentic decomposition for algebraic reformulation—extends prior “Chain-of-Experts” frameworks toward symbolic linearization.\n* Transparent and auditable pipeline, improving explainability compared with solver black boxes.\n* Empirical evidence supports consistent performance improvement, especially on complex nonlinearities.\n* Potentially impactful for democratizing optimization modeling—bridging LLM reasoning and mathematical tractability."}, "weaknesses": {"value": "* Limited scale and diversity of experiments (20 synthetic instances).\n* No formal validation of algebraic equivalence beyond numerical consistency.\n* Dependence on specific prompt templates—unclear generalization to unseen nonlinearity structures.\n* No runtime or efficiency analysis—LLM cost, inference time, or token usage are missing.\n* Baseline scope (only one-shot and another model) is insufficient to prove general superiority.\n* Illustration of the LinearizeLLM workflow in figure 1 is quite confusing. Further explanation in caption will be helpful."}, "questions": {"value": "* What is the computational overhead (LLM calls, tokens) compared to manual reformulation or solver preprocessing?\n* How sensitive is performance to prompt phrasing or context length? The context-blind ablation hints at brittleness—can this be mitigated via meta-reasoning?\n* How does the system ensure algebraic equivalence beyond solver outcome matching? Could symbolic simplification or constraint hashing be used for formal verification?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3wIrAJjsJ5", "forum": "tO7Je5SFF1", "replyto": "tO7Je5SFF1", "signatures": ["ICLR.cc/2026/Conference/Submission20699/Reviewer_kNgt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20699/Reviewer_kNgt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20699/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761612918853, "cdate": 1761612918853, "tmdate": 1762934075578, "mdate": 1762934075578, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **LinearizeLLM**, an agent-based framework that automates the exact linear reformulation of nonlinear optimization problems using Large Language Models. It addresses the expertise gap in operations research by employing specialized reformulation agents, each trained to detect and linearize specific nonlinear patterns—such as absolute values, bilinear terms, and fractional expressions—into equivalent linear or mixed-integer linear models. The system iteratively processes a problem until it becomes solver-ready. Evaluated on a benchmark of 20 real-world problems derived from ComplexOR, LinearizeLLM with Gemini 2.5 Flash significantly outperforms one-shot and other LLM baselines, achieving high success rates in detection, reformulation, and overall model correctness. This work demonstrates the potential of LLM-driven agents to make advanced optimization techniques accessible to non-experts."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.  **Effective Multi-Agent Specialization:** The framework's core strength is its decomposition of the complex linearization task into specialized agents, each an expert in a specific nonlinear pattern (e.g., bilinear, absolute value). This targeted approach, guided by structured reasoning checklists, proves significantly more reliable than a single, one-shot LLM prompt, leading to higher success rates and more robust reformulations.\n\n2.  **Enhanced Auditability and Portability:** Unlike opaque solver-internal reformulations, LinearizeLLM produces a transparent, human-readable linear model. This allows users to verify the correctness of the introduced auxiliary variables and constraints, building trust. Furthermore, the output is a standard LP/MILP that can be ported to any compatible solver, ensuring flexibility and independence from proprietary nonlinear solvers."}, "weaknesses": {"value": "1.  **Limited Scope and Insufficient Experimental Evidence:** The experimental benchmark is narrow, comprising only 20 custom-made problems derived by injecting specific nonlinearities into an existing linear dataset. This small, synthetic test set is insufficient to robustly support the paper's claim of handling a \"broad class\" of real-world nonlinear problems. A more convincing evaluation would involve a larger, diverse set of native nonlinear problems from established MINLP libraries.\n\n2.  **Marginal Novelty in Core Concept:** The fundamental concept of using pattern-specific rules for linearization is a well-established, textbook practice in operations research. The paper's primary novelty lies in orchestrating this process with LLM agents rather than hard-coded rules. While the LLM-based automation is a contribution, the underlying linearization techniques themselves are not new, and the agent-based workflow is an incremental step over existing LLM frameworks like Chain-of-Experts.\n\n3.  **Dependence on Predefined Patterns and Assumptions:** The framework's effectiveness is confined to a predefined set of six, mutually independent nonlinear patterns. It cannot handle nested nonlinearities or patterns outside its trained agents' knowledge. This lack of generalizability is a significant limitation, as real-world optimization models often contain complex, interdependent nonlinear relationships that fall outside these clean, pre-defined categories."}, "questions": {"value": "same as the weakness:\n\n* **Limited Scope and Insufficient Experimental Evidence**\n* **Lack of Novelty**\n* **Dependence on Predefined Patterns and Assumptions**\n\nI will be happy if the authors will solve my issues, then I would like to raise my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P9ecBhdXyS", "forum": "tO7Je5SFF1", "replyto": "tO7Je5SFF1", "signatures": ["ICLR.cc/2026/Conference/Submission20699/Reviewer_ccd4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20699/Reviewer_ccd4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20699/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906683855, "cdate": 1761906683855, "tmdate": 1762934074773, "mdate": 1762934074773, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}