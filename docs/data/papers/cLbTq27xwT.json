{"id": "cLbTq27xwT", "number": 20967, "cdate": 1758312192903, "mdate": 1759896949413, "content": {"title": "Unlearning Paradox: Auditing Residual Identity Traces in Face Recognition", "abstract": "Face recognition systems raise a critical privacy question: how do we prove that a person’s biometric data has been deleted when laws such as GDPR or CCPA require it? We highlight an unlearning paradox - A model can still verify “forgotten” identities because face recognition works in an open set, where unseen identities remain recognizable. This makes standard accuracy-based tests misleading. We contribute three ideas. (1) We formalize this paradox and show why current metrics give a false sense of forgetting. (2) We design a generative auditing framework that reconstructs faces from embeddings, exposing that existing methods keep up to 57\\% of identity information even when they appear to succeed. (3) We propose FUSE (Forgetting Using Structural Erasure), which treats identities as hypercones and erases them with region-aware surrogates while preserving recognition of others. On CASIA-WebFace and D-LORD, FUSE reduce the amount of semantic residual ($>$0.6) for forget set while retaining high verification for non-target classes. Our work shifts evaluation from accuracy to semantics, setting stronger privacy standards for face recognition.", "tldr": "", "keywords": ["Face Recognition", "Machine Unlearning"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/46f3d09e7ad95937aacbcfc2fc9fd21b4792cb04.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses a critical challenge in facial recognition: how to verify that data has been genuinely “forgotten.” It offers profound insights and innovative solutions to an important and practical problem. Its definition of the “anti-learning paradox” represents a major contribution to the field, while the FUSE method and “semantic residual” evaluation framework together form a comprehensive and compelling technical approach. Experimental results strongly support its claims, demonstrating an excellent balance between privacy protection and model performance.\n\nMy decision is to strongly accept."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. Importance and Novelty of the Problem: This paper addresses a critically important issue in both legal and ethical contexts—how to effectively implement users' “right to be forgotten” within facial recognition systems. The authors' clear definition and exposition of the “anti-learning paradox” provide a solid theoretical foundation and fresh perspective for research in this field.\n\n2. Innovative Methodology: The FUSE approach is highly novel and ingeniously designed. The idea of modeling identity as a geometric “super-pyramid” and creating “dead space” through structured erasure directly and elegantly addresses the core challenge. Its three loss functions—pyramid exclusion, retention, and global consistency—collectively form a comprehensive and logically rigorous solution that achieves an excellent balance between forgetting and retention.\n\n3. Advanced Evaluation Framework: Traditional evaluation metrics fall short in open-set recognition tasks. The proposed “Semantic Residual” (SR) audit represents a significant advancement. It moves beyond reliance on misleading accuracy rates to directly quantify residual identity information in features, establishing a higher standard for measuring anti-learning effectiveness.\n\n4. Thorough Experimental Validation: The authors conduct comprehensive experiments across multiple large-scale datasets, meticulously comparing FUSE against diverse baseline methods. Evaluation dimensions are richly covered, encompassing Member Inference Attacks (MIA), multi-group Verification Accuracy (VA), category drift, and open-set recognition performance. Furthermore, extensive ablation studies clearly demonstrate the contributions of each component within FUSE."}, "weaknesses": {"value": "- The primary weakness of the proposed method lies in the uncontrolled nature of the forgotten embeddings' final destination. The FUSE method effectively pushes the target identity's embeddings out of their original cone into what the paper describes as \"unrelated or noisy regions\" of the hypersphere. While the cone preservation and global consistency losses ensure that these embeddings do not interfere with the known retained classes from the training set, the process does not provide explicit control over where these forgotten vectors ultimately land. Their final distribution is a result of the optimization process rather than a predetermined target. This lack of control raises questions about the potential latent structure in these \"noisy\" regions and the long-term stability of the feature space"}, "questions": {"value": "- Is there a theoretical risk that the new, dispersed location of a forgotten identity's embeddings could accidentally overlap with the natural embedding space of a distinct, unseen identity that was not part of the unlearning process? For instance, could a forgotten identity 'A' be moved to a region that coincidentally corresponds to where a future, unseen identity 'B' would naturally be mapped by the model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fzHYFCZJVa", "forum": "cLbTq27xwT", "replyto": "cLbTq27xwT", "signatures": ["ICLR.cc/2026/Conference/Submission20967/Reviewer_tEMv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20967/Reviewer_tEMv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20967/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760620942874, "cdate": 1760620942874, "tmdate": 1762939066349, "mdate": 1762939066349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the \"unlearning paradox\" in face recognition: models may still verify \"forgotten\" identities (open-set generalization), making accuracy-based metrics misleading for privacy compliance. It contributes three key points: (1) Formalizes the paradox, showing current metrics fake forgetting success. (2) Designs a generative audit framework, finding existing methods retain up to 57% identity info. (3) Proposes FUSE, modeling identities as hypercones to erase them via region-aware surrogates while preserving others’ recognition.\n\nEvaluated on CASIA-WebFace and D-LORD, FUSE reduces semantic residual (>0.6) for forgotten sets, retains 85% discriminability, and outperforms baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The major strengths of the submission are as follows:\n\nS1. The studied task is very important in recent field.\n\nS2. The methodology is technical sound."}, "weaknesses": {"value": "W1. Limited Generalization to Diverse Face Recognition Models. According to Tab. 1, the authors evaluate their method primarily on ResNet-50 backbones trained with ArcFace losses. The authors do not verify if FUSE’s hypercone modeling and loss design adapt to other methods.\n\nW2. According to the description, a new evaluation method SEMANTIC RESIDUAL is introduced. This method is built on an existing diffusion model. However, the implementation of the model is missed. In addition, the final metric is also influenced by the model. The authors should better address these concerns.\n\nW3. Ablations on the hyperparameters (losses) are missed.\n\nW4. Illustrations are too small. Important visualizations are missed. For example, the generation images of semantic residual.\n\nW5. It will be better for the authors to provide a discussion on the proportion of the representations they can erase."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "I will update my rating based on the rebutall and other reviewers' comments."}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "75W2drl6n6", "forum": "cLbTq27xwT", "replyto": "cLbTq27xwT", "signatures": ["ICLR.cc/2026/Conference/Submission20967/Reviewer_Fff5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20967/Reviewer_Fff5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20967/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974835152, "cdate": 1761974835152, "tmdate": 1762939065347, "mdate": 1762939065347, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper focuses on unlearning in face recognition as an open-set problem, which is an important topic given regulations such as GDPR. The authors first present a paradox for unlearning in face recognition. They discuss why current metrics give a false sense of forgetting.  By their definition of unlearning, they expect the forgotten sample to be failed. They also propose a generative auditing framework that reconstructs faces from embeddings. In addition, they propose an unlearning method, called FUSE (Forgetting Using Structural Erasure), which treats identities as hypercones and erases them with region-aware surrogates while preserving recognition of others."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Unlearning face recognition in open-set condition is important and demanding topic.\n- The paper reports quantitative comparison of the method with existing unlearning techniques, where the proposed method outperforms existing ones."}, "weaknesses": {"value": "- The definition of unlearning in the paper is that \"we expect the model to fail\" on forgotten identities (line 162). However, the main purpose of unlearning techniques is to remove information from the model as if the forgotten data was not used in the training. That means the performance of the unlearned model for forgotten data should be similar to unseen data, and therefore we do not necessarily expect the model to fail for forgotten data.\n- The results for \"Open Set Recognition\" experiments are not complete and the reported numbers are very low. Which model (training dataset) was used for this evaluation? Recognition accuracy of 95.7% for the original model and 94.49% for FUSE model are very poor performance for a face recognition model on LFW. Authors are required to provide more information and also benchmark on more datasets (IJB-C, AgeDB, CFP, etc).\n- SOTA Face recognition models are trained on larger datasets such as WebFace. The paper presents a paradox in unlearning and then propose a method, however it needs to be studied on large scale datasets, such as WebFace4M or WebFace12M.\n- For generative auditing framework (second contribution), authors proposed a diffusion-based model to reconstruct faces from embeddings. However, there are also several work on reconstruction of face from embeddings, and the paper lacks comparison with previous work on face reconstruction from embeddings."}, "questions": {"value": "- Why should we we expect the model to fail on forgotten identities? In unlearning we would like the forgotten sample should act as unseen, not necessarily “fail.”\n- If train labels Y and test data Z partially overlap then we do not have `Z ∩ Y ⊆ ∅` in line 148. Can you please clarify?\n- For \"Open Set Recognition\" experiments, how other unlearning methods perform?\n- Why D-LORD is used for training? This dataset is not often used for training face recognition. Authors used only 1600 identities for training which is very small.\n- How would be the performance if trained on larger datasets, such as WebFace4M or WebFace12M?\n- Authors proposed a diffusion-based model to reconstruct faces from embeddings for the auditing framework (second contribution). However, the paper lacks illustrative examples of face reconstruction. Authors are suggested to include example images in the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GmZxVqU6mQ", "forum": "cLbTq27xwT", "replyto": "cLbTq27xwT", "signatures": ["ICLR.cc/2026/Conference/Submission20967/Reviewer_w6Qc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20967/Reviewer_w6Qc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20967/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995073994, "cdate": 1761995073994, "tmdate": 1762939064724, "mdate": 1762939064724, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper deals with the problem of machine unlearning in face recognition in the context of privacy regulations such as GDPR  right to be forgotten. The authors identify and formalize the unlearning paradox that a face recognition system, even after unlearning a person identity, may still verify them because such systems inherently generalize to unseen identities in open-set recognition.\n\nThe paper formalize the unlearning paradox showing that conventional accuracy-based evaluations fail to detect residual identity traces. present a generative framework that trys to expose hidden semantic leakage by reconstructing residual identity information. and present a geometry-aware unlearning method that models each identity as a hypercone in embedding space and erases those structures through repulsion and preservation losses. Experiments performed on multiple datasets including CASIA-WebFace, D-LORD, and LFW."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- main contribution is the correct definition of unlearning. In recent works unlearning have been considered to be the property to stop recognizing the identity. However, what it should be and defined here is being making the model behave as if this identity was not being part of the training.\n\n- proposes a theoretically principled and empirically effective geometry-based unlearning method (FUSE)."}, "weaknesses": {"value": "- the used dataset CASIA-Webface has well known mislabels to a large degree. one can see that in the difference in the results (maybe the reason) to the other dataset. It is not clear why these datasets were chosen among many available evaluation datasets. and does these mislabels effect the results.\n\n- there is no clear indication of the effect of the unlearning on the general model performance. this might be critical.\n\n- Could adversarial reconstruction or inversion attacks still reveal residual information after FUSE?\n\n- How do hyperparameter settings (λ1, λ2, λ3) affect the robustness of forgetting?\n\n- minor note, maybe linking the methods in table 1 to their respective papers would enhance readability."}, "questions": {"value": "- Could adversarial reconstruction or inversion attacks still reveal residual information after FUSE?\n\n- How do hyperparameter settings (λ1, λ2, λ3) affect the robustness of forgetting?\n\n- are the mislabe;s in casia webface effecting the results and conclusion?\n\nwhy common evaluation benchmarks are not used?\n\n- what was the effect on the general performacne of the model?\n\n- How stable is the Semantic Residual metric across architectures and datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "N9g14aMiNV", "forum": "cLbTq27xwT", "replyto": "cLbTq27xwT", "signatures": ["ICLR.cc/2026/Conference/Submission20967/Reviewer_TePw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20967/Reviewer_TePw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20967/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762177654108, "cdate": 1762177654108, "tmdate": 1762939064034, "mdate": 1762939064034, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}