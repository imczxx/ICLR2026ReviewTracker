{"id": "5ubZyHPhnK", "number": 20100, "cdate": 1758302449389, "mdate": 1759897001579, "content": {"title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "abstract": "Transformer models learn in two distinct modes: in-weights learning (IWL), encoding knowledge into model weights, and in-context learning (ICL), adapting flexibly to context without weight modification. To better understand the interplay between these learning modes, we draw inspiration from evolutionary biology's analogous adaptive strategies: genetic encoding (akin to IWL, adapting over generations and fixed within an individual's lifetime) and phenotypic plasticity (akin to ICL, enabling flexible behavioral responses to environmental cues). In evolutionary biology, environmental predictability dictates the balance between these strategies: stability favors genetic encoding, while reliable predictive cues promote phenotypic plasticity. We experimentally operationalize these dimensions of predictability and systematically investigate their influence on the ICL/IWL balance in Transformers. Using regression and classification tasks, we show that high environmental stability decisively favors IWL, as predicted, with a sharp transition at maximal stability. Conversely, high cue reliability enhances ICL efficacy, particularly when stability is low. Furthermore, learning dynamics reveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift occurs in some settings (e.g., classification with many classes), we demonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL acquisition (e.g., regression) can exhibit an initial IWL phase later yielding to ICL dominance. These findings support a relative-cost hypothesis for explaining these learning mode transitions, establishing predictability as a critical factor governing adaptive strategies in Transformers, and offering novel insights for understanding ICL and guiding training methodologies.", "tldr": "Evolutionary theory reveals how environmental predictability and relative learning costs dictate whether Transformers learn in-context or in-weights.", "keywords": ["In-Context Learning", "In-Weights Learning", "Transformers", "Evolutionary Biology", "Predictability", "Adaptation", "Learning Dynamics"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ce9eebdd3d7df6a4e3eebe34ab8e36bb058b6052.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors investigate in-context learning versus in-weights learning in Transformers (though I don't see why the experiments couldn't be done with other memory-based architectures, like RNNs).\n\nAdopting meta-learning settings,  both Omniglot and sinusoid regression, they independently manipulate the stability of the (outer-loop, across tasks) task distribution, and the reliability of the (inner-loop, within-task) contextual cues.\n\nThen, testing with a new task allows then to estimate how much the network relies on in-weights or in-context learning, based on whether its answer to the final query input is closer to that predicted from current in-context cues, or from the ongoing training task, respectively. \n\nThey show that higher contextual reliability favors in-context learning, while higher task stability favors in-weight learning. Different tasks have different dynamics. Increasing the number of possible classes decreases preference for in-weights learning in the Omniglot task."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The question is interesting. The experiments are informative. The review of the literature (on both evolution and ML) is nice."}, "weaknesses": {"value": "There seems to be no fatal flaw in the paper that I can see.\n\nIt may be argued that some of the results are not really earth-shattering (\"more stability = more overfitting?\"), though the additional experiments in Figures 4 and 5 provide more details on the dynamics.\n\nIt's not clear how much the \"relative cost\" hypothesis helps, because there seems to be no precise definition of \"cost\", except for a-posteriori hardness on IWL? (I note that the parameter used to tune Omniglot task is the total number of classes; however, the sinusoid task has an infinite number of classes, yet it doesn't seem to clearly favor ICL or IWL more than Omniglot, but rather it seems to incline differently for various regimes of stability/reliability)."}, "questions": {"value": "If the authors can make their hypotheses a bit more precise and/or actionable it would probably increase the reach of the paper. Other than that I have no pressing questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "odZRKybbx3", "forum": "5ubZyHPhnK", "replyto": "5ubZyHPhnK", "signatures": ["ICLR.cc/2026/Conference/Submission20100/Reviewer_ER3k"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20100/Reviewer_ER3k"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20100/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761604679587, "cdate": 1761604679587, "tmdate": 1762932995519, "mdate": 1762932995519, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how environmental predictability influences the balance between in-context learning (ICL) and in-weights learning (IWL) in Transformers. The paper draws many analogies to evolutionary biology's phenotypic plasticity and genetic encoding and the circuit learned in transformers. The authors set up two model systems: sinusoidal regression and Omniglot and set up variables representing environmental stability (task consistency across training) and cue reliability (how informative are in-context examples). Key findings include: (1) high stability favors IWL while high cue reliability enhances ICL, (2) learning dynamics show task-dependent transience patterns (both ICL→IWL and IWL→ICL transitions, this latter seems quite novel), and (3) a \"relative-cost hypothesis\" suggesting that the computational ease of acquiring each strategy determines preference and transition dynamics."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "S1: The experiments are quite novel and interesting, even though some past studies study curriculum learning where the loss landscape keeps changing, studying this together with the question of ICL vs IWL is genuinely interesting.\n\nS2: The **quality** of the paper's presentation is great, even though the framing seems questionable (see W1). The paper is well-written and figures are clear. The experimental design is clean and easy to understand.\n\nS3: The identification of IWL->ICL transience (in addition to previously documented ICL transience) seems novel and interesting."}, "weaknesses": {"value": "W1: This is my only major concern of the paper. The connection to evolutionary biology seems to be just at the very high level. The framing makes sense, but does not actually offer any falsifiable statements or predictions. While this could have been a nice discussion point, I don't see why this should be a main theme of the paper instead of simply framing it as a study of circuit competition on non stationary losses. Furthermore the training method lacks any kind of evolutionary mechanism such as selection, mutation, reproduction. The authors themselves do acknowledge that there is no direct equivalence. It seems like the paper could be much better linked to other concepts like learning theory, meta-learning frameworks, complexity theory, etc. I really like the experiments and the experiments were genuinely interesting, but I am left confused why such a superficial connection to evolution was made, without discussing core concepts of evolution: G-P mapping, mutations, genetic drift, etc.\n\nHowever, I am happy to discuss this further, perhaps there is a connection which is genuinely helpful that I'm missing.\n\nW2: Beyond the weaknesses discussed in W1, it seems like the relative-cost hypothesis is a good intuition to have, but at the same time doesn't seem to be too novel compared to classic discussions in simplicity bias, circuit complexity, memorization budget in deep learning.\n\nW3: The choice of learning rate scheduling is questionable when the data distribution is non-stationary. Perhaps this makes the results harder to interpret since it artificially slows down the speed of learning. However, I don't think this will qualitatively change the results too much."}, "questions": {"value": "It would be good to cite some more papers which also explore IWL vs ICL:\n\nhttps://arxiv.org/abs/2306.04891 <- this paper seems to co-pioneer the findings on transience, although they didn't focus on presenting it that way.\nhttps://arxiv.org/abs/2412.01003 <- seems directly related to the cost of memorizing more processes and also discuss that circuit complexity slows ICL.\nhttps://arxiv.org/abs/2506.17859 <- also seems related to the relative cost hypothesis.\nhttps://arxiv.org/abs/2506.19351 <- discusses an Occam's razor on complexity.\n\nQ1: I'm not so sure if this is possible, but is it possible to decompose the model prediction in the style of https://arxiv.org/abs/2412.01003, i.e. decomposing the probability itself by the ICL vs IWL probabilities?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "80eXf3g3Vy", "forum": "5ubZyHPhnK", "replyto": "5ubZyHPhnK", "signatures": ["ICLR.cc/2026/Conference/Submission20100/Reviewer_XQNw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20100/Reviewer_XQNw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20100/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979029271, "cdate": 1761979029271, "tmdate": 1762932995004, "mdate": 1762932995004, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates when decoder-only Transformers rely on in-context learning (ICL) versus in-weights learning (IWL). Using an evolutionary analogy (phenotypic plasticity vs genetic encoding), the authors operationalize cue reliability and environmental stability and perform dense parameter sweeps on two controlled tasks (sinusoid regression and Omniglot binary classification). They introduce a preference score (SICL) comparing errors against ICL- and IWL-targets, present asymptotic preference maps and training-time transience dynamics, and posit a qualitative 'relative-cost' hypothesis to explain strategy emergence."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper comes with a clear, motivating framing that yields testable experimental axes (stability and cue reliability).\n\nThe scientific claims are substantiated with systematic empirical evaluation with dense sweeps and temporal analyses across many configurations.\n\nCoherent qualitative findings across two tasks: stability favors IWL; reliable cues favor ICL; transience depends on relative difficulty.\n\nEfficient experimental design allowed broad exploration and reproducibility in principle; hyperparameter grids and compute are reported."}, "weaknesses": {"value": "I might be mistaken but is there a critical and central inconsistency?: SICL is defined as SICL = EIWL / (EICL + EIWL + eps) but interpreted (and plotted) as higher SICL meaning more ICL.\n\nInsufficient robustness: only 3 seeds per configuration; many key effects (thresholds, transience) need more seeds and statistical tests.\n\nLimited external validity: only two simplified tasks and a single small Transformer; applicability to larger models and potentially LLMs or naturalistic domains is untested.\n\nMissing important ablations/controls: prompt-length (N) sweep, encoder-freeze/pretrain ablations for Omniglot, model-capacity sweep, and explicit conflict trials to directly distinguish ICL vs IWL.\n\nMechanistic evidence is lacking: no attention/head diagnostics, weight-change tracking, probes, or lesioning to support claims of circuit-level implementation or assimilation into weights.\n\nThe relative-cost hypothesis is qualitative and unquantified; no direct cost or sample-complexity metrics are provided to predict transience."}, "questions": {"value": "Please correct and clarify the SICL definition and interpretation. If it was a typesetting mistake, state the intended formula and re-run affected figures and analyses. As a sanity check, include results for a synthetic pure-ICL and pure-IWL predictor showing the corrected SICL behaves as intended.\n\nProvide explicit pseudocode for the evaluation protocol: how EICL and EIWL are constructed, how evaluator prompts are sampled, number of evaluation examples per measurement, and how conflict trials are generated and scored.\n\nIncrease robustness: re-run key configurations (those showing sharp transitions or notable transience) with >=5-10 seeds and report SEMs/confidence intervals and statistical tests for main claims.\n\nPerform the following ablations/controls: (a) vary prompt length N; (b) freeze and/or pretrain the ResNet encoder for Omniglot to localize effects; (c) sweep model capacity (smaller/larger Transformers); (d) include explicit conflict trials during evaluation and report how often models follow prompt vs internal mapping.\n\nQuantify the relative-cost hypothesis: measure steps-to-target-error for ICL-only and IWL-only baselines, parameter-efficiency, or representational complexity, and test whether these predict observed transience directions.\n\nAdd basic mechanistic analyses: track layerwise weight changes over training, analyze attention-head patterns, or use linear probes/lesioning to show distinct circuitry for ICL vs IWL and to support any assimilation claims."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "42Y1AJ5ORh", "forum": "5ubZyHPhnK", "replyto": "5ubZyHPhnK", "signatures": ["ICLR.cc/2026/Conference/Submission20100/Reviewer_yWAK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20100/Reviewer_yWAK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20100/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998255448, "cdate": 1761998255448, "tmdate": 1762932993871, "mdate": 1762932993871, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}