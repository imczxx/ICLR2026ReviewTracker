{"id": "PRN6sitmfc", "number": 3003, "cdate": 1757315050187, "mdate": 1759898114279, "content": {"title": "HGT-UCOD: A Hint-Guided Teacher Framework for Unsupervised Camouflaged Object Detection", "abstract": "Camouflaged Object Detection (COD) holds significant potential in various high-stakes applications, yet its progress is fundamentally bottlenecked by a heavy reliance on large-scale, pixel-level annotated data. While Unsupervised Domain Adaptation (UDA) offers a promising path forward, real-world scenarios often impose stricter constraints due to data privacy, leaving us with only a pre-trained source model—a more challenging setting known as source-free domain adaptation. A critical flaw in current methods is their direct use of the source model (e.g., one trained for salient object detection) to generate pseudo-labels. The inherent \"saliency bias\" of such models—an inclination to find objects that \"stand out\" rather than \"blend in\"—results in incomplete and noisy labels that only capture the most conspicuous parts of a target. Self-training on this flawed guidance inevitably falls into confirmation bias, amplifying initial errors and limiting performance.\nWe introduce a paradigm shift in addressing this problem. Instead of treating the biased predictions as mere noise, we innovatively reframe their high-confidence fragments as reliable \"hints\". Based on this philosophy, we propose HGT-UCOD, a novel Hint-Guided Teacher framework designed to guide the model in inferring the complete object from these sparse yet trustworthy cues. The cornerstone of our framework is a unique teacher pre-adaptation stage. Here, we first cultivate an \"expert teacher\" by compelling it to learn to infer the full object from partial views containing only these \"hints,\" thus building specialized knowledge. Subsequently, during student refinement, this expert teacher collaborates with the source model to generate high-quality pseudo-labels via a dynamic fusion strategy. This process is further enhanced by strong consistency regularization, which forces the student to learn robust, perturbation-invariant features. To empower this inference, both our teacher and student models are equipped with a novel Dynamic Convolution Mixture (DCM) module, which adaptively generates content-aware kernels to capture the subtle, context-dependent features of camouflaged objects.\nExtensive experiments on multiple benchmark datasets demonstrate that our method achieves superior performance, establishing a new state-of-the-art for source-free unsupervised COD.", "tldr": "", "keywords": ["Camouflaged Object Detection"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e1279891a29358d72a5abd87af2fe94bbd4534fe.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the \"saliency bias\" in existing unsupervised camouflaged object detection methods.\nSource models typically create noisy pseudo-labels that only find salient object parts.\nThe proposed HGT-UCOD framework reframes this issue by treating these sparse, high-confidence predictions as reliable \"hints.\"\nA pre-trained teacher first learns to infer complete objects from these partial cues, and then generates high-quality labels to train a student model, achieving new state-of-the-art results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The core concept of repurposing biased, high-confidence predictions as \"reliable hints\" rather than noise is a highly innovative approach to bypass saliency bias.\n- The proposed teacher pre-adaptation stage provides a logical and effective framework for compelling the model to learn to infer global object structures from sparse local information.\n- The method achieves better results, demonstrating its empirical effectiveness."}, "weaknesses": {"value": "1. The related work section lacks important comparisons with recent works [1,2], even though they are cited later, which makes the section incomplete. The paper should compare the proposed method with these existing methods to highlight its uniqueness. Similarly, in Sec. 3.1, the authors state the architecture is inspired by UCOS-DA and UCOD-DPL, but the differences between this work and those two are not clarified.\n2. Dynamic convolution networks have been developed for many years. As this is a primary design choice for the model architecture, the paper lacks necessary citations and comparative analysis of related work in this specific area.\n3. The method's design is confusing. While targeting the camouflaged object detection (COD) task, the proposed method seems to lack specific designs tailored for it. The current design appears to treat camouflaged objects as \"salient objects\". For example, the high-confidence regions emphasized during the source model's supervision of the teacher are, for perceptual stability, most likely the visually salient parts (or why is this necessarily relevant to the camouflaged object of interest?).  A teacher model trained this way does not seem specialized for the COD task. Therefore, it is questionable whether the pseudo-labels generated by fusing predictions from such a teacher and the source model (Equ. 5) truly correspond to camouflaged objects to effectively train the student model. Furthermore, it is even more confusing that the algorithm achieves such high unsupervised COD performance under these conditions. These require more in-depth and rational explanations.\n4. Regarding the experimental comparisons:\n    1. Tab. 1 should be supplemented with the computational complexity and input size for different models. It should also specify the backbones or key component models used by each model to ensure a clearer and fairer comparison.\n    2. The current algorithm focuses excessively on overall foreground performance while neglecting the impact of different target scales. Recent work [3] has introduced size-invariance metrics; this paper should also consider analysis using such indicators.\n    3. The ablation study section fails to describe the architecture of the baseline model used.\n\n\nREF:\n1. UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, CVPR 2025    \n2. Shift the Lens: Environment-Aware Unsupervised Camouflaged Object Detection, CVPR 2025\n3. Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection, ICML 2024"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "IZnjx4zcLz", "forum": "PRN6sitmfc", "replyto": "PRN6sitmfc", "signatures": ["ICLR.cc/2026/Conference/Submission3003/Reviewer_9ohC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3003/Reviewer_9ohC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3003/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761385869330, "cdate": 1761385869330, "tmdate": 1762916493600, "mdate": 1762916493600, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents HGT-UCOD, a novel hint-guided teacher–student framework for unsupervised camouflaged object detection (UCOD) in a source-free domain adaptation setting. Instead of treating biased pseudo-labels from the source model as noise to be filtered, the method extracts high-confidence, perturbation-stable regions (“hints”) to guide a teacher model in reconstructing complete object structures. A Dynamic Convolution Mixture (DCM) module is further proposed to enhance the teacher and student models with content-adaptive feature extraction. Extensive experiments on three COD benchmarks demonstrate that the proposed method outperforms prior unsupervised approaches and achieves competitive results with semi-supervised and fully supervised baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Clear conceptual innovation: The idea of reframing biased pseudo-labels as “hint” cues is simple yet elegant, providing a new perspective on how to handle saliency bias in source-free COD.\n\n2. Well-designed framework: The two-stage teacher pre-adaptation and student refinement pipeline is clearly structured and effectively operationalises the hint-guided idea.\n\n3. Strong empirical results: The method achieves state-of-the-art performance across multiple COD benchmarks, demonstrating both accuracy and robustness."}, "weaknesses": {"value": "While the proposed hint-guided strategy is interesting, several technical and conceptual issues remain unclear and deserve further clarification or discussion:\n\n1. Dependency on Teacher Initialization: The hint points are strongly influenced by the teacher model’s prior. If the teacher is not properly initialized or inherits biased information from the source model, it seems that these errors may not be effectively corrected during training. This could potentially lead to confirmation bias or error accumulation in the adaptation loop. The authors should clarify whether any mechanism exists to mitigate such errors or to enable self-correction.\n\n2. Handling Non-Salient Camouflaged Regions: As acknowledged by the authors, most existing object detection or segmentation methods are designed to detect salient targets, whereas many regions in COD are non-salient and deliberately blended into the background. It remains unclear how the proposed hint selection strategy can reliably identify these irregular and camouflaged regions, rather than only the most conspicuous parts. A more detailed explanation or empirical analysis would be beneficial here.\n\n3.Missing Discussion of Task-Generic Promptable Segmentation: Recent task-generic promptable segmentation methods (e.g., SAM-based frameworks [1–3]) have also shown strong potential for unsupervised object detection, including camouflaged scenarios. It would be helpful for the authors to position their work in relation to this line of research, discussing its relevance, differences, or complementarity, especially since both approaches address unsupervised object discovery under limited supervision.\n\n[1] Hu, Jian, et al. \"Relax image-specific prompt requirement in sam: A single generic prompt for segmenting camouflaged objects.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 11. 2024.\n\n[2] Tang, Lv, et al. \"Chain of visual perception: Harnessing multimodal large language models for zero-shot camouflaged object detection.\" Proceedings of the 32nd ACM international conference on multimedia. 2024.\n\n[3] Ren, Tianhe, et al. \"Grounded sam: Assembling open-world models for diverse visual tasks.\" arXiv preprint arXiv:2401.14159 (2024)."}, "questions": {"value": "1. Impact of K on Performance: Since the proposed hint-guided strategy relies on greedily sampling K points with the smallest prediction differences, the choice of  K seems likely to influence the overall performance. How sensitive is the method to this hyperparameter, and how was K selected in practice?\n\n2. Multiple Camouflaged Objects: How does the method handle scenes containing multiple camouflaged objects? Will the greedy selection process distribute hint points across different instances, or is there a risk that all hints might concentrate on a single object, leading to incomplete localization?\n\n3. Local Hint Coverage vs. Global Object Structure: The proposed Hint Mask is derived from local high-confidence patches, which may only correspond to small, salient parts of the object (e.g., the head or edges). Camouflaged objects often exhibit non-uniform textures and blend irregularly with the background. If these hints fail to cover key structural components (e.g., the main body contour), the teacher model may struggle to reconstruct the complete object. How does the method address this issue or mitigate the risk of incomplete guidance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bRQppYhb10", "forum": "PRN6sitmfc", "replyto": "PRN6sitmfc", "signatures": ["ICLR.cc/2026/Conference/Submission3003/Reviewer_4XE7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3003/Reviewer_4XE7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3003/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761648004717, "cdate": 1761648004717, "tmdate": 1762916492722, "mdate": 1762916492722, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes HGT-UCOD, a hint-guided teacher-student framework for source-free unsupervised camouflaged object detection (COD). It reframes high-confidence saliency-biased predictions as reliable “hints,” uses a teacher pre-adaptation stage to learn full-object inference from partial hints, introduces a Dynamic Convolution Mixture (DCM) module for adaptive feature extraction, and applies dynamic fusion + consistency regularization during student refinement. Experiments on CAMO, COD10K, and NC4K show new SOTA in source-free UDA for COD."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Novel paradigm: treats saliency bias as useful hints instead of noise — elegant and counterintuitive.\nTeacher pre-adaptation is a creative self-supervision strategy tailored to COD.\nDCM module enables content-aware kernel mixing, well-motivated and cleanly formulated.\nStrong empirical gains: +5–10% in $S_\\alpha$, $F_\\beta^w$, MAE across benchmarks.\nClear writing, excellent figures (hint maps, failure cases, ablations), and reproducible setup."}, "weaknesses": {"value": "Hint confidence threshold fixed at 0.8 — no sensitivity analysis (e.g., 0.6–0.95).\nNo real-world cross-domain test (e.g., source from SOD → wildlife camera traps).\nDCM interpretability limited: no visualization of learned kernel mixtures per camouflage type.\nNo runtime/inference cost reported for two-stage training."}, "questions": {"value": "How is the hint threshold (0.8) chosen? Please include a table ablating thresholds [0.6, 0.7, 0.8, 0.9].\nCan DCM kernel weights be visualized per input (e.g., texture vs. edge focus)?\nHave you tested on non-benchmark real-world data (e.g., biodiversity monitoring footage)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fMkcEFHJUi", "forum": "PRN6sitmfc", "replyto": "PRN6sitmfc", "signatures": ["ICLR.cc/2026/Conference/Submission3003/Reviewer_ujQJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3003/Reviewer_ujQJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3003/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761905099096, "cdate": 1761905099096, "tmdate": 1762916491289, "mdate": 1762916491289, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents HGT-UCOD, a novel *Hint-Guided Teacher framework* for Unsupervised Camouflaged Object Detection (UCOD). The method tackles the inherent “saliency bias” in source models (trained on salient object detection tasks) by reframing their confident outputs as *reliable hints* rather than noise. The framework includes a teacher pre-adaptation stage, a student refinement stage, and a Dynamic Convolution Mixture (DCM) module designed to enhance feature adaptivity. Extensive experiments on multiple benchmark datasets demonstrate that the proposed method achieves state-of-the-art performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Innovative Teacher Pre-Adaptation Mechanism: The paper introduces a unique *teacher pre-adaptation stage*, where a confidence-guided strategy compels the teacher to infer complete object structures from sparse yet highly reliable hints, effectively forming an “expert teacher” capable of providing stronger guidance.\n2. Superior Camouflaged Object Detection Performance: According to *Figure 2* in the paper, the proposed method significantly outperforms previous approaches in capturing fine contour details of camouflaged objects and avoids the fragmented predictions commonly seen in other methods, producing more coherent and precise segmentation results.\n3. Clear and Accessible Presentation: The paper is well-structured and clearly written, presenting the methodology and experimental findings in an organized and easy-to-follow manner that effectively communicates its core ideas and innovations."}, "weaknesses": {"value": "1. The core contribution, Teacher Model Pre-Adaptation, has questionable effectiveness. Although the paper claims that guiding the teacher model to infer full object shapes from partial but reliable information can address the inherent *“saliency bias”* and pseudo-label noise issues in UCOD, this reasoning is not sufficiently justified. Moreover, in Table 2 (Ablation Study), the improvement brought by the pre-adaptation stage seems rather limited only around 1–2% which raises doubts about its actual contribution.\n2. In Figure 2, the authors claim that the proposed method eliminates the fragmented prediction problem commonly seen in previous methods. While the visual results are indeed impressive, the paper lacks a concrete analysis or explanation of *why* this approach effectively resolves the fragmentation issue.\n3. The CHAMELEON (87) dataset, which is commonly used in related works for evaluation, was not included in the comparisons. This omission weakens the overall persuasiveness and completeness of the experimental validation."}, "questions": {"value": "My main concern lies in the first weakness, which relates directly to the paper’s core innovation and contribution. The justification and effectiveness of the *teacher pre-adaptation mechanism* are not clearly demonstrated. A more detailed explanation or theoretical analysis of why this stage helps to overcome saliency bias and noisy pseudo-labels would greatly strengthen the paper.\n\nIn addition, further exploration of the *fragmentation prediction issue* why and how the proposed method alleviates it would provide valuable insights and enhance the paper’s impact."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RfTCVNvzzw", "forum": "PRN6sitmfc", "replyto": "PRN6sitmfc", "signatures": ["ICLR.cc/2026/Conference/Submission3003/Reviewer_pf6q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3003/Reviewer_pf6q"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3003/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990932420, "cdate": 1761990932420, "tmdate": 1762916490247, "mdate": 1762916490247, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}