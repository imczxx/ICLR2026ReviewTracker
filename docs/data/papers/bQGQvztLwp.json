{"id": "bQGQvztLwp", "number": 20333, "cdate": 1758304855778, "mdate": 1759896983365, "content": {"title": "Hallucination Detection and Mitigation with Diffusion in Multi-Variate Time-Series Foundation Models", "abstract": "Foundation models for natural language processing have many coherent definitions of hallucination and methods for its detection and mitigation. However, analogous definitions and methods do not exist for multi-variate time-series (MVTS) foundation models. We propose new definitions for MVTS hallucination, along with new detection and mitigation methods using a diffusion model to estimate hallucination levels. We derive relational datasets from popular time-series datasets to benchmark these relational hallucination levels. Using these definitions and models, we find that open-source pre-trained MVTS imputation foundation models relationally hallucinate on average up to 59.5\\% as much as a weak baseline. The proposed mitigation method reduces this by up to 47.7\\% for these models. The definition and methods may improve adoption and safe usage of MVTS foundation models.", "tldr": "", "keywords": ["Multivariate Time-Series", "Foundation Model", "Hallucination", "Diffusion Model"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/eb8cb036e812761ccfa71e35abad35f48f28d77e.pdf", "supplementary_material": "/attachment/e7569d631d5c838defecd9587bfa7f1f3ce1d4a2.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates the hallucination problem in MVTS foundation models when applied to generative tasks. The authors distinguish between two types of hallucinations: distributional hallucinations and relational hallucinations. They propose a diffusion-based hallucination detection metric, termed composite error, to quantify the degree of hallucination, and design a sampling-based mitigation approach, which is validated across multiple MVTS datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This work is the first to systematically explore the hallucination problem in MVTS models from the perspective of generative modeling. The research question is novel and holds strong potential for future studies in the time-series domain.\n2. The proposed CE leverages diffusion–reverse diffusion discrepancies to measure latent distributional consistency, offering a degree of causal interpretability.\n3. The combination of detection and mitigation modules forms a closed-loop framework, demonstrating both engineering practicality and methodological feasibility."}, "weaknesses": {"value": "1. The paper lacks a theoretical explanation of the mathematical interpretability of the CE metric, as it does not derive its relationship with hallucination intensity from diffusion probability theory or an energy-based perspective.\n2. No significance testing is provided, leaving the statistical reliability of the reported results unclear.\n3. The adopted MLP-DDPM architecture lacks the capacity to model temporal dependencies.\n4. The proposed method relies heavily on the integrity of the training data; if the dataset contains noise or erroneous relationships, the CE metric may fail.\n5. The paper only compares hallucination levels across different models but does not evaluate against alternative hallucination detection methods, making it difficult to demonstrate the superiority of the CE metric."}, "questions": {"value": "1. Can the CE metric be formalized as a variant of an energy function or likelihood estimation?\n2. Is the choice of detection threshold statistically robust? Would it lead to false detections under different data distributions?\n3. How sensitive are the detection results to the number of diffusion steps T?\n4. Can relational hallucinations be validated through causal interventions, such as fixing variable dependency structures?\n5. Has the study considered comparisons with traditional out-of-distribution detection or uncertainty estimation methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "RUSJt2VBDE", "forum": "bQGQvztLwp", "replyto": "bQGQvztLwp", "signatures": ["ICLR.cc/2026/Conference/Submission20333/Reviewer_Tf5S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20333/Reviewer_Tf5S"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20333/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761754650200, "cdate": 1761754650200, "tmdate": 1762933790244, "mdate": 1762933790244, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper draws an analogy from NLP to define \"relational hallucination\" for Multi-Variate Time-Series (MVTS) Foundation Models. The core contribution is a detection method using an external diffusion model as a \"verifier.\" This verifier calculates a \"Combined Error\" (CE) metric (RMSE between the FM's output and the verifier's correction) to quantify and mitigate hallucinations in existing MVTS FMs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "( I have little experience with Time-Series Foundation Models, so my confidence score is low. I kindly ask the AC to assign a lower weight to my review. )\n\nThe paper provides a valuable conceptual contribution by defining \"hallucination\" in the MVTS context, which is critical for model reliability in scientific applications.\n\nThe creation of \"relational datasets\" with known ground-truth functions allows for a robust, quantitative validation of the proposed CE metric against the true relational error, supporting the claims."}, "weaknesses": {"value": "( I have little experience with Time-Series Foundation Models, so my confidence score is low. I kindly ask the AC to assign a lower weight to my review. )\n\nThe method's main drawback is its reliance on a dataset-specific diffusion model. This verifier must be trained for each target dataset, which increases computational overhead and undermines the zero-shot/few-shot promise of FMs.\n\nThe proposed mitigation strategy (sampling N=20 times and filtering) is a costly, brute-force approach."}, "questions": {"value": "Please refer to the previous section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "uF8JEG2wyF", "forum": "bQGQvztLwp", "replyto": "bQGQvztLwp", "signatures": ["ICLR.cc/2026/Conference/Submission20333/Reviewer_6wmR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20333/Reviewer_6wmR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20333/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762159945199, "cdate": 1762159945199, "tmdate": 1762933789473, "mdate": 1762933789473, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper “Hallucination Detection and Mitigation with Diffusion in Multi-variate Time-Series Foundation Models” addresses the absence of formal definitions and detection methods for hallucinations in multivariate time-series (MVTS) foundation models (FMs). While hallucination in NLP FMs is well studied, its equivalent in time-series contexts has not been explored. The authors introduce two key definitions—distributional hallucination, where a model’s prompt–response pair is out-of-distribution (OOD) relative to training data, and relational hallucination, where variable relationships are inconsistent with ground-truth relational functions. The paper focuses on the latter, proposing a Combined Error (CE) metric derived from diffusion models to estimate relational hallucination levels. A diffusion-based conditioning mechanism (RePaint) allows the model to “re-impute” its own outputs, comparing predictions across denoising steps to measure deviation. The authors design relational versions of common MVTS datasets (rECL, rWTH, rTraffic, rIllness, rETT) by adding synthetic relational variables (sums, differences, products, nonlinear functions). Experiments show that state-of-the-art MVTS foundation models (MOMENT, TIMER) hallucinate relationally up to 59.5% as much as a weak baseline, while the diffusion-based mitigation reduces this by up to 47.7%. Results across three task types (over-constrained, under-constrained, forecast) confirm the method’s robustness, with low overlap coefficients between low- and high-hallucination distributions (≤1% in most cases)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper provides the first formalization of hallucination in the time-series domain, making an important conceptual and methodological contribution. The definitions of distributional and relational hallucination are clearly motivated by NLP analogies yet appropriately adapted for MVTS. The proposed Combined Error (CE) metric is elegant and computationally efficient, as it reuses a diffusion model’s denoising dynamics to quantify internal consistency without requiring external labels or supervision. The authors demonstrate ingenuity by creating relational benchmark datasets (rECL, rWTH, etc.) to enable quantitative evaluation, a valuable contribution in itself. The experiments are thorough and well-documented, showing clear and interpretable metrics (Tables 1–2). The CE-based quartile thresholding method for hallucination detection is simple yet empirically effective, yielding well-separated distributions across datasets. The mitigation strategy—sampling multiple responses and selecting the one with the lowest CE—provides an effective and generalizable filtering mechanism that reduces relational error substantially across models. Methodological transparency (Section 6, Reproducibility Statement) is commendable, and the inclusion of RePaint conditioning and diffusion background ensures accessibility for non-specialist readers."}, "weaknesses": {"value": "Despite its novelty, the paper has several weaknesses limiting its theoretical depth and empirical generalizability. The diffusion-based CE metric is heuristically motivated and lacks theoretical grounding linking it to true relational error; no formal proof connects CE to hallucination likelihood beyond empirical correlation. Furthermore, the evaluation setting is limited—all relational datasets are derived from existing benchmarks by appending simple transformations, so the results may not generalize to complex domains like finance, climate, or medical forecasting. The experimental comparison is restricted to only two open-source FMs (MOMENT and TIMER), both of which are structurally different and much larger than the diffusion baseline, complicating fairness in interpretation."}, "questions": {"value": "The paper would benefit from a more rigorous theoretical connection between the CE metric and the true relational error—perhaps via a proof of monotonicity or boundedness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PEN74WrgzM", "forum": "bQGQvztLwp", "replyto": "bQGQvztLwp", "signatures": ["ICLR.cc/2026/Conference/Submission20333/Reviewer_ZwXd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20333/Reviewer_ZwXd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20333/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762240256839, "cdate": 1762240256839, "tmdate": 1762933788971, "mdate": 1762933788971, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}