{"id": "0x1a6fSSeL", "number": 16534, "cdate": 1758265648082, "mdate": 1759897234701, "content": {"title": "Modality Matters: Universal Time Series Modeling via Channel Dependency Search", "abstract": "The expanding development of wireless and mobile devices results in a proliferation of multivariate time series data, enabling various analytical tasks, e.g., forecasting, classification, and anomaly detection. Most existing time series modeling methods are dedicated to developing task-specific models due to the heterogeneous dimensionalities, resulting in inefficient resource utilization and limited cross-domain transferability. To address this issue, this study achieves a unified paradigm transcending task boundaries and proposes a universal modality-aware Time series modeling framework leveraging Channel Dependency Search named TimeCDS. Specifically, TimeCDS innovatively identifies a certain number of representative features by projecting the heterogeneous time series features into the hierarchical spaces and dynamically modeling their inter-channel relationships to alleviate the heterogeneity issue. A novel time series imaging method is then proposed to automatically introduce the image modality from sequences, facilitating the comprehensive temporal-spatial pattern extraction. Further, a dual-branch architecture is designed to process the sequential data and the visual representations simultaneously, exploiting the complementary cross-modal features through the proposed Cross-Modal Attention and Dynamic Weighted-Averaging. Extensive experiments across different analytical tasks demonstrate the consistently superior performance of TimeCDS, outperforming existing state-of-the-art baselines by up to 15.9%. The code of TimeCDS is publicly available at https://anonymous.4open.science/r/TimeCDS/.", "tldr": "", "keywords": ["Time Series Modeling", "Channel Dependency Search"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c0f182eeebaec9af4cf659301523b5813bcc7b89.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes TimeCDA, a novel framework designed to address the *heterogeneous dimensionality* problem among different channels in multivariate time series. TimeCDA introduces several key components, including a Channel Dependency Search (CDS) module and a dual-branch architecture, to model inter-channel relationships and fuse numerical and visual representations. The method is evaluated across multiple domains and benchmarks, demonstrating promising performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. While most prior works assume *channel independence*, this paper’s decision to explicitly model inter-channel relationships is refreshing and conceptually meaningful.\n2. The proposed Dual-Branch Encoding, together with CMAM and DWAM, achieves a well-balanced integration between the *numerical view* and the *visual (image-based) view* of time series."}, "weaknesses": {"value": "1. The current discussion lacks a deeper justification for why inter-channel modeling offers advantages over the dominant *channel-independent* approaches (e.g., PatchTST, TimeLLM). A detailed analysis or empirical study highlighting this superiority would strengthen the contribution.\n2. The choice of baselines could be broader. Recent strong models, such as iTransformer and N-HiTS, should be included. Additionally, works that similarly combine sequence modeling with image-based representations, such as TimeVLM and DMMV, should be discussed or compared."}, "questions": {"value": "1. The motivation for introducing the image-based encoder is not sufficiently clear. Could other architectures (e.g., LLM-based encoders) achieve similar benefits?\n2. The proposed dual-branch encoding might lead to additional computational overhead. It would be useful for the authors to include a discussion or analysis of time complexity and efficiency.\n3. Some reported numbers in Table 1 appear inconsistent with those in the cited references. Were the experiments reproduced using different input windows or settings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "P5U7F4ze0i", "forum": "0x1a6fSSeL", "replyto": "0x1a6fSSeL", "signatures": ["ICLR.cc/2026/Conference/Submission16534/Reviewer_29P7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16534/Reviewer_29P7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761446226583, "cdate": 1761446226583, "tmdate": 1762926617852, "mdate": 1762926617852, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces TimeCDS, a framework for universal time series modeling that combines temporal and spatial representations using multimodal fusion. It addresses challenges in dimensional heterogeneity and captures both temporal dynamics and spatial correlations. The framework features a unique channel dependency search for selecting representative features and a dual-branch encoding architecture. Evaluations across forecasting, anomaly detection, and classification tasks show TimeCDS outperforming existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides a clear and structured explanation of its methodology, especially the channel dependency search and dual-branch encoding.\n2. The framework outperforms state-of-the-art methods in multiple tasks, including forecasting, anomaly detection, and classification."}, "weaknesses": {"value": "1. The paper introduces many methods but does not clearly explain the motivation behind converting time series data into images. \n2. It would be beneficial to include additional experiments to verify which features image-based methods are particularly good at extracting from time series data."}, "questions": {"value": "Q1: A couple of confusion regarding channel dependency search:\n(1) I’m curious about why we specifically choose K channels. In multi-channel time series, the relationships between the channels are interconnected and serve different purposes. How can we determine that there is always one or several channels that are \"most representative\"?\n(2)  Is the number of channels, K, treated as a hyperparameter in the paper? Considering that the relationships between channels can change dynamically with events, would it make sense for K to also change over time? And could the value of K vary depending on the specific dataset or domain?\n\nQ2: I wonder what the effect of shuffling channels would be on time images encoder. Since images have inherent spatial relationships, do the channels of the multivariate time series also carry spatial significance? Given that different datasets may have channels that represent different physical meanings, would it still be reasonable to convert them into time images to capture spatial information?\n\nQ3: In Section 3.4.4, it is suggested to consider comparing TimeCDS with other image/CNN-based methods, such as the classic InceptionTime, Rocket, and others, to highlight the advantages of the proposed time image encoder.\n\nQ4: It is recommended that the figures 1,2, 3 in the paper be presented as vector images to enhance the clarity and resolution, especially for better scalability in different viewing formats."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XYUFT0Y5se", "forum": "0x1a6fSSeL", "replyto": "0x1a6fSSeL", "signatures": ["ICLR.cc/2026/Conference/Submission16534/Reviewer_8Req"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16534/Reviewer_8Req"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761934252624, "cdate": 1761934252624, "tmdate": 1762926617484, "mdate": 1762926617484, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a channel dependency search module to model time series data under a unified scenario. The proposed framework handles different tasks at the same time and empirical results show its effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Time series analysis is critical research field with solid motivation, especially under a multi-task scenario.\n2. The proposed channel aware searching is reasonable to flexibly adapt into different tasks in a unified time series modeling framework."}, "weaknesses": {"value": "1. Overall format needs significant improvement. Table is too small to read and figures are squeezed too much. They affect the readability of this draft.\n2. It is hard to tell the proposed framework is novel enough, which is more like a combination of previous methods.\n3. The term \"search\" of the proposed method is a little confusing. There is no searching operation, it is more like a graph learning concept.\n4. That will be great if the comparison methods can be referred to corresponding papers in the experimental tables."}, "questions": {"value": "Please check the above section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HKkuUpbgoG", "forum": "0x1a6fSSeL", "replyto": "0x1a6fSSeL", "signatures": ["ICLR.cc/2026/Conference/Submission16534/Reviewer_7pQD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16534/Reviewer_7pQD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762019201611, "cdate": 1762019201611, "tmdate": 1762926617028, "mdate": 1762926617028, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes TimeCDS, a universal, modality-aware framework for multi-task time-series analysis. It attempts to overcome the dimensional-heterogeneity problem across datasets by (i) selecting a fixed number of representative channels via HNSW-based channel-dependency search, (ii) converting the reduced series into an “image” representation, and (iii) fusing temporal and spatial features through a dual-branch Transformer/CNN encoder plus a cross-modal attention module. Extensive experiments on forecasting, anomaly detection and classification report consistent gains over ten or more baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "(1) Tackling heterogeneous variable counts and multiple tasks with one model is an important open problem.\n(2) Channel-dependency search with soft distance-weighted fusion is new, and the imaging pipeline (periodicity + relation matrix + phase-amplitude) is creative.\n(3) Best average MSE/MAE on 8 forecasting sets, highest F1/AUC/PATE on 5 anomaly sets, and top accuracy/F1 on 10 UEA classification sets; ablations show each module contributes.\n(4) Well-organized structure, easy-to-follow notation, comprehensive appendix."}, "weaknesses": {"value": "(1) Dual-branch Transformer+CNN with cross-attention resembles prior vision-language or multimodal models; novelty is mostly in the channel-search and imaging steps.\n(2) No justification why 20 channels suffice, no analysis of information loss after discarding N−K channels.\n(3) HNSW search + dual-branch forward pass + Cross-Modal Attention Mechanism (CMAM) is heavy; runtime/memory vs. baselines not reported.\n(4) Foundation-model baselines (Timer, UniTS) were fine-tuned on individual tasks, whereas TimeCDS uses joint pre-training on UTSD-4G; comparison is therefore slightly favorable to TimeCDS.\n(5) Only “w/o branch” and “w/o CMAM” tested; no study on patch size, imaging choices, or HNSW hyper-parameters."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bURR4LZL7f", "forum": "0x1a6fSSeL", "replyto": "0x1a6fSSeL", "signatures": ["ICLR.cc/2026/Conference/Submission16534/Reviewer_MaBJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16534/Reviewer_MaBJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762074005375, "cdate": 1762074005375, "tmdate": 1762926616567, "mdate": 1762926616567, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}