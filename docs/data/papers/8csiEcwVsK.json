{"id": "8csiEcwVsK", "number": 20951, "cdate": 1758311950030, "mdate": 1759896950114, "content": {"title": "Backdoor Vectors: a Task Arithmetic View on Backdoor Attacks and Defenses in Model Merging", "abstract": "Model merging (MM) recently emerged as an effective method for combining large deep learning models. However, it poses significant security risks. Recent research shows that it is highly susceptible to backdoor attacks, which introduce a hidden trigger into a single fine-tuned model instance that allows the adversary to control the output of the final merged model at inference time. In this work, we propose a simple framework for understanding backdoor attacks by treating the attack itself as a task vector.\n$\\textit{Backdoor Vector (BV)}$ is calculated as the difference between the weights of a fine-tuned backdoored model and the clean fine-tuned one, which reveals new insights: analogies reflect backdoor transfer, addition injects attacks, and subtraction helps to remove them. Furthermore, we propose a novel method that enhances backdoor resilience through merging dubbed $\\textit{Sparse Backdoor Vector (SBV)}$ that combines multiple attacks into a single one.\nWe identify the core vulnerability behind backdoor threats in MM: $\\textit{inherent triggers}$ that exploit adversarial weaknesses in the base model. To counter this, we propose $\\textit{Injection BV Subtraction (IBVS)}$ -- a vector-based, assumption-free defense against backdoors in MM. Our results show that SBVs surpass prior attacks by being the first to leverage merging for backdoor attacks, while IBVS provides a lightweight, general defense that remains effective even when the backdoor threat is entirely unknown.", "tldr": "We show that representing backdoors as task vectors improves the understanding of backdoor robustness in model merging, with gains in proposed more resilient attacks and a way to build task-arithmetic-based defense.", "keywords": ["backdoor attacks", "backdoor defense", "model merging", "backdoor transfer", "robustness"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7183ae7a7ab9c24f4702f1b8c2cb8f78af2c6ce5.pdf", "supplementary_material": "/attachment/426656458c02eae9980da62ac78def4ad348a975.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes viewing backdoor attacks in CLIP-based image classification as task vectors (from task arithmetic work). The paper shows that adding backdoor vectors results in more potent backdoor attacks in the context of model merging with two selected backdoor attacks: badnets and bad merging. The paper also proposes that subtracting backdoor vectors is a good defense against unknown triggers."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper presents some insights into backdoors in CLIP-based image classification tasks.\n- The paper shows that a sign-consistent merging of backdoor vectors results in better backdoor attacks (even better than no merging scenarios from the results).\n- The paper shows backdoor vectors follow task arithmetic and proposes to use subtraction as a defense."}, "weaknesses": {"value": "- The novelty of this paper may be limited. The use of task vectors in the backdoor domain is not new, as cited in the paper (BADTV).\n- The framing of backdoor vector merging is not practical. To get one backdoor vector, one needs to train one backdoor model first. It is not clear why there is a need for the attacker to train multiple backdoor models instead of training one potent backdoor model.\n- The experiments are limited, and the effectiveness of the IBVS is not clear.\n- The experiments are way less compared to the original task, arithmetic (TV), even for the image classification tasks.\nThere are only two backdoor attacks in the experiment. The paper may overclaim the generalization ability of IBVS.\n\nMinor:\n- The writing is not very coherent. The reviewer thinks the paper should focus on defense against backdoors, as it seems the best contribution of the paper.\n- The shorthands, SC, RND are not clearly defined in the paper for Algorithm 1, although the reviewer understands them as sign consistent and random.\n- Algorithms 1 and 2 are not explained in the paper."}, "questions": {"value": "- How does this paper compare to BADTV, as both of them are inspired by task vectors?\n\n- What is the target class (alone) accuracy on clean images after subtracting backdoor vectors?\n\n- In Table 3, does it mean merging is better than not merging?  Is the bad merging ASR lower than before merging (27%)?\n\n- In Table 4, are the results for the same badnets with different triggers?\n\n- The paper says addition and subtraction of BVs are not symmetric. Then what are the guarantees of the backdoor defense (IBVS)?\n\n- In Table 9, the adversary tasks from the caption are different from the ones inside the table. How do the multi-tasks work for the results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OoUWTzseVO", "forum": "8csiEcwVsK", "replyto": "8csiEcwVsK", "signatures": ["ICLR.cc/2026/Conference/Submission20951/Reviewer_zgj3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20951/Reviewer_zgj3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20951/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761706988518, "cdate": 1761706988518, "tmdate": 1762939046270, "mdate": 1762939046270, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Backdoor Vectors (BVs) as a task-arithmetic-based framework to analyze and mitigate backdoor attacks in model merging (MM). By interpreting backdoor attacks as task vectors, the authors identify key properties of attack transferability and propose two main contributions: (1) Sparse Backdoor Vector (SBV) – a method to merge multiple BVs into a more resilient backdoor, and (2) Injection BV Subtraction (IBVS) – a simple, assumption-free defense against unknown backdoors. Experiments on CLIP-based models and various datasets show that SBV strengthens attack persistence, while IBVS effectively mitigates unseen threats."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The discussion of backdoor learning in model merging is new and meaningful. This paper can provide insights to inspire future work in this field.\n- The work presents a novel conceptual framing of backdoor attacks as “task arithmetic,” providing a unified analytical view that bridges attack and defense perspectives. \n- The paper includes solid empirical validation with diverse datasets (CIFAR100, ImageNet100, TinyImageNet) and architectures (ViT, ConvNext), demonstrating effectiveness and robustness.\n- The paper is well-structured with clear mathematical formulation and illustrative figures."}, "weaknesses": {"value": "- The framework assumes linearity in task vectors, which may not hold in nonlinear regimes or across architectures, limiting the theoretical generality.\n- While IBVS is lightweight, its robustness under adaptive or multi-stage attacks is not deeply explored; more comparison with recent adversarial defenses would strengthen the claims.\n- Some sections (e.g., Section 3) are heavy on newly introduced terms (BV, SBV, BV⊕, BV⋆), which may hinder accessibility for readers outside the MM subcommunity."}, "questions": {"value": "Could the proposed BV framework be extended to language or multi-modal models beyond CLIP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pd2iX5foxo", "forum": "8csiEcwVsK", "replyto": "8csiEcwVsK", "signatures": ["ICLR.cc/2026/Conference/Submission20951/Reviewer_w4na"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20951/Reviewer_w4na"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20951/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761718717200, "cdate": 1761718717200, "tmdate": 1762939045870, "mdate": 1762939045870, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel perspective, modeling backdoor attacks as task vectors (BVs), and systematically analyzes the backdoor attack and defense mechanisms in model fusion. The authors propose two main methods:\n\n- SBV (Sparse Backdoor Vector) improves attack robustness and success rate by merging multiple backdoor vectors through sparsification.\n\n- IBVS (Injection BV Subtraction) is a lightweight defense method that suppresses unknown attacks by subtracting a fixed backdoor vector."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Treating backdoor attacks as task vectors provides a novel perspective to understand backdoor behavior.\n\n- The writing is easy to understand.\n\n- The paper considers both attacking and defending."}, "weaknesses": {"value": "- The assumption of linear additivity of task vectors is not explored in depth.\n\n- The paper only includes comparisons with BadMerging and BadNets.\n\n- No adaptive attack experiments against IBVS."}, "questions": {"value": "The idea of BV does not sound reasonable, since there are only a small number of weights contributing to backdoor behaviors, which is proven by backdoor pruning works. However, BV contains a large number of weight variations related to the main task (clean behavior). This makes BV a mixture of a highly sparse \"backdoor signal\" and a dense \"benign task noise\". \n\nIt is possible that the benign weights are similar in both backdoor and benign models, so subtracting the weights of a clean fine-tuned model from those of a backdoored fine-tuned model could ignore the benign weights. But the authors should explicitly demonstrate it. I suggest that the authors provide some experiments to analyze why BV is effective rather than only showing the attacking performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KISRwbXvDm", "forum": "8csiEcwVsK", "replyto": "8csiEcwVsK", "signatures": ["ICLR.cc/2026/Conference/Submission20951/Reviewer_Foyn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20951/Reviewer_Foyn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20951/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941093628, "cdate": 1761941093628, "tmdate": 1762939045474, "mdate": 1762939045474, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a defense that enhances backdoor resilience in the scenario of model merging (MM). The authors identify inherent triggers as the core mechanism that enables backdoor behaviors to emerge or persist after MM. To address this, the proposed approach seeks to detect and neutralize these inherent triggers before or during the merging process to improve the robustness of the resulting composite model. Different datasets and threat scenarios have been evaluated."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper is well-presented, with clear motivation and a solid background. Casting backdoors as task vectors clearly explains attack/defense behavior and transfer in model merging."}, "weaknesses": {"value": "Lack of comparison to federated learning backdoor. Although the paper frames backdoor attacks through task-vector arithmetic and discusses model merging scenarios, it does not position its contributions relative to federated learning (FL) backdoor research, which explores conceptually similar dynamics of model aggregation under adversarial updates. In FL, malicious clients can inject backdoors through model updates that also behave like additive parameter shifts—essentially “backdoor vectors” at the client level. Many existing FL backdoor defenses (e.g., clipping) already suppress these malicious update vectors. The absence of any conceptual or empirical comparison to this well-established line of work limits the broader impact of the proposed framework. The authors could strengthen their contribution by connecting Backdoor Vectors (BVs) to adversarial update vectors in federated learning and discussing how IBVS might relate to robust aggregation or update normalization strategies. Without this bridge, the novelty and generality of the proposed “task arithmetic” perspective remain somewhat isolated from the broader literature on distributed and federated backdoor threats.\n\nMissing adaptive attack evaluation. The paper does not evaluate adaptive or defense-aware backdoor attacks. An adaptive adversary could exploit the same assumptions in several ways, for example, randomizing to invalidate the “sign-consistency” heuristic in SBV. Including adaptive attacks would greatly strengthen the empirical validation and demonstrate the practical resilience of both the attack (SBV) and defense (IBVS) strategies."}, "questions": {"value": "Please discuss at least conceptually the connection with the backdoor in FL. Please discuss adaptive backdoor attacks."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hB1k8WrgV0", "forum": "8csiEcwVsK", "replyto": "8csiEcwVsK", "signatures": ["ICLR.cc/2026/Conference/Submission20951/Reviewer_ZGey"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20951/Reviewer_ZGey"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20951/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762759737845, "cdate": 1762759737845, "tmdate": 1762939044547, "mdate": 1762939044547, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}