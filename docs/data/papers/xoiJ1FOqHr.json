{"id": "xoiJ1FOqHr", "number": 7071, "cdate": 1758006662845, "mdate": 1759897874224, "content": {"title": "Softly Constrained Denoisers for Diffusion Models", "abstract": "Diffusion models struggle to produce samples that respect constraints, a common requirement in scientific applications. Existing approaches have introduced regularization terms in the loss or guidance methods during sampling to enforce such constraints, but they bias the generative model away from the true data distribution. This is a problem, especially when the constraint is misspecified, a common issue when formulating constraints on scientific data. In this paper, instead of changing the loss or the sampling loop, we integrate a guidance-inspired adjustment into the denoiser itself, giving it a soft inductive bias towards constraint-compliant samples. Through experiments, we show that these softly constrained denoisers exploit the constraint knowledge to produce compliant samples, while maintain enough flexibility to deviate from it when there is misspecification with observed data.", "tldr": "We present a method to embed differentiable constraints as inductive biases in a score matching diffusion model", "keywords": ["Diffusion Models", "Inverse Problems", "Constrained Generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c9916b39ce3831fbdbc42f4baf4c196ea65fddb8.pdf", "supplementary_material": "/attachment/95842027dadf1655030fa83a4641199432c1d62d.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes Softly Constrained Denoisers (SCD) to embed constraint knowledge directly into diffusion model denoisers via a learnable gradient-based adjustment, instead of adding explicit regularizers or inference-time guidance. This gives diffusion models a soft inductive bias toward constraint satisfaction while maintaining data fidelity and robustness to misspecified constraints. Results on toy and PDE (Darcy flow) tasks show SCD improves constraint compliance without the strong bias seen in Physics-Informed Diffusion Models (PIDM)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of integrating constraints through architecture, not loss is interesting.\n\n2. The demonstrated robustness can handle constraint misspecification adaptively.\n\n3. Minimal computational cost, drop-in compatible with standard denoisers."}, "weaknesses": {"value": "1. Although the proposed method is more flexible than traditional physics-informed regularization, it still relies on the correctness of the constraint function (for example, the residual term that encodes a physical law). If that constraint is inaccurate or incomplete, the model can still be guided in the wrong direction. The paper argues that the learnable scaling factor can help the model “ignore” bad constraints, but there is no formal guarantee that this will always happen. In highly misspecified cases, the denoiser may still learn unrealistic or unstable patterns. More importantly, PIDM can also be coupled with an adaptive weight factor to alleviate bad constraints. I do not see the inherent differences if the proposed method applies to real-world scenario. \n\n2. PIDM or PINN usually applies to scenario genuinely governed by PDE or physical laws. For PINNs or PIDMs, the constraint corresponds to a real physical model, so enforcing it makes scientific sense, even if imperfect. For SCD, the “constraint” could be arbitrary or only partially relevant to the data; so, when the data is not truly governed by a known PDE, the method’s rationale becomes weaker. \n\n3. The core formulation of the softly constrained denoiser is derived from several simplifying assumptions that are not theoretically rigorous. The authors replace complex probabilistic terms with direct gradient-based corrections and diagonal approximations. While this makes the approach practical, it weakens the theoretical grounding. As a result, it is unclear whether the denoiser still accurately represents the true underlying diffusion process or only an approximation that happens to work empirically.\n\n4. The experiments are restricted to simple two-dimensional toy problems and the Darcy flow benchmark. These are clean and controlled settings with relatively smooth constraints. The paper does not test high-dimensional, noisy, or real-world datasets. It also lacks ablations showing how different definitions of the constraint function or the scaling factor affect performance. This leaves open questions about robustness and generalization beyond the presented cases. Moreover, If SCD is designed for scenarios not entirely governed by physical laws, the experiments should reflect that. For example, weather forecasting is not entirely governed by diffusion and advection and usually needs post-hoc assimilation. There are currently no convincing experiments to reflect scenarios where physical law alone is not perfect."}, "questions": {"value": "To strengthen the paper, the authors may want to address the following questions:\n\n1. How does SCD behave with non-differentiable or discontinuous constraints?\n\n2. Can $\\gamma_\\theta$ be learned dynamically to detect and suppress harmful constraints?\n\n3. How stable is training when $r_c(x)$ provides noisy or conflicting gradients?\n\n4. Could this framework extend to hard constraints (e.g., manifold diffusion)?\n\n5. How does SCD scale with high-dimensional scientific data (e.g., 3D turbulence)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qsQdWYEEX3", "forum": "xoiJ1FOqHr", "replyto": "xoiJ1FOqHr", "signatures": ["ICLR.cc/2026/Conference/Submission7071/Reviewer_V5bD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7071/Reviewer_V5bD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760901083750, "cdate": 1760901083750, "tmdate": 1762919258659, "mdate": 1762919258659, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Softly Constrained Denoiser (SCD) proposes to embed a constraint directly into the denoiser as a guidance-style correction. Advantage against PIDM is claimed in terms of misspecification robustness and distributional bias."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "On toy example of data generation on a circle with misspecified constraints, SCD maintains low Wasserstein-1 distance (i.e., better data fidelity) while PIDM degrades as misspecification increases, indicating robustness of SCD to wrong constraints. On the Darcy Flow PDE benchmark, SCD avoids the strong distributional bias observed with PIDM."}, "weaknesses": {"value": "The theoretical idea is not sufficiently novel. The experiments are limited to a toy setup of circles and a single PDE benchmark, so external validity across other constraint types (hard equalities/inequalities, manifold constraints) is unclear, and distributional fidelity is mostly argued via histograms/qualitative plots rather than likelihood/FID score. Methodologically, the denoiser correction hinges on aggressive approximations which avoids VJPs but offers no guarantee against bias or consistency. The paper does not contain extensive theoretical analysis or sufficient experimental results to clear the high bar of ICLR."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fS8qj5BX25", "forum": "xoiJ1FOqHr", "replyto": "xoiJ1FOqHr", "signatures": ["ICLR.cc/2026/Conference/Submission7071/Reviewer_N3A7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7071/Reviewer_N3A7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761845847815, "cdate": 1761845847815, "tmdate": 1762919258310, "mdate": 1762919258310, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the problem of constraint misspecification in diffusion-based generative models. During inference, guidance typically approximates $P(x_0|x_t)$, leading to cumulative errors that significantly distort the final output distribution. On the other hand, applying direct regularization to the training loss tends to break the intrinsic connection between the denoiser and the score function, further biasing the modeled distribution. To mitigate these issues, the authors propose a softly constrained denoiser, which replaces the covariance term with a lightweight learnable scaling factor network. This design eliminates the need for expensive vector–Jacobian computations during guidance, while maintaining compatibility with standard diffusion training and sampling pipelines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper offers a new perspective on constrained distribution estimation by introducing a learnable scaling factor to replace the covariance term. This substitution effectively reduces computational complexity while preserving the structure of standard diffusion training and sampling schemes, requiring no architectural or procedural modifications."}, "weaknesses": {"value": "1. The method builds heavily on prior work, particularly on the approximation from Eq. (6) to Eq. (4), and the main contribution lies in substituting the covariance with a learnable scaling factor. While this reduces computation, it also diminishes interpretability and controllability. There is no analysis about the relationship between the scaling factor and covariance. \n\n2. The experimental section is weak. The experiments in Fig 1 and Fig 2 are performed only on toy datasets. The quantitative results in Table 2 are not compelling; the improvements are marginal and fail to convincingly demonstrate the method’s practical utility. The claimed advantages of the softly constrained denoiser in the PDE setting are not well supported by the flow-based experimental results."}, "questions": {"value": "1. The design of $r_c(x)$ and the residual function appears to be nontrivial. Could the authors provide a more systematic or generalizable recipe for constructing these functions?\n\n2. Why were there no comparisons against guided vanilla diffusion or other standard benchmark methods in the relative works to more clearly establish the benefits of the proposed approach? \n\n3. In Fig 1, 2 & 5, why don't show the results of guided diffusion?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1u1dkxHkH0", "forum": "xoiJ1FOqHr", "replyto": "xoiJ1FOqHr", "signatures": ["ICLR.cc/2026/Conference/Submission7071/Reviewer_iiNj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7071/Reviewer_iiNj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7071/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762074742477, "cdate": 1762074742477, "tmdate": 1762919257841, "mdate": 1762919257841, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}