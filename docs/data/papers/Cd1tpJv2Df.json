{"id": "Cd1tpJv2Df", "number": 517, "cdate": 1756743466911, "mdate": 1763039088257, "content": {"title": "FrePhys: Frequency-aware Diffusion Model for Remote Physiological Measurement", "abstract": "Remote photoplethysmography (rPPG) enables non-contact physiological monitoring by capturing subtle skin color variations in facial videos. Existing approaches predominantly rely on time-domain modeling to extract cardiac-related periodic signals, but they are highly vulnerable to motion artifacts and illumination changes, where physiological clues are easily obscured by noise. To address these challenges, we propose a Frequency-aware Physiological diffusion model, dubbed FrePhys, that integrates physiological frequency priors into rPPG estimation. Specifically, it first employs a \\textit{physiological bandpass filter} to suppress out-of-band noise, followed by \\textit{physiological spectrum modulation} and \\textit{adaptive spectrum selection} for in-band noise suppression and pulse-related clues enhancement. A \\textit{cross-domain representation learning} module then fuses frequency-domain insights with the deep time-domain features to capture spatial–temporal dependencies. Finally, a frequency-aware conditional diffusion process iteratively reconstructs high-fidelity rPPG signals. Extensive experiments on multiple datasets demonstrate that our method significantly outperforms existing state-of-the-art methods, particularly under challenging motion conditions, highlighting the effectiveness of incorporating frequency priors. The source code is available at \\url{https://anonymous.4open.science/r/FrePhys}.", "tldr": "A novel  frequency-aware diffusion model for remote physiological measurement", "keywords": ["remote physiological measurement"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/d12d99cd9bebacd5b62faaa8c8e3685e539a0613.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes to enhance the diffusion based rPPG deblurring by applying spectral priori to cross attention, for which 3 filters are desgined, namely, PBF, PSM, and ASS. PBF removes the spectral components outside the known band centering on the HR. PSM applies a hyper network to produce the mask at each frequency point, and ASS highlights the peak components in the spectrum by applying a given threshold. The experiments on 4 benchmarks show SOTA performance. The paper also includes mathematical proof on the uncertainy reduction caused by introduing the spectral proiri as guidance for denoising network in terms of entropy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Spectral priori is introduced in refining the diffusion process. The experiment results seem good."}, "weaknesses": {"value": "Why can the proposed innovations work is still not straightforward. The presentation could be improved."}, "questions": {"value": "The implementation of the denoising network is not mentioned. It seems Transformer due to the cross attention in Fig. 2. Yet, I cannot understand why the filtered spectrum can help refining the cross attention. You concate the MSTmap and BVP as input to diffusion, and filter MSTmap to produce the outside control to the cross attention. Can you explain why? \n\nWhy use the same QK resulting from the so-called Physiological Frequency Denoiser for two different cross attentions, say, space-frequency and time-frequency cross-attention in Fig. 2? How do you define them? The two items seem heterogeneous, and cannot be tuned using the same QK in general.\n\nIn Fig. 2. why PBF is performed more than once? Band-pass filtering can be ensured by performing only once. \n\nThe aforementioned doubts can be clarified through a couple of abaltion studies to alter input to diffusion as either BVP or MSTmap, different QK for time and frequency respectively, and applying PBF only once. \n\nWhat is the sensitivity of the hyper parameter Tao in the ASS? Any testing result?\n\nThe paper claims that the proposed method can capture both the time-domain transient and the global profile in frequency-domain. Such kind of claim should be cautious unless there is experimental evidence. \n\nTheorem 1 is well known in the textbook of signal procesing. Proof in the appendix is unnecessary.  \n\nSymbol C appears all over the paper but with different meanings. Please add definitions or clarify via statement."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rDV3zslQQZ", "forum": "Cd1tpJv2Df", "replyto": "Cd1tpJv2Df", "signatures": ["ICLR.cc/2026/Conference/Submission517/Reviewer_x3v9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission517/Reviewer_x3v9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761487488232, "cdate": 1761487488232, "tmdate": 1762915536622, "mdate": 1762915536622, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "WcwAGHQYqy", "forum": "Cd1tpJv2Df", "replyto": "Cd1tpJv2Df", "signatures": ["ICLR.cc/2026/Conference/Submission517/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission517/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763039087622, "cdate": 1763039087622, "tmdate": 1763039087622, "mdate": 1763039087622, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FrePhys, a frequency-aware diffusion model for remote photoplethysmography (rPPG) — the task of estimating cardiac-related physiological signals from face videos. Existing diffusion-based rPPG methods (e.g., PhysDiff, DiffPhys) operate purely in the time domain, which struggles with irregular noise due to motion or illumination. FrePhys instead explicitly incorporates physiological frequency priors into the denoising process, thereby unifying spectral and temporal reasoning for robust pulse estimation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Frequency-domain conditioning: FrePhys is the first diffusion-based rPPG model to explicitly embed physiological frequency priors (0.66–3 Hz band, dominant harmonic enhancement) directly into the diffusion process.\n\n- Clear physiological motivation: Grounded in cardiac spectral regularities: dominant peaks and narrowband energy, yielding interpretable and physiologically meaningful denoising.\n\n- Empirical performance: Consistently surpasses state-of-the-art baselines on intra- and cross-dataset tests for HR, HRV, and respiration rate, showing excellent robustness to motion and illumination."}, "weaknesses": {"value": "- Conceptual novelty moderate: The proposed modules (bandpass filter, modulation, thresholding) are adaptations of classical DSP principles; the main innovation lies in integration with diffusion.\n\n- Computational complexity: Frequency transforms and cross-domain attention add overhead; runtime and latency are not benchmarked, which is relevant for real-time rPPG.\n\n- Limited generalization study: Evaluation focuses on facial datasets; no validation on diverse demographics or extreme lighting conditions beyond VIPL-HR subsets. However, the CVPR 2022 “Synthetic Generation of Face Videos with Plethysmograph Physiology” dataset (Wang et al.) already provides a controlled yet demographically diverse benchmark that could be leveraged for fairer cross-subject evaluation.\n\n- FrePhys uses a diffusion model as a learned iterative denoiser for rPPG, leveraging its probabilistic noise modeling and progressive refinement ability.\nHowever, much of its success appears to come from the frequency-aware conditioning rather than diffusion itself. The diffusion backbone provides a principled yet computationally heavy scaffold; a simpler deterministic model with spectral priors might achieve similar results if trained carefully."}, "questions": {"value": "- Minor typos and formatting issues (“learnig,” “ans future work”) and overlong mathematical appendices.\n- Ethical statement could discuss bias mitigation for different skin tones or camera sensors."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HUko5TVtBA", "forum": "Cd1tpJv2Df", "replyto": "Cd1tpJv2Df", "signatures": ["ICLR.cc/2026/Conference/Submission517/Reviewer_QuCX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission517/Reviewer_QuCX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922831062, "cdate": 1761922831062, "tmdate": 1762915536445, "mdate": 1762915536445, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "his paper proposes FrePhys, a frequency-aware diffusion model for remote photoplethysmography (rPPG) that addresses the vulnerability of existing time-domain methods to motion artifacts and illumination changes by integrating physiological frequency priors. The model first employs a three-stage physiological frequency denoiser (PBF for out-of-band noise suppression, PSM for enhancing cardiac harmonics, and ASS for adaptive in-band noise removal), then fuses frequency-domain insights with time-domain features via a cross-domain representation learning module, and finally reconstructs high-fidelity rPPG signals through a frequency-aware conditional diffusion process. Extensive experiments on four public datasets (UBFC-rPPG, PURE, MMPD, VIPL-HR) demonstrate that FrePhys outperforms state-of-the-art methods in heart rate (HR), heart rate variability (HRV), and respiration frequency (RF) estimation, especially under challenging motion conditions and cross-domain scenarios, while maintaining low computational cost."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper introduces a novel and effective paradigm by seamlessly embedding physiological frequency priors into diffusion modeling, which fills the gap of underutilizing frequency-domain insights in existing rPPG diffusion methods. The hierarchical denoising design (PBF, PSM, ASS) strategically targets different types of noise, enabling robust separation of physiological signals from interference in both out-of-band and in-band frequency ranges. The comprehensive experimental evaluation, covering multiple datasets, diverse physiological indicators, and cross-domain generalization, provides strong evidence for the model’s accuracy, robustness, and practical applicability."}, "weaknesses": {"value": "1. FrePhys may still be susceptible to unseen highly dynamic or non-repetitive motion artifacts, especially those overlapping with the physiological frequency band [0.66, 3.0] Hz, which is explicitly acknowledged as a limitation in the paper and indicates room for improvement in handling such complex motion interference.\n2. Despite the adoption of accelerated training and sampling techniques, diffusion models inherently require multiple denoising iterations during inference, making FrePhys computationally heavier than traditional regression-based models and posing challenges for real-time deployment on resource-constrained devices.\n3. The paper’s experimental validation is mainly conducted on four standard public datasets (UBFC-rPPG, PURE, MMPD, VIPL-HR), but it fails to fully explore the model’s adaptability to diverse special populations (e.g., children or the elderly with different physiological frequency ranges) or extreme real-world lighting conditions, leaving the model’s versatility in broader practical scenarios insufficiently verified."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "qQh41t0Pl1", "forum": "Cd1tpJv2Df", "replyto": "Cd1tpJv2Df", "signatures": ["ICLR.cc/2026/Conference/Submission517/Reviewer_hn9t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission517/Reviewer_hn9t"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967877795, "cdate": 1761967877795, "tmdate": 1762915536306, "mdate": 1762915536306, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper propose a frequency-aware diffusion model for remote PPG estimation from face videos. Results on UBFC, PURE, VIPL-HR, and MMPD show state-of-the-art heart rate and HRV performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- We can see strong empirical performance and broad evaluation across four public datasets.\n- The architecture is good, there is a clear problem framing, and thorough experiments.\n- The frequency-domain motivation is sound and supported by good visual analysis.\n- Cross-dataset tests and HRV/RF metrics are nice to have.\n- There is sufficient figures, ablations, reproducibility, dataset coverage which makes paper easy to read and contributions well articulated."}, "weaknesses": {"value": "- The novelty of the paper is limited. Frequency filtering, spectral masking, and Fourier-domain losses are well-explored in rPPG and signal processing. Embedding them inside a diffusion framework is logical, but not very theoretical or conceptual per se.\n- The work is heavily on the engineering side and module stacking rather than a new principle that is theoretically grounded.\n- Some claims (“rethinks how frequency information is used in rPPG”) are probably too much of a hype. In reality, what we have is a straightforward pipeline extension.\n- The paper does not deeply analyze why diffusion + frequency priors beat simpler architectures. The results hence are mostly empirical.\n- There is a little heavy compute and training complexity. On the other side, even with heavy complexity, there is a less conceptual advancement.\n- It is not clear whether diffusion is needed or not here. A non-diffusion frequency-aware baseline could also close the gap?"}, "questions": {"value": "- Could a simpler time-freq network (e.g., transformer + spectral attention + freq-loss) achieve similar gains?\n- Is the bandpass + adaptive mask really learnable necessity, or is this hand-designed DSP with training bolted on?\n- Why diffusion versus denoising autoencoder or score-based model? What unique benefit does diffusion provide?\n- How sensitive is the approach to sampling rate, ROI extraction steps, or dataset frequency bias?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "z1HNuJtFVy", "forum": "Cd1tpJv2Df", "replyto": "Cd1tpJv2Df", "signatures": ["ICLR.cc/2026/Conference/Submission517/Reviewer_h8F5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission517/Reviewer_h8F5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission517/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762027914452, "cdate": 1762027914452, "tmdate": 1762915536150, "mdate": 1762915536150, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}