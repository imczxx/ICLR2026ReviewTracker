{"id": "bbmcIaEmJG", "number": 11180, "cdate": 1758192240413, "mdate": 1763396902370, "content": {"title": "GDR-learners: Orthogonal Learning of Generative Models for Potential Outcomes", "abstract": "Various deep generative models have been proposed to estimate potential outcomes distributions from observational data. However, none of them have the favorable theoretical property of general Neyman-orthogonality and, associated with it, quasi-oracle efficiency and double robustness. In this paper, we introduce a general suite of generative Neyman-orthogonal (doubly-robust) learners that estimate the conditional distributions of potential outcomes. Our proposed generative doubly-robust learners (GDR-learners) are flexible and can be instantiated with many state-of-the-art deep generative models. In particular, we develop GDR-learners based on (a) conditional normalizing flows (which we call GDR-CNFs), (b) conditional generative adversarial networks (GDR-CGANs), (c) conditional variational autoencoders (GDR-CVAEs), and (d) conditional diffusion models (GDR-CDMs). Unlike the existing methods, our GDR-learners possess the properties of quasi-oracle efficiency and rate double robustness, and are thus asymptotically optimal. In a series of (semi-)synthetic experiments, we demonstrate that our GDR-learners are very effective and outperform the existing methods in estimating the conditional distributions of potential outcomes.", "tldr": "we introduce a general framework of generative Neyman-orthogonal (doubly-robust) meta-learners that target at the covariate-conditional distributions of potential outcomes (GDR-learners)", "keywords": ["causal machine learning", "orthogonal learning", "deep generative models", "potential outcomes estimation"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c7c796d83ef465d584adc4f1b06e42fc16c8e57f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces GDR-Learners (Gradient Disentangled Regularization Learners), a framework for causal representation learning that enforces gradient-based orthogonality among latent variables. The key idea is to regularize the model such that the gradients of reconstructed inputs with respect to different latent dimensions are orthogonal, promoting disentanglement between the causal mechanisms encoded in each latent. Theoretical analyses suggest that under mild assumptions, this orthogonality constraint helps achieve identifiable and disentangled representations up to monotone transformations. Empirical results on standard disentanglement benchmarks show consistent improvements over state-of-the-art baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles an important challenge in causal representation learning: achieving identifiable and interpretable factors without strong structural assumptions.\n2. The proposed GDR term is simple to compute, model-agnostic, and can be seamlessly added to a wide range of encoder–decoder architectures.\n3. Experimental results show that the method improves disentanglement scores across several datasets and remains robust when combined with other regularization terms."}, "weaknesses": {"value": "1. While the paper provides some intuitive propositions, it does not establish a formal link between gradient orthogonality and causal identifiability. The theoretical results remain qualitative and lack proofs that guarantee uniqueness or sufficiency for disentanglement.\n2. The paper mainly compares against unsupervised disentanglement models (β-VAE, FactorVAE, etc.) but omits direct comparison with causal representation learners such as iVAE or CausalVAE, which share similar objectives and stronger theoretical grounding.\n3. The evaluation focuses entirely on disentanglement metrics. There is no demonstration that GDR-learners improve causal inference capabilities.\n4. The gradient regularization term introduces additional computation and hyperparameters (e.g., λ). The paper does not provide runtime analysis or ablations to assess stability and sensitivity across hyperparameter choices."}, "questions": {"value": "See Weaknesses Part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ak0w9gF1XN", "forum": "bbmcIaEmJG", "replyto": "bbmcIaEmJG", "signatures": ["ICLR.cc/2026/Conference/Submission11180/Reviewer_VATR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11180/Reviewer_VATR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11180/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761479699495, "cdate": 1761479699495, "tmdate": 1762922335867, "mdate": 1762922335867, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This proposes to employ conditional deep generative models for estimating the conditional distribution of a potential outcomes in a causal framework for conditional outcomes.  The key contributes lies in an estimation procedure (with appropriate objective functions) that guarantees  the general Newman-orthogonality constraints.  They also provide some theoretical guarantees by establishing the Quasi-oracle efficiency and double robustness."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "+propose a class of deep generative models for modeling the conditional distribution of the potential outcomes that satisfy the Neyman-orthogonality and establish quasi-oracle efficiency and double robustness of the learners \n\n+ the paper is well-written with very clear presentations (e..g, the graphical presentation in Figure 3 is extremely helpful) \n\n+a thorough numerical study is included"}, "weaknesses": {"value": "-in my opinion, the key contribution lies in the formulation of the objective functions that ensures the Neyman-orthogonality (as given by equation (7)). This is not a strong weakness per say, but the degree of novelty is somewhat in question \n\n-given equation (9), one should further discuss the rates of the error based on the various conditional deep generative estimators, utilizing an existing  literature on theory and convergence rates of conditional VAE, conditional discussion models and. so on. \n\n\n- \n\n-"}, "questions": {"value": "Q1: can you provide more intuition and explanation of the bias correction of RA learner behind equation (7)? First glance, it weights the RA and IPTW learners. \n\nand a quick comment: GDR. should be defined the first time it was introduced ( in the abstract)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "s3JTs3XBEj", "forum": "bbmcIaEmJG", "replyto": "bbmcIaEmJG", "signatures": ["ICLR.cc/2026/Conference/Submission11180/Reviewer_fv3L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11180/Reviewer_fv3L"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11180/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982380776, "cdate": 1761982380776, "tmdate": 1762922335294, "mdate": 1762922335294, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes GDR-learners, a general two-stage framework for estimating the conditional distributions of potential outcomes from observational data using deep generative models. The key idea is to combine estimates of conditional distributions of potential outcomes with a doubly robust, Neyman-orthogonal target loss so that errors in estimation do not affect the second-stage objective to first order. The framework is model-agnostic and can be instantiated with conditional normalizing flows, GANs, VAEs, and diffusion models. The authors claim quasi-oracle efficiency and rate double robustness in theory, and report empirical gains over plug-in, RA, and IPTW alternatives on synthetic and semi-synthetic benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method and objective is model-agnostic and applicable to multiple generative models, including CNF, CGAN, CVAE.\n2. The proposed framework is able to computer conditional distribution of potential outcomes.\n3. Empirical results show improved performance compared with other models."}, "weaknesses": {"value": "1. Some theoretical conditions (“mild model-dependent convexity and positivity”) are not fully unpacked. The identifiability condtion i - iii are not clear.\n2. The proposed method show show very large reported standard deviations in some datasets, such as HC-MNIST. Is this considered as instability. Or some other reason?\n3. In additional to the median out-sample w2+std results, it is necessary to report the worst case (e.g., max difference between the estimated distribution and the truth) estimation results. This result will show the performance under failure modes."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "BE6ZrgxjYP", "forum": "bbmcIaEmJG", "replyto": "bbmcIaEmJG", "signatures": ["ICLR.cc/2026/Conference/Submission11180/Reviewer_ebKH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11180/Reviewer_ebKH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11180/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762058864312, "cdate": 1762058864312, "tmdate": 1762922334679, "mdate": 1762922334679, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose an approach to generate/model potential outcomes using deep generative models such as diffusions, GANs etc in a wya that preseves the neyman orthogonality property, which allows for double robustness and efficient semiparametric type guarantees."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Originality: The ideas in the paper are original and non-trivial in my opinion. \nSignificance: Causal ML and Neyman Orthogonality are certainly \"hot\" topics as of late, and bringing that together with deep generative models is a timely contribution that I find significant enough to meet the bar for ICLR. \nClarity: The clarity/presentation style of the paper is something that needs some minor improvement. I think the expert will have no trouble understanding the paper, but for a general ML/AI audience this paper will be a rather difficult read. \nQuality: the quality and soundness of the math/theory portions of the paper is high. I find the arguments to be well reasoned and to the best of my knowledge, sound. The authors also performed some experiments which I find sufficient for this paper."}, "weaknesses": {"value": "Clarity of presentation and accessibility of writing are the biggest areas that this paper can improve on. I highlight some aspects of this below. \n\n1. GDR, Neyman Orthogonality, Double robustness etc are the core concepts that underlie and motivate this paper. Yet, neyman orthogonality was not formally defined until page 6 of the paper (inside a theorem, and then more formally in the appendix), and double robustness, quasi-oracle efficiency etc are nowhere formally defined in the main text (high level explanations in 2nd page and formal definitions only given in the appendix). this is understandable given space constraints, but I believe some more formal/rigorous explanation of these terms in the beginning of the main text is *absolutely required*. These are not part of the standard training/vocabulary of a typical ICLR or general AI/ML reader, and clarifying these terms will help broaden the reach of the paper to a more general audience. \n\n2. There are important references (canonical, even) that this paper seems to have missed. Many examples in econometrics come to mind, with the double machine learning paper by Chernozhukov et al and related semiparametric efficiency papers (e.g. Whitney Newey) not mentioned. There are too many references to be listed here. I suggest giving more proper reference to the econometrics literature."}, "questions": {"value": "1. Typically, one thinks of these DR/Neyman orthogonal approaches are using ML to nonparametrically handle a nuisance with the bigger goal to infer a finite dimensional parameter of interest, in a way that the slow convergence of the nonparametric part doesn't affect the nice properties of the finite dimensional inference on the parameter.  In your case, the parameter of interest appears to be the CDPOs, which themselves are nonparametrically generated. In this case, one can reasonably think that learning the CDPOs themselves might be a more difficult problem than learning the nuisance, which calls into question the value of double robustness/quasi oracle efficiency in this setting. For example ,what if the rate of learning the CDPOs is even slower than estimating the nuisance? \n\n\nMinor points: the abbreviation GDR is used in the abstract before definition"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "d3lpeswYox", "forum": "bbmcIaEmJG", "replyto": "bbmcIaEmJG", "signatures": ["ICLR.cc/2026/Conference/Submission11180/Reviewer_UrWJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11180/Reviewer_UrWJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11180/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762428898471, "cdate": 1762428898471, "tmdate": 1762922334164, "mdate": 1762922334164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Rebuttal"}, "comment": {"value": "We are grateful for the reviews of our paper, as well as the constructive and helpful comments!  We addressed all of your comments below. We also uploaded a **revised version of our paper**, where we highlight key changes colored in $\\color{blue}{\\text{blue}}$).\n\nHere are our main improvements: \n- **Additional high-dimensional benchmark**. To further evaluate our GDR-learners in high-dimensional settings, we adopted the colored MNIST dataset (i.e., a benchmark with high-dimensional outcomes). We reported the results in a **new paragraph in Sec. 6** and a **new Appendix E.5**. In the new experiments, _our GDR-learners consistently outperform other meta-learners for the majority of the generative models_.\n- **Additional insights**. We added new discussions on the practical relevance of  \n   - (i) the mildness of the conditions required for Theorem 2 (see **updated Sec. 5.1** and a **new Remark 1 in Appendix C**).  \n   - (ii) the rates of the convergence of the conditional generative models (see **updated Sec. 5.1**).\n- **Improved clarity**. We have moved some key definitions to the main part of the paper (e.g., Neyman-orthogonality and quasi-oracle efficiency). We also added more references to classical semi-parametric inference and orthogonal learning  (e.g., double ML). Furthermore, we added more explanations about the intuition behind the one-step bias correction.\n\nWe are confident that the feedback has greatly improved the quality of our paper, and we believe that the paper is a good fit for the ICLR 2026 conference."}}, "id": "LRUazsXUnn", "forum": "bbmcIaEmJG", "replyto": "bbmcIaEmJG", "signatures": ["ICLR.cc/2026/Conference/Submission11180/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11180/Authors"], "number": 9, "invitations": ["ICLR.cc/2026/Conference/Submission11180/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763398201237, "cdate": 1763398201237, "tmdate": 1763398201237, "mdate": 1763398201237, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}