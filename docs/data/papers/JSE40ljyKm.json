{"id": "JSE40ljyKm", "number": 5590, "cdate": 1757921660891, "mdate": 1759897966004, "content": {"title": "Predicting LLM Reasoning Performance with Small Proxy Model", "abstract": "Given the prohibitive cost of pre-training large language models, it is essential to leverage smaller proxy models to optimize recipes before scaling up. However, this approach becomes challenging for reasoning capabilities, which exhibit \\textit{emergent} behavior that only appears reliably at larger model sizes, often exceeding 7B parameters. To address this, we introduce \\tsc{rBridge}, showing that small proxies ($\\leq$1B) can effectively predict large-model reasoning by aligning more closely with \\textbf{(1)} the pre-training objective and \\textbf{(2)} the target task. \\tsc{rBridge} achieves this by weighting negative log-likelihood with task alignment, using reasoning traces from frontier models as gold labels. In our experiments, \\tsc{rBridge} \\textbf{(i)} reduces dataset ranking costs by over 100$\\times$ relative to the best baseline, \\textbf{(ii)} achieves the strongest correlation across six reasoning benchmarks at 1B to 32B scale, and \\textbf{(iii)} transfers predictive relationships across pre-training recipes at 1B to 7B scale. These findings indicate that \\tsc{rBridge} offers a practical path for exploring reasoning-oriented pre-training at lower cost.", "tldr": "We enable small proxy models to reliably predict large model reasoning performance using next-token prediction on reasoning traces with task-aligned weighting, dramatically reducing pre-training recipe search cost.", "keywords": ["Language Models", "Pre-training", "Reasoning", "Evaluation", "Efficiency"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6ec7ba723e11f810cd6cc62fd51bd8b02fdf6acf.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper offers an improved method for predicting large language model performance on reasoning tasks using results from smaller proxy models. RBridge is an elegant solution. First, reasoning traces from a frontier model are extracted for some benchmark dataset. Second, the negative log-likelihood of each token in the reasoning trace is computed using a small proxy language model. Finally, this token-wise NLL is weighted by MinMax normed average probability of each character in that token, as defined by the frontier model. This produces a weighted negative log-likelihood of the reasoning trace. The authors show that this value ranks and predicts performance of larger models. \n\nIn the first experiment, they train small proxy models and large target-size models on 25 different datasets. They compute the agreement (Decision Accuracy) between the rankings of which dataset leads to better performance (on specific benchmarks) for the proxy models and for the target models. They show that they outperform other methods for ranking datasets and incur a significant compute saving.\n\nIn the second experiment, they show that the RBridge value (weighted NLL) for proxy models at different stages of training is strongly correlated with and predictive of the performance of much larger models.\n\nIn the third experiment, they show that fitting a function to predict accuracy given the RBridge value (weighted NLL) based on one dataset, transfers seamlessly to predicting performance for a model trained on an entirely different dataset.\n\nOverall, this work offers an innovative and powerful new metric for optimising pre-training datasets through the use of small proxy models. This will be very useful to the community for improving LLM pre-training efficiently, because they can iterate on different training regimes using a small model, with the knowledge that they can predict the performance of much larger models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "The paper has many strengths:\n* The motivation and methodology are well thought through and sound.\n* The empirical work is diligent and complete. I commend the authors on the number of training and testing runs they must have performed to complete this project.\n* The results are very impressive. The efficiency gain from using RBridge compared to other methods is considerable and will greatly accelerate the development of optimal pre-training datasets for large-scale reasoning models."}, "weaknesses": {"value": "There are only a few minor weaknesses with the paper at the moment:\n1. The authors miss some important literature on predictable AI and the use of assessor models for predicting model performance on unseen tasks. I include relevant references at the bottom.\n2. The writing is quite rough in several areas. I outline the key spelling/syntax problems below. I would recommend going over the whole paper to check for sense and grammaticality.\n3. I would include the limitations and future directions section in the main text, given the extra page.\n4. The authors are right to point out that obtaining the reasoning traces from frontier models is an extra cost and may be imperfect. I would definitely like to see the authors make their datasets public upon publication.\n5. This is not really a weakness, but the authors could emphasise more that their results really mean that LLM development can *greener*. Right now, iterating over different data regimes uses a lot of energy, which their method can help to reduce if the community makes use of RBridge.\n\n\n## Missing References\n\nKipnis, A., Voudouris, K., Buschoff, L. M. S., & Schulz, E. (2024). metabench--A Sparse Benchmark of Reasoning and Knowledge in Large Language Models. arXiv preprint arXiv:2407.12844.\n\nPacchiardi, L., Voudouris, K., Slater, B., Martínez-Plumed, F., Hernández-Orallo, J., Zhou, L., & Schellaert, W. (2025). PredictaBoard: Benchmarking LLM score predictability. arXiv preprint arXiv:2502.14445.\n\nPrudêncio, R. B., Lorena, A. C., Silva-Filho, T., Drapal, P., & Valeriano, M. G. (2024, June). Assessor models for explaining instance hardness in classification problems. In 2024 International Joint Conference on Neural Networks (IJCNN) (pp. 1-8). IEEE.\n\nSchellaert, W., Martínez-Plumed, F., & Hernández-Orallo, J. (2025). Analysing the predictability of language model performance. ACM Transactions on Intelligent Systems and Technology, 16(2), 1-26.\n\n\n## Spelling/Syntax\n\nApproximation line numbers followed by the corrected sentence.\n\nLine 36: \"suggests that there may be a limit...\"\nLine 88: \"To bridge the evaluation scheme between small proxy models to large target-scale models...\"\nLine 94: \"We improve task alignment at ....\"\nLine 95 and the enumerated list: This needs to be fully revised for sense. It should start with \"We empirically validate our method in the following five ways:\" and then each number should be a full sentence.\nLine 269: \"which demonstrates that including an SFT stage...\"\nLine 286: \"can help target metric Acc./p@1 to be used as signals\"\nLine 286-7: The sentence on TED oes not make sense to me.\nLine 289: \"Last is ScB which visualizes...\"\nLine 299: \"respectively\""}, "questions": {"value": "* Are letter-level probabilities within each token conditional on the previous characters/tokens?\n* The performance of $R^\\phi$ alone is surprisingly high (e.g., in Table 2). Why bother with the extra hassle of character-wise tokenization etc.? What argument can the authors make about the meaningfulness of the difference in performance between $R^\\phi$ and RBridge? To some, these differences might look negligible."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Vz230rrMlN", "forum": "JSE40ljyKm", "replyto": "JSE40ljyKm", "signatures": ["ICLR.cc/2026/Conference/Submission5590/Reviewer_KWnN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5590/Reviewer_KWnN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5590/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761308076604, "cdate": 1761308076604, "tmdate": 1762918150528, "mdate": 1762918150528, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to reliably estimate the reasoning capabilities of large LLMs using small proxy models. \nThe paper shows that, as the reasoning capability is an emergent property of large LLMs, the vanilla loss obtained from small models can be noisy.\nThere are two key limitations identified: (i) evaluation objective misalignment (e.g., NLL loss v.s. pass@K, and off-policy Y distribution ) (ii) task alignment and at the token-level (e.g., important tokens like branching/searching/backtracking should be taken into consideration)\n\nThe proposed rBridge tackles the limitations via (i) using a reasoning trace generated by frontier models as a proxy of Y and (ii) the loss is weighted according to the normalized log-probs of the frontier model, where the potential tokenization mismatch issue is tackled by using the character-level average.\n\nExperimental results show the proposed rBridge successfully predicts the model performance using much smaller proxy models (< 100M) for a 1.2B target model. The correlation stays strong when using the 1B model to predict 13B/32B models and shows promising transferability across pre-training datasets."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The investigated problem is of great practical value, reducing the computational cost for training large-scale LLMs.\n- The rBridge is generally effective and easy to implement, with details well covered."}, "weaknesses": {"value": "- While the papers examine the choices of frontier models in the appendix (i.e., no meaningful difference), I am still concerned about whether the quality of the reasoning trajectories would influence the estimation. As frontier models remain a black box, it is challenging to understand the underlying training distribution. Would the prediction performance degrade significantly if the reasoning benchmarks are OD even for those frontier models?\n- The weighted NLL is not ablated. How much does it contribute to the final prediction performance?"}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3QJSFpMshr", "forum": "JSE40ljyKm", "replyto": "JSE40ljyKm", "signatures": ["ICLR.cc/2026/Conference/Submission5590/Reviewer_v8sd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5590/Reviewer_v8sd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5590/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761793220042, "cdate": 1761793220042, "tmdate": 1762918149966, "mdate": 1762918149966, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces RBRIDGE, a method for predicting large language model reasoning performance using small proxy models (≤1B parameters) by aligning evaluation with both the pre-training objective and the target task. RBRIDGE leverages reasoning traces from frontier models as gold labels and introduces a weighted negative log-likelihood metric that emphasizes task-critical tokens, achieving strong correlations across six reasoning benchmarks and reducing dataset ranking costs by over 100×. It further demonstrates zero-shot transfer of predictive relationships across pre-training datasets, enabling efficient performance estimation at large scale."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The discussed problem is both intellectually engaging and practically important for advancing efficient LLM development.\n\n2. The proposed RBRIDGE metric shows strong performance, achieving high correlation with large-model reasoning while greatly reducing computational costs."}, "weaknesses": {"value": "1. The paper shows small models struggle with noisy tasks but doesn't clearly explain how to identify which datasets are noisy—more analysis on dataset characteristics would help.\n\n2. The frontier model choice matters: models like R1 and GPT-4o differ in style and training data, which could affect reasoning trace quality and RBRIDGE’s consistency.\n\n3. RBRIDGE is tested on math and QA tasks, but performance may differ on code (e.g., LiveCodeBench) or subjective tasks (e.g., Arena-Hard), where reasoning patterns vary.\n\n4. Figure 5(b) illustrates RBRIDGE’s strong fit, but similar plots on other benchmarks would strengthen the empirical support.\n\n5. Minor typos need fixing, e.g., “is becomes” in Figure 1’s caption.\n\n6. The paper exceeds 9 pages, which violates the rule."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "o0vFSA5Kcp", "forum": "JSE40ljyKm", "replyto": "JSE40ljyKm", "signatures": ["ICLR.cc/2026/Conference/Submission5590/Reviewer_bXEE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5590/Reviewer_bXEE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5590/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761806666730, "cdate": 1761806666730, "tmdate": 1762918149652, "mdate": 1762918149652, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new method to use a small proxy model to predict the reasoning performance of LLM. It uncovers that existing methods don’t work well because they fail to align with the pre-training objective and the target task. To address the limitations, the proposed method uses frontier-model generated gold reasoning traces for better alignment. Experimental results demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ using frontier-model generated gold reasoning traces for better alignment\n+ significantly improved performance in terms of compute cost, proxy model size, and zero-shot transferring from one pre-trained dataset to another"}, "weaknesses": {"value": "- needs a frontier-model to generate gold reasoning traces, making the proposed method less useful\n- it is unclear how the small proxy models less than <100M work so well"}, "questions": {"value": "How was the compute cost measured? Is it measured in a real system or just calculated by the model size? What are the system (hardware and software) settings if a real system was implemented? Using the proposed method, can a larger proxy model work better and how much better than a smaller proxy model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "5txiWy2vnW", "forum": "JSE40ljyKm", "replyto": "JSE40ljyKm", "signatures": ["ICLR.cc/2026/Conference/Submission5590/Reviewer_4B33"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5590/Reviewer_4B33"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5590/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762000780893, "cdate": 1762000780893, "tmdate": 1762918149416, "mdate": 1762918149416, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}