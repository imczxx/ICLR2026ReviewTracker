{"id": "Srs2hqLfjR", "number": 15757, "cdate": 1758254931059, "mdate": 1759897284096, "content": {"title": "High-Dimensional Hettmansperger-Randles Estimator and Its Applications", "abstract": "The classic Hettmansperger-Randles estimator has found extensive use in robust statistical inference. However, it cannot be directly applied to high-dimensional data. In this paper, we propose a high-dimensional Hettmansperger-Randles estimator for the location parameter and scatter matrix of elliptical distributions in high-dimensional scenarios. Subsequently, we apply these estimators to two prominent problems: the one-sample location test problem and quadratic discriminant analysis. We discover that the corresponding new methods exhibit high effectiveness across a broad range of distributions. Both simulation studies and real-data applications further illustrate the superiority of the newly proposed methods.", "tldr": "", "keywords": ["Hettmansperger-Randles estimator", "High-dimensional data", "One-sample location test problem", "Quadratic discriminant analysis", "Spatial-sign"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f0ccb04b980c43509218faf89c5f161b970c3ddc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a high-dimensional version of the Hettmansperger-Randles (HR) estimator for the location parameter and scatter matrix under elliptical distributions. The core adaptation for high-dimensional settings lies in Algorithm 2, specifically Step 3, which introduces the normalization $\\widehat{\\Sigma} \\leftarrow \\tfrac{p\\widehat{\\Sigma}}{tr(\\widehat{\\Sigma})} $ and the operator $\\mathcal{B}_h(\\cdot)$. The authors further demonstrate the statistical utility of this estimator by applying it to two classic high-dimensional problems: the one-sample mean test problem and quadratic discriminant analysis, supported by detailed asymptotic theory and comprehensive experimental comparisons."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "*   **Solid Theoretical Foundation:** The work is built upon the well-established HR estimator framework, which is affine equivariant and offers robustness (Elliptical Distribution).\n*   **Relevant High-Dimensional Applications:** Applying this robust estimator to fundamental high-dimensional problems like mean testing and QDA is highly relevant and demonstrates practical value.\n*   **Comprehensive Evaluation:** The paper includes thorough theoretical analysis (asymptotic theory) and empirical validation through experiments, which is commendable."}, "weaknesses": {"value": "*   **Algorithmic Description Lacks Rigor:** The description of the algorithms is not precise enough. Key details are missing, making it difficult to understand or reproduce the methods. For instance:\n    *   It is unclear how $\\widehat{\\Sigma}^{-1/2}$ is computed. If a method like the Sparse Graphical Lasso (SGLASSO) is used, the process for hyperparameter tuning is not mentioned.\n*   **Unverified Assumptions:** The methodology seems to rely on the assumption that the elliptical distribution is non-degenerate, and its validity or impact in this context is not discussed.\n*   **Incomplete Experimental Analysis:** The experimental section lacks certain standard analyses for statistical tests and classifiers, such as:   Analysis under different signal strengths."}, "questions": {"value": "1.  The algorithmic descriptions need clarification. Specifically, how is $\\widehat{\\Sigma}^{-1/2}$ practically computed? If SGLASSO or a similar method is employed, how are the corresponding hyperparameters selected or tuned?\n2.  The authors claim their \"approach achieves robustness with respect to the sparsity of $\\widehat{\\Sigma}^{-1/2} \\mu$.\" How should this form of \"sparsity\" be interpreted? Are there real-world examples or references that illustrate or motivate the relevance of sparsity in this specific transformed mean $\\widehat{\\Sigma}^{-1/2} \\mu$.\"?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3otCmrdx8i", "forum": "Srs2hqLfjR", "replyto": "Srs2hqLfjR", "signatures": ["ICLR.cc/2026/Conference/Submission15757/Reviewer_Tnby"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15757/Reviewer_Tnby"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15757/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760951994233, "cdate": 1760951994233, "tmdate": 1762925990452, "mdate": 1762925990452, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper develops a high-dimensional Hettmansperger-Randles (HR) estimator that jointly estimates location and scatter under elliptical models while preserving affine equivariance and robustness, offering a practical alternative where Tyler's M-estimator can be ill-defined for $p>n$. Building on this estimator, the authors establish a Gaussian approximation for standardized spatial statistics and prove the asymptotic independence between sum-type ($L_2$) and max-type ($L_{\\infty}$) statistics, thereby providing a principled basis for a Cauchy combination that adapts to both sparse and dense alternatives. Methodologically, the work introduces robust tests (TSUM and TMAX) and an adaptive combined test that maintains power across heterogeneous regimes. HR-based standardization enables reliable inference under heavy-tailed and mixture distributions, achieving valid size control and competitive power. The implementation is practical, employing lightweight bootstrap calibration and scalable strategies such as banding and sparse precision estimation. Beyond testing, the framework extends to robust quadratic discriminant analysis (HRQDA) with a consistency result for the misclassification rate. Simulations and a real-data example support the theory, demonstrating accurate type-I error control and improved detection power relative to covariance-based baselines. Overall, the paper offers a coherent path from theory to algorithms and applications with attention to reproducibility."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper extends the Hettmansperger-Randles (HR) estimator to high-dimensional settings so that location and scatter can be estimated jointly in a robust manner while preserving affine equivariance (invariance under linear transformations). This provides a practical and principled alternative in cases where Tyler's estimator tends to be ill-defined when $p>n$.\n\nThe authors establish a Gaussian approximation for standardized statistics and show that sum-type ($L_2$) and max-type ($L_{\\infty}$) statistics are asymptotically independent. These results place the Cauchy combination on firm theoretical ground, enabling an adaptive testing procedure that maintains power under both sparse and dense alternatives. On the implementation side, the testing pipeline (TSUM/TMAX with the Cauchy combination) employs lightweight bootstrap calibration to correct finite-sample bias, keeping computation manageable.\n\nHR-based standardization delivers valid size control and strong power under heavy-tailed and mixture distributions, where outliers are common. The framework is further extended to classification via a robust quadratic discriminant analysis (HRQDA), with a consistency result for the misclassification rate. Simulation studies and a real-data example indicate improved type-I error control and detection power compared with covariance-based baselines. Overall, the paper connects theory, algorithms, and applications in a transparent and reproducible way."}, "weaknesses": {"value": "**Dependence on elliptical distributions (explicitly acknowledged by the authors)**: \n   The main results rely substantially on the elliptical family—specifically the approximation (p^{-1}\\hat S \\approx I_p) that motivates Step 3 banding in the high-dimensional HR algorithm (Sec. 2; Algorithm 2; definition of B_h). As explicitly noted by the authors (Conclusion), relaxing this assumption is left for future work. The manuscript does not yet articulate minimal conditions under which the Gaussian approximation and asymptotic independence would continue to hold in non-elliptical settings.  \n\n**No explicit contamination experiments**: \n   Robustness is examined through heavy-tailed and mixture distributions (multivariate normal, (t_3), and mixture normal) in Sec. 4 Simulation, but there are no experiments with explicit epsilon-contamination or cellwise contamination. Figure 2 reports power curves for the Cauchy combinations under the three elliptical settings.  \n\n**Lack of IF/BDP analysis for high-dimensional HR**:\nThe paper does not provide an analysis of the influence function and the breakdown point for the high-dimensional approximate procedure. This procedure is described in Algorithm 2. It applies banding to the covariance estimator and then uses regularization to estimate the precision matrix. The authors do not claim this result, so it is not a flaw relative to the stated goals. Still, given the emphasis on robustness, the absence of IF and BDP theory is a limited weakness and leaves a clear theoretical gap.\n\n**Limited sensitivity analysis and practical guidance**: \n   Systematic evidence on performance–compute trade-offs with respect to the banding width h, regularization strength, and the number of bootstrap iterations is limited. The paper commonly uses h=3 (Table 5 in Appendix C) and states that M=50 bootstrap iterations suffice for bias correction in sum/max tests."}, "questions": {"value": "**Non-elliptical extensions**: *(noted by the authors as future work)*: \n   Could you specify minimal sufficient conditions under which the Gaussian approximation for the sum-type statistic and the asymptotic independence between the sum-type and max-type statistics continue to hold beyond the elliptical family? For example, near-spherical directional distributions and finite-moment conditions. A brief checklist would be greatly appreciated, to the extent feasible.\n\n**Explicit contamination evaluation**: \n   As a numerical study, could you report empirical size, power, and misclassification rates under epsilon-contamination (e.g., 5%–20%) and under cellwise contamination, covering a grid over contamination rate, contamination strength, and sparsity or density? If possible, please include the proposed tests (sum, max, Cauchy combination) and HRQDA.\n\n**Influence function and breakdown point for the implemented HR**: \n   For the algorithmic estimator that uses banding and regularized precision estimation, could you outline a path toward an upper bound on the influence function and a lower bound on the finite-sample breakdown point? As feasible, auxiliary results that quantify how approximation errors contribute to the influence function—for example via a Gateaux-type argument—would be very helpful. \n\n**Sensitivity analyses and practical guidance**: \n   Could you provide performance-and-compute sensitivity curves for the banding width, regularization parameters, and the number of bootstrap iterations, so practitioners can understand acceptable ranges around the current recommendations? Reporting run time and dependence on sample size would also be useful.\n\n**Roadmap toward regression** *(e.g., high-dimensional asset pricing)*: \n   When transplanting the pipeline to a regression setting—HR-based residual estimation, robust prewhitening, sum or max statistics with asymptotic independence, and Cauchy combination—what are the main technical bottlenecks? For example, conditions on the design matrix and the treatment of estimation error in \\hat{\\Omega}. A short outline of how these issues could be addressed would clarify feasibility and scope."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9t4ljRXzq1", "forum": "Srs2hqLfjR", "replyto": "Srs2hqLfjR", "signatures": ["ICLR.cc/2026/Conference/Submission15757/Reviewer_yVX9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15757/Reviewer_yVX9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15757/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761489177176, "cdate": 1761489177176, "tmdate": 1762925989560, "mdate": 1762925989560, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper suggests the modification of Hettmansperger-Randles estimator in high dimensional setup (Algorithm 2), and shows its application in high dimensional location parameter testing problems (Section 3, 4). Based on this statistic, authors propose three tests: $T_{max}$, $T_{sum}$, and $T_{CC1}$, which can cope with sparse, dense, and universal precision matrices, and show their consistency (Section 3). Numerical experiments on three different setups are provided (Section 4)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* While I could not check the entire proof, I tried to check the Lemma 1 (which I believe is the most technical ingredient), and it seems correct (if my questions are resolved. See the question section). I think theoretical analyses conducted in this paper are nontrivial.\n\n* Given the concern on Assumption 1 is resolved (see the weakness section), the ARE calculation shows that the method behaves better than standard methods under the heavy tail distribution as claimed. In this regard, the proposed method is valuable if my concern is resolved.\n\n* Numerical results show the robustness of the test on the heavy tail problems."}, "weaknesses": {"value": "* The underlying assumptions are highly restrictive, and justifications are missing. I believe the assumptions are unlikely to hold for any practical problems.\n    * Precisely, I conjecture Assumption 1--specifically sub-Gaussian condition--fails for almost every case. Here is the heuristic reasoning. Let’s assume $\\zeta_1^{-1}$ exists by a constant (which seems like a weak condition in high dimensional setting). Then, $P(\\zeta^{-1}r^{-1} > t) = P(r < t^{-1}\\zeta^{-1})$. Since we are looking at the tail behavior, let’s consider the case when t is large, i.e., $t^{-1}\\zeta^{-1} \\approx 0$. Write the density of $\\epsilon_i$ by $f$. Under some regularity conditions of $f$ near 0, the probability is approximated by $f(0) \\times Vol(B_0(t^{-1}\\zeta^{-1}))$ (I have not thought about the precise condition deeply, but I think this would hold unless $f$ decays extremely fast, e.g., faster than any exponential power). Then, whatever density $\\epsilon_i$ has, as long as $f(0) > 0$, then $f(0) \\times Vol(B_0(t^{-1}\\zeta^{-1})) = Ct^{-p}$ for some constant $C > 0$. This implies $P(\\zeta^{-1}r^{-1} > t) \\approx C t^{-p}$, failing to exhibit the exponential tail. Of course this statement is not rigorous, as I used the approximation. But I think one should be able to write this in a rigorous statement with some regularity conditions of $f$ near 0 (which is suspected to be something that prevents extremely fast decay near 0), and $\\zeta^{-1}r^{-1}$ is not going to be a sub-Gaussian. This implies that to fulfill the assumption, whenever $\\zeta_1$ is finite, $\\epsilon_i$ should never be 0 or show extremely fast decay near 0, neither of which are standard settings in my opinion (e.g., even in simple Gaussian $\\epsilon_i$ with p > 1, these conditions are not satisfied. For Gaussian, I think one can make my statement more explicit using the Chi-square density instead of the approximation). \n    * If I am thinking wrong, can authors provide explicit examples when this condition is satisfied, possibly under the fairly standard setup?\n\n* How Assumptions 1-4 are involved in the proof is not explicitly stated. I want to see where the sub-Gaussian condition on $r_i^{-1}$ is used. \n\n* I am not sure whether ICLR is the right venue for this paper. I would expect such material in a statistics journal."}, "questions": {"value": "* The authors claim elliptic distribution includes multivariate mixture in Line 35. But isn’t it false? I believe this will happen only in very special cases (e.g. same mean and covariance). Seems like authors used this setup in simulation. I think authors should clarify that only certain Gaussian mixtures are elliptic.\n\n* Minor: use $\\in$ instead of $=$ in Equation (1) and (2), as solutions may not be unique.\n\n* The paper has not introduced what $\\Omega$ is in Assumption 3. I assume it is a precision matrix. Am I correct?\n\n* Assumptions 1 and 4: As mentioned in the weakness part, I would expect more explanations about assumptions. I believe Assumptions 2 and 3 are standard. However, Assumption 4 and the case $k = -1$ in Assumption 1 are not familiar to me. Particularly, I believe more explanations about Assumption 1 are needed, as I conjecture this assumption is never likely to be true except in very extreme cases (see the weakness part).\n\n* The first $\\lesssim$ part in Line 1120 is not clear. Can you elaborate on this?\n\n* The authors claim Lemma 4 is the restatement of Theorem 1 in [1]. However, I do not see why. Particularly, $\\widehat \\Omega$ in Lemma 4 seems different from $\\widehat V_{SCLIME}$ in [1]; based on the construction, if $\\widehat \\Omega$ is the precision matrix, then it depends on the choice of $h$ in the Algorithm 2, but $\\widehat V_{SCLIME}$ does not have such bandwidth parameter. So these two cannot be fundamentally the same. Can you elaborate on this?\n\n* Missing . in Line 351.\n\n[1] Lu and Feng, “Robust Sparse Precision Matrix Estimation and its Applications”, Arxiv 2025."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rUi9bnnSYc", "forum": "Srs2hqLfjR", "replyto": "Srs2hqLfjR", "signatures": ["ICLR.cc/2026/Conference/Submission15757/Reviewer_SqUN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15757/Reviewer_SqUN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15757/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761548725627, "cdate": 1761548725627, "tmdate": 1762925988704, "mdate": 1762925988704, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers the problem of estimating the location and scale parameter of multivariate elliptical distribution. A classic affine-equivariant robust estimator is the so-called Hettmansperger–Randles (HR) estimator. But, it fails in the high dimension. The authors extend the Hettmansperger–Randles (HR) estimator to the high-dimensional regime and propose a computationally tractable version of the HR estimator by combining spatial-sign statistics and banded shrinkage. They establish consistency, derive a Bahadur representation, and prove Gaussian approximation results that enable inference."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1, The generalization of the HR estimator to high dimensional data seems to be novel and the proposed banded HR update (Algorithm 2) is sound and computationally implementable.\n\n2, The authors establish rigorous theoretical development. They proved the Bahadur representation for the HR location estimator, the Gaussian approximation over convex sets, and the asymptotic independence between $T_{sum}$ and $T_{max}$, justifying the Cauchy combination test."}, "weaknesses": {"value": "1, the method lacks theoretical guidance on the selection of bandwidth.\n\n2, All results rely on the elliptical model. Simulation study lacks sensitivity analysis beyond elliptical data.\n\n3, Competing robust methods (e.g., robust covariance shrinkage) are not included in experiments. Including at least one such baseline would make the empirical evaluation more comprehensive."}, "questions": {"value": "1, can the authors provide some theoretical insight into bandwidth choice?\n\n2, can the authors provide a sensitivity analysis beyond elliptical data? This would enhance credibility of the method.\n\n3, can the authors include other robust estimators in the simulation study?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8fnN3QwzEt", "forum": "Srs2hqLfjR", "replyto": "Srs2hqLfjR", "signatures": ["ICLR.cc/2026/Conference/Submission15757/Reviewer_NwUT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15757/Reviewer_NwUT"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15757/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762214360964, "cdate": 1762214360964, "tmdate": 1762925988293, "mdate": 1762925988293, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}