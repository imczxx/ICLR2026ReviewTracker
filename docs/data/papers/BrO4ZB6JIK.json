{"id": "BrO4ZB6JIK", "number": 9330, "cdate": 1758119167152, "mdate": 1759897731044, "content": {"title": "Spatial-Spectral Binarized Neural Network for Panchromatic and Multi-spectral Images Fusion", "abstract": "Remote sensing pansharpening aims to reconstruct spatial-spectral properties during the fusion of panchromatic (PAN) images and low-resolution multi-spectral (LR-MS) images, finally generating the high-resolution multi-spectral (HR-MS) images. Although deep learning-based models have achieved excellent performance, they often come with high computational complexity, which hinder their applications on resource-limited devices. In this paper, we explore the feasibility of applying the binary neural network (BNN) to pan-sharpening. Nevertheless, there are two main issues with binarizing pan-sharpening models: (i) the binarization will cause serious spectral distortion due to the inconsistent spectral distribution of the PAN/LR-MS images; (ii) the common binary convolution kernel is difficult to adapt to the multi-scale and anisotropic spatial features of remote sensing objects, resulting in serious degradation of contours.\nTo address the above issues, we design the customized spatial-spectral binarized convolution (S2B-Conv), which is composed of the Spectral-Redistribution Mechanism (SRM) and Gabor Spatial Feature Amplifier (GSFA). Specifically, SRM employs an affine transformation, generating its scaling and bias parameters through a dynamic learning process. GSFA, which randomly selects different frequencies and angles within a preset range, enables to better handle multi-scale and-directional spatial features.\nA series of S2B-Conv form a brand-new binary network for pan-sharpening, dubbed as S2BNet. Extensive quantitative and qualitative experiments have shown our high-efficiency binarized pan-sharpening method can attain a promising performance.", "tldr": "", "keywords": ["pan-sharpening", "binary neural network"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/987b4de232bb098bc4e91bbfc7a17b60e57e7ba5.pdf", "supplementary_material": "/attachment/1660da097559e2896fce55892229feb5ca8f6155.zip"}, "replies": [{"content": {"summary": {"value": "The paper tackles remote sensing pansharpening—fusing a high-resolution panchromatic (PAN) image with a low-resolution multispectral (LR-MS) image to produce a high-resolution multispectral (HR-MS) image—under tight compute and memory constraints. The authors propose S2BNet, a largely binarized U-shaped network for efficient pan-sharpening. Its core is a Spatial-Spectral Binarized Convolution (S2B-Conv) that combines with Spectral-Redistribution Mechanism (SRM) and Gabor Spatial Feature Amplifier (GSFA).\nS2BNet places these modules within a U-shaped architecture (dual encoders, bottleneck, dual decoders with skip connections), using binary convolutions for most layers and a small number of full-precision layers. Experiments on GaoFen-2, WorldView-2, and QuickBird (4-band) with standard Wald protocol and metrics (e.g., PSNR, SSIM, SAM, ERGAS, Q-index, QNR and its components) show that S2BNet outperforms other binary approaches and is competitive with some full-precision baselines. Ablation studies indicate both SRM and GSFA contribute measurable gains, and binarizing different parts trades accuracy for parameter/OPs reduction. The authors claim code will be released."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Practical and targeted adaptation of BNNs to pansharpening, addressing two concrete pain points (spectral mismatch and anisotropic/multi-scale spatial textures) via SRM and GSFA.\n- Extensive experiments on three common satellites (GF-2, WV-2, QB), with strong baselines including recent CNN/Transformer and binary methods; both quantitative and qualitative results; ablations showing each component’s effect and binarization placement trade-offs.\n- Architecture and modules are explained clearly; equations for SRM and Gabor filters help reproducibility."}, "weaknesses": {"value": "Limited novelty: SRM is essentially a bounded affine calibration and GSFA leverages classical Gabor filtering with randomized parameterization. While these yield practical gains, the conceptual advance is incremental relative to recent pansharpening models introducing stronger spatial–spectral mechanisms, such as transformer-based fusion [1], content-adaptive non-local convolution [2], adaptive kernel-shape learning [3], and frequency-domain mixture-of-experts [4].                    \n\nGeneralization and robustness: No cross-sensor generalization (train on one sensor, test on another). In full-resolution evaluation, per-band spectral fidelity (e.g., band-wise SAM) and spectral index errors (e.g., NDVI) are not reported. There is no sensitivity analysis for GSFA parameter ranges nor an exploration of learnable Gabor parameters, despite recent emphasis on adaptivity in spatial kernels and frequency components [2][3][4].\n\n[1] Zhou, H., Liu, Q., & Wang, Y. (2022). PanFormer: A transformer based model for pan-sharpening. 2022 IEEE International Conference on Multimedia and Expo (ICME). arXiv:2203.02916\n\n[2] Duan, Y., Wu, X., Deng, H., & Deng, L.-J. (2024). Content-adaptive non-local convolution for remote sensing pansharpening. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 27738–27747.\n\n[3] Wang, X., Zheng, Z., Shao, J., Duan, Y., & Deng, L.-J. (2025). Adaptive rectangular convolution for remote sensing pansharpening. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 17872–17881.\n\n[4] He, X., Yan, K., Li, R., Xie, C., Zhang, J., & Zhou, M. (2024). Frequency-adaptive pan-sharpening with mixture of experts. Proceedings of the AAAI Conference on Artificial Intelligence, 38(3), 2121–2129. https://doi.org/10.1609/aaai.v38i3.27984"}, "questions": {"value": "Robustness and generalization:\n- Add cross-sensor generalization (train on GF-2, test on WV-2/QB) and cross-resolution tests. These would strengthen claims that S2BNet is not sensor-specific.\n- Report multiple seeds (mean±std) and significance tests for main results and ablations to contextualize ~0.3–0.5 dB gains.\n\nSpectral fidelity and full-resolution analysis\n- Provide per-band SAM and errors on spectral indices (e.g., NDVI) to directly assess spectral preservation.\n- For full-resolution, include qualitative failure cases (e.g., thin structures, haze, strong PAN–MS mismatch)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "FyZNt1DXXp", "forum": "BrO4ZB6JIK", "replyto": "BrO4ZB6JIK", "signatures": ["ICLR.cc/2026/Conference/Submission9330/Reviewer_HWxd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9330/Reviewer_HWxd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761530668214, "cdate": 1761530668214, "tmdate": 1762920964548, "mdate": 1762920964548, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces S2BNet, a binary neural network tailored for panchromatic–multispectral pansharpening. The core innovation is the S2B-Conv that contains two novel sub-modules:\nSpectral-Redistribution Mechanism – learnable affine re-scaling of each spectral band to combat spectral distortion caused by heterogeneous PAN/LR-MS distributions;\nGabor Spatial Feature Amplifier – randomly-selected Gabor kernels that enrich binary filters with multi-scale / anisotropic cues before binarization.\nStacking S2B-Conv units into a light U-Net yields S2BNet, which is trained end-to-end with pure L1 loss. Extensive experiments on WorldView-2, GaoFen-2 and QuickBird show S2BNet outperforming every published BNN (+2.5 dB PSNR gap) and many full-precision models, while keeping ≈ 1/32 parameters and ≈ 1/60 FLOPs of the latter."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. First BNN for PAN-MS fusion; SRM & GSFA are novel in the binary context.\n2. multi-sensor, multi-metric evaluation; ablation of each submodule\n3. Overall pipeline easy to follow; equations complete. The presentation is good."}, "weaknesses": {"value": "1.This paper is not the first to apply binarized neural networks to pansharpening.\nThe paper titled \"Binarized Neural Network for Multi-spectral Image Fusion\" holds that distinction.\n2.The authors claim that their method surpasses other BNNs by more than 2 dB in PSNR; however, Table 1 shows that it is only about 0.2 dB higher than BiSRNet.\n3.Likewise, Table 1 shows that the proposed method has three times the parameters of BiSRNet and significantly higher FLOPs. Is the reported performance gain entirely due to this larger model capacity rather than to the novel SRM/GSFA components?\n4.From Figure 2 it is completely impossible to tell which method produces higher visual-quality fused images, and the method names in the figure are somewhat blurry.\n5.The motivation behind the proposed core modules—the Spectral-Redistribution Mechanism and the Gabor Spatial Feature Amplifier—is unclear. There is only some textual explanation, but no other intuitive or quantifiable evidence is provided."}, "questions": {"value": "see the Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CX6S6GIXmh", "forum": "BrO4ZB6JIK", "replyto": "BrO4ZB6JIK", "signatures": ["ICLR.cc/2026/Conference/Submission9330/Reviewer_2CBq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9330/Reviewer_2CBq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761534349499, "cdate": 1761534349499, "tmdate": 1762920963179, "mdate": 1762920963179, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a Spatial-Spectral Binarized Neural Network (S2BNet) for efficient panchromatic and multispectral image fusion (pan-sharpening). The method introduces a custom Spatial-Spectral Binarized Convolution (S2B-Conv) layer, consisting of two modules:\n(1) Spectral-Redistribution Mechanism (SRM) — dynamically adjusts spectral distribution through data-driven affine scaling and bias;\n(2) Gabor Spatial Feature Amplifier (GSFA) — captures multi-scale, multi-directional spatial patterns using Gabor kernels.\nS2BNet is designed to achieve comparable reconstruction quality to full-precision networks while being lightweight enough for resource-limited satellite platforms. Experiments on GaoFen-2, WorldView-2, and QuickBird datasets are used to demonstrate that S2BNet outperforms other binary networks and approaches full-precision models in PSNR, SSIM, and QNR metrics"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Motivation relevance: The work targets a meaningful problem—deploying deep pan-sharpening models on resource-limited devices such as satellites—where efficiency is crucial.\n\nArchitecture clarity: The proposed S2B-Conv structure (with SRM and GSFA) is conceptually simple and well integrated into a binarized U-Net-like framework.\n\nEmpirical completeness: The paper provides quantitative and qualitative experiments, including ablation on both SRM and GSFA and comparisons with state-of-the-art (SOTA) binary and full-precision models.\n\nEnergy efficiency: The use of bitwise operations (XNOR, bit-count) is suitable for low-power environments, aligning with practical needs in embedded EO applications."}, "weaknesses": {"value": "Limited originality / incremental contribution.\nThe technical innovation is minimal. Both SRM and GSFA are straightforward combinations of existing ideas: adaptive scaling (used in SE, FiLM) and Gabor filters (widely applied in image enhancement and texture analysis). Their integration into BNNs does not represent a fundamental advance in pan-sharpening or network design. The approach is essentially a routine adaptation of BiSRNet (Cai et al., 2023) with Gabor initialization.\n\nLack of theoretical or methodological depth.\nThere is no formal justification for why SRM or GSFA mitigates spectral distortion or anisotropy introduced by binarization. The discussion is qualitative and lacks rigorous analysis of spectral error propagation or frequency response behavior.\n\nOverstated performance claims.\nWhile numerical improvements over other BNNs (~0.3–0.5 dB PSNR) are reported, these are minor and may not be statistically significant. Results still lag behind top full-precision models (e.g., FAMENet, CANNet). The claim that S2BNet “outperforms most full-precision baselines” is exaggerated.\n\nInsufficient novelty compared with prior lightweight or quantized models.\nThe paper overlooks related quantization-aware pan-sharpening or efficient Transformer works (e.g., HyperTransformer, LitePNN). The positioning of S2BNet as a novel direction in efficient fusion is weak.\n\nPoor figure readability.\nFigures (e.g., Fig. 1, 2, 3) are too small, and the text is illegible. Important architectural components and qualitative comparisons are difficult to interpret, limiting reproducibility.\n\nLimited generalization and scalability.\nAll experiments are conducted on moderate-resolution datasets; there is no evidence that S2BNet scales to very large images or complex multimodal datasets. The efficiency discussion also lacks actual inference latency or hardware deployment results."}, "questions": {"value": "How does S2B-Conv differ mathematically from existing spectral recalibration (SE, FiLM) and orientation-sensitive convolutions (GaborNet, DCTNet)?\n\nCan the authors provide quantitative analyses on spectral distortion reduction introduced by SRM, beyond PSNR/SSIM metrics?\n\nWhat is the real computational saving in milliseconds or watts on embedded hardware compared to full-precision models?\n\nHow robust is S2BNet under cross-sensor transfer (e.g., training on GF-2, testing on WV-2)?\n\nFigures should be enlarged and restructured for readability—particularly the architecture and ablation visualizations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gK29zTb90u", "forum": "BrO4ZB6JIK", "replyto": "BrO4ZB6JIK", "signatures": ["ICLR.cc/2026/Conference/Submission9330/Reviewer_GcwT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9330/Reviewer_GcwT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916768122, "cdate": 1761916768122, "tmdate": 1762920962887, "mdate": 1762920962887, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces S2BNet, a Spatial–Spectral Binarized Neural Network tailored for remote sensing pan-sharpening. The network incorporates two novel components: a Spectral Redistribution Mechanism (SRM) and a Gabor Spatial Feature Amplifier (GSFA). Evaluated on four-band datasets—GaoFen-2, WorldView-2, and QuickBird—S2BNet achieves performance that is competitive with or superior to both full-precision and other binarized models, while maintaining significantly higher computational efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tSubstantially reduces model size and FLOPs, making it suitable for deployment on resource-limited satellite or embedded platforms without significant performance degradation.\n2.\tEnhances the recovery of both spectral and spatial information."}, "weaknesses": {"value": "* Limited parameter analysis is provided.\n* Generalization to datasets with more spectral bands remains unexplored.\n* No runtime comparison is included. While “efficiency” is emphasized, inference time benchmarks on actual hardware are missing.\n* Citation formatting should be corrected.\n* The related work section should more systematically review prior binarized methods.\n* Metrics and methods are tested with inconsistent presentation across tables. For example, the QNR is not comprehensive for full-resolution cases.\n* The reference for metrics is missing. \n* The simulated process is missing."}, "questions": {"value": "* How does the adaptive SRM perform on datasets with greater spectral diversity?\n* How does S2BNet’s binarization affect color fidelity and edge preservation in visually demanding applications? In ablation studies where numerical differences are subtle, visual comparisons would be more informative.\n* Why is binarization not applied in conjunction with linear layers? What trade-offs exist between binarization and module design? Could partial binarization offer a better balance?\n* Have the SRM and GSFA modules been tested in other network architectures? Without such validation, the effectiveness of these modules lacks statistical support and may be difficult to substantiate.\nIn summary, the effectiveness of this method remains unclear."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "xJDtVjWypp", "forum": "BrO4ZB6JIK", "replyto": "BrO4ZB6JIK", "signatures": ["ICLR.cc/2026/Conference/Submission9330/Reviewer_DFy9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9330/Reviewer_DFy9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925723191, "cdate": 1761925723191, "tmdate": 1762920962524, "mdate": 1762920962524, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}