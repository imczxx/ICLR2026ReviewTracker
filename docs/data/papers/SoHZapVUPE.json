{"id": "SoHZapVUPE", "number": 2283, "cdate": 1757048444944, "mdate": 1759898158067, "content": {"title": "Coefficients-Preserving Sampling for Reinforcement Learning with Flow Matching", "abstract": "Reinforcement Learning (RL) has recently emerged as a powerful technique for improving image and video generation in Diffusion and Flow Matching models, specifically for enhancing output quality and alignment with prompts. A critical step for applying online RL methods on Flow Matching is the introduction of stochasticity into the deterministic framework, commonly realized by Stochastic Differential Equation (SDE). Our investigation reveals a significant drawback to this approach: SDE-based sampling introduces pronounced noise artifacts in the generated images, which we found to be detrimental to the reward learning process. A rigorous theoretical analysis traces the origin of this noise to an excess of stochasticity injected during inference. To address this, we draw inspiration from Denoising Diffusion Implicit Models (DDIM) to reformulate the sampling process. Our proposed method, Coefficients-Preserving Sampling (CPS), eliminates these noise artifacts. This leads to more accurate reward modeling, ultimately enabling faster and more stable convergence for reinforcement learning-based optimizers like Flow-GRPO and Dance-GRPO.", "tldr": "A new sampler to inject stochasticity into flow matching instead of SDE for RL.", "keywords": ["Flow Matching", "Diffusion sampler", "RLHF", "GRPO"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f03d8fa44fe4ce0636c3f5fbed958305ba3b6e41.pdf", "supplementary_material": "/attachment/24d06e6a2ca9babd8bcae2f62a6eb05d2e9285a2.zip"}, "replies": [{"content": {"summary": {"value": "The paper addresses an issue in the RL optimization of generative flow models: noisy samples during training. Recent approaches of inducing stochasticity via SDEs introduce artifacts that corrupt the reward signal, leading to unstable and inefficient optimization. The authors attribute the root cause of this problem to existing SDE-based samplers failing to preserve the coefficient schedule of the underlying ODE, resulting in out-of-distribution samples with excess noise. As a remedy, they propose Coefficients-Preserving Sampling (CPS), a stochastic sampling method inspired by DDIM. CPS is designed to inject controllable randomness while adhering to the model's original coefficient schedule, ensuring that both the sample and noise components remain well-behaved throughout the sampling process."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper provides a clear and insightful dissection of the noise mismatch in SDE-based sampling for Flow Matching, proving it as a first-order Taylor approximation with errors, particularly in low-step regimes common in modern samplers. This addresses an oversight in prior works, such as Flow-GRPO.\n2. CPS mitigates noise artifacts, ensuring cleaner and diverse samples without compromising the scheduler. Empirical results on benchmarks demonstrate faster convergence and higher rewards, thereby directly improving the stability of RL.\n3. By enhancing RL for flow-based models, the work aligns with growing interest in efficient, high-quality image generation, which is of timely relevance to community trends."}, "weaknesses": {"value": "1. The \"noisy image\" issue is likely overstated: no perceptual metrics are provided to quantify noise, and although CPS converges faster in Figure 5, Table 2 shows CPS only matches, not surpasses, the baseline; in fact, CPS performs worse than the baseline w/o KL regularization. \n2. Experimental design lacks proper controls: the authors use $\\eta = 0.7$ for Flow-CPS but $\\eta = 0.3$ for Dance-GRPO in Figure 5 which seems not to be a fair comparison. And across the four tables in Section 5.3, each table compares only Dance-GRPO or Flow-GRPO separately, comprehensive side by side comparisons are missing."}, "questions": {"value": "Could you clarify and potentially revise the framing in Section 4.2 to better acknowledge that Flow-SDE's noise inequality (Eq. 10) is a deliberate design for RL exploration in Flow-GRPO, rather than overstating it as a fundamental flaw, while highlighting CPS's empirical value in mitigating artifacts for cleaner reward computation? And for Theorem 1, could you emphasize that the Taylor approximation inverts historical development (Flow-SDE predates this work) and serves as a retrospective insight into noise mismatches, not a revelation of prior oversight? Finally, in Appendix B, might you more explicitly underscore that DPM-Solver++ is essentially DDIM  with a tuned schedule, positioning CPS as an adaptation to Flow Matching for RL?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cgrSuXrlP7", "forum": "SoHZapVUPE", "replyto": "SoHZapVUPE", "signatures": ["ICLR.cc/2026/Conference/Submission2283/Reviewer_ce1K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2283/Reviewer_ce1K"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761597217706, "cdate": 1761597217706, "tmdate": 1762916175215, "mdate": 1762916175215, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a critical issue in applying reinforcement learning to Flow Matching models for image generation: the introduction of noise artifacts when using Stochastic Differential Equations (SDEs) for sampling. The authors identify that existing methods like Flow-GRPO and Dance-GRPO convert deterministic ODEs to SDEs to enable diverse sampling, but this introduces excessive noise that corrupts generated images and misleads reward models. Through rigorous theoretical analysis, they demonstrate that SDE-based sampling injects more noise than the scheduler expects, violating what they term \"Coefficients-Preserving Sampling\" (CPS). Inspired by DDIM, they propose Flow-CPS, which reformulates noise injection  to maintain consistency between noise levels and the scheduler at every timestep. Experiments across multiple reward functions (GenEval, OCR, PickScore, HPSv2) on FLUX and Stable Diffusion models demonstrate that Flow-CPS produces cleaner images during training, enables more accurate reward computation, and achieves faster convergence with higher final rewards compared to SDE-based baselines. The authors also prove that Flow-SDE is a first-order Taylor approximation of their method (Flow-CPWS), explaining why approximation errors accumulate especially in low-step sampling regimes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Shows train-test mismatch problem: Flow-SDE suffers larger gap between training and evaluation performance \n* Addresses practical bottleneck in training state-of-the-art generative models with RL\n*  Well-motivated problem with concrete visual examples showing noise artifacts across different noise magnitudes"}, "weaknesses": {"value": "1. **Lack of convergence analysis**: No theoretical guarantees about convergence rates, sample complexity, or optimality of Flow-CPS for RL. Does CPS provably lead to better policy gradients? How does noise level accuracy affect GRPO convergence?\n2. **Limited diversity analysis**: Paper claims \"diverse samples\" but provides no quantitative diversity metrics (intra-prompt variance, coverage, etc.). Does cleaner sampling reduce exploration diversity, hurting RL? This is critical since stochasticity is introduced specifically for diversity.\n3. **Taylor approximation analysis incomplete**: Theorem 1 states Flow-SDE is approximation \"in the limit of $\\sigma_t^2\\Delta t \\ll t - \\Delta t$ and $\\Delta t \\to 0$\" but doesn't quantify approximation error for practical $\\Delta t$ values."}, "questions": {"value": "1. **Diversity quantification**: Can you provide quantitative diversity metrics (Vendi score, intra-prompt LPIPS distance, coverage on COCO captions) comparing Flow-CPS vs Flow-SDE at matched $\\eta$ values?\n2. **Statistical significance**: Please provide error bars (mean ± std over multiple seeds) for Tables 1-4 and training curves. What are p-values for claimed improvements using paired t-tests?\n3. **Hyperparameter selection**: Can you propose an automated method for selecting $\\eta$? Perhaps via validation set performance or some theoretical criterion based on reward model characteristics?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8tdkbQN3LX", "forum": "SoHZapVUPE", "replyto": "SoHZapVUPE", "signatures": ["ICLR.cc/2026/Conference/Submission2283/Reviewer_QL9h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2283/Reviewer_QL9h"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761618702567, "cdate": 1761618702567, "tmdate": 1762916175103, "mdate": 1762916175103, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Coefficients-Preserving Sampling (CPS), a modification to stochastic sampling in Flow Matching–based reinforcement learning frameworks (e.g., Flow-GRPO, Dance-GRPO). The authors claim that existing SDE-based samplers inject excessive noise, producing artifacts that harm reward learning. They theoretically analyze the mismatch between the SDE’s stochastic term and the scheduler coefficients, derive a “coefficients-preserving” condition, and reformulate the sampling process inspired by DDIM. Experiments across several reward models (GenEval, PickScore, HPSv2, OCR) show that the proposed CPS allegedly leads to faster convergence and slightly improved rewards."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Addresses a practical issue in applying RL to flow-matching generative models: noise accumulation during stochastic sampling.\n- The proposed formulation is concise, easy to implement (essentially modifying the noise coefficient schedule).\n- Figures are generally clear, with visual comparisons that help illustrate the qualitative difference in noise."}, "weaknesses": {"value": "- The central theoretical analysis—particularly Eq. (10) and Theorem 1—contains several unjustified assumptions. The derivation of the “total noise level” treats $\\hat{x}_1$ as an independent Gaussian variable, which is not true in flow matching where it depends on the network output. Consequently, the conclusion that Flow-SDE necessarily injects excessive noise lacks mathematical rigor. The proof of Theorem 1 is also informal and largely heuristic, making the claimed “first-order Taylor approximation” relationship between Flow-SDE and CPS unconvincing.\n- The proposed CPS method mainly modifies the noise coefficient schedule and re-parameterizes it using trigonometric terms. This is a minor variation inspired directly by DDIM and does not introduce fundamentally new insights into stochastic sampling or reinforcement learning with flow matching.\n- Although the authors report slightly faster convergence, the quantitative gains across all benchmarks (e.g., PickScore +0.3–0.4, HPSv2 +0.01) are small and lack statistical significance. There is no ablation on initialization seeds or exploration of when CPS fails, so the practical impact remains unclear.\n- 4. incomplete justification and reproducibility concerns.\nThe log-probability definition (Eq. 14) arbitrarily removes normalization terms to avoid numerical issues, which changes the underlying objective without theoretical grounding. Some key assumptions (e.g., independence between variables in Eq. 10) are unstated. Together, these raise doubts about the soundness and reproducibility of the results."}, "questions": {"value": "1. **On the correctness of Eq. (10)**\n   The derivation of Eq. (10) assumes that $\\hat{x}_1$ behaves as an independent Gaussian noise term with unit variance, which is not true in flow matching where $\\hat{x}_1=x_t+(1-t)\\hat{v}(x_t,t)$  depends on the model output.\n\n   * Can the authors clarify under what assumptions Eq. (10) holds?\n   * Please provide a mathematically rigorous justification of the “total noise level” computation.\n\n2. **On the claimed Taylor approximation (Theorem 1)**\n   Theorem 1 states that Flow-SDE is a first-order Taylor approximation of Flow-CPWS. However, the proof appears to rely on informal expansion and ignores higher-order stochastic terms.\n\n   * Could the authors provide a precise derivation showing the order of approximation and the required regularity conditions (e.g., $\\Delta t \\to 0$, bounded $\\sigma_t$)?\n\n3. **On the validity and generality of the CPS condition**\n   The definition of “coefficients-preserving” sampling (Definition 1) seems heuristic.\n\n   * Is there any probabilistic or geometric justification for why the squared-sum of coefficients should equal 1?\n   * How does this definition generalize to non-linear schedulers or other noise parameterizations?\n\n4. **On empirical robustness**\n\n   * Were the reported improvements averaged across multiple random seeds?\n   * Could the authors provide variance estimates or confidence intervals to establish statistical significance?\n\n5. **On altered log-probability (Eq. 14)**\n   Removing the normalization term from the log-probability affects the reward gradient.\n\n   * Can the authors justify this modification theoretically?\n   * Was the same change applied to the baselines to ensure fair comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9BZt9pk4WH", "forum": "SoHZapVUPE", "replyto": "SoHZapVUPE", "signatures": ["ICLR.cc/2026/Conference/Submission2283/Reviewer_gVq6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2283/Reviewer_gVq6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761718020267, "cdate": 1761718020267, "tmdate": 1762916174975, "mdate": 1762916174975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **Coefficients-Preserving Sampling (CPS)** for reinforcement learning with flow matching. The authors observe that existing Flow-SDE sampling injects **excess stochasticity**, producing visually noisy images and inconsistent reward signals during training. They trace this to a mathematical mismatch between the noise level imposed by the scheduler and the total noise actually injected at each step (Eq. 10, Fig. 2). To fix this, they define a sampling scheme that preserves (1) the coefficients of data and noise dictated by the scheduler, and (2) the total noise variance at every step (Def. 1). The derived formula (Eq. 12) aligns sample and noise coefficients geometrically as a quarter-circle interpolation, ensuring exact coefficient preservation. They further prove that **Flow-SDE is the first-order Taylor approximation** of their CPS-Wiener formulation (Eq. 15–17). Empirically, CPS yields faster and more stable RL convergence on multiple reward functions—GenEval, OCR, PickScore, and HPSv2—across base models (FLUX.1-dev, FLUX.1-schnell, SD3.5)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. **Precise identification and quantification of the “noise mismatch” problem.** Eq. (9)–(10) show analytically that Flow-SDE introduces excessive variance $\\sigma_\\text{total}=\\sqrt{(t-\\Delta t)^2+\\frac{(\\sigma_t\\Delta t)^2}{t}+\\big(\\frac{\\sigma_t^2\\Delta t}{2t}\\big)^2}\\ge t-\\Delta t$, matching the deviations in *Fig. 2* and the noisy artifacts in *Fig. 1*.\n2. **Formal, testable definition of coefficient preservation.** Definition 1 (p. 4) lays out two explicit conditions—scheduler-aligned sample coefficients and total noise variance matching. The derivation confirms DDIM sampling satisfies both, providing a solid baseline reference.\n3. **Sound geometric and mathematical formulation.** The proposed CPS rule (Eq. 12) $x_{t-\\Delta t}=(1-(t-\\Delta t))\\hat x_0+(t-\\Delta t)\\cos\\frac{\\eta\\pi}{2}\\hat x_1+(t-\\Delta t)\\sin\\frac{\\eta\\pi}{2}\\epsilon$ preserves coefficients exactly, visualized as circular trajectories in *Fig. 3(d)*.\n4. **Unified interpretation covering existing samplers.** Appendix B shows SDE-DPM-Solver++1 satisfies the CPS condition exactly (Eq. 22–24), revealing CPS as a unifying principle across DDIM, DPM-Solver++, and Flow sampling.\n5. **Strong evidence for reduced train–eval discrepancy.** Since evaluation uses noise-free sampling, the consistent alignment of CPS (Eq. 12) mitigates the mismatch clearly visible for SDE in *Fig. 1 vs Fig. 4*."}, "weaknesses": {"value": "- **Non-equivalent training objectives across baselines.** The GRPO objective replaces the probabilistic log term (Eq. 13) with a simplified quadratic form (Eq. 14) removing the denominator $2\\sigma_t^2$ and constants. Tables 1–4 do not clarify if baselines used the same approximation, meaning observed gains may conflate sampler and loss differences. Appendix D (Fig. 9) further admits that the full version “fails to converge,” implying unequal comparison conditions.\n- Appendix D states that \"although removing the denominator/constant is faster initially, the final performance is comparable to the original version,\" but the caption on the same page states that \"our algorithm with the denominator cannot converge, therefore it is not shown.\" The former seems to be comparing \"the original Flow-GRPO version vs. the version with the constant removed,\" while the latter refers to \"the CPS version with the denominator.\" Juxtaposing these two can easily mislead readers.\n- Appendix B has shown that SDE-DPM-Solver++1 satisfies CPS (Equations (22)–(24)), but it was not used as the training sampling baseline in the main experiments. Since this method naturally satisfies \"coefficient conservation\", its absence would weaken the argument chain of \"necessity/uniqueness of CPS\"."}, "questions": {"value": "- **How are the “Noise Level” curves in Fig. 2 computed?** Are they analytical evaluations of Eq. (10)/(25) or empirical variances over generated latents? Specify normalization and averaging procedures to ensure reproducibility.\n- **Which log-probability formulation is used in Tables 1–4?** Is the simplified Eq. (14) applied to both baseline and CPS, or only to CPS? Report whether $-\\log\\sigma_t$ and $1/(2\\sigma_t^2)$ terms are removed or clamped.\n- **Independence assumption between $\\hat x_1$ and $\\epsilon$.** Eq. (10) treats these as independent to add variances. Given $\\hat x_1$ is a deterministic function of $x_t$, which itself contains earlier noise, please justify the independence assumption or provide measured correlation values.\n- **Comparison with SDE-DPM-Solver++1.** Since Appendix B proves it satisfies CPS, please include or discuss results using it in RL training to isolate the benefit of the proposed derivation. Please report the training curve/final value of “GRPO + SDE-DPM-Solver++1” at least once under the same base model/number of steps/η/reward to verify that the “necessity/advantage of CPS” comes from the coefficient conservation itself rather than other implementation details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "l4FIyEcH1B", "forum": "SoHZapVUPE", "replyto": "SoHZapVUPE", "signatures": ["ICLR.cc/2026/Conference/Submission2283/Reviewer_gqwb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2283/Reviewer_gqwb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2283/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761889341013, "cdate": 1761889341013, "tmdate": 1762916174745, "mdate": 1762916174745, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}