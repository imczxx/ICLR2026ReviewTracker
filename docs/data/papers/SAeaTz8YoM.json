{"id": "SAeaTz8YoM", "number": 4900, "cdate": 1757791962362, "mdate": 1759898006412, "content": {"title": "SysMoBench: Evaluating AI on Formally Specifying Complex Real-World Systems", "abstract": "Formal models are essential to specifying large, complex computer systems and verifying their correctness, but are notoriously expensive to write and maintain. Recent advances in generative AI show promise in generating certain forms of specifications. However, existing work mostly targets small code, not complete systems. It is unclear whether AI can deal with realistic system artifacts, as this requires abstracting their complex behavioral properties into formal models. We present SysMoBench, a benchmark that evaluates AI's ability to formally model large, complex systems. We focus on concurrent and distributed systems, which are keystones of today's critical computing infrastructures, encompassing operating systems and cloud infrastructure. We use TLA+, the it de facto specification language for concurrent and distributed systems, though the benchmark can be extended to other specification languages. We address the primary challenge of evaluating AI-generated models by automating metrics like syntactic and runtime correctness, conformance to system code, and invariant correctness. SysMoBench currently includes nine diverse system artifacts: the Raft implementation of Etcd and Redis, the Spinlock and Mutex in Asterinas OS, etc.; more artifacts are being actively added. SysMoBench enables us to understand the capabilities and limitations of today's LLMs and agents, putting tools in this area on a firm footing and opening up promising new research directions.", "tldr": "A new benchmark on AI's ability of modeling real-world systems", "keywords": ["Specification", "Benchmark", "Distributed System", "Concurrent System", "Agentic AI", "Large Language Model"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8edfe0d9acae13f64e98ce7efba8bcd8e9c43c0f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this work, the authors propose a benchmark dataset for evaluating LLMs in terms of their capability of system modelling. The dataset contains 9 systems/models, and the authors propose 4 different metrics for evaluating the quality of the model constructed by the LLMs. Some empirical results are then presented."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "On the positive side, I enjoy reading the draft for the following reasons.\n\nFirst, the problem of evaluating LLMs capability of system modeling, which can be regarded as one particular form of abstract thinking capability, is an interesting and important one.\n\nSecond, the idea of evaluating the quality of the models at different levels is a valid idea.\n\nLastly, the writing is easy to follow and some of the empirical results are interesting."}, "weaknesses": {"value": "On the less positive side, the draft can be improved from the following aspects.\n\nFirst, the benchmark data is fairly small in size and lacks variety (i.e., only one modeling language), and there is not a very interesting or useful benchmark yet. More importantly, it seems to be rather hard to scale up the dataset as well.\n\nSecond, the proposed ways of measuring the quality of the model can be much improved, and much details on how exactly the scoring is done is missing. For instance, for per-action specification, it is not clear how a specification is considered correct - do you have to check specification equivalence, modular renaming, using different data structures and so on? \n\nThe following are a list of detailed comments.\n\nPage 2: “SYSMOBENCH currently includes a diverse set of nine real-world artifacts, …”\n\nComment: The size of the benchmark set raises questions on whether such a benchmark set would produce statistically significant evaluating results. \n\nPage 2: “SYSMOBENCH enables us to understand the capabilities and limitations of AI in modeling realworld\nsystems by evaluating different agent designs with various AI models.”\n\nComment: Given that only one modelling language is evaluated, this statement is rather an over-statement. \n\nSection 3.1: line 183-190\n\nComment: It is rather arguable whether such a modeling requirement is reasonable or. In practice, the level of details to be included in the model typically depends on the analysis task. i.e., the properties to be established or falsified. Simply saying that some actions should be modeled is not sufficient as there are many ways of modeling the same action.\n\nPage 5: “It then uses SANY to check the per-action specification.”\n\nComment: How is this done? In general, this boils down to a specification equivalence checking which is hard.\n\nPage 9: “For example, adding Etcd Raft took one SYSMOBENCH author four days; an Xline CURP contributor with no experience of SYSMOBENCH added the system to SYSMOBENCH in four days.”\n\nComment: Four days per mode is not exactly efficient. Furthermore, there are questions such as who decides the model is correct? Lastly, if four man/day is all that is needed for one model, why are there only 9 in total?"}, "questions": {"value": "If the AI uses different data-structures (one-dimensional list instead of two-dimensional one) or different encoding to model the same action,  can you tell that it is correct?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lxNJjw9oEL", "forum": "SAeaTz8YoM", "replyto": "SAeaTz8YoM", "signatures": ["ICLR.cc/2026/Conference/Submission4900/Reviewer_RwMC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4900/Reviewer_RwMC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760876746569, "cdate": 1760876746569, "tmdate": 1762917747058, "mdate": 1762917747058, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SYSMOBENCH, a benchmark designed to evaluate generative AI (LLMs and agents) on their ability to formally model complex real-world systems, particularly concurrent and distributed ones.\nUsing TLA+ as the modeling language, the benchmark assesses how well AI can synthesize system-level formal specifications from code, documentation, and execution traces.\n\nSYSMOBENCH defines four automatic evaluation metrics and provides tasks from nine real-world system artifacts (e.g., Etcd Raft, Redis Raft, Asterinas OS spinlock/mutex).\nExperiments with four LLMs (Claude-Sonnet-4, GPT-5, Gemini-2.5-Pro, DeepSeek-R1) and three agent designs show that AI can handle simple concurrency models (e.g., spinlocks) but fails on large-scale distributed systems (e.g., Raft)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Novel Benchmark and Scope\n\nFocusing on system-level formal modeling, going beyond prior works on function-level specification or toy TLA+ examples.\n\n- Automatic and Quantitative Evaluation Metrics\n\nProposes a clear, reproducible metric suite (syntax, runtime, conformance, invariant) for assessing AI-generated TLA+ models without human involvement.\n\n- Empirical and Realistic Evaluation\n\nUses real-world system artifacts (Etcd, Redis, Asterinas, etc.), showing the practical limitations of current LLMs and agents in understanding and abstracting complex system behaviors."}, "weaknesses": {"value": "- Shallow Semantic Understanding\n\nThe current metrics emphasize syntactic, runtime, and invariant correctness, but do not directly measure whether AI truly captures the semantic intent or design rationale of the system.\n\n- Lack of Human Baseline Comparison\n\nNo comparison with expert-written TLA+ specifications is provided. Without a human reference, it is hard to assess how “good” the AI-generated models truly are in abstraction quality or maintainability.\n\n- Limited Scalability\n\nAdding a new system using LLM still requires 3–4 days of human setup (instrumentation, trace harness preparation), which challenges scalability despite claims of automation. \n\n- Risk of Contamination and Overfitting\n\nSome system code (e.g., Etcd Raft) may already appear in LLM training data, possibly affecting fairness; the paper lacks a clear anti-contamination discussion."}, "questions": {"value": "How easy is it to extend SYSMOBENCH to other formal languages (e.g., Alloy, PAT)? A discussion on generalization beyond TLA+ would make the benchmark more widely applicable.\n\nThe authors note that LLMs often fail on liveness invariants. Could they provide finer-grained analysis (e.g., which temporal operators or fairness conditions are most misunderstood)?\n\nCan SYSMOBENCH-produced AI-generated models be useful to human engineers (e.g., partial correctness checking or documentation)? Some qualitative human evaluation would strengthen its practical impact."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vGfnzd0jKi", "forum": "SAeaTz8YoM", "replyto": "SAeaTz8YoM", "signatures": ["ICLR.cc/2026/Conference/Submission4900/Reviewer_K1Um"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4900/Reviewer_K1Um"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760879652979, "cdate": 1760879652979, "tmdate": 1762917746645, "mdate": 1762917746645, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SysMoBench, which is a benchmark framework for evaluating the outputs of large language models using a formal specification language called TLA^{+}. The authors developed nine benchmarks and evaluated the types of syntax and runtime errors, as well as violations of safety and liveness specifications. The authors evaluate the frontier models by expressing them using TLA^{+} language outputs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors develop a benchmarking tool to evaluate LLM outputs with tools from formal methods, and using a formal specification language. The benchmark also evaluates several types of errors, such as syntax and runtime errors, as well as violations of safety and liveness specifications."}, "weaknesses": {"value": "I think the benchmarks in the paper mainly demonstrate the lack of capability of outputting TLA^{+} models for these models, which is mentioned in the \"Analysis on LLMs\". I think that the reason Claude-sonnet is overperforming is mainly because it's more adept at creating outputs with TLA^{+} syntax, but not necessarily having a superior ability to reason and generate real-world system artifacts."}, "questions": {"value": "The authors listed a number of benchmarks, such as MMLU, ARC, and HELM, but I think there's a lack of motivation behind using TLA^{+}. There are also some comparisons missing relevant to structured reasoning, such as EvalScope and Agent-SafetyBench. I would like to understand why using TLA^{+} is a much better alternative than these benchmarks, considering that it's not a very common specification language, such as linear temporal logic. The authors should also spend some time on defining the basic properties of TLA^{+}.\n\nI think it's also unclear how the benchmark tasks were generated, and how this tool can be extended to use different benchmarks. The authors mention this in a paragraph, but I don't see the point of adding their subjective experience without an extensive introduction in the appendix."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "t6jbaorvBi", "forum": "SAeaTz8YoM", "replyto": "SAeaTz8YoM", "signatures": ["ICLR.cc/2026/Conference/Submission4900/Reviewer_Sb7c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4900/Reviewer_Sb7c"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761774340150, "cdate": 1761774340150, "tmdate": 1762917746225, "mdate": 1762917746225, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new benchmark, SysMoBench, for assessing the ability of AI systems to generate valid formal models of complex real-world systems. The main contributions of the paper are threefold:\n1. The authors properly define key metrics to assess the quality of the AI generated system models (based on syntax correctness, runtime correctness, conformance to the system implementation and invariant correctness)\n2. The authors also clearly lay out an effective fully automated approach to compute those metrics \n3. An empirical evaluation that shows the limitation of state-of-the-art LLMs in generating system models for real-world complex systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. **Relevance**\nThe paper addresses a critical challenge: evaluating the capability of AI systems to move beyond basic code generation and comprehension, toward a deeper understanding and modeling of complex real-world systems.\n\n2. **Significance and Novelty**\nTo the best of my knowledge, the proposed approach is novel in its problem formulation, the techniques used to fully automate the quality assessment of AI-generated models, and its focus on real-world complex systems. The introduction of this new benchmark holds strong potential for significant impact, as it provides a vital resource that could accelerate progress in AI-driven modeling of complex systems.\n\n3. **Soundness and Experimental Evaluation**\nThe experimental results validate the effectiveness and robustness of the key LLM-assisted components within the automated evaluation pipeline. They also highlight that current state-of-the-art LLMs still face challenges in accurately modeling complex real-world systems, which underscores the importance of this benchmark in advancing research on AI modeling of intricate software systems."}, "weaknesses": {"value": "I could not find any major problem with the paper."}, "questions": {"value": "The authors write in section 3.2.4: \n>\"In principle, if a system model fully conforms to code, violations of these invariants would indicate bugs in system code; in practice, few\nAI-generated models achieved fine-grained conformance.\"\n\nLet's assume that, with the help of this new benchmark, state-of-the-art LLMs improve significantly at complex system modeling tasks. What approach would you recommend to determine whether a violation of an invariant stems from a rare LLM modeling error or from an actual bug in the system code?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "VDva2Fl2QL", "forum": "SAeaTz8YoM", "replyto": "SAeaTz8YoM", "signatures": ["ICLR.cc/2026/Conference/Submission4900/Reviewer_f1Je"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4900/Reviewer_f1Je"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4900/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933501170, "cdate": 1761933501170, "tmdate": 1762917745698, "mdate": 1762917745698, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}