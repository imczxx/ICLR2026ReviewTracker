{"id": "8iAoBRObJg", "number": 15584, "cdate": 1758252905402, "mdate": 1763730870392, "content": {"title": "STAPS : Training-Free Zero-Shot Anomaly Detection via Semantic-Temporal Scoring and Prototype Selection", "abstract": "Zero-shot anomaly detection (ZAD) addresses the need for anomaly detection without large-scale labeled datasets by leveraging large pretrained representations without domain-specific supervision. However, existing ZAD methods still depend on labeled pretraining, limiting their applicability in practical scenarios. Training-free ZAD eliminates this dependency by directly leveraging pretrained backbones without additional training, offering a cost-efficient alternative. However, training-free ZAD suffers from semantic bias by applying class-oriented representations to anomaly detection without fine-tuning. In this work, we propose a novel training-free framework Semantic-Temporal scoring and Prototype Selection (STAPS) that mitigates semantic bias and incorporates temporal context into anomaly detection. The proposed method comprises two key components. First, semantic-temporal anomaly scoring refines anomaly scores that are biased toward class semantics by leveraging temporal locality and continuity to capture sequential dependencies. Second, bayesian gaussian mixture-based prototype selection automatically identifies prototypes sensitive to anomaly evidence, thereby reducing semantic bias in backbone features and enhancing pixel-level anomaly segmentation. Extensive experiments on nine benchmark datasets demonstrate that our proposed method achieves state-of-the-art performance, achieving 91.9\\% image-level AUROC for anomaly detection and 97.7\\% pixel-level AUROC for anomaly segmentation, highlighting both robustness and generalizability.", "tldr": "", "keywords": ["Anomaly detection", "zero-shot learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/94fbcc16af3d85812c2983ec45f0dd881eb2645e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces STAPS, a training-free zero-shot anomaly detection framework designed to reduce semantic bias in pretrained representations and enhance robustness without fine-tuning. The method achieves strong results (91.9% image-level and 97.7% pixel-level AUROC) across nine benchmarks, surpassing existing training-free and training-based baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.Nine benchmark datasets (industrial + medical) with consistent improvement and ablation analyses demonstrate robustness and generalization.\n\n2.The combination of STAS (semantic‚Äìtemporal scoring), BGMPS (prototype selection), and EMA smoothing is conceptually coherent and computationally light, aligning well with the ‚Äútraining-free‚Äù principle."}, "weaknesses": {"value": "1.The paper‚Äôs central idea of introducing semantic-temporal anomaly scoring assumes that image datasets exhibit some form of ‚Äútemporal coherence,‚Äù yet this notion remains conceptually vague and empirically unverified. In static industrial or medical datasets, consecutive samples do not possess any temporal order or dependency; hence, it is unclear what kind of temporal continuity is being modeled. The motivation for treating the dataset as a temporal sequence should be clarified.\n\n2.The paper lacks visual or quantitative analysis (e.g., prototype visualization, attention map diversity, or clustering metrics) to show how BGMPS truly mitigates semantic bias or captures anomaly-relevant prototypes.\n\n3.The improvement over MuSc and other strong baselines is relatively modest."}, "questions": {"value": "See above comments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AFYlqkLGbB", "forum": "8iAoBRObJg", "replyto": "8iAoBRObJg", "signatures": ["ICLR.cc/2026/Conference/Submission15584/Reviewer_ikwS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15584/Reviewer_ikwS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15584/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761953197607, "cdate": 1761953197607, "tmdate": 1762925857159, "mdate": 1762925857159, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a training-free zero-shot anomaly detection framework called STAPS, which mitigates semantic bias and incorporates temporal context into anomaly detection. It integrates two key components: a semantic-temporal anomaly scoring mechanism that refines anomaly scores biased toward class semantics, and a Bayesian Gaussian mixture-based prototype selection module that identifies prototypes sensitive to anomaly evidence, thereby reducing semantic bias and improving pixel-level anomaly segmentation. Extensive experiments on nine diverse benchmark datasets demonstrate that STAPS achieves state-of-the-art performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The method is somewhat novel, introducing temporal concepts into a set of non-temporal images.\n\n2. The experiments are comprehensive, covering both industrial and medical datasets.\n\n3. The writing is clear and well-organized."}, "weaknesses": {"value": "1. STAS requires constructing a temporal adjacency matrix T, but the paper does not clearly specify how the ordering of test samples is determined (original order? sorted by class? random shuffle? averaged over multiple permutations?).\n\n2. STAS computes a full similarity matrix ùëÜ over all test samples. Thus, the method is inherently transductive‚Äîeach sample‚Äôs score depends on the entire test set.\n\n3. On the HeadCT dataset, the image-level AUROC is only 76.2%, indicating limited generalization for certain medical modalities. The authors are encouraged to analyze the reasons behind this performance."}, "questions": {"value": "1. STAS requires constructing a temporal adjacency matrix T, but the paper does not clearly specify how the ordering of test samples is determined (original order? sorted by class? random shuffle? averaged over multiple permutations?).\n\n2. STAS computes a full similarity matrix ùëÜ over all test samples. Thus, the method is inherently transductive‚Äîeach sample‚Äôs score depends on the entire test set.\n\n3. On the HeadCT dataset, the image-level AUROC is only 76.2%, indicating limited generalization for certain medical modalities. The authors are encouraged to analyze the reasons behind this performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "a4FISIcJ9r", "forum": "8iAoBRObJg", "replyto": "8iAoBRObJg", "signatures": ["ICLR.cc/2026/Conference/Submission15584/Reviewer_Y8ni"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15584/Reviewer_Y8ni"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15584/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993897488, "cdate": 1761993897488, "tmdate": 1762925856198, "mdate": 1762925856198, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces STAPS, a training-free zero-shot anomaly detection framework that aims to mitigate semantic bias in pretrained backbones by combining two key components: (1) Semantic-Temporal Anomaly Scoring (STAS), which integrates temporal coherence into anomaly scoring; and (2) Bayesian Gaussian Mixture-based Prototype Selection (BGMPS), which refines pixel-level localization through prototype clustering and fusion. Experiments on nine benchmark datasets show the effectiveness of the proposed method for anomaly image detection and segmentation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ The topic is important. A training-free zero-shot anomaly detection method is proposed to solve the problem of insufficient anomaly training images.\n\n+ The proposed STAS and BGMPS are conceptually clear and modular, making the approach easy to reproduce.\n\n+ Some ablation studies are provided to facilitate the understanding of how the performance benefits from different components, including STAS, BGMPS, and EMA."}, "weaknesses": {"value": "- The novelty is somewhat incremental over existing training-free methods such as MuSc and CLIP-based variants. The proposed ‚Äútemporal‚Äù dimension is pseudo-temporal and not derived from real sequence data, making the motivation less convincing.\n\n- The conceptual justification for treating unordered image datasets as temporally coherent sequences is weak and may not generalize well beyond experimental setups.\n\n- Technical depth is limited. Both STAS and BGMPS rely on relatively straightforward post-processing (similarity weighting, EMA smoothing, and clustering) rather than introducing a fundamentally new model.\n\n- Some improvements are marginal, especially for pixel-level anomaly detection. It is unclear whether such gains (e.g., 0.2% in Average in Table 2) are meaningful in practice.\n\n- Ablation results, while present, are not sufficiently analyzed, especially regarding when temporal smoothing helps or harms performance."}, "questions": {"value": "1. Can you clarify how the pseudo-temporal ordering is defined for datasets without any inherent sequence?\n\n2. How robust is STAPS to changes in the temporal window parameter L and decay factor gamma?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gifPVvxECg", "forum": "8iAoBRObJg", "replyto": "8iAoBRObJg", "signatures": ["ICLR.cc/2026/Conference/Submission15584/Reviewer_khmS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15584/Reviewer_khmS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15584/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762003273744, "cdate": 1762003273744, "tmdate": 1762925855634, "mdate": 1762925855634, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes STAPS, a training-free zero-shot anomaly detection framework that leverages semantic text alignment and pseudo-segmentation to localize anomalies without requiring additional training or fine-tuning.\nSTAPS aligns CLIP-derived visual features with dynamically generated textual prompts that describe normality and abnormality, and introduces a pseudo-segmentation mechanism that refines region-level anomaly localization in a self-guided manner.\nThe approach is simple to implement, and achieves strong results across multiple industrial anomaly detection benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. STAPS offers a clean and effective training-free solution for zero-shot anomaly detection. The combination of semantic alignment and pseudo-segmentation integrates global semantics and local semantics.\n\n2. The method achieves competitive or superior results on multiple industrial benchmarks compared to both training-based and zero-shot baselines, including AnomalyCLIP, WinCLIP, and FAPrompt. The experiments are comprehensive and show consistency across diverse settings."}, "weaknesses": {"value": "1. The definition of the temporal matrix is ambiguous, and it is unclear how this component effectively captures temporal relations among images. The paper does not provide sufficient explanation.\n\n2. The overall contribution of the paper is limited. Although the method builds upon the MUSC framework and integrates temporal modeling into the anomaly detection pipeline, the proposed approach appears to be an incremental extension rather than a fundamentally novel concept."}, "questions": {"value": "See Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xso3hrWHTH", "forum": "8iAoBRObJg", "replyto": "8iAoBRObJg", "signatures": ["ICLR.cc/2026/Conference/Submission15584/Reviewer_DBuh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15584/Reviewer_DBuh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15584/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762883633753, "cdate": 1762883633753, "tmdate": 1762925855085, "mdate": 1762925855085, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}