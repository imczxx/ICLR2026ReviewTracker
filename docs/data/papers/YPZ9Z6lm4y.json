{"id": "YPZ9Z6lm4y", "number": 23512, "cdate": 1758344786435, "mdate": 1762998276399, "content": {"title": "MedFuse: Multiplicative Embedding Fusion for Irregular Clinical Time Series", "abstract": "Clinical time series derived from electronic health records (EHRs) are inherently irregular, with asynchronous sampling, missing values, and heterogeneous feature dynamics. While numerical laboratory measurements are highly informative, existing embedding strategies usually combine feature identity and value embeddings through additive operations, which constrains their ability to capture value-dependent feature interactions. We propose MedFuse, a framework for irregular clinical time series centered on the MuFuse (Multiplicative Embedding Fusion) module. MuFuse fuses value and feature embeddings through multiplicative modulation, preserving feature-specific information while modeling higher-order dependencies across features. Experiments on three real-world datasets covering both intensive and chronic care show that MedFuse consistently outperforms state-of-the-art baselines on key predictive tasks. Analysis of the learned representations further demonstrates that multiplicative fusion enhances expressiveness and supports cross-dataset pretraining. These results establish MedFuse as a generalizable approach for modeling irregular clinical time series.", "tldr": "", "keywords": ["Irregular multivariate time series; Clinical prediction; Electronic health records; Multiplicative embedding; Missing data modeling; Representation learning."], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/6a1718a5de93ca60320073a9b9ab6b24a2636bb0.pdf", "supplementary_material": "/attachment/0db4fbce5f66957b9b4ca20fc876ba9e27663192.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes MedFuse, a framework for irregular clinical time series centered on the MuFuse (Multiplicative Embedding Fusion) module. MuFuse fuses value and feature embeddings through multiplicative modulation, preserving feature-specific information while modeling higher-order dependencies across features. Experiments on two datasets demonstrate the superior performance of MedFuse."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The studie problem is interesting and important. Especially irregular time series analysis is a pretty challenging domain for clinical data analysis.\n\n2. The proposed approach achieve good results on 3 different tasks."}, "weaknesses": {"value": "1. The paper’s contribution appears incremental. Representing each feature at each timestamp as an embedding follows prior work in SUMMIT [1], as the authors acknowledge. The main novelty is the multiplicative fusion of the feature identifier and the value embedding. As presented, this reads more as a heuristic than a method: the paper does not explain why multiplication is preferable to alternatives such as addition, concatenation, gating, attention, or bilinear pooling.\n\n2. Empirically, the gains are unclear. In Table 1, MedFuse and SUMMIT achieve overlapping performance once the reported standard deviations are considered, suggesting no statistically meaningful improvement. \n\n3. In addition, several figures and tables (e.g., Figure 1, Figure 3, Table 2) closely mirror SUMMIT’s presentation, which further blurs what is substantively new beyond [1].\n\n\n[1]. Huang, Chun-Kai, Yi-Hsien Hsieh, Ta-Jung Chien, Li-Cheng Chien, Shao-Hua Sun, Tung-Hung Su, Jia-Horng Kao, and Che Lin. \"Scalable Numerical Embeddings for Multivariate Time Series: Enhancing Healthcare Data Representation Learning.\" arXiv preprint arXiv:2405.16557 (2024)."}, "questions": {"value": "1. What is the rationale for choosing a multiplicative operation to fuse feature-identity and value embeddings? Please provide theoretical motivation or comparative experiments against common alternatives (addition, concatenation, gating/MLP, attention, bilinear).\n\n2. Table 2 reports ablations only on PhysioNet 2012 (P12). Could you extend these ablations to other datasets or tasks to demonstrate robustness and generality?\n\n3. What is the intended takeaway of Table 3? As written, the transfer results do not show clear gains, and performance when transferring from P12 to MIMIC-III appears to worsen."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ehQzq5CYzL", "forum": "YPZ9Z6lm4y", "replyto": "YPZ9Z6lm4y", "signatures": ["ICLR.cc/2026/Conference/Submission23512/Reviewer_8iZu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23512/Reviewer_8iZu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977124839, "cdate": 1761977124839, "tmdate": 1762942692572, "mdate": 1762942692572, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We sincerely thank all the reviewers for their detailed and constructive reviews. We have decided to withdraw this submission and thoroughly revise it by incorporating all the suggestions and addressing all the concerns and questions. We appreciate the reviewers' tremendous effort in helping us improve our submission."}}, "id": "MEvEVfWl5V", "forum": "YPZ9Z6lm4y", "replyto": "YPZ9Z6lm4y", "signatures": ["ICLR.cc/2026/Conference/Submission23512/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23512/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762998275502, "cdate": 1762998275502, "tmdate": 1762998275502, "mdate": 1762998275502, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MedFuse, a model incorporating irregular clinical time series. The core of the paper is a novel 'MuFuse embedding module' that performs value-conditioned multiplicative fusion. The multiplicative factors themselves are obtained via sigmoid function to supress outliers. The authors claim this approach better captures nonlinear feature-value interactions compared to existing fusion methods that are generally additive. They evaluate MedFuse on three clinical datasets (two public and one private) showing performance improvements over several baselines. The paper also includes a cross-dataset transfer experiments to support the idea of learning cohort-agnostic features."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The main contribution of fusion methods for irregular EHR data is an interesting and underexplored area. The paper generalizes the SUMMIT model, and the derivation is sound.\nThe formulation and mathematical notation are generally clear presented. The overall paper is easy to read. The experiments are not just on ICU mortality prediction datasets, but also carcinoma, suggesting some generalizability.\nIf the claims hold, the approach proposed in the paper can influence how numerical values are embedded in clinical models."}, "weaknesses": {"value": "The paper heavily relies on the claim that multiplicative fusion enables \"richer feature-value interactions\" and \"nonlinear modulation,\" but provides limited evidence about its benefit for clinical data. \n\nThe justification for multiplicative gating is also hand-wavy, and relevant only at the last layer. Since we have a transformer architecture with multiple layers, there is no reason to see why the relevant interaction cannot be learned under additive terms. Furthermore, there are multiple papers which have porposed incorporating multiplicative interactions. How is this work different?\n\nThe paper talks about irregularly sampled time series, but I do not see anything specific to that use case here. Any argument in the paper can be applied even to regularly sampled no-missing data series as well.\n\nThe improvements are minor, and are often not significant. This might not be as important, if the paper established that these differences are clinically meaningful. But I see no such evidence. Additionally all the results are based on only 2 datasets PhysioNet and MIMIC.  The third HCC data is entirely private with no reference.\n\nFurthermore on Physionet, accuracy increases only marginally but the model deviation increased 4 times. This undermines the entire argument about the model capturing specific multiplicative interactions which others do not."}, "questions": {"value": "What specific types of clinical patterns or relationships does your method capture that is not captured by other methods?\n\nWhat is the value of Sec 5.3. The alternate parameterization was not experimented on nor theoretically analyzed, so this seems like unnecessary addendum to the paper.\n\nAs the paper also says, the transfer results are influenced more by dataset size rather than embedding quality. Moreover the descriptions says that after initial freezing, the embeddings is fine-tuned as well. Doesn't this undermine the claim of learning \"reusable, cohort-agnostic embedding\"? \n\nAdditionally multiplicative interactions baseline models can be added. See [1,2,3] and references there in \n\n Have you conducted any error analysis to identify specific patient subgroups or clinical scenarios where the improvement is most pronounced?\n\nIMPORTANT: I was a last minute/emergency reviewer, so I have not had the chance to read this in detail. If I have misunderstood or missed anything, please bring it to my notice, and I will correct myself and revise my ratings.\n\nMinor:\nThere are many duplicated references ( Song et al, Shukla and Marlin, Tipirneni and Reddy, etc.)\n\n1 Multiplicative interactions and where to find them, Jayakumar et al\n2 AdaDHP: Fine-Grained Fine-Tuning via Dual Hadamard Product and Adaptive Parameter Selection, Liu et al\n3 SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZCF2XVhf7x", "forum": "YPZ9Z6lm4y", "replyto": "YPZ9Z6lm4y", "signatures": ["ICLR.cc/2026/Conference/Submission23512/Reviewer_EooK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23512/Reviewer_EooK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762579173396, "cdate": 1762579173396, "tmdate": 1762942692182, "mdate": 1762942692182, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To effectively model numerical laboratory measurements, this paper proposes MedFuse to disentangle irregular clinical time series numerical values into value and feature embeddings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The motivation is clear. \n- The problem is interesting.\n- The paper is easy to read and understand."}, "weaknesses": {"value": "- Insufficient experiments.\n- Novelty is limited. It is a technique that disentangles numerical values into two parts. But this has been done by others like FT-Transformer and TabTransformer-like series models."}, "questions": {"value": "- Novelty clarification. Please reclarify your novelty after surveying the Transformers for tabular data.\n- More details about the standard lookup table are needed.\n- The method is claimed to model the feature identity embeddings and value embeddings. Validation experiments or detailed interpretation are needed to support your claim.\n- Why repeat each entry of $e_v$ for k times? There are other choices, like using an MLP (or other layers) to map the two embeddings into one shared embedding. Repeating k times does not make sense.\n- The TabTransformer-like series models should also be included as baselines.\n- The step in \"Comparison of different partitioning factors k on P12\" is too large. A fine-grained setting is needed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "8cmGmVsIio", "forum": "YPZ9Z6lm4y", "replyto": "YPZ9Z6lm4y", "signatures": ["ICLR.cc/2026/Conference/Submission23512/Reviewer_MULN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23512/Reviewer_MULN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23512/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762604278582, "cdate": 1762604278582, "tmdate": 1762942691729, "mdate": 1762942691729, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}