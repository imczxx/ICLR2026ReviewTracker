{"id": "RMWcdp5IUy", "number": 23980, "cdate": 1758351313415, "mdate": 1759896788134, "content": {"title": "Online Conformal Prediction with Adversarial Feedback via Regret Minimization", "abstract": "Quantifying uncertainty is crucial in safety-critical learning systems where decisions are made based on uncertainty. Conformal prediction is one promising way to quantify uncertainty that comes with a theoretical guarantee. However, the theoretical guarantee comes with a price of the assumption on data generation process, including exchangeability or full feedback. In this paper, we propose a novel conformal prediction method with less data generation assumption, i.e., a learning method for online conformal prediction with partial feedback from an adaptive adversary. In particular, we leverage matured literatures in sequential prediction and adversarial bandits to design our online conformal prediction algorithm. The great benefit of the reliance on adversarial bandits is that we can exploit theoretical regret bounds for conformal prediction guarantees. Here, we explicitly connect the regret and a desired miscoverage guarantee in conformal prediction such that our algorithm via adversarial bandits can naturally provide a miscoverage guarantee from the regret bounds. Furthermore, we extend an existing adversarial bandit method to leverage the properties of conformal prediction, resulting in a bandit method with a tighter regret bound. We empirically demonstrate the efficacy of our conformal prediction method over various learning setups, including a stochastic setup and covariate shift setup, showing a controllability on a micoverage rate while achieving a reasonable conformal set size.", "tldr": "", "keywords": ["Online Conformal Prediction", "Adversarial Bandit", "Partial Feedback", "Regret"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f0a3b2ec17daa87a256550c015622e056dc99c4c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper tackles online conformal prediction with semi-bandit feedback and adaptive adversaries by reducing threshold selection to an adversarial bandit problem. It designs a loss that trades off deviation from a target miscoverage level with efficiency (tuned by λ) and proves a conversion from bandit regret to miscoverage guarantees. Implementations with EXP3.P and an “unlocking” variant that reuses feedback via monotonicity provide high-probability bounds, and experiments on classification and regression show accurate coverage tracking with compact prediction sets, including under covariate shift."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper introduces an adversarial semi bandit formulation for online conformal prediction and reduces threshold selection to an adversarial bandit with a transparent bridge from regret control to miscoverage control, together with an unlocking mechanism that exploits monotonicity to reuse feedback. It offers high probability guarantees and a clear analysis pipeline from loss design to regret bounds to miscoverage guarantees, implemented with practical EXP3.P algorithms. Experiments on classification and regression show close tracking of target miscoverage with strong sample efficiency, consistent with the theory. The writing is clear, and the modular design lets other bandit learners plug in, increasing impact in retrieval, selective prediction, and human in the loop systems."}, "weaknesses": {"value": "See details in Questions."}, "questions": {"value": "1. In both experiments, the choice of the hyperparameter $\\lambda$ is not specified. How is $\\lambda$ selected, and how sensitive are the results to different values of $\\lambda$? The paper lacks discussion on this critical design choice.\n2. What is the performance of the proposed method under low feedback rates (i.e., when semi-bandit feedback is rarely triggered)? The current experiments do not analyze or discuss scenarios with sparse feedback.\n3. Could there exist a more direct threshold-updating mechanism (e.g., standard online quantile tracking or reinforcement learning methods) that also achieves adversarial miscoverage control? Why is the bandit framework preferred here, and what are its concrete advantages over such alternatives?\n4. In the abstract (line 025), the word \"micoverage\" should be corrected to \"miscoverage\".\n5. In line 127, the definition of “size” is unclear. Why is it claimed to be proportional to exp(-$\\pi$)? Please provide a reasonable justification or reference.\n6. In line 172 (Equation 3), the definition of $a_t(\\pi_t)$ appears, but later discussions refer to $a_t(\\pi)$. Are they the same quantity? A unified and explicit definition for $a_t(\\pi)$ is missing.\n7. In line 213 under EXP3.P-CP, the parameters $\\delta$and $K$ are used without prior introduction or definition. Please clarify their meanings.\n8. In line 225, what is the valid range of the probability distribution $p_t$? It would be helpful to explicitly state its domain or constraints.\n9. In Figure 1, the blue curve (MVP) is barely visible or unidentifiable. Please consider adjusting the visualization for clarity.\n10. In line 568, there is an unexplained symbol or placeholder \"(?)\", which appears to be a typo.\n11. On the final page of the appendix (Page 18), there are punctuation issues in one of the equations. A thorough proofreading of all punctuation throughout the paper is recommended."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KTsVwxV4BQ", "forum": "RMWcdp5IUy", "replyto": "RMWcdp5IUy", "signatures": ["ICLR.cc/2026/Conference/Submission23980/Reviewer_7ZrS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23980/Reviewer_7ZrS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23980/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811140408, "cdate": 1761811140408, "tmdate": 1762942881396, "mdate": 1762942881396, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper explores how regret minimization techniques from bandit and sequential prediction literature can be adapted to online conformal prediction under partial feedback. It establishes a theoretical link by deriving an upper bound on the miscoverage rate in terms of the learner’s regret, enabling the use of these methods in this setting. Building on this, the paper demonstrates the application of the EXP3.P algorithm and introduces a novel variant, EXP3.P-CP with Unlocking, which exploits additional partial feedback and the monotonicity of prediction set construction. For both methods, the paper provides miscoverage guarantees and evaluates their empirical performance on regression and classification tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The partial feedback setting in online conformal prediction is highly relevant, offering practical value to both the conformal prediction research community and real-world practitioners.\n- The paper’s connection to regret minimization methods is particularly compelling, as it unlocks a rich toolbox of established techniques that can be effectively applied to conformal prediction. I am not an expert in this specific area of conformal prediction, and I am surprised this connection has not appeared in the literature before, but to the best of my knowledge, it is novel.\n- The paper is generally clear and well-structured, making it easy to follow. The proofs are also well detailed and, I believe, sound."}, "weaknesses": {"value": "- The experiments are somewhat limited in the sense that the only baselines considered operate under a different setting. This makes it hard to evaluate the effectiveness of the proposed method. Are there no other conformal prediction methods designed for partial feedback, or at least methods that could be adapted to this setting?\n- The presentation could be improved as there are a few minor typographic errors and occasional non-idiomatic phrasing (see minor issues below).\n\n### Minor issues\n\n- Line 16: “with fewer data generation assumptions” instead of “with less data generation assumption”\n- Line 18: \"mature literature\" or \"established literature\" instead of “matured literatures”\n- Line 41:  I am not sure “enjoyable” is a good word choice in “enjoyable guarantee”. Maybe just “guarantee” would read better.\n- Line 126: “minimizes” should be “minimize”.\n- Line 133: The sentence “due to exploiting the achievement of adversarial bandits under an adaptive adversary” is not clear. What does the “achievement of adversarial bandits” mean?\n- Line 159: “which we leverage this algorithm as our baseline” does not read well. Probably better to add a full stop and then “We leverage this algorithm as our baseline”.\n- Line 208: “method” instead of “methods”.\n- Line 209: “to use” instead of “to using”.\n- Line 568: Missing reference."}, "questions": {"value": "1. After Lemma 1, it says that “the corresponding miscoverage rate converges to a desired level $\\alpha$”. However, we do not really see that in the results of Figure 1. Why is that?\n2. How are the set of candidate thresholds chosen? How does that affect the results in both theoretical and practical terms? I imagine that the resolution of the threshold might affect the convergence of the regret, for example.\n3. The results focus on the absolute coverage gap, treating undercoverage and overcoverage equally. Would it be possible to extend the analysis to penalize undercoverage more heavily than overcoverage? Relatedly, EXP3.P-CP with Unlocking appears more conservative than EXP3.P-CP, leading to overcoverage in Figure 1. Is this behavior expected?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dBe3ixjh70", "forum": "RMWcdp5IUy", "replyto": "RMWcdp5IUy", "signatures": ["ICLR.cc/2026/Conference/Submission23980/Reviewer_d5vm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23980/Reviewer_d5vm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23980/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761846090164, "cdate": 1761846090164, "tmdate": 1762942881068, "mdate": 1762942881068, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new framework for online conformal prediction under partial and adversarial feedback, where the learner only observes limited information about prediction correctness.  Conformal prediction has been connected to adversarial bandit learning by framing conformal set selection as an arm-selection problem. They develop a conversion lemma linking regret bounds to miscoverage guarantees, allowing the use of existing bandit algorithms for online conformal prediction."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Establishes a clear connection between regret minimization and coverage guarantees in conformal prediction.\n\n- The introduction of the EXP3.P-CP-UNLOCK algorithm effectively adapts the classic EXP3.P framework to the unique structure of conformal prediction feedback.\n\n- Provides regret and miscoverage bounds with detailed proofs."}, "weaknesses": {"value": "- The review of online conformal prediction is insufficient. Important recent works are missing, including:\n   - Angelopoulos et al. (2023), Conformal PID Control for Time Series Prediction;\n   - Angelopoulos et al. (2024), Online Conformal Prediction with Decaying Step Sizes;\n   - Gibbs & Candès (2024), Conformal Inference for Online Prediction with Arbitrary Distribution Shifts;\n   - Zhang et al. (2025), Online Differentially Private Conformal Prediction for Uncertainty Quantification.\n\n\n- As $m_t$ is an indicator function, the regret formulation may not distinguish between observing or not observing $y_t$, potentially causing information loss. Clarification on how the true label feedback is used is needed.\n\n- A formal theorem explicitly stating the miscoverage rate bound would make the theoretical results clearer.\n\n- Please clarify whether specific techniques are used to address non-i.i.d. or non-exchangeable data.\n\n- The differences from Ge et al. (2025) should be highlighted more clearly in terms of assumptions,method, and theoretical guarantees."}, "questions": {"value": "- Should it be “minimize the miscoverage rate” in line 128 on page 3?\n\n- There are no comparisons with other recent partial-feedback uncertainty quantification frameworks.\n\n- Please discuss how sensitive the results are to the choice of $λ$ and the discretization level $K$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cqbplQelHq", "forum": "RMWcdp5IUy", "replyto": "RMWcdp5IUy", "signatures": ["ICLR.cc/2026/Conference/Submission23980/Reviewer_KKfP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23980/Reviewer_KKfP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23980/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896134623, "cdate": 1761896134623, "tmdate": 1762942880845, "mdate": 1762942880845, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}