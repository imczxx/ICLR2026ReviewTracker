{"id": "OjJVe1frVt", "number": 8371, "cdate": 1758080436015, "mdate": 1759897789205, "content": {"title": "LiRDSC: Ligand-Conditioned RNA Sequence Design via Diffusive Structural Conditioning", "abstract": "RNA design for specific small-molecule ligands is a central goal in molecular engineering, yet computational approaches are hindered by two fundamental challenges: extreme sensitivity to the fidelity of input tertiary structure scaffolds and a tendency toward ``mode collapse'', where models generate generic rather than ligand-specific sequences. To address this, we present two core contributions. First, we introduce RLData2400, a benchmark dataset combining high-resolution experimental structures with diverse, high-confidence \\textit{in silico} models to facilitate the development of models. Second, we propose \\textbf{LiRDSC (Ligand-conditioned RNA Design via Diffusive Structural Conditioning)}, a deep generative framework architected for specificity. LiRDSC uniquely employs a \\textbf{Diffusive Structural Encoder (DSE)}, which learns resilient representations by training on noise-perturbed structures, and a \\textbf{Ligand-Contextual FiLM Conditioner (LCFC)} that steers the model to reason about the ligand’s identity, preventing mode collapse. Trained on our dataset (RLData2400), LiRDSC not only achieves high sequence recovery but also generates a vast diversity of ligand-target RNA sequences. Crucially, its superiority is most pronounced on structurally augmented data, directly validating the robustness imparted by our diffusion-based conditioning. Inverse folding experiments further confirm that these designs accurately recapitulate their target tertiary structures, and importantly, computational analysis predicts high binding compatibility with the target ligands, demonstrating  LiRDSC’s ability to produce structurally viable and ligand-specific RNA candidates.", "tldr": "", "keywords": ["RNA design", "RNA-Ligand", "Structure"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bbdb32b1fb08809442a6a7fbf8e8e19ff9f7987d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes LiRDSC, a ligand-conditioned model for RNA sequence generation. The model embeds a ligand (together with an RNA sequence during training) using a ligand specific conditioner and a separate 3D structure diffusive encoder to inform a diffusion-based decoder at test time. Furthermore, the paper introduces RLData2400, a new benchmark dataset for RNA-ligand interactions. The performance of LiRDSC is reported against 3 sota RNA design methods (gRNAde, RDesign, and RiboDiffusion). The reported results show that LiRDSC outperforms the competitors across sequence-, secondary structure-, 3D-evaluation measures, as well as binding score. In an ablation study, the authors further assess the importance of different components."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Ligand conditioned RNA design could clearly improve RNA design capabilities with applications in drug discovery and RNA therapeutics.\n- The results indicate a substantial performance improvement across multiple measures compared to the competitors.\n- The encoding strategy of the ligand and 3D structure appears to be novel and well suited for the problem at hand."}, "weaknesses": {"value": "**Major**:\n1. The 3D structure conditioning seems to be based on backbone structures only (according to problem formulation and later sections), not full-atom structures. While I think this is also done in e.g. gRNAde, it would be good to (1) make this clear already at the beginning of the work, and (2) describe at least which backbone atoms were used. \n2. Regarding the similarity measure, I’m a bit confused. In the paper, it reads like higher similarity is better. In the appendix, it reads like this is a measure of similarity based on alignments. So then lower similarity is better, or? Meaning higher diversity, or?\n3. I think some important aspects of the experiments are missing, most importantly: How many sequences were generated per sample for each method? \n4. In 5.1, the authors claim that LiRDSC solves a harder problem than the competitors due to the ligand conditioning but still achieves better performance. However, this also means that the competitors have less information available for generation than LiRDSC. It would be good if the authors e.g. also evaluate on some other dataset than RLData2400 (and maybe exclude the ligand information as done in the ablation). For me, this is not necessarily a main paper experiment but could potentially show that LiRDSC’s structure embedding approach is generally superior to the others.  \n\n**Minor**:\n1. There are many citations missing in the main paper (I think they appear elsewhere, e.g. in the appendix but should be in the main paper). For example: introduction of RNA-FM and CHEmberta in Section 3; FiLM is cited in appendix A2.2 only; RiboDiffusion is not cited at first appearance in Section, and more…\n2. Similarly, it would be good to have the appropriate references to the appendix from the main paper. If I did not overlook any, I only see one reference to app A.4 in the main paper.\n3. Wrong citation in Section 2.2 -> AF3 should be Abramson et al., 2024., not Jumper et al., 2021\n4. The math parts could also benefit from some more explanations on the variables' meaning, already starting in Section 3.1 “Problem Definition” where multiple variables remain undefined.\n5. Tables should have captions above the table, not below.\n6. Which folding engine was used in the qualitative case study?\n7. Clearly, the proposed approach has limitations. One example is the sequence length limitation of RNA-FM during training. However, there is no clear statement about limitations in the main paper, nor the appendix."}, "questions": {"value": "1. The authors use a cutoff of 3.5\\AA during data generation to define the distance cutoff. I also heard about cutoffs at 5\\AA. Was the cutoff based on the cited literature, or would a 5A cutoff still make sense and increase the available data?\n2. During data processing, the authors mention that 192 complexes were hold-out for testing. What was that split based on? Since the pairwise TM-Scores were computed anyways for Figure 4, was this information also used to split the training and test data based on structure similarity? If not, that would be good to ensure accurate evaluations without data leakage. \n3. I was wondering if LiRDSC is the first RNA design method that does ligand-conditioned generation? If yes, I would encourage the authors to clearly state this early in the paper. If not, I would like to see a comparison to such an existing approach and the methods should be named in the related work section.\n4. Do the authors have a rationale for using RNA-FM for RNA sequence embeddings? Did the authors also experiment with other tools?\n5. During preparation of RLData2400, the authors use in silico data besides the data obtained from PDB. There are several questions on this approach: (1) How are the RNAs generated, at random? (2) Do the authors ensure that the generated data is biologically plausible by any means, or is it only structurally plausible as stated in step 4. of the pipeline? (3) Is there any rationale on the sequence length limitation to 200nt for RNA generation? (4) Maybe I missed it, but how is the ligand distribution in the set? Are there any ligands that are over represented after filtering the structures with plddt?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "91qLtZ2jNu", "forum": "OjJVe1frVt", "replyto": "OjJVe1frVt", "signatures": ["ICLR.cc/2026/Conference/Submission8371/Reviewer_XHfm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8371/Reviewer_XHfm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8371/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761772850224, "cdate": 1761772850224, "tmdate": 1762920279961, "mdate": 1762920279961, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LiRDSC, a deep generative model for RNA sequence design conditioned on small-molecule ligands. The authors propose two key innovations: (1) a diffusion-based structural encoder trained on noise-perturbed RNA backbones to reduce sensitivity to structural fidelity, and (2) a ligand-contextual FiLM conditioning mechanism to enforce ligand-specific sequence generation. The model is trained on RLData2400, a dataset combining 1,200 experimentally determined RNA-ligand complexes from PDB and 1,200 computationally predicted structures from AlphaFold3 (AF3). The authors report significant improvements in sequence recovery, structural fidelity, and predicted binding affinity compared to existing baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel Regularization Strategy: The diffusion-based noise injection during training is an interesting approach to mitigate over-sensitivity to input structural fidelity, a known issue in structure-based RNA design.\n2. Ligand-Specific Conditioning: The use of FiLM to inject ligand information during generation is well-motivated and appears effective in promoting ligand-specific sequence design.\n3. Comprehensive Evaluation: The paper evaluates the model across multiple dimensions (sequence, secondary structure, tertiary structure, and binding affinity), using several external tools, which strengthens the empirical assessment."}, "weaknesses": {"value": "1)Related to Strength 1: the paper applies diffusion noising to the 3D RNA backbone and claims this improves generalization, but I did not see an ablation that toggles this component. It is unclear whether diffusion noising is crucial compared with no noising at all or with simpler random offset perturbations, especially since the diffusion process is integrated into LIRDSC’s training and is specific to this model.\n2)Roughly half of the constructed dataset consists of RNA sequences generated by AlphaFold AF3-predicted structures may carry inherent biases (e.g., crystal packing artifacts, template dependencies) and are not validated with the same criteria as experimental PDB entries, raising concerns about dataset reliability."}, "questions": {"value": "AF3 Bias Analysis\nHow do you address potential biases in AF3-predicted structures (e.g., crystal artifacts, confidence variations)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eh8XDHHrv2", "forum": "OjJVe1frVt", "replyto": "OjJVe1frVt", "signatures": ["ICLR.cc/2026/Conference/Submission8371/Reviewer_2YkC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8371/Reviewer_2YkC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8371/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761934415651, "cdate": 1761934415651, "tmdate": 1762920279561, "mdate": 1762920279561, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LiRDSC, a ligand-conditioned RNA sequence design framework built on a diffusive structural conditioning paradigm. The model integrates a Diffusive Structural Encoder (DSE) to enhance robustness against noisy tertiary structures and a Ligand-Contextual FiLM Conditioner (LCFC) to enforce ligand specificity. Trained on a newly curated RLData2400 dataset that includes both experimental and high-confidence in silico RNA–ligand complexes, LiRDSC achieves solid improvements in sequence recovery, structural fidelity, and binding-related metrics compared to RiboDiffusion, RDesign, and gRNAde."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is technically sound and well-written, with careful dataset construction and comprehensive experiments. It represents a competent application of diffusion-based generative modeling to the RNA-ligand domain. The proposed FiLM-based ligand conditioning is conceptually reasonable, and the results demonstrate consistent gains across multiple evaluation levels. The presentation is clear, and the work successfully completes its stated goal of extending diffusion-style inverse folding to the ligand-aware RNA setting."}, "weaknesses": {"value": "The main limitation lies in novelty. The proposed framework closely follows established paradigms in protein design, such as ligand-conditioned or structure-guided diffusion models (e.g., those leveraging ESM or Denoising Diffusion frameworks for protein inverse folding). The diffusive encoder and ligand conditioning via FiLM are adaptations rather than fundamentally new mechanisms. As a result, the contribution feels incremental—essentially applying existing protein design strategies to RNA. While the results are solid, they do not clearly demonstrate conceptual advances beyond prior ligand-conditioned diffusion models."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "A1cQWmpTHv", "forum": "OjJVe1frVt", "replyto": "OjJVe1frVt", "signatures": ["ICLR.cc/2026/Conference/Submission8371/Reviewer_gNL1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8371/Reviewer_gNL1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8371/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937258050, "cdate": 1761937258050, "tmdate": 1762920278917, "mdate": 1762920278917, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of RNA inverse sequence design conditioned on small drug-like molecules and ligands. The paper introduces some new architectural ideas to better condition sequence design upon a target ligand. Evaluations show favorable performance compared to existing RNA inverse folding methods."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The problem being tackled is significant and biologically relevant. A successful approach could be an extremely useful foundation for de-novo aptamer design and RNA engineering. This is one of the first works to explore this problem. I want to encourage the authors for exploring this direction. However, the paper in its current form is not ready for publication. I have stated my reasons below under Weaknesses.\n\n- The exposition is generally well-written, grammatically."}, "weaknesses": {"value": "- There is no information provided on how the test set was constructed for evaluation. There is no information about how the validation set is constructed either. Thus, one concludes that there was no validation set, and the test set was split randomly. This is not acceptable, as all **the performance is likely to be highly overestimated for the proposed model (vs baselines) and the authors may be tuning the model on the test set**. I would advise the authors to carefully design a new, biologically relevant test set and to split the data with a lot more care (see PLINDER benchmark on best practices to evaluate ligand+biomolecule interaction without data leakage). I would suggest a complete re-do of the experiments and claims made. I realise this sounds demanding, but the current standard of experiments is not sufficiently high in my opinion.\n\n- The new model uses embeddings of the RNA sequence via RNA-FM (an RNA language model). Based on how this is presented, I think this is a major weakness which limits practical applicability to real inverse design problems. If the model is given access to the original input sequence, it is not surprising that the sequence recovery will be very high (which is what we see during evaluation and case studies). \n\n- I found the qualitative studies to actually be a negative point against the proposed method, as it tells me that the model is not ready for real-world usage. Essentially, the studies show the proposed model doing extremely well (like 90-100% sequence recovery rate, perfect TM-score) — but this is likely a clear case of **data leakage and overfitting**. Consider a sequence with 95% similarity to the groundtruth - that is actually not a useful design because the goal of design is to retain structural/functional properties while being far away in sequence space. Such a model will not be useful for real-world design settings which are outside of the training distribution, and none of these case studies actually support that the model is useful in practice. I would unfortunately not use such a model, currently.\n\n- No variances or standard deviations or error bars included with most results."}, "questions": {"value": "- The Intro tries to tell a story around “mode collapse” being the main motivation of the proposed architectural contribution. I personally don’t buy this / would like to have then seen this supported by some experiments. Is it the case that baselines like gRNAde are mode-collapsing?\n\n- On binding metrics: Is it known that either of the two proposed metrics is actually correlated with RNA ligand binding? As far as I am aware, nobody has shown this, esp. for the AF3 pAE score.\n\n- On the use of random sequences for data augmentation: I find this choice suspicious without any actual justification in the text. Why did you chose random sequences, why that length range, how do you ensure you don’t encounter something from the test set? What is the performance of the model trained purely on PDB structures without augmentation? (Did I miss this experiment, or is it currently missing?)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WweBJXZJNR", "forum": "OjJVe1frVt", "replyto": "OjJVe1frVt", "signatures": ["ICLR.cc/2026/Conference/Submission8371/Reviewer_EeHz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8371/Reviewer_EeHz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8371/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762002937588, "cdate": 1762002937588, "tmdate": 1762920278438, "mdate": 1762920278438, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}