{"id": "5hrCwqnBng", "number": 16146, "cdate": 1758260610842, "mdate": 1759897258411, "content": {"title": "SYNTHIA: A Multi-Agent GAN-LLM Fusion for Statistically Guided Synthetic Data Generation", "abstract": "Access to high-quality, large-scale datasets is critical for training effective AI models, yet high costs, privacy concerns, and regulatory barriers often constrain data collection. Existing synthetic data generation methods, particularly for tabular data, struggle to preserve statistical integrity and utility, limiting their applicability in sensitive domains. To address this, we propose SYNTHetic Intelligence Architecture (SYNTHIA), a novel framework that integrates large language models (LLMs) as both the generator and discriminator within a GAN-inspired architecture for high-fidelity tabular data generation. Guided by metadata encodings, the LLM-based generator ensures that synthetic data reflects the statistical and structural properties of real datasets. A core innovation is the statistically enhanced discriminator, which incorporates a novel evaluation algorithm to rigorously quantify fidelity, diversity, and alignment with real data. This mechanism minimizes distributional divergence and accelerates convergence, ensuring realistic and utility-preserving synthetic data. Extensive experiments across diverse tabular datasets demonstrate that SYNTHIA consistently outperforms state-of-the-art methods, highlighting its scalability and adaptability for applications in data-constrained environments such as healthcare, finance, and security.", "tldr": "SYNTHIA is a GAN-inspired, multi-agent LLM framework for tabular data generation that leverages statistical feedback to iteratively refine prompts, achieving state-of-the-art fidelity and diversity over strong baselines.", "keywords": ["Synthetic Data Generation", "Multi-Agent Systems", "Large Language Models", "Generative Adversarial Networks"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c6c235cdb6678b16b162db6e99b5a1d6f0fcbcf8.pdf", "supplementary_material": "/attachment/b2dd97673f657e6dc2917f8379fb2eeaf4bfdd87.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces a framework that leverages LLM to generate tabular data. By leveraging the LLM and mimicking a generative adversarial network, integrating a statistical enhanced discriminator."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The paper introduces a LLM based statistical analyzer. By incorporating several statistical metrics, the methods can generate high fidelity synthetic data that maintains the distribution of the real data."}, "weaknesses": {"value": "- The paper's novelty is very limited. The idea to use the multi-agent LLM to mimick a GAN architecture was proposed in other paper, while the paper did not cite the relevant paper[1]. The only difference the paper made is to use a LLM based discriminator. \n- Another contribution of the paper is to introduce the theoretical perspective of the GAN. However, the theories are grounded on strong assumptions. Here are my concerns about the basis of your grounded theory: \n- **Theorem** Lipschitz objective in prompt space. The assumption is too strong to be true. 1. There is no evidence support the Lipschitz property of the prompt space (If there is any study support this, please cite it.). The problem is that the mapping from prompt to the generation is a blackbox function, there is no empirical or theoretical analysis that how will the prompt affect the generation outputs.\n- **Method** The readability of the methods is poor. For example, how to initialize the first prompt, how many samples are allowed per generation.\n- **Method** A key component of the framework is to use the statistical analysis to improve the generation quality over iterations (A.3). But in the manuscript, the author did not show some evidence that how will the statistics change over iterations. Also, in section A.5, the author states that the loop will converge in 3-6 iterations, please provide some examples of the outputs to show what the convergence looks like. \n- **Experiment**. The paper presents a benchmark experiments on several datasets while only presents datasets on public datasets only. Since there might be data leakage in the training data of the model, to prove the efficacy of the model, the author should also consider doing experiments on the private datasets.\n4. **Experiment**. The paper presents a benchmark experiments to show performance on fildelity only. But to evaluate the synthetic data, one also need to consider the utility and the privacy problem.\n\n[1] Ling, Y., Jiang, X., & Kim, Y. (2024). Mallm-gan: Multi-agent large language model as generative adversarial network for synthesizing tabular data. arXiv preprint arXiv:2406.10521."}, "questions": {"value": "Please see the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9xI33bjahP", "forum": "5hrCwqnBng", "replyto": "5hrCwqnBng", "signatures": ["ICLR.cc/2026/Conference/Submission16146/Reviewer_bsdX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16146/Reviewer_bsdX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16146/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761425016081, "cdate": 1761425016081, "tmdate": 1762926313808, "mdate": 1762926313808, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a multi-agent framework that uses LLMs with GAN-style adversarial training to generate synthetic data."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Including the statistical test in the feedback pipeline will (incrementally) help the quality of statistical validation on the newly generated data"}, "weaknesses": {"value": "-Lack of rigorous justification for the use of LLM for synthetic data generation. The data generative model should learn the distribution of numerical variables. LLM has a limited capacity to learn the distribution of numerical variables, compared to other generative models (e.g., diffusion model, GAN models). \n-Lack of rigorous justification for the use of the GAN structure for LLM orchestration for synthetic data generation\n-This paper fails to cite a critical prior work that first proposed GAN-based multi-agent LLM (https://arxiv.org/abs/2406.10521) and falsely claimed its primitivity.\n- Theorems provided are generic convergence arguments, not specific to the proposed model. \n- In the experimental setup, the performance gain is marginal and incremental. The metrics are not very standard."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lKk27QNrAY", "forum": "5hrCwqnBng", "replyto": "5hrCwqnBng", "signatures": ["ICLR.cc/2026/Conference/Submission16146/Reviewer_aPgr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16146/Reviewer_aPgr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16146/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761577239311, "cdate": 1761577239311, "tmdate": 1762926313451, "mdate": 1762926313451, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SYNTHIA, a GAN-inspired multi-agent framework for generating tabular synthetic data. In SYNTHIA, LLMs act as both the generator and discriminator, using metadata-aware prompting to synthesize data and language-based feedback loops guided by statistical diagnostics (including Chi-squared tests, KS-tests, KL-divergence, correlation similarity, and others) to iteratively improve data realism. This architecture replaces gradient-based optimization with feedback-driven prompt refinement, achieving convergence toward statistically indistinguishable data."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The generation of tabular synthetic data is a timely and important problem for the ICLR community. The paper presents a novel idea by employing LLMs as both the generator and discriminator within a GAN-inspired framework. Embedding statistical diagnostics such as Chi-squared, KS, KL-divergence, and correlation similarity directly into the feedback loop is a creative way to encourage distributional alignment between synthetic and real data. However, while this approach is likely to enhance data fidelity, it may also raise concerns regarding data privacy—a potential issue further discussed in the Weaknesses section."}, "weaknesses": {"value": "HIGH LEVEL SUMMARY OF WEAKNESSES:\n\nAt a conceptual level, the paper lacks a clear mechanism for balancing data fidelity and privacy, raising doubts about whether SYNTHIA can truly generate private data. The refinement process appears designed to maximize fidelity. Additionally, the potential for data contamination is also a concern.\n\nFurthermore, the experimental section raises substantial concerns about evaluation rigor and transparency. Many baseline results appear to have been directly copied from prior works (Zhang et al., 2024; Shi et al., 2025) without clear disclosure or confirmation that identical evaluation pipelines were used, making the reported comparisons potentially invalid. There are also inconsistencies across tables regarding datasets and baselines, with some entries seemingly mismatched or mislabeled, and possible confusion between the C2ST and DCR metrics. These issues, coupled with the limited number of datasets evaluated, insufficient methodological details, lack of standard deviation reporting, and unclear documentation of LLM usage, collectively undermine the credibility and reproducibility of the results. \n\nBelow, I describe all these issues in more detail. \n\nCONCEPTUAL ISSUES:\n\nOne key point that is not clear to me is how SYNTHIA controls the tradeoff between data fidelity and data privacy. As described in Appendix A.5 (Refinement Loop Termination Criteria) the refinement iterations continue until the discriminator decides the synthetic data cannot be distinguished from the real data using the process described in Appendix A.4 (Discriminator D_LLM). But it seems to me that this process will be much more effective in generating high fidelity data than in generating private data.  \n\nIn lines 316 to 320 and again in lines1492 to 1504 the paper claims that SYNTHIA is able to generate highly private data because it can flag when the statistical diagnostics metrics produce values that indicate suspiciously precise reproduction of the real data. But how exactly can the LLM discriminator decide when the metrics are indicating memorization? For instance, for the correlation similarity score we for sure have a problem when it is 1. But, how about when it is 0.95 or 0.99? We might still have severe privacy issues when these scores are high but not perfect. How can the LLM decide on an appropriate cutoff? \n\nI would think that a better way to balance the fidelity vs privacy tradeoff would be to add some privacy metrics to the statistical evaluator, so that the discriminator would have access to both fidelity and privacy information. This way you could, for example, prompt the discriminator LLM to (at the same time) look for increases in correlation and decreases in DCR to as close to 0.5 as possible. (As opposed to having to decide when the correlation is too high.) \n\nData contamination is another potential issue that worries me. If the LLM used by SYNTHIA’s generators has been trained on the public benchmark datasets used in the paper evaluations, the high fidelity achieved by the model could be due, at least in part, to data contamination. The fact that SYNTHIA converges in very few iterations is worrisome in this respect. (In line 896 the paper states that the iteration loop typically converges in 3 to 6 iterations.)\n\nEXPERIMENTAL ISSUES:\n\nFor most of the modern baseline models, the paper appears to have reused evaluation scores reported by Zhang et al. (2024) (which introduced TabSyn) and Shi et al. (2025) (which introduced TabDiff), without explicitly disclosing this or clarifying whether the same evaluation pipeline was employed. Unless identical procedures—such as train/test splits and other experimental settings—were used, the performance of these baselines is not directly comparable to that of SYNTHIA.\n\nFor example, the alpha-precision and beta-recall scores reported in Table 1 for the CTGAN, TVAE, GOOGLE, GReaT, StaSy, CiDi, and TabDDPM baselines on the Adult, Default, Shoppers, and Magic datasets are identical to those published in Tables 9 and 10 of Zhang et al. (2024)—with the only difference being that Table 1 rounds values to one decimal place, whereas Zhang et al. report two decimal places. The only exception is the TabSyn results, which differ systematically: Table 1 reports lower values than those in Zhang et al., even though the alpha-precision scores of TabSyn in Table 9 of Zhang et al. are actually higher than SYNTHIA’s corresponding scores.\n\nSimilarly, the DCR and C2ST results in Tables 5 and 6 of the paper are identical (after rounding) to the DCR and C2ST results in Tables 10 and 11 of Shi et al.\n\nThere are also inconsistencies in the baseline models and benchmark datasets reported across the three tables. Each table presents a different set of baselines. Moreover, Table 5 includes results for an additional dataset (Diabetes) that does not appear in Tables 1 or 6. Even more puzzling, the Magic dataset results in Table 5 are identical to those for the Beijing dataset in Table 10 of Shi et al. (2025), and the Diabetes results in Table 5 exactly match those for the News dataset in the same table of Shi et al. \n\nThe fact that the TabSyn results in Table 1 differ from those reported in Zhang et al. (2024) and Shi et al. (2025) suggests that the authors re-evaluated this baseline themselves. However, the consistently lower scores compared to the original papers indicate possible differences in the evaluation pipeline—such as variations in data splits, preprocessing, or other implementation details. Interestingly, the DCR and C2ST results for the TabSyn baseline in Tables 5 and 6 are identical to those in Tables 10 and 9 of Shi et al., implying that the paper did not recompute these particular metrics.\n\nTo ensure fair and meaningful comparisons across all baselines, the paper should either re-evaluate all baselines using its own experimental pipeline or re-run SYNTHIA’s evaluations following the same procedures used in the referenced works. If previously published results are reused, this must be explicitly disclosed to maintain transparency.\n\nEven more concerning, the paper presents conflicting descriptions of how the C2ST metric is interpreted. In lines 1471–1475, the paper states:\n\n“We also evaluate the Detection score using the Classifier Two-Sample Test (C2ST) … A score closer to chance-level performance (50%) indicates that synthetic and real data are indistinguishable, reflecting strong fidelity.” \n\nHowever, Table 6 reports C2ST scores following the SDMetrics convention, where the AUROC score is transformed to a scale from 0 to 1, with higher values indicating better fidelity. This inconsistency raises the possibility that the paper may have inadvertently swapped the DCR and C2ST results in Tables 5 and 6—that is, reporting the C2ST scores in Table 5 and the DCR scores in Table 6. Such a mix-up would make the results more credible to me, since C2ST values near 0.5 and DCR values near 1 would indeed correspond to high data fidelity and low privacy, respectively.\n\nAdditionally:\n\nThe evaluations cover only 5 datasets (which is relatively small for a paper making strong claims of state-of-the-art performance). The paper would benefit from performing comparisons over a more extensive set of datasets.\n\nRegarding the Traditional Techniques discussed in Section 4.1 (lines 300–305) and further detailed in Appendix D.4, the paper should provide clearer methodological descriptions and include appropriate citations to the referenced works. Although I am reasonably familiar with this literature, it is difficult to discern exactly which methods are being implemented based on the current presentation.\n\nSimilarly, the descriptions of the low-order metrics in Appendix D.5 should be expanded and clarified. It appears that the paper may be using metrics from DataCebo, but this is not explicitly stated. \n\nAlthough the paper states that each experiment was run 50 times, Table 1 reports only the average results. To better convey the reliability and variability of the findings, the paper should also report standard deviations.\n\nFINAL COMMENTS:\n\nThe paper does not provide any disclosure regarding the use of LLMs. While the proposed method itself relies heavily on LLMs, there may be other uses of these models within the paper that should be reported. For example, given the incomplete and occasionally inconsistent methodological descriptions—and the discrepancies observed across tables—it is possible that portions of the Appendix were generated or assisted by an LLM without thorough verification by the authors.\n\nI have not examined the theoretical formulation of the paper in detail, but it appears to rely heavily on conceptual analogies (such as framing “language updates as gradient steps”) to provide a form of mathematical grounding for the proposed method.\n\nFinally, although the supplementary materials include code for implementing SYNTHIA, they do not appear to contain scripts for reproducing the experimental results presented in the paper. (I was unable to locate these scripts upon a quick review of the provided files.)\n\n\nOVERALL ASSESSMENT:\n\nWhile the generation of tabular synthetic data is an important and timely topic for the ICLR community, the paper’s current presentation raises substantial concerns regarding the experimental results and their reproducibility. The lack of clarity about how SYNTHIA simultaneously achieves high fidelity and privacy, the potential for data contamination, incomplete methodological descriptions, and multiple inconsistencies across tables collectively undermine confidence in the paper’s claims of state-of-the-art performance.\n\nAt this stage, I recommend rejection. However, I would be open to revising this assessment if the paper can provide clearer explanations and stronger empirical evidence."}, "questions": {"value": "Can you explain in more detail how SYNTHIA would be able to generate highly private data, as claimed in the paper? \n\nHow does the method account for potential data contamination issues?\n\nIs SYNTHIA using the same evaluation pipeline as Zhang et al. (2024)?\n\nCan you double check that the paper is not mistakenly reporting the C2ST score in Table 5 and the DCR score in Table 6?\n\nWhy did the paper perform its own evaluation of SynTab for alpha-precision and beta-recall but not for the DCR and C2ST metrics?\n\nWhy the paper reports DCR and C2ST for both TabSyn and TabDiff but alpha-precision and beta-recall are only reported for TabSyn?\n\nCan you clarify any additional uses of LLMs, other than in the implementation of SYNTHIA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xhyCxhXDzl", "forum": "5hrCwqnBng", "replyto": "5hrCwqnBng", "signatures": ["ICLR.cc/2026/Conference/Submission16146/Reviewer_xVwa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16146/Reviewer_xVwa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16146/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990702313, "cdate": 1761990702313, "tmdate": 1762926313135, "mdate": 1762926313135, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a GAN-like framework using pretrained large language models for the roles of generator and discriminator. The prompt of the generator contains (1) metadata, (2) a sample of the training data and (3) feedback from the discriminator. The discriminator's prompt contains (1) the output of several measures comparing the synthetic data with real data, (2) a sample of synthetic data from the generator and (3) a sample of training data. The process is repeated until the discriminator outputs that the data is indistinguishable. The resulting synthetic data is evaluated using $\\alpha$-precision and $\\beta$-recall for fidelity and distribution coverage, distance to closest record for privacy risk, and detection score for measuring realism based on a post-hoc discriminator that attempts to discern real from synthetic samples."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "1. Extensive evaluation shows superior performance when compared with prior non-LLM based work.\n2. Comprehensive ablation study shows the importance of each component of the system.\n3. Novel direction for tabular data synthesis, the iterative generation of synthetic data under GAN-like conditions is a potential direction for zero- / few-shot generative models.\n4. Strong results even under modest levels of compute (using a high-end gaming setup) and could likely work on a laptop with minor tweaks."}, "weaknesses": {"value": "1. No related work on using large language models for tabular data generation. A brief literature search revealed the following relevant works:\n\t1. Wang, Yuxin, et al. \"HARMONIC: Harnessing LLMs for tabular data synthesis and privacy protection.\" _Advances in Neural Information Processing Systems_ 37 (2024): 100196-100212.\n\t2. Nguyen, Dang, et al. \"Generating realistic tabular data with large language models.\" _2024 IEEE International Conference on Data Mining (ICDM)_. IEEE, 2024.\n2. Some claims might require additional clarification or motivation:\n\t- **Line 185-187:** \"yielding synthetic data statistically indistinguishable from real data without memorization\" could benefit from additional details. It is clear from the paper that the discriminator, with help from the various statistical measures, helps to obtain \"statistically indistinguishable data\", but I cannot find any details in the paper that describes which parts of the model help it avoid memorization. Perhaps this can be clarified.\n3. Some additional details are necessary for reproducibility:\n\t1. What are the parameters and settings used for the various baseline models?\n\t2. What are the embedding functions used when calculating the $\\alpha$-precision and $\\beta$-recall? \n\t3. What is the similarity measure used for the distance to closest record (DCR) analysis?\n4. Limited discussion on the potential risk of the datasets being part of the training data of the LLMs used in this study."}, "questions": {"value": "1. To investigate whether the datasets are part of the LLM training data: Would it be possible to ablate the training data from the prompt altogether? I.e., to investigate whether the language models are able to generate the data without being shown the training data directly? Two experiments that might be interesting:\n\t1. The generator does not have access to any samples from the training data, while discriminator has access to samples from the training data. \n\t2. Neither the generator nor the discriminator have access to training data. \n2. Could you expand the related work section to also compare your model with pre-existing LLM-based approaches for generating tabular data? \n3. Have you seen any cases where the models does not converge to synthetic data that satisfies the discriminator? Did you have to put any mitigation in place to prevent this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hLAPwZBpyy", "forum": "5hrCwqnBng", "replyto": "5hrCwqnBng", "signatures": ["ICLR.cc/2026/Conference/Submission16146/Reviewer_EVqs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16146/Reviewer_EVqs"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16146/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991801239, "cdate": 1761991801239, "tmdate": 1762926312739, "mdate": 1762926312739, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}