{"id": "1OZLUrewhw", "number": 330, "cdate": 1756735641205, "mdate": 1759898267354, "content": {"title": "COMPASS: Training-Free Guidance for Skill Discovery with Human Feedback", "abstract": "Unsupervised skill discovery (USD) aims to learn diverse behaviors without reward functions, but often results in task-irrelevant or hazardous behaviors due to uniform exploration. Guided skill discovery (GSD) addresses this issue by incorporating human intent to focus exploration on meaningful and safe regions. However, existing GSD methods typically rely on pre-defined rules, expert demonstrations, or training instruction models, which are either costly to obtain or ineffective with sparse human feedback. To tackle this, we identify a key insight: a semantically coherent skill latent space, where nearby embeddings correspond to behaviors with similar human desirability, enables training-free guidance from sparse feedback. Building on this insight, we propose COMPASS, a training-free GSD framework that ensures semantic coherence in the latent space. Exploiting the coherence of this latent space, COMPASS constructs a dense, training-free guidance signal in this latent space, eliminating the need for any model training beyond the skill policy itself. This guidance signal is then integrated into skill discovery objectives to direct exploration toward human-desirable regions. Theoretical analysis guarantees the reliability of our training-free guidance signal, and extensive experiments across diverse state-based and pixel-based tasks show that COMPASS learns diverse, human-aligned skills, avoids hazardous behaviors, and achieves superior downstream performance with minimal human feedback.", "tldr": "", "keywords": ["Reinforcement Learning", "Skill Discovery"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/42b9f884d5f2e4da93ea45959358c14268747d19.pdf", "supplementary_material": "/attachment/014f7c8411911b8f435b219edd57f17338c4a705.zip"}, "replies": [{"content": {"summary": {"value": "Extends guided skill discovery with positive and negative labels to a small number of states to group skills in latent space according to similar human desirability without training. These skills are theoretically reliable in the sense that the probability of the skills failing is dependent on the smoothness of the feedback in latent space. Then, the skills avoid hazardous behaviors and achieve superior downstream performance empirically in simple mujoco domains with negative regions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This work introduces a simple and elegant method for including trinary human feedback into the online learning process of unsupervised skill discovery. This setting is underexplored and the simplicity is valuable.\n\nThis method provides an evaluation of the method and demonstrates that under appropriate settings it can perform well."}, "weaknesses": {"value": "This work tends to overstate and obfuscate what appears to be a straightforward concept and application, which makes it harder rather than easier to understand.\n\nThe evaluations for a setting predicated on human feedback signals do not include a human element such as noise, ease of providing feedback, or human evaluations.\n\nThe theoretical bounds appear to be quite loose in settings that are plausible, so the efficacy of the method is predicated on assumptions that are not necessarily strong, and there are no visualizations to suggest that a simpler metric, such as using the Euclidean distance between raw states would not work just as well in the settings evaluated."}, "questions": {"value": "Why isn't the insight of how the semantics are included (human trinary feedback) part of the abstract? This seems like an addition that would make it much less vague, since that appears to be the main algorithmic contribution and requirement for the method.\n\nIt seems like a formal description of guided skill discovery is missing from the preliminaries and perhaps not well defined, and since this is a core part of the algorithm, this is a significant oversight. \n\nThe use of the term \"training free\" seems to be inaccurate. While the feedback does not need to be separately trained, it does have to be incorporated during training. Thus, the term training-free is misleading, since without incorporation into the training loop the guidance signal is useless (unlike a method which modifies an existing set of unsupervised skills training free to match the desired constraints). \n\nThe derivation of the \"equivalent but more practical objective\" is given no space in the main paper. At least some intuition for how this transformation is justified in the main paper would be useful.\n\nThe notion of semantic coherence seems at odds with the notion that \"states occurring successively along a trajectory typically share similar desirability\" (L208). Besides the fact that \"typically\" is imprecise, it seems like a trajectory drawn from an unsupervised algorithm could easily move in and out of desirability, such as if it were desirable to move toward a goal, and the agent moved alternately towards and away from the goal (or in and out of a negative region). If the trajectories are sampled from an expert, then this would need to be stated since that is a significant departure from USD. \n\nA small note, but the use of \"camera rotation in visual environments\" is not a good example where semantically similar states may be far apart in state space, since camera rotation is not really a transformation of state as much as it is a transformation of observation in a partially observed environment. \n\nWhile the Bayes error rate is useful, it is not clear from the main paper how tight this bound is, since it seems like this value could actually be quite large in the case when the state is near a transition point of g(s).\n\nThe description from the introduction seems overstated, considering that the method is simply reweighting the DSD objective with a soft nearest neighbor in latent space. \n\nBecause the algorithm is not included in the main paper, Algorithm 1 seems like it would be necessary to be included in the main paper; otherwise, the actual procedure of COMPASS is opaque (the core algorithm should not be buried in the appendix)\n\nSince this guidance is used during training, it seems like there could be a case where the choice of guidance makes it hard for the agent to learn. In fact, this appears to be at least somewhat the case in the \"guidance signal smoothing\" section. A greater discussion of this and the actual techniques that were tried and failed should be included in the Appendix, since this would be a core tool for a downstream use case. \n\nThe evaluations seem insufficient, since one would expect a performance drop in some domains by adding the human constraint, but because of the choice of evaluations as simply 2D positive and negative regions with clear gaps for exploration, this does not end up being applied in a meaningful way. Inclusion of both noisy \"human signals\" and human feedback which transforms the task to be hard exploration, would make this a much more effective evaluation. \n\nAnother inadequacy of this work is the lack of human signals. Because this work is marketed as being guided by human segmentation, there is an expectation that at least some experiments where a human provides the guidance signal would be necessary to illustrate that the method has grounding.\n\nThe choice of baselines seems inadequate, since most of the methods are not meant to include human guidance at all (except for DoDont, which appears to be applied to a different setting). Since there appears to be a wider range of GSD algorithms, it would be useful to include more of these. \n\nIt seems like a good deal of coverage is left unreached in the experiments, so experiments with a much greater number of skills would help illuminate if the feedback produces dead regions, where, because of the feedback, the agent does not learn to reach certain positive regions, and if other methods can reach those regions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PoJoKRS0Up", "forum": "1OZLUrewhw", "replyto": "1OZLUrewhw", "signatures": ["ICLR.cc/2026/Conference/Submission330/Reviewer_tmQR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission330/Reviewer_tmQR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761411816259, "cdate": 1761411816259, "tmdate": 1762915495266, "mdate": 1762915495266, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "COMPASS addresses the pretraining phase of unsupervised skill discovery. Specifically, the authors assume there are some “good” pretraining behaviors to learn and “bad” ones to avoid. For example, a good behavior could be learning different skills that move north-ward, whereas a bad behavior may be moving in the other directions. Notably, we desire imbuing these biases during the skill pretraining phase, and not the downstream finetuning phase, because we would like to explore useful skills given these constraints and human priors.\n\nTo do this, COMPASS augments an existing guided skill discovery framework, DSD / Do’s Don’t, with (1) a semantically coherent latent space and (2) human-in-the-loop queries. A coherent latent space is a prerequisite for this type of constrained skill discovery, and the human-in-the-loop queries are necessary as the only way of identifying good/bad transitions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem is scoped appropriately.\n2. COMPASS results are compelling and show an improvement over existing baselines."}, "weaknesses": {"value": "1. The contributions are fairly minimal. First, the scope of this is limited to simulated environments with scripted teacher. Second of all, the contribution on top of DoDon’t is minimal, with the primary differences being the different scoping.\n2. I think it could be made slightly clearer what parts of the method are strictly taken from prior work, and which parts are novelties for this method.\n3. Prior work on human feedback does not feel adequately represented in related work / prior works.\n4. Some of the numbers (Table 3, 4, etc.) are kind of hard to parse. For example, could the state space coverage be normalized so it reports what % of the trajectories (or steps within the trajectory) are taken in the safe zone? Essentially normalizing the existing numbers -- if I understand how it is being computed."}, "questions": {"value": "1. How important is the semantic latent space?\n2. I understand that the goal is learning useful pretrained skills. However, since there is some metric of desired downstream tasks (“move in general direction,” “avoid these hazards”), why not incorporate this, so the skill discovery reward supplements a pretraining task reward? Baselines where DIAYN/METRA are aware of pretraining hazards/rewards could be valid baselines."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "U5ACJwDMYC", "forum": "1OZLUrewhw", "replyto": "1OZLUrewhw", "signatures": ["ICLR.cc/2026/Conference/Submission330/Reviewer_LQ8d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission330/Reviewer_LQ8d"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761674520825, "cdate": 1761674520825, "tmdate": 1762915494974, "mdate": 1762915494974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a guided skill discovery method as an extension to METRA where it learns an extra weight function based on human feedback to reduce intrinsic reward in undesired states. The weight function is based on the nearest neighbor method and thus does not require parameter learning. Additionally, the authors propose an active learning method to gather human feedback, based on state coverage."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well written. The clear presentation and the adequate coverage of preliminaries make the paper easy to follow.\n2. The proposed framework of combining reward weight in the representation space learned by METRA is interesting and novel.\n3. The ablation of human label query methods is helpful for evaluating the effectiveness of different active learning methods."}, "weaknesses": {"value": "My major concerns are the effectiveness of the **non-parametric** guidance function $w(s)$ and the assumption that $\\phi$ learned by METRA is a good representation space to **semantically** adjust skill behavior.\n\nSpecifically, the paper mainly focuses on navigation tasks with relatively simple unsafe zones. However, in many tasks the unsafe space would be complex. For example, in the kitchen environment used by METRA, we would like the arm to avoid self-collision and collision with other fixed furniture. In the configuration space, the unsafe region would be a complex non-convex space, and I doubt the proposed non-parametric form of guidance function could effectively representation such a space. Especially as current experiment results already somewhat show COMPASS's ineffectiveness with slightly complex safe/unsafe boundaries: in all hole environments, the skills learned by COMPASS, though avoiding the whole, barely explores the region behind the hole. Instead, most skills simply keep moving straight forward after passing the holes. Of course, given that METRA mainly learns moving straight skills, it's hard to tell whether the under-exploration comes from METRA's limitation of $w$'s ineffectiveness. Any insights / empirical results on how the proposed non-parametric $w$ can (or how to adapt it to) work / scale to complex safety boundaries are welcome."}, "questions": {"value": "1. L440, \"Boundary\" approach should be \"Uncertainty\"?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FTwsbFSGXA", "forum": "1OZLUrewhw", "replyto": "1OZLUrewhw", "signatures": ["ICLR.cc/2026/Conference/Submission330/Reviewer_AmYS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission330/Reviewer_AmYS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892765650, "cdate": 1761892765650, "tmdate": 1762915494797, "mdate": 1762915494797, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a way to achieve guided skill discovery without relying on predefined rules, expert demonstrations or training instruction models. The method is based on  the insight that behaviours with a similar human desirability lie close to each other in a semantically coherent skill latent space. This insight is used to construct a training-free guidance signal which is then used in skill discovery in order to learn aligned and safe skills with minimal human feedback."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an important problem – that of learning aligned skills via skill discovery. The overall method is quite intuitive and it seems to be effective. The paper is also generally presented well."}, "weaknesses": {"value": "Although the approach seems simple and intuitive, I am not very convinced about the way human labels are used. I suspect treating all states within a segment to have the same label may require segments to be very short, and may not work well in general. \n\nAlso, I am unsure how COMPASS compares to other existing approaches that aim to solve the same problem. For instance, two works that seem very related, but are not discussed in the paper are:\n[1] Controlled Diversity with Preference: Towards Learning a Diverse Set of Desired Skills. In Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems. 2023.\n \n[2] Human-Aligned Skill Discovery: Balancing Behaviour Exploration and Alignment. In Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems (AAMAS '25). International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC, 1025–1033.\n\nParticularly [1], which learns a desired state region from human preferences seems to have quite a lot of similarities with the paper, perhaps enough to warrant an empirical comparison, at least in the simple environments in Fig 2."}, "questions": {"value": "1. The assumption that all states within segment carry the same label seems overly simplistic. I would assume this approach only works when very small segments are used. Have the authors considered using approaches like diverse density [3] to better capture the landscape of ‘good’, ‘bad’ and ‘neutral’ states?\n\n2. Related to the previous question – how does the performance vary with longer trajectory segments?\n\n3. What happens to states that are part of both ‘good’ as well as ‘bad’ trajectory segments? How are the labels for these states decided?\n\n4. How many samples does COMPASS use for different types of problems?\n\n5. I would also be curious to seem how sensitive COMPASS would be with decreasing availability of human data.\n\n6. How sensitive is COMPASS’s performance with and without active query selection?\n\n[3] \"A framework for multiple-instance learning.\" Advances in neural information processing systems (1997)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hzrTUqY18p", "forum": "1OZLUrewhw", "replyto": "1OZLUrewhw", "signatures": ["ICLR.cc/2026/Conference/Submission330/Reviewer_wg5W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission330/Reviewer_wg5W"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762090580886, "cdate": 1762090580886, "tmdate": 1762915494542, "mdate": 1762915494542, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}