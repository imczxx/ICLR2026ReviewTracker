{"id": "UERyQwQ4zq", "number": 7810, "cdate": 1758037157702, "mdate": 1759897831108, "content": {"title": "Dataset Protection via Watermarked Canaries in Retrieval-Augmented LLMs", "abstract": "Retrieval-Augmented Generation (RAG) has become an effective method for enhancing large language models (LLMs) with up-to-date knowledge. However, it may pose a significant risk of copyright infringement, as IP datasets may be incorporated into the knowledge database by malicious Retrieval-Augmented LLMs (RA-LLMs) without authorization. To protect the rights of the dataset owner, an effective dataset membership inference algorithm for RA-LLMs is needed. In this work, we introduce a novel approach, \\textit{CanaryTrace}, to safeguard the ownership of text datasets and effectively detect unauthorized use by the RA-LLMs. Our approach preserves the original data completely unchanged while protecting it by inserting specifically designed canary documents into the IP dataset. These canary documents are created with synthetic content and embedded watermarks to ensure uniqueness, consistency, and statistical provability. During the detection process, unauthorized usage is identified by querying the canary documents and analyzing the responses of RA-LLMs for statistical evidence of the embedded watermark. Our experimental results demonstrate high query efficiency, detectability, and consistency, along with minimal perturbation to the original dataset, all without compromising the performance of the RAG system.", "tldr": "", "keywords": ["LLM", "Watermark", "RAG", "Dataset Protection"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bf94036ed0e4d9eb9eef86402180fb7d4c67ac96.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces CanaryTrace, a novel framework for protecting intellectual property datasets used in retrieval-augmented large language models. Instead of altering the original data, the method inserts synthetic, watermarked canary documents designed to be indistinguishable from the authentic dataset. These canaries are generated using a watermarked LLM and maintain consistency with the original dataset. When a potentially infringing RAG system is queried, the presence of the embedded watermark in model outputs serves as statistical evidence of dataset misuse. Empirically, CanaryTrace achieves 100% detection performance with only 12 queries, preserves dataset utility and maintains downstream RAG task performance across multiple datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The authors propose a novel canary strategy, which combines imperceptible watermarking and synthetic text generation, maintaining the original dataset completely intact.\n\n- Extensive experiments across different datasets and retrievers demonstrate robustness, query efficiency, and minimal dataset distortion.\n\n- The framework operates without access to model logits, making it deployable against closed-source RAG systems like GPT-5 or Gemini."}, "weaknesses": {"value": "- Although the number of inserted canary documents is small, their presence could still introduce noise in large-scale retrieval systems. Normal user queries may inadvertently retrieve these synthetic canaries, slightly degrading retrieval precision or response quality in downstream applications.\n\n- Despite efforts to ensure attribute-level consistency, there remains an inherent discrepancy between the original IP documents and the synthesized canaries. A sophisticated adversary could exploit subtle stylistic, semantic, or embedding-level differences to identify and filter out canary documents, thereby weakening the protection mechanism.\n\n- The proposed z-test for watermark detection assumes that the queries used are independent. In practice, query correlation (e.g., overlapping semantics or shared retrieval results) could violate this assumption, leading to biased z-scores and inaccurate p-values, potentially affecting the reliability of the detection decision."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qja4qfrain", "forum": "UERyQwQ4zq", "replyto": "UERyQwQ4zq", "signatures": ["ICLR.cc/2026/Conference/Submission7810/Reviewer_yvtf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7810/Reviewer_yvtf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7810/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761852449545, "cdate": 1761852449545, "tmdate": 1762919851104, "mdate": 1762919851104, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces CanaryTrace, a dataset-ownership protection scheme for RAG systems. It inserts a small set of synthetic, watermarked canary documents that (1) match the attributes of the dataset, (2) are fictional to ensure the uniqueness for high retrievability, and (3) are robust enough so their content causes a detectable watermark signal to diffuse into RAG responses when retrieved. Experiments show strong target-retrieval accuracy and detection, while leaving downstream RAG accuracy intact."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.The DMI-RAG task is well-posed, which keeps the original dataset untouched, avoids quality regressions common to paraphrase-based watermarking, and canaries provide separable evidence\n\n2.The work provides a principled synthesis pipeline. \n\n3.Detection with statistical guarantees.\n\n4.Extensive experiments and strong empirical results under realistic constraints."}, "weaknesses": {"value": "1. More broader evaluation of robustness should be done. How does detection performance change if the generator performs an aggressive attack, e.g., paraphrasing, before answering?\n\n2. The experiments show the effectiveness of the watermarked canary on text RAG. Can you discuss its potential application to non-text RAG, e.g., image?"}, "questions": {"value": "Have you considered a standardized disclosure (e.g., a notarized canary list and key escrow) to bolster evidentiary value?\n\nHow should practitioners choose $\\eta$ to achieve, say, 1% FPR?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hSR1wrDDnK", "forum": "UERyQwQ4zq", "replyto": "UERyQwQ4zq", "signatures": ["ICLR.cc/2026/Conference/Submission7810/Reviewer_MqVp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7810/Reviewer_MqVp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7810/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878792315, "cdate": 1761878792315, "tmdate": 1762919850099, "mdate": 1762919850099, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses dataset copyright protection in Retrieval-Augmented Generation systems, which risk unauthorized incorporation of intellectual property datasets into Retrieval-Augmented LLMs. The authors propose CanaryTrace, a novel method for detecting dataset misuse. CanaryTrace works by inserting synthetic documents that contain unique, statistically provable embedded watermark into the original dataset without altering it. When unauthorized use occurs, querying these canaries from the RA-LLM reveals statistical evidence of the watermark. Experiments show high query efficiency, detectability, and consistency, with minimal impact on dataset quality or RAG performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper introduces a black-box dataset protection framework that preserves the integrity of the original IP dataset while achieving high detection accuracy through LLM-based watermarking in synthetic canary documents\n\n- The authors conduct extensive experiments demonstrating strong quantitative performance, including high retrieval accuracy with minimal queries and negligible impact on downstream RAG tasks"}, "weaknesses": {"value": "- The proposed method lacks clear novelty. Its core idea primarily relies on applying existing watermarking techniques within the RAG framework. While the implementation is well-executed, the approach essentially extends known watermarking methods to a familiar setting without introducing fundamentally new algorithms or theoretical insights.\n\n- The method used to detect the watermark also lacks clear novelty. This paper primarily applies an existing detection algorithm to detect the watermark."}, "questions": {"value": "What is the retriever model used for the experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zjh75sRcSF", "forum": "UERyQwQ4zq", "replyto": "UERyQwQ4zq", "signatures": ["ICLR.cc/2026/Conference/Submission7810/Reviewer_KykN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7810/Reviewer_KykN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7810/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761940564125, "cdate": 1761940564125, "tmdate": 1762919849681, "mdate": 1762919849681, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel method for dataset copyright protection in retrieval-augmented large language models (RAG-LLMs) via the use of watermarked canaries. The key idea is to embed special, inconspicuous textual fragments (canaries) into the retrieved data with imperceptible yet verifiable watermarks. These canaries enable the dataset owner to later verify unauthorized usage or leakage of their dataset in an LLM system, even when the model or retriever is proprietary.\n\nThe authors design semantic-preserving watermarking techniques to inject canaries without degrading retrieval or generation quality.\n\nThey introduce an adaptive embedding mechanism that selects insertion points based on retrieval relevance and semantic alignment.\n\nA verification framework detects the presence of watermarked canaries in LLM outputs through probabilistic decoding analysis and semantic matching.\n\nThe approach is evaluated on multiple RAG settings (e.g., GPT-4-retrieval hybrid, open-source retrievers)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. address a timely problem for protecting the intellictual property for external knowledge base used for the RAG system.\n\n2. The results evaluated on various dataset is really good.\n\n3. The presentation is easy to understand."}, "weaknesses": {"value": "1. There is no thereotical guarantee that this unique  (e.g., \"VitalityBoost and ExerciseShield \" ) will trigger the retrieval of systhetic paragraph. For example, what happens if these unique content (e.g., \"VitalityBoost and ExerciseShield \" ) will exist in other  external knowledge bases which would be combined into the protected dataset. \n\n2. How do you verify the ownership with answers containinng the sythentic content. It is possible that the user claim that their knowledge base contains these contents? Different from other backdoor-based defense, they have malicious behaviour used as verification evidence.  \n\n3. I here challenge the novely of this paper as it seems a variant of previous work [1]. Both of these work use generated / systhetic paragraph / content as evidences for ownership. I would like to see the merits or disadvantages of this work comparing with previous work.\n\n4. There is no evaluation on real-world IP-sensitive database such as Harry Potter series book.\n \n5. Lack important baselines, such as membership inference-based approaches and a general framework for data use auditing (CCS). \n\n6. How can you ensure your question will accurately retrieve the synthetic content aas you expected with varying k and the external datasets ?\n\n\n[1] Towards copyright protection for knowledge bases of retrieval-augmented language\nmodels via ownership verification with reasoning. arXiv preprint arXiv:2502.10440, 2025"}, "questions": {"value": "See Above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pOLndCi4wE", "forum": "UERyQwQ4zq", "replyto": "UERyQwQ4zq", "signatures": ["ICLR.cc/2026/Conference/Submission7810/Reviewer_djSQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7810/Reviewer_djSQ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7810/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762240804400, "cdate": 1762240804400, "tmdate": 1762919849337, "mdate": 1762919849337, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}