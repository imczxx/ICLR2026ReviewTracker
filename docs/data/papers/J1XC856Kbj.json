{"id": "J1XC856Kbj", "number": 17313, "cdate": 1758274631620, "mdate": 1763654820265, "content": {"title": "Provable Adversarial Detection: Prime Quantization meets Gromov–Wasserstein", "abstract": "Adversarial vulnerability persists across modern vision architectures from CNNs to vision language models (VLMs), yet existing detection methods rely on heuristics without theoretical guarantees. We address the fundamental question of when adversarial perturbations can be provably detected from a geometric perspective.\nOur key insight is that adversarial perturbations cannot simultaneously preserve geometric structure across spaces with fundamentally different properties. Accordingly, we construct two such complementary metric spaces.\nFirst, we use a standard CNN embedding space $Z$, where adversarial samples exhibit significant displacement patterns. Second, we build a novel prime-quantized space $P$, that absorbs small perturbations through number-theoretic discretization, resulting in minimal displacement, while preserving discriminability. We then leverage the geometric discrepancies across spaces $Z$ and $P$ to detect adversarial samples.\nTo the best of our knowledge, we establish the first rigorous separation theory for adversarial detection, proving that adversarial samples create unavoidable geometric inconsistencies across both spaces. Our framework provides theoretical guarantees including pixel-level absorption bounds, neighborhood diameter concentration, Gromov-Wasserstein (GW) separation theorems, and practical risk control.\nExtensive experiments validate our theoretical predictions and achieve consistently strong detection performance across a wide range of attack types and model families.", "tldr": "Our work introduces prime quantization and cross-space geometry as a principled foundation for adversarial detection with formal guarantees and broad empirical validation.", "keywords": ["Adversarial detection", "prime quantization", "Gromov-Wasserstein geometry", "theoretical guarantees", "robust ML"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c66c562632b8f01b5461cb09cc2dff2d4568f293.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a theoretically grounded framework for adversarial example detection that combines prime quantization with Gromov-Wasserstein (GW) geometric analysis. The core idea is to map images into two complementary spaces:\n\n1. a conventional CNN embedding space Z\n\n2. a prime-quantized space P, where each pixel is rounded to nearby prime numbers under a secret bit mask.\n\nThe paper shows that adversarial perturbations necessarily create geometric inconsistencies between Z and P. It formally proves pixel-level absorption bounds, image-level injectivity, diameter concentration theorems, and GW-based separation theorems, culminating in provable detection guarantees. Empirical results on CIFAR-10, FMNIST, and KMNIST, as well as zero-shot VLMs (LLaVA-1.5), show strong detection accuracy and robustness against adaptive attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.This paper has a strong theoretical grounding, where formal guarantees (absorption, injectivity, GW gap) are well-motivated and rigorously proved.\n\n2.Proposing original concept, Introducing prime quantization as a geometric stabilizer is novel and intellectually elegant.\n\n3.This paper conducts a comprehensive assessment, it covers a wide range of attack types and adaptive scenarios, including VLMs.\n\n4.It achieves robust empirical performance, consistently outperforms strong baselines with 95–98% detection accuracy.\n\n5.The paper effectively combines theory and practice, demonstrates provable guarantees in a domain usually dominated by heuristics."}, "weaknesses": {"value": "1.Limited computational analysis: GW computations are known to be expensive (even with entropic regularization). The paper lacks runtime and scalability metrics for large-scale or real-time deployment.\n\n2.Code is not yet released, which limits reproducibility at review time.\n\n3.The zero-shot experiments are promising but limited to CalTech-101 and LLaVA-1.5. It needs more diverse multimodal tests to increase generality."}, "questions": {"value": "1.Could you clarify the computational complexity of the proposed detector, especially regarding GW distance estimation for large K-NN neighborhoods?\n\n2.I’m curious about how sensitive the detector is to the choice of the prime resolution parameter k and the secret bit mask b?\n\n3.Would replacing primes with another non-uniform discretization (e.g., Fibonacci numbers) yield similar theoretical properties?\n\n4.Could the framework be extended beyond vision tasks such as graph or tabular modalities? Are metric-space inconsistencies also meaningful in these tasks?\n\n5.Are there any potential risks if the secret key bis leaked (e.g., adversarial reverse-engineering of P)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "dVoA0ahTxy", "forum": "J1XC856Kbj", "replyto": "J1XC856Kbj", "signatures": ["ICLR.cc/2026/Conference/Submission17313/Reviewer_rTka"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17313/Reviewer_rTka"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761465253974, "cdate": 1761465253974, "tmdate": 1762927246336, "mdate": 1762927246336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a prime quantisation–based detector that identifies adversarial samples by measuring geometric inconsistencies between the embedding and quantised spaces using entropy-regularised Gromov–Wasserstein distances. It provides theoretical guarantees of separability and shows strong empirical performance across various attacks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper presents detailed theoretical analyses that show solid effort in formalising the proposed detection approach.\n\n- The experimental results look promising. The evaluations on vision–language models suggest the potential generality of the proposed method."}, "weaknesses": {"value": "1.  It is not surprising that any perturbations could induce inconsistencies between the original embedding space and a quantised representation, leading to detectable shifts in geometry.\nWhat remains unclear is why the proposed prime quantisation space is specifically necessary for this effect. Would other quantisation schemes (e.g., uniform or logarithmic quantisation and [a]) fail to provide similar separability? A comparison or justification along these lines would greatly clarify the unique role and necessity of the prime-based construction.\n\n2. An important missing aspect is the method’s behaviour under random or benign perturbations (e.g., Gaussian or sensor noise) [b]. Without such control experiments, it’s unclear whether the detector is truly specific to adversarial manipulations. \n\n3. In addition, relying solely on accuracy and TPR is not sufficient to assess detection performance. Please consider reporting more informative metrics such as the PR curve, ROC–AUC, and F1 score to provide a fuller picture. The baseline methods appear to be outdated. Please consider adding more recent defences, such as [a].\n\n[a] Dong, Z., & Mao, Y. (2023). Adversarial defenses via vector quantization. arXiv preprint arXiv:2305.13651.\n\n[b] Hendrycks, D., & Dietterich, T. (2019). Benchmarking neural network robustness to common corruptions and perturbations. ICLR. 2019."}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IpAbHr8aPs", "forum": "J1XC856Kbj", "replyto": "J1XC856Kbj", "signatures": ["ICLR.cc/2026/Conference/Submission17313/Reviewer_rZii"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17313/Reviewer_rZii"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761751257569, "cdate": 1761751257569, "tmdate": 1762927246092, "mdate": 1762927246092, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method for detecting adversarial samples by comparing geometric differences between samples in two distinct spaces and provides a geometric proof that adversarial perturbations can be identified. Specifically, the authors construct two complementary metric spaces: the standard CNN embedding space Z and the prime quantization space P, which discretizes pixel values by rounding them to the nearest prime number. Adversarial detection is then performed by assessing structural consistency between these two spaces. Experimental results show that the proposed detection method outperforms baseline approaches against a variety of attack methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper establishes a rigorous theoretical framework for adversarial detection and proves that adversarial perturbations inevitably lead to cross-space inconsistencies.\n\n2. This paper introduces a prime quantization space capable of dampening small perturbations to preserve the distinguishability of adversarial samples.\n\n3. Experimental results demonstrate that the proposed method outperforms baseline approaches, confirming its performance advantages."}, "weaknesses": {"value": "1. In the algorithm, the authors neither clearly define the two scales lo and gl nor specify how they are used in the experiments. The authors should explicitly define these parameters and clarify their roles in the framework. Moreover, it remains unclear why only two scales are considered, rather than exploring a wider range of scales for a more comprehensive analysis.\n\n2. In Section 5.1, the authors state that the budget for real-world adversarial attacks typically exceeds the absorption radius, allowing attacks to penetrate the stable region of the P-space and produce detectable discrepancies between the two spaces. However, this discussion fails to consider imperceptible adversarial attacks (e.g., AdvAD [1]), which typically involve extremely small perturbation magnitudes.\n\n3. The experimental results presented in Table 1 of Section 6.2 are not sufficiently comprehensive. The evaluation should incorporate more recent attack [2–3] and defense [4–5] methods to ensure a fair and up-to-date comparison. The lack of such inclusion limits the representativeness of the results and diminishes the credibility of the claimed effectiveness and superiority of the proposed method.\n\n4. In Section 6.2, the authors use only ResNet-18 as the surrogate model, which limits the generalizability of the results. Moreover, the evaluation is conducted solely on small-scale datasets such as CIFAR-10, FMNIST, and KMNIST, without including a large-scale dataset like ImageNet.\n\n5. Notably, GW distance computation typically entails high computational costs. However, the experimental section does not include efficiency or cost comparisons with other methods, which may limit the practical applicability of the proposed detection approach.\n\n[1] AdvAD: Exploring Non-Parametric Diffusion for Imperceptible Adversarial Attacks. NeurIPS 2024.\n\n[2] Boosting Adversarial Transferability by Achieving Flat Local Maxima. NeurIPS 2023.\n\n[3] Boosting Adversarial Transferability by Block Shuffle and Rotation. CVPR 2024.\n\n[4] Detecting Adversarial Data by Probing Multiple Perturbations Using Expected Perturbation Score. ICML 2023.\n\n[5] Be Your Own Neighborhood: Detecting Adversarial Examples by the Neighborhood Relations Built on Self-Supervised Learning. ICML 2024."}, "questions": {"value": "1. Could the authors clarify whether the proposed GW-based method is capable of detecting imperceptible adversarial attacks (e.g., AdvAD)? Furthermore, are all the relevant theorems still valid when dealing with extremely small adversarial perturbations?\n\n2. How are the two scales (lo and gl) utilized in the experiments, and how are their optimal values determined? What performance differences are observed under different scale settings? Additionally, could incorporating more scales further enhance the defense performance?\n\n3. How does the proposed detection method compare with state-of-the-art approaches when evaluated across various CNN and ViT architectures and tested against recent attack methods? Additionally, how does its performance differ when applied to ImageNet, a widely used benchmark dataset in the adversarial attack field?\n\n4. What is the efficiency of the proposed detection method, such as runtime and memory usage, compared with state-of-the-art detection approaches?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AYnRZQUWlD", "forum": "J1XC856Kbj", "replyto": "J1XC856Kbj", "signatures": ["ICLR.cc/2026/Conference/Submission17313/Reviewer_ZUqf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17313/Reviewer_ZUqf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992416398, "cdate": 1761992416398, "tmdate": 1762927245748, "mdate": 1762927245748, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel detection method against adversarial examples. In particular, the paper introduces a new technique, prime quantization, that maps the given input to a quantized space. The main trick is based on the discrepancy of two spaces: the feature embedding extracted by the classifier and the quantized space. Due to the property of the quantized space, there are systematic discrepancies between the probability distributions derived from the neighborhoods of the input point’s mapping in each space. To utilize these differences, the method uses the Gromov-Wasserstein (GW) distances between neighborhood-induced distributions as new feature vectors that the detector utilizes. The paper provides several theoretical results. The main theoretical results prove the upper bound of the GW distance (for benign inputs) and the lower bound of the GW distance (for adversarial inputs), which guarantees the effectiveness of the detection method. Through experiments, the paper demonstrates the effectiveness of the proposed method."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. To the best of my knowledge, the proposed method is novel.\n2. The concept of prime quantization seems interesting.\n3. The proposed method has a theoretical guarantee.\n4. The experiment on detection effectiveness covers various setups, including three datasets, thirteen attack methods, and four baseline detection methods.\n5. The experimental results demonstrate clear improvements over various attack methods.\n6. The paper also considers the adversary who adapts the attack, and demonstrates the robustness against the adaptive attack."}, "weaknesses": {"value": "1. The baseline detection methods are relatively old. It would be better to include more recent works on adversarial example detection.\n2. Only one model (ResNet18) was used in the experiment."}, "questions": {"value": "1. Consider adding some comparison to more recent detection methods.\n2. Is there a specific reason why the experiment used the ResNet18 architecture? If I understand correctly, the detection method is model-agnostic and should show the improvement even when a different model architecture is used. Please add more results with a different model architecture."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "glrBkjWdFB", "forum": "J1XC856Kbj", "replyto": "J1XC856Kbj", "signatures": ["ICLR.cc/2026/Conference/Submission17313/Reviewer_hd7U"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17313/Reviewer_hd7U"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762146930543, "cdate": 1762146930543, "tmdate": 1762927245392, "mdate": 1762927245392, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global Response to all Reviewers"}, "comment": {"value": "We thank all reviewers for their thoughtful and constructive feedback. Their comments helped us substantially strengthen both the empirical evaluation and the presentation. All newly added material appears in blue in the revised manuscript.\n\n**Expanded empirical evaluation.** We added several missing *recent* adversarial detectors (EA, BY) and a broad set of *modern attacks*, including low-magnitude and optimization-free variants (AdvAD/AAD, PGN, BSR). These are now comprehensively evaluated across CIFAR-10 in both the main paper and Appendix L, using multiple metrics (accuracy, AUROC, F1). Our method consistently remains the strongest detector across settings.\n\n**Architectural and dataset diversity.** We now validate the detector on both ResNet-18 and ViT, and we added an ImageNet evaluation. Performance remains strong across architectures and scales, supporting the model-agnostic nature of the approach.\n\n**Zero-shot VLM experiments.** We broadened the VLM study by adding more datasets (Food-101, CalTech-256) and multiple attacks for LLaVA-1.5 and Qwen-2.7B-VL. The detector maintains high accuracy in realistic, API-only zero-shot settings.\n\n**Runtime and memory analysis.** We added a detailed profiling table showing that the method is computationally practical: entropic-GW operates on small neighborhoods, converges in a few iterations, and has modest memory usage.\n\n**Robustness to benign corruptions.** We included CIFAR-C experiments (Gaussian and common corruptions), showing that the detector does not misclassify natural noise as adversarial.\n\n**Ablations and sensitivity analyses.** We added sensitivity studies for the prime-resolution parameter k, and for the local/global scales used in the GW coupling. Detection accuracy is stable across a wide range, validating that no fine-tuning is required.\n\n**Clarifications and theoretical refinements.** We expanded explanations of the absorption radius, injectivity preservation, GW-separation, and the geometric roles of the local/global neighborhood operators. We also clarified the behavior under imperceptible perturbations and contrasted our prime-based discretization with uniform, logarithmic, and Fibonacci schemes, which empirically fail to yield meaningful Z–P separation.\n\nWe hope that the expanded experiments, clarifications, and additional analyses fully resolve the concerns raised during the initial review. The revised manuscript now provides a broader, clearer, and more rigorous presentation of the method. We appreciate the reviewers’ careful consideration and would be grateful if the improvements in the revised version are reflected in their final evaluation."}}, "id": "pOOnzYC1Pq", "forum": "J1XC856Kbj", "replyto": "J1XC856Kbj", "signatures": ["ICLR.cc/2026/Conference/Submission17313/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17313/Authors"], "number": 9, "invitations": ["ICLR.cc/2026/Conference/Submission17313/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763656659035, "cdate": 1763656659035, "tmdate": 1763656659035, "mdate": 1763656659035, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}