{"id": "0uiWQTYpzb", "number": 12513, "cdate": 1758208326442, "mdate": 1759897504783, "content": {"title": "Histogram-Guided Source-Free Domain Adaptive Regression", "abstract": "Source-Free Domain Adaptation (SFDA) enables model adaptation under distribution shifts without access to source data, making it an appealing solution for privacy-sensitive applications. Despite being a fundamental problem in machine learning, regression remains largely underexplored in SFDA, where most existing work has focused predominantly on classification tasks. To bridge this gap, we propose a novel algorithm that leverages sample-wise, histogram-informed supervisory signals to refine pseudo-labels under an uncertainty-aware paradigm. This design simultaneously achieves pseudo-label refinement and uncertainty modeling, two key components that are critical for effective adaptation in classification but remain largely absent in regression. We further theoretically show that the resulting histograms exhibit robustness to potential perturbations, supporting reliable SFDA for regression. Empirical results across multiple benchmarks confirm the effectiveness of our method and reveal that histogram-guided learning promotes more compact and structured feature representations, mitigating the inherent challenges of adapting regression models under distribution shift.", "tldr": "", "keywords": ["Domain adaptation", "unsupervised learning", "regression model"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f266b4f513e473cd738a5a05a6bb1548b91d615f.pdf", "supplementary_material": "/attachment/52991e65631ed69e2cffd1ef79226ed88e73aeae.zip"}, "replies": [{"content": {"summary": {"value": "Summary:\n\nThis paper introduces a novel approach that uses histogram-based supervision signals to improve pseudo-label quality for domain adaptation, addressing challenges caused by domain shifts. \n\nThe proposed method integrates pseudo-label refinement and uncertainty modeling for more effective adaptation. \n\nThe authors also provide a theoretical perspective connecting histogram information transfer from classification to regression problems and demonstrate experimental results on several small-scale datasets showing performance gains."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Strengths:\n\n+ As a first-version submission, the paper appears largely complete in structure and scope.\n  \n+ The authors offer some insightful analyses and discussions based on small-scale datasets, providing potentially valuable intuitions.  \n\n+ Several visualizations (e.g., Fig. 4) are appealing and help illustrate the method, though their explanations could be improved."}, "weaknesses": {"value": "Weaknesses:\n\n**Major**\n\n- The manuscript is written in an unnecessarily complex manner. Several key concepts (e.g., “continuous”, “discrete”) are introduced without sufficient explanation. The method section is sparsely organized and lacks logical flow, making it difficult to grasp the core innovations. The notions of *deterministic output* and *explicit uncertainty* are mentioned but not clearly defined or contextualized.  \n\n- Several definitions and notations are unclear or missing. For example: (i) The meaning of $Y$ (Line 50, Page 1) is not defined before use. (ii) The round circle operation (Line 151, Page 3) and notation $[K]$ (Line 158) are not explained. (iii) Mathematical symbols such as $\\lambda_{\\text{prior}}$ and $L_{\\text{PL}}$ (Eq. 1) lack definition. (iii) Equations are inconsistently numbered, with several (e.g., Lines 268, 299–300, 319–320) missing equation numbers. (iv) Some equations appear incorrect or ambiguous (e.g., Line 268, where $|S|$ is used inconsistently with its earlier definition as a cardinality term).\n\n- Methodology presentation issues: (i) The main pipeline in Fig. 2 is unclear. The caption is too short and fails to explain the figure’s content or the work’s innovation. (ii) Many symbols (e.g., PL, KL, $k\\sigma$, $\\mu$, “/”) are unexplained. (iii) The meaning of “dropout sampling” and “continuous pseudo labels” is vague, along what dimension are the pseudo labels continuous? (iii) Line 203–204 lacks precision in describing what is actually used. (iv) The explanation of “cross-head interactions” (Line 75) and how the model reflects them is missing or unclear. (v) The claim that the model “encourages feature compression” (Page 2, Lines 92–93) is not theoretically or empirically supported.  \n\n- Evaluation limitations: (i) Experiments are only conducted on small and somewhat outdated datasets, which limits the significance of the results. (ii) The authors should evaluate on larger and more challenging datasets (e.g., DomainNet) to validate generalization. (iii) The ablation studies are limited and do not adequately explore the contribution of each component or hyperparameter setting.  \n\n- Inconsistency and ambiguity: (i) The paper claims that the proposed method “supports regression adaptation without labeled target data” (Line 114) and operates “without access to source data” (Abstract, Line 23). However, the text also refers to a pre-trained source model being available. (ii) It is unclear what dataset this source model was trained on, how “without access to source data” is reconciled with the use of a source-pretrained model, and whether the pretraining violates this assumption. (iii) Similar inconsistencies appear in Lines 169–170 (“in the absence of source data”).  \n\n- Organization and flow: (i) The method section is fragmented and lacks a cohesive narrative connecting subcomponents. (ii) Frequent references to appendices hinder understanding of the main ideas. (iii) Some mathematical derivations are introduced without adequate motivation or linkage to the proposed framework.  \n\n \n- Figures: (i) Fig. 1 is poorly motivated and confusing: The meanings of colors are not explained, nor is it clear whether they are consistent across subfigures (a)–(c). In Fig. 1(b), the meaning of “no explicit uncertainty” is unclear, and the visual similarity of regression outputs makes interpretation difficult. (ii) Fig. 2 suffers from similar issues as mentioned above. (iii) Fig. 4 subfigures are shown from different viewpoints, making comparisons and conclusions about efficiency or effectiveness unreliable. (iv) In the appendix, figures such as E4 and E5 are hard to interpret due to small font sizes and inconsistent viewpoints.  \n\n- Limited literature review: (i) The related work section is very narrow, referencing only two papers from 2025. (ii) Given the paper is being submitted at the end of 2025, this raises the question of whether relevant contemporary works have been omitted. The discussion should be expanded to better situate this work within recent literature.\n\n**Minor**\n\n- Numerous grammatical and typographical errors reduce readability. A careful proofreading is strongly recommended before submission. \n \n- Many hyperparameters are introduced without detailing their tuning strategy. Are they tuned jointly or individually, and based on which dataset? \n \n- The notation $\\langle \\cdot , \\cdot \\rangle$ (Line 285–286) presumably denotes a dot product, but this is never clarified. \n \n- Some claims (e.g., “feature compression” and “structured representation”) are not empirically substantiated."}, "questions": {"value": "**Questions**\n\n- The abstract (Lines 23–24) claims that histogram-guided learning produces more compact and structured feature representations. Could the authors provide quantitative or qualitative evidence to support this (e.g., visualization of feature embeddings or clustering metrics)?  \n\n- What exactly is $Y$ (Page 1, Line 50)? Please define it before use.  \n\n- Figure 1 clarifications: (i) What do the colors represent, and are they consistent across subfigures (a)–(c)? (ii) What does “no explicit uncertainty” mean in Fig. 1(b)? (iii) Why do the regression outputs appear nearly identical?  \n\n- Cross-head interactions: How does the proposed model capture or reflect cross-head interactions (Line 75)? Please provide a clearer explanation.  \n\n- Feature compression claim: The model is said to encourage feature compression (Page 2, Line 92–93). Could the authors clarify the underlying mechanism or empirical evidence for this claim?  \n\n- Source data vs. source model: Please clarify the contradiction between “no access to source data” and the use of a pre-trained source model. (i) What data was used for pretraining? (ii) How does this comply with the claim of “source-free” adaptation?  \n\n- Mathematical clarity: (i) What is the meaning of the round circle operator (Line 151)? (ii) What does $[K]$ represent (Line 158)? (iii) In Fig. 2, what are PL, KL, $k\\sigma$, $\\mu$, and the “/” symbol? (iv) In Eq. (1), what do $\\lambda_{\\text{prior}}$ and $L_{\\text{PL}}$ denote?  \n\n- Hyperparameter tuning: How were the hyperparameters tuned to maximize model performance? Were they tuned jointly or sequentially? Were the same values (e.g., from UTKFace) applied across all datasets?  \n\n- Experimental scope: Why were only small-scale datasets used? Would the proposed method generalize to large-scale domain adaptation benchmarks such as DomainNet?  \n\n- Figures E4 and E5 are difficult to interpret due to small font sizes and differing viewpoints. Could these be improved for clarity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZRz0b99GP0", "forum": "0uiWQTYpzb", "replyto": "0uiWQTYpzb", "signatures": ["ICLR.cc/2026/Conference/Submission12513/Reviewer_pCsT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12513/Reviewer_pCsT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761564886195, "cdate": 1761564886195, "tmdate": 1762923381998, "mdate": 1762923381998, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles Source-Free Domain Adaptive Regression (SFDAR), positing that it is fundamentally more challenging than classification due to its smooth feature space and the difficulty in quantifying prediction uncertainty. The core contribution is MERCI, a dual-head architecture that enables bi-directional knowledge transfer. Initially (Regression-to-Classification), the regression model's stochastic forward passes are used to generate an uncertainty-aware partial label set, which, combined with a unimodal prior, supervises a histogram head. Subsequently (Classification-to-Regression), this trained histogram head generates refined, high-quality continuous pseudo-labels to guide the adaptation of the main regression head."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1: This work addresses the challenges in SFDAR novelly by leveraging histograms as a bridge between classification and regression, which allows the method to effectively model label uncertainty.\nS2: The work is well-motivated, and the paper is well-written.\nS3: The method design appears principled and is supported by theoretical analysis."}, "weaknesses": {"value": "W1: The method's core component, the Histogram Information Set, is somewhat fragile because its binning structure ($K, b$) is determined only once, as a pre-processing step, based entirely on the initial source model's predictions. If the domain shift is large, these initial predictions are unreliable, creating a sub-optimal solution that fundamentally limits performance, as confirmed by experiments in Appendix E.4.\n\nW2: The paper completely lacks an efficiency and scalability analysis, despite introducing significant computational overhead. The method requires an expensive pre-processing step of $M$ forward passes for the entire dataset and adds a new histogram head ($f_{hist}$), but no comparisons of total training time, parameter count, or GPU memory usage are provided.\n\nW3: The framework introduces a large number of new hyperparameters, including the scaling factor $\\kappa$, threshold $\\tau$, dropout ratio $\\rho$, and sampling number $M$, and so on. The sensitivity analyses in Figure 3 and Figure E.3 show that these hyperparameters require careful tuning and are not as broadly robust as implied, with optimal values differing across datasets.\n\nW4: While the paper includes relevant 2023-2024 works, the set of baselines could be strengthened. Benchmarking against a wider array of recent and powerful domain adaptation methods would be necessary to more robustly establish the method's contributions."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "umcmo8l9iG", "forum": "0uiWQTYpzb", "replyto": "0uiWQTYpzb", "signatures": ["ICLR.cc/2026/Conference/Submission12513/Reviewer_qHRJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12513/Reviewer_qHRJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761829270876, "cdate": 1761829270876, "tmdate": 1762923381666, "mdate": 1762923381666, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the important and challenging problem of Source-Free Domain Adaptive Regression (SFDAR). It proposes MERCI, a novel dual-head framework to tackle this problem. The central contribution is the introduction of a histogram head that approximates the sample-wise conditional label distribution, thereby explicitly modeling uncertainty for the regression task. This histogram is constructed from initial pseudo-labels generated by Monte Carlo (MC) dropout on the source model, using a self-adaptive KDE binning strategy. The histogram head's training is regularized with a unimodal Gaussian prior via a KL divergence term. The output of this learned histogram head is then used to generate refined, uncertainty-aware pseudo-labels to supervise the regression head. Experiments across four datasets (UTKFace, Biwi-Kinect, California Housing, and Digits) demonstrate that MERCI consistently improves performance over source-only and other data-free baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper tackles SFDAR, which is both highly relevant and significantly underexplored compared to its classification counterpart. The proposed approach is novel and elegantly motivated.\n\n- The paper is well-written, clearly structured, and easy to follow. The proposed methodology is sound and well-motivated by the unique challenges of regression.\n\n- The authors provide extensive experimental validation, including thorough ablation studies and sensitivity analyses, both in the main paper and the appendix."}, "weaknesses": {"value": "1. The paper introduces many hyperparmeters. Some of the parmaeters are “treated as learnable parameters” and optimized with Adam to minimize the total loss. As formulated, a trivial solution with  λ→0 exists. The paper should clarify how this is avoided (e.g., constraints/regularization) and include training trajectories of all  λ in the appendix. \n\n2. The reported performance of the SSA and TASFAR baselines is surprisingly low, often barely improving upon or even underperforming the 'Source'-only model (e.g., in Table 1 and Table 2). Could the authors please elaborate on this. \n\n3. A simple, common, and often strong baseline in source-free adaptation is missing: Test-Time Adaptation (TTA) by updating only the Batch Normalization (BN) statistics on the target data. The authors are strongly encouraged to report results for this baseline to better contextualize their method's performance.\n\n4. The adaptation pipeline appears computationally expensive. The initialization step (Algorithm 1) requires stochastic forward passes and a global KDE estimation for the entire target dataset before training can begin. The authors acknowledge this is \"time-consuming.\" To quantify this, the authors are encouraged to add a section to the appendix comparing MERCI's total training time (including initialization) and per-epoch training time against the baselines.\n\n5. The entire framework is built upon uncertainty estimates from MC-dropout on the source model. However, there is no evidence that this uncertainty is well-calibrated for the target domain. A calibration analysis would be valuable. A compelling addition would be to compare MC-dropout uncertainty against alternative, such as an ensemble based on the augmentations for example. \n\n6. While proposition 4.1 provides a robustness property for the internal optimization of the histogram head, it is not obvious to me how this theoretical insight translates to the performance, robustness, or convergence of the final regression model."}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OiIONMVz7j", "forum": "0uiWQTYpzb", "replyto": "0uiWQTYpzb", "signatures": ["ICLR.cc/2026/Conference/Submission12513/Reviewer_dSV3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12513/Reviewer_dSV3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864177811, "cdate": 1761864177811, "tmdate": 1762923381367, "mdate": 1762923381367, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses Source-Free Domain Adaptive Regression (SFDAR), which allows access to the source domain only before the deployment, and adapts the model to the target domain in an unsupervised manner. The challenge of SFDA in regression tasks are (1) the feature space is smooth rather than clustered, and standard regression models are deterministic; therefore, they cannot provide the uncertainty (entropy calculated by the softmax probability distribution) to minimize for the training (such as the first SFDA paper did).\nMoreover, recent work suggests that standard regression losses (MSE, L1) compress feature entropy in ways that can harm generalization under label noise and distribution shift.\n\nTo tackle the above problem, this paper proposes MERCI (Mutual Enhancement of Regression-Classification Integration), which trains a regression head with an assumption of the variation (histogram). Given the target distribution, the method does the Monte-Carlo Dropout way of the forward passes through the regression head to obtain an ensemble of predictions, which defines a partial label set showing output uncertainty. \n\nAlong with that, the authors discretize the output spaced to be K bins, and have an assumption of a unimodal (Gaussian) prior over the label space, which encodes the prior that conditioned the regression outputs (which could be a limitation of this paper). The authors called it a histogram (classification) head.\n\nAfter the histogram head has been trained, MERCI feeds the output from histogram back to the regression head. They maintain an exponential moving average of the predicted histogram and compute a truncated expectation over the bins.\n\nEmpirically, the authors evaluate MERCI on four regression settings: age estimation on UTKFace, head-pose prediction on Biwi-Kinect, house-price prediction on California Housing, and digit regression using SVHN and MNIST."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-written.\n\nThe motivation of this paper is clear. - The regression tasks are much more challenging in the unsupervised adaptation paradigms, especially considering that the mainstream of the SFDA and Test-Time adaptation paradigm leverage the entropy calculated by the softmax probability distribution.\n\nIntroduces the uncertainty in the regression task by introducing monte-carlo dropout way of inference, and utilizes it for the adaptation."}, "weaknesses": {"value": "- Limited choices of the prior assumption (the distribution could be multi-modal, not uni-modal).\n\n- Limited novelty in re-formulating the classification head to the regression head - has been done in the monocular depth estimation in a cost-volume way of the prediction.\n\n- The benchmark is limited to the small-scale benchmarks. Especially, MNIST and SVHN experiments are not convincing. In the reviewer's resolution, the expected outputs are discrete (1,2,3,4,5,6,7,8,9), and this cannot be considered as a regression task."}, "questions": {"value": "1. The method explicitly uses a unimodal (Gaussian) prior on the label space. Why this particular choice instead of, say, a Laplace prior, a mixture of Gaussians, or a non-parametric prior? Is there empirical evidence that the chosen prior is well aligned with the empirical label distributions?\n\n\n2. The method emphasizes mutual enhancement between the histogram and regression heads. Is there any evidence that one direction (histogram → regression or regression → histogram) is doing most of the work? For example, if the feedback from histogram to regression is removed, how much performance degrades relative to removing the regression-to-histogram partial labels?\n\n3. Do the authors think the method can be adapted to other regression tasks (such as a simple depth estimation benchmark - KITTI to VKITTI)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zACdTqFeMP", "forum": "0uiWQTYpzb", "replyto": "0uiWQTYpzb", "signatures": ["ICLR.cc/2026/Conference/Submission12513/Reviewer_a6i2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12513/Reviewer_a6i2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12513/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762230619357, "cdate": 1762230619357, "tmdate": 1762923380784, "mdate": 1762923380784, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}