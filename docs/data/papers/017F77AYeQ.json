{"id": "017F77AYeQ", "number": 9157, "cdate": 1758113495159, "mdate": 1759897740443, "content": {"title": "SMART-3D: Scaling Masked AutoRegressive Transformer for Efficient 3D Shape Generation", "abstract": "Autoregressive models have shown promise in 3D shape generation by modeling complex spatial dependencies between discrete shape tokens. However, their sequential nature and token-by-token sampling limit scalability and generation speed, especially for high-resolution shapes. In this work, we propose SMART-3D (Scaling Masked AutoRegressive Transformers for 3D generation), a novel framework that combines the modeling capacity of autoregressive transformers with the efficiency of masked generation. By introducing a hierarchical token representation and a progressive masked generation schedule, SMART-3D enables parallel decoding of 3D structures without sacrificing autoregressive fidelity. We further optimize the model with spatially-aware masking and lightweight transformer blocks, allowing generation of detailed 3D shapes with significantly reduced computational overhead. Experiments on ShapeNet, ModelNet, and ShapeNet-55 datasets demonstrate that SMART-3D achieves state-of-the-art performance in both generation quality and speed, outperforming previous competitive baselines. Our approach offers a scalable and practical solution for high-fidelity 3D shape synthesis in real-world applications.", "tldr": "", "keywords": ["Autoregressive models", "3D shape generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/676ed3977332fe4f530434b6e3796debb83cbe57.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes SMART-3D, a mask token modeling approach for 3D generation."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper studies a fundamental problem in the 3D domain, 3D generation."}, "weaknesses": {"value": "There are obvious flaws in the interpretation of metrics and methods:\n\n1. The dimension in the equation (line 244) is not right. Here, $\\mathbf{B}_{\\text{spatial}} \\in \\mathbb{R}^{L \\times L}$ while $\\phi\\left(\\mathbf{Q}\\right)\\left(\\phi\\left(\\mathbf{K}\\right)^{T}\\mathbf{V}\\right)  \\in \\mathbb{R}^{L \\times d}$. Therefore, they can not be added.\n\n2. The metrics in Table 1 is not right. The optimum score for `1-NNA` should be 50\\%, *i.e.* the nearest neighbor classifier cannot distinguish the generated samples from the ground truth samples, not \"the lower the better\".\n\n3. There are no ablation studies on the highlighted architectures, *e.g.* the impact of linear attention, the generation speed comparison with other diffusion / auto-regressive methods."}, "questions": {"value": "See weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gZowcvNNqh", "forum": "017F77AYeQ", "replyto": "017F77AYeQ", "signatures": ["ICLR.cc/2026/Conference/Submission9157/Reviewer_zn3H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9157/Reviewer_zn3H"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9157/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830076642, "cdate": 1761830076642, "tmdate": 1762920839731, "mdate": 1762920839731, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an framework that merges masked autoregressive generation with diffusion modeling and linear attention, addressing key efficiency bottlenecks in 3D shape generation. However, technically novelty and evaluation are limited."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The progressive masked decoding strategy combined with linear attention (O(L) complexity vs O(L²)) enables faster inference (up to 3.2× speedup) while maintaining quality.\n\nThe paper includes thorough experiments covering unconditional generation, conditional completion, multi-class scaling, and model size ablations, demonstrating robustness across different settings."}, "weaknesses": {"value": "Limited novelty in individual components: While the combination is novel, the core techniques (masked autoregressive models, linear attention, diffusion processes) are well-established. The paper primarily integrates existing ideas rather than introducing fundamentally new concepts.\n\nThe paper doesn't compare against some recent 3D generation methods, particularly newer diffusion-based approaches and more recent autoregressive models shown in the Missing refrences below. The baseline comparisons are somewhat dated (mostly 2021-2023). \n\nMissing refrences:\nTRELLIS: Structured 3D Latents for Scalable and Versatile 3D Generation. In CVPR 2025 \nSAR3D: Autoregressive 3D Object Generation and Understanding via Multi-scale 3D VQVAE. In CVPR 2025\nMAR-3D: Progressive Masked Auto-regressor for High-Resolution 3D Generation. In CVPR 2025\nG3PT: Unleash the Power of Autoregressive Modeling in 3D Generation via\nCross-Scale Querying Transformer. In IJCAI 2025\nCube3D:https://arxiv.org/abs/2503.15475"}, "questions": {"value": "You mention hierarchical token representation, but how is this implemented? Are there multiple resolution levels? How do they interact?\n\nCan you provide detailed time and memory consumption comparisons with baselines？\n\nHow does the model perform on out-of-distribution shapes or novel object categories not seen during training?\n\nHow this formulation is different from MAR-3D: Progressive Masked Auto-regressor for High-Resolution 3D Generation. In CVPR 2025?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "kE0H4cZdnO", "forum": "017F77AYeQ", "replyto": "017F77AYeQ", "signatures": ["ICLR.cc/2026/Conference/Submission9157/Reviewer_kuxL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9157/Reviewer_kuxL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9157/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989029340, "cdate": 1761989029340, "tmdate": 1762920839400, "mdate": 1762920839400, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SMART-3D (Scaling Masked AutoRegressive Transformers for 3D generation) for 3D shape generation. The framework combines the modeling capability of autoregressive models with the efficiency of masked generation strategies. It uses progressive masked decoding to enable parallel decoding and reduce sampling steps, and employs a linear attention mechanism to lower computational complexity, achieving state-of-the-art performance in both generation quality and speed."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ The motivation of this paper is solid, and the technique sounds interesting\n+ Designed a progressive masking strategy, predicting multiple tokens in parallel to improve generation speed.\n+ By using a linear attention mechanism, memory usage is reduced, and positional information is incorporated into the computation through 3D biases."}, "weaknesses": {"value": "- The paper lacks an illustration of a complete model framework and does not show how category labels are fed into the network, which affects the clarity of the method.\n- The progressive masking strategy of the paper provides multiple approaches (diagonal, spiral), but does not compare the effects brought by different masking strategies.\n- Table 1 is incorrectly labeled. The FastDiT-3D-S method performs best in the fourth column for the object 'chair', which contradicts the table title stating that it 'significantly outperforms previous baselines in all categories.\n- It lacks comparisons with other methods published in 2024-2025 (such as DiffGS [A]). The evaluation of the method's effectiveness is insufficient.\n\n[A] Zhou, J., Zhang, W., & Liu, Y.-S. (2024). DiffGS: Functional Gaussian Splatting Diffusion"}, "questions": {"value": "- What masking strategy was used in the final experiment? Do different masking strategies affect the model's performance?\n- Where exactly is the learnable class embedding applied in the model? Is it implicitly used as a condition in the cross-attention mechanism in SMART-3D?\n- Why weren't comparisons with the latest methods included, and all the comparison methods are from 2023 or earlier?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WIDwzbIezO", "forum": "017F77AYeQ", "replyto": "017F77AYeQ", "signatures": ["ICLR.cc/2026/Conference/Submission9157/Reviewer_jvkj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9157/Reviewer_jvkj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9157/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762132855684, "cdate": 1762132855684, "tmdate": 1762920838846, "mdate": 1762920838846, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "-"}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "-"}, "weaknesses": {"value": "This paper does not show any visual comparison with baselines.\n\nThe author seems to misunderstand the concept of an autoregressive model.\n\nThis is an outdated paper that only compares with methods from before 2023."}, "questions": {"value": "-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "dS8t6uDrPN", "forum": "017F77AYeQ", "replyto": "017F77AYeQ", "signatures": ["ICLR.cc/2026/Conference/Submission9157/Reviewer_nxya"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9157/Reviewer_nxya"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9157/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762175649568, "cdate": 1762175649568, "tmdate": 1762920838464, "mdate": 1762920838464, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}