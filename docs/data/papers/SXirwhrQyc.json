{"id": "SXirwhrQyc", "number": 13985, "cdate": 1758226510983, "mdate": 1763727404714, "content": {"title": "DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models", "abstract": "Text-to-Image (T2I) models have advanced rapidly, yet they remain vulnerable to semantic leakage, the unintended transfer of semantically related features between distinct entities. Existing mitigation strategies are often optimization-based or dependent on external inputs. We introduce **DeLeaker**, a lightweight, optimization-free inference-time approach that mitigates leakage by directly intervening on the model’s attention maps. Throughout the diffusion process, DeLeaker dynamically reweights attention maps to suppress excessive cross-entity interactions while strengthening the identity of each entity. To support systematic evaluation, we introduce **SLIM** (Semantic Leakage in IMages), the first dataset dedicated to semantic leakage, comprising 1,130 human-verified samples spanning diverse scenarios, together with a novel automatic evaluation framework. Experiments demonstrate that DeLeaker consistently outperforms all baselines, even when they are provided with external information, achieving effective leakage mitigation without compromising fidelity or quality. These results underscore the value of attention control and pave the way for more semantically precise T2I models.", "tldr": "", "keywords": ["text-to-image", "semantic leakage", "computer vision", "automatic evaluation", "multimodal"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/74ad60508506700f70b05e93e7455f233490ae63.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In multiple objects generation tasks, it is well known that content or style leakage occasionally occurs. To address this issue, the proposed paper mitigates leakage in a training-free manner by suppressing or strengthening the model’s attention maps. Furthermore, to evaluate the effectiveness of this mitigation, the authors propose the SLIM Dataset and an automatic evaluation framework. The evaluation framework leverages a vision-language model (VLM) to extract differences between images and uses these as key visual difference metrics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The method does not require any additional mask nor bounding box, and it can be applied as a training-free manner, which is highly practical. This approach seems general enough to be applied to other diffusion architectures that use attention layers.\n- Proposing the SLIM dataset to systematically evaluate the content leakage problem, which has not been thoroughly studied before, and using a VLM-based automatic evaluation framework is a creative and meaningful contribution.\n- The method achieves significantly better results than previous approaches in both automatic evaluation and human preference studies."}, "weaknesses": {"value": "- Although the method appears simple yet effective, many of its design choices seem heuristic. For example, the assumption that high attention values correspond to unwanted semantic transfer lacks strong theoretical justification and appears to be chosen empirically. Similarly, the thresholds and coefficients that determine this behavior are treated as hyper-parameters.\n- There could be cases where high attention values represent meaningful interactions rather than content leakage. From the visualized results, many images seem to lack strong interactions between objects. More results showing related actions between objects (e.g., playing a game together, sharing food) would strengthen the argument.\n- Experiments and comparisons related to the automatic evaluation method are insufficient. For example, how does the proposed evaluation differ from a simpler baseline, such as directly querying a VLM about whether content leakage occurred in the target image?"}, "questions": {"value": "- The reviewer concerns if the assumption to judge high attention values as content leakage is too strong. Is there any evidence supporting this claim?\n  - Does the method still perform well in scenarios with a larger number of objects? What if two objects are the same animal while the other is not?\n- As mentioned in the Weakness section, how can it be demonstrated that the proposed evaluation method is superior to a simpler VLM-based querying approach?\n- The previous works performance seems too bad even though they also tackle the same problem. For instance, in the case of RAG-Diffusion, adding some rough location (next to, left/right) may produce much higher-quality results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HJ6fqOBEiq", "forum": "SXirwhrQyc", "replyto": "SXirwhrQyc", "signatures": ["ICLR.cc/2026/Conference/Submission13985/Reviewer_pKUr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13985/Reviewer_pKUr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13985/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761145344705, "cdate": 1761145344705, "tmdate": 1762924482408, "mdate": 1762924482408, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents DeLeaker, an inference-time methodology designed to specifically handle cases of semantic leakage in text-to-image models. By directly injecting into the attention mechanism of the underlying generation model, DeLeaker is able to perform light-weight inference-time adjustments which results in more robustly generated images. \n\nIn addition to DeLeaker, the paper also presents both a new SLIM dataset, which is specifically curated to evaluate semantic leakage. Separately the authors also provide a set of evaluation pipeline with justification on its validity based on human assessments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The reviewer notes the following strengths:\n- The paper is well written with clearly explained motivation for all methods & datasets.\n- The presented DeLeaker method is both intuitive and showcases strong performance under human assessment.\n- The SLIM dataset marks a very relevant contribution for all future research into semantic leakage.\n- Human evaluation is presented showcasing both clear strengths in DeLeaker and justification for the sanity of the automatic evaluations."}, "weaknesses": {"value": "The reviewer notes the following Weaknesses:\n- The reviewer finds some concern with the reliance on attention maps to reliably localize entities in the DeLeaker method. In particular, the reviewer would like to see specific evaluation on cases where attention miss-localization occurs.\n- The SLIM dataset could also be expanded, given semantic groupings are limited to animals and fruits.\n- The paper contains multiple components (DeLeaker, SLIM, evaluation pipeline) that sometimes overwhelms & detract from its core contributions."}, "questions": {"value": "As noted in the weaknesses, the reviewer’s main concern remains the reliance on attention maps for localization. It would be helpful if the authors could share any additional thoughts or clarifications on this point."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "k0Qy4EpJqb", "forum": "SXirwhrQyc", "replyto": "SXirwhrQyc", "signatures": ["ICLR.cc/2026/Conference/Submission13985/Reviewer_UoR2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13985/Reviewer_UoR2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13985/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761597930840, "cdate": 1761597930840, "tmdate": 1762924481907, "mdate": 1762924481907, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a training-free, guidance-free inference-time algorithm for mitigating entity-level semantic leakage in text-to-image (T2I) diffusion models.\n\nThe method, DeLeaker, constructs per-entity masks from the model’s attention maps, suppresses cross-entity attention to reduce unintended feature transfer, and strengthens self-identity through targeted reweighting of text–image attention.\n\nThe authors introduce a VLM-based automatic evaluation pipeline and demonstrate that DeLeaker consistently outperforms all baselines across both automatic and human evaluations."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Simple and Effective**:\nThe method is conceptually simple yet highly effective. Its reliance on a single hyperparameter ($\\beta_1$) for adaptive attention thresholding is an elegant design choice that highlights its efficiency and robustness. This kind of minimalistic control mechanism is one of the method’s most appealing aspects."}, "weaknesses": {"value": "* **Entity Neglection (minor).**\n  A potential limitation arises when the base model’s attention maps fail to properly attend to certain entities.\n  For instance, if an entity token receives little or no attention over image patches (“token neglection”), DeLeaker may entirely suppress or ignore that entity, as the method operates strictly on existing attention activations.\n  Consequently, its effectiveness strongly depends on the *attention quality* of the underlying base model (e.g., FLUX). In corner cases with poor attention calibration, this could produce undesirable omissions.\n\n* **Fit to Venue (minor).**\n  While the paper is solidly executed, it may be more naturally aligned with the *computer vision* community (e.g., CVPR), where readers are more accustomed to attention-based control in generative models.\n  That said, as ML and vision research continue to converge, this distinction is becoming less rigid, so I do not consider it a major concern."}, "questions": {"value": "* The method seems potentially sensitive to **token neglect**, i.e., cases where an entity token receives incomplete or biased attention coverage. Is the attention quality in models like FLUX sufficiently strong that this is rarely an issue in practice?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0eJzunUJvu", "forum": "SXirwhrQyc", "replyto": "SXirwhrQyc", "signatures": ["ICLR.cc/2026/Conference/Submission13985/Reviewer_xvBT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13985/Reviewer_xvBT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13985/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962720770, "cdate": 1761962720770, "tmdate": 1762924481336, "mdate": 1762924481336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an optimisation-free, lightweight inference time control approach, DeLeaker, which reduces leakage by directly intervening on the model's attention maps. The pipeline dynamically adjusts the attention map weights to suppress cross-entity interactions while strengthening the identity of each entity. The authors also propose a FLUX-generated dataset of semantic leakage consisting of 1,130 images. The DeLeaker pipeline achieves the highest mitigation rate of Major = 46.07% and Minor = 9.76%, with the lowest degradation rates of Major = 12.98% and Minor = 5.83%."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "The paper writing was clear and easy to follow. I have 2 strengths to highlight:\n\n- Systematic evaluation pipeline and dataset: The creation of SLIM, the first benchmark explicitly targeting semantic leakage, and its associated automatic evaluation framework represent strong empirical contributions. \n- Novel inference-time attention intervention: By distinguishing between cross-entity suppression and self-identity strengthening, it achieves a practical balance between leakage mitigation and fidelity preservation"}, "weaknesses": {"value": "I have mainly one weakness to highlight in the paper:\n\n-Evaluation dependence on external VLMs: The automatic evaluation framework depends heavily on Gemini outputs and textual reasoning to infer visual differences. While the authors validate it with a human study, this dependence could bias results due to VLM limitations in visual grounding and typicality judgments."}, "questions": {"value": "I require some clarification from the authors in regards to the methodology:\n\n- The exact diffusion step range and sensitivity of Beta1, Beta2, and alpha coefficients to scene complexity are briefly mentioned but not fully justified; a stability analysis across prompt types would help.\n\n- It would also help to clarify whether DeLeaker’s interventions introduce latency overhead or computational trade-offs compared to baseline inference."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "e7D0oxYM4U", "forum": "SXirwhrQyc", "replyto": "SXirwhrQyc", "signatures": ["ICLR.cc/2026/Conference/Submission13985/Reviewer_bdJX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13985/Reviewer_bdJX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13985/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762003421183, "cdate": 1762003421183, "tmdate": 1762924480808, "mdate": 1762924480808, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}