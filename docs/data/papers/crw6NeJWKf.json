{"id": "crw6NeJWKf", "number": 2703, "cdate": 1757213336830, "mdate": 1759898132606, "content": {"title": "Reasoning-to-Encoder Distillation for Recommendation", "abstract": "Large Language Models (LLMs) have significantly advanced recommendation systems by leveraging their extensive knowledge and reasoning skills. However, applying them to large-scale systems faces two main problems: prohibitive inference latency, especially in autoregressive models, and the generation of misaligned reasoning that is not grounded in actual user preferences. Existing distillation methods attempt to solve these problems but often fall short either by failing to transfer the essential reasoning capabilities of LLMs or by distilling flawed, misaligned reasoning, which compromises the performance and reliability of the student model. To address these challenges, we introduce a new framework, Reasoning-to-Encoder Distillation (R2END). This framework is designed to effectively transfer an LLM’s complex reasoning into an efficient, embedding-based architecture. To ensure the distilled reasoning is grounded in actual user behavior, we employ an “oracle-guided” process where the ground-truth item is provided to the LLM to generate a well-aligned reasoning. This reasoning is then distilled into a text encoder, which learns to create a “reasoning-infused” embedding from\nuser history, eliminating the need for the LLM during inference. Extensive experiments on three benchmark datasets demonstrate that our method substantially outperforms state-of-the-art distillation-based methods in terms of both accuracy and diversity of recommendations. Most importantly, R2END drastically reduces inference latency and computational costs, demonstrating that it provides a practical and efficient approach to creating scalable recommendation systems that benefit from the deep reasoning capabilities of LLMs.", "tldr": "To address slow and flawed LLM reasoning in recommendations, we generate oracle-guided reasoning and distill it into a Text Encoder. Our resulting encoder-only system is faster, cheaper, and more accurate than state-of-the-art methods.", "keywords": ["recommender systems", "large language models", "distillations"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/534e5a7ec60145e519ce79c7f5db77d592052ad2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the critical challenges of high inference latency and misaligned reasoning in LLM-based recommender systems by introducing R2END, a novel and practical framework. Its core contributions lie in the \"oracle-guided\" reasoning generation mechanism and the innovative approach of distilling complex reasoning into an efficient text encoder, which collectively achieve a significant reduction in inference latency. Evaluations across three categorical datasets demonstrate that R2END outperforms the compared LLM-based and distillation baselines in specific benchmarks while exhibiting lower latency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper demonstrates exceptional logical rigor, featuring a clear structure and rigorous argumentation. It proposes the novel R2END framework that effectively balances efficiency and performance.\n\n2. The introduction of oracle-guided reasoning generation successfully addresses the misalignment between LLM reasoning and actual user behavior.\n\n3. The authors provide reproducible code and detailed experimental configurations to support their findings."}, "weaknesses": {"value": "1. The paper claims that the proposed method significantly reduces inference latency and provides a practical and efficient approach for building scalable recommendation systems. However, this evaluation was conducted on only a single dataset and lacks validation in real-world scenarios or online service environments. Furthermore, the method's effectiveness has been demonstrated solely on three datasets: Sports, Beauty, and Toys (all belonging to the Amazon dataset). In practice, recommender systems typically need to handle user behavior data from mixed domains and face challenges such as temporal distribution shifts. The paper does not evaluate R2END's generalization capability on mixed-category datasets, nor does it test its robustness against out-of-distribution data or user interest drift. \n\n2. The scope of baseline comparisons remains narrow, omitting commonly used approaches such as \"LLM features combined with traditional models.\". It is recommended that the authors supplement their experiments with comparisons against methods such as \"incorporating LLM-generated item embeddings or user features into traditional recommendation models\" and demonstrate its relative advantages under comparable conditions."}, "questions": {"value": "1. The font size of the results in Table 1 is too small, which hinders readability and makes it difficult for readers to review and compare specific values. The subplot arrangement in Fig. 3 could also be further optimized, as the current layout appears somewhat awkward, likely due to space constraints. Additionally, the lack of numbering for all equations in the text undermines the clarity and referenceability of the discussion.\n\n2.The evaluation was conducted on only three categories from Amazon dataset. To better demonstrate the effectiveness of your method, it is recommended to include tests on additional datasets.\n\n3. Both the LLM-based baselines and the proposed method in this paper rely entirely on LLMs. In practice, alternative approaches exist, such as hybrid methods that combine pure LLM components with traditional recommendation models (e.g., incorporating embeddings into traditional recommender systems). These approaches often yield stronger performance and are commonly deployed in real-world systems. It is advisable to include comparisons with such methods :\n    1) NoteLLM: A Retrievable Large Language Model for Note Recommendation Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models\n    2) LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding\n    3) Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application\n\n4. How does the performance of the encodings from R2END  when applied to traditional recommendation models?\n\n5. While the paper claims that the proposed method is suitable for practical applications, its validation of industrial deployment feasibility and generalization capability is notably insufficient. Specifically, the claimed \"orders-of-magnitude reduction in inference latency\" was measured under ideal laboratory conditions, lacking stress tests that simulate real-world online environments (e.g., high concurrent requests, resource competition).\n\n6. The approach exhibits a strong dependency on the Teacher LLM, where any inherent biases or inaccuracies in the teacher model could potentially compromise the effectiveness of the distillation process."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3CgliKHSfc", "forum": "crw6NeJWKf", "replyto": "crw6NeJWKf", "signatures": ["ICLR.cc/2026/Conference/Submission2703/Reviewer_MK2r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2703/Reviewer_MK2r"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2703/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761400350627, "cdate": 1761400350627, "tmdate": 1762916335871, "mdate": 1762916335871, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes R2END, a method that distills the reasoning ability of large language models into a fast text encoder for recommendation. By using the ground-truth item as an oracle to guide the LLM's reasoning, it ensures high-quality knowledge transfer. The resulting system matches or surpasses LLM-based recommenders, while achieving a reduction in inference latency and cost. However, the paper has several weakness, such as lack of novelty, unsound experiment design, and lack of experiment insights."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well written, and the topic is of good interest to the community.\n2. The method of oracle-guided reasoning is reasonable.\n3. The experiment design is good, from effectiveness to efficiency."}, "weaknesses": {"value": "1. Lack of novelty: The technical point is not new, following well-studied lines of research, i.e. privileged knowledge distillation, and LLM-based representation learning in recommendation.\n\n2. Lack of baseline: \n\n2.1 For distillation, the paper should also compare traditional distillation methods (e.g. through logits matching), rather than simply SFT on student LM.\n\n2.2 For embedding method, the paper should also compare LLM-based embedding models, e.g. models on MTEB leaderboard.\n\n3. Unfair comparison with traditional recommendation methods: User embeddings in this paper are augmented with additional semantics, while the traditional recommendation methods are not. A fair comparison would be taking these text embeddings as additional features for them [1,2].\n\n[1] Representation Learning with Large Language Models for Recommendation\n\n[2] Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models"}, "questions": {"value": "1. In Section 4.5.1, it is predicable to have increased similarity, as the encoder is trained to do so. However, increased similarity does not necessarily denote reasoning mimic. Can the authors make the reasoning mimic more visible?\n\n2. What is the practical advantage of R2END over current LLM4Embed methods in recommendation [3]? They can use larger LLMs for better results, and prestore the embeddings for inference.\n \n[3] NoteLLM: A Retrievable Large Language Model for Note Recommendation"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "5hRiAMvtPn", "forum": "crw6NeJWKf", "replyto": "crw6NeJWKf", "signatures": ["ICLR.cc/2026/Conference/Submission2703/Reviewer_5QwB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2703/Reviewer_5QwB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2703/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761812939466, "cdate": 1761812939466, "tmdate": 1762916335589, "mdate": 1762916335589, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of integrating LLM reasoning into text encoder. The proposed Reasoning-to-Encoder Distillation (R2END), is a framework that distills aligned reasoning from an LLM into a lightweight text encoder. The oracle‑guided generation process grounds the LLM’s rationales in real user behavior, coupled with a “compilation” step that compresses this reasoning into a vector representation. Extensive experiments show that R2END sets new state‑of‑the‑art results while significantly reducing inference latency, offering a practical and effective path toward next‑generation recommender systems."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear paper presentation\n- The research topic is timely, distilling LLM reasoning into a lightweight text encoder. This eliminates LLM dependency during inference, achieving orders-of-magnitude reductions in latency and computational cost\n- On three benchmark datasets (Sports, Beauty, Toys), R2END outperforms chosen baselines"}, "weaknesses": {"value": "- Dependence on ground truth. The oracle-guided process relies on access to ground-truth next items, yet the accuracy of the generated rationales is not guaranteed. Why not use GPT‑5 as the LLM in Fig. 2?\n\n- Encoder capacity constraints. Although R2END is compatible with diverse text encoders (Appendix D), small encoders (e.g., 24M) underperform the baselines. This suggests a minimum capacity is required to distill complex LLM reasoning, potentially increasing deployment costs in resource‑constrained settings. The capacity gap between teacher and student is a well‑known challenge in knowledge distillation, which is not carefully addressed in this paper.\n\n- Extensibility to SLM-based distillation. The oracle‑guided process could also be integrated into SLM‑based distillation methods, but the results of such a design are unclear.\n\n- Fairness concerns. By grounding reasoning in historical behavior, the oracle‑guided process may amplify existing dataset biases (e.g., demographic skews in user preferences) if no corrective measures are taken."}, "questions": {"value": "1. How to Handle Dynamic User Preferences? User preferences evolve over time, but R2END conducts offline reasoning generation. \n\n2. Does R2END Extend to Non-Sequential Tasks?The framework is designed for sequential recommendation. Would its reasoning-to-encoder distillation work for other recommendation paradigms (e.g., collaborative filtering, content-based filtering) ?\n\n3.Real-world user histories often include noisy interactions (e.g., accidental clicks). Does noisy input degrade the quality of the encoder’s reasoning-infused embeddings?\n\n4. What Is the Cost of Offline Reasoning Generation?The offline stage uses a 12B-parameter teacher LLM to generate reasoning. For large-scale datasets (e.g., 100M+ users), what is the computational cost of this stage?\n\n5. Why Is the Encoder More Sample-Efficient Than SLMs?Empirically, the encoder’s MSE loss outperforms SLMs’ token-level objectives, but there is no theoretical analysis of this sample efficiency. \n\n6. How to Quantify \"Reasoning Quality\" Beyond Embedding Alignment? Current metrics (L2 distance, cosine similarity) measure embedding alignment, but not the logical validity of the encoder’s implicit reasoning. \n\n7. Missing reference work\nDistillation Matters: Empowering Sequential Recommenders to Match the Performance of Large Language Model\nC2kd: Cross-layer and cross-head knowledge distillation for small language model-based recommendation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VxQmzZnn9v", "forum": "crw6NeJWKf", "replyto": "crw6NeJWKf", "signatures": ["ICLR.cc/2026/Conference/Submission2703/Reviewer_QcGM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2703/Reviewer_QcGM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2703/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842614539, "cdate": 1761842614539, "tmdate": 1762916335422, "mdate": 1762916335422, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}