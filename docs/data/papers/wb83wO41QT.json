{"id": "wb83wO41QT", "number": 9786, "cdate": 1758140463844, "mdate": 1763720320608, "content": {"title": "Noise-Aware Generalization: Robustness to In-Domain Noise and Out-of-Domain Generalization", "abstract": "Methods addressing Learning with Noisy Labels (LNL) and multi-source Domain Generalization (DG)  use training techniques to improve downstream task performance in the presence of label noise or domain shifts, respectively.  Prior work often explores these tasks in isolation, with only limited work that evaluates how label noise affects existing DG methods without also exploring methods to reduce its effect. However, many applications require methods that are robust to both label noise and distribution shifts, which we refer to as Noise-Aware Generalization (NAG), and when these problems are considered together new challenges emerge. E.g., most LNL methods identify noise by detecting distribution shifts in a class’s samples, i.e., they assume that distribution shifts often correspond to label noise. In NAG distribution shifts can be due to label noise or domain shifts, breaking the assumptions used by LNL methods. DG methods often overlook the effect of label noise entirely, which can confuse a model during training, reducing performance. A naive solution to this issue is to make a similar assumption as many DG methods, where we presume to have domain labels during training, enabling us to isolate the two types of shifts. However, this ignores valuable cross-domain information. Specifically, our proposed DL4ND approach improves noise detection by taking advantage of the observation that noisy samples that may appear indistinguishable within a single domain often show greater variation when compared across domains. Experiments show DL4ND significantly improves performance across seven diverse datasets, offering a promising direction for tackling NAG.", "tldr": "", "keywords": ["label noise", "domain generalization", "noise-robust generalization"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8eb106636f68b07e96f0620ef8dec164b6d93fd7.pdf", "supplementary_material": "/attachment/8921aff231a43c6df2f1e0bbccbc654762f70749.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces Noise-Aware Generalization (NAG) to tackle noisy, diverse real-world data by improving in-domain noise handling and out-of-domain generalization. The authors show that distinguishing noise from domain shifts is challenging, and naive combinations of LNL and DG fail because domain shifts interfere with noise detection. They propose using cross-domain comparisons as a signal for identifying noise, leveraging its lack of intrinsic class features. Experiments validate that this approach significantly improves performance and offer insights for further advancing NAG."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper is well-motivated and seems to be reproducible.\n2. This paper is well-organized and easy to follow. Specifically, in Sce. 3, the authors provide an in-depth analysis of the causes and implications of the proposed task, and in Sec. 4, they present concrete solutions, which are highly insightful.\n3. This paper addresses real-world challenges and significantly improves task performance."}, "weaknesses": {"value": "1. Existing works [A][B] have discussed the presence of real-world noisy labels in domain adaptation, which this paper seems to overlook. The related work section should be improved to include comparative discussion with these methods.\n2. The formula proposed in Section 3.1 is explored with a toy experiment in Section 3.2. In my view, the authors could provide deeper theoretical analysis to make the argument more convincing.\n3. The experiments lack some qualitative analysis to illustrate specific cases, which would help demonstrate the method’s advantages and enhance understanding of the task.\n4. Currently, NAG is evaluated on synthetic noisy data. Introducing more realistic “asymmetric noise,” as studied in noisy label learning, could improve the practical applicability of NAG.\n5. In my opinion, the abstract focuses almost entirely on the NAG task itself, while neglecting to highlight the insightful ideas behind the proposed method.\n\n[A] Feng, Yanglin, et al. \"ROAD: Robust unsupervised domain adaptation with noisy labels.\" Proceedings of the 31st ACM international conference on multimedia. 2023.\n\n[B] Yin, Ziniu, et al. \"RoDA: Robust Domain Alignment for Cross-Domain Retrieval Against Label Noise.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 39. No. 9. 2025."}, "questions": {"value": "Please refer to the strengths and weaknesses of the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "peJzjvKRJS", "forum": "wb83wO41QT", "replyto": "wb83wO41QT", "signatures": ["ICLR.cc/2026/Conference/Submission9786/Reviewer_QyAy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9786/Reviewer_QyAy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761659320539, "cdate": 1761659320539, "tmdate": 1762921270902, "mdate": 1762921270902, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the joint setting where data contains both domain shifts and label noise, which the authors call Noise-Aware Generalization. The idea is that existing domain generalization and noisy-label learning methods usually handle one problem at a time. The proposed method, DL4ND, uses cross-domain feature comparison to detect mislabeled samples. After a warm-up stage, it selects low-loss samples as clean, computes class-domain prototypes, and relabels high-loss samples based on the closest prototype from another domain. The method can be combined with standard DG approaches such as ERM++, SWAD, or SAGM. Experiments on seven datasets show consistent but relatively modest improvements."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The topic is relevant and realistic since many real-world datasets contain both domain shifts and noisy annotations.  \n2. The method is simple and easy to integrate into existing frameworks.  \n3. Experimental coverage is broad, with multiple datasets and several DG and LNL baselines.  \n4. The paper is well written and figures are clear."}, "weaknesses": {"value": "1. The novelty is limited. The proposed approach mainly reuses existing ideas from noisy-label learning such as loss-based sample filtering, GMM separation, and prototype relabeling. The only new component is comparing features across domains, which is a small modification conceptually.  \n2. The framing of Noise-Aware Generalization as a new task feels overstated, since similar scenarios have appeared in prior DG or LNL discussions.  \n3. The paper lacks deeper analysis or theory explaining why cross-domain comparison works better."}, "questions": {"value": "1. How does the proposed cross-domain comparison differ fundamentally from prototype-based noisy-label methods such as DivideMix or UNICON?  \n2. What motivates defining Noise-Aware Generalization as a new task rather than treating it as DG with label noise?  \n3. Can you provide visualization or analysis to support the claim that cross-domain comparison improves noise detection?  \n4. How sensitive are results to the relabeling frequency and the accuracy of domain labels?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PccaFknjOm", "forum": "wb83wO41QT", "replyto": "wb83wO41QT", "signatures": ["ICLR.cc/2026/Conference/Submission9786/Reviewer_wQm5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9786/Reviewer_wQm5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761721289368, "cdate": 1761721289368, "tmdate": 1762921269979, "mdate": 1762921269979, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Learning with Noisy Labels (LNL) addresses label noise and multi-source Domain Generalization (DG) handles domain shifts to boost downstream performance, but prior work mostly explores them in isolation, with limited efforts to mitigate label noise’s impact on DG.\nMany applications require robustness to both label noise and distribution shifts (defined as Noise-Aware Generalization, NAG), posing challenges: LNL’s assumption that distribution shifts equal label noise fails, and DG’s neglect of label noise harms training. A naive NAG solution uses domain labels to separate shifts but wastes cross-domain information, while the proposed DL4ND improves noise detection by leveraging greater variation of noisy samples across domains. Experiments on seven diverse datasets show DL4ND significantly enhances performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is easy to follow.\n\n2. The performance of the proposed method is good. The experimentail results are relatively extensive."}, "weaknesses": {"value": "1. It seems that there is no practical application of NAG in real world, so is it meaningful to address this new setting? The authors should discuss the potential value in real world application.\n\n2. More related methods [1-4] in the filed of Robust Domain Adaptation under Label Noise should be reviewed and discussed. \n\n[1] Y. Shu, Z. Cao, M. Long, and J. Wang, “Transferable curriculum for weakly-supervised domain adaptation,” in Proc. AAAI Conf. Artif. Intell., 2019, vol. 33, pp. 4951–4958.\n\n[2] Z. Han, X. Gui, C. Cui, and Y. Yin, “Towards accurate and robust domain adaptation under noisy environments,” in Proc. 29th Int. Joint Conf. Artif. Intell., C. Bessiere, Ed., 2020, pp. 2269–2276. \n\n[3] Y. Zuo, H. Yao, L. Zhuang, and C. Xu, “Seek common ground while reserving differences: A model-agnostic module for noisy domain adaptation,” IEEE Trans. Multimedia, vol. 24, pp. 1020–1030, 2022. \n\n[4] Junbao Zhuo, Shuhui Wang, Qingming Huang. Uncertainty modeling for robust domain adaptation under noisy environments. IEEE Transactions on Multimedia. pp. 6157-6170. 2023."}, "questions": {"value": "Please refer to the Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fk8kupV20f", "forum": "wb83wO41QT", "replyto": "wb83wO41QT", "signatures": ["ICLR.cc/2026/Conference/Submission9786/Reviewer_SNwE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9786/Reviewer_SNwE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993691906, "cdate": 1761993691906, "tmdate": 1762921269360, "mdate": 1762921269360, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the joint problem of robustness to label noise and domain shifts, termed Noise-Aware Generalization (NAG). The authors propose DL4ND, a method that detects noisy samples by performing cross-domain comparisons among low-loss examples. The idea is that comparing samples across domains helps identify intrinsic class features and avoid confusion caused by domain-specific artifacts. Experiments on several benchmark datasets demonstrate that DL4ND improves both in-domain and out-of-domain performance over prior LNL and DG methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is easy to follow and logically developed.\n    \n- The proposed approach is reasonable and intuitively well-motivated, combining insights from both LNL and DG.\n    \n- Extensive experiments across multiple datasets validate the effectiveness of the method and provide detailed ablation analysis."}, "weaknesses": {"value": "- Although the setup is novel, it appears somewhat artificial, and its practical real-world scenarios are unclear.\n    \n- The method heavily relies on the multi-domain assumption. It is uncertain how DL4ND would perform if only one source domain with noisy labels were available.\n    \n- The analysis in this manuscript (such as lines 251–258) is mostly heuristic and lacks rigorous theoretical justification or stronger empirical evidence/observation.\n    \n- The experimental evaluation could be further strengthened, for example by involving more diverse noise types."}, "questions": {"value": "- Have the authors evaluated whether low-loss samples truly correspond to clean labels in practice?\n    \n- How robust and reliable is the clean/noisy distinction under different training dynamics or noise levels?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mTuAbOLM5Z", "forum": "wb83wO41QT", "replyto": "wb83wO41QT", "signatures": ["ICLR.cc/2026/Conference/Submission9786/Reviewer_fTkm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9786/Reviewer_fTkm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9786/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762801326483, "cdate": 1762801326483, "tmdate": 1762921268996, "mdate": 1762921268996, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}