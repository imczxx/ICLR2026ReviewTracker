{"id": "p6sJSEuoRE", "number": 16223, "cdate": 1758261921470, "mdate": 1759897253539, "content": {"title": "iCAS: A In-Context Anomaly Segmentation Framework for Industrial Visual Inspection", "abstract": "Visual in-context prompting has recently made promising progress, achieving training-free  segmentation with a generalized model derived from large-scale pre-training. However, we observe that these in-context segmentation models fail on the anomaly detection task, e.g., visual inspection. In this study, we propose iCAS, a novel model for In-Context Anomaly Segmentation enabling automatic defect annotation and visual prompting anomaly segmentation. The framework is built upon an in-context mask transformer, further enhanced by a greedy query selection strategy and a mask-level feature matching module to improve both sensitivity and generalization. Further, we propose the General-to-Specific pre-training to solve the weak generalization problem caused by the scarcity of anomalous samples. Finally, we conduct comprehensive experiments under a variety of anomaly detection and segmentation tasks. Evaluations on multiple publicly available datasets show the generalization and effectiveness of our method.", "tldr": "", "keywords": ["Anomaly Detection", "In-Context Learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b0278da0c2365a0a4613c6a1859b0eb71e3fcd45.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces what the authors claim to be the first in-context segmentation method tailored for industrial visual inspection. By combining a greedy query selection strategy, a mask-level feature matching module, and a general-to-specific pretraining paradigm, the proposed framework not only outperforms existing general in-context segmentation methods, but also delivers strong few-shot anomaly detection performance. Overall, the work is interesting, but there are several issues that should be addressed before it is ready for acceptance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "The paper explores the first in-context anomaly segmentation model designed specifically for industrial inspection.\n\nThe general-to-specific pretraining strategy is reasonable and clearly motivated, as training solely on industrial anomaly datasets is often insufficient.\n\nExperimental results demonstrate promising performance."}, "weaknesses": {"value": "The motivation needs to be strengthened. Why is an in-context segmentation model particularly important for industrial inspection? More discussion is needed.\n\nThe related work section is not comprehensive enough. Several recent methods published in 2025 are missing.\n\nThe description of the in-context transformer is too brief, making it difficult for readers to understand how it works internally.\n\nThe comparisons with PerSAM and Matcher appear unfair. The proposed method leverages both semantic segmentation data and targeted industrial anomaly data for training, while prior in-context segmentation baselines do not use anomaly detection data.\n\nTable 3 reports promising results, but the evaluation metric used is not clearly indicated.\n\nWhile I understand that space limitations make it difficult to include extensive details, the current description of the proposed method is still hard for readers to follow. Some parts require further elaboration—particularly Section 3.2 on the objective function, which is difficult to understand in its current form."}, "questions": {"value": "How does the method perform when anomalies have fuzzy or unclear boundaries, which is very common in real industrial settings?\n\nFigure 2 suggests that a mask set is required for training. How is this mask set obtained in practice? Does it require manual annotation?\n\nIn line 306, it is mentioned that semantic masks are obtained via SAM. How exactly is this performed?\n\nIn Table 1, what do the notations CP, BT, HN, etc. stand for? Please clarify."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "52rSrx0q6a", "forum": "p6sJSEuoRE", "replyto": "p6sJSEuoRE", "signatures": ["ICLR.cc/2026/Conference/Submission16223/Reviewer_Tqxe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16223/Reviewer_Tqxe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16223/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761801551280, "cdate": 1761801551280, "tmdate": 1762926383613, "mdate": 1762926383613, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the iCAS model together with a General-to-Specific pre-training paradigm. iCAS is based on a mask classification transformer architecture and introduces Greedy Query Selection (GQS) and Mask-level Feature Matching (MFM) to accurately localize anomalous regions. This approach enables robust anomaly segmentation, even under limited anomaly data conditions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper evaluates the iCAS model using a wide range of evaluation metrics and a variety of well-structured experiments.\n2. This paper defines a new pre-training paradigm, the General-to-Specific approach, that effectively bridges the gap between general semantic segmentation and specialized anomaly segmentation."}, "weaknesses": {"value": "1. The paper lacks comparison with recent few-shot anomaly detection methods, such as: UniVAD: A Training-free Unified Model for Few-shot Visual Anomaly Detection (CVPR 2025), DictAS: A Framework for Class-Generalizable Few-Shot Anomaly Segmentation via Dictionary Lookup (ICCV 2025)\n\n2. Experiments on backbone networks are limited. Ablation studies involving CLIP-ViT and DINOv1 would strengthen the effectiveness of this paper.\n\n3. Greedy Query Sampling (GQS) is likely sensitive to the choice of K, but no ablation studies on this parameter have been presented. Furthermore, if GQS tends to select queries in the normal region, the robustness of the model should be verified on datasets with diverse object locations, such as MPDD or medical datasets, which are not covered in this paper.\n\n4. General-to-Specific pre-training paradigm consists of two stages; an analysis of its computational cost would be valuable."}, "questions": {"value": "1. We are curious about the performance of iCAS in an unsupervised learning anomaly detection environment and its performance in the presence of anomaly data.\n2. For backbone networks, a comparison study comparing DINOv2, CLIP-ViT, and DINOv1 would be interesting.\n3. General-to-Specific pre-training paradigm consists of two stages, and an analysis of their computational costs would be important."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oRnAVTEqPY", "forum": "p6sJSEuoRE", "replyto": "p6sJSEuoRE", "signatures": ["ICLR.cc/2026/Conference/Submission16223/Reviewer_eNU5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16223/Reviewer_eNU5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16223/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761953011012, "cdate": 1761953011012, "tmdate": 1762926382932, "mdate": 1762926382932, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces iCAS, a new In-Context Anomaly Segmentation framework designed to generalize visual in-context prompting (e.g., SAM-style models) to industrial anomaly segmentation. The core idea is to enable training-based, prompt-driven anomaly localization using only a few anomaly or normal samples. The method achieves strong performance across diverse datasets, significantly outperforming existing in-context segmentation models and anomaly detection methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.iCAS unifies promptable segmentation (SAM-like) and anomaly detection in a training-based, in-context fashion\n\n2.The proposed GQS and MFM modules are simple yet effective, addressing practical issues of query redundancy and boundary precision.\n\n3.Extensive experiments (five datasets, multiple tasks, and ablations) convincingly show robustness, scalability, and effectiveness of each component."}, "weaknesses": {"value": "1.While iCAS performs well, its components (GQS, MFM, two-stage training) are mostly adapted from known concepts (active learning, mask matching, transfer learning). The true methodological novelty might be seen as moderate.\n\n2.The paper primarily focuses on industrial surface defects, it is unclear whether iCAS generalizes to other anomaly types (e.g., medical or natural images) or remains domain-specific due to the specialized anomaly-aware pre-training."}, "questions": {"value": "1.Could the authors clarify why GQS is necessary beyond standard query embeddings? How much does it reduce redundancy compared to random or uniform query sampling?\n\n2.How scalable is the method computationally? Please report training cost and inference time compared to SAM or Matcher."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6JOgMtUL1M", "forum": "p6sJSEuoRE", "replyto": "p6sJSEuoRE", "signatures": ["ICLR.cc/2026/Conference/Submission16223/Reviewer_QgxX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16223/Reviewer_QgxX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16223/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761953965805, "cdate": 1761953965805, "tmdate": 1762926382435, "mdate": 1762926382435, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes iCAS, an in-context anomaly segmentation framework designed for industrial visual inspection.  The model extends a mask-classification transformer with two modules: Greedy Query Selection (GQS), which selects representative visual tokens, and Mask-level Feature Matching (MFM), which refines mask alignment across queries.  It further adopts a General-to-Specific pre-training schedule—first training on large-scale semantic segmentation datasets, then fine-tuning on anomaly-focused data (RealIAD, MANTA).  Experiments on MVTec-AD, VisA, and related benchmarks report improved mIoU compared to existing in-context and SAM-based baselines (PerSAM, Matcher, SINE)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "•\tAmbitious effort to unify semantic, interactive, and few-shot anomaly segmentation within one framework.\n•\tBroad empirical evaluation across multiple benchmarks with consistent results.\n•\tWell-executed ablation studies showing measurable effects of GQS, MFM, and the pre-training strategy.\n•\tBuilt on open, reproducible components (MaskFormer, DINOv2), which aids transparency."}, "weaknesses": {"value": "1. The proposed method is primarily a reassembly of existing techniques with limited conceptual advancement.\n2. Claims of “training-free” or “in-context reasoning” are overstated, given the reliance on large-scale supervised pre-training and conventional fine-tuning.\n3. The contributions of GQS and MFM are empirically validated but not theoretically grounded or well-explained.\n4. The paper does not clearly separate iCAS from prior in-context segmentation approaches (SAM, HQ-SAM, SegGPT, SINE, Matcher). GQS and MFM are minor technical variations on existing promptable frameworks and do not introduce a new capability or reasoning mechanism.\n5. Existing vision-language anomaly detection models (WinCLIP, AnomalyCLIP, InCTRL, RegAD, MetaUAS) are mentioned but never compared under equal conditions. The reported gains may stem from backbone choice and training scale rather than a new formulation.\n6. The General-to-Specific pre-training scheme closely follows the standard “pretrain on generic segmentation → fine-tune on anomaly masks” pipeline already used in RegAD, MetaUAS, and RealNet. Thus, its novelty is marginal."}, "questions": {"value": "This paper presents a solid empirical study with clear organization and credible results, but the core contribution lies in engineering integration rather than conceptual innovation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3FrsOZh0q1", "forum": "p6sJSEuoRE", "replyto": "p6sJSEuoRE", "signatures": ["ICLR.cc/2026/Conference/Submission16223/Reviewer_AgJu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16223/Reviewer_AgJu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16223/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762012222801, "cdate": 1762012222801, "tmdate": 1762926381920, "mdate": 1762926381920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}