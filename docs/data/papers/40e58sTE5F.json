{"id": "40e58sTE5F", "number": 17785, "cdate": 1758280474216, "mdate": 1763578366936, "content": {"title": "Hierarchical Multi-Stage Recovery Framework for Kronecker Compressed Sensing", "abstract": "In this paper, we study the Kronecker compressed sensing problem, which focuses on recovering sparse vectors using linear measurements obtained using the Kronecker product of two or more matrices. We first introduce the hierarchical view of the Kronecker compressed sensing, showing that the Kronecker product measurement matrix probes the sparse vector from different levels, following a block-wise and hierarchical structure. Leveraging this insight, we develop a versatile multi-stage sparse recovery algorithmic framework and tailor it to three different sparsity models: standard, hierarchical, and Kronecker-supported. We further analyze the restricted isometry property of Kronecker product matrices under different sparsity models, and provide theoretical recovery guarantees for our multi-stage algorithm. Simulations demonstrate that our method achieves comparable recovery performance to other state-of-the-art techniques while substantially reducing run time owing to the hierarchical, multi-stage recovery process.", "tldr": "We study the Kronecker compressed sensing where we demonstrate a hierarchical view of the Kronecker compressed sensing and develop a versatile algorithmic and theoretical framework.", "keywords": ["Compressed sensing;Kronecker product;Restricted isometry property;Hierarchical sparsity;Tensor operation"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fb87e38e86332290aa00225a9ed73ea0e0d69cf5.pdf", "supplementary_material": "/attachment/d45bad4e8ba4d302b8faa4ac4e10e53540cb2509.zip"}, "replies": [{"content": {"summary": {"value": "In the Kronecker compressed sensing (KCS) framework, the measurement matrix is composed by the Kronecker product of multiple factor matrices as $ H = H_I \\otimes \\cdots \\otimes H_1$. While this allows for efficient measurement of signals with multidimensional structures, the dimensionality increases rapidly (e.g., $O(N^I))$, which makes existing methods computationally expensive. They also fail to fully utilize the individual factor matrix structures and hierarchical sparsity.\nThis paper addresses these difficulties by introducing the {\\em hierarchical view}. \nThe contribution of this paper is composed of the following three parts. \nFirst, it is theoretically demonstrated that the Kronecker product structure is a \"hierarchical block partition\" and that each factor matrix $H_i$ measures the sparsity of a different \"hierarchical level.\" Taking advantage of the Kronecker structure, an algorithm, Multi-Stage Recovery (MSR), that performs reconstruction sequentially (or in parallel) for each layer is proposed. This reduces the computational cost for signal reconstruction to $O((MN)^I)$ to $O(MN^I)$. \nSecond, a theoretical guarantee is developed by introducing a new type RIP-based condition. \nFinally, for all three sparse models, MSR methods (MSOMP, MSHTP, MSSBL, etc.) show comparable or superior accuracy to existing methods (KroOMP, HiHTP, KroSBL, etc.), while reducing computational time by 1–3 orders of magnitude."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "By introducing a new perspective into the Kronecker compressed sensing framework, we propose a signal restoration algorithm that can significantly reduce the required computational effort compared to conventional methods. At the same time, we also conduct novel performance evaluations, theoretically guaranteeing performance, and demonstrate the practical usefulness of the proposed algorithm through numerical experiments."}, "weaknesses": {"value": "Kronecker compressed sensing is only possible when the observed signal has multidimensional structural sparsity or separable statistical structure, which limits the practical applications in which the proposed method is useful."}, "questions": {"value": "This paper refers to radar imaging and wireless communication as examples of applications where the proposed method is useful, because the sparsity of each signal can be separated into dimensions. Can the usefulness of this method be verified for real data in these fields?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5d5fj6GNgH", "forum": "40e58sTE5F", "replyto": "40e58sTE5F", "signatures": ["ICLR.cc/2026/Conference/Submission17785/Reviewer_MA64"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17785/Reviewer_MA64"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17785/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760753378830, "cdate": 1760753378830, "tmdate": 1762927628252, "mdate": 1762927628252, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors consider the problem of recovering sparse vectors $x$ from Kronecker measurements, i.e., measurement matrix of the form $H=H_1\\otimes \\dots \\otimes H_N$. The overarching idea is to perform the recovery in stages: By unfolding of the measurement $y=Hx$ in different manners, the recovery problem can be viewed as a number of  MMV problems of the form $y= H_j U_j$, that can be solved in an iterative fashion. They coin this class of algorithms MSR, multi-stage recovery. Importantly, their method is improved if the $x$ also is assumed to have a Kronecker sparse structure, since the MMV problems become coupled.\n\nThey derive a convergence guarantee for their method that is valid under the assumption that each $H_i$ has the RIP. Their bound can be applied to different types of sparsity in $x$, and in particular improves when $x$ Kronecker-sparse. It however potentially suffers from the potential of error propagation between the folded stages."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The main strength of the paper is that it proposes a method which performs better for Kronecker-based sparsity than for general hierarchical sparsity, which with the exception of He and Joseph, 2025, seems to be novel. \n\nThe recovery guarantee that the authors provide is interesting in that it only requires each constituent matrix to have a constant RIP ($\\delta_{s_i}(H_i)<1/\\sqrt{3}$) for convergence in the noiseless case. This is actually a lot better than previous guarantees -- using the bound in Theorem 1 to get an RIC (which is what is needed for e.g. the HiHTP to converge), one essentially need the sums of the $\\delta_{s_i}(H_i)$ to be less than $1/\\sqrt{3}$, which intuitively means that each constant must be smaller than $1/\\sqrt{I\\cdot 3}$, which will be very low for a high number of Kronecker levels. It is also interesting to see that their technique, through Corollary 1, improves on the previously quite weak bounds for standard sparsity."}, "weaknesses": {"value": "The paper is sometimes hard to follow, mainly due to the complexity of the notation related to tensor-algebra and the different sparsity notions. I think that refinement of the illustrations would go a long way to alleviate the problems. The color coding in Figure 4 is in my opiniion rather confusing than helpful.\n\nThe RIC analysis offers some new interesting perspectives, but it seems very close to the one performed in [Roth et. al; 2020] and [Roth et al; 2018]. The relations between the two should be better explained, see questions below.\n\nThe superiority of the proposed methods compared to the SOTA, both for hierarchically sparse vectors and Kronecker-sparse vectors, are mainly argued for via comparison of run-times. This metric depends a lot of the specifics of the implementation. Could something more objective be measured and presented, such as the number of iterations? I particularly stumble upon this since the discussion regarding time-complexity on page 5 seems to contain mistakes for HiHTP, see below."}, "questions": {"value": "** Relation of RIP analysis to [Roth et al; 2020]** Although the formulation of the results are different, it seems like the formulation and proof of Theorem 1 in the manuscript at hand is essentially the same as the formulation and proof of Theorem 4. Can the authors comment on this, and in particular pinpoint exactly how the analyses are different?\n\n** Complexity discussion and HiHTP ** In the complexity discussion, the authors claim that the space- and time-complexity for HiHTP ($I=2$) both are $M^2N^2$. However [Roth et al; 2020] claim in their paper that the per-iteration time- complexity of their algorithm (for generic measurement matrices) is (in this notation) $MN^2$. Can the authors clarify?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Wg8kHeQSQO", "forum": "40e58sTE5F", "replyto": "40e58sTE5F", "signatures": ["ICLR.cc/2026/Conference/Submission17785/Reviewer_Wv5h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17785/Reviewer_Wv5h"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17785/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761296571817, "cdate": 1761296571817, "tmdate": 1762927627573, "mdate": 1762927627573, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a multi-stage sparse recovery framework for Kronecker compressed sensing, tailored to three sparsity models, with theoretical guarantees and simulations showing comparable performance and faster runtime than state-of-the-art methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1）Developed a versatile multi-stage sparse recovery algorithmic framework tailored to three different sparsity models (standard, hierarchical, and Kronecker-supported) for the Kronecker compressed sensing problem.\n\n2）Provided theoretical recovery guarantees by analyzing the restricted isometry property of Kronecker product matrices under different sparsity models, and demonstrated comparable recovery performance with significantly reduced run time through simulations."}, "weaknesses": {"value": "1）Compared to traditional compressed sensing, Kronecker Compressed Sensing (KCS) has not garnered sufficient attention, primarily due to its excessive complexity—including challenges in measurement matrix construction, signal reconstruction and hardware implementation—while lacking significant performance advantages that could justify its complexity. One notable strength of the method proposed in this paper is its reduced reconstruction complexity. However, we are particularly interested in how it compares to traditional methods in terms of runtime and reconstruction accuracy, yet the paper appears to lack relevant experimental evaluations.\n\n2）The construction of measurement matrices remains a major challenge in KCS. While the paper claims to improve Restricted Isometry Property (RIP) conditions, there seems no  concrete method for constructing matrices that satisfy these enhanced conditions."}, "questions": {"value": "Besides the two major concerns mentioned above, I have the following questions:\n\n1) The paper introduces three sparsity models, but it does not specify which types of real-world data these models are tailored for. Despite asserting broad applicability, the paper lacks simulations using authentic datasets. \n\n2) As previously mentioned, a critical comparison with traditional compressed sensing methods in terms of reconstruction accuracy is essential, given the high computational complexity of KCS.\n\n3) In the experiments, the analysis is limited to cases with a number of stages no greater than three, namely $I\\leq 3$. Why was this restriction imposed? Ideally, the performance variations across different stage numbers should have been explored."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "p8Qzx5SzTx", "forum": "40e58sTE5F", "replyto": "40e58sTE5F", "signatures": ["ICLR.cc/2026/Conference/Submission17785/Reviewer_64D7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17785/Reviewer_64D7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17785/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761567145162, "cdate": 1761567145162, "tmdate": 1762927627049, "mdate": 1762927627049, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the performance of Kronecker compressed sensing (CS) for three different hierarchical/structured sparsity patterns. New algorithms that mix reshaping of signal, observation, and sensing tensors and joint sparsity algorithms applied to tensor slices allow for improvements in performance versus agnostic baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper covers theoretical analysis, algorithmic contributions, and numerical performance for several different signal setups. \n\nThe analytical results expand over existing contributions in Kronecker CS by proposing and leveraging custom restricted isometry properties, obtaining better scaling laws for the number of measurements necessary from random CS matrix constructions. The results also include the commonly observed tolerance to the presence of noise in the measurements.\n\nThe proposed algorithms exploit the structure of Kronecker matrices for CS and sparsity to reduce the computational complexity of recovery vs. their agnostic counterparts.\n\nThe numerical comparisons are convincing."}, "weaknesses": {"value": "It is not always clear if these proposed sparsity structures find readily available applications where Kronecker CS is feasible and an improvement over baselines. All experiments are based on synthetic data.\n\nThere appears to be no discussion of the role of the sparsity transformation, which implicitly would have to follow a Kronecker product formulation as well."}, "questions": {"value": "Are there applications where the newly proposed hierarchical sparsity structures arise naturally?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AXIEjnRrxK", "forum": "40e58sTE5F", "replyto": "40e58sTE5F", "signatures": ["ICLR.cc/2026/Conference/Submission17785/Reviewer_27dS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17785/Reviewer_27dS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17785/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877179409, "cdate": 1761877179409, "tmdate": 1762927626618, "mdate": 1762927626618, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}