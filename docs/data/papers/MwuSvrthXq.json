{"id": "MwuSvrthXq", "number": 4310, "cdate": 1757660100630, "mdate": 1759898040359, "content": {"title": "Reinforcement Learning for Heterogeneous DAG Scheduling with Weighted Cross-Attention", "abstract": "Efficient scheduling of directed acyclic graphs (DAGs) in heterogeneous environments is challenging due to diverse resource capacities and intricate dependencies. In practice, the need for adaptability across environments with varying resource pools, task types, and other settings, alongside rapid schedule generation, complicates these challenges. We propose WeCAN, an end-to-end reinforcement learning framework for heterogeneous DAG scheduling featuring task-resource compatibility. WeCAN rapidly generates schedules through single-pass network inference. Leveraging the weighted cross-attention layer, WeCAN utilizes all available environment information while preserving adaptability across diverse heterogeneous environments. Moreover, we analyze the optimality gap inherent in list-scheduling-based methods, revealing their inability to guarantee optimal solutions and their reduced performance in certain cases. Under the single-pass setting, we develop a method to enable skip actions, addressing this gap without sacrificing computational efficiency. Our approach delivers robust performance and adaptability, outperforming state-of-the-art methods across diverse datasets.", "tldr": "", "keywords": ["Combinatorial Optimization", "Directed Acyclic Graph", "Heterogeneous Scheduling", "Reinforcement Learning"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9c06214b963c706b55f79f325620326b81e9ec8d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces WeCAN, a novel, end-to-end reinforcement learning framework for scheduling Directed Acyclic Graphs (DAGs) in heterogeneous environments. The core problems it addresses are (1) adapting to diverse resource pools and task-pool compatibility coefficients, and (2) overcoming the inherent \"optimality gap\" of fast, single-pass list-scheduling methods. The main contributions are a new **Weighted Cross-Attention (WeCA) layer** to flexibly encode task-pool compatibility and a novel method to enable a dynamic **skip action** in a single-pass, non-auto-regressive decoder. The authors provide theoretical justification for their approach and demonstrate state-of-the-art performance in terms of schedule quality (makespan) and inference speed on real-world and synthetic benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.  **Problem Significance:** The paper tackles an NP-hard problem that is highly relevant to modern distributed systems, cloud computing, and data centers. The focus on *heterogeneity* (diverse pools and task compatibility) and *adaptability* (generalizing to new numbers of tasks/pools) addresses key practical challenges that are often abstracted away.\n\n2.  **Novelty of WeCA Layer:** The proposed Weighted Cross-Attention (WeCA) layer is a novel and effective mechanism for this problem. [cite_start]Unlike prior works that either average compatibility coefficients (losing information) or use fixed-size one-hot encodings (losing adaptability), WeCA integrates these coefficients directly into the attention mechanism[cite: 351, 354, 359]. This allows the model to learn context-dependent task features while remaining scalable and adaptable to varying numbers of task types and pools. [cite_start]The ablation study (Table 3) confirms its superiority over alternative designs[cite: 701, 778].\n\n3.  **Novelty of Single-Pass Skip Action:** This is arguably the paper's strongest technical contribution. The authors correctly identify that fast, list-scheduling-based methods suffer from an \"optimality gap\" because they cannot \"wait\" (skip) for a better scheduling opportunity. While skip actions exist (e.g., Mao et al., 2016), they are typically used in multi-round, auto-regressive models, which are slow. [cite_start]This paper introduces a method to enable a *dynamic* skip action within a *single-pass, non-auto-regressive* framework [cite: 440-444, 508]. [cite_start]This is achieved by having the network output three coefficients ($u_a, u_b, u_c$) that define a dynamic score for skipping, which elegantly solves the challenge of enabling \"waiting\" without sacrificing single-pass efficiency[cite: 442].\n\n4.  **Theoretical Justification:** The paper provides a solid theoretical analysis in Section 4 to motivate the skip action. [cite_start]By defining the \"original space\" of all feasible schedules and a \"reduced space\" of schedule orders, it formally argues that the standard list scheduling map ($S_{list}$) is not surjective and can therefore miss the optimal solution[cite: 529, 1607, 1777]. [cite_start]It then proves that their proposed map (Algorithm 1), which includes the skip action, is surjective and can generate an optimal schedule (Theorem 1) [cite: 448-450, 1673-1674]. This provides a strong foundation for *why* the skip action is necessary.\n\n5.  **Strong Empirical Results:** The experimental validation is comprehensive and convincing.\n    * [cite_start]**Performance:** WeCAN outperforms all heuristic and SOTA RL baselines (PPO-BiHyb, One-Shot) on both TPC-H and Computation Graph datasets (Tables 1 & 2), achieving up to an 18.1% makespan improvement[cite: 621, 629, 645, 690].\n    * [cite_start]**Efficiency:** The greedy version (WeCAN-Greedy) is extremely fast, with inference times comparable to simple heuristics and orders of magnitude faster than multi-round RL methods like PPO-BiHyb[cite: 629, 684].\n    * **Skip Action Ablation:** The ablation study on \"heavy task\" datasets (Table 8, Fig. 3) is a key result. [cite_start]It shows that WeCAN-with-Skip significantly outperforms WeCAN-No-Skip and all list-scheduling-based methods, empirically proving the value of the skip action in closing the optimality gap [cite: 772, 781-785, 2549].\n    * [cite_start]**Generalization:** The WeCA design is validated in generalization experiments (Fig. 2, Appx. F.3), where a model trained on one environment setting shows robust performance when tested on environments with more pools, new pool types, or new task types [cite: 686-688, 770, 2536]."}, "weaknesses": {"value": "1.  **Clarity of Section 4:** While the theoretical analysis in Section 4 is a strength, its presentation is very dense and difficult to parse. The definitions of \"reduced space B\", \"original space A\", and the maps $T$, $S_{list}$, and $S_n$ [cite: 512-515, 1223-1229, 1290-1291] could be explained more intuitively. The core idea—that list scheduling is overly greedy and can't \"wait\" for a better task to become available—is clear, but the formalism is challenging.\n\n2.  **Skip Score Formulation:** The formulation for the skip score, $u_{\\pi_{skip}}=u_{a}(1-\\frac{k}{2n})^{u_{b}}+u_{c}$[cite: 442], feels somewhat ad-hoc. The paper justifies it as preventing the skip action from being \"overly prioritized\", but it would be beneficial to include more justification or an ablation study on this specific functional form. How sensitive is the model to this design choice versus, for example, a simpler linear decay?\n\n3.  **Ablation on LDDGNN:** The LDDGNN component, while shown to be effective (beating GAT in Table 3) [cite: 701, 780], is presented as a secondary contribution [cite: 422-429]. It's not entirely clear how much of the performance gain comes from this sophisticated GNN versus the two primary contributions (WeCA and the skip action). An ablation with a simpler GNN (e.g., GIN or GCN), combined with WeCA and the skip mechanism, would help isolate the true impact of the main proposals.\n\n4.  **\"Heavy Task\" Scenarios:** The \"heavy task\" ablation (Table 8) is excellent, but the method for generating these tasks (randomly replacing 1% or more of tasks) [cite: 2281-2282, 2284-2285] feels synthetic. The paper's impact could be strengthened by discussing how this scenario maps to real-world workloads (e.g., are 1-3% heavy tasks common?) or by testing on a real-world dataset known to have this \"heavy-task\" property. Figure 8[cite: 2132], which shows the benefit of skip scaling with the heavy task ratio, is very informative and might be better placed in the main paper."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xyy5En5F2v", "forum": "MwuSvrthXq", "replyto": "MwuSvrthXq", "signatures": ["ICLR.cc/2026/Conference/Submission4310/Reviewer_DcSo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4310/Reviewer_DcSo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4310/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761400493066, "cdate": 1761400493066, "tmdate": 1762917289490, "mdate": 1762917289490, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a Scheduling method for Directed Acyclic Graphs in heterogenous environments. The heterogeneity is presenting in compatibility coefficients and resource pools. The presented method WeCan, leverages Weighted Cross Attention Based Graph Encoding, and is shown to outperform the baselines in given benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Claims are supported by extensive empirical analysis.\n\n- Outperforms existing benchmarks."}, "weaknesses": {"value": "- The need for retraining in different scales leads to question on how well the model can scale up.\n\n- While the empirical results show that the model is able to outperform heuristics, it is unclear how good the performance is with respect of exact solvers such as Gurobi or SCIP.\n\n- It is unclear how different constraints would effect the performance of the model."}, "questions": {"value": "What are the advantages of the presented method compared to Graph Scheduling methods based on Attention [1, 2, 3]?\n\nSkip action in Multi-Agent Task Allocation and Scheduling has been done in sequential MARL based methods [2]. How does the proposed method compare to existing methods that leverage skip action?\n\nHow does the proposed method differ from Heterogenous Task Allocation and Scheduling proposed in [3]? What are the advantages and disadvantages of the proposed method.\n\nMost sequential decision making methods represent the problems in a Markovian Decision Process. \n\n[1] Y. Hu, Y. Yao, and W. S. Lee, “A reinforcement learning approach for optimizing multiple traveling salesman problems over graphs,” _Knowledge-Based Systems_, vol. 204, p. 106244, Sept. 2020, doi: [10.1016/j.knosys.2020.106244](https://doi.org/10.1016/j.knosys.2020.106244).\n\n[2] Z. Wang and M. Gombolay, “Stochastic Resource Optimization over Heterogeneous Graph Neural Networks for Failure-Predictive Maintenance Scheduling,” _ICAPS_, vol. 32, pp. 527–536, June 2022, doi: [10.1609/icaps.v32i1.19839](https://doi.org/10.1609/icaps.v32i1.19839).\n\n[3] B. Altundas, Z. Wang, J. Bishop, and M. Gombolay, “Learning Coordination Policies over Heterogeneous Graphs for Human-Robot Teams via Recurrent Neural Schedule Propagation,” in _2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)_, Kyoto, Japan: IEEE, Oct. 2022, pp. 11679–11686. doi: [10.1109/IROS47612.2022.9981748](https://doi.org/10.1109/IROS47612.2022.9981748)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UwN8hm8U1X", "forum": "MwuSvrthXq", "replyto": "MwuSvrthXq", "signatures": ["ICLR.cc/2026/Conference/Submission4310/Reviewer_dXJx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4310/Reviewer_dXJx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4310/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951120764, "cdate": 1761951120764, "tmdate": 1762917289248, "mdate": 1762917289248, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes **WeCAN**, a reinforcement learning framework for *one-shot DAG scheduling* in heterogeneous environments. The method uses a single forward pass of a neural network to generate task-pool priority scores, which are then converted into schedules using heuristic-based generation. The claimed key components include weighted cross-attention layers to incorporate compatibility coefficients $K_{acc}$ and a longest directed distance graph neural network (LDDGNN) for structural encoding. \n\nWhile the paper claims contributions in network architecture and skip-action design, the actual novelty appears limited compared to existing one-shot scheduling approaches like [1] Jeon et al. (2023), and the experimental evaluation lacks breadth in datasets and baselines. I would rate this paper **3/10** for weak novelty and limited evaluation (temporarily rating as “2” since 3 is not selectable).\n\n----\n[1] Jeon et al., *Neural DAG Scheduling via One-Shot Priority Sampling*, ICLR 2023."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* Provides a scheduling framework similar to HEFT, but implemented with a learned model.\n* The integration of skip actions in a single-pass inference setting shows performance gains in many scenarios.\n* The paper clearly formulates the heterogeneous DAG scheduling problem with compatibility constraints and provides a detailed MILP formulation."}, "weaknesses": {"value": "* **Limited novelty**: The core approach of one-shot priority generation closely follows [1] Jeon et al. (2023), with incremental improvements mainly in the attention mechanism and skip action design. The weighted cross-attention essentially amplifies compatibility coefficients in softmax, while LDDGNN adds a distance-based bias to GNN computations. The term “featuring task–resource compatibility” is highlighted as a key property, but most recent scheduling works already include this.\n* **Insufficient theoretical contribution**: Section 4 provides a formalization of the optimality gap in list scheduling but does not offer new theoretical insights or convergence guarantees for RL-based scheduling. The analysis feels more like a formalization of existing intuition rather than a substantive theoretical advancement.\n* **Incomplete experimental evaluation**:\n  - Missing comparison with important benchmarks like Pegasus workflow traces and Flexible Job Shop Scheduling (FJSP) instances, which are standard in scheduling literature.\n  - Baseline selection omits recent heuristic methods (e.g., PEFT, IPPTS) and learning-based schedulers (e.g., L2D), limiting the persuasiveness of performance claims.\n* **Presentations**:\n  - Input features for task and pool embeddings are not thoroughly described.\n  - Figures (especially Fig. 1) are unclear, and several key definitions (e.g., generation map, skip score design, input features) are not well explained.\n  - The claimed synthetic dataset reference ([1] Jeon et al., 2023) is inaccurate, as that dataset is not publicly available."}, "questions": {"value": "1. The Introduction cites older works under “Neural DAG Schedulers for Heterogeneous Environments.” Please include more recent literature that addresses adaptability in dynamic heterogeneous settings (e.g., recent papers from top AI/Systems venues).\n1. Given that the scheduling problem is formulated as a MILP, why not compare with off-the-shelf solvers (e.g., Gurobi, CPLEX) on smaller instances to benchmark optimality gaps?\n1. The skip action score is defined as $u_{\\pi_{skip}} = u_a(1 - \\frac{k}{2n})^{u_b} + u_c$. What is the intuition behind this specific form? How does it prevent over-prioritization of skip actions, and were alternative formulations explored?\n1. Figure 1 is hard to interpret — please clarify the full pipeline and the meaning of the “generation map.”\n1. What raw features are used to construct the task and pool embeddings?\n1. The paper states that the “Computation Graphs” dataset was generated following Jeon et al. (2023), but that dataset was not released; please clarify your data generation process.\n1. This work appears as an incremental extension of [1] Jeon et al. (2023), which evaluated on broader domains (JSP, TPC-H, computation graphs). Please evaluate the proposed method on the Pegasus datasets and the FJSP instances.\n1. The baselines are incomplete — recent heuristic methods such as PEFT and IPPTS should be compared, along with neural methods (e.g., L2D, other workflow NCO models) to highlight performance and inference-time trade-offs."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "47c6n7uxvQ", "forum": "MwuSvrthXq", "replyto": "MwuSvrthXq", "signatures": ["ICLR.cc/2026/Conference/Submission4310/Reviewer_PDB6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4310/Reviewer_PDB6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4310/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989328090, "cdate": 1761989328090, "tmdate": 1762917289020, "mdate": 1762917289020, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents WeCAN, an RL-based framework for heterogeneous DAG scheduling that integrates a weighted cross-attention mechanism and skip actions to model task–resource compatibility and generate optimized schedules in a single inference pass."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper clearly defines the problem and formulates how cross-attention and GNN are used to improve scheduling.\n\n- The proposed WeCAN maintains high performance across environments (varying pools, tasks, and resource types), with robust generality. And the single pass design enables fast, one-shot scheduling with minimal inference time."}, "weaknesses": {"value": "1. The experimental RL-based baselines (HEFT, PPO-BiHyb, One-Shot) do not include more recent RL–based schedulers using advanced graph or attention mechanisms. This makes it difficult to assess WeCAN’s relative improvement over SOTA. \n\n2. The integration of weighted cross-attention and skip actions is conceptually sound but not fundamentally novel. Both have been explored in prior works on RL-based resource allocation, so WeCAN’s contribution is primarily architectural refinement for heterogeneous environments rather than theoretical innovation. \n\n3. The reward function focuses solely on makespan reduction, with little quantitative analysis of how skip frequency or policy variance affects convergence and stability during training.\n\n4. How is it theoretically or empirically validated in WeCAN that advancing the physical time immediately after a skip action leads to optimal or near-optimal scheduling decisions, rather than introducing suboptimal temporal transitions?\n\n5. The paper employs its LDDGNN but does not compare it with modern GNN variants such as Graph Transformer [1] or other graph architectures [2, 3]. Such comparisons are necessary to clarify the actual advantage of LDDGNN over existing methods beyond GAT (2018).\n\n6. The proposed weighted cross-attention module for heterogeneous DAG scheduling appears similar to recent heterogeneous graph neural network designs [4, 5]. Including these models as baselines would strengthen the empirical justification and clarify the novelty of WeCAN’s architecture.\n\n7. The definition of the skip-action function $u_{\\pi_{skip}}$ is not well motivated. The paper provides limited analysis of alternative formulations or sensitivity to its hyperparameters, making it unclear whether the chosen form is empirically optimal or arbitrarily selected.\n\n[1] Yun, Seongjun, et al. \"Graph transformer networks.\" Advances in neural information processing systems 32 (2019). \n\n[2] Corso, Gabriele, et al. \"Principal neighbourhood aggregation for graph nets.\" Advances in neural information processing systems 33 (2020): 13260-13271. \n\n[3] Wu, Qitian, et al. \"Nodeformer: A scalable graph structure learning transformer for node classification.\" Advances in Neural Information Processing Systems 35 (2022): 27387-27401. \n\n[4] Hu, Ziniu, et al. \"Heterogeneous graph transformer.\" Proceedings of the web conference 2020. 2020. \n\n[5] Jin, Yufei, et al. \"HGDL: Heterogeneous Graph Label Distribution Learning.\" Advances in Neural Information Processing Systems 37 (2024): 40792-40830."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UfYQ6PIGNz", "forum": "MwuSvrthXq", "replyto": "MwuSvrthXq", "signatures": ["ICLR.cc/2026/Conference/Submission4310/Reviewer_C3Wq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4310/Reviewer_C3Wq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4310/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994391477, "cdate": 1761994391477, "tmdate": 1762917288794, "mdate": 1762917288794, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}