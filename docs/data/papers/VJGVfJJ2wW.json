{"id": "VJGVfJJ2wW", "number": 4398, "cdate": 1757672896673, "mdate": 1759898034657, "content": {"title": "EAMET: ROBUST MASSIVE MODEL EDITING VIA EMBEDDING ALIGNMENT OPTIMIZATION", "abstract": "Model editing techniques are essential for efficiently updating knowledge in\nlarge language models (LLMs). However, the effectiveness of existing approaches\ndegrades in massive editing scenarios, particularly when evaluated with\npractical metrics. Their robustness is also limited in context-rich settings or\nwhen editing multiple facts of the same subject simultaneously. We attribute\nthese failures to the embedding misalignment among knowledge items, which\nundermines editing reliability at scale. To address this, we propose EAMET\n(Embedding Alignment Model Editing in Transformers), which addresses this issue\nby aligning the space of key and residual embeddings. Extensive experiments\nacross six LLMs and three datasets demonstrate that EAMET consistently\noutperforms existing methods, achieving about 90\\% editing efficacy when editing\n10k facts.", "tldr": "", "keywords": ["Model Editing", "Massive Editing", "Large Language Models"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ea2fba3cacaa7863a4535b4eec783d7d0d134d3d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper aims to address the sharp performance degradation of large language models (LLMs) when performing massive simultaneous factual edits. The authors attribute this failure to embedding misalignment, a geometric inconsistency between the key embeddings representing knowledge and the residual embeddings responsible for executing updates, which leads to information loss during aggregated updates.\n\nTo tackle this issue, they propose EAMET, a novel model editing method whose core idea is to progressively and proactively align the structures of the key and residual embedding spaces during the optimization of each knowledge update, guided by KL divergence and MSE losses. Extensive experiments demonstrate that EAMET significantly outperforms existing methods, achieving higher accuracy and robustness when editing thousands of facts, particularly in challenging and realistic scenarios such as long-prefix interference and multi-point edits on the same subject."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* This paper attributes the performance degradation of existing model editing methods in large-scale realistic editing scenarios to **embedding misalignment**, which is a novel and interesting perspective.\n* The paper conducts an in-depth theoretical and empirical analysis of **embedding misalignment**.\n* The paper proposes **EAMET** to address the problem of **embedding misalignment**.\n* Extensive experiments demonstrate the effectiveness of **EAMET**."}, "weaknesses": {"value": "The assumption regarding **embedding misalignment** is overly strong, which concerns the theoretical foundation of the paper. Although **EAMET** shows strong experimental results, the theoretical aspect is an essential part of the paper‚Äôs contribution. Please refer to the **Questions** section for details."}, "questions": {"value": "* In Equation (20), the paper assumes that in a large-scale editing batch, any knowledge update vector $(r_i)$ can be approximately represented as a weighted average of all other update vectors $(r_j)$ within the same batch. While this assumption might hold with a small $\\epsilon_i$ in semantically related cases, it may not hold in semantically unrelated batches, where $\\epsilon_i$ could be large. In such cases, the reconstruction residual would be excessively high and lose its interpretative significance. How do the authors explain this issue?\n* Is the cosine similarity in Equation $9$ order-invariant? In massive editing, the order of knowledge updates should be arbitrary, so I believe an order-invariant definition should be provided here. If it is not order-invariant, what would the empirical results look like when the order is randomized?\n* Why is preserving original knowledge defined as $\\Delta C_p = 0$? Theoretically, $C_p$ should be a positive value to ensure the protection of existing knowledge. Practically speaking, removing $C_p$ should lead to a significant drop in editing performance (intuitively), since it serves as a regularization term, especially for preserving existing knowledge (specificity metric). How do the authors justify this design choice?\n* Robustness when editing the same subject is indeed important. However, what happens if the facts about the same subject are potentially contradictory? Would the post-edit LLM produce inconsistent answers in such cases?\n* Figure 1 is not mentioned in the main text, and the last case (i.e., {Sentences | $ùë†_i$ = Jeep Commander}) requires further clarification of its meaning to make it more reader-friendly."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "mN8UzgfRLu", "forum": "VJGVfJJ2wW", "replyto": "VJGVfJJ2wW", "signatures": ["ICLR.cc/2026/Conference/Submission4398/Reviewer_jhJa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4398/Reviewer_jhJa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4398/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760668339047, "cdate": 1760668339047, "tmdate": 1762917339019, "mdate": 1762917339019, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies why massive editing (e.g., 10k facts at once) breaks many model-editing methods and proposes EAMET, which aligns key and residual embedding spaces during the edit step. Under the stricter metric and in harder settings, EAMET claims high editing efficacy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem is interesting where massive editing fails. \n2. It introduces a stricter, more practical success metric tied to generation.\n3. The results show the effectiveness of their method."}, "weaknesses": {"value": "1. The primary experiments appropriately focus on large-batch editing, but the performance under single-edit or small-batch scenarios (e.g., editing only one or a few facts) remains unexplored. It would be valuable to examine whether the proposed alignment mechanism still provides benefits in these simpler settings.\n2. The use of KL divergence over similarity-based softmax distributions to measure embedding misalignment is unconventional. The paper should clarify whether similar formulations have been used in prior literature.\n3. The strategy for choosing the number of neighbors M in the pairwise MSE alignment term is not discussed.\n4.The method introduces multiple additional hyperparameters, making the approach potentially fragile.\n5. Although EAMET achieves notable gains in certain large-scale settings, its improvements are not consistently observed across all datasets and model families"}, "questions": {"value": "Please refer to the Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pKGdNjqjLR", "forum": "VJGVfJJ2wW", "replyto": "VJGVfJJ2wW", "signatures": ["ICLR.cc/2026/Conference/Submission4398/Reviewer_QuKf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4398/Reviewer_QuKf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4398/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980987376, "cdate": 1761980987376, "tmdate": 1762917338583, "mdate": 1762917338583, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an innovative approach, EAMET, for enhancing the robustness of large-scale model editing, focusing on aligning key and residual embeddings to improve the editing efficacy in large language models. The research addresses a pertinent issue in model editing, and the proposed method demonstrates promising results across various benchmarks. However, there are several areas that need further clarification and improvement for better understanding and impact."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed EAMET framework brings an innovative solution to improve the effectiveness of model editing, particularly in massive editing scenarios. By aligning key and residual embeddings, it overcomes limitations seen in traditional methods, making it a valuable contribution to the field.\n\n2. The paper includes comprehensive experiments on multiple datasets and models, demonstrating the effectiveness of the proposed method in real-world scenarios. The experimental design is solid, and the results are promising, showing EAMET‚Äôs superiority over existing methods."}, "weaknesses": {"value": "1. The current empirical analysis (starting at line 200)  would benefit from a deeper investigation into how the success rate of editing varies across different categories of knowledge, particularly considering their varying degrees of representation inconsistency. This would provide stronger evidence for the challenges addressed by the proposed method.\n\n2. The paper does not provide a detailed complexity analysis of the Key Embedding Preparation step, which involves calculating a large number of cosine similarities.\n\n3. While not a major issue, some points in the writing need improvement. For example, the abbreviation for \"CF ZS\" in the experiments section is not defined; Formula (15) lacks punctuation; The definition of \"N\" in Formula (14) is not provided.\n\n4. Formula (14) is central to the paper‚Äôs approach, but it is difficult to fully understand without a more detailed explanation. While I can infer its meaning, the explanation provided is insufficient, and I spent considerable time trying to understand it."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jnk6vLcQ2q", "forum": "VJGVfJJ2wW", "replyto": "VJGVfJJ2wW", "signatures": ["ICLR.cc/2026/Conference/Submission4398/Reviewer_XmZ3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4398/Reviewer_XmZ3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4398/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762140079032, "cdate": 1762140079032, "tmdate": 1762917338283, "mdate": 1762917338283, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes EAMET, a massive model editing method that aims to address a key failure of existing locate-then-edit approaches such as MEMIT/PMET: the embedding misalignment between key embeddings and residual/memory embeddings when many facts are edited simultaneously. The authors provide a theoretical analysis linking reconstruction error in closed-form edits to the mismatch between similarity structures in key space and residual space, then introduce an alignment-based optimization of residual embeddings integrated into a MEMIT-style update. Empirically, EAMET seems to show consistently improved efficacy, robustness, and portability across multiple LLM architectures and factual datasets, with minimal degradation to general capabilities."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ This paper clearly identifies and theoretically characterizes embedding misalignment as a core scalability bottleneck for existing massive edits approaches.\n\n+ The proposed EAMET is architecturally compatible with MEMIT-style pipelines. It introduces alignment-based optimization of the derived residual embeddings, which makes sense to address the embedding misalignment problem.\n\n+ The experiments with 10k+ edits or long prefixes seem to demonstrate the effectiveness of the proposed method."}, "weaknesses": {"value": "- It seems that the per-fact residual optimization and alignment steps may be expensive at very large scales. I'm curious about the detailed runtime, memory, and scalability trade-offs with the MEMIT-style baselines.\n\n- The optimization of the alignment seems to be sequential. I also wonder if the optimization order can have a difference to the editing results."}, "questions": {"value": "Please refer to my summary of weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "LrHFXABTJ5", "forum": "VJGVfJJ2wW", "replyto": "VJGVfJJ2wW", "signatures": ["ICLR.cc/2026/Conference/Submission4398/Reviewer_ifDP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4398/Reviewer_ifDP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4398/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762752873787, "cdate": 1762752873787, "tmdate": 1762917337967, "mdate": 1762917337967, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global Response by Authors"}, "comment": {"value": "Dear Reviewers,\n\nWe thank all reviewers for their insightful feedback. The comments have been invaluable in improving our work. In this rebuttal, we provide new experimental results (including new correlation, reliability, and variance analyses) to address all concerns. All these new analyses and the corresponding discussions will be integrated into our revised paper.\n\nBest regards"}}, "id": "86ky34DbNa", "forum": "VJGVfJJ2wW", "replyto": "VJGVfJJ2wW", "signatures": ["ICLR.cc/2026/Conference/Submission4398/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4398/Authors"], "number": 12, "invitations": ["ICLR.cc/2026/Conference/Submission4398/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763359876096, "cdate": 1763359876096, "tmdate": 1763359876096, "mdate": 1763359876096, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}