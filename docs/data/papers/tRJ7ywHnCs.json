{"id": "tRJ7ywHnCs", "number": 11953, "cdate": 1758204867857, "mdate": 1762923655865, "content": {"title": "Learning Universal Sample Difficulty with Pathology Foundation Models in Histopathology Image Analysis", "abstract": "The fast scaling speed of histopathology datasets allows researchers to train various foundation models for disease-centered research with applications in classifying disease-state information and predicting gene expression levels. However, it has been shown that current models tend to be overconfident and make classification at a low-calibration level. This case is underexplored for regression-type tasks such as gene expression prediction as well, which could seriously affect the diagnosis and treatment based on the developed models. To resolve this critical issue, we propose a \\underline{u}niversal framework\\footnote{Full codes can be found here: \\url{https://anonymous.4open.science/r/USD-13EB/} (also in supplementary files).} to estimate the \\underline{s}ample \\underline{d}ifficulty (USD) in both regression and classification tasks. In particular, we fit the data in the embedding space with Gaussian distribution and then utilize prior-informed relative Mahalanobis distance to estimate sample difficulty. Moreover, we incorporate such difficulty as a weight to regularize the model prediction, which can improve model performance by emphasizing challenging samples. Our method can be seamlessly extended to regression tasks by the incorporation of discrete targets. Extensive experiments demonstrate that our proposed USD can improve the disease-state classification accuracy by up to 3.8\\% and gene-level correlation by up to 62.2\\% compared with the most frequently used approaches. Finally, we provide comprehensive ablation tests to demonstrate the importance of including sample difficulty in the training stage and case studies for the reasonability of assigning samples with different difficulty levels.", "tldr": "We propose a generalized sample difficulty estia", "keywords": ["histopathology"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/9c5cc050aaff4dc281b708f819a414fe41139d24.pdf", "supplementary_material": "/attachment/e1c4abdb43e524a0b7ee1d3a41c4ffd41e9acc24.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a framework to estimate sample difficulty from PFM embeddings using a modified relative Mahalanobis distance (MRMD). Samples consistently misclassified by LR are assigned maximal difficulty. Difficulty weights regularize training (either entropy-regularized CE or Poly) for classification. The proposed method improves over baselines across 3 classification datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tClear high-level idea: Estimating difficulty in representation space and using it to weight training is intuitive; extending to regression via discretization is practical.\n2.\tBreadth of evaluation: Multiple datasets (including large histopathology datasets and 8 spatial transcriptomics cohorts), several PFMs (UNI v1/v2, GigaPath, plus ResNet50), and a reasonably comprehensive set of baselines and ablations (choice of K, batch correction, loss components, training head vs full finetune)."}, "weaknesses": {"value": "1.\tMRMD definition/sign: The paper defines MD with a negative quadratic form and then $RMD = MD_k − MD_b$, which is counter to the conventional “distance ≥ 0” notion. It’s not fully clear whether larger MRMD corresponds to harder or easier samples before normalization.\n2.\tGaussian modeling: Fitting full covariances $Σ$ and $Σ_b$ in high-dimensional PFM embedding spaces can be ill-conditioned given typical sample sizes. No discussion of regularization/shrinkage or dimensionality reduction prior to MD computation is provided. This may be crucial for robustness and reproducibility.\n3.\tRegression formulation and OE term: In Eq. (9), the second term collapses to zero because each feature is its own center, leaving only pairwise penalties between “centers.” This deviates from OE formulations that trade off tightness and diversity. More justification is needed.\n4.\tStroger difficulty estimation baselines: Compare against stronger baselines such as kNN density in embedding space, energy-based OOD scores, ODIN/Mahalanobis OOD, deep ensemble/MC-dropout uncertainties, and sample reweighting via OHEM or margin-based hardness."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XvV814ydxE", "forum": "tRJ7ywHnCs", "replyto": "tRJ7ywHnCs", "signatures": ["ICLR.cc/2026/Conference/Submission11953/Reviewer_guJe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11953/Reviewer_guJe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761027827792, "cdate": 1761027827792, "tmdate": 1762922955387, "mdate": 1762922955387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We will withdraw this manuscript."}}, "id": "vhb0ABWRdp", "forum": "tRJ7ywHnCs", "replyto": "tRJ7ywHnCs", "signatures": ["ICLR.cc/2026/Conference/Submission11953/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11953/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762923654902, "cdate": 1762923654902, "tmdate": 1762923654902, "mdate": 1762923654902, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates sample difficulty in histology image analysis, which is estimated by prior-informed relative Mahalanobis distance (RMD), for both classification and regression tasks. For those difficult samples, a higher weight is assigned to regularize the training."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. It is new to explore sample difficulty in histology image analysis.\n2. Both classification and regression are considered."}, "weaknesses": {"value": "1. The elaboration in this paper is ambiguous. For example, it is confusing about low-level information. What’s the low-level information? What’s a low-low-calibration level? What’s the relationship between “current models tend to be overconfident” and sample difficulty?\n2. Some explanations are inaccurate. TCGA LUSC-LUAD is for cancer subtyping, and CAMELYON16 is for the detection of cancer metastasis instead of the disease state. PANDA is for grading, which is actually supposed to be measured by the kappa coefficient.\n3. The novelty is incremental. The authors simply applied RMD [1] in slide-level or patch-level embedding without sufficient motivation.\n4. The empirical evidence cannot support that learning based on sample difficulty is necessary. The common pipeline of modeling WSI is multiple instance learning. However, no comparison to these MIL approaches is given.\n\n[1] Learning Sample Difficulty from Pre-trained Models for Reliable Prediction, NeurIPS 2023."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "P6YnDagYgy", "forum": "tRJ7ywHnCs", "replyto": "tRJ7ywHnCs", "signatures": ["ICLR.cc/2026/Conference/Submission11953/Reviewer_unxz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11953/Reviewer_unxz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761836643735, "cdate": 1761836643735, "tmdate": 1762922955007, "mdate": 1762922955007, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a method to quantify the difficulty of training samples, in order to increase their importance in the training loss, with a specific focus on the digital pathology data domain. The difficulty of a sample is derived from its similarity to other samples from the same label and ones from other labels in embedding space, but also from errors made by the trained model on the given sample. The method is compared against diverse baselines on different slide-level histopathology datasets."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- S1:  Estimating sample difficulty is a promising direction to improve performance and calibration of classifiers.\n- S2: The method is compared against many other baselines on diverse datasets."}, "weaknesses": {"value": "- W1: [Major] The paper lacks clarity, making it hard to properly understand the contributions. It is thus very challenging to judge its relevance for the community. The introduction does not tell a clear story, and the methods section is hard to follow. This explains why my summary of this paper is rather short. I’m ready to re-consider this point if other reviewers have an opposite impression, but clarity was a major obstacle for me to properly assess the quality of the presented work.\n- W2: [Major] It is surprising that different methods achieve 100% accuracy and AUROC on the TCGA dataset (Table 1). Do authors have any reflexion about this?\n- W3: [Major] The authors present their method in the context of histopathology image analysis. However, it is not clear to me whether digital pathology is a better fit for this contribution than any other domain. Could authors elaborate on this?\n- W4: [Minor] L.200 {x_i} is used to refer to features while it was previously used to refer to the set of images. A feature-specific notations should be introduced here.\n- W5: [Minor] Many paper references should be between parentheses (you can use “\\citep{}” in latex)."}, "questions": {"value": "- Q1: [Related to W1] Can authors explain how they will improve the presentation of their method and overall contributions to make the paper easier to follow?\n- Q2: [Related to W2] Do authors have any reflexion about the 100% accuracy of many baselines on the TCGA dataset (Table 1)?\n- Q3: [Related to W3] Could authors explain why histopathology is more relevant as the application domain for this method compared with other domains?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wSVe7HbPl1", "forum": "tRJ7ywHnCs", "replyto": "tRJ7ywHnCs", "signatures": ["ICLR.cc/2026/Conference/Submission11953/Reviewer_WQsu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11953/Reviewer_WQsu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929878600, "cdate": 1761929878600, "tmdate": 1762922954396, "mdate": 1762922954396, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper improves downstream task learning with pathology foundation models by estimating sample difficulty in an unsupervised fashion and then using these difficulty weights to assign larger weights to more difficult samples in the loss. The authors perform experiments with three publicly available foundation models (UNI, UNIv2, Gigapath) and one ResNet-50 ImageNet baseline on five different benchmarks (TCGA subset, CAMELYON16, PANDA, HEST-1k, STImage-1K4M). Their experiments showed that the method can improve the accuracy on morphology based classification tasks  by up to 3.8% and gene-level correlation by up to 62.2%."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Improving the downstream probes for pathology foundation models is an understudied problem. In that regard the paper makes a valuable contribution.\n\n* The evaluation is performed over multiple public datasets and publicly available models. Therefore, the results can be easily reproduced.\n\n* The downstream training is compared to multiple baseline methods (LS, L_1, Focal, Poly, WER, WPoly).\n\n* The method archives significant gains over the standard training regimes."}, "weaknesses": {"value": "* The paper basically just applies the method from [1] to the pathology domain. It is interesting how much impact it can have there but the methodological novelty is limited.\n\n* The paper uses the Malahanobis distance to measure the outlierness of a sample relative to the other samples in the class. Only the Malahanobis distance is considered and not any other outlier/anomaly detection methods. For an applied study, it would be particularly interesting to compare various methods from the literature and see how they are performing. Further, it would be good to put the paper into context of other anomaly detection works on pathology images.\n\n* Stylistic: The citations do not use brackets which make the paper really hard to read in some paragraphs. Additionally, some of the plot axis values (yticks) are really hard to read (e.g. Fig 4).\n\n[1] Peng Cui, Dan Zhang, Zhijie Deng, Yinpeng Dong, and Jun Zhu. Learning sample difficulty from pre-trained models for reliable prediction. Advances in Neural Information Processing Systems, 36:25390–25408, 2023."}, "questions": {"value": "* Why are not all  HEST-1K tasks used? The following are missing: PAAD, SKCM, LUAD. This always looks a little bit suspicious. Also for the other tasks standardized splits from a commonly used evaluation framework for pathology foundation models ( https://github.com/kaiko-ai/eva/tree/main) could be used. This would make the paper much stronger in my view.\n\n* How were the hyperparameters for the proposed and all the baseline methods tuned (How many values were considered and how was the validation split done)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vWDO9OsX1O", "forum": "tRJ7ywHnCs", "replyto": "tRJ7ywHnCs", "signatures": ["ICLR.cc/2026/Conference/Submission11953/Reviewer_88i4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11953/Reviewer_88i4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11953/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997655566, "cdate": 1761997655566, "tmdate": 1762922953877, "mdate": 1762922953877, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}