{"id": "jNY2bQnQ6D", "number": 4579, "cdate": 1757712699031, "mdate": 1759898025282, "content": {"title": "Data Unlearning Beyond Uniform Forgetting via Diffusion Time and Frequency Selection", "abstract": "Data unlearning aims to remove the influence of specific training samples from a trained model without requiring full retraining.\nUnlike concept unlearning, data unlearning in diffusion models remains underexplored and often suffers from quality degradation or incomplete forgetting.\nTo address this, we first observe that most existing methods attempt to unlearn the samples at all diffusion time steps equally, leading to poor-quality generation. We argue that forgetting occurs disproportionately across time and frequency, depending on the model and scenarios. By selectively focusing on specific time–frequency ranges during training, we achieve samples with higher aesthetic quality and lower noise. We validate this improvement by applying our time–frequency selective approach to diverse settings, including gradient-based and preference optimization objectives, as well as both image-level and text-to-image tasks. \nFinally, to evaluate both deletion and quality of unlearned data samples, we propose a simple normalized version of SSCD. Together, our analysis and methods establish a clearer understanding of the unique challenges in data unlearning for diffusion models, providing practical strategies to improve both evaluation and unlearning performance.", "tldr": "", "keywords": ["data unlearning", "diffusion model", "diffusion unlearning"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a032c7f5372e402ef02720653da7de62f6df0d3b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses data unlearning in diffusion models, which aims to remove the influence of specific training samples without full retraining. The authors identify a limitation of existing approaches: they attempt to unlearn samples uniformly across all diffusion time steps, resulting in quality degradation and incomplete forgetting. Through empirical analysis, the paper tries to demonstrate that forgetting occurs disproportionately across time and frequency domains, with different time steps encoding different levels of information (coarse semantics in late steps, fine details in early steps). Based on these insights, they propose a selective unlearning framework that applies non-uniform time step weighting and low-pass filtering to target specific time-frequency ranges during unlearning. The approach is compatible with various unlearning objectives (gradient ascent, SISS, DPO, KTO) and is validated on both image-level (CelebA-HQ) and text-to-image (Stable Diffusion) tasks, and it appears to show improved aesthetic quality and better preservation of unlearned sample quality. Additionally, they introduce SSCDnorm, a normalized version of SSCD that better captures unlearning quality by considering the directionality of changes rather than just similarity scores."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The authors conduct a thorough empirical evaluation across multiple unlearning objectives (Gradient Ascent, SISS, DPO, KTO) and systematically explore different time step intervals and frequency cutoffs. This comprehensive analysis  demonstrates that forgetting occurs non-uniformly across specific time steps and frequency components for CelebA-HQ dataset.\n- The proposed method achieves  gains in aesthetic quality (up to 34.83% improvement) while maintaining or improving unlearning performance. The results  show better preservation of visual quality in unlearned samples compared to baseline methods, addressing a critical limitation of existing approache\n- The introduction of SSCDnorm is a valuable contribution that addresses limitations of standard SSCD by considering directionality of changes. This provides a more meaningful measure of unlearning quality that distinguishes between true forgetting and quality degradation.\n- The paper is well-written and easy to follow"}, "weaknesses": {"value": "* The paper relies entirely on empirical observations and prior findings about image formation in diffusion processes, without providing theoretical analysis or formal justification for why selective time-frequency unlearning should work. The hypotheses are validated through experiments, but there is no principled framework to predict which time steps and frequencies are optimal for a given scenario, limiting the generalizability of the findings.\n* The method requires manual tuning of time step intervals [t₁, t₂] and frequency cutoff radius r_t for each scenario. Critically, the paper shows that optimal settings differ significantly between tasks (e.g., middle steps [250, 750] for CelebA-HQ vs. late steps [750, 1000] for Stable Diffusion), but provides limited guidance on how practitioners should determine appropriate parameters for new datasets or models. The authors acknowledge this limitation in the conclusion but do not propose solutions.\n* While the experiments cover multiple unlearning objectives, the evaluation is restricted to two specific settings (CelebA-HQ and Stable Diffusion v1.4 with 45 prompts). Broader evaluation across different model architectures, image resolutions, and diverse forgetting scenarios would strengthen the claims about the method's general applicability.\n* While the authors acknowledge \"failure cases in quality preservation\" (Section 4.2), there is no systematic analysis of when and why the method fails, what characteristics of forget samples lead to poor outcomes, or how to predict and mitigate these failures.\n* The \"catastrophic collapse\" phenomenon has also been commented on (for T2I models): \"Laria, H., Gomez-Villa, A., Wang, K., Raducanu, B., & van de Weijer, J. (2024). Assessing Open-world Forgetting in Generative Image Model Customization\""}, "questions": {"value": "* Have you tested your approach on other datasets or other diffusion model architectures (e.g., DiT, different versions of Stable Diffusion)?\n* Can you provide a more detailed characterization of the failure cases mentioned in Section 4.2? What percentage of forget samples experience quality degradation? Are there identifiable patterns (e.g., certain image characteristics, proximity to retain distribution) that predict failures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZyRun1VH6G", "forum": "jNY2bQnQ6D", "replyto": "jNY2bQnQ6D", "signatures": ["ICLR.cc/2026/Conference/Submission4579/Reviewer_EcA4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4579/Reviewer_EcA4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4579/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761757752109, "cdate": 1761757752109, "tmdate": 1762917452756, "mdate": 1762917452756, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work focuses on data unlearning in diffusion models. The authors identify that most existing data unlearning approaches perform uniform unlearning across all diffusion timesteps, which often causes severe degradation of image fidelity and incomplete removal of learned information. To overcome this limitation, the paper introduces a time–frequency selective unlearning framework, which applies unlearning selectively to particular middle-late timesteps and focuses on low-frequency semantic components in the latent space.  Extensive experiments on CelebA-HQ and Stable Diffusion v1.4 demonstrate that the proposed method consistently outperforms existing baselines in terms of unlearning accuracy and image quality, confirming the effectiveness of the time–frequency selective strategy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed time–frequency selective unlearning mechanism introduces a simple yet effective improvement over baseline approaches. This method focuses on mid-to-late timesteps and further constrains unlearning to low-frequency components through an FFT-based low-pass filter. This selective design allows the model to remove semantic information while preserving high-frequency texture details.\n\n2. This paper introduces SSCDnorm to provide a more reliable measurement of unlearning effectiveness. While traditional SSCD often rewards methods that simply degrade image quality, SSCDnorm decouples perceptual degradation from unlearning. As a result, it can better distinguish between genuine unlearning and trivial quality loss. \n\n3. Extensive experiments on CelebA-HQ and Stable Diffusion v1.4 validate the effectiveness of the proposed framework. On CelebA-HQ, the method achieves the lowest SSCDnorm and competitive FID and Aesthetic scores. On Stable Diffusion, selective unlearning within the [750, 1000] timestep range leads to faster convergence and a higher unlearning success rate than baselines."}, "weaknesses": {"value": "1. The time window and frequency cutoff are chosen empirically without adaptive tuning or robustness analysis. This makes the method less stable and difficult to generalize across different models and tasks. It is recommended that the authors conduct further experiment to explore how different parameter settings affect the unlearning performance and model stability.\n\n2. The paper lacks systematic ablation studies, and the image-level experiment [l375] only removes six faces, which is too few to convincingly verify the generality of the approach.\n\n3. The paper reports only a simple “attack success rate” in Figure 10. Given that the selective unlearning framework may introduce potential vulnerabilities, it is recommended that the authors adopt standardized robustness evaluation metrics proposed in recent studies [1-3].\n\n\n\n4. The proposed approach appears can be viewed as an incremental extension of existing unlearning frameworks rather than a fundamentally novel algorithm. Specifically, the method builds directly upon prior optimization-based unlearning methods such as GA and SISS, maintaining the same training objective and loss formulation. Its main modification lies in introducing time–frequency selection, which heuristically restricts the unlearning process to certain diffusion timesteps and frequency bands. While this design provides empirical improvements and clearer interpretability, it does not fundamentally alter the underlying optimization principle or introduce a new learning paradigm, thus positioning the work as an empirical extension rather than a methodological breakthrough.\n\n\n[1] Yu-Lin Tsai, Chia-Yi Hsu, Chulin Xie, Chih-Hsun Lin, Jia-You Chen, Bo Li, Pin-Yu Chen,Chia-Mu Yu, and Chun-Ying Huang. Ring-a-bell! how reliable are concept removal methods for diffusion models? ICLR, 2024.\n\n[2] Yijun Yang, Ruiyuan Gao, Xiaosen Wang, Nan Xu, and Qiang Xu. Mma-diffusion: Multimodal attack on diffusion models. CVPR, 2024.\n\n[3] Yimeng Zhang, Jinghan Jia, Xin Chen, Aochuan Chen, Yihua Zhang, Jiancheng Liu, Ke Ding, and Sijia Liu. To generate or not? safety-driven unlearned diffusion models are still easy to generate unsafe images... for now. arXiv preprint, 2023"}, "questions": {"value": "Please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lqe1qw95fE", "forum": "jNY2bQnQ6D", "replyto": "jNY2bQnQ6D", "signatures": ["ICLR.cc/2026/Conference/Submission4579/Reviewer_SjNC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4579/Reviewer_SjNC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4579/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878784991, "cdate": 1761878784991, "tmdate": 1762917452436, "mdate": 1762917452436, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper experiments with selective timestep and frequency selection for data unlearning in diffusion models. The authors find that careful selection of timestep and using a low-pass filter helps improve the sample quality of the unlearned images on normalized SSCD and aesthetic scores."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- A good deal of quantitative and qualitative empirical evidence is provided to justify claims that the middle range of timesteps are most effective to target and that awkward artifacts in the samples of unlearned images using existing methods are primarily the result of high frequency components being targeted.\n- Analysis of the performance of preference optimization methods such as DPO and KTO are provided as well and appear to be quite effective."}, "weaknesses": {"value": "- I would say the primary weakness of the paper is why the quality of the unlearned samples matters if they have already been successfully unlearned\n- Section 3 is missing some details - see questions"}, "questions": {"value": "- Regarding section 3:\n    - In Figure 4b, which loss function is being used - I'm assuming gradient ascent? Why is the gap in gradient norm before and after unlearning meaningful?\n   - In Hypothesis 2, it appears there is a distinct between collapsed forget data and non-collapsed forget data. What does collapsed mean in this context?\n\n- I may have missed it, but details surrounding the construction of the DPO and KTO preference optimization datasets would be appreciated\n- Noting some typos:\n    - Line 306: Citation incorrectly inside parantheticals\n    - Line 318: Hyperparameter is misspelled, citation is incorrectly inside parantheticals"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9YGzh4xDzK", "forum": "jNY2bQnQ6D", "replyto": "jNY2bQnQ6D", "signatures": ["ICLR.cc/2026/Conference/Submission4579/Reviewer_53d3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4579/Reviewer_53d3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4579/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762064348718, "cdate": 1762064348718, "tmdate": 1762917452037, "mdate": 1762917452037, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses data unlearning in diffusion models, focusing on removing specific training samples without full retraining. The authors observe that existing methods uniformly apply unlearning across all diffusion timesteps, leading to quality degradation and incomplete forgetting. They propose a selective unlearning framework based on middle-to-late timestep forgetting and preserving high-frequency components through low-pass filtering to maintain fine-grained details. Their approach shows improvements in aesthetic quality while maintaining unlearning effectiveness on both CelebA-HQ and Stable Diffusion experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper provides empirical investigation across multiple dimensions. The toy experiment on two half-moons (Figure 2) clearly illustrates how different timestep ranges affect unlearning. The gradient norm analysis (Figure 4b) provides concrete evidence that middle-to-late timesteps are most affected by unlearning. The power spectral density analysis (Figures 5-6) offers compelling evidence for the frequency filtering hypothesis. These analyses are well-grounded in prior work on diffusion model behavior.\n- The proposed framework is simple and can be integrated with existing unlearning objectives without modifications. The experiments demonstrate consistent improvements across diverse settings.\n- The normalized SSCD metric addresses a genuine limitation in existing evaluation where low similarity scores can result from quality degradation rather than effective unlearning. The motivation is clear and the metric provides more meaningful evaluation of unlearning direction.\n- The paper tests multiple baseline methods, providing consistent gains in aesthetic scores while maintaining or improving forgetting metrics."}, "weaknesses": {"value": "- While the appendix mentions searching over discrete time ranges and frequency cutoffs $r_t$, this still requires manual grid search for each new scenario. The paper shows that CelebA-HQ works best with [250, 750] while Stable Diffusion requires [750, 1000], but provides no systematic approach for determining these ranges a priori beyond trial and error. Without principled guidelines or even heuristics, practitioners must conduct extensive grid search for each new task, limiting practical applicability.\n- The paper provides no timing comparisons or computational overhead analysis. The FFT operations and selective timestep sampling add computational cost that is never quantified. Without wall-clock time measurements or memory usage comparisons, it is difficult to assess the practical efficiency of the method.\n- While the empirical analysis is extensive, the paper lacks theoretical grounding for why these specific time-frequency regions are optimal. The hypotheses are supported by experiments and references to prior work on diffusion model behavior, but there is no formal analysis or theoretical framework. Why should frequency filtering specifically help?\n- The dramatically different optimal timestep ranges between CelebA-HQ and Stable Diffusion suggest that the approach may be highly task-dependent. The explanations for these differences (Section 4.3) are post-hoc and qualitative. Without clear principles for predicting optimal ranges, users cannot confidently apply this method to new scenarios.\n- While the motivation for the normalized metric is reasonable, it is introduced without validation against human perceptual judgments or established quality metrics beyond aesthetic scores. The choice of $l_2$ normalization and the specific formulation in Equation 13 appear arbitrary without ablation studies or justification.\n- The paper mentions \"failure cases in quality preservation\" on line 429, but does not analyze them or discuss when and why the method fails.\n\n\nThis paper addresses an important problem with well-motivated empirical analysis and demonstrates consistent improvements across multiple settings. However, the contribution is incremental, lacking principled hyperparameter selection methods and computational cost analysis, while theoretical understanding remains limited to post-hoc explanations of empirical observations."}, "questions": {"value": "- Have you explored adaptive or learnable selection mechanisms? Rather than manual tuning, could the optimal time-frequency regions be learned from data or estimated using gradient-based importance measures?\n- Why not explore learnable frequency masks? Instead of hard cutoffs at radius $r_t$, have you considered learning which frequency components to preserve or remove during unlearning?\n- What causes the failure cases you mention? Can you characterize when your method fails to preserve quality and identify patterns in these failures?\n- How does the method perform on other diffusion architectures? Have you tested on DiT (Diffusion Transformers) or other recent architectures beyond UNet-based models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jTI2KJjN3v", "forum": "jNY2bQnQ6D", "replyto": "jNY2bQnQ6D", "signatures": ["ICLR.cc/2026/Conference/Submission4579/Reviewer_4PVH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4579/Reviewer_4PVH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4579/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762104579051, "cdate": 1762104579051, "tmdate": 1762917451688, "mdate": 1762917451688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}