{"id": "EQjKmXpF8Z", "number": 12709, "cdate": 1758209652281, "mdate": 1759897492750, "content": {"title": "Analyzing Neural Style Representations for Unsupervised Clustering: Visual Art as a Testbed", "abstract": "Neural networks claim to capture artistic style, but it remains unclear whether their representations can organize artworks in unsupervised settings, or which aspects of style they truly encode. We present the first comprehensive analysis of neural style representations for unsupervised clustering of visual artworks. Our study systematically compares representations derived from classification networks, generative models, diffusion architectures, and vision-language systems, including our novel language-based features. Using both real-world artwork collections and synthetically curated datasets, we evaluate how effectively these representations capture style across multiple definitions. Our results show that specialized style representations consistently outperform generic embeddings, yet no single representation works across all style definitions. This variability reflects the inherent ambiguity of “style” itself, revealing a gap between human perception, art-historical categories, and machine-learned features. Taken together, our findings position visual art as a rigorous testbed for advancing unsupervised representation learning with broader implications for digital curation, cultural heritage, and style-aware computer vision.", "tldr": "How well do neural networks capture artistic style? We present the first comprehensive study of style representations for unsupervised artwork clustering.", "keywords": ["Style based clustering", "Neural representations for style", "Visual art"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/043c4a8353a63966854d64c48a1e315f23c1a38a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper delivers a large-scale, systematic benchmark of neural style representations for unsupervised clustering in visual art. It evaluates 16 representation families (task-based, style-transfer, and language-based, including a few novel variants) with two clustering paradigms across real and synthetic datasets that encode different operationalizations of “style.” Metrics include ARI, NMI, Silhouette, and Calinski–Harabasz, complemented by a small human perceptual study. The central finding is clear: specialized style features generally outperform generic ones on perceptual cohesion, yet no single representation works across all definitions of style—highlighting the concept’s inherent ambiguity and positioning visual art as a challenging testbed for unsupervised representation learning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper demonstrates exceptional rigor through a comprehensive benchmark spanning 16 representation families and multiple datasets, unified by a carefully designed evaluation protocol that respects competing definitions of \"style.\" The authors employ thoughtfully constructed synthetic style-transfer datasets to probe style-content disentanglement in ways that real annotations cannot easily support, while incorporating a perceptual study that strengthens the finding that \"ground truth\" style is inherently subjective and provides valuable context for interpreting metric-only results. Throughout the work, claims are consistently grounded in quantitative outcomes, and the visualizations effectively illustrate the meaningful gap between art-historical labels and perceptual clusters, making the evidence both compelling and accessible."}, "weaknesses": {"value": "The paper suffers from significant under-specification of methods and notation that undermines reproducibility. Key implementation details remain missing or inconsistent throughout, including exact formulations for Gram-based and language-derived features, layer selection strategies, normalization and whitening procedures, dimensionality reduction pipelines, and clustering configurations. Metric formulas are incompletely documented, and the handling of edge cases such as class imbalance and degenerate partitions is not adequately addressed, leaving readers unable to faithfully replicate the experimental setup.\n\nThe choice of clustering baselines is notably narrow, limiting the evaluation to only K-Means and DEC, which weakens the core benchmarking claim. The authors overlook stronger and more directly relevant methods such as Invariant Information Clustering (IIC), spectral and graph-based clustering approaches, and modern contrastive clustering techniques. Inclusion of these methods could meaningfully alter the conclusions about which representations best capture artistic style, and their absence represents a missed opportunity to establish more robust comparative insights.\n\nThe human perceptual study, while valuable in principle, is reported with insufficient detail. Critical information about participant recruitment, task instructions, randomization procedures, and inter-rater reliability measures such as Cohen's kappa are not provided. The analysis lacks fine-grained statistics and uncertainty quantification, making it difficult to assess the robustness and generalizability of the human-algorithm alignment findings.\n\nFinally, the paper demonstrates limited analytical depth and notable gaps in the literature review. Concrete failure cases are scarce, hyperparameter sensitivity is minimally explored, and important issues such as dataset bias and the synthetic-to-real domain gap receive insufficient discussion. The related work section under-cites or omits several foundational and recent contributions, including Ji et al. (2019) on IIC, Karayev et al. (2013) on recognizing image style, Crowley & Zisserman (2014) on CNN-based painting retrieval, Gonthier et al. (2018) on weakly supervised detection in art, generative art models like ArtGAN (Tan et al., 2018) and CAN (Elgammal et al., 2017), and more recent art-focused clustering work such as Gultepe et al. (2025) and Hu et al. (2023)."}, "questions": {"value": "Could you provide complete, reproducible implementation details and formulas for all representation families evaluated? \n\nWhy were stronger unsupervised clustering baselines not included in the benchmark？\n\nThe human perceptual study requires substantially more methodological transparency. Can you provide detailed information on participant recruitment procedures, exact task instructions, randomization protocols, and inter-rater reliability statistics such as Cohen's kappa? Furthermore, please include finer-grained statistical analysis with confidence intervals or error bars, and offer a systematic correspondence analysis between human judgments and each algorithmic metric to strengthen the human-algorithm alignment claims."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bstjcqalSd", "forum": "EQjKmXpF8Z", "replyto": "EQjKmXpF8Z", "signatures": ["ICLR.cc/2026/Conference/Submission12709/Reviewer_8ivT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12709/Reviewer_8ivT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761556587067, "cdate": 1761556587067, "tmdate": 1762923538205, "mdate": 1762923538205, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a comprehensive analysis of multiple art datasets, using different definitions of style, and two different clustering algorithms (no similarity measures considered or mentioned). The major conclusion is that unsupervised clustering for art to find style is difficult and hence we can conclude that the information that is needed is not sufficiently captured in the low-level embeddings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper gives an elaborate analysis including a large appendix where additional results are presented. \n- Good overview of the role of different aspects of style in art and how that is / is not reflected in the clustering results.\n- The paper is well written and easy to follow with many figures that give a good overview of the results. Findings are also presented in a well structured manner."}, "weaknesses": {"value": "- There is only an indication that this could also be applied to other domains. For now the paper is only relevant for art so probably is more suited for publication in a more digital humanities venue. Also reflected in the abstract where the contributions mentioned are digital curation, cultural heritage, and style-aware computer vision. The latter is only discussed in a very limited way and not backed by evidence beyond art. Furthermore, the references are not including ICLR. \n- The paper considers one method by the authors but that method is not outperforming the rest and also doesn't yield a clear complementary perspective.\n- The procedure is a well designed but standard experimental protocol. Not sufficiently innovative to be a blueprint for other application domains. \n- The clustering techniques are rather old. More modern methods should be considered. \n\nMINOR:\n- Many references are incomplete."}, "questions": {"value": "- What perspective does you own method bring that is not already covered by the other methods?\n- How would this method generalize to other domains?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N.A."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eFYCeZuzFu", "forum": "EQjKmXpF8Z", "replyto": "EQjKmXpF8Z", "signatures": ["ICLR.cc/2026/Conference/Submission12709/Reviewer_AdRZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12709/Reviewer_AdRZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761674339025, "cdate": 1761674339025, "tmdate": 1762923537822, "mdate": 1762923537822, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the inability of neural style representations to effectively support unsupervised clustering of visual artworks, despite their widespread use in style classification and transfer. It systematically evaluates 16 state-of-the-art neural style representations across 4 datasets (covering diverse style definitions) and 2 clustering algorithms, aiming to clarify how these representations capture \"style\"—a concept with inherent ambiguity (art movements, artist signatures, perceptual attributes, etc.). The paper develops a unified framework integrating datasets, clustering algorithms, and metrics to compare style representations. To address the limitation of real-world datasets (where style and content are often entangled), the paper introduces two synthetic curated datasets (MSC/MMC). Through cluster distribution analysis and hierarchical dendrograms, the paper demonstrates that artistic styles exhibit inherent multi-level relationships."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper demonstrates strong originality by addressing longstanding limitations in style representation research and introducing creative solutions that expand the scope of unsupervised clustering. It maintains exceptional methodological quality through well-controlled experiments, multi-faceted validation, and detailed documentation—ensuring reproducibility and credibility. The paper is exceptionally clear, making complex technical concepts and experimental results accessible to readers across computer vision, art informatics, and machine learning."}, "weaknesses": {"value": "The key results that the study yields three main insights seems trivial and with restricted specific value to guide the representation learning investigation in the future."}, "questions": {"value": "Thank you for conducting extensive experiments and presenting several insightful new findings in the paper. Could the authors explain the specific guiding significance of these new insights for future research work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "E2TnsppfvL", "forum": "EQjKmXpF8Z", "replyto": "EQjKmXpF8Z", "signatures": ["ICLR.cc/2026/Conference/Submission12709/Reviewer_RF1M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12709/Reviewer_RF1M"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761820285635, "cdate": 1761820285635, "tmdate": 1762923537514, "mdate": 1762923537514, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper claims to be the first systematic benchmark for unsupervised style clustering of artworks: it compares 16 neural representations with K-Means and DEC across four datasets that operationalize distinct style notions—WikiArt–ArtMove (27 movements), WikiArt–Artist (40 artists), DomainNet-3k (6 styles × 50 contents), and two synthetic curated sets (MSC/MMC) introduced here via style transfer for controlled style–content disentanglement. Evaluation combines external (ARI, NMI) and internal (Silhouette, Calinski–Harabasz) metrics plus a 25-participant perceptual study. The contributions of this study include language-based style features (FStyleCap, FAnnot) and artwork-trained Vision Transformers (FArtMove, FArtist). DEC improves internal geometry without altering external alignment, indicating that cleaner clusters do not always align better with ground-truth style categories."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The motivation is clear: style has multiple meanings, and there are few available labels; therefore, unsupervised analysis serves as an effective stress test. The paper effectively addresses this gap.\n\n2. Broad coverage. 16 embeddings spanning CNN/ViT, style transfer, diffusion, VLMs, and the two new language features, all under one protocol. Method families are laid out cleanly.\n\n3. Multi-view datasets. Beyond WikiArt and DomainNet-3k, the new MSC/MMC synthetic sets enable controlled checks of style–content disentanglement.\n\n4. Insightful results. On WikiArt-Artist, FCSD and FArtist beat generic features; on synthetic data, style-transfer family features (e.g., StyleShot/Mamba-ST derived) dominate—evidence that no single embedding fits all “style” definitions.\n5. Two-axis evaluation. Internal vs. external metrics are separated, and the DEC analysis makes the geometry-vs-semantics tension explicit.\n6. Perceptual study. Human ratings show that perceived style can diverge from art-historical labels—useful nuance for this area."}, "weaknesses": {"value": "1. Mostly point estimates; variance across seeds/initializations and significance tests are missing for K-Means/DEC.\n2. Several settings appear to set K = number of ground-truth classes (e.g., DomainNet-3k), which injects label priors into an “unsupervised” evaluation.\n3. MSC/MMC are built with specific style-transfer engines; even with “exclude same-source features,” rankings may reflect generator artifacts.\n4. FStyleCap/FAnnot often show higher internal but modest external scores; the claim that they capture interpretable style cues would benefit from direct analysis.\n5. No hierarchical/spectral/density methods despite hints of hierarchical style structure."}, "questions": {"value": "1. Can you add an unsupervised K selection (e.g., Silhouette/CHI/information criteria) and report how method rankings and key claims change relative to K = ground-truth?\n2. For K-Means/DEC, report mean ± std over multiple seeds, significance tests, and DEC stopping/temperature details. Do any conclusions flip under different inits?\n3. Rebuild MSC/MMC with different style-transfer engines and disjoint style pools (OOD); redo evaluation and report rank stability. Which methods are most/least sensitive?\n4. Given the paper’s claim of hierarchical/structured style, why limit to K-Means/DEC? Can you include hierarchical, spectral, and density-based (e.g., HDBSCAN) baselines and test whether the finding holds?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "y5ImqQbBrp", "forum": "EQjKmXpF8Z", "replyto": "EQjKmXpF8Z", "signatures": ["ICLR.cc/2026/Conference/Submission12709/Reviewer_Jmjt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12709/Reviewer_Jmjt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957756774, "cdate": 1761957756774, "tmdate": 1762923537279, "mdate": 1762923537279, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}