{"id": "s0zLtkY7iu", "number": 5350, "cdate": 1757903290646, "mdate": 1759897980155, "content": {"title": "Teaching Metric Distance to Discrete Autoregressive Language Models", "abstract": "As large language models expand beyond natural language to domains such as mathematics, multimodal understanding, and embodied agents, tokens increasingly reflect metric relationships rather than purely linguistic meaning. We introduce DIST2Loss, a distance-aware framework designed to train autoregressive discrete models by leveraging predefined distance relationships among output tokens. At its core, DIST2Loss transforms continuous exponential family distributions derived from inherent distance metrics into discrete, categorical optimization targets compatible with the models’ architectures. This approach enables the models to learn and preserve meaningful distance relationships during token generation while maintaining compatibility with existing architectures. Empirical evaluations show consistent performance gains in diverse multimodal applications, including visual grounding, robotic manipulation, generative reward modeling, and image generation using vector-quantized features. These improvements are most notable in low-data regimes, demonstrating DIST2Loss’s strength under resource constraints.", "tldr": "DIST2Loss trains discrete models to respect token distances, boosting performance in diverse domains, especially with limited data.", "keywords": ["Large Language Models", "Autoregressive Modeling", "Generative Modeling", "Efficient Training"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d286cd16a1070c9502e7d57573ddc874d85ed82f.pdf", "supplementary_material": "/attachment/621be38b16b007f4af290cf989e37239fa68cc26.zip"}, "replies": [{"content": {"summary": {"value": "The paper addresses a key limitation in adapting large language models (LLMs) to tasks involving numerical or metrically structured data. Conventional fine-tuning methods treat tokens as categorical variables, ignoring the intrinsic distance relationships among them—such as numerical proximity or spatial metrics. To overcome this, the authors propose DIST² loss, a new objective that integrates predefined distance relationships between tokens into the autoregressive loss used during training. This approach enables LLMs to better capture metric structure while remaining compatible with standard categorical token modeling. Empirical results demonstrate substantial performance improvements across tasks where distances are semantically meaningful, including object detection, object manipulation, reward modeling, and image generation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is clearly written and easy to follow.\n* The problem is important and timely, addressing a fundamental gap in how LLMs handle numerical and metric relationships.\n* Empirical results show significant improvements across diverse downstream tasks, including those with limited data\n* The proposed method integrates smoothly into existing LLM training objectives, maintaining compatibility with categorical token modeling."}, "weaknesses": {"value": "The paper does not clearly discuss how different types of numerical or metric data (e.g., integers, floats, directions) are handled under the same framework. It remains unclear whether the model improves actual numerical reasoning accuracy, beyond performance metrics on downstream tasks. There is a lack of explicit evaluation of the model’s ability to reason about true numerical distances or relationships, which would more directly validate the method’s intended benefits. See the questions below."}, "questions": {"value": "1. Is the same metric used for every numeral token, or are different metrics applied depending on token type (e.g., integers vs. floats vs. directions)?\n2. Are metric-based losses applied to text-only tokens, or only to numerically meaningful ones?\n3. Are such tokens, on which the metric/distance-based loss is applied, extracted manually?\n4. While the paper shows improvements in downstream tasks, could the authors demonstrate that the model achieves more accurate numerical reasoning (e.g., better alignment between predicted and true distances)? The authors could consider a design of a controlled experiment where digits/numbers are extracted from data and the trained models are asked to evaluate the distances or any related tasks. The results are then compared with true numerical distance values to directly test metric reasoning performance.\n\nThe current score reflects the questions above. I will consider updating the rating once my concerns have been resolved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Y4mq0Gj8UD", "forum": "s0zLtkY7iu", "replyto": "s0zLtkY7iu", "signatures": ["ICLR.cc/2026/Conference/Submission5350/Reviewer_Pvxr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5350/Reviewer_Pvxr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5350/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761555497572, "cdate": 1761555497572, "tmdate": 1762918019213, "mdate": 1762918019213, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper propose to learn the connections between discrete outputs, such the correlations between them can be captured during the learning process."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The reported results are marginally improved compared with existing methods.\n\n2. The source code is produced."}, "weaknesses": {"value": "1. The motivation of learning correlations among discrete concepts/semantics is not novel, which has been largely explored in the knowledge distillation works for a decade.\n\n2. The proposed DIST^2 loss is just a combination of loss used in knowledge distillation and KL-divergence, which is also proposed in 'Distilling Knowledge from Graph Convolutional Networks. CVPR 2020'.\n\n3. Overall, this work lacks of novelty and is with limited technical contribution."}, "questions": {"value": "Please refer to the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "2N2aYccBBu", "forum": "s0zLtkY7iu", "replyto": "s0zLtkY7iu", "signatures": ["ICLR.cc/2026/Conference/Submission5350/Reviewer_7BSi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5350/Reviewer_7BSi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5350/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761760197964, "cdate": 1761760197964, "tmdate": 1762918018997, "mdate": 1762918018997, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work aims to incorporate an additional regularisation term into the loss of an LLM which more explicitly forces the model to learn a representation of distance (in terms of the metric used in the regularisation term). The distance regulariser is also phrased in terms of entropy-regularisation in policy optimisation. Extensive experiments are shown, including an ablation study, which consistently support the utility of the proposed regularisation term."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "## Originality\nThe work is fairly original, particularly in the exact way they approach incorporating the distance metric. I'm particularly considering the discretised distance loss in this case which enables the KL divergence to work in a straight forward manner. The related work section at the end provides a nice overview of the literature and is very fair to other works in the space. I think contextualising the work in this manner should count towards originality, even if it does make the source of the ideas for the work more transparent.\n\n## Quality\nThe experimental design and extensive nature of the experimentation is a large strength of this work for me. Particularly as the work is proposing a \"framework\" it is good to see such breadth of experimentation considered. The motivation and hypothesis of the work is clear and grounded well in the literature (to my knowledge). The results which are obtained do directly test the claims of the work and are interpreted fairly overall.\n\n## Clarity\nOverall the paper is well written, with clear tables and figures. The paper is structured well to support understanding and mathematical notation is clear, consistent and mostly intuitive. I also appreciate how the sections are structured in order of task complexity (as best they can be).\n\n## Significance\nOverall I think the work has the potential to inspire future work and does provide good results on the benchmarks. Once again the extensive literature review also supports the fact that this work has broad utility across a couple domains which supports its significance."}, "weaknesses": {"value": "## Clarity\nI find the manner that subsequences is introduces in Section 2.2 a bit unintuitive and requires some effort to parse. I'm puzzles that the subsequence needs to be sequential within the input sequence. I assume this is answered by the point: \"...multiple elements are present within $s$, we limit our explanation to a singe $x$-subsequence here for clarity\". I find that this is a bit too subtle of a statement to actual convey the fact that it could easily generalise (if indeed it can and so ease of explanation becomes the priority). For example, what would need to change to the formulation or equations to make it work for multiple sequences? What tasks are of this nature and why might a single sequence be a sufficient explanation? Does this require the permutation invariance of the LLM to work?\n\n## Significance and Quality\nI will ground these two sections as they share a common point. One of the primary issues for me is that the need for supervision on the distance metric is somewhat glossed over. Fundamentally the model is being given more supervision and so higher performance is expected. This limits significance to a degree, but this affect quality more for me as this should really be discussed. How easy it is to define metric spaces for a variety of problems is the determinant of the success and significance of the work and this should be more clearly acknowledged and discuss. The level of experimentation shown here does support that it is possible, but it is left to the reader to gauge and really this is where the conceptual insight of the work lies."}, "questions": {"value": "I have listed a number of questions under weaknesses regarding the limitations of presenting the mathematical details using a single subsequence. I would appreciate if these could be answered."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Kkc1NNxgqW", "forum": "s0zLtkY7iu", "replyto": "s0zLtkY7iu", "signatures": ["ICLR.cc/2026/Conference/Submission5350/Reviewer_qCXL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5350/Reviewer_qCXL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5350/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991991691, "cdate": 1761991991691, "tmdate": 1762918018650, "mdate": 1762918018650, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the field of LLM extended to non-linguistic domains (e.g., multimodal understanding, robotic manipulation, generative reward modeling) and addresses the key problem that traditional one-hot targets and cross-entropy loss ignore the metric relationships (e.g., coordinates, rotation angles, quantized embeddings) inherent in tokens. Motivated by the inefficiency of conventional fine-tuning (neglecting metric structure) and the instability of RL methods (sampling/rollout noise), the authors aim to enhance model performance in low-data regimes while maintaining compatibility with existing architectures . The core method, DIST2Loss, transforms continuous exponential family distributions derived from inherent distance metrics (e.g., Euclidean distance, RMSE) into discrete categorical targets, computes distance-aware loss via KL divergence, and fuses it with standard cross-entropy loss. Empirical results show that DIST2Loss consistently improves performance across diverse tasks with the most notable gains in data-scarce settings ."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The manuscript addresses a critical limitation of discrete autoregressive models (neglect of metric token relationships) with a principled solution—DIST2Loss directly embeds metric structure into the target distribution without relying on extra data or architectural modifications. This fills a gap in extending LLMs to non-linguistic tasks where spatial/numerical relationships matter.\n\n2. DIST2Loss is validated on five distinct tasks (meta linear regression, visual grounding, robotic manipulation, reward modeling, image generation), demonstrating its broad applicability. This cross-task consistency strengthens the credibility of the method. It also performs well in low-data regimes."}, "weaknesses": {"value": "1. Insufficient details on hyperparameter $\\tau$: The temperature hyperparameter $\\tau$  controls the smoothness of the target distribution, but the manuscript only states \"small values for digits and larger values for VQ-VAE vocabularies\" without providing specific values or a systematic sensitivity analysis. \n\n2. I suggest the paper incorporates additional technical approaches for comparable distance perception methods. For instance, it could detail whether other methods achieve distance modeling through modifications to the loss function, adjustments to the target distribution, or the introduction of external modules. \n\n3. Does the default setting of $\\alpha$ = 0.1 potentially lead to a scale imbalance problem? Is it possible to incorporate an adaptive scaling mechanism to prevent this?\n\n4. The authors evaluate other capabilities solely after single-task fine-tuning (e.g., MMLU after fine-tuning for reward modeling). However, they do not validate performance in multi-task fine-tuning scenarios. \n\n5. The authors only validated general language abilities (MMLU) and did not cover non-linguistic fundamental abilities (e.g., image understanding capabilities). Including these aspects would significantly enhance the paper's quality."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vFdSiOvvxj", "forum": "s0zLtkY7iu", "replyto": "s0zLtkY7iu", "signatures": ["ICLR.cc/2026/Conference/Submission5350/Reviewer_aRs1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5350/Reviewer_aRs1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5350/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762064208743, "cdate": 1762064208743, "tmdate": 1762918018289, "mdate": 1762918018289, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}