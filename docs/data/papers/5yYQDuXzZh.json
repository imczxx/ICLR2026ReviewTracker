{"id": "5yYQDuXzZh", "number": 19069, "cdate": 1758293263054, "mdate": 1759897062757, "content": {"title": "DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models", "abstract": "Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as ‘distracting tokens’. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dy-namically detects and prunes these distracting image tokens. By correcting the model’s visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA mod- els, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.", "tldr": "", "keywords": ["Token Pruning; Visual Attention Pattern; Vision-Language Action; Vision-Language Models"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8e092b623da884bbcf204a74ecc52b3f0e22a88f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Existing VLAs may overly attend to task-irrelevant vision tokens during inference, ultimately hurting policy performance. The authors propose distracting token pruning (DTP), a framework to dynamically detect and prune the distracting tokens. Experiments are conducted purely in simulation, in SIMPLER, and show minor improvements over baselines (SpatialVLA, Nora, UniVLA) without DTP."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The proposed DTP framework is techincally sound and the simulations appear well executed. The authors test DTP across three different VLAs, demonstrating their approach is model agnostic. \n\nA particular strength lies in the ablations (Tables 3 and 4). The improvement over the random pruning ablation is insightful, which shows DTP's efficacy. \n\nFinally, the paper is very clear. The problem is well motivated and the proposed solution is explained well. The attention visuals are clean and instructive."}, "weaknesses": {"value": "Exclusive reliance on simulation: there are no real-world robotic experiments. While simulators like SIMPLER may serve as a proxy for downstream deployment, the results obtained therein are not always indicative of the real-world, and any conclusions we draw from simulation must be tempered. The sim-to-real-gap is notorious challenging, and by confining all analysis to simulation, the paper's core claims lack contextualization on real hardware, which is ultimately where we want to see improvement benefits. \n\nMarginal performance gains on baselines: the simulation results, while consistently positive, do not result in large improvements. For example, averaging the results (as exemplified by Figure 1 and the Tables), the relative improvement with DTP is not very great. If these results were contrasted against real-world experiments, I think modest improvements are justified, but in simulation, the bar is higher (because the results don't always translate across the sim-to-real gap). This raises questions about the method's utility."}, "questions": {"value": "Comparison to prior work: while this work proposes mechanistic interpretability techniques applied to VLAs, the core idea of a run-time intervention scheme is not entirely new, and contextualizing this work with regard to prior work would be beneficial. For instance, [1] proposes a run-time intervention scheme to alter task-irrelevant regions in the VLA's observation based upon sensitivity. For offline work, [2] presents an architecture to filter visual features to focus on task-relevant information. It would be great to add [2] as a possible baseline for comparison. It makes more sense to discuss these types of works, instead of VLMs, in related work.\n\nThreshold parameter $\\tau$. Figure 4 shows that $\\tau$ is task and model dependent, in addition to be sensitive to value. This seems to challenge the generality of the proposed approach. How do you envision a roboticist using DTP in the real-world? Would they select this hyperparameter for every new task, or do you think a single value would suffice and be task-invariant?\n\nInference time overhead: the appendix (pg. 13, line 697) states that tricks were applied to SpatialVLA to mitigate inference speed issue. Could you elaborate on this point? It seems otherwise the inference speed may be non-negligible. \n\nGenerality of Important Region:  DTP applies corner suppression and Gaussian smoothing to construct the import regions. While an ablation is provided, this design choice seems to implicitly limit DTP to simple tasks. Do you think this part of the method would work if the key object were located in the corner of the observation, for example?\n\nNumber of evaluations: for the main results in Tables 1 and 2, can you please clarify the number of rollouts performed for each task. I couldn't find this information in the main part of the manuscript and is important for assessing the statistical significance of the reported improvements. \n\n[1] Hancock, A. J., Ren, A. Z., & Majumdar, A. (2025, May). Run-time observation interventions make vision-language-action models more visually robust. In 2025 IEEE International Conference on Robotics and Automation (ICRA) (pp. 9499-9506). IEEE.\n[2] Huang, H., Liu, F., Fu, L., Wu, T., Mukadam, M., Malik, J., ... & Abbeel, P. (2025). Otter: A vision-language-action model with text-aware visual feature extraction. arXiv preprint arXiv:2503.03734."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DqnAV8rMw1", "forum": "5yYQDuXzZh", "replyto": "5yYQDuXzZh", "signatures": ["ICLR.cc/2026/Conference/Submission19069/Reviewer_3oSv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19069/Reviewer_3oSv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19069/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760990436469, "cdate": 1760990436469, "tmdate": 1762931096087, "mdate": 1762931096087, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a mechanism to determine distracting tokens by comparing text to vision token attention with action to vision token attention patterns. The input image is split into important and unimportant regions based on average text to vision attention magnitudes. At the same time, a weighted average across layers of action to vision token attention magnitudes are constructed to determine attention patterns during action generation. Finally, a vision token is deemed distracting if it is unimportant and attends proportionally higher to actions than any other important vision token. Different vision-language-action (VLA) architectures are tested on the SIMPLER benchmark and consistent success rate improvements are shown."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-\tThe paper proposes a principled way to extract important task-relevant vision tokens and utilizes this to prune tokens. This adds a new tool to VLA inference that allows boosting success rates without the need for finetuning.\n-\tThe method is tested on a good diversity of VLAs with various VLM backbones such as Paligemma 2, Qwen2.5VL and UniVLA, demonstrating the generality of the approach.\n-\tAn analysis of attention patterns is presented, which is valuable from an interpretability perspective and gives insights into why VLA models fail at certain tasks.\n-\tOverall, the paper is well-written and clearly explains the method, supported by figures with insightful illustrations."}, "weaknesses": {"value": "-\tWhile the results on the SIMPLER benchmark are overall encouraging, relative success rate improvements on the Google robot tasks are minor, which makes the main result heavily rely on the WidowX robot tasks. Given the training-free nature of the approach, it would be important to test additional benchmarks with higher task diversities to confirm the efficacy of the method.\n-\tGiven the small number of tasks, the number of hyperparameters of the method seem high, including the threshold $\\tau$, the selected layers for constructing the relevance heatmap, the number of top relevant tokens and Gaussian smoothing settings."}, "questions": {"value": "-\tThe notation in section 3.3 is slightly confusing, the important region is called $G$ and $A_g$ simultaneously. The section would benefit from a clear definition of $A_g$ and $A_u$.\n-\tSection 4.2 adds mathematical definitions, but they do not seem to contribute to the content in a major way. Could you make use of the formulas to present, e.g. Figure 4, or otherwise remove them?\n-\tWhat process did you undergo for optimizing hyperparameters of the method? Are they selected to maximize success rates per VLA and per task?\n-\tOptimally, a token pruning mechanism should focus on improving efficiency. Was this considered in any way and why / why not?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "npds96lhZr", "forum": "5yYQDuXzZh", "replyto": "5yYQDuXzZh", "signatures": ["ICLR.cc/2026/Conference/Submission19069/Reviewer_zxVV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19069/Reviewer_zxVV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19069/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761818596516, "cdate": 1761818596516, "tmdate": 1762931095813, "mdate": 1762931095813, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Distracting Token Pruning (DTP) to improve VLA models for robotic manipulation. The core idea is to dynamically detect and prune image tokens that receive high attention but are irrelevant to the task, in three stages: (i) constructing task-relevant regions via prompt-image token interactions, (ii) analyzing attention patterns during action generation, and (iii) pruning tokens in unimportant regions if their attention exceeds a threshold. Experiments are performed on the SIMPLER Benchmark."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* **Simplicity and generality**: DTP is a simple, plug-and-play method that, assuming a standard VLA architecture, does not require architectural changes or additional inputs, making it broadly applicable to existing VLA models.\n* **Interpretability**: other than slightly improving performance, the approach helps visualize and understand model attention, potentially aiding debugging and further research on semantic information within the VLA framework."}, "weaknesses": {"value": "* **Modest improvements**: the overall increase in success rate across the Simpler environments is about ~4%. While the improvements seem to be consistent, the performance gap from optimality is still quite large and this approach does not seem to substantially advance the current state of VLAs.\n* **Slower training/inference**: as stated by the authors the method introduces a (small) overhead during training and inference. Given the small performance improvements, this hinders the adoptability of the approach"}, "questions": {"value": "* Can the authors add a comparison of the training and inference time?\n* Could the pruning be using to process visual information faster/more efficiently?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qfQblQC63m", "forum": "5yYQDuXzZh", "replyto": "5yYQDuXzZh", "signatures": ["ICLR.cc/2026/Conference/Submission19069/Reviewer_dc8u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19069/Reviewer_dc8u"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19069/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952161525, "cdate": 1761952161525, "tmdate": 1762931095119, "mdate": 1762931095119, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a visual token pruning approach for vision language action models. The paper posits that vision backbones of VLAs are prone to attending to “task-irrelevant” regions in the images which are termed as “distracting tokens”. They then propose a simple approach to identify these distracting tokens automatically by constructing an “important region” on the image which is relevant for the task; a visual attention pattern which relates what the model is looking at while generating the action and then thresholding tokens in the visual attention pattern that are not part of the “important region”. This leads to significant performance improvements across multiple models on the SimplerEnv environment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper presents a very interesting observation that visual backbones of VLAs tend to attend to unimportant regions in the images which lead to failure cases and then propose a super simple fix based on identifying important regions and thresholding the attention weights.\n2. The paper presents results on multiple models showing that the issue is prevalent and the fix is general enough to work across these models."}, "weaknesses": {"value": "***1. Results only on SimplerEnv.***\n\nI would have liked to see this study replicated on a larger set of environments and tasks. Note that most of the VLAs are not actually trained on SimplerEnv and are evaluated zero-shot. It would be interesting to see if this effect is observed in cases where the VLA is trained on the environment as well. Not saying doing evals on SimplerEnv is not valuable but it will be interesting to see the results on other benchmarks too!\n\nSimilarly it would be also very interesting to see if this also holds on real-world data.\n\n\n\n***2. How efficient is it?***\n\nThe paper does not present how it affects the inference speed of these models. Is it feasible to run in the real world? \nIt would be nice to see the speed / accuracy trade-off of this pruning approach.\n\n\n***3. Sensitivity of the tolerance tau?***\n\nIt seems from Figure 4 that the method is very sensitive to what tau is selected and it varies significantly between different tasks. \nHow was tau selected for the results in Section 4.1? Will the value of the tau generalize between simulation and real-world? How would a tau be selected in the real-world where policy evaluation is much more expensive and a sweep may not be feasible (specially for each task)?"}, "questions": {"value": "Please see the weaknesses section for my questions. \n\nIn general, I like the observation and a super simple idea that potentially fixes it. However I have some concerns over its applicability in the real-world and its sensitivity to tau. I am leaning towards a weak reject for now but will be happy to bump by score if the authors can answer the above questions and other reviewers do not bring up any major concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0Th6FnFCJD", "forum": "5yYQDuXzZh", "replyto": "5yYQDuXzZh", "signatures": ["ICLR.cc/2026/Conference/Submission19069/Reviewer_xJud"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19069/Reviewer_xJud"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19069/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984942092, "cdate": 1761984942092, "tmdate": 1762931094635, "mdate": 1762931094635, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}