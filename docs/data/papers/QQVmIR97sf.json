{"id": "QQVmIR97sf", "number": 20131, "cdate": 1758302828239, "mdate": 1759897000039, "content": {"title": "Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space", "abstract": "Semantic representations can be framed as a structured, dynamic knowledge space through which humans navigate to retrieve and manipulate meaning. To investigate how humans traverse this geometry, we introduce a framework that represents concept production as navigation through embedding space. Using different transformer text embedding models, we construct participant-specific semantic trajectories and extract geometric and dynamical metrics—including distance to next, distance to centroid, entropy, velocity, and acceleration. These measures capture both scalar and directional aspects of semantic navigation, providing a computationally grounded view of semantic representation search as movement in a geometric space. We evaluate the framework on four datasets across different languages, spanning different property generation tasks: Neurodegenerative, Swear verbal fluency,  Property listing task in Italian, and in German. Across these contexts, our approach distinguishes between clinical groups and concept types, offering a mathematical framework that requires minimal human intervention compared to typical labor-intensive linguistic pre-processing methods. Critically, different embedding models were essentially similar in describing these differences, highlighting similarities between different learned representations despite different training pipelines. By framing semantic navigation as a structured trajectory through embedding space, bridging cognitive modeling with learned representation, thereby establishing a pipeline for quantifying semantic representation dynamics with applications in clinical research, cross-linguistic analysis, and the assessment of artificial cognition.", "tldr": "We propose a natural language-based characterization of human semantic navigation in concept production as trajectories in embedding space through metrics to classify groups and concepts", "keywords": ["Semantic Navigation", "Natural Language Processing", "Human Cognition", "Text Embeddings"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/39091015edbbf37797890a9c1173613a6ead0605.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper models human concept production as trajectories in embedding space, extracting many geometric/dynamical markers from participant-specific paths built with cumulative text embeddings. The framework differentiates groups and concept types and appears robust across encoders for local trajectory metrics, while centroid-based dispersion shows model-dependent geometry. The authors discuss clinical and cross-lingual applications and note limitations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality. Recasts verbal fluency/property listing as geometry + dynamics in learned representation spaces, bridging cognitive foraging accounts with modern NLP embeddings. The cumulative-embedding design captures history dependence rather than treating items independently.\n\nQuality. Clear metric definitions (including a binarized entropy proxy) and mixed-effects modeling (GLMM via glmmTMB) are appropriate for repeated-measures data; cross-encoder replication is a strong robustness check.\n\nClarity. The paper’s pipeline is easy to follow; per-dataset result summaries and heatmaps for cross-model correlations aid interpretation.\n\nSignificance. Demonstrates clinically and linguistically informative signals with minimal manual annotation, and highlights encoder-agnostic local dynamics vs model-dependent global geometry, aligning with known cross-lingual structure and anisotropy issues in embeddings."}, "weaknesses": {"value": "1. The analyses only adopt Euclidean differencing despite acknowledged anisotropy in contextual embeddings; consider non-Euclidean or locally whitened metrics (e.g., hyperbolic/Riemannian, subspace-projected velocities) to test robustness will be helpful.\n2. Velocity/acceleration use implicit $\\Delta t=1$ because timestamps are missing. Include more results to show where real inter-response times modulate the dynamics will be helpful.\n3. Provide confidence intervals, seed/split variability, and multiple-comparison controls for pairwise tests in the figures; this will improve clinical interpretability.\n4. Writing/format nits. A few typos (“Neurodegerative”), minor grammatical errors like “This approach hold…”; ensure all acronyms expand on first use."}, "questions": {"value": "1. Do your main findings persist under whitened cosine, Riemannian distances, or other nonlinear metrics? A small ablation would help separate method from metric.\n2. If inter-response times become available, do velocity/acceleration still distinguish groups once scaled by real time?\n3. How do your metrics correlate with clustering/switching scores on the same sessions, and do they add incremental predictive value?\n4. Given stable local dynamics across encoders, can you leverage multilingual alignment (e.g., shared subspaces) to standardize centroid-based dispersion across languages/models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics concern."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AUtVa8gRiL", "forum": "QQVmIR97sf", "replyto": "QQVmIR97sf", "signatures": ["ICLR.cc/2026/Conference/Submission20131/Reviewer_GZZr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20131/Reviewer_GZZr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761813650471, "cdate": 1761813650471, "tmdate": 1762999995238, "mdate": 1762999995238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "*Concept production* refers to the task of a person listing as many words as they can within a given category in a short time period. This paper proposes a method to quantify the semantic dynamics of concept production by measuring dynamic properties of Language Model embeddings of the produced words.\n\nThey authors propose 5 summary statistics of the embedding trajectories: distance-to-next, entropy, velocity, acceleration and distance-to-centroid. They employ four datasets of to evaluate:\n - a neurodegenerative dataset containing participants with Parkinson's disease, frontotemporal dementia and healthy controls,\n- a swear fluency dataset, with three categories control categories and I swear word category,\n - Italian and German datasets, where particants were asked to produce words from a variety to categories in either Italian or German\n\nQualitative results in the form of plots, and quantitative statistical test are performed to assess the variability between categories of the embedding dynamics within datasets.\n\nThe authors perform their experiment using three different embedding models and find similar results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is clearly written and the methodology is novel, providing a means to quantify properties of the semantic dynamics of words produced during these experiment using Language model embeddings as a proxy.\n\nThe paper considers a variety of tasks, datasets and models and the results are clearly explained."}, "weaknesses": {"value": "While this work clearly shows how the metrics they propose vary across groups in their datasets,  it's not clear to me what this actually tells us about human semantic navigation.\n\nI think there is some value in the proposed metrics, but the experiments only provide a weak indication that they are useful for the classification tasks described."}, "questions": {"value": "- Does the findings here align with other research on human semantic cognition?\n- What other methods exist to measure the semantic dynamics of words produced in these experiments? For example. what metrics are used in the papers originally proposing the datasets? You mention that your finding corroborate theirs, but how?\n- What are the advantages of this method over other methods?\n- In the definition of entropy, the time series $\\{x_t\\}_{t=1}^n$ is a vector time series, so what is the median of a set of vectors?\n- Similarly, the velocity and acceleration are vectors. Do you report their magnitude as the metric, or something else?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "klmDI1pYKz", "forum": "QQVmIR97sf", "replyto": "QQVmIR97sf", "signatures": ["ICLR.cc/2026/Conference/Submission20131/Reviewer_Xfqo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20131/Reviewer_Xfqo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837317056, "cdate": 1761837317056, "tmdate": 1762999995919, "mdate": 1762999995919, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework to quantify human semantic navigation during concept production using trajectory-based metrics in transformer embedding spaces. It represents sequential concept generation (e.g., verbal fluency or property listing tasks) as a path through semantic space and computes geometric and dynamical metrics—distance to next, entropy, velocity, acceleration, and distance to centroid—to characterize this navigation. The method is applied to four datasets (neurodegenerative, swear-word fluency, and Italian/German property listing), showing that these metrics distinguish clinical groups, semantic categories, and languages. Results are robust across embedding models (OpenAI, Google, Qwen). The authors argue this approach bridges cognitive modeling and learned representations, offering potential applications in clinical and cross-linguistic research.\n\nOverall, the approach is interesting. However, its mathematical grounding is limited, and comparisons to prior methods are absent. It is unclear whether this paper is primarily a methodological contribution, or an empirical contribution. While it seems to be a mixture of both, neither is particularly compelling. This work may be more suitable as an expanded manuscript for a cognitive science journal venue, where the results can be more effectively situated within the broader relevant literature, and targeted towards a more appropriate community."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Potentially novel conceptual framing: the paper presents a method for modeling semantic search as trajectories in embedding space, bridging computational linguistics and cognitive science. \n2. Methodological simplicity and reproducibility: the framework requires minimal manual annotation and is implemented with publicly available datasets and embeddings, making it scalable and easy to replicate.\n3. Comprehensive empirical validation: the authors test across multiple datasets (languages, clinical populations, and semantic domains), providing strong evidence of the method’s generality.\n4. Cross-model robustness analysis: the inclusion of multiple embedding models (OpenAI, Google, Qwen) and the correlation analysis (Figure 6) convincingly demonstrate stability of local trajectory measures across model architectures.\n5. Interdisciplinary contribution: the work effectively connects semantic cognition, NLP, and neuropsychology, potentially valuable for both cognitive modeling and clinical diagnostics."}, "weaknesses": {"value": "1. Limited theoretical grounding for metrics: while the chosen metrics (velocity, acceleration, entropy) are intuitive, their psychological interpretation is underspecified. The link between these geometric quantities and cognitive mechanisms of search (e.g., clustering/switching, semantic control) could be better formalized.\n2. Simplistic dynamics assumption: the framework assumes Euclidean dynamics, even though embeddings are anisotropic and often non-Euclidean. The authors acknowledge this multiple times, but do not explore or justify why Euclidean treatment suffices.\n3. Use of non-causal embeddings. It is a reasonable first step to use cumulative text embeddings, rather than independent word embeddings. However, by using non-causal encoder models for embeddings, for a sequence \"A B C\", the representation of token B has access to token \"C\", whereas in the earlier part of the sequence it does not. Rather than acquiring embeddings, the authors should use a causally-masked model, such that the token representation for \"B\" is the same across both \"A B C\" and \"A B\". This would likely make the trajectories smoother and more amenable to the kinematic metrics employed. \n4. Figures are dense: Figures 2–5 (and corresponding appendices) show many small boxplots and correlation matrices. It may be helpful to use comparison lines above the scatter plots rather than the correlation matrices, if the goal is merely to show which effects are significant. This is a more standard approach and would take less space, improving readability. \n5. No comparison to traditional linguistic baselines: the framework is presented as superior to “labor-intensive linguistic pre-processing,” yet there’s no quantitative comparison to classical measures (e.g., clustering, switching, word frequency, semantic similarity). A comparison with these approaches would strengthen the claim of added value.\n6. Missing temporal information: since no timestamp data are used, “velocity” and “acceleration” are only metaphorical. The interpretation of these measures as cognitive dynamics rather than geometric derivatives is thus limited.\n7. The work only characterizes semantic trajectories, it does not model them through some sampling from the latent space of a transformer. This makes the theoretical contribution weaker."}, "questions": {"value": "1. How does this work improve upon prior baselines? \n2. Why are all of the metrics needed? What are the main distinctions between them? \n3. Do you agree with weakness 3? Can you perform another analysis with a causally masked transformer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UCLLIqbclE", "forum": "QQVmIR97sf", "replyto": "QQVmIR97sf", "signatures": ["ICLR.cc/2026/Conference/Submission20131/Reviewer_6H8S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20131/Reviewer_6H8S"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837581888, "cdate": 1761837581888, "tmdate": 1762933036780, "mdate": 1762933036780, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework for characterizing human semantic navigation by representing concept production tasks (semantic fluency and property listing) as trajectories through transformer-based embedding spaces. The authors extract geometric and dynamical metrics including distance-to-next, velocity, acceleration, entropy, and distance-to-centroid from cumulative word sequences. They evaluate their approach on four datasets spanning clinical populations (Parkinson's, frontotemporal dementia), different languages (Italian, German), and semantic categories, showing that these trajectory-based metrics can distinguish between clinical groups and concept types across different transformer models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novel computational framework: The trajectory-based approach to semantic navigation is creative, moving beyond static embedding analyses to capture dynamic aspects of semantic search. The use of cumulative embeddings (where x_t encodes items 1:t) is particularly interesting as it captures sequential dependencies.\n- Robust empirical validation: The evaluation across four diverse datasets (clinical, multilingual, different task types) demonstrates broad applicability. The consistency of findings across three different embedding models (OpenAI, Google, Qwen) strengthens the results.\n- Clinical relevance: Successfully differentiating neurodegenerative groups from healthy controls using distance-to-next and other metrics provides potential clinical utility. The finding that patient groups show greater variability and entropy aligns with executive dysfunction literature.\n- Minimal preprocessing: The approach requires less manual intervention compared to traditional linguistic preprocessing methods, making it more scalable and reproducible."}, "weaknesses": {"value": "- Missing baselines and comparisons: The paper lacks comparison to previous computational methods for analyzing semantic fluency data. No baselines using simpler embeddings (e.g., Word2Vec, GloVe) or traditional NLP metrics are provided. Prior work like Linz et al. (2017) used word embeddings for similar tasks but isn't compared against.\n- Limited theoretical grounding: While the authors claim semantic retrieval can be \"understood as navigation through a multidimensional space\" (Hills et al., 2015), this theoretical framework needs stronger support. The connection between observed metrics and established cognitive theories (e.g., clustering-switching models by Troyer et al., 1997) is underdeveloped.\n- Interpretation of results lacks depth: The clinical findings (e.g., \"greater spread, higher variability, increased entropy\" in patient groups) are presented without sufficient discussion of whether these align with expected patterns from cognitive neuroscience literature. Are these results validating known theories or revealing new phenomena?\n- Euclidean assumption: The authors acknowledge but don't address their \"assumption of Euclidean dynamics\" which \"overlooks the anisotropic nature of embedding spaces\" (citing Nickel & Kiela, 2017; Ethayarajh, 2019). This could significantly impact the validity of velocity and acceleration metrics."}, "questions": {"value": "- Centroid computation: The distance-to-centroid shows lowest inter-model correlation. Could you elaborate on why this metric is particularly sensitive to model-specific geometry? How does collapsing repeated properties affect this measure?\n- Category effects: The category-specific patterns differ between Italian and German datasets. Do these differences reflect linguistic/cultural variations or task administration differences? This needs deeper analysis."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dIDgP0M49V", "forum": "QQVmIR97sf", "replyto": "QQVmIR97sf", "signatures": ["ICLR.cc/2026/Conference/Submission20131/Reviewer_xS4F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20131/Reviewer_xS4F"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20131/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879222404, "cdate": 1761879222404, "tmdate": 1762933034894, "mdate": 1762933034894, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}