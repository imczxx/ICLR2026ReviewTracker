{"id": "URjuuHqcQw", "number": 23568, "cdate": 1758345625516, "mdate": 1759896807247, "content": {"title": "Sparse but Sharp: Saliency-guided Black-box Attacks  Reveal Vulnerabilities in Skeleton-based Human  Action Recognition", "abstract": "The remarkable performance of Graph Convolutional Networks and Transformers in skeleton-based human action recognition is a progress to celebrate.  However, recent studies reveal their vulnerability to adversarial attacks.We focus on black-box attacks, which hold greater practical relevance, and propose the first saliency-guided spatio-temporal sparse black-box attack framework for skeleton-based recognition.By estimating the contribution of joints and frame segments to recognition accuracy, our solution is able to inject perturbations only into a localised set, thereby enhancing stealth.Compatible with both confidence-based and label-only black-box settings, our framework offers broad applicability in real-world scenarios.We conduct a comprehensive evaluation of the proposed attack methodology on public large-scale datasets and compare its performance with SOTA algorithms. It is demonstrated that our attack strategy achieves competitive or even superior effectiveness in most settings, while offering better imperceptibility and a favourable balance between query efficiency and attack performance. Importantly, our evaluation reveals significant disparities in robustness across existing action recognition models. \nOur solution presents a practical paradigm for efficient sparse attack strategies, providing novel insights into the structural robustness of skeleton-based recognition methods.", "tldr": "We propose a saliency-guided spatio-temporal sparse black-box attack framework that efficiently fools skeleton-based action recognition models under low perturbation, revealing model robustness differences under sparse conditions.", "keywords": ["Skeleton-based Action Recognition", "Black-box Adversarial Attack", "Spatiotemporal Sparsity", "Saliency-guided Perturbation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d8d1f3e76a494e9a51b6c877ba2c15b78ad5c109.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a saliency-guided spatio-temporal sparse black-box attack framework targeting skeleton-based human action recognition models. By selectively perturbing critical frames and joints identified through temporal and spatial saliency analysis, the method achieves high attack success rates with minimal perturbations, enhancing stealth and efficiency. Extensive experiments on NTU datasets demonstrate the framework's effectiveness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "(1) This paper proposes a saliency-guided joint selection method that accurately detects the most impactful spatio-temporal regions without relying on gradient-based information. \n(2) This paper provides a comprehensive analysis of the adversarial vulnerabilities of GCN-based and Transformer-based models, highlighting their distinct sensitivities to spatio-temporal perturbations."}, "weaknesses": {"value": "(1) While the proposed spatio-temporal sparse attack framework (Temporal Sparsity and Spatial Sparsity) incorporates saliency analysis, the concept of sparsity itself is not new. Sparse attacks have been widely studied, especially in the image domain. The paper does not clearly articulate how its method is technically superior or innovative compared to existing approaches.\n(2) Although the paper mentions prior methods like BASAR and TASAR, it does not thoroughly discuss the differences between these methods and the proposed approach. For instance, BASAR is referenced, but its implementation could not be reproduced, leading to a lack of direct comparison, which weakens the credibility of the experimental evaluation.\n(3) The paper lacks diversity in both datasets and model selection, as the experiments are conducted only on NTU 60 and NTU 120, which, while widely used, offer limited scene and action diversity. Additionally, the experiments focus on three models (ST-GCN, CTR-GCN, and SkateFormer), with ST-GCN receiving the most attention, while newer skeleton-based action recognition models, such as those based on hybrid architectures or self-supervised learning, are not included, restricting the generalizability and applicability of the proposed framework to more complex datasets and recent advancements in the field."}, "questions": {"value": "(1) The saliency analysis relies on masking frames and joints to evaluate their importance. However, in the confidence-based black-box setting, model outputs may not be sensitive to minor perturbations, which could lead to inaccurate saliency assessments. How does the framework handle cases where the saliency analysis is unreliable?\n(2) The paper mentions that increasing sparsity reduces the attack success rate, but it does not quantify the relationship between sparsity (e.g., the proportion of selected frames and joints) and performance. How does the framework determine the optimal balance between sparsity and attack success? Additionally, does the sparsity strategy need to be adjusted for different models?\n(3) Are the adversarial examples generated by the sparse attack transferable across models? For instance, can an example crafted for ST-GCN successfully attack CTR-GCN or SkateFormer? The paper does not evaluate the cross-model transferability of its adversarial examples."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eG02ydr2ZM", "forum": "URjuuHqcQw", "replyto": "URjuuHqcQw", "signatures": ["ICLR.cc/2026/Conference/Submission23568/Reviewer_g7yA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23568/Reviewer_g7yA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761702731459, "cdate": 1761702731459, "tmdate": 1762942715754, "mdate": 1762942715754, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a spatiotemporally sparse black-box attack method for human action recognition. By selecting the most salient temporal segments and joint positions in both time and space, the method perturbs the input sequence minimally while still achieving effective attacks. Experimental results show that under a limited perturbation budget, the proposed approach achieves a high attack success rate."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The spatiotemporal sparsity focuses effectively on key temporal frames and joint positions.\n2. The attack is validated on both GCN-based and Transformer-based recognition models.\n3. The experiments take realistic perturbation budgets into account, and the results are quite promising."}, "weaknesses": {"value": "1. The construction of spatiotemporal sparsity relies on the confidence scores provided by the target model.\n2. In settings where only labels are available, the method depends on predefined masks and attenuation factors, which may limit the diversity of generated adversarial samples.\n3. For models that rely on global information, such as SkateFormer, the attack performance drops significantly."}, "questions": {"value": "1. Perturbation budget: What do the budget values (3000 and 15000 for NTU60 and NTU120) represent, and how are they determined?\n2. Effect of QC: Under the same budget, is the higher performance compared with the baseline partly due to the sparsity in frames and joints, which may save budget and allow for more query counts (QC)?\n3. Comparison with other methods: The authors mention that their baseline represents only a lower bound. Are there comparisons with other SOTA methods in terms of performance and budget?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l29CF8MUZT", "forum": "URjuuHqcQw", "replyto": "URjuuHqcQw", "signatures": ["ICLR.cc/2026/Conference/Submission23568/Reviewer_cAET"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23568/Reviewer_cAET"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907016657, "cdate": 1761907016657, "tmdate": 1762942715380, "mdate": 1762942715380, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a saliency-guided spatio-temporal sparse black-box adversarial attack framework tailored for skeleton-based human action recognition systems. The method identifies critical joints and temporal segments through heuristic saliency estimation—without access to model gradients—and injects perturbations only into these localized regions. The approach is evaluated under both confidence-based and label-only black-box settings across multiple state-of-the-art models (e.g., ST-GCN, CTR-GCN, SkateFormer) on the NTU60 and NTU120 datasets. Results show that the proposed attack achieves high attack success rates with significantly reduced perturbation budgets, demonstrating superior stealth and query efficiency compared to dense baselines. The work also provides insights into the differing robustness of GCN- versus Transformer-based architectures under sparse perturbations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Comprehensive Evaluation: The paper includes thorough experiments across multiple models, datasets, and attack settings (untargeted/targeted, confidence-based/label-only), offering valuable empirical insights.\n\n2. Imperceptibility Emphasis: The use of spatial-temporal sparsity and the SIO (Swarm Intelligence Optimization) module enhances the naturalness and stealth of adversarial examples."}, "weaknesses": {"value": "1. Limited Practicality of Perturbation Model:\nThe paper assumes that an attacker can directly add noise to 3D joint coordinates, which may not reflect real-world deployment. In practice, skeleton sequences are typically estimated from RGB or depth sensors (e.g., via pose estimators like OpenPose or MediaPipe). A more realistic threat model would involve physical perturbations—such as wearable patches or clothing—that indirectly alter joint positions. Without addressing how such perturbations translate into skeletal noise (e.g., through a pose estimation pipeline), the attack’s applicability remains largely theoretical.\n2. Lack of Technical Novelty:\nWhile the application to skeleton-based action recognition is timely, the core idea—sparse, saliency-guided adversarial perturbations in spatio-temporal domains—has been explored in prior video attack literature. For instance, Wei et al. (AAAI 2019), “Sparse Adversarial Perturbations for Videos” already introduced content-aware sparse attacks on video classifiers. The current work adapts similar principles (temporal segmentation, spatial region selection, mask-based importance scoring) to skeletons but does not sufficiently differentiate its methodological contribution or analyze why skeletons demand a fundamentally new approach.\n3. Diminishing Returns of Pure Attack Research:\nAdversarial vulnerability in deep models is now a well-established phenomenon. Given the maturity of the field, the community increasingly prioritizes robustness-enhancing defenses, certified robustness, or attack-aware training. This paper, while technically sound, contributes another attack without proposing mitigation strategies or actionable guidance for defenders. A more impactful direction would be to leverage the identified vulnerabilities to design robust architectures (e.g., saliency-regularized training or sparsity-aware data augmentation)."}, "questions": {"value": "see the weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7YKpuI5iAc", "forum": "URjuuHqcQw", "replyto": "URjuuHqcQw", "signatures": ["ICLR.cc/2026/Conference/Submission23568/Reviewer_c3Vh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23568/Reviewer_c3Vh"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23568/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762052329084, "cdate": 1762052329084, "tmdate": 1762942714570, "mdate": 1762942714570, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}