{"id": "kdu3zj4GuM", "number": 18577, "cdate": 1758289227732, "mdate": 1762973696494, "content": {"title": "Mitigating Context Bias via Foreground-Background Separation and Pooling: A Causal Analysis and Robust Evaluation", "abstract": "Context bias refers to the association between the foreground objects and background during the object detection training process. Various methods have been proposed to minimize the context bias when applying the trained model to an unseen domain, known as domain adaptation for object detection (DAOD). But a principled approach to understand why the context bias occurs and how to remove it has been missing. \nIn this work, we provide a causal view of the context bias in the network architecture as the possible source of this bias. We present an analytical framework that utilizes an explicit foreground mask during feature aggregation with the proposed pooling operation to separate foreground and background, which leads the trained model to detect objects in a more robust manner under different domains. We use the ground truth masks and also masks generated using Segment Anything Model (SAM) to showcase the performance of the different state-of-the-art network model architectures such as ALDI++, ResNet, EfficientNet and Vision Transformer.  We also provide a benchmark designed to create an ultimate test for DAOD, using foregrounds in the presence of absolute random backgrounds, to statistically analyze the robustness of the intended trained models using 95\\% confidence. Through these experiments, our goal is to provide a principled approach for minimizing context bias under domain shift for object detection.", "tldr": "", "keywords": ["pooling", "context bias", "object detection"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/dc40f55dd05b3cff0f7ea253fc9ae118339499ba.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the issue of context bias in domain adaptation for object detection (DAOD), where models inadvertently learn spurious associations between foreground objects and their backgrounds during training. The authors propose a causal perspective to understand and mitigate this bias and introduce an analytical framework based on explicit foreground-background separation using a Mask Pooling operation, which leverages either ground truth or SAM-generated masks to isolate object features during feature aggregation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The approach is evaluated across multiple models—including ALDI++, ResNet, EfficientNet, and Vision Transformer—demonstrating improved robustness in cross-domain settings.\n2. The inclusion of SAM-generated masks makes the method more scalable and practical, reducing reliance on costly manual annotations."}, "weaknesses": {"value": "1. The excessive use of acronyms and abbreviations in the paper makes it very difficult to read. The authors are advised to reorganize and clarify the presentation of this section. In particular, the figures are challenging to interpret.\n2. The paper lacks sufficient novelty. The core contribution centers on Equation (2), but the idea of suppressing background and focusing on foreground has already been explored in numerous prior works, and this is not the only possible approach. For instance, could we instead train the model on both the original training set and an augmented version with added background, to prevent the model from over-relying on background cues?"}, "questions": {"value": "Please refer to weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eg4UtkuRbC", "forum": "kdu3zj4GuM", "replyto": "kdu3zj4GuM", "signatures": ["ICLR.cc/2026/Conference/Submission18577/Reviewer_tfiX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18577/Reviewer_tfiX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875652894, "cdate": 1761875652894, "tmdate": 1762928292678, "mdate": 1762928292678, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We want to thank the reviewers for their comments. We will take it into consideration and come up with a better version."}}, "id": "0108cHDPWH", "forum": "kdu3zj4GuM", "replyto": "kdu3zj4GuM", "signatures": ["ICLR.cc/2026/Conference/Submission18577/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18577/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762973695685, "cdate": 1762973695685, "tmdate": 1762973695685, "mdate": 1762973695685, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the issue in Domain Adaptation for Object Detection (DAOD) where typical detectors use both foreground (FG) and background (BG) features jointly, which harms domain adaptation performance and robustness. To mitigate this, the authors propose a Mask Pooling method that separates FG and BG using masks obtained from either ground truth or SAM. The model then performs feature aggregation on the separated regions. The authors conduct experiments using images synthesized by combining separated FG with random BG, as well as experiments using FG-only images, across multiple datasets and detector architectures, and report performance comparisons."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The method is simple and easy to implement, and clearly aims to reduce the blending of FG and BG features, presenting a clear hypothesis and design rationale.\n\nThe authors conduct diverse experiments across various datasets and detector models."}, "weaknesses": {"value": "(Major) The performance difference between experiments with no background and those with original background is minimal, which weakens the paper’s central claim that FG–BG feature mixing negatively impacts performance. Moreover, the paper does not provide a direct comparison table between inference with original background and without it. When indirectly comparing Figure 2 and Appendix Table 5, there appears to be no meaningful performance gap—making most of the paper’s main claims unsubstantiated.\n\nThe proposed approach replaces the pooling layer, but it is unclear whether this alone effectively mitigates the early FG–BG mixing the paper highlights. Theoretical and experimental justifications for this claim are insufficient.\n\nAlthough the authors mention it as a limitation, obtaining ground-truth masks in real-world scenarios is impractical, which significantly reduces the applicability of the proposed method.\n\nSince the masking strategy is based on existing ground-truth or SAM-derived masks, the method offers limited novelty."}, "questions": {"value": "See Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6KI5yMaroq", "forum": "kdu3zj4GuM", "replyto": "kdu3zj4GuM", "signatures": ["ICLR.cc/2026/Conference/Submission18577/Reviewer_Yt2i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18577/Reviewer_Yt2i"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936268221, "cdate": 1761936268221, "tmdate": 1762928292160, "mdate": 1762928292160, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates a phenomenon termed context bias in object detection methods using causal methods. It proposes a boundary-aware pooling operation with the goal of reducing context bias. It furthermore proposes a DAOD benchmark based on copy-pasted instances on random backgrounds."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper compares a reasonable set of backbones, detectors, and state-of-the-art DAOD methods. The set of datasets used for benchmarking is reasonable and in line with prior work."}, "weaknesses": {"value": "I find the paper very difficult to follow. For example, section 2 starts with a discussion of causal models of object detection, and arrives at a definition of interventional risk (equation 1), without providing an intuitive explanation or defining variables (for example, how are x and y defined?).\n\nThe boundary-aware pooling operation is not particularly novel (see, for example, [1, 2] for similar approaches). That said, if there was a clear and interesting interpretation of this type of pooling from a causal perspective, I think that would be sufficiently novel. Unfortunately, the connection between the causal perspective and the pooling operation is just not sufficiently clearly described.\n\nSome claims seem unfounded (and in fact unachievable), for example: \"We also provide a benchmark designed to create an ultimate test for DAOD\". It is unclear to me based on the paper what makes the proposed benchmark \"ultimate\", and I would argue there is no single benchmark for any task that captures all possible relevant aspects.\n\nSome statements seem contradictory, for example: “recent research shows that context bias between FG and background (BG) leads to substantial deterioration of DAOD performance (Son & Kusari, 2024).” vs.\n“However, it remains uncertain whether undesirably learned FG-BG association can impact DAOD.”\n\nThe paper seems to confuse “models”, “backbones”, and “detectors”, for example in section 3.2 and table 1: ResNets and Efficientnets are backbones, ALDI++ is a detector- / backbone-agnostic domain-adaptation method, and ViTDet is a detector, yet they are all mentioned as “models”. I think the paper would greatly benefit from being more clear about which backbones, detectors, \tand domain adaptation methods were used in which configuration, and where exactly the mask pooling layer fits in.\n\nOverall, I think this paper needs a substantial rework in order to be more approachable and more precise in its language.\n\n[1] https://openaccess.thecvf.com/content_ICCV_2017/papers/Harley_Segmentation-Aware_Convolutional_Networks_ICCV_2017_paper.pdf\n[2] https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Weiyue_Wang_Depth-aware_CNN_for_ECCV_2018_paper.pdf"}, "questions": {"value": "How does boundary-aware pooling mitigate context bias? Wouldn’t backbones still learn to exploit useful signals between foreground and background, with or without boundary-aware pooling?\n\nThe caption of Figure 2 says that the figure contains error bars, but I can not seem to find them. Also, what do you mean by \"Standard deviation is displayed as error bars but it is trivial\"?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9TLDwLoOhH", "forum": "kdu3zj4GuM", "replyto": "kdu3zj4GuM", "signatures": ["ICLR.cc/2026/Conference/Submission18577/Reviewer_jTBd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18577/Reviewer_jTBd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969127605, "cdate": 1761969127605, "tmdate": 1762928291730, "mdate": 1762928291730, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles context bias in Domain Adaptive Object Detection (DAOD), where models learn spurious correlations between foreground objects and their backgrounds. The authors frame this problem using causal analysis and propose Mask Pooling, a method that explicitly separates foreground and background features during aggregation using masks (either ground truth or SAM-generated). The core contribution is twofold: 1) the Mask Pooling method itself as a causal intervention, and 2) a new evaluation benchmark designed to test model robustness by placing foregrounds onto completely random backgrounds, thereby rigorously measuring the model's reliance on contextual cues."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) The method introduced in the paper is very intuitive and easy to understand.\n\n2) The proposed method achieves strong performance."}, "weaknesses": {"value": "1) The proposed method is overly simple, more like a trick. The core contribution of the paper is in Section 3.1, which is just a pooling operation to separate the foreground and background. This type of processing is quite common in object detection tasks and lacks novelty.\n\n2) The methodology section (Section 3) reads more like a technical report. It describes the method's workflow (or perhaps the experimental workflow) in a very fragmented manner. This makes the paper's quality insufficient to meet the standards for an ICLR paper.\n\n3) Why was it necessary to create a new benchmark?\n\n4) The model's performance improvement also relies on additional computation (e.g., from SAM). The trade-off between computational cost and performance requires further analysis."}, "questions": {"value": "1) A common and more practical method to break FG-BG spurious correlations is using \"Copy-Paste\" data augmentation, which is similar to the process the authors used to build the random background benchmark. If this Copy-Paste augmentation were used during training, how would its effectiveness compare to Mask Pooling? This seems like a simpler and less computationally expensive alternative.\n\n2) Why was it necessary to create a new benchmark?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "T6rcE8RAX1", "forum": "kdu3zj4GuM", "replyto": "kdu3zj4GuM", "signatures": ["ICLR.cc/2026/Conference/Submission18577/Reviewer_GsW7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18577/Reviewer_GsW7"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18577/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762696552930, "cdate": 1762696552930, "tmdate": 1762928291327, "mdate": 1762928291327, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}