{"id": "BNHplerBYE", "number": 13735, "cdate": 1758221753751, "mdate": 1759897416772, "content": {"title": "Score-based Greedy Search for Structure Identification of Partially Observed Linear Causal Models", "abstract": "Identifying the structure of a partially observed causal system is essential to various scientific fields. Recent advances have focused on constraint-based causal discovery to solve this problem, and yet in practice these methods often face challenges related to multiple testing and error propagation. These issues could be mitigated by a score-based method and thus it has raised great attention whether there exists a score-based greedy search method that can handle the partially observed scenario. In this work, we propose the first score-based greedy search method for the identification of structure involving latent variables with identifiability guarantees. Specifically, we propose Generalized N Factor Model and establish the global consistency: the true structure including latent variables can be identified up to the Markov equivalence class by using score. We then design Latent variable Greedy Equivalence Search (LGES), a greedy search algorithm for this class of model with well-defined operators, which search very efficiently over the graph space to find the optimal structure. Our experiments on both synthetic and real-life data validate the effectiveness of our method.", "tldr": "", "keywords": ["Causal Discovery", "Latent Variable"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6d019f89dabb60558b26ecc8958f52dab73bd61d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes LGES (Latent variable Greedy Equivalence Search), a score-based greedy algorithm to learn the causal structure of partially observed linear SEMs with latent variables. The authors prove global consistency under some assumptions. They design an efficient two-phase search with tailored operators and show empirical results versus constraint-based baselines on synthetic and real data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Overall, the paper tackles an important gap: scalable score-based discovery for latent-variable models with identifiability guarantees. A greedy score-based method with identifiability guarantees in the presence of latent variables is nontrivial. Linking equality constraints, minimal dimension, and GNFM to MEC identifiability. Strong synthetic performance vs. constraint-based baselines."}, "weaknesses": {"value": "I am not sure if the conditions, such as GNFM structure, generalized faithfulness, and linear/noise are satisfied.\nAbout experiments, I see that on Big Five and Burnout, LGES fits worse than hand-designed CFA structures (Table 3) you should discuss why and provide intuition. Also, since Ng et al. (2024) is cited as an exact search score-based approach for latent models, a direct comparison would be informative to position LGES.\nPlease clarify the notation and correct the expression in equation 3.\nTypos/edits:\n“propogation” → “propagation”;\n“eal-life” → “real-life”;\n\neal-life\n\nδ definition has conflicts in Section 5.2, Appendix C.4"}, "questions": {"value": "In which real domains do you expect the 2|Lp| pure-children and group-wise uniform adjacency assumptions to hold?\nWhat happens when there are fewer than 2|Lp| pure children, or when pure children do not exist for some groups? Do you degrade gracefully (e.g., to equivalence classes over merged latents)? You argue the identifiability story extends because equality constraints over covariance remain. But then the method does not exploit higher-order moments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eyH6dEaLXH", "forum": "BNHplerBYE", "replyto": "BNHplerBYE", "signatures": ["ICLR.cc/2026/Conference/Submission13735/Reviewer_yLgV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13735/Reviewer_yLgV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13735/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761663995168, "cdate": 1761663995168, "tmdate": 1762924273349, "mdate": 1762924273349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a score-based causal discovery for latent variable models, more precisely \"Generalized n factor models\", that is inspired by GES. It builds upon a MLE score that is proven to be consistent. Moreover, the presented algorithm LGES also provably recovers (up to permutation) the equivalence class of the true graph."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper studies an important topic: causal discovery without assuming causal sufficiency of the observed variables. The proposed approach for generalized n factor models is novel and the techniques non-trivial. The theorems for asymptotic consistency are sound and additionally the algorithm is evaluated on synthetic data. Generally, the writing in the paper is clear (apart from a significant number of small typos and grammatical errors)."}, "weaknesses": {"value": "Relation to other recent work:\nWhile the paper gives a broad overview of causal discovery (in the presence of latent variables), the papers (Ng et al, 2024) and (Dong et al, 2024) appear to be closely related. In particular for the results in Section 3.1, it is not clear to me how novel the contributions in the paper are (Theorem 1 is stated as \"inspired by Ng et al (2024)\"). The paper would benefit from distinguishing itself more clearly here.\n\nGES as a score-based algorithm in contrast to constraint-based methods:\nIn the paper it is argued that score-based methods compare favorably to constraint-based methods in particular because the latter are prone to error propagation. I agree with the sentiment, but to me it seems that the proposed algorithm suffers from exactly the same problem. If I understand correctly, the algorithm starts with a graph that (at least in some parts) is complete (similar to constraint-based methods), and then deletes edges which lead to no worsening of the MLE score. An incorrectly deleted edge can never be added back into the graph (thus errors propagate) and also there is an intuitive connection to the independence tests that the algorithm aims to avoid (the edge can be deleted asymptotically because some conditional independence is found to hold and delta could be interpreted as some cutoff value). Another thing is that \"Greedy\" is maybe an unfortunate name, because it usually suggests that each step is done to be locally optimal wrt the score but it doesn't appear to be the case here.\n\nAssumption of the generalized n factor model:\nGenerally, it is of course clear that restrictive assumptions are needed to recover latent variables. Thus, I find it fair to confine the analysis to a model such as the generalized n factor model even though it may reduce applicability. The paper could do a better job though of explaining why the constraints in Def. 2 are needed. With the proofs deferred to the appendix I find this rather opaque.\n\nCode availability:\nThe code doesn't appear to be part of the submission, which I find unfortunate. \n\nGrammatical errors and typos:\nWhile I found the paper generally easy-to-read and thus do not weigh this issue much, the paper contains a significant grammatical errors, small inconsistencies and typos, which could have been avoided by careful proofreading (a list of suggestions for improvement is under questions)."}, "questions": {"value": "1. Can you clarify the relation to recent work by Ng et al. (2024) and Dong et al. (2024)? In particular, the novel aspects of Section 3.1.\n\n2. Can you comment how the approaches distinguishes itself from constraint-based methods that start with a complete graph and subsequently delete edges? How does the proposed method avoid issues with error propagation?\n\nSuggestions:\n- line 020: \"propose *the* generalized...\"\n- line 020: \"establish *its* global consistency\"\n- line 022: \"by using score\" ?\n- line 024: \"class of *models*\" and \"which *searches*\"\n- line 033: \"are being made *towards*...\"\n- line 041: \"on *the* discovery of *the* entire structure\n- line 042: \"on rank or tetrad constraints linearity assumption\" ?\n- line 048: \"statistical *tests*\"\n- line 053: \"most classical\"\n- line 060: \"As a consequence, considerable attention has been given...\" please provide references to substantiate this statement\n- line 063: \"What is the core of structure identifiability by using likelihood scores?\" I don't understand what this means\n- line 068: \"We characterize how *a* likelihood...\"\n- line 071: \"We propose *the*...\" and below \"*the* score\"\n- line 072: \"MEC\" this abbreviation has not been introduced thus far\n- line 074: \"develop *the* Latent...\"\n- line 076: \"identifiability *guarantees*\"\n- line 096: \"v-structures\" this term is not introduced\n- line 107: \"formulation of *the* likelihood\"\n- line 139: \"*algebraically* equivalent\"\n- line 159: \"*the* number of edges and *the* number *of* measured variables\n- line 180: \"by making use of score\" ?\n- line 200: \"how *the* likelihood score\"\n- line 218: \"we propose *the* generalized\"\n- line 266: establishes\n- line 281: \"we follow the traditional wisdom GES Chickering (2002)\"\n- line 317: \"In Definition 3, it implicitly requires\"\n- line 338: remove superfluous \".\"\n- line 403 and 407: Def. 1 and Def.2 (also please be consistent with abbreviations)\n- line 481 to the end: please remove or replace by a proper section or conclusion"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "S7J1ATV2cH", "forum": "BNHplerBYE", "replyto": "BNHplerBYE", "signatures": ["ICLR.cc/2026/Conference/Submission13735/Reviewer_JjnK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13735/Reviewer_JjnK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13735/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761750619570, "cdate": 1761750619570, "tmdate": 1762924273065, "mdate": 1762924273065, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a score-based observational causal discovery algorithm in the presence of latent variables for linear SCM. It provides identifiability guarantees for the causal structure involving latent variables. This paper aims to identify the whole underlying causal structure among both observed and latent variables. It also propose Generalized N Factor Model and can identify the structure up to the Markov equivalence class by score."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper seems to extend the work by Ng et al. 2024. The major difference between this paper and Ng et al. 2024 seems to be greedy search vs. exact search. Particularly, this work proposes an algorithm named LGES, a two-phase GES-style greedy search, operating directly over MEC. This is the first score-based greedy search method for the identification of structures involving latent variables with identifiability guarantees.\n\n- By introducing the generalized N factor model, LGES proves that algebraic equivalence implies Markov equivalence, providing a clean route to global consistency up to MEC via a greedy method. That’s a nontrivial step on top of the SALAD’s algebraic equivalence by Ng et al. 2024.\n\n- The description of LGES is clear.\n\n- The paper provides some real-world datasets to motivate the design of the algorithm.\n\n- Proofs seem to be sound. \n\n- The proposed algorithm can incorporate Verma-type constraints.\n\n\nReference:\n\nNg, Ignavier, et al. \"Score-based causal discovery of latent variable causal models.\" Forty-first International Conference on Machine Learning. 2024."}, "weaknesses": {"value": "- The algorithm is limited to linear Gaussian SCM. \n- Since this paper is highly related to Ng et al. 2024,  it should give a more in-depth discussion between this work and Ng et al. 2024 in the introduction or related work to highlight the differences and contributions of this work.\n- The organization of the paper needs improvement. Some terms such as equality constraints are mentioned in line 136, but it does not provide a brief explanation what that means at the same place of the paper. Rather, it refers to the appendix of the paper to see Definition 6. In terms of organization, this makes the reading more difficult. Similarly for Definition 7. Also, line 197, inequality constraints appear without any explanation about what the means. Line 214 does not provide any contexts about Definition 2 before it says ‘the number of all possible graphs that satisfy Definition 2’. Definition 2 only shows up later in the paper.\n- Besides the organization of the paper, the clarity of the paper also needs improvement. For example, GNFM and GNF are used interchangeably. \n- Lines 253-254 are very hard to follow: ‘At the same time, if the number of observed children is insufficient, we can still gather more relevant observations or measurements of the underlying system.’\n- The efficiency of the proposed algorithm lies critically on the proposed generalized N factor model. It is debatable whether this model assumption is realistic or not. In practice, there should be way more latent than observed. \n- The paper should introduce some basic terms in causal graphical models such as CPDAG.\n- It is confusing to use the same notation $\\mathcal{S}$ to represent both the state and a CPDAG.\n- The paper should cite the exact theorem number in line 299.\n\nReference:\n\n- Ng, Ignavier, et al. \"Score-based causal discovery of latent variable causal models.\" Forty-first International Conference on Machine Learning. 2024."}, "questions": {"value": "- What is $V$ in line 223?\n- Lines 246-247: Why does the partitioning make the requirement of $2|\\mathbf{L}_{p}|$ observed variables being minimal?\n- What is GNF in line 248? Is it GNFM?\n- Lines 253-254 say ‘At the same time, if the number of observed children is insufficient, we can still gather more relevant observations or measurements of the underlying system.’ Do the authors mean the number of observed children is sufficient instead of insufficient?\n- Why does the CPDAG in the initial state need to explicitly list out all the latent variables in the graph?\n- Why is SALAD by Ng et al. 2024 not compared in the experiment?\n- Do all the baselines output CPDAG? Are they compared against a ground truth CPDAG in the experiment?\n- Can authors report the performance only based on the causal structure among the observed variables, including the F1 scores for arrowheads?\n- In the experiment, it says 10 random seeds, but there are 20 randomly generated DAGs. Does that mean each DAG is used 10 times to generate 10 different datasets for each sample size?\n- Which CI test is used for GIN in the experiment? What is the alphas used? \n- Why not compare the performance with the baselines when the ground truth graphs do not satisfy Definition 2 (generalized N factor models), instead of the violation of normality and linearity, as the first experiment has already used uniform noise terms?\n- Why is the performance only reported for sample sizes 500 and 1000 for the model specification case in the experiment? What about the sample size of 100?\n\n- Why is LCD [1] for latents not compared against LGES?\n\nReference:\n\n[1] Rohekar, Raanan Y., et al. \"Iterative causal discovery in the possible presence of latent confounders and selection bias.\" Advances in Neural Information Processing Systems 34 (2021): 2454-2465."}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "details_of_ethics_concerns": {"value": "The wording used in the abstract and the introduction looks quite similar to the paper titled 'Score-Based Causal Discovery of Latent Variable Causal Models' by Ng et al. 2024, but the main content seems fine. I am not sure whether both papers come from the same authors. I suspect that is the case since the graph drawing tools seem to be the same in both papers by comparing Figure 2 in Ng et al. 2024 and the figures in the submitted manuscript. I leave my observations below.\n\n**Example 1:**\n\n**This paper lines 41-51:**\n\n- 'To this end, recent advance has been on discovery of entire structure including latent variables, by introducing additional parametric or graphical assumptions. **This includes methods based on rank or tetrad constraints linearity assumption (Silva et al., 2003; 2006; Silva & Scheines, 2005; Choi et al., 2011; Kummerfeld & Ramsey, 2016; Huang et al., 2022; Dong et al., 2024a), high-order moments (Shimizu et al., 2009; Zhang et al., 2018; Cai et al., 2019; Salehkaleybar et al., 2020; Xie et al., 2020; Adams et al., 2021; Dai et al., 2022; Amendola et al., 2023; Wang & Drton, 2023), matrix decomposition (Anandkumar et al., 2013), mixture oracles (Kivva et al., 2021), and multiple domains (Zeng et al., 2021; Sturma et al., 2023).**   **Despite of the asymptotic correctness, however, these methods generally fall into the category of constraint-based methods; they rely heavily on statistical test to iteratively construct the structure and thus suffer from the problem of multiple-testing and error propogation (Spirtes, 2010; Colombo et al., 2012), especially with small sample size and large number of variables.**'\n\n- Lines 99-101: '**Despite the asymptotic correctness of constraint-based causal discovery approaches, in practice these\nmethods often suffer from the problem of multi-testing and error propagation (Spirtes, 2010; Colombo\net al., 2012)**'\n\n**Ng et al. 2024:**\n\n- 'Hence, another line of work has been developed to discover the causal structure also among latent variables. For the identifiability conditions, these methods typically introduce additional parametric assumptions to mitigate the large model indeterminacies faced by FCI. **This includes rank or tetrad condition-based methods with linearity assumption (Silva et al., 2003; 2006; Silva & Scheines, 2005; Choi et al., 2011; Kummerfeld & Ramsey, 2016; Huang et al., 2022; Dong et al., 2023), high-order moments-based methods (Shimizu et al., 2009; Zhang et al., 2018; Cai et al., 2019; Salehkaleybar et al., 2020; Xie et al., 2020; Adams et al., 2021; Dai et al., 2022; Chen et al., 2022; Am´endola et al., 2023; Wang & Drton, 2023), matrix decomposition-based methods (Anandkumar et al., 2013), copula model-based methods (Cui et al., 2018), mixture oracles-based methods (Kivva et al., 2021), and multiple domains-based methods (Zeng et al., 2021; Sturma et al., 2023).**.    For the algorithmic procedures, **these methods generally fall under the category of constraint-based methods**, by matching the statistical properties to possible structural patterns and constructing the whole causal structure iteratively. A typical constraint-based method in the causally sufficient case is PC (Spirtes & Glymour, 1991). **Despite the asymptotic consistency, the empirical reliability of constraint-based methods may be limited due to testing-order dependency and error propagation (Spirtes, 2010; Colombo et al., 2012), especially when the number of variables is large.** '\n\n**Example 2**\n\n**This paper lines 52-53:**\n\n- ''On the other hand, **score-based causal discovery may not suffer from these issues and thus is believed to be more practially favorable (Nandy et al., 2018; Ramsey et al., 2017).**''\n\n**Ng et.al 2024:**\n\n- 'To address such empirical issues of constraint-based methods, **score-based causal discovery methods have been introduced, and may be more favored in practical applications (Nandy et al., 2018; Ramsey et al., 2017).**'\n\n**Example 3**\n\n**This paper lines 54-58**\n\n- '**There also exists several scorebased methods that can handle latent variables (Shpitser et al., 2012; Triantafillou & Tsamardinos, 2016; Nowzohour et al., 2017; Bhattacharya et al., 2021; Shahin & Chechik, 2020; Bernstein et al., 2020; Bellot & van der Schaar, 2021; Claassen & Bucur, 2022). Similar to FCI, most of them do not discover the causal relations among latent variables, except the method by Zhang (2004)**'\n\n**Ng et.al 2024:**\n\n- '**There also exists several score-based methods that can handle latent variables (Shpitser et al., 2012; Triantafillou & Tsamardinos, 2016; Nowzohour et al., 2017; Bhattacharya et al., 2021; Shahin & Chechik, 2020; Bernstein et al., 2020; Bellot & van der Schaar, 2021; Claassen & Bucur, 2022). Similar to FCI, most of them do not discover the causal relations among latent variables, except the method by Zhang (2004)** without identifiability guarantee.'\n\n\n**Example 4**\n\n**This paper lines 67-69:**\n\n- 'We characterize how likelihood score can be used for the structure identification of partially observed linear causal models. **Specifically, we show that the structure with the best likelihood score and minimal dimension is algebraically equivalent to the ground truth** (in Theorem 1)' \n\n**Ng et al. 2024:**\n\n- 'We develop a formulation of scoring function for identifying linear latent variable causal models. **We show (1) that it is score equivalent and (2) that minimizing it yields a structure that is algebraic equivalent to the true structure**'\n\n**Reference:**\n\n- Ng, Ignavier, et al. \"Score-based causal discovery of latent variable causal models.\" Forty-first International Conference on Machine Learning. 2024."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4MsSKOIqvd", "forum": "BNHplerBYE", "replyto": "BNHplerBYE", "signatures": ["ICLR.cc/2026/Conference/Submission13735/Reviewer_WPvf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13735/Reviewer_WPvf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13735/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991248688, "cdate": 1761991248688, "tmdate": 1762924272558, "mdate": 1762924272558, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}