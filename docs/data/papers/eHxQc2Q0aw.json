{"id": "eHxQc2Q0aw", "number": 5065, "cdate": 1757841453049, "mdate": 1759897997013, "content": {"title": "Stability and Generalization for Bellman Residuals", "abstract": "Offline reinforcement learning and offline inverse reinforcement learning aim to recover near–optimal value functions or reward models from a fixed batch of logged trajectories, yet current practice still struggles to enforce Bellman consistency. Bellman residual minimization (BRM) has emerged as an attractive remedy, as a globally convergent stochastic gradient descent–ascent based method for BRM has been recently discovered. However, its statistical behavior in the offline setting remains largely unexplored. In this paper, we close this statistical gap. Our analysis introduces a single Lyapunov potential that couples SGDA runs on neighbouring datasets and yields an $\\mathcal{O}(1/n)$ on-average argument-stability bound—doubling the best known sample-complexity exponent for convex–concave saddle problems.  The same stability constant translates into the $\\mathcal{O}(1/n)$ excess risk bound for BRM, without variance reduction, extra regularization, or restrictive independence assumptions on minibatch sampling. The results hold for standard neural-network parameterizations and minibatch SGD.", "tldr": "Our analysis yields an $\\mathcal{O}(1/n)$ on-average argument-stability bound for Bellman residual minimization—doubling the best known sample-complexity exponent for convex–concave saddle problems.", "keywords": ["statistical learning theory", "algorithmic stability", "generalization analysis", "offline reinforcement learning", "inverse reinforcement learning"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4f7b99b1c14f286f78b9590e8f6d1402c91bd3ff.pdf", "supplementary_material": "/attachment/4783469b346a34524ef91aa592ae549e7cc789e6.pdf"}, "replies": [{"content": {"summary": {"value": "This paper analyzes the statistical behavior of Bellman Residual Minimization (BRM) for offline RL/IRL. Building on the recent optimization view that the bi-conjugate BRM objective induces a PL–strongly-concave minimax structure, the authors couple two SGDA runs on neighboring datasets via (i) a single Lyapunov potential that mixes primal suboptimality and primal–dual mismatch, and (ii) a “ghost-index” device to decouple sampling noise. They prove on-average argument stability of SGDA with an O(1/n) rate (under Robbins–Monro stepsizes), and transfer this to O(1/n) generalization and an excess-risk bound that cleanly decomposes optimization and estimation errors. The setup, assumptions (A1–A9), and the transfer to weak PD-gap follow the minimax stability framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality\n- Closes a real theoretical gap: Prior minimax stability analyses (e.g., Wang–Lei–Ying–Zhou, NeurIPS 2022) deliver O(n^{-1/2}) rates under convex–concave assumptions. This paper’s O(1/n) stability and generalization results for SGDA in a PL–strongly-concave regime appear novel.\n- Combines multiple theoretical tools—bi-conjugate BRM formulation, PL geometry, a Lyapunov potential, and ghost-index coupling—into a coherent analysis without variance reduction or independence assumptions.\n- The unification of optimization and generalization analysis through a single Lyapunov potential is an elegant methodological contribution.\n\nQuality\n- The proofs are internally consistent and technically sound under the stated assumptions (A1–A9). The Lyapunov-based stability recursion is clearly constructed and all major theorems are proven in full.\n- The paper avoids dependence on variance-reduction or mixing assumptions, deriving O(1/n) bounds via standard SGDA under Robbins–Monro step sizes.\n- The key limitations lie in the strong assumptions—bounded per-sample gradients, uniform constants across neighboring datasets, and uniqueness of the saddle—that may not strictly hold for deep neural networks.\n\nClarity\n- The exposition is clear, particularly in articulating the problem gap (“optimization picture is clear; statistical picture remains open”).\n- The algorithmic setup, potential function, and contraction argument are well explained with intuitive justification for summability of noise terms.\n- Proof dependencies and structure are explicitly cross-referenced in the reproducibility statement, ensuring transparency.\n\nSignificance\n- The results provide the first O(1/n) generalization bound for Bellman Residual Minimization in offline reinforcement learning, doubling the exponent achieved in prior convex–concave analyses.\n- The theoretical framework may generalize to other PL-minimax problems beyond BRM, influencing theoretical and algorithmic directions in RL and IRL.\n- While the assumptions restrict direct practical application, the analysis sets a higher theoretical standard for understanding statistical generalization in nonconvex–concave RL objectives."}, "weaknesses": {"value": "1) Assumptions feel strong and under-motivated for neural BRM\nIssue: The analysis depends on assumptions such as bounded per-sample gradients, uniform constants across neighboring datasets, and uniqueness of the saddle. These are not linked to concrete architectural or data-level conditions.\nActionable Fixes:\n- Provide sufficient conditions (e.g., Lipschitz activations, spectral normalization, weight decay) ensuring these assumptions hold.\n- Add perturbation lemmas for small constant drift across neighboring datasets.\n- Explain how regularization ensures uniqueness of the saddle.\n\n2) Positioning vs. existing stability literature could be sharper\nIssue: The claimed novelty (O(1/n) vs O(1/√n)) relative to convex–concave minimax works (e.g., Wang et al., NeurIPS 2022) lacks a clear side-by-side comparison.\nActionable Fixes:\n- Include a comparison table contrasting assumptions, settings, and rates.\n- Explicitly highlight which steps rely on PL–strong concavity and would fail otherwise.\n\n3) Minibatch dependence not clearly quantified\nIssue: Theorems mention minibatch adaptation “verbatim” without giving explicit batch-size-dependent constants.\nActionable Fixes:\n- Add a corollary deriving ε_T(B) with explicit 1/B scaling and its impact on generalization and excess-risk bounds.\n- Provide practical guidance on choosing batch size B.\n\n4) Lack of empirical sanity checks\nIssue: The paper claims parametric O(1/n) scaling but shows no supporting experiment.\nActionable Fixes:\n- Include a toy experiment using linear BRM satisfying all assumptions to empirically verify slope ≈ –1 in log–log plots.\n- Compare against convex–concave baselines to show contrast.\n\n5) Clarity gaps in bi-conjugate BRM formulation\nIssue: The connection from the bi-conjugate Bellman residual to the minimax form is hard to follow for non-experts.\nActionable Fixes:\n- Add a concise boxed derivation linking the BRM objective to the dual variable.\n- Include a diagram illustrating shared-index coupling and “hit” events.\n\n6) Excess-risk decomposition underemphasized\nIssue: The clean decomposition between stability and optimization error appears late and without clear interpretation.\nActionable Fixes:\n- Promote the decomposition as a boxed equation in the main text.\n- Explain how tuning T and η_t balances the two error terms.\n\n7) Limited discussion beyond entropy-regularized BRM\nIssue: It is unclear whether the results extend to non-entropy (hard-max) BRM formulations.\nActionable Fixes:\n- Add remarks outlining when PL–strongly-concave structure persists under different smoothings (e.g., Moreau envelopes).\n\n8) Ambiguity in “one pass over n samples” phrasing\nIssue: The notion of “one pass” may be misread without clarifying total gradient calls or sampling scheme.\nActionable Fixes:\n- Specify whether T ≈ n steps correspond to one epoch and whether sampling is with or without replacement.\n\nOverall, the paper would improve by making its assumptions verifiable in practice, providing explicit batch-size scaling, and including minimal empirical verification. These additions would make the theory more credible, checkable, and actionable for the ICLR audience."}, "questions": {"value": "1. On Assumptions and Applicability\n- Could you provide explicit sufficient conditions on the neural-network architecture or data distribution that ensure assumptions (A5) and (A8) hold? For example, do ReLU or tanh activations satisfy the Lipschitz and gradient-boundedness assumptions under spectral normalization or weight clipping?\n- The analysis assumes a unique saddle point, yet neural networks are often overparameterized. Is uniqueness strictly necessary, or could the analysis extend to a set of equivalent saddles?\n\n2. On Novelty and Positioning\n- The claimed improvement from O(n^{-1/2}) to O(1/n) hinges on the PL–strongly-concave structure. Could you explicitly summarize which elements of your proof break down in purely convex–concave settings?\n- To what extent could your Lyapunov and ghost-index coupling analysis extend to other PL-minimax settings (e.g., actor–critic or distributional RL formulations)?\n\n3. On Practical Interpretability\n- You mention that the minibatch setting follows “verbatim” with rescaled constants. Could you please provide the explicit scaling law of ε_T(B) in terms of B and n?\n- When stating that you achieve the O(1/n) rate “after one pass over n samples,” do you mean T ≈ n SGDA steps, one epoch with sampling with or without replacement?\n\n4. On Theoretical Sharpness\n- Your current bounds are in expectation. Do you think similar rates could hold with high probability using martingale inequalities (e.g., Azuma or Freedman)? If so, how would the constants or rates degrade?\n- Could you comment on how sensitive your results are to the condition numbers L/μ_PL and L/ρ?\n\n5. On Empirical Verification\n- Would you be open to adding a toy experiment (e.g., linear-quadratic BRM under the assumptions you make) to confirm the slope of the generalization error versus sample size?\n- Even a small-scale plot could visually substantiate the theoretical rate and convince a broader ICLR audience.\n\n6. On Extensions and Generality\n- Your analysis focuses on the softmax (entropy-regularized) case. Could you clarify whether the PL–strongly-concave geometry and stability proof extend to hard-max or Moreau-smooth Bellman operators?\n- Would your argument still hold under Markovian dependence rather than i.i.d. samples? If not directly, what modifications would be necessary to handle the mixing-time dependence?\n\n7. On Presentation and Readability\n- Could you include a short boxed derivation showing how the Bellman residual minimization problem transforms into the minimax form involving the dual variable?\n- The final decomposition separating optimization and generalization errors is one of your most interpretable results. Consider moving it earlier into the main body with a brief intuitive discussion.\n\n8. On Possible Future Directions\n- How do you envision extending your analysis to policy-based or actor–critic settings, where the loss is not strictly bi-convex/bi-concave?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gtGlUB77Ze", "forum": "eHxQc2Q0aw", "replyto": "eHxQc2Q0aw", "signatures": ["ICLR.cc/2026/Conference/Submission5065/Reviewer_kFyc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5065/Reviewer_kFyc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5065/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976923373, "cdate": 1761976923373, "tmdate": 1762917852599, "mdate": 1762917852599, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies Bellman Residual Minimization (BRM) for offline RL. Using a bi-conjugate reformulation, minimizing MSBE is turned into a Polyak--Łojasiewicz (PL)–strongly-concave minimax problem that can be solved by SGDA, thereby avoiding the double sampling problem. The analysis couples two SGDA runs on neighboring datasets and proves on-average algorithmic stability with an $O(1/n)$ rate, without requiring variance reduction or independence assumptions. By stability-to-generalization transfer, the work bounds (i) the gap between population and empirical Bellman-residual risks and (ii) the population Bellman-residual risk of the SGDA output."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Without requiring independence assumptions on the sample indices nor variance reduction, the paper establishes an $O(1/n)$ on-average stability and, via stability-to-generalization transfer, an $O(1/n)$ generalization bound for BRM, doubling the exponent from $1/2$ to $1$ over prior work.\n    \n- The population excess risk is cleanly decomposed into an optimization term that decays with training and a sample-size–dominated statistical term, naturally aligning with standard minibatch SGDA.\n    \n- All assumptions are stated explicitly and clearly, making the analysis easy to follow."}, "weaknesses": {"value": "- It would be helpful to add illustrative examples and comparisons to aid understanding (see Q 1 and 2).\n\n\n- Sections~2 and 3 include substantial repetition of well-known material, and the exposition feels overly long. For example, the standard SGDA routine could be moved to the appendix for brevity."}, "questions": {"value": "- How strong is Assumption A8? Do the constants remain unchanged under a single-sample replacement in general setting, and could the authors provide a concrete example illustrating when A8 holds or fails?\n\n- In Corollary~4, could you quantify the iteration threshold $T^\\star$ at which the optimization term is below the statistical term formally? Additionally, for the small-$T$, could you provide a comparison with prior methods? \n  \n- Would it be possible to use one of $(w,v)$ or $(\\theta_1,\\theta_2)$ to unify the notation since these seem to denote the same primal/dual variables?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "QrhskCHEoU", "forum": "eHxQc2Q0aw", "replyto": "eHxQc2Q0aw", "signatures": ["ICLR.cc/2026/Conference/Submission5065/Reviewer_uiVV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5065/Reviewer_uiVV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5065/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762048800437, "cdate": 1762048800437, "tmdate": 1762917852252, "mdate": 1762917852252, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes the excess risk bound for offline reinforcement learning in view of Bellman residual minimization."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The problem of analyzing the excess risk bound for Bellman residual minimization does seem open so far."}, "weaknesses": {"value": "- The comparison to existing works in approximate dynamic programming methods e.g. projected Bellman equation-based approaches seems inadequate. Is Bellman residual minimization the only way to accommodate the difficulty of enforcing Bellman consistency? What are the other existing risk bounds when incorporating function approximations and how do these results compare?\n- The techniques used seem to be standard, e.g. PL for analyzing SGDA etc. It seems unclear from the manuscript what are the technical challenges and the techniques developed in this paper that are independent of the developments from combining Kang et al. 2025 and Wang et al 2022. What is the motivation when defining the Lyapunov potential? Some discussions around lines 369-375 when introducing this object would greatly help the reader.\n- The presentation of Theorem 6 and in general Section 3 can be improved. As far as I understand, this paper is considering the specific problem of learning the (action)-value function, and thus introducing 9 assumptions for a general function F and auxiliary results about general risks introduces additional notation while not clear to what extent they are helpful in elucidating the final result (Theorem 6). I would think a clearer explanation why value functions and lyapunov potential satisfy the assumptions needed to establish Theorem 6 and intuition of the result would be more helpful than the results about general F along with 9 additional assumptions (that will automatically be satisfied).\n\n\nMinor points:\n- There are superfluous \"equation\" when referring to equations throughout the paper, e.g., Equation 4, etc. Please remove those.\n- Line 80: \"Throughout, focus on single-agent decision making problem interacting with a discounted Markov Decision Process (MDP) described by the tuple ( S, A, P, r, β , ν 0)\" is lacking a subject.\n- Bellman consistency in line 38 comes out directly without motivation or explanation. Why do we want consistency and what does it mean? In the last sentence you said \"satisfies the Bellman optimality equations even though no new state–action pairs can be queried.\" but Bellman consistency means fixed point of Bellman equations, which is not shown here."}, "questions": {"value": "See previous section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Qy2w5RgCff", "forum": "eHxQc2Q0aw", "replyto": "eHxQc2Q0aw", "signatures": ["ICLR.cc/2026/Conference/Submission5065/Reviewer_yTNX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5065/Reviewer_yTNX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5065/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762082381822, "cdate": 1762082381822, "tmdate": 1762917851931, "mdate": 1762917851931, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers the problem of minimizing the Bellman error in a TD (Temporal Difference) update and cast this as a minimax problem of optimizing an objective that involves two parameterized functions : 1) Q function as a function of state and action and 2) The other is a parameterized neural net that given current state and action approximates the value function of the future sampled state. This optimization objective is derived (from prior work) by characterizing the bias between the squared Bellman error with respected to the expected TD operator and sampled TD Bellman error.  Further the surprising fact about this parameterization is that the problem is concave with respect the second function and the objective after inner optimization satisfies the PL condition with respect to the first Q function when you consider the stochastically approximated variant under general parameterizations (specifically linear function approximation).\n\nMotivated by this, the authors propose to perform a stability analysis that would bound the generalization error (in terms of the duality gap) between the mini max problems which sees the population version and the the sample version. Authors adopt the stability analysis (that is known to imply generalization in the sense of duality gap from prior work) where the mini max problem see two sets of sequence of samples (state transitions) where one of the samples is different and authors seek to bound the distance of between the primal and dual iterates of these two coupled minimax problems. \n\n Authors introduce two interesting ideas: 1) Ghost index which is an index independently sampled from the dataset which is independent of the Filtration and gradient with respect to this sample in expectation can approximate the population gradient 2) PL condition implies for the outer problem and strong concavity for the inner problem imply contraction for a Lyapunov function that is a combination of the primal gap and the dual gap in the expected function value.\n\nAuthors use this and existing results about stability to prove generalization of the primal and dual gap from sample to the population version."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper (to my knowledge) is the first to consider stability analysis exploiting the PL condition and strong concavity of the respective problem to show generalization errors in primal and dual gaps.  There are a lot of algebraic manipulations that deftly use the ghost index, contraction properties of the outer and inner problem to establish bounds on generalization error. The application to Bellman residual optimization is noteworthy although it borrows heavily from prior work."}, "weaknesses": {"value": "1) My first concern is inadequate quoting of results from Kang et al 2025 that misleads reading this paper. Line 230 and 231 says that Kang et al. 2025 proved that PL condition is satisfied with respect to the parameters of the Q function (primal variables) when parameterized by a Neural Network. I read the prior paper. There are lots of caveats to the Neural Network result - it traces back to the result in https://arxiv.org/pdf/2003.00307 - where authors show that - wide and deep neural nets satisfy the PL condition over a radius around a random initialization if the width scales as radius^depth.  Further, the theorem is easily proven only for linear function approximation in Kang et.al. 2025.\n\n2) Second concern is that ghost index trick works because, say for the inner problem, gradient is assumed to be uniformly bounded. This is rather a very strong assumption. However, the inner problem is strongly concave and *Page 2 of this ICML paper https://proceedings.mlr.press/v80/nguyen18c.html  shows that unless the ball of iterates is bounded explicitly, uniform gradient norm bound contradicts strong convexity (or concavity) !*\n\nAuthors can have uniform bound G on gradient norm only if the iterates stay within a ball of certain radius from where it starts at least for the inner concave problem. The algorithm described is unprojected SGDA and the problem needs to project itself on every update to some ball. In the RL context that would mean projecting the iterates of the parameters of the Q function to a ball that would encapsulate the optima - rather a very strong assumption. Even the Neural net satisfying bounds of gradient, Hessian and Jacobian operator (assumption 5 in Kang et al 2025  paper) is possibly within some small ball around the initialization for a network of given width."}, "questions": {"value": "1) Can you answer the above 2 weakness points ? Question about the need for projected steps if gradient bound is assumed is rather concerning and could be a serious weakness as written\n\n2) Paper quotes the deadly triad relating to convergence of Q learning. There is a recent paper on resolving it for linear function approximation (https://arxiv.org/abs/2203.02628) using truncation and target network. Discussing these alternative works is very important.\n\nI think the gradient bound issue is more serious. Therefore, I have given rating of 2. I would wait for authors to respond to that and I can raise my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dVNEQM20Wb", "forum": "eHxQc2Q0aw", "replyto": "eHxQc2Q0aw", "signatures": ["ICLR.cc/2026/Conference/Submission5065/Reviewer_MpYr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5065/Reviewer_MpYr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5065/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762714277156, "cdate": 1762714277156, "tmdate": 1762917851700, "mdate": 1762917851700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Sincere gratitude to reviewers and ACs"}, "comment": {"value": "Dear AC and reviewers,\n\nWe would like to express our sincere gratitude to the area chair and the reviewers. We have not encountered such thoughtful, thorough, and high-quality reviews in many years, and we are deeply appreciative of the care and expertise that went into them. \n\nIn particular, we are especially grateful to the reviewers who invested substantial time and effort in evaluating our work. Your detailed comments and suggestions have given us many concrete ideas for improving the paper, and they will significantly strengthen the paper. We are grateful for this chance given to us to learn this area more.\n\nThank you again for your exceptional feedback and support. Although our score set is closer to rejection than acceptance, we would not trade this review set for a set of acceptance-level scores with less effort.\n\nWe will upload our detailed responses to your reviews as soon as possible, in the hope that they further clarify our contributions and address your concerns.\n\nAuthors"}}, "id": "Hts2r7troH", "forum": "eHxQc2Q0aw", "replyto": "eHxQc2Q0aw", "signatures": ["ICLR.cc/2026/Conference/Submission5065/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5065/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission5065/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763006967403, "cdate": 1763006967403, "tmdate": 1763006999415, "mdate": 1763006999415, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}