{"id": "U30FO4wae8", "number": 25284, "cdate": 1758366178478, "mdate": 1759896726705, "content": {"title": "Entropy-driven Fair and Effective Federated Learning", "abstract": "Federated Learning (FL) enables collaborative model training across distributed devices while preserving data privacy. Nonetheless, the heterogeneity of edge devices often leads to inconsistent performance of the globally trained models, resulting in unfair outcomes among users. Existing federated fairness algorithms strive to enhance fairness but often fall short in maintaining the overall performance of the global model, typically measured by the average accuracy across all clients. To address this issue, we propose a novel algorithm that leverages entropy-based aggregation combined with model and gradient alignments to simultaneously optimize fairness and global model performance. Our method employs a bi-level optimization framework, where we derive an analytic solution to the aggregation probability in the inner loop, making the optimization process computationally efficient. Additionally, we introduce an innovative alignment update and an adaptive strategy in the outer loop to further balance global model's performance and fairness. Theoretical analysis indicates that our approach guarantees convergence even in non-convex FL settings and demonstrates significant fairness improvements in generalized regression and strongly convex models. Empirically, our approach surpasses state-of-the-art federated fairness algorithms, ensuring consistent performance among clients while improving the overall performance of the global model.", "tldr": "We propose a fair FL algorithm that addresses the underexplored challenge of improving performance fairness while enhancing global accuracy, with theoretical and empirical demonstrations.", "keywords": ["fairness alignment", "federated learning"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6b387893a1e1da8333909721171641b166c97874.pdf", "supplementary_material": "/attachment/b2f2b80d686cd5396ea3480f1a828698746e1a5f.zip"}, "replies": [{"content": {"summary": {"value": "The paper addresses the dual objectives of enhancing predictive performance and ensuring client-level fairness in Federated Learning (FL) setting. To this end, the authors proposed FedEBA+, which formulates the problem as a bi-level optimization. FedEBA+ involves entropy-based aggregation mechanism, model and gradient alignment update strategy. A practical variant is further proposed to mitigate communication costs. Theoretical analyses establish convergence guarantees and examine fairness properties under strongly convex settings. Empirical results support, to some extent, the effectiveness of the proposed approach."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper presents a novel fairness-aware FL method, FedEBA+, and its practical variant Prac-FedEBA+, which integrates an entropy-based fair aggregation scheme together with model and gradient alignment strategies.\n2. The discussion of related work is relatively comprehensive.\n3. Theoretical analyses are provided to establish convergence guarantees and fairness properties of the proposed method."}, "weaknesses": {"value": "**Overall:**\n1. The motivation is not clearly articulated. Although the authors point out the limitations of existing approaches, i.e., high communication and computational overhead, degradation of global model performance in pursuit of fairness, and insufficient problem modeling, it is unclear what concrete innovations are introduced to address them. For example, regarding fairness, the rationale for adopting a constrained maximum-entropy strategy is not sufficiently explained, i.e., its advantages over more common strategies such as re-weighting or gradient adjustment are not clearly justified.\n2. Several statements and claims in the paper are overstated.\n3. The notation system is inconsistent and confusing, which significantly hinders readability and continuity of the technical presentation.\n\n**Details:**\n\n1 Statements and claims are overstated, or insufficiently supported by evidence.\n\ni) “Enhance” the accuracy of the global model:\n - Is this improvement intended to be measured against predictive performance-focused methods?\n- However, the experimental evaluation does not include comparisons with predictive performance–focused methods, making it hard to validate whether the proposed method truly improves the global model’s predictive capability.\n- Lines 416-417 state that accuracy improves by 4% on CIFAR-10 and 3% on CIFAR-100 and Tiny-ImageNet, but it is not clear how these gains were computed. However, in fact, the margins over the second-best compared methods seem to be below 1%, and in some cases, the proposed approach performs worse than the compared methods.\n\nii) Communication efficiency:\n- There are no any theoretical analysis or empirical evidence to support the claim of superior communication efficiency of proposed method.\n- Lines 043-044: the proposed method requires transmitting both model and gradient information in each communication round, which is not more efficient than FedFV [Wang et al., AAAI 2021].\n- Regarding the claim of “fast convergence”, Figure 3b does not clearly support this, as the proposed method requires a similar number of communication rounds to reach optimal performance compared with several other methods.\n\niii) Effectiveness of proposed methods:\n- In Lines 266–267, the so-called “ideal global gradient” is approximated by averaging local one-step gradients. However, this approximation may not yield the optimal updated gradient, as client gradients are prone to conflict, especially in the case of data heterogeneity. The same concern arises in the Gradient Alignment for Improving Fairness procedure.\n\n2 Confusing notation system\n- x_t denotes the global model at round t in most parts of the paper, but in Definition 3.1, it represents a different model.\n- In Eq. (3), the subscript notation for x is inconsistent with earlier definitions. Specifically, in Line 117, the subscript denotes the communication round and the superscript is originally used for the client index, but Eq. (3) uses the subscript to denote the client index.\n- The symbol n is used ambiguously. It denotes the number of clients selected in communication round t (as defined in Line 114) and simultaneously represents the number of data points in client i (in Line 213).\n- In Lines 254-256, $\\eta_L$ should be $\\eta$, as according to the definition in Line 120, $\\eta_L$ denotes the local learning rate, whereas $\\eta$ denotes the global learning rate.\n- Line 119: $\\eta_L$ is missing\n- In Eq. (5) and (6), N is not defined.\n- The number of clients is expressed with various symbols, e.g, n, m, N.\n- These notation issues persist throughout Sections 3, 4, and 5, affecting the clarity of the presentation.\n3. Other issues\n- Figure 1 makes little sense, as the compared methods are not novel, and it does not provide new insights or clarify the motivation for the proposed approach.\n- Lines 413–414 refer to “diverse models” ; however, it is not clear which models are included. In the tables, it seems that only a single model was actually used for evaluation.\n- The results of “coefficient of variation” are not provided in Table 1 and Table 2.\n\n**Minor issues:**\n- Line 135, “parameter”—does it refer to a single parameter? Or should be “parameters”.\n- In Definition 3.1, “more fair” should be “fairer”"}, "questions": {"value": "1. Line 409 states that existing methods “fail to model the problem directly,” leading to suboptimal performance. It is unclear what is meant by directly modeling the problem, how the claim of suboptimal performance is demonstrated, and why the proposed method can be considered to model the problem directly, whereas other methods do not.\n2. Proposition 4.1 is difficult to follow. It is unclear how it relates to Eq. (3): does it describe a solution to Eq. (3)? In addition, how the conclusion in Lines 207–211, i.e., “assigning higher aggregation weights … reducing the gap with top performers…”, is derived (even if the statement seems intuitive)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Pu7hRwmxol", "forum": "U30FO4wae8", "replyto": "U30FO4wae8", "signatures": ["ICLR.cc/2026/Conference/Submission25284/Reviewer_RaBA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25284/Reviewer_RaBA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25284/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761792216915, "cdate": 1761792216915, "tmdate": 1762943387378, "mdate": 1762943387378, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies an important problem: finding a balance between fairness and utility for federated learning. It is a well-known fact that, although heterogeneity is necessary for realistic scenarios, it usually negatively impacts the performance. The paper's main novelty is the algorithm that uses entropy-based aggregation and during the learning process, it adaptively optimizes for either global accuracy or fairness depending on the current performance of the model. There are two major theoretical results. The first is on convergence and there is no assumption on convexity. The second result confirms the improvement in fairness under the strongly convex loss function. The authors also conducted extensive empirical analysis on the performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem is interesting and important. Although FL fairness is a widely studied topic, it has never been entirely solved.\n\n2. The algorithm using entropy-based aggregation and adaptive optimization strategy is novel and interesting.\n\n3. The theoretical analysis is extensive and sound.\n\n4. The experiments are convincing and show the promising consequences of the algorithm."}, "weaknesses": {"value": "In general, it is a decent work. But my main concern is the strong assumption for the theoretical analysis. The part (2) of Theorem 5.4 is the key part of theoretical analysis, yet it assumes strong convexity of the loss function. This is a strong condition and may downgrade the applicability."}, "questions": {"value": "See Weaknesses. Please give a brief explanation on the difficulty of relaxing the assumption, e.g. convexity instead of strong convexity."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "H4ZGt4aU6S", "forum": "U30FO4wae8", "replyto": "U30FO4wae8", "signatures": ["ICLR.cc/2026/Conference/Submission25284/Reviewer_QJHA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25284/Reviewer_QJHA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25284/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936472079, "cdate": 1761936472079, "tmdate": 1762943387165, "mdate": 1762943387165, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work adopted constrained entropy maximization objective to improve the performance fairness in federated settings. \nAs a result, the proposed method `FedEBA+`, constructs an adaptive strategy that determines aggregation weights in terms of a softmax distribution from local test losses (optionally dampened by a temperature). For a complete formulation, authors employed bi-level optimization framework with respect to a parameter and the aggregation weights."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Constrained entropy maximization and performance fairness in FL\n  - The authors provided thorough justification that the proposed objective can improve performance fairness by reducing to the low variance of performance distribution. (in Eq. (3), Proposition 4.1, and Appendix I.1)\n\n* Addendum on global utility\n  - The authors proposed an additional trick to strike balance between utility and fairness of a global model by aligning the global update using the server-side ideal global gradient. (in Eq. (10-11))\n\n* Extensive demonstration\n  - `FedEBA+` showed comparable performance and fairness in several metrics and benchmark datasets: worst/best acc, variance, coefficient of variation."}, "weaknesses": {"value": "- While different in motivation and objective, the resulting update formula coincides with that of `AAggFF`, cited in the draft.\n- The alignment update is not novel, proposed and used similarly in `FedFA` (Wang et al., 2021) and `FedMDFG` (Pan et al., 2023), which are cited in lines 43-44.\n- In Proposition 4.3, although authors provided the approximation method of aligned gradient, the increase in communication cost is unavoidable. \n  - That being said, each client should upload local gradients, local updates, and local losses in every communication round."}, "questions": {"value": "- The convergence guarantee in Theorem 5.1 is questionable in three main aspects: \n  - i) the convergence upper bound given in eq. (13) can be _inflated to infinity_, i.e. unbounded chi-squared divergence, $\\chi_{\\boldsymbol{w} || \\boldsymbol{p}^t}^2\\rightarrow\\infty$.\n  - ii) the main constant related to the theoretical local learning rate was also induced by an incomplete assumption: the condition of the constant $C$ stated in the statment cannot hold, when if $\\frac{1}{2}< 10L^2 \\frac{1}{m} \\sum_{i=1}^{m} K^2 \\eta_L^2 (A^2 + 1)(\\chi_{\\boldsymbol{w} || \\boldsymbol{p}}^2 A^2 + 1)$. This should be justified to have nonnegative server-side learning rate. \n  - iii) the convergence rate scales with the number of client $m$, as the same rate of the total steps $KT$. This directly violates _linear speedup guarantee_, which is desirable for typical FL algorithms.\n    - However, the empirical convergence speed is faster than other methods in Figure 3-(b). Please clarify this gap.\n- From Section 4.2, it is implied that $\\alpha$ acts as a knob to balance tradeoff between utility and fairness.\n  - Is the $\\alpha$ selected heuristically as $\\alpha=\\beta/\\tau$?\n  - While this is one of main contributions of `FedEBA+`, there is *no (theoretical/empirical) analyses* related to $\\alpha$... Please consider adding in-depth discussion on this, e.g., the optimal choice of $\\alpha$ and its contribution to the generalization error.\n  - What can we expect the effect of $\\alpha$ on the variance of final performance distribution, the target notion of fairness of the proposed method?\n- Please add dots and lines for `AAggFF` in Figure 3-(a) and 3-(b)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "oLhGQFRJFB", "forum": "U30FO4wae8", "replyto": "U30FO4wae8", "signatures": ["ICLR.cc/2026/Conference/Submission25284/Reviewer_26eQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25284/Reviewer_26eQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25284/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976480389, "cdate": 1761976480389, "tmdate": 1762943386977, "mdate": 1762943386977, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces FedEBA+, a bi-level federated learning framework that integrates constrained max-entropy aggregation—which upweights clients with higher losses—alongside model and gradient alignment techniques. This approach simultaneously enhances client-level fairness by reducing performance variance across clients while maintaining strong global accuracy. To address practical deployment constraints, the authors develop Prac-FedEBA+, a variant that approximates the fair gradient computation to preserve FedAvg's efficient communication pattern. The framework is supported by theoretical analysis establishing non-convex convergence guarantees and variance reduction properties. Experimental validation across Fashion-MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrates performance improvements over existing fairness-oriented federated learning methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) Addresses a critical challenge in federated learning by simultaneously optimizing both global model performance and fairness across clients through a principled bi-level optimization framework. Previous methods like AFL seem to do well on client level but loose performance on global level.\n\n2) Provides comprehensive empirical validation supported by rigorous theoretical analysis, featuring experiments across multiple datasets with diverse client level fairness metrics including variance, worst/best-5% accuracy, and coefficient of variation. The work is further strengthened by thorough ablation studies and sensitivity analyses detailed in the appendix."}, "weaknesses": {"value": "1) Communication overhead per global round is not clearly outlined:\n\nAlgorithm 1 indicates that FedEBA+ requires transmitting a fair gradient back to clients and collecting per-client losses and gradients at the current model state, which means additional downlink and uplink communication beyond FedAvg's requirements. Prac-FedEBA+ claims to maintain the same communication pattern as FedAvg. Can you include  a small table comparing FedEBA+/Practical version with a  breakdown of per round communication cost that includes: the number of uplink and downlink transmissions, total bytes transferred etc. Additional rounds and additional bandwidth cost analysis must be included.\n\n\n2) Typos eg: Inconsistency in Table 1 regarding local epochs.The caption states \"a single local epoch (K = 10),\" which got me confused for a while. Please make sure there are no typos\n\n\n3) The Non-IID data construction and its results should be clearly explained ideally in the main paper. Clarification should be made on strong non-IID conditions eg: class-imbalance scenarios  which are tested separately from weak non-IID (eg: sample-proportion skew) . Ideally your method should demonstrate the greatest advantages under strong non-IID conditions\n\n\n4) There should be an Impact of local epochs K on drift and the role of alignment.\nThe paper's motivation suggests that alignment should mitigate local drift under non-IID conditions, implying that increasing K (local epochs) should benefit FedEBA+ more than FedAvg in terms of variance reduction.Please add an experiment varying K (e.g., K ∈ {1, 5, 10, 20}) under strong class imbalance  plotting variance, worst-5% accuracy, and global accuracy versus K for FedAvg, FedEBA+, and Prac-FedEBA+."}, "questions": {"value": "Please see weaknesses I have merged my concerns with the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ffwQmurwfK", "forum": "U30FO4wae8", "replyto": "U30FO4wae8", "signatures": ["ICLR.cc/2026/Conference/Submission25284/Reviewer_1mR6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25284/Reviewer_1mR6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25284/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762021157698, "cdate": 1762021157698, "tmdate": 1762943386609, "mdate": 1762943386609, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}