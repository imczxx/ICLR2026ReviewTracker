{"id": "agnchf9dVn", "number": 8111, "cdate": 1758063950368, "mdate": 1759897806881, "content": {"title": "Survival VAE: Robust Local Explanations via Double-Pass Risk Consistency", "abstract": "In the era of advanced machine learning, the need to explain models has grown significantly. One particular domain, survival analysis, has benefited from the rise of deep learning but has lagged behind in the development of methods for explaining risk and survival models. \nOnly a few works have adapted explainable AI methods, such as LIME and SHAP, to survival analysis. Despite these efforts, explaining survival models remains challenging given the complex nature of the data used for survival predictions and the presence of censoring.\nIn this work, we propose a local feature identification method that inherently operates on the instance ordering induced by event and censoring times. It enables faithful, per-sample feature importance by identifying which reconstructed input features preserve consistency in predicted survival risk across a double-pass through the variational autoencoder.\nEmpirical results on the large multi-cohort dataset from The Cancer Genome Atlas demonstrate superior quantitative performance of our method. Qualitatively, analysis of mask weights highlights the biological relevance of the feature selection process.\nThis information can be used to identify new diagnostic markers and treatment targets for cancer patients.", "tldr": "", "keywords": ["XAI", "Survival Analysis"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8b67980bbd69bf7d750e12d192438f2dc61a9c0d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a novel method, DP-SurVAE, for generating local feature explanations for survival analysis models. The core idea is to utilize a VAE and a novel \"double-pass\" training objective designed to ensure that predicted survival risk remains consistent even after applying a sparse feature mask to the reconstructed samples. The authors evaluate their method on the large-scale, high-dimensional TCGA dataset, demonstrating that features selected by DP-SurVAE achieve superior quantitative performance and show biological relevance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "$\\textbf{Importance of the Problem:}$ The paper tackles a critical problem in medical AI: providing reliable and faithful explanations for complex survival analysis models, especially when dealing with censored data. This is an active and impactful area of research.\n\n$\\textbf{Strong Empirical Results:}$ The paper conducts a comprehensive empirical evaluation on two large-scale, high-dimensional datasets from TCGA. The results show that a downstream model trained on the feature subset selected by DP-SurVAE consistently and significantly outperforms baselines.\n\n$\\textbf{Biological Relevance Validation:}$ A major highlight of this work is the validation of the selected features for biological relevance. Through Gene Ontology (GO) enrichment analysis and correlation analysis with known cancer genes, the authors provide strong qualitative evidence for the model's explanatory power, suggesting it not only performs well in prediction but also uncovers meaningful biomarkers."}, "weaknesses": {"value": "$\\textbf{Lack of Theoretical Justification for the Core Loss Function:}$ This is the most significant weakness of the paper. The proposed \"Double-Pass Log-Partial Likelihood\" (DPLPL) loss is the central innovation. However, the paper provides no theoretical proof or deep explanation as to why this specific formulation is the \"correct\" or \"principled\" way to enforce risk consistency. This leaves the theoretical foundation of the core contribution feeling weak.\n\n$\\textbf{Excessive Model Complexity and Lack of Ablation Studies:}$ The DP-SurVAE architecture is quite complex, integrating a VAE, an attention-masking module, and a double-pass encoding flow. The authors do not sufficiently justify this complexity. For instance, it is unclear why the mask is applied to the reconstructed sample instead of directly to the original input. The paper lacks ablation studies on these alternatives, making it difficult to assess the actual contribution of each component.\n\n$\\textbf{Questions Regarding the Evaluation Method:}$ The evaluation primarily focuses on using the selected features to retrain a downstream model and comparing its predictive performance. While this reflects feature importance, it does not directly measure the faithfulness of the explanation—that is, how well the explanation represents the model's own decision-making process. Since DP-SurVAE is an end-to-end model and the baselines are post-hoc, the comparison might inherently favor DP-SurVAE."}, "questions": {"value": "$\\textbf{1. }$ Could you provide a more rigorous theoretical motivation for the specific form of the $L_{dplpl}$ loss function? Why is treating the original and masked samples as separate entries in an extended risk set the optimal way to enforce consistency?\n\n$\\textbf{2. }$  Theorem 1 states that the masking operation degrades risk consistency, thus motivating a training objective to correct for it. Beyond this intuitive observation, what is the primary theoretical insight provided by this theorem? Does it justify $L_{dplpl}$ as the unique or optimal solution to this problem?\n\n$\\textbf{3. }$ Have you considered simpler architectures, such as applying the mask directly to the input x and then enforcing consistency between the latent means or risk predictions of the original and masked samples via a KL divergence or L2 loss? How does such a simplified model perform compared to DP-SurVAE?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aQSipjt3UP", "forum": "agnchf9dVn", "replyto": "agnchf9dVn", "signatures": ["ICLR.cc/2026/Conference/Submission8111/Reviewer_mxxS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8111/Reviewer_mxxS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8111/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760860980896, "cdate": 1760860980896, "tmdate": 1762920091676, "mdate": 1762920091676, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DP-SurVAE, a method for local feature importance in survival analysis \nthat combines a VAE with masking and a novel \"double-pass\" objective to ensure risk \nconsistency when identifying important features for predicting patient survival. The method \noperates on high-dimensional gene expression data from The Cancer Genome Atlas (TCGA), \ncomparing against LIME, SHAP, SurvLIME, and SurvSHAP. The authors evaluate on 37 disease \ncohorts using C-index and provide biological validation via Gene Ontology enrichment and \ncancer gene analysis. While the paper addresses an important problem, it suffers from \nsignificant clarity issues and vague technical exposition"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Important and timely problem**: Explainability in survival analysis is genuinely \n   underexplored. Accounting for censoring when explaining predictions is an interesting \n   problem domain.\n\n2. **Large-scale empirical evaluation**: Testing on 37 TCGA cohorts (19 mRNA, 18 miRNA) \n   demonstrates consistency across multiple cancer types."}, "weaknesses": {"value": "The paper combines existing techniques without sufficient novelty for a top-tier venue:\n\n**VAE for feature importance is well-established**\n- Using VAEs for interpretability/feature importance has been extensively studied (e.g., \n  β-VAE for disentanglement, attention-based VAE masking).\n- The main contribution—masking on VAE reconstructions—is a straightforward extension of \n  existing attention-masking mechanisms (not novel).\n- Reference: CompSense, IntGradCAM, attention-based VAE masking are standard techniques \n  that the paper does not clearly differentiate from.\n\n**Double-pass might be incremental contribution**\n\n- The \"double-pass\" mechanism is simply: (1) encode original, (2) mask reconstruction, \n  (3) re-encode masked version.\n- This is a minor engineering contribution. It's unclear why this specific procedure is \n  necessary vs. alternative consistency enforcement mechanisms (e.g., auxiliary losses, \n  constraints on latent space).\n\n\n**Comparison to SurvLIME/SurvSHAP is unfair**\n\n- SurvLIME/SurvSHAP are post-hoc explainers for arbitrary survival models.\n- DP-SurVAE is a full model that jointly learns predictions + explanations.\n- These are not comparable; a fair comparison would be DP-SurVAE vs. other jointly-learned \n  interpretable survival models (e.g., neural additive models, attention-based models).\n- The paper excludes CoxNAM (the only jointly-learned baseline) due to \"impracticality in \n  high dimensions\"—but this is exactly where interpretability is needed most.\n\n**What exactly is novel?**\n\n- Combining VAE + masking + Cox loss: incremental engineering.\n- Double-pass consistency: engineering solution, not conceptual novelty.\n- Biological validation: application validation, not methodological novelty.\n\n\n**The paper relies almost exclusively on C-index for evaluation, which is fundamentally \ninsufficient**\n\n- C-index only measures ranking agreement between predicted risk and actual survival times.\n- It says nothing about:\n  - Calibration (are predicted probabilities accurate?)\n  - Discrimination at specific time points \n  - Sensitivity/specificity tradeoffs\n  - Ability to identify high-risk vs. low-risk patients\n  \n\n**Missing standard survival analysis metrics**\n\n- **Time-dependent AUC (AUC(t)):** Evaluates ranking at specific time horizons (e.g., 1-year, \n  5-year survival). Critical for clinical applications. Missing.\n- **Brier score:** Measures calibration, crucial for predicting actual survival probabilities. \n  Missing.\n- **Integrated Brier Score (IBS):** Integrates calibration error over the entire follow-up \n  period. Standard in survival analysis literature. Missing.\n\n\n\n**The method is not evaluated for its core purpose: explainability**\n\n- The paper claims to provide \"faithful, per-sample feature importance.\"\n\n- **No evaluation of explanation quality:**\n\n  - Do selected features have causal effects on survival?\n  - Are explanations consistent across similar samples?\n  \n- Only C-index (predictive performance) is measured. Explanation quality is never evaluated.\n\n**Theorem 1 derivation is informal and circular**\n\n- The theorem doesn't *prove* consistency is maintained after training. It merely states that \n  \"optimizing for consistency enforces consistency\"—this is tautological.\n- No bound on how loose δ(α) becomes with aggressive masking (e.g., α=0.99).\n- No proof that training L_dplpl actually achieves |h(μ_x̂̂) - h(μ_x)| ≤ ε(α).\n\n\n**Missing Ablation: Loss component contributions**\n- What is the contribution of each term in L_total?\n\n**Missing Ablation : Double-pass necessity**\n- How much does the double-pass contribute vs. single-pass?\n\n**Unclear VAE formulation**\n\n- Section 4.1 introduces ELBO with z_x sampling, but Section 4.2 uses μ_x (the mean) for \n  risk prediction.\n- Why not use z_x? Deterministic use of μ_x removes the stochasticity that the ELBO is \n  meant to regulate.\n- **Current:** No justification. Appears to be a design choice, not principled.\n- **Needed:** Explain why μ_x instead of z_x. Ablation comparing both."}, "questions": {"value": "1. **Novelty**: What exactly is novel beyond combining VAE masking + Cox loss? How does \n   double-pass differ from simply adding a consistency auxiliary loss?\n\n2. **Theorem 1**: Can you formally define \"risk consistency\"? Provide explicit bounds on \n   |h(μ_x̂̂) - h(μ_x)| after training?\n\n3. **Extended risk set**: How does Equation (5) maintain Cox PH assumptions? Samples are \n   paired (x, x̂̂), not independent. Proof?\n\n4. **C-index only**: Why not report AUC(t), Brier score, calibration plots? These are standard."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uOwEzvsxzu", "forum": "agnchf9dVn", "replyto": "agnchf9dVn", "signatures": ["ICLR.cc/2026/Conference/Submission8111/Reviewer_bi7L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8111/Reviewer_bi7L"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8111/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761430767482, "cdate": 1761430767482, "tmdate": 1762920091255, "mdate": 1762920091255, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Survival-VAE, a novel framework that combines VAEs with survival analysis to model heterogeneous hazard distributions across subpopulations, aiming to build more explainable and individualized survival models. Following standard VAEs, \nSurvival-VAE encodes input covariates into a latent distribution and then decodes the latent distribution back to the input space by optimizing the ELBO objective. To model the individial risk, the authors add a learnable hazard function $h$ in the latent space that takes as input the latent features to predict risk by optimizing the partial likelihood. An additional masking objective is introduced to enable sample-specific feature selection. Finally, the authors propose a double-pass risk prediction by feeding the reconstructed input covariates to the VAE encoder and risk prediction function, which is a reminiscent of the IntroVAE."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The exploration of generative models (in contrast to discriminative models) for survival prediction is interesting and sound. The proposed double-pass prediction can further regularize the learned latent distributions. \n- The paper is theoretically justified. \n- Experimental results on miRNA cohorts demonstrate the effectiveness of the proposed method compared to strong baselines.\n- The paper is easy to follow."}, "weaknesses": {"value": "- The main focus of this paper is on developing explainable survival models. However, tree-based survival models (such as Survival Tree [3]), which are inherently interpretable. There are also some works that combine traditional survival tree and deep neural works (see e.g. [4]). However, this family of works is neither discussed nor included in the comparative analysis. \n- The Deep Survival Machine [1] is also a generative model for survival prediction. It would be interesting to see the comparison with this method. \n- Comparison to other survival models, such as discrete-time survival models (e.g., deephit [2]) is encouraged. \n- Ablations of different loss components are missing. \n- It is also meaningful to evaluate on standard survival benchmarks, e.g., METABRIC, SUPPORT.\n\n[1] Deep Survival Machines: Fully Parametric Survival Regression and Representation Learning for Censored Data with Competing Risk\n\n[2] DeepHit: A Deep Learning Approach to Survival Analysis With Competing Risks\n\n[3] Tree-structured survival analysis\n\n[4] SurvReLU: Inherently Interpretable Survival Analysis via Deep ReLU Networks"}, "questions": {"value": "- While Survival-VAE learns meaningful clusters, the mapping between latent factors and clinical variables is not deeply analyzed—making interpretability somewhat superficial.\n- Can the authors also provide evaluations using Integrated Brier Score (IBS)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "t5SO8gJHWo", "forum": "agnchf9dVn", "replyto": "agnchf9dVn", "signatures": ["ICLR.cc/2026/Conference/Submission8111/Reviewer_gT7q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8111/Reviewer_gT7q"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8111/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930312546, "cdate": 1761930312546, "tmdate": 1762920090809, "mdate": 1762920090809, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}