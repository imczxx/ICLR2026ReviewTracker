{"id": "X6QN8is120", "number": 1220, "cdate": 1756865844502, "mdate": 1759898220568, "content": {"title": "Blur to Focus Attention in Fine-Grained Visual Recognition", "abstract": "Fine-grained visual recognition (FGVR) requires distinguishing categories separated by tiny discriminative cues such as fine textures, part shapes, or color patterns. In typical datasets, discriminative regions occupy less than 30% of the image area, and in ultra-fine-grained cases often under 10%. This sparsity makes training highly fragile. Standard data augmentations risk destroying these subtle signals, while part-based or attention-driven models depend on annotations or rigid architectures and often fail under pose variation, occlusion, or cluttered backgrounds. We present DEFOCA, a simple layer that patchifies an image and stochastically applies Gaussian blur to selected patches. Each patch selection (e.g., random or contiguous) defines a single view, and multiple such views encourage the model to rely on diverse subsets of discriminative cues while reducing dependence on spurious background features. In this way, DEFOCA functions as a soft, attention-like mechanism that integrates seamlessly with existing architectures. Theoretically, we show that DEFOCA is label-safe, that contiguous patch layouts maximize the probability of label-safety, and that the expected representation drift is minimized. This guarantees that critical features are preserved while irrelevant high-frequency noise is suppressed, thereby narrowing the generalization gap. Empirically, DEFOCA achieves competitive performance on widely used fine-grained benchmarks (CUB-200-2011, Stanford Cars, NABirds, FGVC Aircraft) as well as ultra-fine-grained datasets (Cotton80, SoyGene, SoyGlobal). These results establish DEFOCA as a principled and highly effective solution for robust and discriminative feature learning in FGVR.", "tldr": "", "keywords": ["Ultra-fine-grained", "fine-grained", "attention", "blur-to-focus", "patchification"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8fae6a2a68193d3df05f2cb093c797393cefec5c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Submission 1220 proposes DEFOCA, a soft, attention-like mechanism for FGVR. It functions by blurring some randomly selected patch patterns of the image during training, aiming to strengthen the learning process of subtle discriminative features."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "DEFOCA achieves fair results with light parameter amount against existing baseline methods."}, "weaknesses": {"value": "1. FGVR is a relatively old topic, which is already thoroughly explored during the CNN-dominated period before 2019. The authors need to validate the necessity and practical value of their additional research investment in such area.\n2. The references are in general out-of-date. Most of them are more than 3 years ago, let alone some are more than 10 years ago.\n3. The method is still highly similar to MIM. In fact, compared to MIM, there is no essential difference by merely changing masking to blurring.\n4. It is hard to see significant improvement among Table 1 & 2. For Table 1, DEFOCA fails to achieve SOTA results; and even compared to a baseline with similar parameter amount (e.g. FIDO), there is no significant advantage. For Table 2, it is confusing that DEFOCA is marked bold face in some columns of SoyAging without the best result."}, "questions": {"value": "Please see the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Vkd9Y1AziM", "forum": "X6QN8is120", "replyto": "X6QN8is120", "signatures": ["ICLR.cc/2026/Conference/Submission1220/Reviewer_gKNU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1220/Reviewer_gKNU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1220/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760510089591, "cdate": 1760510089591, "tmdate": 1762915712383, "mdate": 1762915712383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DEFOCA, a lightweight “blur-to-focus” layer that partitiones images into patches and stochastically applies Gaussian blur to selected patches during training to encourage a network to rely on unblurred discriminative regions. The authors supply a theoretical analysis and extensive experiments on fine-grained and ultra-fine-grained datasets"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- DEFOCA is architecture-agnostic, applied on-the-fly after usual augmentations, and removed at test time, which makes it easy to adopt. \n- Results reported across standard FGVR datasets (CUB-200, Stanford Cars, NABirds, FGVC-Aircraft) and several ultra-fine-grained datasets show consistent gains.\n- The paper gives a concise theory grounding (label-safety probability, Lemma 1 on expected representation drift, Proposition 1 SNR argument) that clarifies why contiguous patch selection is beneficial."}, "weaknesses": {"value": "- Lemma 1 and subsequent bounds rely on an L-Lipschitz assumption for the feature map and an ad-hoc large constant M for when discriminative patches are altered. The analysis is conceptually fine, but it’s not clear how realistic the Lipschitz assumption is for modern deep nets or how large M is in practice.\n- Could DEFOCA be applied to current SOTA baselines and generate better performance?"}, "questions": {"value": "Please refer to the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o54icryv5X", "forum": "X6QN8is120", "replyto": "X6QN8is120", "signatures": ["ICLR.cc/2026/Conference/Submission1220/Reviewer_Lm8d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1220/Reviewer_Lm8d"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1220/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761588359900, "cdate": 1761588359900, "tmdate": 1762915712261, "mdate": 1762915712261, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a method called DEFOCA, a training-time, patch-wise Gaussian blur layer placed after standard augmentations. At each iteration, it selects image patches (random, dispersed, or contiguous) and blurs them to create stochastic views, aiming to suppress background/high-frequency noise and nudge the network toward discriminative regions. The authors provide an interpretation as implicit attention, a combinatorial label-safety argument, a bound on representation drift, and a PAC-Bayes generalization bound. Empirically, DEFOCA is plugged into ResNet and Tiny-ViT backbones and evaluated on various FGVC and UFGVC datasets. It is removed at test time. Results are generally competitive in comparison to Tiny-ViT baselines."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Motivation for FGVC fragility (small discriminative area, pose/occlusion/clutter) is well framed, and figures are illustrative.\n\nA simple, architecture-agnostic mechanism. Patch-blur as a layer is easy to adopt and integrates with standard backbones, with no labels or architectural edits needed.\n\nConsistent gains over Tiny-ViT/ResNet baselines across multiple datasets; qualitative maps/t-SNE show tighter clusters and more focused regions.\n\nThe paper varies patch layouts (random/contiguous/dispersed), operations (low-/high-pass, noise, colour jitter), and key hyperparameters (grid size P, ratio n/N, blur $\\sigma$), with contiguous low-pass emerging as best.\n\nNo test-time cost or architectural brittleness; ablations suggest robustness to reasonable hyperparameter ranges."}, "weaknesses": {"value": "Lack of novelty as it is close to known ideas (Cutout [1], Hide-and-Seek[2], DropBlock[3], Random Erasing[4], etc). The core is a localized degradation augmentation. The differentiator is “blur not mask” plus “contiguous patches,” but this is still an augmentation variant rather than a new learning principle. The paper should position against these families much more rigorously (same backbones, same training budgets, tuned strengths), not only via narrative.\n\nTo claim principled superiority, DEFOCA should be compared head-to-head against Cutout[1], Hide-and-Seek [2], DropBlock[3], Random Erasing[4], Mixup[5], CutMix [6] (and their FGVC-tuned strengths), RandAugment [7], TrivialAugment [8], AugMix[9], and a global Gaussian-blur-probability baseline under the same schedule/backbone. \n\nCurrent comparison tables exclude state-of-the-art patch-driven methods [10-12] whose FGVC performance is significantly higher (Aircraft > 96%, CUB-200 > 92%, Cars > 96%, NABirds > 92%) than the proposed approach, making SOTA positioning ambiguous. There are many SOTA approaches in [10] whose performances are significantly higher than the proposed approach, and they are excluded from the list. It is good to have a comparison with the SOTA approaches to justify. \n\nWhile attention maps look sharper, there’s no causal test that DEFOCA improves causal localization (e.g., counterfactual part perturbations, deletion/insertion metrics).\n\nThe theory assumes a hidden set of discriminative patches S and argues that contiguous selection maximizes label-safety. But S is unobserved, no estimator is used, and no sensitivity to misspecification is analyzed. The “contiguous maximizes Psafe” statement is asserted, not proven under realistic image statistics.\n\nThe drift bound assumes per-patch Lipschitz behaviour and an M >> Ln gap when discriminative patches are hit. This is plausible but not verified empirically. The PAC-Bayes inequality is boilerplate and does not yield a sharper or measurable bound tied to DEFOCA’s specifics (e.g., to $\\sigma$, n/N, or contiguity).\n\nThere’s no human-part or saliency-overlap evaluation showing blurred regions avoid critical parts more often with a contiguous layout vs a random.\n\nClaims about occlusion/pose/clutter robustness would be stronger with corruption/occlusion suites (e.g., defocus/zoom blur, occludes) and partial visibility tests, plus calibration under shift. Qualitative maps are suggestive but insufficient.\n\nThe paper sets V=8 views but does not show the accuracy vs compute curve as V varies, or the effect of $\\sigma$ when it does touch discriminative parts. Also missing: train-time cost, and analysis of interactions with standard augmentations (is DEFOCA still helpful atop RandAugment+Mixup+CutMix?)\n\nIt’s not fully clear that every baseline uses the same augmentation stack, epochs, parameter count, and tuning budget. Without a unified training protocol table, fairness is hard to judge.\n\n\n[1] DeVries, T., & Taylor, G. W. (2017). Improved regularization of convolutional neural networks with Cutout. arXiv:1708.04552.\n\n[2] Singh, K.K., Yu, H., Sarmasi, A., Pradeep, G. and Lee, Y.J., 2018. Hide-and-seek: A data augmentation technique for weakly-supervised localization and beyond. arXiv preprint arXiv:1811.02545. ICCV 2017.\n\n[3] Ghiasi, G., Lin, T.-Y., & Le, Q. V. (2018). DropBlock: A regularization method for convolutional networks. NeurIPS.\n\n[4] Zhong, Z., Zheng, L., Kang, G., Li, S., & Yang, Y. (2020). Random Erasing Data Augmentation. AAAI.\n\n[5] Zhang, H., Cisse, M., Dauphin, Y., & Lopez-Paz, D. (2018). Mixup: Beyond empirical risk minimization. ICLR.\n\n[6] Yun, S., Han, D., Oh, S. J., Chun, S., Choe, J., & Yoo, Y. (2019). CutMix: Regularization strategy to train strong classifiers with localizable features. ICCV.\n\n[7] Cubuk, E. D., Zoph, B., Shlens, J., & Le, Q. V. (2020). RandAugment: Practical automated data augmentation with a reduced search space. CVPR Workshops.\n\n[8] Müller, S. G., & Hutter, F. (2021). TrivialAugment: Tuning-free yet state-of-the-art data augmentation. ICCV.\n\n[9] Hendrycks, D., Mu, N., Cubuk, E. D., Zoph, B., Gilmer, J., & Lakshminarayanan, B. (2020). AugMix: A simple data processing method to improve robustness and uncertainty. ICLR.\n\n[10] Sikdar, A., Liu, Y., Kedarisetty, S., Zhao, Y., Ahmed, A. and Behera, A., 2025. Interweaving insights: High-order feature interaction for fine-grained visual recognition. International Journal of Computer Vision, 133(4), pp.1755-1779.\n\n[11] Behera, A., Wharton, Z., Hewage, P., & Bera, A. (2021). Context-aware attentional pooling (CAP) for fine-grained visual classification. AAAI conference on artificial intelligence (pp. 929–937)\n\n[12] Bera, A., Wharton, Z., Liu, Y., Bessis, N., & Behera, A. (2022). SR-GNN: Spatial relation-aware graph neural network for fine-grained image categorization. IEEE Transactions on Image Processing, 31, 6017–6031"}, "questions": {"value": "How does DEFOCA compare to the SOTA approaches in references [10-12]?\n\nHow does DEFOCA compare, under identical backbones/schedules, to Cutout, Hide-and-Seek, DropBlock, Random Erasing, Mixup/CutMix, RandAugment/TrivialAugment/AugMix, and global random Gaussian blur with tuned probability and kernel?\n\nWhat is the accuracy vs V curve (e.g., 1/2/4/8/16 views)? What is the train-time overhead (wall-clock, GPU hours) attributable to DEFOCA as V increases?\n\nYour theory hinges on avoiding discriminative patches. What happens when blur does overlap S (e.g., high $\\sigma$, small patches)? \n\nPlease provide sensitivity sweeps ($\\sigma$, n/N, P) with attention-overlap metrics (e.g., % of CAM/Grad-CAM mass blurred) and accuracy drops.\n\nCan you add corruption/occlusion evaluations (defocus/zoom blur, cutout occludes) and partial-visibility protocols to quantify robustness?\n\nYou assert that contiguous maximizes label-safety. Can you formalize the distributional assumptions under which this is true and add an empirical check?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "w5TrWxBWgR", "forum": "X6QN8is120", "replyto": "X6QN8is120", "signatures": ["ICLR.cc/2026/Conference/Submission1220/Reviewer_dQCx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1220/Reviewer_dQCx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1220/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761662730118, "cdate": 1761662730118, "tmdate": 1762915712042, "mdate": 1762915712042, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DEFOCA, a stochastic defocus layer that applies Gaussian blur to image patches to encourage fine-grained visual recognition (FGVR) models to focus on discriminative regions. The method is theoretically grounded—analyzing label-safety, representation drift, and generalization—and can be easily integrated into existing architectures. Experiments show competitive results across multiple FGVR and ultra-fine-grained datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Simple, lightweight, and architecture-agnostic design requiring no additional supervision.\n\n2. Solid theoretical analysis connecting stochastic blurring with representation stability and generalization.\n\n3. Comprehensive experimental evaluation with clear visualization of attention and feature clustering.\n\n4. Good writing and clear motivation for tackling the challenges of fine-grained visual recognition."}, "weaknesses": {"value": "1. Performance is weak compared to the state-of-the-art. As shown in Table 1, the mean accuracy of DEFOCA-Tiny ViT (91.9%) is significantly below the current best (93.5%) despite similar or larger model scales.\n\n2. Marginal gain in parameter efficiency. Even considering model size, ACNet-R50 (25 M parameters, published five years ago) achieves 91.7%—only 0.2% lower—suggesting the improvement is not statistically significant at this scale.\n\n3. Unbalanced model comparison. The authors compare their Tiny ViT variant against larger baselines (e.g., ViT-Base) but do not report smaller configurations of those methods. A fairer comparison would use matched model sizes (e.g., ViT-Tiny or equivalent small-scale backbones).\n\n4. The paper lacks strong justification for why DEFOCA’s regularization mechanism leads to superior generalization beyond mild smoothing effects, especially when similar results could arise from existing data augmentation or attention regularizers."}, "questions": {"value": "1. How statistically significant are the reported improvements across runs and datasets?\n\n2. Can DEFOCA outperform simple augmentations like CutMix or DropBlock under controlled comparisons?\n\n3. Have you evaluated smaller versions of other SOTA methods for fair model-scale comparison?\n\n4. How sensitive is DEFOCA to the number of stochastic views (V = 8) and blur strength σ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8tNhdG0n1t", "forum": "X6QN8is120", "replyto": "X6QN8is120", "signatures": ["ICLR.cc/2026/Conference/Submission1220/Reviewer_9wsV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1220/Reviewer_9wsV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1220/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762328553359, "cdate": 1762328553359, "tmdate": 1762915711899, "mdate": 1762915711899, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}