{"id": "fQ0ESh72CK", "number": 6481, "cdate": 1757986694736, "mdate": 1763058656511, "content": {"title": "SM-ShapNAS: Shapley-Enhanced Multimodal Neural Architecture Search via Sparse Modeling", "abstract": "Despite their excellent performance on various multimodal learning tasks, deep neural networks (DNNs) are often characterized as \"black boxes\". Some techniques aid in designing explainable DNNs. For instance, sparse modeling limits the sparsity while preserving key features, and the Shapley value from game theory quantifies the true contribution of each component, both of which are recognized for their strong explainability. However, designing explainable multimodal DNNs by manually designing unimodal backbones and multimodal feature fusion models requires substantial expertise and time. This paper proposes a novel multimodal neural architecture search (NAS) method, termed Shapley-Enhanced Multimodal Neural Architecture Search via Sparse Modeling (SM-ShapNAS), for automating the design of appropriate and explainable multimodal DNNs. SM-ShapNAS incorporates sparse attention and sparse convolutional operations within a predefined search space, and uses the Shapley value approximated by group policy to evaluate the true contribution of each operation in the fusion cells. By combining sparse modeling and the Shapley value, the proposed SM-ShapNAS automatically generates efficient and explainable multimodal DNNs. Experimental results on three multimodal datasets demonstrate that the SM-ShapNAS achieves competitive performance compared to the state-of-the-art multimodal NAS methods, particularly in noisy environments.", "tldr": "", "keywords": ["Neural architecture search", "Multimodal learning", "Sparse modeling", "Shapley value", "Explainability"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/d66362d86144d2edcd415f28d70367c7803bdb87.pdf", "supplementary_material": "/attachment/8557e7176ce32a87e6f7f65498dd6f6c71108e69.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a multimodal neural architecture search method for automating the design of appropriate and explainable multimodal DNNs. Specifically, the proposed method incorporates sparse attention and sparse convolutional operations within a predefined search space, and uses the Shapley value approximated by group policy to evaluate the true contribution of each operation in the fusion cells."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Using shaplely value is a great choice to make NAS more explainable."}, "weaknesses": {"value": "1. The motivation of sparse modeling is not clearly clarified. Why the sparse modeling is a necessity? Please clarify its motivation.\n\n2. P in Algorithm is not defined. Besides, the input in Algorithm is missing.\n\n3. The explanation for the physical meaning of the first part of Eq. (8) is missing. What is the definition of $P(group = kg)$?\n\n4. How about the Monte Carlo sampling error for Eq. (9)? Authors should experimentally evaluate the stability of the Monte Carlo sampling and the magnititude of such sample error to ensure the reliability of the sampling.\n\n5. Authors do not explain clearly how to get Eqs. (10)--(12). Please clarify clearly.\n\n6. The experiments are limited to two modalities per task. Can the proposed method generalize to  tasks with three or more modalities, such as video + audio + text ?\n\n7. The experiments focus heavily on comparing with other NAS methods but lack comparison with strong hand-designed multimodal models or non-NAS explainable models. This makes it difficult to assess the absolute advantage of the proposed framework."}, "questions": {"value": "Please refer to weaknesses, especially the intuition of sparse modeling and approximation details.\nIf all my problems are addressed, I will increase my rating."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Lc2quKbv1W", "forum": "fQ0ESh72CK", "replyto": "fQ0ESh72CK", "signatures": ["ICLR.cc/2026/Conference/Submission6481/Reviewer_HLmT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6481/Reviewer_HLmT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6481/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760924480145, "cdate": 1760924480145, "tmdate": 1762918859553, "mdate": 1762918859553, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "wrg7CaNOBP", "forum": "fQ0ESh72CK", "replyto": "fQ0ESh72CK", "signatures": ["ICLR.cc/2026/Conference/Submission6481/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6481/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763058655303, "cdate": 1763058655303, "tmdate": 1763058655303, "mdate": 1763058655303, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces SM-ShapNAS to address the challenge of designing explainable and efficient deep neural networks. The method combines the concept of sparse modeling and Shapley values. SM-ShapNAS showed higher performance compared to other NAS methods. While the paper proposes a novel approach to the problem, the low readability makes it hard to grasp the details and the key contributions."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- SM-ShapNAS presents a novel approach of integrating two powerful explainability techniques, sparse modeling and Shapley values, into a multimodal NAS framework."}, "weaknesses": {"value": "- The readability of the paper is low, and it was hard to follow the details and the key contributions. Many context-specific jargons were used without any definition or clarification.\n- When comparing with other baselines (e.g., in table 2), the control for model sizes is lacking.\n- The search space is narrow, and its generalizability or practical implication are limited."}, "questions": {"value": "- What is the definition of “cell” or “fusion cell”?\n- “Algorithm 1 shows the search process, which follows DARTS to alternatively optimize architecture parameters and model weight” What does DARTS mean here?\n- What does group policy mean?\n- Why does the complexity of Shapley value computation go down from O(N · 2^N) to O(mN) after grouping? I understand that the estimates could converge faster as the number of players has decreased, but why does the exponential term also completely disappear?\n- Can you discuss the specific advantages and niche of this NAS-based approach compared to other popular strategies like training large models and subsequent pruning, especially for practical implications?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gmG0HE2z33", "forum": "fQ0ESh72CK", "replyto": "fQ0ESh72CK", "signatures": ["ICLR.cc/2026/Conference/Submission6481/Reviewer_U852"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6481/Reviewer_U852"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6481/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761889140450, "cdate": 1761889140450, "tmdate": 1762918859215, "mdate": 1762918859215, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SM-ShapNAS, a novel explainable multimodal neural architecture search (NAS) framework that integrates sparse modeling and grouped Shapley value estimation. \n\nIts main contributions are: \n\n(1) a search space incorporating both normal and sparse operations (e.g., sparse attention and sparse convolution) to enhance feature extraction and robustness; \n\n(2) an efficient evaluation mechanism that approximates the Shapley value via group policy and Monte Carlo sampling to fairly quantify each operation’s true contribution;\n\n (3) an end-to-end differentiable NAS framework that updates architecture parameters based on estimated Shapley values rather than gradient magnitudes; \n\n(4) extensive experiments on three multimodal benchmarks (MM-IMDB, NTU RGB+D, EgoGesture) demonstrating state-of-the-art performance, particularly under noisy conditions, along with comprehensive ablation studies validating the effectiveness of both sparse modeling and the grouped Shapley strategy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The work demonstrates strong originality through a creative synthesis of two theoretically grounded concepts—sparse modeling and Shapley value attribution—within the context of multimodal NAS, a domain where explainability has been largely overlooked. While sparse operations and Shapley-based evaluation have appeared separately in prior literature (e.g., Shapley-NAS for unimodal tasks, sparse coding for interpretability), their joint integration into a differentiable multimodal NAS framework is novel.\n\nThe paper is well-structured and clearly written. The narrative flows logically from problem motivation to technical design (search space, Shapley evaluation) to validation (experiments, ablations, visualizations)."}, "weaknesses": {"value": "Noise is only applied to image modalities, but real-world multimodal systems often suffer from asynchronous or modality-specific corruption (e.g., missing text, noisy depth, occluded poses). The claim of “robustness in noisy environments” would be stronger if add experiments with cross-modality noise or modality dropout, aligning with recent robust multimodal benchmarks."}, "questions": {"value": "While SM-ShapNAS is a promising step toward explainable multimodal NAS, its claims of robustness, efficiency, and explainability require deeper validation. Addressing the above points like broader noise scenarios and quantitative explainability metrics would significantly strengthen the contribution and align it more closely with its stated goals."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "SDSa6fWsWy", "forum": "fQ0ESh72CK", "replyto": "fQ0ESh72CK", "signatures": ["ICLR.cc/2026/Conference/Submission6481/Reviewer_4e7q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6481/Reviewer_4e7q"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6481/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927168716, "cdate": 1761927168716, "tmdate": 1762918858897, "mdate": 1762918858897, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SM-ShapNAS, a multimodal neural architecture search (NAS) framework that aims to improve both efficiency and explainability by combining sparse modeling and Shapley-value–based operation evaluation. Within a predefined search space containing both normal and sparse operations, the method estimates grouped Shapley values (via Monte Carlo sampling and group policy) to assess each operation’s contribution to the overall architecture. Sparse convolution and sparse attention layers are included to enhance noise robustness and model interpretability. Experiments on three multimodal datasets show competitive or slightly improved performance compared to previous NAS baselines such as BM-NAS and DC-NAS."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper makes a clear attempt to integrate explainability concepts into multimodal NAS. Using Shapley values to quantify operation contributions is conceptually coherent with the motivation of fair attribution, and adopting sparse operations is a reasonable choice for improving robustness under noise. The framework is complete, with explicit pseudocode, mathematical definitions, and ablation studies. The implementation appears reproducible, and experiments span multiple datasets, offering empirical breadth."}, "weaknesses": {"value": "- The paper’s technical novelty is limited and its claimed interpretability remains superficial. The use of Shapley values to evaluate architecture components has already appeared in prior work such as Shapley-NAS (Xiao et al., 2022), and this paper extends it mainly by grouping operations and applying Monte Carlo estimation—both standard approximations that add little methodological depth. \n\n- The “group policy” mechanism is under-explained and lacks formal analysis of its convergence or bias. \n\n- The integration of sparse modeling is mostly additive: the sparse attention and sparse convolution layers follow standard formulations and do not fundamentally change the NAS optimization process. As a result, the contribution lies more in combining existing ideas rather than introducing a new algorithmic insight.\n\n- The theoretical framing of the Shapley evaluation is also weakly justified. The architecture-search process still depends on differentiable relaxation (as in DARTS), but the grouped Shapley update (Eq. 10–12 in the paper) is grafted onto this process without explaining how it interacts with gradient-based optimization or what stability guarantees it provides. The cooperative-game analogy is conceptually appealing but mathematically shallow, as the payoff function (validation accuracy) is treated as a noisy, non-additive measure that invalidates the linear-value assumptions of Shapley theory. Furthermore, the paper does not demonstrate that the derived architectures are actually more explainable—no visualization, attribution trace, or qualitative interpretation is shown to support this claim.\n\n- Empirically, the reported gains over BM-NAS and DC-NAS are marginal (e.g., +0.5–1 % on most datasets), and the claimed noise robustness lacks statistical significance testing. Many experimental settings reuse strong pretrained unimodal backbones, meaning improvements could come from data handling rather than the NAS procedure itself. The discussion sections (especially 4.3 and 4.4) mostly restate numerical comparisons without deeper insight into why grouped Shapley evaluation changes the search dynamics."}, "questions": {"value": "- How does the grouped Shapley update interact with gradient-based optimization in DARTS? Does it replace or augment alpha-updates, and what guarantees of convergence or monotonic improvement exist?\n\n- The cooperative-game analogy assumes additivity of payoff contributions. How is this justified when operation effects are non-linear and interdependent?\n\n- Can the authors provide any interpretability evidence (e.g., feature-importance visualizations or contribution maps) beyond scalar fidelity metrics?\n\n- How sensitive are the results to the number of Monte Carlo samples (mn, ms) and the grouping scheme? Are these hyperparameters tuned per dataset?\n\n- Does the proposed framework generalize beyond two-modality fusion (e.g., tri-modal or cross-temporal settings), and how would computational cost scale?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Uy6nuTyXBY", "forum": "fQ0ESh72CK", "replyto": "fQ0ESh72CK", "signatures": ["ICLR.cc/2026/Conference/Submission6481/Reviewer_cfuV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6481/Reviewer_cfuV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6481/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762189106122, "cdate": 1762189106122, "tmdate": 1762918858362, "mdate": 1762918858362, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}