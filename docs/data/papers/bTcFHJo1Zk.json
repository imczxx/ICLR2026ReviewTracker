{"id": "bTcFHJo1Zk", "number": 6562, "cdate": 1757989012121, "mdate": 1763435990975, "content": {"title": "Learning From Dictionary: Enhancing Robustness of Machine-Generated Text Detection in Zero-Shot Language via Adversarial Training", "abstract": "Machine-generated text (MGT) detection is critical for safeguarding online content integrity and preventing the spread of misleading information. \nAlthough existing detectors achieve high accuracy in monolingual settings, they exhibit severe performance degradation on zero-shot languages and are vulnerable to adversarial attacks. \nTo tackle these challenges, we propose a robust adversarial training framework named \n\\textbf{T}ranslation-based \n\\textbf{A}ttacker \n\\textbf{S}trengthens \nMul\\textbf{T}ilingual \nDef\\textbf{E}nder (\\detectorname). \n\\detectorname comprises two core components: an attacker that performs code-switching by querying translation dictionaries to generate adversarial examples, and a detector trained to resist these attacks while generalizing to unseen languages. \nWe further introduce a novel Language-Agnostic Adversarial Loss (LAAL), which encourages the detector to learn language-invariant feature representations and thus enhances zero-shot detection performance and robustness against unseen attacks. \nAdditionally, the attacker and detector are synchronously updated, enabling continuous improvement of defensive capabilities. \nExperimental results on 9 languages and 8 attack types show that our \\detectorname surpasses 8 SOTA detectors, improving the average F1 score by \\textbf{0.064} and reducing the average Attack Success Rate (ASR) by \\textbf{3.8\\%}.\nOur framework offers a promising approach for building robust, multilingual MGT detectors with strong generalization to real-world adversarial scenarios.\nWe will release our code, models, and dataset upon acceptance.", "tldr": "This paper proposes an adversarial training approach to enhance the robustness of machine-generated text detection in zero-shot languages against adversarial attacks.", "keywords": ["Large Language Model", "Adversarial Training", "Machine Generated Text Detection"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/795381aa6ae30a7ea12c18f053e13d57a32cb857.pdf", "supplementary_material": "/attachment/a789c64d87d5e53f03c4fb1afdfd190a2be87761.zip"}, "replies": [{"content": {"summary": {"value": "The paper addresses the challenge of building robust multilingual machine-generated text (MGT) detectors when low-resource languages lack labeled training data.\n\nIt proposes TASTE (Translation-based Attacker Strengthens Multilingual Defender), a framework that conducts adversarial training using a translation dictionary and surrogate modeling under a black-box setting.\n\nThe core idea is to let an attacker perform cross-lingual code-switching using important token gradients while the detector learns language-invariant representations through a new loss called Language-Agnostic Adversarial Loss (LAAL)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces a novel translation-based adversarial training framework that effectively leverages multilingual dictionaries under a black-box setting to address the data scarcity problem in low-resource languages.\n2. The proposed attacker-detector adversarial mechanism and the Language-Agnostic Adversarial Loss (LAAL) jointly enable the detector to learn language-invariant features, enhancing robustness and cross-lingual generalization.\n3. Experiments on 9 languages and 8 attacks show significant improvements in F1 score."}, "weaknesses": {"value": "1. The attacker’s token-importance estimation relies on a surrogate model distilled from target labels, where importance is computed as the gradient of the loss with respect to individual tokens. It would strengthen the work to include ablation studies comparing alternative importance metrics (e.g., attention-based or perturbation-based methods?). In addition, Eq. (4) introduces a hyperparameter $k$ whose size likely affects the attack strength.\n2. The method perturbs token-level translations from a dictionary, which does not account for phrase-level paraphrasing. Robustness against broader multilingual or adaptive attack forms remains insufficiently explored.\n3. The co-evolution process between the attacker and detector requires multiple updates per iteration, which increases computational overhead and may limit scalability to larger datasets."}, "questions": {"value": "1. Since the surrogate model is trained using pseudo-labels from the target, how does label noise or prediction bias affect the gradient quality and the attacker’s reliability in the black-box setting? Currently this surrogate model is implemented using  GPT2. How about a smaller model?\n2. The alternating training between the attacker and detector does not include a convergence or stability analysis. Could the authors provide evidence or discussion on whether the training dynamics reach equilibrium or exhibit oscillation?\n3. Could the authors conduct ablation studies on key hyperparameters identified in the weakness section to assess their impact on performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "f3x6n2q7Qg", "forum": "bTcFHJo1Zk", "replyto": "bTcFHJo1Zk", "signatures": ["ICLR.cc/2026/Conference/Submission6562/Reviewer_aEgz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6562/Reviewer_aEgz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6562/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959714200, "cdate": 1761959714200, "tmdate": 1762918901846, "mdate": 1762918901846, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the critical challenges of zero-shot generalization and adversarial robustness in multilingual machine-generated text (MGT) detection by proposing TASTE, a novel adversarial training framework. The approach integrates a code-switching attacker leveraging translation dictionaries with a detector trained using a Language-Agnostic Adversarial Loss (LAAL) to learn language-invariant representations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The figures in the paper are presented with exceptional clarity.\n2.The paper's underlying assumptions are sound, and the writing is accessible and easy to understand."}, "weaknesses": {"value": "1. Additional evaluation dimensions are needed. For instance, metric-based detectors require no training, whereas model-based detectors do. The authors should disclose the associated training costs (e.g., time, computational resources).\n2. Potential unfair comparison. Among the model-based detectors, RADAR, GREATER-D, and TASTE employ adversarial training, while the other methods do not. It is uncertain whether this constitutes a fair comparison.\n3. Suboptimal performance of TASTE. The experimental results for TASTE are relatively weak, rarely achieving state-of-the-art outcomes.\n4. Lack of comprehensive ablation studies. The paper seems to lack genuine ablation experiments. The authors should perform ablations on the individual loss components in Equation (8) and the various modules of TASTE, rather than conducting only limited experiments in Section B.1 of the appendix.\n5. Conventional methodology. The methods section appears somewhat standard, lacking significant innovation."}, "questions": {"value": "In the model-based detectors, the authors consistently use pre-trained models. Would the performance be improved if LLMs were employed instead?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OvrcQLgjXx", "forum": "bTcFHJo1Zk", "replyto": "bTcFHJo1Zk", "signatures": ["ICLR.cc/2026/Conference/Submission6562/Reviewer_S8Qh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6562/Reviewer_S8Qh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6562/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984994520, "cdate": 1761984994520, "tmdate": 1762918901435, "mdate": 1762918901435, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce an improvement method for LLM-generated text detection in a multilingual setting based on selective vocabulary-based translation to other languages of tokens detected as important for generated text detection in a surrogate model. The authors demonstrate better performance of their model on the languages used in training, as well as on previously unseen languages, and conduct generalization and ablation analyses."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Low-resource detection of LLM-generated texts is a critical and timely subject. With the development of massively multilingual LLMs, the communities that have been previously shielded from information operations are likely to become reachable by attackers. As the authors have mentioned, the vast majority of LLM-generated text detection work has focused on the English language, with even the most dominant commercial options supporting a limited selection of high-resource languages, leaving the inherent lack of performance of LLMs as the only viable detection method, which is not sustainable in the long term/ \n\nTo achieve this, authors combine several existing well-performing methods, such as surrogate models, detection-relevant token identification, adversarial learning, and single-word vocabulary-based translation, in a non-trivial manner.\n\nAdditionally:\n- Authors provide a clear and realistic threat model\n- Authors select relevant baselines, for both zero-shot detection and a base model for fine-tuning\n- Authors check the method generalization to previously unseen languages\n- Authors examine the resilience of their method to adversarial attacks, which is the currently most salient issue with LLM detectors\n- Evaluation of dictionary error impact, which is essential for low-resource languages, where high-quality dictionaries do not exist or cannot be defined due to the inherent diversity and heterogeneity of low-resource languages. \n- Clear path to a defensive use of an LLM for security work\n- Computational resource-aware experiments"}, "weaknesses": {"value": "While the manuscript and the underlying ideas are both overall excellent, it has several shortcomings in its current state. Specifically: \n\n- Authors do not share code, making it impossible to evaluate the contribution or prove that work has been actually performed and would be replicable. Evaluation of papers whose main contribution is a novel algorithm is impossible without the artifacts used to generate them, and the promise of publication upon release is insufficient.\n- The selection of performance metrics (F1 and Acc) is not consistent with the current best practices in the LLM detection research. Namely, given the threat model of real-world deployment of LLM detectors, the recommended and generally adopted metric in the field is TPR @ fixed low FPR [1]. The use of accuracy and F1 scores is inconsistent with this threat model, making comparisons somewhat difficult, especially since more recent LLM detection methods, particularly zero-shot ones such as Binoculars and Fast DetectGPT, were optimized for TPR at a fixed low FPR, potentially sacrificing performance on other metrics. I strongly suggest that authors replicate at least some of their result tables with the relevant performance metrics, showing consistency with the rest of the field. \n- Autoencoder LLMs fine-tuned for detection are known to perform well and generalize well on the in-distribution training data, but demonstrate problematic FPR on the out-of-distribution texts [2]. While the authors try to account for it by evaluating the performance of autoencoders trained on the English part of the M4 dataset on the Semeval-2024/8 dataset, they do not report the FPR scores with the same parameters as would be used for a TPR@fixed low FPR on the M4 dataset, making it impossible to evaluate this potential failure mode.\n\n[1] Carlini, N., Chien, S., Nasr, M., Song, S., Terzis, A., & Tramèr, F. (2021). Membership Inference Attacks From First Principles. 2022 IEEE Symposium on Security and Privacy (SP), 1897-1914.\n\n[2] Gameiro, H.D., Kucharavy, A., & Dolamic, L. (2024). LLM Detectors Still Fall Short of Real World: Case of LLM-Generated Short News-Like Posts. ArXiv, abs/2409.03291."}, "questions": {"value": "- The detection-critical identification method seems to be focusing on tokens, whereas translation dictionaries use words. How do you transition from one to another?\n\n- L263: You mention that the gradient flow through the language discriminator erases the language-specific clues. Could you please elaborate as to why?\n\n- L464: Why do you expect the performance of dictionary errors to be the same as the performance of detection models in English, which is the base training language for the model? \n\n- L130-132: RADAR detector cited as the prior work seems to perform poorly compared to other methods on standardized benchmarks, notably RAID [3]. Could you please elaborate on why your method appears to be performing better than RADAR, which uses a similar approach? \n\n[3] Dugan, L., Hwang, A., Trhlik, F., Ludan, J.M., Zhu, A., Xu, H., Ippolito, D., & Callison-Burch, C. (2024). RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors. ArXiv, abs/2405.07940."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "irf9LrgVCi", "forum": "bTcFHJo1Zk", "replyto": "bTcFHJo1Zk", "signatures": ["ICLR.cc/2026/Conference/Submission6562/Reviewer_CasE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6562/Reviewer_CasE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6562/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991691021, "cdate": 1761991691021, "tmdate": 1762918900987, "mdate": 1762918900987, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper propose TASTE, a two-component framework that helps to train a robust multilingual MGT detector. Specifically, includes two core parts. The adversarial attacker generates code-switched or partially translated adversarial examples via dictionary-based perturbation, while the detector is trained jointly with a  language-agnostic loss to encourage language-invariant features and resilience against unseen perturbations. Experiments results show that TASTE outperforms eight SOTA detectors, and ablation studies further suggest the importance of LAAL."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed training method is useful and could enhance the effectiveness of MGT detectors.\n2. The motivation and logic of this paper is clear.\n3. The proposed method is model-agnostic and can be used on existing detectors ."}, "weaknesses": {"value": "1. The construction of the adversarial examples rely on existing dictionaries, yet how about the performance of this method on low-resource language tasks, where high-quality dictionary may not exist?\n2. It would strengthen the paper to include human annotation to study whether the generated adversarial examples remain natural and human-readable."}, "questions": {"value": "Please see my reviews above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "D3Sv3hVoFx", "forum": "bTcFHJo1Zk", "replyto": "bTcFHJo1Zk", "signatures": ["ICLR.cc/2026/Conference/Submission6562/Reviewer_9HJS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6562/Reviewer_9HJS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6562/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762105148894, "cdate": 1762105148894, "tmdate": 1762918900507, "mdate": 1762918900507, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper propose TASTE, a two-component framework that helps to train a robust multilingual MGT detector. Specifically, includes two core parts. The adversarial attacker generates code-switched or partially translated adversarial examples via dictionary-based perturbation, while the detector is trained jointly with a  language-agnostic loss to encourage language-invariant features and resilience against unseen perturbations. Experiments results show that TASTE outperforms eight SOTA detectors, and ablation studies further suggest the importance of LAAL."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed training method is useful and could enhance the effectiveness of MGT detectors.\n2. The motivation and logic of this paper is clear.\n3. The proposed method is model-agnostic and can be used on existing detectors ."}, "weaknesses": {"value": "1. The construction of the adversarial examples rely on existing dictionaries, yet how about the performance of this method on low-resource language tasks, where high-quality dictionary may not exist?\n2. It would strengthen the paper to include human annotation to study whether the generated adversarial examples remain natural and human-readable."}, "questions": {"value": "Please see my reviews above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "D3Sv3hVoFx", "forum": "bTcFHJo1Zk", "replyto": "bTcFHJo1Zk", "signatures": ["ICLR.cc/2026/Conference/Submission6562/Reviewer_9HJS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6562/Reviewer_9HJS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6562/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762105148894, "cdate": 1762105148894, "tmdate": 1763476010165, "mdate": 1763476010165, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "Dear AC and Reviewers,\n\nWe sincerely thank you for your time and thoughtful feedback. We are very encouraged that our method is seen as **“a novel translation-based adversarial training framework”** (aEgz), whose training procedure is **“useful and enhance the effectiveness of MGT detectors”** and **“model-agnostic and can be used on existing detectors”** (9HJS), and that it **“combine several existing well-performing methods … in a non-trivial manner”** (CasE). We appreciate that our problem is recognized as **“a critical and timely subject” in low-resource LLM-generated text detection\"** (CasE), and that TASTE is viewed as **“enhancing robustness and cross-lingual generalization” with “significant improvements in F1 score”** (aEgz). We are also grateful for the positive comments on clarity and presentation, including **“exceptional clarity” of figures, “underlying assumptions are sound”, and “writing is accessible and easy to understand”**(S8Qh), as well as **“the manuscript and the underlying ideas are both overall excellent”** (CasE) and **“the motivation and logic of this paper is clear”**(9HJS).\n\nIn our rebuttal, we have carefully addressed every weakness (W) and question (Q):\n\n* **Reviewer 9HJS.**\n  We clarified that TASTE is explicitly designed for zero-shot low-resource languages and already outperforms all baselines on languages without dictionaries. We added a dictionary coverage study (10–100%) showing that even small/noisy dictionaries still bring substantial gains over the best baseline, and we conducted a human evaluation (3 annotators, 100 pairs, 3 dimensions) confirming that adversarial examples remain readable and coherent, with only moderate and expected degradation.\n\n* **Reviewer CasE.**\n  We clarified that the full implementation (code, requirements, documentation) has been in the supplementary material since before the review phase, and we will release code, datasets, and checkpoints on GitHub and Hugging Face upon acceptance. We added TPR@FPR=1% results on M4 (where TASTE achieves the best cross-lingual mean TPR) and TPR/FPR on SemEval-2024 (OOD) at the same thresholds, and we detailed the token→word mapping for dictionary substitution, how LAAL with gradient reversal suppresses language-specific cues, how performance degrades gracefully as dictionary errors increase, and the methodological differences from RADAR that explain TASTE’s stronger multilingual robustness.\n\n* **Reviewer S8Qh.**\n  We enriched the evaluation by reporting training cost (about 40 minutes for 3 epochs on a single RTX 4090) and adding a full inference-time comparison, showing that encoder-based detectors like TASTE have much lower latency than metric-based methods, which is crucial for deployment. We clarified fairness by noting that all adversarially trained methods (RADAR, GREATER-D, TASTE) share the same mBERT backbone and setup, and we showed that under deployment-relevant metrics (TPR@FPR=1%), zero-shot settings, and OOD robustness, TASTE achieves state-of-the-art average performance across languages and attacks. We summarized our existing loss and hyperparameter ablations (attack strength and dictionary quality) and explained our focus on encoder-only detectors (efficiency, calibration, stable thresholds), while pointing to LLM-based detectors as future work.\n\n* **Reviewer aEgz.**\n  We added extensive ablations on importance estimators, comparing attention-based, perturbation-based, and random variants against our gradient-based design on multilingual accuracy and attack success rate, and found that the gradient-based TASTE gives the best cross-lingual accuracy and lowest mean attack success. We linked the key hyperparameter controlling attack strength to our analysis in Section 6.1 on replacement ratio versus accuracy, robustness, and training time, highlighted that our robustness evaluation already includes strong phrase-level multilingual attacks (back-translation, paraphrasing) on 9 languages and 8 attacks where TASTE has the lowest average attack success rate, and quantified the cost of our co-evolution training (one attacker update and one detector update per batch, about 40 minutes on 10k samples with ~10 GB GPU). We also introduced experiments on pseudo-label noise (0/10/20% flips) and smaller surrogates (ALBERT-base-v2, Pythia-70M), showing that TASTE remains robust to realistic noise levels and does not rely on a large surrogate, and we examined training dynamics, with loss curves and a brief stability discussion to be added in the revised manuscript.\n\nWe again thank the AC and all reviewers for their constructive feedback, which has helped us substantially strengthen the paper. If you have any further questions or suggestions, we would be very happy to discuss them during the rebuttal period and will respond as promptly as possible."}}, "id": "b7kyt4nRBR", "forum": "bTcFHJo1Zk", "replyto": "bTcFHJo1Zk", "signatures": ["ICLR.cc/2026/Conference/Submission6562/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6562/Authors"], "number": 17, "invitations": ["ICLR.cc/2026/Conference/Submission6562/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763257692617, "cdate": 1763257692617, "tmdate": 1763257692617, "mdate": 1763257692617, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Revised version has already uploaded"}, "comment": {"value": "Dear AC and Reviewers,\n\nWe would like to once again thank you for your careful reading of our submission and for the many constructive comments and suggestions. We have now uploaded a revised version of the manuscript that incorporates all the changes discussed in our rebuttal.\n\nFor ease of cross-referencing between your reviews and the revised manuscript, we have highlighted the newly added or substantially revised text in different font colors according to the reviewer whose comments they address: **red** for Reviewer 9HJS, **blue** for Reviewer CasE, **orange** for Reviewer S8Qh, and **green** for Reviewer aEgz. All line numbers below refer to the updated version of the main paper.\n\n* **Reviewer 9HJS (red):**\n\n  * We added a more detailed **dictionary coverage experiment** in **Lines 500–518**, where we vary the coverage from 10% to 100% and report the impact on cross-lingual accuracy.\n  * We added a **human evaluation study** of the readability, coherence, and overall quality of adversarial examples in **Lines 1228–1263**, including the evaluation protocol and summary statistics.\n\n* **Reviewer CasE (blue):**\n\n  * We added an evaluation of **TPR@FPR = 1% on the M4 dataset** and reported **TPR and FPR on the SemEval 2024 Task 8 dataset** under the same thresholds in **Lines 1266–1335**, aligning our metrics with current best practices in MGT detection.\n  * We revised the discussion around dictionary errors in **Lines 476–500** (corresponding to Line 464 in the original submission) to avoid potential ambiguity about the relationship between dictionary noise and performance in English vs. other languages.\n\n* **Reviewer S8Qh (orange):**\n\n  * We added a detailed discussion of **training and inference cost**, including **end-to-end inference latency and per-sample inference time for all detectors**, in **Lines 1337–1384**, to better contextualize our method relative to both metric-based and model-based detectors.\n\n* **Reviewer aEgz (green):**\n\n  * We included an **ablation study on importance-score definitions** (gradient-based vs. attention-based, perturbation-based, and random baselines) in **Lines 953–1046**.\n  * We analyzed the **effect of using smaller surrogate models** (e.g., ALBERT-base-v2, Pythia-70M) in **Lines 1078–1113**.\n  * We added an experiment on the **impact of pseudo-label noise** on both accuracy and robustness in **Lines 1115–1180**.\n  * We described the **training dynamics and stability** of the attacker–detector co-evolution, including loss behavior over training steps, in **Lines 1386–1403**.\n\nWe are very grateful for the time and effort you have invested in reviewing our work, which has helped us substantially improve the clarity, completeness, and empirical support of the paper. If there are any remaining concerns or if further clarification would be helpful on any of the new results or explanations, we would be very happy to continue the discussion and respond as promptly as possible during the rebuttal period."}}, "id": "3FqwMFE8Yo", "forum": "bTcFHJo1Zk", "replyto": "bTcFHJo1Zk", "signatures": ["ICLR.cc/2026/Conference/Submission6562/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6562/Authors"], "number": 18, "invitations": ["ICLR.cc/2026/Conference/Submission6562/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763435664414, "cdate": 1763435664414, "tmdate": 1763435664414, "mdate": 1763435664414, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}