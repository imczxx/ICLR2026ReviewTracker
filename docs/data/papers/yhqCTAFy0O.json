{"id": "yhqCTAFy0O", "number": 22177, "cdate": 1758327234752, "mdate": 1759896882175, "content": {"title": "Teacher-Student Multi-Agent Reinforcement Learning Framework for AutoML Pipeline Construction", "abstract": "We present an asymmetric teacher--student multi-agent reinforcement learning framework for automated machine learning (AutoML) pipeline synthesis. Unlike monolithic search methods (Bayesian optimization, evolutionary algorithms, single-agent RL), our formulation casts guided pipeline construction as a Dec-POMDP with selective interventions: a teacher proposes counterfactual improvements only when the estimated advantage exceeds an adaptive threshold, enabling accelerated early learning and graceful withdrawal. We approximate component-level credit using sparse ablations with historical reuse, improving interpretability and transfer readiness, and warm-start policies across datasets to reduce sample requirements. Empirically, our method matches or surpasses strong baselines (Random / Grid Search, H2O AutoML) while requiring  fewer evaluations to reach accuracy targets, and produces emergent curriculum behavior where intervention rates decay from $\\sim$40\\% to less than 5\\%. We emphasize architectural novelty and learning dynamics over exhaustive scaling, arguing that asymmetric pedagogical control provides a principled inductive bias for structured AutoML search.", "tldr": "We propose an teacher–student multi-agent RL framework for AutoML pipeline synthesis, where selective pedagogical interventions accelerate learning and outperform standard search methods with fewer evaluations", "keywords": ["Multi-Agent Reinforcement Learning", "Automated Machine Learning", "Decentralized POMDP", "Pedagogical Reinforcement Learning", "Pipeline Optimization"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e2f81627a3a8a968cc39c6e78892cf45fafcc478.pdf", "supplementary_material": "/attachment/d5080fc57f64c0592c596b51fc6d0f0746e63e57.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a framework for AutoML pipeline construction using an asymmetric teacher-student multi-agent reinforcement learning (MARL) approach. The core idea is to frame pipeline synthesis as a Decentralized Partially Observable Markov Decision Process (Dec-POMDP) where a \"student\" agent proposes pipeline components and a \"teacher\" agent selectively intervenes. The authors claim their method matches or surpasses baselines in final accuracy while requiring 35-60% fewer evaluations, and that the framework is more interpretable and supports knowledge transfer."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.  The pedagogical motivation of a teacher guiding a student provides an intuitive inductive bias for the AutoML search process.\n2.  The paper aims to address a critical bottleneck in AutoML—the high cost of pipeline evaluation."}, "weaknesses": {"value": "1.  The authors explicitly state in Section 5.8 that the quantitative ablation table was omitted because prior results became invalid after code refactoring. This is a critical omission for a paper whose main contributions are new algorithmic components.\n2.  The description of the framework in Section 3 lacks clarity. Key concepts, particularly the Dec-POMDP formulation, are introduced without sufficient definition. The mapping between the formal elements of the Dec-POMDP (states, observations, transition functions) and the concrete task of building a machine learning pipeline is not well-explained, making the method difficult to understand.\n3.  The main performance results in Table 1 show that the proposed MARL approach only marginally outperforms the strongest baseline (H2O AutoML) on most datasets.\n4.  The related work section is quite brief and could be expanded to better contextualize the work. Furthermore, figures are difficult to read."}, "questions": {"value": "1. The omission of the ablation study is a critical issue. Can you provide results from ablation studies?\n2. Could you please provide a clearer explanation of your method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aeACcU3gCA", "forum": "yhqCTAFy0O", "replyto": "yhqCTAFy0O", "signatures": ["ICLR.cc/2026/Conference/Submission22177/Reviewer_Vqqa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22177/Reviewer_Vqqa"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22177/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761655154156, "cdate": 1761655154156, "tmdate": 1762942102212, "mdate": 1762942102212, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present an asymmetric teacher–student multi-agent reinforcement learning framework for automated machine learning and compare it against baselines like Random/Grid Search, single-agent DDQL, TPOT."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "None. The motivation behind the paper's methodology is lackluster, the problem statement is unclear, and more; see the weaknesses."}, "weaknesses": {"value": "I cannot in good faith recommend this paper for acceptance, and I strongly recommend rejection. Without even reading the disclosure of LLM usage at the end of the article, I already knew it was almost entirely LLM-generated. The writing is incoherent, disorganized, poorly motivated, and abrasive in tone.\n\nAbstract:\n* More motivation is required. Too much focus on your method without talking about the big picture. Hence, your problem statement is unclear. What are the challenges of AutoML? You mention monolithic search, but I doubt that there is no literature addressing this.\n* Strong baselines? Random/Grid Search and single-agent DDQL are not strong baselines. And DDQL should be spelled out - is it double deep q learning or dueling deep q learning?\n\nIntroduction:\n* I find the wording very confusing: teacher-student, curriculum pacing, etc. You should relate this more closely to asymmetric pedagogical control. Also, asymmetrical with respect to what?\n* The presentation is a disorganized mess. The problem statement is barely established. There are bold claims (e.g., \"attains competitive or superior accuracy\", \"reduces evaluations 35-60%\", \"yields interpretable credit traces\", \"transfers knowledge with up to 40% episode reduction\"); none of this sounds scientific or statistical. Where are the means, standard deviations, confidence intervals, etc.? These percentages could be outliers.\n* Where are your citations for \"Positioning vs LLM Orchestration\"? That entire section needs evidence.\n\nRelated Work:\n* NAS: you need to spell this out = Neural Architecture Search (NAS)\n* Too short and brief; seems incoherent.\n\nFramework:\n* 3.2: This does not seem novel at all if this is  ASYMMETRIC DEC-POMDP. Also, what does DEC-POMDP stand for?\n\nResults:\n* Poor selection of visualizations for displaying results. Performance looks bad and unstable. Unprofessional y-axis labels for Figure 1, bottom right plot. Ridiculous and unnecessary scatter plot in Figure 2. Confusing Figure 3 with a shared y-axis between unrelated metrics. Deceptive Figure 4 dual axes plot with bar plot and line plot. \n\n5.1: \"Auto-sklearn removed due to instability\". I feel that this needs further discussion or investigation.\n5.2: Incoherent and lackluster results.\nLine 269: There is an upside-down question mark that should not be there\nLine 313: put a period after your sentences\n\nThis submission does not meet ICLR quality standards due to its lack of clear presentation or convincing/rigorous results."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["Yes, Other reasons (please specify below)"]}, "details_of_ethics_concerns": {"value": "I have worked with ChatGPT enough to recognize its output and tone. Almost the entirety of this submission is written by ChatGPT, and it should not, by any means, be considered for acceptance to ICLR. Regardless of how it was authored, the paper is incomplete, incoherent, and disorganized."}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0A24oT2ypZ", "forum": "yhqCTAFy0O", "replyto": "yhqCTAFy0O", "signatures": ["ICLR.cc/2026/Conference/Submission22177/Reviewer_KcKR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22177/Reviewer_KcKR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22177/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882906052, "cdate": 1761882906052, "tmdate": 1762942101939, "mdate": 1762942101939, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces an asymmetric teacher–student multi-agent RL (MARL) framework for AutoML pipeline synthesis. The approach frames AutoML pipeline construction as a Decentralized POMDP, in which a student agent sequentially builds pipeline components, and a teacher agent selectively intervenes only when the expected counterfactual advantage exceeds a dynamic threshold. Through this selective pedagogical intervention, the system accelerates early learning while fostering autonomy later, mimicking human teaching dynamics. A component-level credit assignment mechanism estimates marginal contributions using sparse ablations and historical reuse, yielding interpretable attributions and enabling transfer across datasets. Empirical results on several tabular benchmarks (Iris, Adult, Covertype, Credit-G, Bank Marketing) demonstrate good performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The formulation of AutoML pipeline construction as an asymmetric MARL problem is interesting. Framing the teacher as a counterfactual intervention policy introduces a pedagogical inductive bias that aligns with human-guided learning metaphors."}, "weaknesses": {"value": "1) The ablation section is largely qualitative, citing environment refactors as justification for omission of quantitative deltas. This prevents precise attribution of performance gains to specific modules (teacher gating, adaptive exploration, or credit approximation).\n\n2) Some key hyperparameters are manually chosen. The lack of sensitivity analysis limits claims of generality and robustness.\n\n3) Evaluation is limited to small and mid-scale tabular datasets. There is no evidence of scalability to large-scale, high-dimensional, or multi-modal AutoML tasks."}, "questions": {"value": "Q1: The paper reports minor negative transfer (e.g., Iris -> Adult). Can the authors isolate whether this originates from the teacher’s overfitting or student policy misalignment? During transfer, does freezing the teacher always outperform joint fine-tuning in stability?\n\nQ2: The decay is heuristic. How sensitive are the results to the chosen decay parameters?\n\nQ3: The system produces structured artifacts (credit weights, intervention logs). Could these be visualized or summarized in a way that aids human debugging? Is there any qualitative user study or visual audit confirming the interpretability claims?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6f40X4g1la", "forum": "yhqCTAFy0O", "replyto": "yhqCTAFy0O", "signatures": ["ICLR.cc/2026/Conference/Submission22177/Reviewer_Bim1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22177/Reviewer_Bim1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22177/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761941424047, "cdate": 1761941424047, "tmdate": 1762942101680, "mdate": 1762942101680, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a asymmetric teacher-student multi agent framework for automated machine learning pipeline synthesis in which the teacher can propose a counterfactual improvement based on the performance of the student agents. They propose component-level credit assignment solution with policy warm start to improve the performance of student learner. The author also test their methods on various dataset and have showed superior performance compared to several baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes an interesting method for AutoML decision by framing it as a teacher-student model where teacher uses a advantage estimator to guide the student towards correct solution.\n\n2. The authors have conducted detailed experiments and have provided good comparison against various baseline algorithms."}, "weaknesses": {"value": "1. The paper is poorly written which obscures the technical content of the paper. The authors have chosen a style with lot of declarative sentences making the text feel fragmented and difficult to follow the narration. \n2. Related works section lacks a proper comparison of their work with prior literature.\n3. Definitions of lot of important terms like component pipeline, many terms like component library, valid ordered pipeline, utility function etc are not well defined. State and observation space definition, rewards, transition - these all definitions are missing in Dec-POMDP. What should one even understand from this in line 103 “Transition integrates component attachment or termination with evaluation (cross-validation + timeout guard).”?"}, "questions": {"value": "1. Can you please clarify the problem setting and Dec-POMPD framework to be more understandable to reader?\n2. Can you clarify what component library means?\n3. A lot of wordings in the text are not at all clear to me as a reader. For example, can you clarify what do you mean by the text \"Credit-weighted marginal gain detection suppresses gratuitous component accretion, yielding emergent complexity pruning without explicit length penalty escalation.\" in line 256-257?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sN5QZWcDmm", "forum": "yhqCTAFy0O", "replyto": "yhqCTAFy0O", "signatures": ["ICLR.cc/2026/Conference/Submission22177/Reviewer_GEG1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22177/Reviewer_GEG1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22177/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945928561, "cdate": 1761945928561, "tmdate": 1762942101375, "mdate": 1762942101375, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel asymmetric teacher–student multi-agent reinforcement learning (MARL) framework for automated machine learning (AutoML) pipeline synthesis, which uses a selective counterfactual intervention mechanism for efficient guidance."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "I think this paper is still unfinished. For example, one section is marked as preliminary. Therefore, it is difficult to fully assess the quality of the work at this stage."}, "weaknesses": {"value": "The paper is poorly organized, with too many subsections. Sentences and paragraphs lack coherence. The references are insufficient, and the experimental results are presented in a rather casual manner. Overall, it feels more like a draft manuscript than a polished paper ready for publication."}, "questions": {"value": "I suggest that the authors further improve the paper by adding more references and experimental results, and by reorganizing the paragraphs. The current version appears more like an AI-generated preliminary draft."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sJ2OxMtHvs", "forum": "yhqCTAFy0O", "replyto": "yhqCTAFy0O", "signatures": ["ICLR.cc/2026/Conference/Submission22177/Reviewer_RAAx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22177/Reviewer_RAAx"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission22177/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762008354855, "cdate": 1762008354855, "tmdate": 1762942101122, "mdate": 1762942101122, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}