{"id": "CPdAB7H8mU", "number": 23895, "cdate": 1758349948137, "mdate": 1759896791659, "content": {"title": "ON THE ROLE OF IMPLICIT REGULARIZATION OF STOCHASTIC GRADIENT DESCENT IN GROUP ROBUSTNESS", "abstract": "Training with stochastic gradient descent (SGD) at moderately large learning rates has been observed to improve robustness against spurious correlations, strong correlation between non-predictive features and target labels. Yet, the mechanism underlying this effect remains unclear. In this work, we identify batch size as an additional critical factor and show that robustness gains arise from the implicit regularization of SGD, which intensifies with larger learning rates and smaller batch sizes. This implicit regularization reduces reliance on spurious or shortcut features, thereby enhancing robustness while preserving accuracy. Importantly, this effect appears unique to SGD: gradient descent (GD) does not confer the same benefit and may even exacerbate shortcut reliance. Theoretically, we establish this phenomenon in linear models by leveraging statistical formulations of spurious correlations, proving that SGD systematically suppresses spurious feature dependence. Empirically, we demonstrate that the effect extends to deep neural networks across multiple benchmarks. Moreover, standard SGD with small batch sizes, while not requiring prior knowledge of spurious correlations or underrepresented groups, achieves group-robust generalization that surpasses specialized debiasing methods in the more challenging setting with multiple spurious correlations, while remaining simpler and more computationally efficient. For the experiments that support these findings, please refer to \\href{https://github.com/ICLR2026-submission/implicit-regularization-in-group-robustness}{https://github.com/ICLR2026-submission/implicit-regularization-in-group-robustness}.", "tldr": "", "keywords": ["Spurious Correlations", "Stochastic Gradient Descent (SGD)", "Implicit Regularization"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/19ae7e5ce9aa787b896e4287a53eabde6a3df7a6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies the effect of batch size on the reliance of stochastic gradient descent on spurious features. The paper considers a simple 4 point model where there are two binary features, one exactly equal to the label and one spurious feature with high correlation with the label  and the spurious one is also larger in magnitude. The paper studies the solution for this problem returned by gradient descent and stochastic gradient descent with an exponential loss function. It shows that due to implicit bias, gradient descent increases the coefficient of the spurious feature whereas stochastic gradient descent with small batch sizes reduces the coefficient of the spurious feature."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper demonstrates an interesting phenomenon relating the implicit biases of different algorithms to their robustness to spurious features. I am not very familiar with the literature on implicit biases but I have not seen this relation being explored before.\n\nThe experiments show that the conclusions also hold to some extent on realistic cases with standard datasets. For a fixed batch size, increasing step size appears to improve the worst group error. For a fixed step size, reducing batch size also appears to improve the worst group error (only if the average error is maintained)."}, "weaknesses": {"value": "The previous works by Puli et al. and Sagawa et al. cited by the paper use the logistic loss function whereas this paper uses an exponential loss function. It would be helpful to explain this change and whether the conclusion continues to hold in the same setting as previous works.\n\nThe conclusions for GD and SGD also need not hold for more sophisticated methods for debiasing, as described in section 4.4.\n\nThe amount of robustness provided by SGD with small batch size seems very small compared with more sophisticated methods in the experiments. If one's goal is to achieve robustness, other methods might be the major factors and the batch size a minor one."}, "questions": {"value": "Could you please explain the reason for changing the loss function."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "STaTjpUTJw", "forum": "CPdAB7H8mU", "replyto": "CPdAB7H8mU", "signatures": ["ICLR.cc/2026/Conference/Submission23895/Reviewer_AkY5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23895/Reviewer_AkY5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23895/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761774745596, "cdate": 1761774745596, "tmdate": 1762942844158, "mdate": 1762942844158, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the implicit regularization of SGD as a factor in robustness against spurious correlations. The main contribution is a theoretical analysis of SGD implicit regularization in a linear setting, under the four-point data model. The batch size and learning rate are identified as key factors in the bound. Experiments are also provided which transition the insights to neural networks, and training with small batch sizes is proposed as a trick to improve robustness."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well written and easy to follow. The overview of the theoretical results in Sections 2/3 has an appropriate level of detail, and the appendix is nicely organized.\n\n2. The intuitive explanation -- that SGD controls the variance of mini-batch gradients, preventing certain mini-batches from overfitting to the gradient in the direction of the optimal majority group classifier -- makes sense and is illustrated well in Section 2.\n\n3. The dichotomy that full-batch GD increases reliance on spurious correlations while small-batch SGD mitigates it is interesting and to my knowledge novel. More generally, this paper fills a gap in the literature on the understanding of how learning rate and batch size, in conjunction with the implicit regularization of gradient descent, affect robustness to spurious correlations.\n\n4. The experiments in Section 4 are rigorous and interesting, both in the validation of the theory and in providing takeaways for practitioners."}, "weaknesses": {"value": "1. A related work section is missing. This is important for contextualization of this paper’s results with the literature. A few references are provided in Section 1.1 and 2.1, but results and implications are not discussed in-depth.\n\n    a. Some papers studying theory for gradient descent in the presence of spurious correlations which may be relevant for discussion: [5, 6, 7, 8]\n\n    b. It would also be great to include more references on small-batch or large-LR training in the vein of [2, 3]. Also, I am particularly curious whether the community has found any other robustness benefits of small batch training (as briefly discussed in Section 2.1). I am aware of at least one reference [4] which showed that small-batch training has benefits for adversarial robustness, via a flat-minima argument. Are there more?\n\n2. The four-point data setting is a relatively simple toy setting and has been well-studied since at least [1]. However, I believe this is acceptable for this paper, as its primary contribution is a new analysis of batch size/learning rate effects of SGD, which is still interesting in the four-point data setting.\n\n3. From a technical perspective, it is unclear whether the proof techniques are particularly novel or sophisticated, i.e., whether this paper introduces any methods that might be generalizable beyond the scope of this paper. From what I can tell, the proofs mainly utilize existing results from KKT theory and probability/concentration, with a substantial amount of careful algebra. (Note: I do not consider this criteria as necessary for acceptance at ICLR, but it would perhaps constitute the difference between an 8 and a 10).\n\n4. A minor critique is that only vision datasets are used for the experiments. While not strictly necessary, showing the small-batch results hold on a language dataset or two (e.g., CivilComments, MultiNLI) with a Transformer architecture would be interesting.\n\n[1] Nagarajan et al. Understanding the failure modes of out-of-distribution generalization. ICLR 2021.\n\n[2] Keskar et al. On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima. ICLR 2017.\n\n[3] Goyal et al. Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour. ArXiv 2017.\n\n[4] Yao et al. Hessian-based Analysis of Large Batch Training and Robustness to Adversaries. NeurIPS 2018.\n\n[5] Qiu et al. Complexity Matters: Feature Learning in the Presence of Spurious Correlations. ICML 2024.\n\n[6] Yang et al. Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias. AISTATS 2024.\n\n[7] Ye et al. Freeze then Train: Towards Provable Representation Learning under Spurious Correlations and Feature Noise. AISTATS 2023.\n\n[8] Jain et al. Bias in Motion: Theoretical Insights into the Dynamics of Bias in SGD Training. NeurIPS 2024."}, "questions": {"value": "1. It would be nice to make clear where the $\\epsilon/b$ scaling comes from in Equation 7. I assume the $1/b$ is hidden in the $f$ term.\n\n2. See Weakness 1a/b: how should this paper’s findings be contextualized with the broader literature on a) gradient descent and spurious correlations, and b) small-batch SGD learning?\n\n3. Minor clarity/grammatical improvements:\n\n    a. \\citep should be used on line 52, 72, 196, 293, 410, Fig 5, etc\n\n    b. Malformed citation on line 739, 764\n\n    c. The word “rate” is missing in line 313"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WDUp26JpjZ", "forum": "CPdAB7H8mU", "replyto": "CPdAB7H8mU", "signatures": ["ICLR.cc/2026/Conference/Submission23895/Reviewer_EN6D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23895/Reviewer_EN6D"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23895/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947989973, "cdate": 1761947989973, "tmdate": 1762942843831, "mdate": 1762942843831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how the implicit regularization effect of stochastic gradient descent contributes to group robustness. Starting from a simple four-point linear model containing one invariant and one spurious feature, the authors theoretically show that SGD implicitly minimizes the variance of mini-batch gradients, which discourages the model from relying on spurious or shortcut features. Through analytical comparison with full-batch gradient descent, they demonstrate that SGD systematically assigns lower weights to spurious dimensions when the learning rate is moderately large. The paper further presents empirical results on multiple deep learning benchmarks (e.g., CMNIST, CelebA, Waterbirds, CIFAR10, Domino)"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Within the four-point linear model, the analysis is mathematically valid and well-grounded in prior implicit-regularization theory.\n\nThe paper is clearly written and visually well-organized."}, "weaknesses": {"value": "The entire formal analysis is restricted to a two-dimensional linear model with exponential loss, where spurious and invariant features are explicitly separable. The main results (Theorems 3.1–3.3) therefore have no direct generalization to nonlinear networks.\n\nThe paper claims that “the phenomenon extends to deep neural networks,” yet the deep network experiments are purely phenomenological and do not demonstrate the mechanism at play.\n\nThe derivation equates “mini-batch gradient variance” with “dependence on spurious features,” which is only true under the toy model’s assumptions. In higher-dimensional or nonlinear cases, gradient variance can stem from many other sources (noise, imbalance, stochasticity).\n\nThe implicit-regularization analysis assumes infinitesimal step size and small learning rate, yet the empirical improvements occur at large learning rates, outside the theoretical validity region.\n\nThe findings largely confirm existing empirical wisdom (“small batch, large lr improves robustness”) without offering new algorithmic insights or a quantifiable predictive model for hyperparameter selection."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VqlhO3kMw6", "forum": "CPdAB7H8mU", "replyto": "CPdAB7H8mU", "signatures": ["ICLR.cc/2026/Conference/Submission23895/Reviewer_XpZs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23895/Reviewer_XpZs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23895/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950368844, "cdate": 1761950368844, "tmdate": 1762942843595, "mdate": 1762942843595, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common Response to Reviewer Comments"}, "comment": {"value": "We would like to thank the reviewers again for their insightful feedback. A common concern raised by Reviewer *XpZs*, comment 5 and Reviewer *AkY5*, comment 3 relates to the **practical usefulness** of our study. We address it here.\n\n\nExisting methods for mitigating shortcut learning perform well on **single-level spurious datasets** such as *CelebA and Waterbirds*. However, on more realistic datasets that contain complex or unknown spurious attributes, such as multi-level spurious correlations in Domino-CMF, these methods often perform **at or below random chance on the minority groups** [1]. This happens because, even after applying these methods, the second-level spurious attribute remains encoded in the learned representation and cannot be corrected when the algorithm only targets the first (known) spurious correlation [1].\n\nIn contrast, **small-batch ERM provides robustness implicitly**, without requiring any knowledge of which spurious attributes exist or how many levels they have. The underlying mechanism—implicit regularization—penalizes non-uniform regions of the loss landscape [2], which naturally improves performance on minority and underrepresented subpopulations that generate higher gradient variability.\n\nAs a result, in multi-level spurious settings, small batch sizes can be decisive: as shown in Table 2, they yield substantial gains of **25–37% in worst-group accuracy** on Domino-CMF across DFR, AFR, and EVaLS. This demonstrates that small-batch SGD is not merely a minor hyperparameter tweak, but **a practical and impactful robustness tool** that can be integrated in the training of the methods for when **spurious attributes are unknown, complex, or unannotatable**, conditions that arise frequently in real-world datasets.\n\nIt is important to note that multi-level and unknown spurious correlations represent a widely practical challenge, but it has very recently been highlighted in [1, 3, 4]. In many real-world datasets, we may not be aware of the specific spurious correlations present, nor can we easily identify the minority and majority subpopulations, especially when the sources of these correlations are not known. In such cases, annotating even a few samples with group labels becomes infeasible. We believe that SGD with small batch sizes is a suitable approach when spurious correlations are present but their nature remains unknown, as it helps mitigate their impact on the learning process.\n\n---\n\n### References\n\n[1] Ghaznavi et al. Exploiting what trained models learn for making them robust to spurious correlations without group annotations. Spurious Correlation & Shortcut Learning Workshop 2025\n\n[2] Prince. Understanding deep learning. MIT Press 2023\n\n[3] Tsirigotis et al. Group robust classification without any group information. NeurIPS 2024\n\n[4] Bayat et al. The pitfalls of memorization: When memorization hurts generalization. ICLR 2025"}}, "id": "giUdekVTgu", "forum": "CPdAB7H8mU", "replyto": "CPdAB7H8mU", "signatures": ["ICLR.cc/2026/Conference/Submission23895/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23895/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23895/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763723517260, "cdate": 1763723517260, "tmdate": 1763723517260, "mdate": 1763723517260, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}