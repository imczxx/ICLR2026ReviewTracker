{"id": "aTxnsFFO7t", "number": 13866, "cdate": 1758224032534, "mdate": 1759897407650, "content": {"title": "Privacy-Protected Causal Survival Analysis Under Distribution Shift", "abstract": "Causal inference across multiple data sources can improve the generalizability and reproducibility of scientific findings. However, for time-to-event outcomes, data integration methods remain underdeveloped, especially when populations are heterogeneous and privacy constraints prevent direct data pooling. We propose a federated learning method for estimating target site-specific causal effects in multi-source survival settings. Our approach dynamically re-weights source contributions to correct for distributional shifts, while preserving privacy. Leveraging semiparametric efficiency theory, data-adaptive weighting and flexible machine learning, the method achieves both double robustness and efficiency improvement. Through simulations and two real data applications: (i) multi-site randomized trials of monoclonal antibodies for HIV-1 prevention among cisgender men and transgender persons in the United States, Brazil, Peru, and Switzerland, as well as women in sub-Saharan Africa, and (ii) an analysis of sex disparities across biomarker groups for all-cause mortality using the \"flchain\" dataset, we demonstrate the validity, efficiency gains, and practical utility of the approach. Our findings highlight the promise of federated methods for efficient, privacy-preserving causal survival analysis under distribution shift.", "tldr": "", "keywords": ["Time-to-event outcome", "Conditional distribution shifts", "Semiparametric efficiency theory", "Federated learning"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d57a0caddd0dc42eded05ed6af79f7d7c569089d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper aims at introducing a new procedure to perform generalization of treatment-specific survival functions to a centralized target population, where the effect is learned of multiple decentralized sources, distinct from the target, and without exchanging raw individual data as in a federated constraint. The authors tackle the challenging setting where the source and target are heterogeneous on their joint distributions. The method proposed is 1. each site fits local nuisance models and EIF for pseudo outcomes at each treatment arm and time point reweighted by estimated density ratios to account for covariate shift relative to the target, 2. the EIFs and other summary statistics are sent to the server and aggregated with weights $\\eta^k$ which penalize sites according to their estimated discrepancy from the target's nuisance functions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The work presented here is a nice foundation for survival curve estimation in a federated setting, which is crucial and where privacy is clearly a big stake.\n\nThe theory seems solid with asymptotic unbiasedness and accounts for heterogeneous designs. I believe most of the strength of the paper is on theorem E.1, which should be the central theorem of the (main) paper instead of the appendix. Assessing how original this theorem is in comparison to [1] is not properly addressed though.\n\n[1] Westling, Ted, et al. \"Inference for treatment-specific survival curves using machine learning.\" Journal of the American Statistical Association 119.546 (2024): 1541-1553."}, "weaknesses": {"value": "## Main Concerns\n\n- **Related work and positioning:**  \n  The discussion of related work is incomplete. Several recent contributions have explored federated causal inference, such as [1] and [2], which could serve as meaningful baselines even if they are not specific to survival outcomes, or at least be referred to. In addition, key competitors have been omitted, including [2] and [3], who propose federated external control arm approaches that relax the positivity assumption across sites. The paper should more clearly situate itself within this literature and justify how it advances beyond these frameworks.\n\n- **Conceptual novelty:**  \n  The proposed method appears to be primarily a survival adaptation of FACE [4]. The paper would benefit from a clearer statement of what new theoretical or methodological insights are introduced beyond this earlier work. Without this clarification, the contribution could read as incremental.\n\n- **Motivation and scope:**  \n  The motivation for privacy preservation in survival analysis should be better articulated. The authors should explain why privacy is especially relevant for survival data and why access to large multi-institutional datasets is critical for estimating treatment-specific survival functions. Currently, the privacy aspect appears overstated relative to its actual methodological treatment.\n\n- **Estimator behavior and information sharing:**  \n  The estimator defined in Theorem 2.5 does not seem to borrow information from other source sites, effectively acting as a generalization of local survival estimators to the target population. The moment-matching aggregation step does not clearly improve efficiency. This raises questions about how much “federation” is actually achieved beyond one-shot aggregation of summaries.\n\n- **Density-ratio estimation and implementation details:**  \n  The section on density-ratio estimation is too brief (line 194) and should be expanded. Estimation under federated constraints is non-trivial, and the so-called “flexible” exponential tilt models are better described as parametric. The authors should discuss the impact of misspecification and the propagation of density-ratio estimation error to the final survival estimates. Moreover, the requirement to share empirical covariance matrices across sites raises both dimensionality and privacy issues that require explicit discussion.\n\n---\n\n## Minor Comments\n\n- The section titled “Limitations of existing work” should be reformulated into a proper **Related Work** section, emphasizing connections to federated causal inference and data fusion.  \n- Clarify in the text which quantities are exchanged across sites (EIFs, covariance matrices, model parameters). This will help readers understand whether the method is truly federated or semi-centralized.  \n- Some claims about “flexible” models or “privacy-protected” estimation should be moderated or substantiated.  \n- Improve notation consistency and specify whether expectations and variances in key equations are empirical or population-level.  \n- The role of overlap (Assumption 2.3) should be highlighted in the discussion of limitations, as it may fail in realistic multi-center observational data.\n\n---\n\n## Recommendations\n\n1. **Reorganize and expand the related work section** to include recent developments in federated causal inference, external control arm methods, and meta-analytic baselines.  \n2. **Clarify the contribution relative to FACE**, identifying specific theoretical or computational advances introduced in this survival extension.  \n3. **Provide additional methodological details** on the estimation of density ratios, including how model misspecification on exponential tilt model and limited covariate overlap affect performance.  \n4. **Discuss communication and privacy aspects** more explicitly, particularly the trade-offs between sharing covariance matrices and preserving data confidentiality.  \n5. **Include stronger baselines** (e.g., meta-analysis and FedECA) in empirical evaluations to demonstrate under which regimes the proposed method achieves measurable improvements.\n\n---\n\n### References\n\n[1] Xiong, Ruoxuan, et al. “Federated causal inference in heterogeneous observational data.” *Statistics in Medicine* 42.24 (2023): 4418–4439.  \n\n[2] Archetti, Alberto, et al. “Heterogeneous datasets for federated survival analysis simulation.” *Companion of the 2023 ACM/SPEC International Conference on Performance Engineering.* 2023.  \n\n[3] Terrail, Jean Ogier du, et al. “FedECA: A federated external control arm method for causal inference with time-to-event data in distributed settings.” *arXiv preprint* arXiv:2311.16984 (2023).  \n\n[4] Han, Larry, et al. “Federated adaptive causal estimation (FACE) of target treatment effects.” *Journal of the American Statistical Association* (2025): 1–14."}, "questions": {"value": "**1. Conceptual positioning and relation to prior work**  \nIn what concrete ways does your approach differ from a meta-analysis of EIF-based local estimators, possibly preceded by a density-ratio reweighting step?  \nCould the proposed method be viewed as a *meta-analysis with adaptive weighting*, and if so, what theoretical or practical advantages does it offer?  \nMore broadly, how does the framework go beyond FACE [5]? Since the EIF-based structure and penalized weighting are similar, what are the novel theoretical or computational insights specific to survival analysis?  \nWhat new theoretical guarantees are provided beyond those of FACE and Westling et al. [1]?\n\n---\n\n**2. Methodology, penalization, and communication**  \nHow is the regularization parameter $\\lambda$ in the penalized objective cross-validated in practice?  \nIs cross-validation performed locally, centrally, or through additional communication between sites?  \nPlease also specify what quantities are exchanged across sites (EIF evaluations, sample moments, covariance matrices, or model parameters), especially for moment matching and density-ratio estimation.  \nThis clarification would help determine whether the method is truly *federated* or rather *semi-centralized*.  \nAdditionally, what is the communication complexity of the procedure in terms of the number of sites $K$, covariate dimension $d$, and time grid $\\tau$?  \nCan the method accommodate time-varying covariates, and is it computationally scalable for large $d$ or fine-grained time grids?\n\n---\n\n**3. Assumptions and robustness**  \nAre there assumptions ensuring that the density ratios $\\omega_{k,0}(X) = P(X|R=0)/P(X|R=k)$ are well-defined, particularly when $P(X|R=k)$ can approach zero under strong covariate shift?  \nThe framework also assumes overlap (Assumption 2.3) across all sites—how robust is the method to *partial or local violations* of this assumption?  \nIn such cases, meta-analysis often remains a strong competitor. Can you demonstrate scenarios where the proposed method outperforms simpler aggregated-data baselines?  \nFurthermore, could the approach extend to situations with multiple non-mergeable target sites or a target population defined as a subpopulation of the sources, as is common in observational studies?\n\n---\n\n**4. Empirical evaluation and interpretation**  \nThe variance gain from the federated estimator relative to the local-target estimator appears small in the experiments.  \nAre there particular regimes (e.g., limited target size, moderate source bias, partial overlap) where the federated approach provides substantial efficiency improvements?  \nAdditionally, why is the pooled estimator biased under shift scenarios in the simulations?  \nWould adjusting for the site indicator as a covariate in the pooled model yield comparable results?\n\n---\n\n**5. Privacy and model specification**  \nCould you specify which privacy risks the method actually mitigates and how this differs from standard aggregated-data sharing?  \nSince no formal privacy guarantees (e.g., differential privacy) are implemented, should the term *privacy-protected* remain in the title?  \nFinally, the density ratios are estimated via exponential-tilt models—could you justify calling these models “flexible,” and discuss how misspecification of the density-ratio model affects the bias or variance of the estimated survival functions?\n\n---\nFinally, I am willing to increase my grade if the authors properly address the above questions, especially my concerns on the framing of the article around privacy, explaining clearly what objects are communicated and the challenges in small sample sizes and high(er) dimensions, and the true contribution of the paper beyond the mere extension of the FACE article to the survival analysis setting.\n\n---\n\n### References\n\n[1] Westling, Ted, et al. “Inference for treatment-specific survival curves using machine learning.”  \n*Journal of the American Statistical Association* 119.546 (2024): 1541–1553.  \n\n[5] Han, Larry, et al. “Federated adaptive causal estimation (FACE) of target treatment effects.”  \n*Journal of the American Statistical Association* (2025): 1–14."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "K0chUws0xV", "forum": "aTxnsFFO7t", "replyto": "aTxnsFFO7t", "signatures": ["ICLR.cc/2026/Conference/Submission13866/Reviewer_n3Hz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13866/Reviewer_n3Hz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761295916930, "cdate": 1761295916930, "tmdate": 1762924383068, "mdate": 1762924383068, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a federated learning strategy to estimate population-level causal effects in survival outcomes, combining the data of multiple sources, under the violation of the _common conditional outcome distribution_ (CCOD) assumption.\nThe strategy is composed by several steps:\n1) Each different site estimate the nuisance functions for its own data: _survival function ($S$), cumulative hazard function ($\\Lambda$), propensity score ($\\pi$), the conditional survival function of censoring ($G$), etc._.\n2) Also, global parameters have to be estimated from coarse statistics: $w^{k,0} = \\frac{P(X|R=0)}{P(X|R=k)}$, $P(R=k)$, etc.\n3) In each site, the target parameter, i.e., the treatment-specific survival function has a closed-form solution, given the nuisance functions and the coarse statistics.\n4) Weights for collaborative learning are computed for each time-point and each site, aligning the EIF with the target distribution, and introducing an $\\ell_1$ loss to remove the sites that do not contribute positively to the estimation of the target parameter in the target site. This problem is solved by optimization.\n5) A federated estimator that combines the sites is the final estimation of the targed parameters.\nThe method has been validated over 1) synthetic data in which the distribution shifts are varied  on demand, and 2) real AMP and _flchain_ data (although _flchain_  is defered to the appendix). \n\nResults show better RMSE and coverage percentage compared with Pooling and IVW, especially when there exist covariate and outcome shift."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The motivation of the paper is clear and strong, the authors aim to give an unbiased estimators of population-level causal effects in survival outcome, given that the CCOD (common conditional outcome distribution) assumptions does not hold.\n\n- The theoretic contribution is based on _Efficient influence function_ theory, and, although I have not studiend in detail the proofs of Appendix E, they seem to be consistent and valid.\n\n- The results present clearly the improvements in comparison with pooling the data and using Inverse Variance Weighting (IVW). Both RMSE and CP show that TGT and FED are consistently better in synthetic data. The results in real data are not that conclusive, but still points in the right direction."}, "weaknesses": {"value": "- My main concern relies on the data-adaptive weighting criterion. The parameters $\\eta$ are the coefficients of a linear regression (omitting $\\ell_1$) to fit the _local_ EIF ( $\\hat{\\varphi}_{t,a}^{*0}$ ), with the site specific EIFs. Therefore, if the local EIF is not well specified, the other sites may contribute negatively to the estimation. That is, the federated learning strategy can be harmful if the local-estimator is not well specified. Is not that exactly what federated learning tries to fight? The same thing happens with the $\\ell_1$ regularization: the optimization process will remove the $\\theta$ that are far from the local estimation, thus benefiting the errors in the local estimation to persist. Is there any explanation for this fact, or any way to fight this positive feedback?\n\n- I have marked the contribution as _fair_ because this is an adaptation of (Han, 2025) to time-to-event data. Although that does not prevent me for accepting the paper, I do not see the contribution as disruptive.\n\n- Results in real data are not conclusive. All the charts present similar results between TGT and FED. Coverage percentage is the most of the time equal, and metrics about RMSE statistical difference are not provided. This limits the interpretation and the strength of the results."}, "questions": {"value": "> Minor concerns\n\n- In the introduction, it seems that no previous work on _federated causal survival analysis_ have been done (especially in `line 054`: 'these methods remain focused on single-study...'). I miss some references to Van der Laan collaborative learning [1, 2]. So I would add some information about this work and its (likely) follows ups. (disclaimer: I have nothing to do with those works.)\n\n- Can we get a explicit definition of what nuisance functions are? From the context, it can be understood that _survival function, hazard function, propensity score, etc._, are nuisance functions, but is not clear in the introduction.\n\n- Can authors provide more intuition about  Equation of line 128? E.g. what the role of $\\frac{I(R=0)}{P(R=0)}$ is? what the role of $\\frac{I(A=a)}{\\pi(a|X)}$ is? It would help to understand the equation. \n\n- What does the RAL property in Appendix E.1.2 mean? It does  not seem to be defined.\n\n- In `line 430-431`, authors say thet TGT yields wider confidence intervals than FED, but I cannot see that in the Figure 4(A). In fact, what I observe is that FED, between aproximately day 80 and day 180, has wider intervals than TGT. Am I missing something?\n\n- Figure 4 (B) represents the weights given to each site in each timepoint. We can observe two curves, one very noisy, and another _filtered curve_. The _smoothing_ component is part of the approach or is it only a representation tool in the figure?\n\n- In general, I would recommend to add more intuitions about theoretical implications and, especially, under which assumptions the oracle-optimal weights are recovered. The pointers to the appendix are overwhelming, and more plain intuitions would be very helpful\n\n> Summary\n\nIn general, I would say that this is a good paper. It is based on other similar approaches that leverages _Efficient influence function theory_ and both the theoretical approach and the results are sound. However, I have several concerns, reflected in _Weaknesses_ and _Questions_ section that prevents me to give a higher score. I would be happy to raise my score if those concerns are solved.\n\n> References\n\n[1] van der Laan, M. J., & Gruber, S. (2010). Collaborative double robust targeted maximum likelihood estimation. The international journal of biostatistics, 6(1), 17.\n[2] Stitelman, O. M., & van der Laan, M. J. (2010). Collaborative targeted maximum likelihood for time to event data."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "G8TEnnjVQN", "forum": "aTxnsFFO7t", "replyto": "aTxnsFFO7t", "signatures": ["ICLR.cc/2026/Conference/Submission13866/Reviewer_shKn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13866/Reviewer_shKn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761747879943, "cdate": 1761747879943, "tmdate": 1762924382438, "mdate": 1762924382438, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "A federated learning framework for survival analysis is a missing topic. This paper presents a federated learning framework for causal survival analysis that aims to estimate treatment-specific survival functions across multiple heterogeneous datasets while respecting privacy constraints. The formulation mostly follows previous papers where we have to adjust the distribution shift between the source and the target dataset."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper does a good job transitioning the federated causal inference problems to this setting. They provide a complete and clean framework. I list the strengths below.\n\n1. Timely and important setting\n2. Clear formulation \n3. Doubly robust estimator\n4. Accounting for biased source states\n5. Complete simulation and real-world studies"}, "weaknesses": {"value": "I believe that there are some important questions that the paper should answer:\n\n1. Comparison with standard setting. Consider a degenerated case in survival analysis, where we do not have censoring and only have time step 1. This becomes the non-survival setting. In this case, does the estimator proposed degenerated to estimators the same with Han et al.? Answering this question can help the reader understand any tricky or nontrivial part in extending the estimator to survival analysis.\n\n2. Estimating the distribution shift is the core problem in causal inference. It would be interesting to see discussions on different strategies on density ratio analysis and their effect on the final result.\n\n3. It would be interesting to see the extension to better estimators, for example, Guo et al. (2024) proposes an estimator that is more efficient than meta-analysis styled estimators.\n\nGuo, Tianyu, Sai Praneeth Karimireddy, and Michael I. Jordan. \"Collaborative heterogeneous causal inference beyond meta-analysis.\" arXiv preprint arXiv:2404.15746 (2024)."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "rErAnz9Z68", "forum": "aTxnsFFO7t", "replyto": "aTxnsFFO7t", "signatures": ["ICLR.cc/2026/Conference/Submission13866/Reviewer_YJNV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13866/Reviewer_YJNV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13866/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762196273756, "cdate": 1762196273756, "tmdate": 1762924381782, "mdate": 1762924381782, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}