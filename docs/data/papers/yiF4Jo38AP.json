{"id": "yiF4Jo38AP", "number": 17563, "cdate": 1758277595381, "mdate": 1759897167468, "content": {"title": "CGSA: Class-Guided Slot-Aware Adaptation for Source-Free Object Detections", "abstract": "Source-Free Domain Adaptive Object Detection (SF-DAOD) aims to adapt a detector trained on a labeled source domain to an unlabeled target domain without retaining any source data. Despite recent progress, most popular approaches focus on tuning pseudo-label thresholds or refining the teacher-student framework, while overlooking object-level structural cues within cross-domain data. In this work, we present CGSA, the first framework that brings Object-Centric Learning (OCL) into SF-DAOD by integrating slot-aware adaptation into the DETR-based detector. Specifically, our approach integrates a Hierarchical Slot Awareness (HSA) module into the detector to progressively disentangle images into slot representations that act as visual priors. These slots are then guided toward class semantics via a Class-Guided Slot Contrast (CGSC) module, maintaining semantic consistency and prompting domain-invariant adaptation. Experiments on five cross-domain object detection datasets demonstrate that our approach outperforms previous SF-DAOD methods, with theoretical derivations and experimental analysis further demonstrating the effectiveness of the proposed components and the framework, thereby indicating the promise of object-centric design in privacy-sensitive adaptation scenarios. All code will be released later.", "tldr": "", "keywords": ["Source-Free Domain Adaptation", "Object Detection", "Object-Centric Learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/79ebcf5e3bb73ba67ecff9e08183b65b5831942f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes CGSA, a novel source-free domain adaptive object detection framework that integrates object-centric learning into DETR-based models. It introduces two modules: Hierarchical Slot Awareness, which decomposes images into slot-based structural priors, and Class-Guided Slot Contrast, which aligns slots with class semantics through contrastive learning. The approach enables domain-invariant adaptation without source data. Experiments on multiple benchmarks show consistent and significant improvements over existing methods, supported by theoretical risk descent analysis."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces CGSA, the first framework to combine Object-Centric Learning with Source-Free Domain Adaptive Object Detection, and integrates slot-based structural priors and class-guided contrastive alignment reasonably to achieve domain-invariant adaptation.\n2. Extensive experiments show that CGSA significantly outperforms prior methods, and the authors also provide theoretical analysis demonstrating risk reduction and stable convergence during adaptation."}, "weaknesses": {"value": "1. Nevertheless, the proposed method remains highly dependent on the DETR framework, showing limited generalizability. Evaluating its effectiveness on other architectures, such as Faster R-CNN, is still desireable.\n2. There is no intuitive visualization or analysis of slot decomposition process.\n3. The risk analysis is mathematically sound but lacks empirical validation of key variables in authors' description, e.g., cosine margin gain or reconstruction consistency."}, "questions": {"value": "1. How sensitive is CGSA to the number of slots (n=5) or slot hierarchy depth?\n2. What is the computational overhead compared to standard DETR?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gb3XQRdAoV", "forum": "yiF4Jo38AP", "replyto": "yiF4Jo38AP", "signatures": ["ICLR.cc/2026/Conference/Submission17563/Reviewer_GFAW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17563/Reviewer_GFAW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17563/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761628910466, "cdate": 1761628910466, "tmdate": 1762927426808, "mdate": 1762927426808, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes integrating object-centric learning into DETR-based detectors for source-free domain adaptive object detection. Specifically, the Hierarchical Slot Awareness (HAS) module decomposes an image into a set of slots, which are then fused with queries to inject object-level visual priors into the object decoder. Additionally, a Class-Guided Slot Contrast (CGSC) mechanism is introduced to guide the slots toward domain-invariant yet class-relevant object features by leveraging contrastive learning with class prototypes. Extensive experiments on multiple datasets demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The method achieves state-of-the-art performance across multiple datasets.\n\n2. The authors provide a solid theoretical analysis explaining why slot-based features can offer domain-invariant priors."}, "weaknesses": {"value": "1. The HAS module introduces additional parameters and computation overhead. It would be beneficial to provide a comparison of speed and parameter size before and after adding HAS.\n\n2. The authors did not provide the performance of the source-only model after adding HAS. This omission makes it unclear whether the performance improvement stems from a stronger source-only model or from HAS enhancing the adaptation capability.\n\n3. HAS requires self-supervised pretraining on the COCO dataset. It would be useful to discuss the importance of this pretraining step."}, "questions": {"value": "1. Why is CGSC not used during training on the source data?\n2. Can this method be applied to source-available domain adaptive object detection (DAOD)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2aLqvv41lw", "forum": "yiF4Jo38AP", "replyto": "yiF4Jo38AP", "signatures": ["ICLR.cc/2026/Conference/Submission17563/Reviewer_5pPM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17563/Reviewer_5pPM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17563/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761819663823, "cdate": 1761819663823, "tmdate": 1762927426346, "mdate": 1762927426346, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework called CGSA, specifically designed for source-free domain adaptive object detection (SFA-OD). CGSA embeds object-centric slot representations into DETR queries, progressively disentangles target images into coarse-to-fine slots and aligns slot prototypes with online class prototypes. Experiments show the effectiveness of the proposed CGSA."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is easy to follow.\n* Using a slot-aware framework for object-level alignment is a reasonable approach.\n* Experiments on five cross-domain shows the effectiveness of the proposed method."}, "weaknesses": {"value": "1. The performance of the base model should be reported(e.g., RT-DETR) for better evaluation.\n2. As shown in Figure 3, the HSA module adapts the pre-trained DINO model. Therefore, the additional computation overhead needs to be analyzed.\n3. Since the method uses a pre-trained model to inject feature knowledge, it is recommended to add some comparative introductions with existing methods that use VLM for knowledge injection, such as [1][2]. And recent DETR-based SFOD methods should also be discussed, such as [3].\n\n[1] Da-ada: Learning domain-aware adapter for domain adaptive object detection. NeurIPS 2024\n\n[2] SEEN-DA: SEmantic ENtropy guided Domain-aware Attention for Domain Adaptive Object Detection. CVPR 2025\n\n[3] Source-Free Object Detection with Detection Transformer. IEEE TIP 2025"}, "questions": {"value": "Please refer to Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ee7gb3j47y", "forum": "yiF4Jo38AP", "replyto": "yiF4Jo38AP", "signatures": ["ICLR.cc/2026/Conference/Submission17563/Reviewer_jc6a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17563/Reviewer_jc6a"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17563/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824019207, "cdate": 1761824019207, "tmdate": 1762927425715, "mdate": 1762927425715, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of Source-Free Domain Adaptive Object Detection (SF-DAOD), where a detector trained on a labeled source domain is adapted to an unlabeled target domain without accessing source data during adaptation. The authors argue that existing SF-DAOD approaches neglect object-level structural information across domains. To address this issue, they propose a new framework named CGSA, which introduces Object-Centric Learning (OCL) into SF-DAOD through slot-aware adaptation. The framework contains two main components: (1) Hierarchical Slot Awareness (HSA), which disentangles image features into slot representations; and (2) Class-Guided Slot Contrast (CGSC), which enhances semantic consistency and promotes domain-invariant adaptation. Experiments on five cross-domain object detection benchmarks show that CGSA achieves consistent performance gains compared to prior SF-DAOD methods. The paper also provides some theoretical analysis to justify the generalization of the proposed approach."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors conduct experiments on multiple benchmark datasets, showing that their method achieves better performance than previous approaches.\n\nThe paper includes theoretical discussions supporting the generalization ability of the proposed method."}, "weaknesses": {"value": "The paperâ€™s description of the proposed method, especially the role of slot attention, is unclear. From the current presentation, it appears that slot attention is applied to the queries in DETR. However, it is not clear how this differs in essence from standard attention mechanisms. The authors should provide a clear comparison or ablation study to demonstrate why slot attention is necessary in this context.\n\nThe paper claims that slot attention helps capture object-level features. However, the provided visualization (Figure G.1 in the supplementary materials) does not clearly show the effectiveness of slot-based decomposition. The authors should include more convincing visual evidence or quantitative analysis to illustrate how slot representations correspond to distinct object structures.\n\nThe proposed method is built on DETR, while several compared SF-DAOD methods are based on Faster R-CNN. Since DETR generally outperforms Faster R-CNN even without adaptation, the comparison may not be fully fair. The authors are encouraged to implement their framework on Faster R-CNN to ensure a fair comparison and isolate the improvement brought by the proposed adaptation mechanism from that of the detector architecture itself."}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XN8AGb2QwE", "forum": "yiF4Jo38AP", "replyto": "yiF4Jo38AP", "signatures": ["ICLR.cc/2026/Conference/Submission17563/Reviewer_WgAU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17563/Reviewer_WgAU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17563/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914565861, "cdate": 1761914565861, "tmdate": 1762927425370, "mdate": 1762927425370, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}