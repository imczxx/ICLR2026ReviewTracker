{"id": "TXJ7vLgOS4", "number": 3297, "cdate": 1757396097717, "mdate": 1759898097383, "content": {"title": "BoostStep: Boosting Mathematical Capability of Large Language Models via Step-aligned In Context Learning", "abstract": "Large language models (LLMs) have demonstrated impressive ability in solving complex mathematical problems with multi-step reasoning and can be further enhanced with well-designed in-context learning (ICL) examples. However, this potential is often constrained by two major challenges in ICL: granularity mismatch and irrelevant information.\nWe observe that while LLMs excel at decomposing mathematical problems, they often struggle with reasoning errors in fine-grained steps. Moreover, ICL examples retrieved at the question level may omit critical steps or even mislead the model with irrelevant details.\nTo address this issue, we propose BoostStep, a method that enhances reasoning accuracy through step-aligned ICL, a novel mechanism that carefully aligns retrieved reference steps with the corresponding reasoning steps. Additionally, BoostStep incorporates an effective \"first-try\" strategy to retrieve for exemplars highly relevant to the current state of reasoning.\nBoostStep is a flexible and powerful method that integrates seamlessly with chain-of-thought (CoT) and tree search algorithms, refining both candidate selection and decision-making. Empirical results show that BoostStep improves GPT-4o’s CoT performance by 4.6\\% across mathematical benchmarks, significantly surpassing traditional few-shot learning's 1.2\\%. Moreover, it can achieve an additional 7.5\\% gain combined with tree search. Surprisingly, it enhances state-of-the-art LLMs to solve challenging math problems using simpler examples. It improves DeepSeek-R1-671B and Qwen3-235B’s performance on AIME by 2.2\\% and 5.0\\% respectively, leveraging simple examples only from the MATH dataset.", "tldr": "BoostStep integrates a step-aligned in-context learning mechanism, effectively enhancing the math reasoning performance of SOTA reasoning models like GPT-4o and DeepSeek-R1.", "keywords": ["Mathematical Reasoning", "Large Language Models", "In-context Learning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f03fa4e9f9757d054bd9586f7e21dfbaeeafc9e1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces BoostStep, a novel method to enhance the mathematical reasoning capabilities of LLMs by refining in-context learning (ICL). BoostStep addresses the issues of traditional ICL by shifting ICL from the problem level to the step level. The core of the method is a \"first-try\" strategy: for each step in a problem, the model first generates an initial attempt. This attempt serves as a semantic query to retrieve a highly relevant, correct reasoning step from a pre-compiled example bank. This targeted example then guides the model to produce a more accurate final step. The paper also emphasizes the importance of creating the example bank by segmenting solutions based on reasoning content rather than simple grammatical delimiters.\n\nThe authors evaluate across multiple models (GPT-4o and Qwen variants) and mathematical benchmarks (MATH, AIME, MathVerse). The results consistently show that BoostStep outperforms both zero-shot and traditional few-shot ICL baselines. Notably, the method demonstrates the ability to use simpler examples to solve more complex problems, generalizes to out-of-distribution benchmarks, and even provides gains in multi-modal reasoning tasks. Finally, the paper shows that BoostStep can be effectively integrated into tree-search algorithms, improving the performance of both the reasoning and verification components."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "*   **Observation and Problem Formulation:** The paper identifies a fundamental bottleneck in LLM reasoning—that errors are often local to a specific reasoning step, while guidance from traditional ICL is global. This reframing of the problem from problem-level to step-level is both intuitive and powerful.\n*   **Effective Method:** The proposed \"first-try\" retrieval mechanism is an effective solution. Using the model's initial reasoning attempt as a rich semantic query to find a relevant example is a significant improvement over methods that rely only on previous correct steps or the overall problem statement.\n*   **Comprehensive Evaluation:** The experimental validation is thorough and convincing. The authors use multiple state-of-the-art models and mathematical benchmarks. The performance gains reported in Tables 1, 2, and 3 strongly support the paper's claims.\n*   **Generalization:** The method shows remarkable robustness. The \"simple-aids-complex\" result (Table 2), where examples from the MATH dataset help solve more challenging AIME problems, is particularly impressive. Furthermore, its ability to improve performance on out-of-distribution and even cross-modality benchmarks (Table 3) highlights that BoostStep learns transferable reasoning patterns."}, "weaknesses": {"value": "*   **Dependence on Example Bank Quality:** The performance of BoostStep is tied to the quality and coverage of the step-level example bank. The paper notes strong performance using a bank built from PRM800K, but it would be beneficial to include a brief discussion on the method's sensitivity to the bank's size and diversity.\n*   **Details on Step Segmentation:** The authors propose a superior method for dividing solutions into steps based on \"reasoning content\" rather than grammatical delimiters. This is a key part of the contribution. While Figure 3 shows a compelling example, the paper could benefit from slightly more detail on the specific prompts or methods used to guide the LLM in performing this crucial segmentation task during the creation of the example bank."}, "questions": {"value": "* **Failure Analysis:** Could you provide insight into the primary failure modes of BoostStep? For example, are there cases where a retrieved step, despite its high similarity score, actually misleads the model due to a subtle contextual difference between the two problems?\n\n* **Sensitivity to the Rejection Threshold:** The paper uses a similarity threshold of 0.7 to decide whether to provide an example. How was this value determined, and how sensitive is the overall performance to this hyperparameter?\n\n* **Applicability to Other Domains:** While the method is brilliantly applied to mathematical reasoning, its core idea seems applicable to other domains requiring complex, sequential reasoning (e.g., programmatic code generation, legal reasoning, or complex question answering). Have you considered the potential of BoostStep in these other areas?\n\n* **Dynamic Knowledge Integration:** The example bank is constructed offline. Do you see a path forward for a system where BoostStep could dynamically integrate newly solved and verified reasoning steps into its own bank, creating a self-improving reasoning system over time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8lvNSq6XNH", "forum": "TXJ7vLgOS4", "replyto": "TXJ7vLgOS4", "signatures": ["ICLR.cc/2026/Conference/Submission3297/Reviewer_GjNr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3297/Reviewer_GjNr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761182297271, "cdate": 1761182297271, "tmdate": 1762916651847, "mdate": 1762916651847, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces BoostStep, a step-aligned in-context learning framework for mathematical reasoning with LLMs. The method builds a bank of step-level exemplars by segmenting worked solutions, runs a quick first-try to guess the next step for the current problem, retrieves similar steps from the bank, and then conditions the model on those exemplars to generate and verify the next step. The authors also plug this idea into tree-style search with a process-reward model, injecting examples during both generation and verification. On several math benchmarks they report gains over zero-shot and standard few-shot prompting, and provide ablations on segmentation and retrieval choices. While the high-level idea is practical and intuitive, I find the empirical support incomplete and the evaluation not aligned with current  standards."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper targets a real pain point. i.e. problem-level exemplars often do not align with the local reasoning step. The proposed pipeline is straightforward to implement, integrates seamlessly with tree search, and appears to consistently produce improvements over plain few-shot learning on several datasets. I also appreciate the attempt to improve step segmentation beyond naive punctuation splitting, which is a practical detail many works gloss over."}, "weaknesses": {"value": "The most serious issue is the already outdated and selective benchmarking. The idea of aligning ICL at the step granularity with a first-try cue is neat from an engineering perspective, but the novelty is incremental compared to existing step-wise reasoning and retrieval-augmented prompting. \n\nMore importantly, the contribution is weakened by the evaluation choices as the model set is not up-to-date and coverage across benchmarks is uneven, so it is hard to judge how competitive this really currently is, especially when considering the fast-paced development. Newer frontier models are only represented in a narrow AIME experiment and not across the full suite. This does not meet ICLR2026 quality expectations and makes the gains hard to interpret. \n\nOn methodology, retrieval is under-analyzed (no quality metrics, no dense/hybrid baselines), statistics are missing (no CIs, no seed variation), and the grading depends on a related model family instead of an independent checker or human audit. Efficiency is not convincingly quantified, given the extra pass and longer prompts. I also worry about potential leakage at the step level since the bank is built from overlapping sources. There is no near-duplicate analysis to rule this out. Finally, several ablations are incomplete (no sensitivity to the rejection threshold, no study of exemplar count and no taxonomy of failure cases where the retrieved step actually misleads)."}, "questions": {"value": "1) Will you re-run the current frontier models (e.g., the latest math-specialized open and strong closed models) across all main benchmarks and report compute-matched numbers with confidence intervals?\n\n2) Can you provide retrieval diagnostics (precision@k/nDCG) and compare TF-IDF with a modern dense retriever and a hybrid setup, including a sensitivity study for the rejection threshold and exemplar count k?\n\n3) How robust are your results to the judge? Please re-score a stratified subset with exact/symbolic matching, a different model family as grader, and, where feasible, human adjudication.\n\n4) Please include end-to-end cost/latency per problem (tokens and wall-clock) for base few-shot vs. BoostStep, both with and without tree search.\n\n5) Did you run a near-duplicate audit at the step level between the step bank and each test set? If yes, please quantify."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "20ATnW1FUN", "forum": "TXJ7vLgOS4", "replyto": "TXJ7vLgOS4", "signatures": ["ICLR.cc/2026/Conference/Submission3297/Reviewer_DQnD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3297/Reviewer_DQnD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761395162034, "cdate": 1761395162034, "tmdate": 1762916651534, "mdate": 1762916651534, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes BoostStep, which aims to enhance reasoning accuracy through aligning retrieved reference steps with the corresponding reasoning steps. It introduces a first-try strategy to ensure high relevance between retrieved examples and current reasoning, marking a shift from problem-level to step-level ICL. Booststep can be combined with CoT and tree search algorithms to improve LLMs to solve math problems."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- BoostStep refines in-context learning from the problem level to the step level, enabling guidance for each reasoning step rather than coarse whole-problem imitation.\n- It introduces a novel first-try strategy: the model first attempts a reasoning step, then retrieves the most similar example step. This improves relevance and reduces distraction from irrelevant examples.\n- The method can be integrated into CoT and tree-search frameworks, which further enhances the model’s performance."}, "weaknesses": {"value": "- When the model’s initial reasoning output is poor, the system cannot effectively perform step-wise in-context learning, since the retrieval stage depends on the content of this initial attempt. In such cases, BoostStep either retrieves irrelevant examples or rejects retrieval altogether, providing no additional guidance.\n- The accuracy of LLM’s automatic step-splitting is not guaranteed. The construction of the step-level problem bank needs further validation.\n- The first-try → retrieve → re-reason cycle adds 30% more inference time, which may become too expensive and less practical for large-scale applications. The trade-off should be further investigated and addressed."}, "questions": {"value": "- As the performance of BoostStep depends on retrieving semantically similar step-level examples, how would the method scale with a significantly larger or more diverse step-level problem bank? \n- Could the authors provide the experimental results for BoostStep when used without the MCTS component? It would be helpful to isolate the contribution of step-aligned in-context learning alone.\n- Can the step-aligned ICL framework transfer to domains beyond mathematics, such as code reasoning or physics derivations, without re-collecting a new step-level example bank?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ySKF3hEDpu", "forum": "TXJ7vLgOS4", "replyto": "TXJ7vLgOS4", "signatures": ["ICLR.cc/2026/Conference/Submission3297/Reviewer_xqRf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3297/Reviewer_xqRf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761763113312, "cdate": 1761763113312, "tmdate": 1762916650851, "mdate": 1762916650851, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper describes a method to perform stepwise retrieval method for ICL called BoostStep, which performs a draft reasoning for retrieval, gain improvements over a few shot baseline on a collection of datasets."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. improvement over baseline few shot ICL method\n2. nice combination with tree-based searching methods"}, "weaknesses": {"value": "1. missing a couple of details in the experiments and claims\n2. the comparison baseline is crispy, similar methods such as IDS (Qin et al. EMNLP findings 24) and LMS3 (Liu et al. 24) are only compared on one dataset, and the base model is not even the same, the reported results for comparison was conducted on GPT-4 while the major results were conducted on GPT-4o, no evidence shows that the current method can outperform these two baselines\n3. the ablation of the method itself is also crispy, see questions part for details. The current experiments does not reveal where the performance gains from"}, "questions": {"value": "1. what exactly is the baseline setting? not given in the current paper\n2. what is the performance of the model performing one-step reasoning with \"Prompt for first-try in step-level COT\"?\n3. what is the performance of the model performing overall retrieval of similar reasoning steps instead of stepwise?  \n4. The authors claim that only 30% more tokens are used, which is quite strange that even only retrieval for once would at least double the cost, so after all is it less than 30% of the examples need retrieval? if similar rejection techniques are applied to other retrieval baselines how would it work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "d1sMxne92z", "forum": "TXJ7vLgOS4", "replyto": "TXJ7vLgOS4", "signatures": ["ICLR.cc/2026/Conference/Submission3297/Reviewer_JDZW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3297/Reviewer_JDZW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3297/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762001046788, "cdate": 1762001046788, "tmdate": 1762916650669, "mdate": 1762916650669, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}