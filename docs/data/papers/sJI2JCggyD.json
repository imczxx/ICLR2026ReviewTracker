{"id": "sJI2JCggyD", "number": 3142, "cdate": 1757342032955, "mdate": 1759898106532, "content": {"title": "Delta Activations: A Representation for Finetuned Large Language Models", "abstract": "The success of powerful open source Large Language Models (LLMs) has enabled the community to create a vast collection of post-trained models adapted to specific tasks and domains. However, navigating and understanding these models remains challenging due to inconsistent metadata and unstructured repositories. We introduce Delta Activations, a method to represent finetuned models as vector embeddings by measuring shifts in their internal activations relative to a base model. Clustering analysis shows that Delta Activations achieve strong separation of finetuned domains, significantly outperforming baselines such as flattened weights, salient parameter masks, and output embeddings, while being more lightweight and computationally efficient. Delta Activations also demonstrate desirable properties: it is robust across finetuning settings and exhibits an additive property when finetuning datasets are mixed. We also explore extensions of Delta Activations: it can represent tasks via few-shot finetuning for reliable model retrieval and guide model selection for merging by quantifying similarity between models. Furthermore, activations can be substituted with other representation extraction methods, demonstrating the flexibility of the broader Delta-X framework.\nWe hope Delta Activations can facilitate the practice of reusing publicly available models.", "tldr": "", "keywords": ["Representation", "LLM", "post-training", "finetuning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dbcbf8f237be01f339198ed027a40d96cf9d96d6.pdf", "supplementary_material": "/attachment/6ceee2ddace6c257d09e121576f863613850829a.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces \"Delta Activations\", a simple and efficient method to create a compact vector \"fingerprint\" for any fine-tuned LLM. The method works by feeding a small set of generic, task-agnostic prompts into both the fine-tuned model and its original base model, and then calculating the _difference_ (the delta) between their internal activations at the final layer. The authors demonstrate that these DA fingerprints are highly effective, allowing models to be automatically and accurately clustered by their specialized domain. Furthermore, the paper shows that this embedding space has some potential capabilities, like additive property and model selection."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Delta Activations method is simple and efficient. It only requires model inference.\n2. The paper discusses various potential methods and shows that Delta Activations works best.\n3. The paper points out potential further research directions."}, "weaknesses": {"value": "1. The motivation is not clear enough. Why representation of models in the same pool should be close? I feel it's more like a hypothesis assumption. The model with very close embedding to a specific task may have bad generalization.\n2. The paper's experimental results are mainly based on the silhouette score, which is just a \"proxy\" metric measuring how well the embeddings clustered. However, the main objective should be applications like downstream task performance, while this paper rarely shows such results.\n3. **Model selection and similarity measurement** (line 421) paragraph is the only place that shows downstream task results. However, this experimental setup is a bit vague. Why only identify the _single_ most-related model and sample the remaining 19 models randomly? Why not sample the top 20 most-related models, which is more aligned to the paper's hypothesis and should even show further improvement?\n4.  **Additive property** experiments show Mixed and Sum has high similarity. But what's the benefit here is unclear. This setting has a big gap between model merging. And a maximum 0.73 cosine similarity in table 4 is not very strong.\n5. The experimental setup is too ideal. The data domains are separated clearly, and they are more independent. But real training data is usually mixed and complex."}, "questions": {"value": "1. Could you explain more about **Additive property** paragraph in line 290? I don't get what's the benefit there.\n2. In line 210, it should be **each** pool contains 15 models or it includes 15 models in total for three pools?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sfNQ1NAwj6", "forum": "sJI2JCggyD", "replyto": "sJI2JCggyD", "signatures": ["ICLR.cc/2026/Conference/Submission3142/Reviewer_9JVg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3142/Reviewer_9JVg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3142/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880589377, "cdate": 1761880589377, "tmdate": 1762916569738, "mdate": 1762916569738, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Fine-tuned large language models (LLMs) are abundant but hard to reuse due to poor metadata and disorganization. This paper proposes **Delta Activations**—a lightweight way to turn fine-tuned models into vector embeddings by comparing internal activation differences between fine-tuned and base models on generic prompts.  \n\nIt outperforms baselines in domain-based clustering (average silhouette score 0.614 across 3 base models) and has key strengths: robustness to training changes, additive properties for mixed datasets, and extension into the **Delta-X framework** (supporting logits/semantic representations). It also enables few-shot task embedding for model retrieval and better model selection for merging (2.0% BBH accuracy gain), aiding efficient reuse of public fine-tuned LLMs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.\tAn interesting problem. It points out the difficulty of reusing fine-tuned LLMs caused by messy metadata and unorganized repositories.\n2.\tLightweight and efficient: Delta Activations only needs one forward pass to compute, avoiding complex calculations like matrix factorization.\n3.\tStrong clustering ability: It outperforms baselines (e.g., flattened weights, output embeddings) in grouping models by fine-tuned domains, with an average silhouette score of 0.614 across three base models."}, "weaknesses": {"value": "1.\tInsufficient evidence for research motivation: The paper claims fine-tuned LLMs are underused due to poor metadata, but lacks real-world data (e.g., stats on unused models or user surveys) to prove this problem.\n2.\tVague practical applications for reuse: It mentions aiding model reuse, but gives few details on how end-users (e.g., developers) would actually apply it, like no step-by-step example of retrieving a model for a real task.\n3.\tRelies on internal model access: It needs hidden activations, which are unavailable for closed-source LLMs—limiting its real-world use where many LLMs are proprietary."}, "questions": {"value": "1.\tCould you provide more real-world evidence (e.g., statistics on unused fine-tuned LLMs, surveys of developers’ reuse struggles) to support the scale and urgency of the \"poor metadata causing underused models\" problem?\n2.\tCan you give a concrete, step-by-step example of how end-users (e.g., a developer building a medical app) would apply Delta Activations to retrieve and reuse a domain-specialized fine-tuned model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XsZz4MQkqy", "forum": "sJI2JCggyD", "replyto": "sJI2JCggyD", "signatures": ["ICLR.cc/2026/Conference/Submission3142/Reviewer_6MYB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3142/Reviewer_6MYB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3142/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897883085, "cdate": 1761897883085, "tmdate": 1762916569559, "mdate": 1762916569559, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new method called \"Delta Activations,\" which aims to create efficient vector representations (embeddings) for a vast collection of fine-tuned LLM that often lack metadata.\n\nThe method works by feeding a fixed set of generic probe datasets into both a fixed \"base model\" and a \"fine-tuned model.\" It then calculates the difference (the \"delta\") between their last-layer hidden states. By aggregating these different vectors (e.g., by averaging), a unique vector embedding is generated for the fine-tuned model."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "* The method shows superior performance when clustering models that are initialized from the same base model.\n\n* The paper is well-written and flows smoothly."}, "weaknesses": {"value": "The paper's main contribution, \"Delta Activations,\" has a fundamental limitation: it heavily relies on a shared, architecturally identical base model. This is because the method's core operation is the calculation of differences between high-dimensional activation vectors (e.g., 4096-D). However, in today's LLM ecosystem, models are often based on different architectures or are closed-source, making their internal architectures inaccessible. Therefore, the truly critical and pressing challenge is cross-architecture model representation and clustering.\n\nThe paper relegates this key challenge to an extension called \"Delta Meaning.\" This approach represents a massive compromise: it degenerates from a high-dimensional (4096-D) internal activation space to an extremely low-dimensional (20-D) external probabilistic space. As shown in Table 3, the representational power of Delta Meaning is far weaker than that of Delta Activations (a score of just 0.20 vs. 0.61), confirming that a significant amount of critical internal information is lost during the transition to this probabilistic space.\nIn essence, Delta Activations solves a \"simple problem\" that relies on overly strong assumptions and is limited in real-world scenarios. Meanwhile, the solution it provides for the \"real problem\" (cross-architecture clustering) is excessively compromised on performance. Consequently, it is not a convincing solution for organizing a heterogeneous model ecosystem.\n\nFurthermore, if the model zoo is very large, even a single inference pass per model will introduce significant computational overhead. The method also relies on a fixed, small, \"generic\" Probe Dataset."}, "questions": {"value": "What is the biggest and most critical application scenario for this method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TP1UBBYsj8", "forum": "sJI2JCggyD", "replyto": "sJI2JCggyD", "signatures": ["ICLR.cc/2026/Conference/Submission3142/Reviewer_KPrH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3142/Reviewer_KPrH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3142/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762003192936, "cdate": 1762003192936, "tmdate": 1762916569370, "mdate": 1762916569370, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}