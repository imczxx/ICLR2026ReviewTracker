{"id": "eEmTxqxLtU", "number": 4431, "cdate": 1757679837622, "mdate": 1759898032748, "content": {"title": "Flames: Multi-Scale Mamba with Adaptive Fourier Filters and Laplace Transform for Time Series Forecasting", "abstract": "Time series data usually exhibit intricate characteristics such as non-stationarity, noise, multi-scale periodicity, and transient dynamics, posing significant challenges to long-term time series forecasting (LTSF). While transformer-based models effectively capture long-range dependencies, their practical applications are hindered by high computational cost with quadratic complexity, noise sensitivity, and overfitting on small datasets. Moreover, time series present distinct patterns at different temporal resolutions, containing both fine-grained (micro) and coarse-grained (macro) information. To address these issues, we propose a novel framework, Flames (multi-scale Fourier Filter Mamba with Laplace), designed for efficient and robust LTSF. Specifically: (i) We introduce an adaptive Fourier filter with a selection module embedded into Mamba. At each scale, the neural operator uses Fourier analysis to refine feature representations, applies learnable thresholds for noise reduction, and captures inter-frequency interactions via global-local semantic filters through element multiplication. (ii) We incorporate the Laplace transform to capture transient dynamics. Extensive experiments on multiple benchmarks demonstrate that Flames consistently outperforms SOTA methods, achieving superior accuracy–efficiency trade-offs. Results highlight its strong robustness and scalability, particularly in noisy or transient settings.", "tldr": "", "keywords": ["Time Series Forecasting", "Adaptive Fourier Filter", "Mamba", "Multi- Scale", "Laplace Transform"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bd30066475e14b4c2a9bea4e62a47bd88296cae0.pdf", "supplementary_material": "/attachment/c0b5728e9c85ba05bbc40d733bfdf8d5f1b474c9.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel multi-scale Mamba framework that incorporates adaptive Fourier filters to cover all frequencies at each scale and a Laplace-transform module to capture short-term fluctuations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. This paper proposes an Adaptive Fourier Filter Module (AFFM) encoder, which employs adaptive Fourier filtering to capture multi-scale periodic patterns and to reduce noise.\n2. This paper applies the inverse Laplace transform to extract short-term dynamics."}, "weaknesses": {"value": "1. The paper is poorly organized and lacks clarity in writing, making it difficult to follow. In addition, multiple inconsistencies in symbol usage should be carefully reviewed, for example, the one observed on Line 232.  \n2. The motivation of the paper is not clear. In the Introduction, the authors argue that using Mamba as the backbone faces three key challenges: (i) multiscale periodicity, (ii) data noise, and (iii) transient dynamics. However, no strong prior studies or preliminary experiments are provided to substantiate these claims. Other important assertions, such as “Linear struggles with noisy data and fails to capture long-term dependencies effectively” are likewise unsupported. In addition, the manuscript does not offer a substantive discussion of whether alternative backbones (e.g., Transformer, MLP) can address these three challenges, nor does it provide comparative analysis to justify the choice of Mamba.  \n3. It would strengthen the work to include additional frequency filter-based baselines, such as FilterNet [1], TSLANet [2], which are closely related to the proposed approach.  \n\n[1] FilterNet: Harnessing Frequency Filters for Time Series Forecasting. NeurIPS, 2024.  \n[2] TSLANet: Rethinking Transformers for Time Series Representation Learning. ICML, 2024."}, "questions": {"value": "pls refer to weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nSzIUvMgPW", "forum": "eEmTxqxLtU", "replyto": "eEmTxqxLtU", "signatures": ["ICLR.cc/2026/Conference/Submission4431/Reviewer_nUNg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4431/Reviewer_nUNg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4431/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915831394, "cdate": 1761915831394, "tmdate": 1762917360817, "mdate": 1762917360817, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposed a framework for long-term time series forecasting. The model enhances the Mamba state space model by integrating three components. Experimental results on eight benchmark datasets show that Flames achieves good performance, outperforming Transformer- and MLP-based baselines with better noise robustness, scalability, and computational efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Combines Fourier and Laplace transforms with state space modeling for a unique approach to capturing multi-scale and transient temporal patterns.\n- Demonstrates consistent improvement over leading baselines across multiple datasets and noise levels, with extensive ablation and robustness studies.\n- Achieves linear computational complexity, lower parameter counts, and faster inference while maintaining high accuracy."}, "weaknesses": {"value": "- The combination of multi-scale processing, Mamba, Adaptive Fourier Filters, and the Inverse Laplace Transform makes the overall model architecture intricate and potentially complex to implement and fine-tune compared to simpler linear or pure Mamba models The formulation, particularly for the Laplace transform integration, is dense.\n- While claims about interpretability are made, there is little empirical validation of how the model captures transient dynamics or multi-scale features in practice. \n- The paper notes that the optimal number of scales varies with the prediction length, suggesting that a fixed choice (like M=3 for efficiency) may not be universally optimal and would require a trade-off analysis for new datasets or forecasting horizons."}, "questions": {"value": "- How to simplify or modularize the integration of multi-scale processing, Adaptive Fourier Filters, and the Inverse Laplace Transform to make the model easier to implement and fine-tune?\n- What experimental approaches or visual analyses could be added to empirically validate how the model captures transient dynamics and multi-scale temporal features?\n- How can the model adaptively determine or learn the optimal number of scales for different datasets or forecasting horizons wthout manual tuning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "mZq0KEOSGz", "forum": "eEmTxqxLtU", "replyto": "eEmTxqxLtU", "signatures": ["ICLR.cc/2026/Conference/Submission4431/Reviewer_Q1SQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4431/Reviewer_Q1SQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4431/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943463595, "cdate": 1761943463595, "tmdate": 1762917360082, "mdate": 1762917360082, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FLAMES, a long-term time-series forecasting model. The FLAMES augments Mamba with three components. (i) multi-scale feature extraction, (ii) Adaptive Fourier Filter Mamba that performs FFT-domain masking and global/local learnable frequency mixing to denoise and enhance periodic structure, and (iii) Laplace transform to capture transient dynamics. Experiments on multiple benchmarks report consistent gains over baselines. The paper also conducts ablations for each component, robustness to synthetic noise, and a scalability analysis to show the superiority of FLAMES."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ The time series forecasting, particularly long-term time series forecasting is an important and practical problem. \n\n+ The evaluation is comprehensive. The experimental results comprehensively cover multiple datasets and horizons with ablations, look-back sensitivity, robustness to noise, and scalability analysis."}, "weaknesses": {"value": "- The method is a careful combination of known tools (such as Mamba, Fourier filter, and Laplace transform) and rather than a fundamentally new learning principle. The paper would benefit from a more formal analysis combing these modules together.\n\n- The paper does not compare many Mamba-based time series forecaster despite mainly built on Mamba backbone. The only relevant baseline is DTMamba. It is not clear why the authors ignore many other Mamba-based time series forecasting papers, even if they are earlier or have been accepted by decent conferences. Just list some examples as below:\n\n[1] Ahamed et al. TimeMachine: A Time Series is Worth 4 Mambas for Long-term Forecasting. ECAI. 2024\n\n[2] Xu et al. SST: Multi-Scale Hybrid Mamba-Transformer Experts for Long-Short Range Time Series Forecasting. CIKM. 2025\n\n[3] Patro et al. SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series. arxiv. 2024.\n\n[4] Hu et al. Time-SSM: Simplifying and Unifying State Space Models for Time Series Forecasting. arxiv, 2024."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RG6q8yoZZW", "forum": "eEmTxqxLtU", "replyto": "eEmTxqxLtU", "signatures": ["ICLR.cc/2026/Conference/Submission4431/Reviewer_A1tm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4431/Reviewer_A1tm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4431/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976212912, "cdate": 1761976212912, "tmdate": 1762917359530, "mdate": 1762917359530, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}