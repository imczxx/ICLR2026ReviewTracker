{"id": "WELrlKB4be", "number": 11937, "cdate": 1758204790582, "mdate": 1759897544169, "content": {"title": "Whole-Brain Connectomic Graph Neural Network Enables Whole-Body Locomotion Control in Drosophila", "abstract": "Whole-brain connectome provides a structural blueprint for linking neural circuits to behavior, yet its application to embodied control remains largely unexplored. We introduce the fly-connectomic Graph Neural Network (flyGNN), a reinforcement learning controller whose architecture is instantiated directly from a complete adult Drosophila connectome. Our flyGNN models the connectome as a directed message-passing graph, partitioned into afferent, intrinsic, and efferent pathways that structure information flow from sensory inputs to motor outputs. Integrated with a dynamically controllable biomechanical model of Drosophila, flyGNN achieves stable control across diverse locomotion tasks, including gait initiation, walking, turning, and flight, without task-specific architectural tuning. These results demonstrate that whole-brain connectivity can directly support embodied reinforcement learning, establishing a new paradigm for connectome-based control algorithms.", "tldr": "We show that a controller instantiated directly from the Drosophila whole-brain connectome can achieve diverse embodied locomotion behaviors, demonstrating connectome topology as a powerful inductive bias for deep reinforcement learning.", "keywords": ["Connectomics", "Graph Neural Network", "Embodied Intelligence", "Sensorimotor Control"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bc0b0bb58243ada08d3b04b48bd6eb4db4746251.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper stands at the intersection of embodied AI and neuroscience, and introduces a novel paradigm which leverages whole-brain connectome for designing learning-based control policies. The proposed flyGNN that mirrors Drosophila connectome is validated on a biomechanical model of fruit fly in MuJoCo and shown to successfully realize four locomotion tasks, spanning gait initiation, walking, turning and flight. The paper also provides in-depth analysis of dynamic neural activities and specialization within flyGNN, yielding meaningful and interpretable results that could also inspire neurobiology studies."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1.This paper addresses an interesting yet under-explored research problem, i.e., embedding whole-brain connectome into controller architectures to yield biologically inspired computational models. It displays a promising avenue for bridging neuroscience and artificial intelligence and how they could provide valuable insights for each other. \n\n2.The proposed fly-connectomic Graph Neural Network (flyGNN) is validated within the flybody physics simulator across four locomotion tasks, showing successful task completion. \n\n3.The abundant visualization results reveal the potential of flyGNN to discover dynamic neural activity patterns, as well as uncover emergent specialization across different functional roles."}, "weaknesses": {"value": "1.The paper lacks any performance comparisons with simpler neural architectures, such as MLPs and vanilla graph neural networks. This leaves it questionable whether the introduction of connectomic inductive biases truly benefits the learning of intelligent behaviors. \n\n2.The authors are suggested to describe in greater detail the training procedure of flyGNN. For example, why do they adopt an imitation learning phase, in contrast to many other robotic control policies that are trained using RL from scratch. Moreover, it is not clearly explained how the MLP-based policy was originally trained, including the source of expert demonstrations."}, "questions": {"value": "1.Could the authors describe the labors required for converting the original FlyWire model into the code of the controller architecture? Is any automation feasible during this process? \n\n2.Following Weaknesses 1, given the higher computation and memory budges of flyGNN, have the authors validated the actual performance gains over simple architectures? Specifically, could the authors provide quantitative comparisons between flyGNN and MLP/vanilla GNNs with comparable parameter amounts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tYD9Q0Uk9C", "forum": "WELrlKB4be", "replyto": "WELrlKB4be", "signatures": ["ICLR.cc/2026/Conference/Submission11937/Reviewer_2soe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11937/Reviewer_2soe"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761737540742, "cdate": 1761737540742, "tmdate": 1762922942693, "mdate": 1762922942693, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose FlyGNN: a graph neural network which uses the Drosophila connectome as a template for its connectivity. The authors claim to simulate the full neural network of the Drosohpila, which numbers upwards of 100,000 neurons. The show that such a network can be trained to control a MuJoCo version of Drosophila that can both walk and fly."}, "soundness": {"value": 1}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The paper is very well presented and the results compelling from an engineering standpoint. Getting this to work must have required a substantial amount of work given the complexity of the model. However, the authors show convincing results that the Drosophila model learns to locomote."}, "weaknesses": {"value": "The authors stated motivation is to bridge the gap between connectomics and neural network circuits that can learn (in their own words t answer the question: \"how can static connectomes be transformed into dynamic, functional models that reproduce the intricate and adaptive motor behaviors of animals?\". This is all well and good, but to what end? What questions does this merging between connectomics and \"plastic\" neural networks enables? What can we learn about Drosophila or about the relation between connectomics and neural networks more broadly? We can't say because the authors don't elaborate on any of it."}, "questions": {"value": "Here are some question that I believe should be answered before this work can be accepted:\n\n1. What is the benefit of including this connectomic information?\n2. Does the simulated Drosophila learn faster for example or is more robust?\n3. What are sensible null models to compare against? What do they tell us about the influence of a powerful model such as the GNN.\n4. Is the GNN variant that the authors settle on more or less biologically plausible? Is it not contradictory with the stated goal of adding more biological realism?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sHqqNvxyRV", "forum": "WELrlKB4be", "replyto": "WELrlKB4be", "signatures": ["ICLR.cc/2026/Conference/Submission11937/Reviewer_Vmi7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11937/Reviewer_Vmi7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828227303, "cdate": 1761828227303, "tmdate": 1762922941076, "mdate": 1762922941076, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper expands upon Vaxenburg et al., 2025 with a policy network constrained by the unweighted, directed structure implied by the Flywire Drosophila connectome dataset. The authors separate the network into afferent, intrinsic, and efferent neurons then decode efferent activity to continuous motor commands. The advertised contribution is a connectome-structured GNN that can drive walking, turning, and flight with the same architectural class. The environments, embodiment, and demonstration data derive from the Vaxenburg paper. The authors do not present a head-to-head comparison, they demonstrate that the connectome architecture can also achieve stable behavior. The authors claim that the connectome provides an inductive bias which yields interpretable internal organization. To support this claim, they present reduced-dimensional node activations which at times show rhythmic, compartment-specific structure during behavior and emergent segregation across superclasses. To train the network, the authors train the parameters of a policy whose topology is fixed by the unweighted brain graph first by imitation of the MLP \"expert\" and then by PPO fine-tuning. The trained weights are the encoder into the afferents, the afferent gate, the message passing operator on the graph, and the readout from efferents (and a separate MLP value network for PPO)"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is ambitious in scope, incorporating the entire Drosophila brain, and the authors make an important stride towards understanding this connectome in an embodied setting by replicating the results of the Vaxenburg paper. The authors also successfully demonstrate that a network structured like the connectome is capable of supporting all behaviors simultaneously. The implementation of the network as a GNN is a sound way to deal with the recurrence of the connectome and a source of novelty over the Vaxenburg paper."}, "weaknesses": {"value": "The authors omit details which are thought within the field to be very important for the working of the connectome- most importantly, this includes the number of synapses between neurons and the neurotransmitter, or at least the sign of the neurotransmitter. Especially lacking a threshold on number of synapses, the unweighted graph the authors use is probably too noisy and lacks the most important pathways (generally, the strongest connections a neuron makes have orders of magnitude more synapses than the weakest, and these weak connections are likely due to both developmental and reconstruction noise see: Flywire Schlegel paper). Additionally, the relevance of the rhythmic activity that the authors claim is thin given the lack of excitatory and inhibitory connections and the lack of a ventral nerve cord, which is putatively thought to be the primary driver of rhythmic activity in the motor tasks the authors describe (chiefly locomotion see: work of Eve Marder and John Tuthill for foundational and new, Drosophila-specific work respectively). From this newer work, it is known that descending neurons mostly encode low-frequency decisions, and the neural enactment of these decisions towards coordinating patterns of motor activity occurs in the VNC, which would be important to model. This does not preclude the importance of rhythms in the central brain, but the authors should further describe the neurons in which rhythms are present to discuss the biological plausibility or importance of these connections. The authors present a surrogate for neural activity in their neural representation intensity, but I would expect either a novel prediction (ie: specific neurons which are correlated with a specific behavior or characteristic of that behavior) and/or a connection to literature (an extrinsic model validation based on the numerous papers connecting central brain neurons to specific characteristics of behavior). \nOn the machine learning side, I question whether the results here support the claim of an inductive bias. I would expect any trained network to be able to learn function to some epsilon (Cybenko); the fact that a network can be trained to some task is not necessarily proof of a beneficial inductive bias. Additionally, claims of an inductive bias are somewhat confounded by the choice to distill from the expert MLP in the first place. To prove this claim, the authors should have had some baseline, for instance a dense network with the same number of neurons, a sparse network with the same number of neurons and edges, and/or a shuffling of the connectome's edges, maintaining the afferent/intrinsic/efferent partitions."}, "questions": {"value": "The following are a superset of questions that if answered would make the paper stronger:\n1) You treat the connectome as an unweighted- can you report sensitivity analysis where you (i) weight edges by synapse counts; (ii) threshold the graph by min-synapses; and (iii) incorporate sign (even heuristically from transmitter labels where available)?\n2) Towards inductive bias, could you aadd baselines? (i) a dense MLP matched on parameter count and inference time; (ii) a sparse random graph matched on nodes/edges; (iii) a degree-preserving edge rewire that maintains afferent/intrinsic/efferent partitions. Report sample efficiency, asymptotic return, and robustness under sensor noise.\n3) From the MLP teacher-student, can you prove the GNN shows advantages beyond simple distillation? Could you report (i) head-to-head returns vs. the MLP teacher on identical seeds; (ii) zero-shot generalization where the student outperforms the teacher under perturbations; and (iii) learning curves from scratch (no IL) to test whether the topology aids exploration/credit assignment.\n4) You mention the increased computational expense of the GNN model - could you report some quantification there? These could include parameter counts, FLOPs, and wall-clock inference time for flyGNN vs. MLP teacher.\n5) Much of the evidence is qualitative (snapshots/plots). Could you provide standardized metrics per task (e.g., CoM tracking error, fall rate, gait-phase stability, flight speed variance), and show confidence intervals over seeds?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ToJe58URr8", "forum": "WELrlKB4be", "replyto": "WELrlKB4be", "signatures": ["ICLR.cc/2026/Conference/Submission11937/Reviewer_DbnM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11937/Reviewer_DbnM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935596511, "cdate": 1761935596511, "tmdate": 1762922939311, "mdate": 1762922939311, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the \"flyGNN,\" a novel reinforcement learning (RL) controller for a simulated Drosophila agent. The key innovation is that the network architecture is not a generic multilayer perceptron (MLP) but is directly instantiated from the adult Drosophila whole-brain connectome (FlyWire). The connectome is modeled as a directed graph, partitioned into afferent (sensory input), intrinsic (internal processing), and efferent (motor output) pathways. The authors demonstrate that a single, untrained flyGNN policy, when trained with RL, can successfully control a sophisticated, physics-based biomechanical model (\"flybody\") to perform diverse locomotion tasks, including gait initiation, straight walking, turning, and flight. The authors claim that this demonstrates the sufficiency of connectome-level structural priors for complex motor control and that this structure leads to the emergence of functional specialization within the network without explicit supervision."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The central idea of using a complete, synaptic-resolution whole-brain connectome as the literal architecture for an RL controller is highly novel. It represents a significant and ambitious conceptual bridge between systems neuroscience and embodied artificial intelligence.\n\n- The ability to train a single policy on this complex, biologically-grounded architecture to perform a variety of distinct locomotion tasks (walking, turning, and even generalizing to flight) is a strong proof of concept. The (implied) videos are a compelling demonstration that the approach is viable.\n\n- By grounding the controller in a known anatomical blueprint, this work opens up a promising new avenue for interpretability. The analysis in Figure 9, while preliminary, shows the potential for linking learned neural dynamics directly to specific, annotated neural classes and potential pathways."}, "weaknesses": {"value": "While the core idea is strong and the results are visually impressive, the paper is currently in a preliminary state and suffers from significant weaknesses in its evaluation, justification of claims, and engagement with existing literature.\n\n\n- The paper's greatest weakness is the complete absence of quantitative baselines. The authors mention that standard RL policies use \"generic multilayer perceptrons\" but provide no comparison. To validate the claim that the connectome structure provides a \"powerful inductive bias,\" it is essential to compare flyGNN against standard architectures.\n    - Missing Baselines: The paper needs to include comparisons against, at a minimum (1) A standard MLP controller with a similar number of trainable parameters. (2) A generic Graph Neural Network (GNN) with a similar parameter count but on a non-biological graph (e.g., a random graph, a sparse graph) to show that the specific topology of the connectome matters.\n\n- The results are presented descriptively (e.g., \"successfully produced a smooth curved trajectory\"). There are no quantitative metrics for performance. How fast is the walking? How stable is the gait? What is the tracking error for the turning task? Without these metrics, it is impossible to \"judge the advancement\" or determine if the controller is performing well or just minimally functional.\n\n- The paper operates at the intersection of several massive fields (connectomics, computational neuroscience, GNNs, RL for locomotion) yet cites remarkably little literature. The \"Related Work\" section is sparse. Section 3.1 includes no citations, giving the false impression that this modeling approach exists in a vacuum. The discussion section contains no citations at all. The authors make sweeping claims about \"a new design paradigm\" and \"advancing both neuroscience and embodied artificial intelligence\" without situating their work relative to any existing studies, such as other neuro-inspired architectures or GNNs in RL, or the vast literature of RL for motor control outside of neuroscience.\n\n\n- Several key parts of the analysis are described in a vague, unscientific manner. The description of the neural analysis is unclear: \"...dimensional representations were reduced and normalized, yielding the quantity we term reduced neural representation intensity... a proxy for neural activity...\" This is insufficient. What dimensionality reduction method was used (PCA, UMAP, etc.)? How was it normalized? Why is this a valid \"proxy\" for neural activity? The clustering method is also opaque: \"We employed random down-sampling... neurons were reordered using a spectral method based on the Fiedler vector of the Laplacian constructed from similarity matrices of neural activity...\" This is a critical step for their \"functional specialization\" claim, but it is poorly explained and justified. How was the similarity matrix defined? Why was this specific clustering method chosen?\n\n\n- The paper's central scientific claim is that \"flyGNN develops functional specialization... directly from connectomic structure, without explicit supervision.\" This claim is not well-supported because it lacks a proper null model. The network is initialized with a highly specific, non-random structure where afferent, intrinsic, and efferent nodes already have vastly different topological roles. It is almost expected that nodes with different structural properties (e.g., inputs vs. outputs) will develop different functional representations during training. The authors fail to disentangle whether the observed specialization is due to the specific FlyWire connectome or just any complex, sparse, graph-structured initialization. A strong null model (e.g., a randomly rewired graph that preserves the in/out-degree distribution) is needed to show that the specific biological wiring is the causal factor.\n\n\n- The model is complex, incorporating the entire 139k-neuron connectome. The authors state their implementation is \"simplified\" (unweighted, directed graph). However, they provide no ablation study to identify which components are crucial for success. Is the full-scale connectome necessary? Would a smaller subgraph work? How important is the afferent/intrinsic/efferent partition? Without ablations, it's unclear why the model works, which limits its scientific and engineering insights."}, "questions": {"value": "1. Baselines: Can you provide quantitative performance metrics (e.g., gait stability, speed, task tracking error) and compare them against at least two critical baselines: (a) a standard MLP controller with a similar parameter count and (b) a GNN controller with a non-biological graph?\n\n\n2. Null Model: To substantiate the claim of \"emergent functional specialization,\" could you provide a comparison against a null model?\n\n\n3. Please elaborate on the spectral clustering method used in Figure 9b. How was the \"similarity matrix\" used to construct the Laplacian defined? Please also provide a precise definition for \"reduced neural representation intensity\"? Specifically, what dimensionality reduction technique was used, and what was the normalization procedure?\n\n\n4. Ablation Study: Given the model's complexity, what are the most crucial components for its success? Can you provide an ablation study (e.g., simplifying the graph, using a subgraph) to isolate the key drivers of performance?\n\n\n5. Literature Context: The discussion section makes broad claims but lacks citations. Could you please situate your work within the existing literature on graph neural networks for RL and other neuro-inspired locomotion controllers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6BooH3NHKS", "forum": "WELrlKB4be", "replyto": "WELrlKB4be", "signatures": ["ICLR.cc/2026/Conference/Submission11937/Reviewer_7bYN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11937/Reviewer_7bYN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958468070, "cdate": 1761958468070, "tmdate": 1762922938531, "mdate": 1762922938531, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}