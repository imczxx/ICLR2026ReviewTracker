{"id": "8xtzk0cHXO", "number": 18266, "cdate": 1758285796583, "mdate": 1759897115386, "content": {"title": "A Cooperation Index for Model Pruning", "abstract": "In complex models, pruning redundant parameters reveals its core functional elements, improving both generalizability and interpretability. Effective pruning can be achieved by criteria to identify redundant parameters, and the SHAP Value (SV) has been considered such a criterion, which is interpreted as averaging the marginal contributions across all possible parameter accumulation paths. However, we find that its averaging process systematically overweights redundant parameters, failing as a decision-making agent. Instead, quantifying the speed of decay of the marginal contribution can serve as a more effective decision criterion for model pruning. We show that it is more effective to count the number of cooperative contributions of parameters for pruning parameters in backward elimination, leading to a more optimal set of remaining parameters.", "tldr": "We propose a new criterion, cooperation Index, for effective model pruning to improve both generalizability and interpretability of the model..", "keywords": ["Parameter Importance", "Model Pruning", "SHAP value"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/77538c68af99ef2ca2006fb93820f2085a048936.pdf", "supplementary_material": "/attachment/11e0b5b6f476df6bed039cbd6b9946050726468e.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a Cooperation Index for pruning that measures how often a parameterâ€™s marginal contribution exceeds its own Shapley average along sampled permutations. This captures the decay speed of contributions rather than relying only on the mean. A two level approximation is presented. First, vertex sampling fits a regression surrogate on the subset hypercube. Next, permutation sampling estimates marginal contributions. Pseudocode and empirical validation are provided on VGG 16 and ResNet 18 across MNIST, CIFAR 10, CIFAR 100, and Tiny ImageNet."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "[1] The motivation is clearly articulated: averaging marginal contributions can overweight redundant parameters; counting cooperative paths aligns better with pruning decisions where replaceability matters\n\n[2] The proposed index is intuitive and interpretable: parameters that consistently help across many contexts are preserved, while sporadically helpful ones are down-weighted."}, "weaknesses": {"value": "[1] Evaluation focuses on very low pruning ratios, approximately 1 to 3 percent. The absence of full accuracy versus sparsity curves limits claims about robustness at moderate or high sparsity.\n\n[2] Scalability evidence is limited to mid scale convolutional networks. Results on transformer architectures or larger models are missing.\n\n[3] Theoretical analysis could be deepened. Mathematical properties of the index such as monotonicity, relations to Shapley axioms, and performance guarantees under milder assumptions are not fully explored.\n\n[4] Ablations and statistics are sparse. Sensitivity to permutation and vertex sample counts, surrogate architecture, and sampling distributions is not systematically quantified. Standard deviations and confidence intervals are not consistently reported.\n\n[5] Presentation can be improved. Some figures are dense and lack error bars. The text repeats parts of related work and could be tightened."}, "questions": {"value": "[1] How does the method behave at higher pruning ratios such as 10 to 60 percent. Are there inflection points where performance degrades more steeply than methods based on Shapley value or magnitude-based baselines?\n\n[2] How sensitive is the ranking to surrogate model misspecification or to underfitting and overfitting on the subset hypercube. Can uncertainty in the surrogate be propagated into confidence intervals for the Cooperation Index?\n\n[3] How would the definition adapt to structured pruning across channels, heads, or layers where units are grouped rather than independent?\n\n[4] In low redundancy regimes, as hinted by the Tiny ImageNet results, could an adaptive blend between the Cooperation Index and the Shapley Value reduce worst-case degradation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "98z9oQiWzE", "forum": "8xtzk0cHXO", "replyto": "8xtzk0cHXO", "signatures": ["ICLR.cc/2026/Conference/Submission18266/Reviewer_Sne6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18266/Reviewer_Sne6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18266/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761589191857, "cdate": 1761589191857, "tmdate": 1762927990460, "mdate": 1762927990460, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address the issue of overweighting redundant parameters in Shapley values, the authors proposed a simple metric Cooperation Index (CI) that utilizes the speed of decay of marginal contributions, by incorporating permutations beyond standard Shapley values calculations. They conducted several pruning experiments on image datasets and demonstrated superior performance in terms of accuracy over previous methods like Shapley values and LOCO."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors proposed a simple extension of Shapley value, Cooperation Index (CI) that achieves better pruning performance on several empirical datasets than previous methods.\n2. The paper is easy to follow with useful visual explanations, such as Figure 1 to help readers understand the intuition."}, "weaknesses": {"value": "1. Unlike Shapley values that satisfy the four important theoretical properties, CI lacks formal theoretical justifications. It seems CI is more designed for pruning-oriented rather than a fairness-oriented approach.\n2. The criteria to choose pruning ratios in Table 2 are not clearly stated. The pruning ratios varies from 3% to 1% without further discussion on rationales.\n3. A more detailed analysis of sampling number for stability of CI from line 426 to 431 would be appreciated. It's likely a number related to sample size and dimension. It would be helpful to see the trend of convergence for CI wrt sample size and dimension to guide users to choose parameters in practice, rather than demonstrating results using only ResNet-18. \n4. The experiments focus exclusively on no-tabular data sets. How does CI work on tabular data sets, or low-dimension datasets? \n\nSome typos:  \n\nLine 84. Missing space after \"uncompromised\".   \nLine 95. Missing space after \"effectively\"."}, "questions": {"value": "1. Shapley values satisfy some important theoretical properties (efficiency, symmetry, dummy, and additivity), which of these, if any, do CI satisfy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QPn8HssmU3", "forum": "8xtzk0cHXO", "replyto": "8xtzk0cHXO", "signatures": ["ICLR.cc/2026/Conference/Submission18266/Reviewer_Ejgo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18266/Reviewer_Ejgo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18266/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761885202429, "cdate": 1761885202429, "tmdate": 1762927990101, "mdate": 1762927990101, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper argues that SHAP is not a good metric for model pruning as it is overweights redundant parameters. The authors propose a novel metric called Cooperation Index, which instead quantifies how consistently a parameter's marginal contribution exceeds its own average to better identify essential parameters."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper's critic about Shapley values being a bad metric for model pruning is insightful. The authors compellingly explain the motivation for their work. \n* The proposed Cooperation Index metric is an elegant and intuitive metric which aims to address this identified limitation."}, "weaknesses": {"value": "The paper's theoretical motivation is unfortunately not matched by a sound and sufficient experimental evaluation:\n\n* **Experiments**: \n1. Pruning is useful for making large and computationally expensive models more efficient. However, the authors exclusively test their method on small models like VGG and ResNet-18 that are already fast and do not have any need for pruning. It is unclear why one would develop a pruning method that scales poorly with the number of parameters and cannot be easily applied to large models that need the pruning the most.\n2. Evaluation is limited to very old and small-scale ConvNets (VGG-16 and ResNet-18) and entirely ignores transformers, which currently represent the dominant paradigm.\n3.  Authors do not include a ViT-tiny model. My suggestion that if this model is too expensive to run for this algorithm, then they need to scale it down even further, but the experiments for the transformer must be presented.\n4. The paper fails to compare against modern pruning methods. For instance Wanda [1], which is a simple, fast, and highly effective method for large models. Its absence makes it difficult to judge the practicality of the proposed method against the current state of the art. \n5. Missing baselines from NLP. For instance, authors could have included tiny version of BERT and GPT.\n* **Runtime**: despite proposing a two-step approximation scheme, the paper provides no empirical runtime to quantify its computational cost. This is especially concerning as the method inherits the factorial complexity of Shapley values, which is fundamentally at odds with the scaling laws (the more parameters the better). I believe the authors need to provide an actual runtime of the algorithm and compare it with a runtime of the competing baselines.\n\n\n[1] A Simple and Effective Pruning Approach for Large Language Models, Sun et al., 2023"}, "questions": {"value": "The dominant trend in deep learning shows that model performance scales predictably with size, favoring methods with low polynomial complexity in terms of the number of parameters. Given this, how do the authors envision their computationally intensive approach fitting into the current landscape? Is there a specific application where such computational costs are justified?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IRffNTVkVT", "forum": "8xtzk0cHXO", "replyto": "8xtzk0cHXO", "signatures": ["ICLR.cc/2026/Conference/Submission18266/Reviewer_ZoJ1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18266/Reviewer_ZoJ1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18266/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931803554, "cdate": 1761931803554, "tmdate": 1762927989432, "mdate": 1762927989432, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors argue that the popular SHAP Value (SV) method, by averaging marginal contributions, systematically overweights redundant parameters. The paper introduces a new metric called the Cooperation Index (CI). CI quantifies the consistency of a parameter's contribution by measuring the frequency of \"cooperative paths\" - permutations where the parameter's marginal contribution exceeds its average SV. Experiments on VGG-16 and ResNet-18 show that CI-based pruning more effectively preserves the model's core functional elements."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a conceptual critique of the SHAP Value (SV) as a pruning criterion. It formally identifies that SV's averaging mechanism fails to distinguish between redundant parameters (replaceable, high variance in marginal contributions) and cooperative parameters (consistent contributions).\n- The proposed Cooperation Index (CI) is a novel metric that directly addresses this identified limitation. \n- The work addresses the exponential computational complexity of the metric with a practical two-level approximation scheme. \n- The experimental results demonstrate the effectiveness of the CI criterion. Across multiple datasets and architectures, CI-based pruning achieves superior or competitive accuracy compared to SV and other baseline methods.\n- The paper is well-written and clear."}, "weaknesses": {"value": "- Specific Evaluation Conditions: The empirical validation is conducted under non-standard conditions, as models are intentionally overfitted on heavily reduced datasets (e.g., 1/100 MNIST) . The method's effectiveness is not guaranteed in standard training regimes. Has its effectiveness also been evaluated when overfitting is caused by other factors, such as prolonged training duration?\n- Focus on Low Pruning Ratios: The main experiments (Table 2) almost exclusively focus on very low, \"delicate\" pruning ratios (e.g., 1-3%). This narrow scope fails to demonstrate the method's scalability and performance at higher, more practical levels of sparsity.\n- Flawed Statistical Reporting: The paper lacks statistical rigor by explicitly reporting the \"best performing result in terms of accuracy\" from five runs, rather than the mean and standard deviation. This practice of \"cherry-picking\" results may significantly overstate the method's true performance.\n- Dependence on Approximation Accuracy: The CI calculation is critically dependent on the accuracy of the regression function used in the two-level approximation scheme. The study does not sufficiently analyze the method's sensitivity to potential errors introduced by this approximation eg. the convergence of CI is shown only for the first few filters.\n- Ambiguity in Tie-Breaking: The illustrative toy example shows identical CI scores (0.25) for four of the five parameters in the initial stage. The paper fails to explain the tie-breaking mechanism used to select $w_4$ for pruning, making the selection criteria ambiguous.\n- Rigid Contribution Threshold: The Cooperation Index relies on a strict binary threshold (above or below the mean SV) to classify contributions. This rigid classification may inaccurately assess parameters whose marginal contributions are consistently very close to the average.\n- Limited Dataset Variety: The evaluation is restricted to a few datasets . The conclusions would be strengthened by validation on a more diverse set of datasets, such as Fashion-MNIST, SVHN, KMNIST, STL-10, Caltech-101.\n- Incomplete Baseline Comparison: The MCI baseline method was prematurely dismissed from the main experiments based only on poor performance in the synthetic example. For a complete and fair comparison, its results on the main experiments should be included regardless, for example, in the appendix.\n\nFigure 8 is unreadable - the font size is too small."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nuluzwimOz", "forum": "8xtzk0cHXO", "replyto": "8xtzk0cHXO", "signatures": ["ICLR.cc/2026/Conference/Submission18266/Reviewer_o8ur"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18266/Reviewer_o8ur"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18266/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991526589, "cdate": 1761991526589, "tmdate": 1762927988840, "mdate": 1762927988840, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}