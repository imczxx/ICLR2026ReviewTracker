{"id": "xus9xNjuCI", "number": 945, "cdate": 1756824733780, "mdate": 1759898234132, "content": {"title": "TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation", "abstract": "Travel planning is a valuable yet complex task that poses significant challenges even for advanced large language models (LLMs). While recent benchmarks have advanced in evaluating LLMs' planning capabilities, they often fall short in evaluating feasibility, reliability, and engagement of travel plans. We introduce a comprehensive benchmark for travel planning that unifies fine-grained criteria into a single reward, enabling direct comparison of plan quality and seamless integration with reinforcement learning (RL). Our evaluator achieves moderate agreement with travel-expert annotations (60.75%) and outperforms multiple LLM-as-judge baselines. We further release a large-scale dataset of 4,870 queries including 219 real-world, free-form requests for generalization to authentic user intent. Using this benchmark, we conduct extensive experiments across diverse methods and LLMs, including test-time computation, neuro-symbolic approaches, supervised fine-tuning, and RL via GRPO. Across base models, RL generally improves itinerary feasibility over prompt-only and supervised baselines, yielding higher unified reward scores.", "tldr": "", "keywords": ["travel plan", "reasoning", "reinforcement learning"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fbec55f34a9f156d507871583d83252fc509dcd8.pdf", "supplementary_material": "/attachment/bfa9c848dd3b6d66ac4cd6be861a0f436c9562c3.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a new benchmark, TripScore, designed to evaluate the travel planning capabilities of large language models (LLMs). The authors also compare different methods, including standard LLMs, supervised fine-tuned LLMs, GRPO-based models, and neuro-symbolic approaches. While the topic is relevant and the implementation appears complete, the novelty and overall contribution of the paper are quite limited.\n\nMajor Comments:\n1. Limited novelty of the benchmark.\nAs acknowledged by the authors, there already exist several travel-planning-related benchmarks and datasets. The incremental contribution of TripScore over these existing resources is unclear. The paper should clearly justify why constructing yet another benchmark is necessary and what unique aspects it provides beyond existing ones. Table 1 is not enough to demonstrate the necessary of this benchmark.\n2. Lack of clarity in requirement collection.\nThe authors mention that task requirements were collected from human users. However, there is insufficient information about the background, diversity, and quality control of the participants. Without this information, it is difficult to assess the reliability and representativeness of the benchmark queries.\n3. Unclear benchmark difficulty and comparative validation.\nThe difficulty level of the benchmark tasks is not analyzed or compared with existing datasets. It would strengthen the paper if the authors could show how the same methods perform on other travel-planning datasets to contextualize TripScore’s difficulty.\n4. High similarity to existing work.\nThe paper closely resembles prior studies in both concept and presentation. For instance, the constraints discussed are similar to those in ChinaTravel. Additionally, Figure 1 in this paper appears visually and structurally similar to Figure 1 in TravelPlanners, raising concerns about originality in presentation.\n5. Lack of experimental insights.\nWhile several models are compared, the experimental section does not yield clear insights or actionable conclusions. The paper would benefit from deeper analysis—for example, discussing why certain methods perform better, and what the benchmark reveals about LLM reasoning or planning limitations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "This paper proposes a new benchmark, TripScore, designed to evaluate the travel planning capabilities of large language models (LLMs). The authors also compare different methods, including standard LLMs, supervised fine-tuned LLMs, GRPO-based models, and neuro-symbolic approaches."}, "weaknesses": {"value": "1. Limited novelty of the benchmark.\nAs acknowledged by the authors, there already exist several travel-planning-related benchmarks and datasets. The incremental contribution of TripScore over these existing resources is unclear. The paper should clearly justify why constructing yet another benchmark is necessary and what unique aspects it provides beyond existing ones. Table 1 is not enough to demonstrate the necessary of this benchmark.\n2. Lack of clarity in requirement collection.\nThe authors mention that task requirements were collected from human users. However, there is insufficient information about the background, diversity, and quality control of the participants. Without this information, it is difficult to assess the reliability and representativeness of the benchmark queries.\n3. Unclear benchmark difficulty and comparative validation.\nThe difficulty level of the benchmark tasks is not analyzed or compared with existing datasets. It would strengthen the paper if the authors could show how the same methods perform on other travel-planning datasets to contextualize TripScore’s difficulty.\n4. High similarity to existing work.\nThe paper closely resembles prior studies in both concept and presentation. For instance, the constraints discussed are similar to those in ChinaTravel. Additionally, Figure 1 in this paper appears visually and structurally similar to Figure 1 in TravelPlanners, raising concerns about originality in presentation.\n5. Lack of experimental insights.\nWhile several models are compared, the experimental section does not yield clear insights or actionable conclusions. The paper would benefit from deeper analysis—for example, discussing why certain methods perform better, and what the benchmark reveals about LLM reasoning or planning limitations."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "c3bD6Zuf5z", "forum": "xus9xNjuCI", "replyto": "xus9xNjuCI", "signatures": ["ICLR.cc/2026/Conference/Submission945/Reviewer_vV7y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission945/Reviewer_vV7y"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission945/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761725074799, "cdate": 1761725074799, "tmdate": 1762915646774, "mdate": 1762915646774, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a comprehensive benchmark designed to evaluate and improve the complex travel-planning capabilities of LLMs.\nIt adopts real-world user queries and constructs a comprehensive evaluation framework.\nThe extensive experiments show that the designed reward is beneficial in RL training."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. This paper adopts real-world user queries, bridging the gap between previous benchmarks and applications.\n2. It proposes a unified and actionable reward score, which can be further used as  a reward model for such tasks and provides deeper insights beyond pass/fail.\n3. This paper conducts extensive experiments on different methods and base models."}, "weaknesses": {"value": "1. Although the authors claim the dataset to be a real-world dataset, it only contains 219 real-world queries out of 4870 total queries, which is not convincing enough for me to view this dataset as a real-world dataset.\n2. The evaluation contains LLM-as-judge and the results in Table 6 show that only 61.32% is correctly evaluated, which poses doubt on the precision of such method.\n3. This paper is an incremental extension of TravelPlanner by extending constraints and constructing a trivial evaluation method."}, "questions": {"value": "1. How is TripScore's unified reward a fundamental advance over these existing, complex reward and evaluation models?\n2. The TripScore evaluator relies on an LLM to score soft and preference constraints. The authors admit this model only achieves \"moderate agreement (60.75%)\" with human travel experts. This implies that for nearly 40% of comparisons, the benchmark's ground truth may be wrong. Why should this 60.75%-accurate reward signal be trusted to train a superior model, and how does this level of noise affect the stability and reliability of the GRPO training?\n3. What is the fundamental difference between TripScore and existing benchmarks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ebyFBJtCSL", "forum": "xus9xNjuCI", "replyto": "xus9xNjuCI", "signatures": ["ICLR.cc/2026/Conference/Submission945/Reviewer_339T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission945/Reviewer_339T"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission945/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761800416969, "cdate": 1761800416969, "tmdate": 1762915646651, "mdate": 1762915646651, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work addresses a critical gap in travel planning benchmarks by unifying fine-grained evaluation criteria into a single reward and incorporating real-world user queries. The 4,870-query dataset (including 219 real-world requests) and four-category constraint framework (format, commonsense, soft, preference) are valuable contributions, filling the void of authentic scenario coverage in existing benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Addresses a key limitation of existing travel planning benchmarks (e.g., TravelPlanner, ChinaTravel) by unifying four types of fine-grained constraints into a single interpretable reward score, providing a more coherent and scalable evaluation mechanism.\n\n2. Constructs a high-quality real-world dataset, mitigating the overreliance on LLM-generated data in prior benchmarks and enhancing generalization and practical applicability.\n\n3. Extensive experiments with diverse algorithms demonstrate the effectiveness of reinforcement learning for travel plan generation."}, "weaknesses": {"value": "1. The framework relies on LLM-based soft or preference evaluation, which introduces potential inaccuracy and computational overhead due to the absence of a purely rule-based alternative.\n\n2. Given the proliferation of travel planning benchmarks, including ChinaTravel, the novelty appears somewhat limited in terms of benchmark design."}, "questions": {"value": "Q1: Why do strict hard constraints often lead to no feasible solutions in NeSy-based approaches to travel plan generation?\n\nQ2: What are the benefits of using a unified evaluation metric in this context?\n\nQ3: Compared with ChinaTravel, which focuses on NeSy reasoning, what type of approach do you personally find more promising for advancing travel planning tasks, and what are your key insights?\n\nQ4: Why was the ReAct baseline not included in the experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5vkP3tNoBm", "forum": "xus9xNjuCI", "replyto": "xus9xNjuCI", "signatures": ["ICLR.cc/2026/Conference/Submission945/Reviewer_h4xw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission945/Reviewer_h4xw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission945/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966155706, "cdate": 1761966155706, "tmdate": 1762915646353, "mdate": 1762915646353, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers the travel planning, proposes TripScore, and a unified reward for evaluating multi-constraint travel itineraries. This reward function integrates the rule-based evaluation and LLM-as-judge. Experiments compare direct prompting, test-time reasoning, neuro-symbolic approaches, and fine-tuning including GRPO, reporting gains in delivery rate, commonsense pass rate, and the unified reward, with analyses of error types and trip-duration sensitivity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem is practically relevant and the authors implement a comprehensive evaluation workflow that attempts to separate hard feasibility from softer quality criteria. \n2. The paper provides careful engineering details, ablations over trip duration, error breakdowns, and an expert-annotation study to partially validate the reward."}, "weaknesses": {"value": "1. The reliability of the unified reward is limited for its intended purpose. Agreement with human experts is only 60.75%. Because the reward is heavily shaped by the gating and by narrow penalty ranges, the final score collapses much of the variation into a few bands that correlate strongly with format and commonsense feasibility, undermining its claim to measure fine-grained quality beyond validity. From my perspective, a unified reward design is a methodological requirement rather than a benchmark requirement. However, the RL algorithm based on this reward proposed by the authors does not seem to have achieved a significant improvement compared to training-free algorithms.  \n2. In summary, from a product development perspective, if the proposed reward design ultimately yields an effective RL solution, then I would consider this work to be more beneficial than TravelPlanner. However, from Benchamrk's current perspective, the incremental benefits of this work compared to TravelPlanner are limited.  \n3. The use of charts is too similar to that of TravelPlanner, especially Figure 1, which is almost identical. Table 2 and Figure 4 are also very similar in design. This level of similarity necessitates special attribution to the figure as originating from TravelPlanner."}, "questions": {"value": "1. Compared to TravelPlanner, what are the core contributions of this article? \n2. What impact does the author believe the presented unified reward will have on the travel planning community?\n1. How do you address the training–evaluation mismatch that risks Goodhart’s law, given RL/RFT use only the rules-based reward while the test metric includes LLM-scored components?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UfGRg6Tads", "forum": "xus9xNjuCI", "replyto": "xus9xNjuCI", "signatures": ["ICLR.cc/2026/Conference/Submission945/Reviewer_bfBK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission945/Reviewer_bfBK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission945/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989455456, "cdate": 1761989455456, "tmdate": 1762915646219, "mdate": 1762915646219, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}