{"id": "vLy6kvtfV6", "number": 24827, "cdate": 1758360781573, "mdate": 1759896746491, "content": {"title": "SAFE: Benchmarking AI Weather Prediction Fairness with Stratified Assessments of Forecasts over Earth", "abstract": "The dominant paradigm in machine learning is to assess model performance based on average loss across all samples in some test set. However, this approach fails to account for the non-uniform patterns of human development and geography that exist across Earth. We introduce Stratified Assessments of Forecasts over Earth (SAFE), a package for elucidating the stratified performance of a set of predictions made over Earth. SAFE integrates various domains of data to perform stratification on different attributes associated with gridpoints: territory (usually country), global subregion, income, and landcover (land or water). This allows us to examine the performance of models for each individual stratum of the different attributes (e.g., the accuracy in every individual country). To demonstrate its importance, we utilize SAFE to benchmark a zoo of state-of-the-art AI-based weather prediction models, finding that they all exhibit disparities in forecasting skill across every attribute. We use this to seed a benchmark of model forecast fairness through stratification at different lead times for various climatic variables. By moving beyond globally-averaged metrics, we for the first time ask: where do models perform best or worst, and which models are most fair? To support further work in this direction, the SAFE package is made available at https://anonymous.4open.science/r/safe-E7C7.", "tldr": "AI weather prediction models exhibit biases in forecast performance based on geographic region, income, landcover, and lead time.", "keywords": ["faireness", "weather", "climate", "artificial intelligence", "machine learning"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d7776304e52cf44cbb892c5271e83fb4d50a92bd.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this paper, the authors study the problem of weather prediction. To be specific, they argue that existing evaluation methods / benchmarks ignore many biases present in prediction models and to address this issue, they introduce SAFE, a fairness evaluation framework for AI-based weather prediction models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ The authors highlight a novel problem in AI-based weather prediction.\n+ They introduce a novel benchmark with its accomponying methods for data collection and evaluation."}, "weaknesses": {"value": "Weaknesses:\n\n1. The paper should introduce a list of concrete desiderata expected from such a benchmark and provide a comparison table with respect to the existing benchmarks. This comparison should also consider benchmark size in terms of samples & locations.\n\n2. Introduction should introduce the research gaps and describe how the paper addresses those gaps.\n\n3. I am not sure ICLR is a good venue for such a paper as I don't think that the weather prediction community is following ICLR.\n\nMinor comments:\n- Lines 46-47: \"Root mean square error (RMSE) is the preeminent metric used in assessing the quality of AIWP models (Radford et al., 2025; Rasp et al., 2020). The general form of RMSE is shown in Equation 1,\" => This paragraph is incomplete and a bit out of place here.\n\n- Please use the following guide for writing equations:\nhttps://wp.optics.arizona.edu/kupinski/wp-content/uploads/sites/91/2023/05/MerminEquations.pdf\n\n- Eq 1: Please introduce the symbols.\n\n- \"high resolution events\" => What is a high resolution event? Did you mean high frequency? \n\n- \"see: section 2\" => \"see Section 2\".\n\n- \"package 1\" => Footnotes should be placed without spaces.\n\n- \"In calculating the loss function for training it is common to weight the (squared if L2) difference in variable prediction and ground truth by the area of the gridpoint cell the forecast was made at before averaging.\" => Please cite.\n\n- \"Q3 + 1.5 ∗ IQR)\" => \"*\" denotes convolution, not multiplication. Use \\times for multiplication."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iFnu5bndvV", "forum": "vLy6kvtfV6", "replyto": "vLy6kvtfV6", "signatures": ["ICLR.cc/2026/Conference/Submission24827/Reviewer_6rWx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24827/Reviewer_6rWx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24827/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761479121386, "cdate": 1761479121386, "tmdate": 1762943210224, "mdate": 1762943210224, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to provide a benchmarking framework for evaluating fairness in AI weather prediction models by detailed, stratified error analysis across geographic, economic, and environmental groups rather than just global averages.​  It measures model performance (mainly RMSE) for each \"stratum,\" e.g., country, region, income group, or land vs. water, using accurate, area-weighted calculations. It introduces per-stratum disparity and variance metrics to quantify fairness. SAFE is applied to several AI weather prediction models, demonstrating disparities in accuracy across all attributes and lead times.\n\nWhile the paper addresses an important issue, I feel that the evaluation is quite limited and that the work should be extended to be a more comprehensive benchmark, encompassing further strata, and probabilistic models.  Moreover, I would argue that such works primarily concerning Atmospheric and Climate science might be better suited to domain journals, and their target audience."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Highlights hidden biases by moving beyond crude spatial averages.​\n\n- Provides fine-grained, interpretable error benchmarks for specific regions, income groups, and land types.​\n\n- Metrics are grounded in fairness literature and extensible.​\n\n- More accurate latitude weighting that accounts for Earth's oblate shape.​\n\n - Open-source and reproducible.​\n\n- Shows systemic bias exists across models and geographies, which is critical for real-world deployment.​"}, "weaknesses": {"value": "- It is well-understood in the literature that RMSE is missing the mark when it comes to these models as it encourages unphysical predictions that blur out solutions. As such, the literature has moved to assess performance by measuring CRPS, spectral fidelity and llocalized scores. The paper does not address or acknowledge any of this and crucially, does not provide any hints on how this could be appl;ied to the more modern, probabilistic models.\n\n- Some claims are made without being backed up. For instance, it is well-known that the Earth is oblate but I doubt that this has a serious effect on either scoring or even on the absolute RMSE values. For instance, apart from FourCastNet3, most ML weather models do not even consider quadrature weights to compute spatial averages on the sphere, without apparent downsides.It would be good to back this up with numerical proof that such changes do have a measurable effect. \n\n- Similar to the previous point, it would be appropriate to demonstrate the usefulness of SAFE by showing how it affects the ranking of models as compared to globally averaged RMSE.\n\n- Often the choice of metric will even lead to different rankings, so one strata to consider would also be performance on extreme events such as tropical cyclones or floods. In this setting the probabilistic nature would be especially important and I expect models that perform well RMSE-wise to perform poorly in this setting.\n\n- Current attributes are limited and fairness metrics are basic: work is needed to incorporate more nuanced strata (like coastlines, islands, or population density).​"}, "questions": {"value": "- How much of a difference does it make to consider the oblate geometry, really?\n- Why not include probabilistic models and more importantly, consider extreme events? There are several datasets providing and extreme events record."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MdqWW046Bf", "forum": "vLy6kvtfV6", "replyto": "vLy6kvtfV6", "signatures": ["ICLR.cc/2026/Conference/Submission24827/Reviewer_mBAM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24827/Reviewer_mBAM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24827/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917976623, "cdate": 1761917976623, "tmdate": 1762943209991, "mdate": 1762943209991, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an open-source framework for evaluating the fairness of ML weather prediction models. Instead of relying on globally averaged metrics like RMSE, SAFE assesses model performance across geographic and socioeconomic strata—such as country, income level, and landcover—to reveal spatial disparities. The paper thus establishes the first benchmark for geographically stratified fairness in weather forecasting."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is among the first to demonstrate a solution for assessing fairness in ML weather prediction, a dimension that is often ignored in existing work that typically focuses only on global accuracy.\nThe authors nicely expose systemic geographic and economic biases in widely used ML weather models."}, "weaknesses": {"value": "- While SAFE introduces valuable stratifications, it currently includes only four attributes (territory, subregion, income, landcover), omitting potentially important ones like population density, climate zone, or infrastructure exposure.\n- The experiments use only two atmospheric variables (T850 and Z500), which may limit generalizability to other variables, resolutions, or forecasting tasks.\n- The proposed fairness measures (RMSE variance and maximum difference) are basic statistical descriptors and may not capture more nuanced or causal forms of bias."}, "questions": {"value": "What factors, e.g., data distribution, model architecture, or physical representation, cause the observed geographic and socioeconomic disparities in forecast accuracy, and how might SAFE be used to mitigate them during model training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5QoCjajq9X", "forum": "vLy6kvtfV6", "replyto": "vLy6kvtfV6", "signatures": ["ICLR.cc/2026/Conference/Submission24827/Reviewer_6egV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24827/Reviewer_6egV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24827/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982590746, "cdate": 1761982590746, "tmdate": 1762943209782, "mdate": 1762943209782, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SAFE, a Python-based open-source toolkit for evaluating fairness in AI-based weather prediction (AIWP) models through stratified performance assessment. Unlike standard evaluation protocols that report globally-averaged RMSE or ACC, SAFE enables model performance analysis across territory, global subregion, income level, and landcover (land/water). The authors evaluate six leading AIWP models (GraphCast, FuXi, Keisler, Pangu-Weather, Spherical CNN, and NeuralGCM) across multiple lead times (12h to 240h), over two key variables (T850 and Z500), using ERA5 data from 2020, and report disparities in per-strata RMSE. The paper further defines two new fairness metrics—maximum RMSE disparity and variance across strata—to benchmark inter-model fairness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Evaluation across 6 major models, 4 fairness attributes, 20 time steps, and 2 variables.\n* The SAFE package is open-source and built on public datasets, facilitating reproducibility.\n* The use of pygeoboundaries_geolab together with an oblate-spheroid area correction improves the accuracy of area weighting and geographic stratification."}, "weaknesses": {"value": "* While novel in this context, both max RMSE difference and RMSE variance are basic summary statistics. The paper acknowledges that fairness metrics from ML are typically binary or categorical, but does not attempt any adaptation of more sophisticated metrics.\n\n* The authors do not consult with any domain experts (e.g., meteorologists or users in Global South) to validate whether the stratified results align with known experience.\n\n* The study focuses only on T850 and Z500. However, precipitation and extreme events, which are crucial for human safety and fairness (e.g., flood warnings), are omitted.\n\n* Although the authors motivate the work with real-world consequences (e.g., extreme heat mortality), they do not quantify the societal impact of the observed disparities."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "es9w7P3DAT", "forum": "vLy6kvtfV6", "replyto": "vLy6kvtfV6", "signatures": ["ICLR.cc/2026/Conference/Submission24827/Reviewer_6Syp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24827/Reviewer_6Syp"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24827/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761985259211, "cdate": 1761985259211, "tmdate": 1762943209583, "mdate": 1762943209583, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}