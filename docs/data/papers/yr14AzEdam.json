{"id": "yr14AzEdam", "number": 12807, "cdate": 1758210463667, "mdate": 1759897483532, "content": {"title": "Multi-agent Imitates Enterprise Dynamics", "abstract": "Imitating enterprise dynamics characterized by volatility, long-horizon coordination, and decision-making offers executives and operational teams a structural understanding of the organization at a much lower cost. Existing LLM-based agent systems have great potential to simulate these activities, yet they still face three challenges to understand the dynamics at the enterprise scale in terms of structure, strategy, and operation. This motivates us to propose TaskWeave, a novel LLM-based multi-agent framework that aims to imitate complex enterprise dynamics. Inspired by theories in the fields of control and business management, our TaskWeave operates at three levels: strategic (executives, e.g. generating phase plans), tactical (coordination, e.g. scheduling resource allocation), and operational (task execution, e.g. leveraging multiple tools), simulating modern enterprise dynamics in an end-to-end manner. Our TaskWeave instantiates an IT company to simulate year-long operations, demonstrating diverse enterprise dynamics. Experiments, including human evaluations, show that it improves performance with less real-world overhead, while also generating internal data as a downstream task and enabling interactions with external contexts.", "tldr": "", "keywords": ["multi-agent systems;enterprise dynamics;behaviour simulation;large language models;"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e64d0bfeaada960f03dbce12838a5a18c630ad0d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces TaskWeave, a multi-agent framework designed to simulate enterprise dynamics by orchestrating LLM-based agents across three interconnected layers: strategic planning, tactical delegation, and operational execution. Specifically, at the strategic level, the system uses the FPDA cycle to perceive internal and external conditions and refine global intent. At the tactical level, agents switch between orchestrating and executing roles to break down goals, delegate tasks, and align efforts. At the operational level, agents use structured memory and tools to access historical data, resolve task dependencies, and support context-based reasoning and traceable outputs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper addresses an important issue by focusing on a specific and complex application scenario: enterprise dynamics. Unlike previous multi-agent systems that were more generalized and not tailored to a particular context, this work zeroes in on the intricacies of enterprise operations.\n\n2. This paper effectively simulates the complexity of enterprise dynamics through a three-level orchestration, including strategic planning, tactical delegation, and operational activities. Such design is attractive."}, "weaknesses": {"value": "1. This paper's main issue is its confusing and disorganized writing, which makes many parts difficult to understand. The use of complex and unclear terminology to explain variables like \"structured task bundle\" significantly hinders readability. This confusion begins with Equation (4), where the meaning of the subscript $i$ and the definitions of functions $\\mathcal{C}$ and $\\mathcal{V}$ are not clearly explained. Examples would be helpful to clarify these concepts.\n\n2. Additionally, the paper lacks explanations for certain variables. For instance, $\\mathcal{N}_{sibling}^+$ on line 221 and $\\mathbb{H}$ on line 257 are not adequately defined. The order of presentation is also problematic; for example, the symbols $\\delta$ and $\\xi$ introduced on line 245 are only explained much later, creating significant reading difficulties.\n\n3. The paper also contains several confusing typos. For example, there are two Equation (6)s, which is a clear mistake."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zTTGslMESE", "forum": "yr14AzEdam", "replyto": "yr14AzEdam", "signatures": ["ICLR.cc/2026/Conference/Submission12807/Reviewer_CfVf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12807/Reviewer_CfVf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761450061052, "cdate": 1761450061052, "tmdate": 1762923616743, "mdate": 1762923616743, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes TaskWeave, a multi-agent LLM-driven framework that imitates complex enterprise dynamics and operates at three levels: strategic planning, tactical delegation, and operational activities. TaskWeave is evaluated through a year-long simulation of an example SaaS company, where the main judgment is conducted via LLM-as-a-Judge and human experts. The proposed framework outperforms the single-agent baseline over six LLM backbones. In addition, TaskWeave is further extended to Fin, Manu, and Gov domains for studying the generalization of the proposed framework. TaskWeave serves as a foundation for synthesizing enterprise data."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. TaskWeave presents as a novel multi-agent framework for imitating enterprise dynamics, which can be valuable for generating enterprise-related data, helping real-world enterprise decision making, and breeding startup companies.\n\n2. The three-level orchestration that includes strategic, tactical, and operational strategies for multi-agent coordination is insightful and a suitable structure for modelling the enterprise behavior. \n\n3. The experiments are conducted over a range of state-of-the-art LLM backbones, where TaskWeave outperforms a single-agent baseline substantially in both LLM score and Human evaluations. TaskWeave also yields richer spans with lower API costs in the OSSD task."}, "weaknesses": {"value": "1. Though TaskWeave imitates the enterprise dynamics, the underlying multi-agent framework involves heavy human engineering and prompt designs for characterizing the role of each agent. The high dependence of human prompt engineering and the lack of automation for imitating enterprise dynamics can strongly limit the generalization of the framework for customization. \n\n2. In Table 1, the evaluation is conducted over a single-agent baseline. However, there are many prior LLM-based MAS frameworks (as listed in Table 6, e.g. AutoGen, MetaGPT) that can be customized into enterprise imitation, which was ignored in the main experiments. In addition, the human evaluation is conducted over a very small group of people with only 4 domain experts, which may expose bias in the evaluation. Some metrics are ill-defined: for instance, the 4:4:2 distribution between Tech, Mkt, Strat is overfitted to a special style of enterprise structure, which makes the KL divergence study misleading.\n\n3.  To the best of my understanding, this framework will be useful when it is evaluated against a real-world enterprise example with the history of the growth and the internal decision-making. However, the main study conducted in this work only involves a year-long simulation of a single company without grounding with real-world dynamics. \n\n4. Though the author states ablation analysis in Appendix E, the influence of each module in the 3-level orchestration is not quantitatively ablated.\n\nIn line 352, there is a missing Appendix reference that can be fixed."}, "questions": {"value": "1. To what extent is the proposed framework automated? Does the agent profile require human engineering or automatically generated by only conditioning on the background information?\n\n2. In Eq 6, how is the task assigned to each agent precisely? How is the alignment computed?"}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "This work involves the generation of enterprise data that may expose sensitive human information."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QN6KLU4zzn", "forum": "yr14AzEdam", "replyto": "yr14AzEdam", "signatures": ["ICLR.cc/2026/Conference/Submission12807/Reviewer_6cxA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12807/Reviewer_6cxA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761675041488, "cdate": 1761675041488, "tmdate": 1762923616392, "mdate": 1762923616392, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes TaskWeave, a llm based multi-agent framework for imitating complex enterprise dynamics. The system operates at three levels - strategic, tactical and operational. The authors evaluate TaskWeave through a year-long SaaS company simulation, comparing it against single-agent baselines across multiple dimensions including task generation quality, role assignment, plan propagation, and task execution. Additional experiments demonstrate generalizability across financial, manufacturing, and government domains."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors tackle an interesting and difficult problem which is simulating enterprise dynamics.\n2. The authors evaluate the method across multiple domains to showcase its generalisability\n3. Simulation along four level temporal hierarchy to enable long horizon planning is something absent in existing multi-agent evaluation setups."}, "weaknesses": {"value": "1. Novelty - The paper lacks significant novelty and mostly becomes an engineering work. The paper says it introduces FDPA, however most of its components correspond to popular and well researched techniques in agentic systems( Formulate -> Task Decomposition, Partition -> Planning/Task Generation, Diagnose -> Aggregation and Summarisation)\n2. Method section is unclear and difficult to follow. The method section includes several symbols and terms which are not well defined. Many components are defined at a high level without implementable details. For example\n      - How does the decompose operator D (eq 5) work?, \n      - What constitutes a dependency query?, \n      - how does $\\phi$ score alignment (eq 6)?\n3. Evaluation - While some of the evaluation metrics proposed are interesting, it lacks important enterprise metrics such as cost, ROI, success metrics, execution efficiency etc. Some of the evaluation details are also unclear such as how task execution is evaluated. The authors also skip evaluation against existing multi-agent framework such as MetaGPT.\n4. Missing Details - The paper does not talk about cost and resource requirements for the framework. It also skips significant implementation details such as the prompts for each of the 14 role-specialized agents as well as prompts for llm-as-a-judge evaluation."}, "questions": {"value": "1. How are individual agentsâ€™ outputs judged for correctness? How are the sub-tasks evaluated for completion?\n2. How does the framework handle scenarios where certain agents fail to accomplish their tasks?\n3. What are the computational and token costs and how does it compare with other multi-agent methods?\n\nSuggestions:\n1. Improve the clarity of the methods section by providing a running example to help understand the various components. Consider reducing mathematical notations that does not aid in understanding. Replace high-level symbolic descriptions with implementable algorithms or detailed prompt recipes.\n2. Compare against multi-agent baselines. Include enterprise relevant metrics.\n\nMinor Comments:\n1. Line 73 - ...  generate interdependent tasks -> incorrect grammar \n2. Line 352 - appendix reference is missing."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZSTxUgSYjS", "forum": "yr14AzEdam", "replyto": "yr14AzEdam", "signatures": ["ICLR.cc/2026/Conference/Submission12807/Reviewer_YZQq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12807/Reviewer_YZQq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761858216022, "cdate": 1761858216022, "tmdate": 1762923615966, "mdate": 1762923615966, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduce TaskWeave, an LLM-based multi-agent framework for simulating complex enterprise dynamics. The system operates at three hierarchical levels: 1) Strategic level. Uses a Formulate-Partition-Diagnose-Align control cycle for long-horizon planning. \n2) Tactical level. Agents alternate between orchestrator and executor roles for task delegation. 3) Operational level. Context-aware execution with memory, dependency tracking, and tool access. The authors evaluate TaskWeave through year-long simulations of SaaS organizations, measuring task generation quality, role assignment distribution, plan completion rates."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation is clear and interesting. The three-level architecture grounded in control theory, strategic management, and division-of-labor theory. Also, the adaptation of traditional control loops (PDCA) to multi-agent hierarchical planning is interesting and potentially generalizable.\n\n2. TaskWeave generates usable synthetic data (e.g., enterprise documents, privacy annotations, hierarchical labels) that can support compliance and enterprise analytics research. The OSSD and ITHC tasks demonstrate meaningful downstream value.\n\n3. Evaluation across six different LLM backbones provides comprehensive evidence. \n\n4. The writing is clear and easy to follow."}, "weaknesses": {"value": "1. I have some confusion with the Arbitrary Ground Truth. For example, \"Ideal\" task distribution (40% Tech, 40% Marketing, 20% Strategy). Why is this correct?\n\n2. The framework design is multi-agent, which involves the closed models and tool-calling. It may consume a significant amount of tokens. What are the computational costs (tokens, time, money) for year-long simulations?\n\n3. In the framework, several steps rely on the Prompt setup. How sensitive is the system to organizational structure, role definitions, and prompt design?"}, "questions": {"value": "See in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eOdmYsxnCn", "forum": "yr14AzEdam", "replyto": "yr14AzEdam", "signatures": ["ICLR.cc/2026/Conference/Submission12807/Reviewer_SrAv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12807/Reviewer_SrAv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12807/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974599807, "cdate": 1761974599807, "tmdate": 1762923615629, "mdate": 1762923615629, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}