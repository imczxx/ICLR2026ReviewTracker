{"id": "UiATTlpNLz", "number": 6359, "cdate": 1757973325870, "mdate": 1763700885391, "content": {"title": "Revisiting Mixout: An Overlooked Path to Robust Finetuning", "abstract": "Finetuning vision foundation models often improves in-domain accuracy but comes at the cost of robustness under distribution shift. We revisit Mixout, a stochastic regularizer that intermittently replaces fine-tuned weights with their pretrained reference, through the lens of a single-run, weight-sharing implicit ensemble. This perspective reveals three key levers that govern robustness: the \\emph{masking anchor}, \\emph{resampling frequency}, and \\emph{mask sparsity}. Guided by this analysis, we introduce GMixout, which (i) replaces the fixed anchor with an exponential moving-average snapshot that adapts during training, and (ii) regulates masking period via an explicit resampling-frequency hyperparameter. Our sparse-kernel implementation updates only a small fraction of parameters with no inference-time overhead, enabling training on consumer-grade GPUs. Experiments on benchmarks covering covariate shift, corruption, and class imbalance, ImageNet / ImageNet-LT, DomainNet, iWildCam, and CIFAR100-C, GMixout consistently improves in-domain accuracy beyond zero-shot performance while surpassing both Model Soups and strong parameter-efficient fine-tuning baselines under distribution shift.", "tldr": "", "keywords": ["parameter-efficient fine-tuning", "domain shift", "classification", "ensemble", "transfer learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4c494a0bfe937067861341ffd0da9f4fe610441a.pdf", "supplementary_material": "/attachment/6d8ee722ae2a8924fdf8bb75ab561e4b8e2dba8f.zip"}, "replies": [{"content": {"summary": {"value": "This paper revisits Mixout (Lee et al.) for robust fine-tuning of a pre-trained vision model under distribution shifts between train and test data. The authors motivate themselves by first reminding the implicit L2-penalty behavior of Mixout and then proposing a better alternative to Mixout, GMixout, by grounding it with an expected OOD loss decomposition proposed in the DiWA paper (Rame et al. 2022). By introducing an exponential moving average anchor with dynamic masking per episode, the proposed method enjoys a better tradeoff between ID and OOD performance compared to the considered baseline.\n\n\n---\n\n> Reference\n- Lee at al. 2023, \"Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models\"\n- Rame et al. 2022, \"Diverse Weight Averaging for Out-of-Distribution Generalization\""}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- Revisiting Mixout (Lee et al. 2023) in the robust fine-tuning setup offers interesting insights to the community.\n- The proposed method is naturally connected to Mixout and DiWA (Rame et al. 2022), which have nice theoretical properties.\n- The proposed method shows a performance gain across multiple distribution shift scenarios.\n- The paper writing is clear and well-organized.\n\n---\n\n> Reference\n- Lee et al. 2023, \"Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models\"\n- Rame et al. 2022, \"Diverse Weight Averaging for Out-of-Distribution Generalization\""}, "weaknesses": {"value": "- `Lack of technical/theoretical innovation`\n  - The core technical contribution of the proposed method is the episodic update of the anchor (which is fixed as the pre-trained model weight in the original Mixout (Lee et al. 2023) and the Mask)\n  - However, the idea of moving the anchor is already well explored by previous works on robust fine-tuning (Jang et al. 2024 -- periodic merging), and the merits of the exponential moving average (EMA) during fine-tuning are also well-explored by existing methods (Shu et al. 2023, Oh et al. 2024)\n  - Although the authors bring a theory from DiWA paper (Rame et al. 2022) to explain the desired property of GMixout, there is **no rigorous analysis** (including supplementary A.1 that only provides a detailed decomposition) of **why GMixout achieves good control on the combination of variance-covariance-locality terms.**\n- `Too limited baseline lineup and less comprehensive literature review`\n  - In the experiment design, the authors **do not include some very representative robust fine-tuning methods**, such as WiSE-FT (Wortsman et al. 2022), LP-FT (Kumar et al. 2022), and FLYP (Goyal et al. 2022), which makes it difficult to gauge how significant the performance gain achieved by GMixout is.\n  - Besides, they do not even mention some relevant works, CLIPood (Shu et al. 2023) and CaRot (Oh et al. 2024), where the **exponential moving average (EMA) style parameter update** was leveraged for the robust fine-tuning context, and VRF (Zhu et al. 2024), which **reduces variance for OOD robustness via ensemble between pre-trained and fine-tuned model prediction**, and DaWin (Oh et al. 2025), a state-of-the-art robust-fine-tuning method that is based on the **weight interpolation between pre-trained and fine-tuned models**.\n    - Lack of citing these highly relevant works raises concern about the completeness of the authors' literature review.\n- `(minor) Incorrect learnable parameter description`\n  - I think the proposed method should have the same learnable parameters as Mixout (85.5 M) in Table 3.\n  - Although the per-step updated parameter can be 9M (only survives after masking), as the authors sample the new mask for every episode, each episode has different updated parameters. \n  - Therefore, the learnable parameter over the whole training should be counted as 85.5 M (the same as the full FT).\n  - And the GMixout is hard to recognize as a PEFT method, thereby.\n---\n\n> Reference\n- Rame et al. 2022, \"Diverse Weight Averaging for Out-of-Distribution Generalization\"\n- Jang et al. 2024, \"Model Stock: All we need is just a few fine-tuned models\"\n- Wortsman et al. 2022, \"Robust fine-tuning of zero-shot models\"\n- Kumar et al. 2022, \"Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution\"\n- Goyal et al. 2022, \"Finetune like you pretrain: Improved finetuning of zero-shot vision models\"\n- Shu et al. 2023, \"CLIPood: Generalizing CLIP to Out-of-Distributions\"\n- Oh et al. 2024, \"Towards Calibrated Robust Fine-Tuning of Vision-Language Models\"\n- Zhu et al. 2024, \"Robust Fine-tuning of Zero-shot Models via Variance Reduction\"\n- Oh et al. 2025, \"DaWin: Training-free Dynamic Weight Interpolation for Robust Adaptation\""}, "questions": {"value": "Please see the weakness section, and feel free to refute if there is any misunderstanding from me."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "dZqB2INGgL", "forum": "UiATTlpNLz", "replyto": "UiATTlpNLz", "signatures": ["ICLR.cc/2026/Conference/Submission6359/Reviewer_26yR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6359/Reviewer_26yR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6359/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761275270313, "cdate": 1761275270313, "tmdate": 1762918651106, "mdate": 1762918651106, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global response [1/2]"}, "comment": {"value": "We thank all reviewers for their constructive feedback. In this global response, we address three concerns that were shared by the majority of reviewers. We then respond to each reviewer’s specific comments in their corresponding sections.\n\n## Lack of innovation\n\nWe emphasize that our contribution goes well beyond simply adding EMA anchoring and resampling frequency to Mixout. Specifically, our work provides:\n\n**1. A new analytical lens for understanding Mixout:** To the best of our knowledge, we are the first to analyze Mixout through the lens of the BVCL decomposition [3]. Since Mixout implicitly defines a weight-space ensemble, this decomposition offers a principled way to understand why Mixout underperforms in many OOD settings. Our analysis (Fig 1,3,4) show that, unlike effective ensembles, Mixout fails to generate sufficiently decorrelated subnetworks. During the rebuttal period, we extended our analysis with a prediction-diversity study (Appendix A.7 highlighted in blue), which confirms that Mixout subnetworks exhibit almost no diversity, providing a clear explanation for its consistent failure modes.\n\n**2. GMixout: A principled generalization of Mixout:** Guided by these insights, we propose GMixout, a structured and theoretically motivated adaptation of Mixout. GMixout preserves the core idea of weight mixing while introducing three key mechanisms that directly target the limitations identified in our BVCL and diversity analyses:\n\n- Resampling frequency: a new hyperparameter controlling how often subnetworks are refreshed. Together with mask sparsity, this increases subnetwork decorrelation and enables Mixout to recover true ensemble benefits.\n- EMA anchor: replacing the fixed pre-trained weights used in Mixout with a moving-average anchor. This provides smoother optimization trajectories and adapts the model more effectively to OOD data.\n- Sparse CUDA kernels: an efficient implementation that updates only the active parameters, making GMixout genuinely memory- and compute-efficient on consumer GPUs.\n\n**3. Comprehensive empirical validation:** We empirically validate the above insights with extensive ablations and cross-domain evaluations. GMixout consistently outperforms strong baselines across several challenging OOD scenarios, including:\n\n- Covariate shift: ImageNet (Tab 4), DomainNet (Tab 1), iWildCam (Tab 1)\n- Common corruptions: CIFAR100-C (Tab 1)\n- Class imbalance: ImageNet-LT (Tab 2), CIFAR100-LT (Tab 2)\n\n## Extension to language\n\nAlthough GMixout makes no assumptions that restrict it to the vision domain, our experiments focused on vision tasks because this area offers widely studied distribution-shift benchmarks [1,3,7] that fit our computational constraints. We have already begun running language-domain experiments and will make every effort to include preliminary results before the end of the discussion period. However, comprehensive evaluations on language and vision–language tasks (e.g., VQA, image captioning) were beyond our computational budget and are deferred to future work.\n\nBecause distribution shifts can arise for many reasons, our evaluation accounts for a broad range of scenarios. Following this principle, and given our computational budget, we prioritized the vision domain, as it offers a rich and diverse testbed for studying robustness. In particular, we evaluate GMixout against strong baselines under **three major shift types** (corruptions, covariate shift, and long-tailed imbalance), across **both medium-scale datasets** (DomainNet, iWildCam, CIFAR-100) and a **large-scale dataset** (ImageNet-1k). These benchmarks also allow us to test GMixout on datasets **close to the CLIP pre-training distribution** (ImageNet, DomainNet) as well as datasets that are **distributionally far from CLIP** (iWildCam, CIFAR100).\n\n---\n\n*[1] Wortsman, et al. 2022, \"Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time.\"*\n\n*[3] Rame et al. 2022, \"Diverse weight averaging for out-of-distribution generalization.\"*\n\n*[7] Gulrajani, et al. 2020, \"In search of lost domain generalization.\"*"}}, "id": "0H9s4eazOy", "forum": "UiATTlpNLz", "replyto": "UiATTlpNLz", "signatures": ["ICLR.cc/2026/Conference/Submission6359/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6359/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6359/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763700388421, "cdate": 1763700388421, "tmdate": 1763700423277, "mdate": 1763700423277, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies and improves OOD robustness during fine-tuning by 1) revisiting MIXOUT, a stochastic regularization technique that replaces finetuned weights with pretrained references, and 2) proposes GMixout to improve robust finetuning of vision foundation models. The authors first analyze Mixout through bias-variance-covariance-locality (BVCL) decomposition to get an ensemble-based theoretical understanding. Then GMixout is designed with two key method-level modifications: (1) replacing the fixed pretrained anchor with an exponential moving average which can adapt during training and (2) controlling mask resampling frequency with a hyperparameter. Memory and compute efficiency is considered with sparse CUDA kernels. The method is evaluated across diverse distribution shift scenarios and demonstrates consistent improvements in OOD robustness with competitive ID accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **Insightful initial theoretical analysis and motivation.** The paper studies a timely and important topic - OOD robustness of fine-tuning methods. The ensemble-based perspective on Mixout and the BVCL decomposition provides explanation for why mask sparsity, EMA coefficient, and resampling frequency matter for robustness. Then GMixout focuses on improving robustness with these three points.\n- **Comprehensive experimental evaluation and ablation studies.** The paper evaluates on (1) a diverse set of benchmarks including different types of distribution shift (covariate shift, coruptions, long-tail) and (2) many baseline methods (full fine-tuning, PEFTs, and Model Soups), which strengthen the claims’ generalizability. Section 5.3 provides multiple ablation studies of different hyparameters, parameter budgets, and architectural choices (Vision vs. VL). GMixout shows higher OOD robustness while maintaining ID accuracy. \n- **Practical efficiency. The authors take memory and computational efficiency into consideration.** The sparse CUDA kernel implementation addresses a limitation of the original Mixout. This helps make the improved method feasible for finetuning large-scale models on consumer GPUs (table 3)."}, "weaknesses": {"value": "We thank the authors for submitting the paper to ICLR 2026! There are a few weaknesses listed below which I believe can make the paper better. For some points, please also refer to the questions below.\n- **Missing statistical significance testing and inconsistent performance on large-scale data.** Throughout the paper, performance differences are often small (0.3-1 point) without error bars, confidence intervals, or significance tests reported. It makes it hard to tell whether improvements are meaningful or within noise margins. This is especially true for larger-scale data (as acknowledged in Observation 2 and table 4), where GMixout achieves only slightly higher average OOD robustness and lower robustness to some fine-tuning strategies (Model Soups and Random Mask). Also, more analysis and understanding on why GMixout sometimes underperforms would strengthen the contribution. \n- **Novel limitation.** GMixout is based on Mixout and the core modification (EMA anchor and resampling frequency) are relatively incremental. EMA-based weight averaging is well-established, and the resampling frequency is hyperparameter to tune. The connection to ensemble methods, which I find interesting to read, tends to be more interpretative than technically novel. But I think the idea of studying and combining all these techniques and the importance of this topic have a strong weight. I think this is not a big concern for me. \n- **Incomplete comparison with related work.** The paper does include a relatively thorough evaluation framework, but there are comparisons with a limited number of other recent robust fine-tuning methods beyond Model Soups and basic PEFT."}, "questions": {"value": "- Can you provide error bars across multiple random seeds? Given the margins in many comparisons, this would strengthen the claims considerably. \n- Why does GMixout’s advantage narrow on ImageNet-1k compared to medium-scale datasets? Is this a fundamental limitation of the approach or coulter more hyperparameter tuning (episode I) help? \n- With long-tail dataset ImageNet-LT (table 2), GMixout achieves the best “few” shot accuracy and is behind Model Soups on “many” shot. Could you provide insight into this trade-off and whether it can be adjusted?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kZO9E5ECwj", "forum": "UiATTlpNLz", "replyto": "UiATTlpNLz", "signatures": ["ICLR.cc/2026/Conference/Submission6359/Reviewer_Tydt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6359/Reviewer_Tydt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6359/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937971345, "cdate": 1761937971345, "tmdate": 1762918649964, "mdate": 1762918649964, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the trade-off between in-domain performance and robustness when finetuning vision foundation models. The authors revisit Mixout, interpreting it as an implicit ensemble via stochastic weight-sharing, and identify three key robustness factors: anchor choice, resampling frequency, and sparsity. They propose GMixout, which adapts the anchor using an exponential moving average and introduces an explicit resampling-frequency hyperparameter. A sparse-kernel implementation ensures efficiency with no inference overhead. Across benchmarks including ImageNet, DomainNet, iWildCam, and CIFAR100-C, GMixout improves finetuning accuracy while outperforming model soups and parameter-efficient baselines under distribution shift."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is clearly written, well structured, and visually polished.\n2. The experimental evaluation is extensive and convincingly supports the paper’s claims across diverse benchmarks."}, "weaknesses": {"value": "1. The comparison is incomplete — several strong robust finetuning methods that dynamically constrain weight drift from pretrained models, such as TPGM[1], FTP[2], SPD[3], are not included.\n2. The evaluation is limited to vision models; no experiments are provided on large language or vision-language models, which would strengthen the generality of the proposed approach.\n\n[1] Tian, Junjiao, et al. \"Trainable projected gradient method for robust fine-tuning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[2] Tian, Junjiao, et al. \"Fast trainable projection for robust fine-tuning.\" Advances in Neural Information Processing Systems 36 (2023): 11374-11393.\n\n[3] Tian, Junjiao, Chengyue Huang, and Zsolt Kira. \"Rethinking weight decay for robust fine-tuning of foundation models.\" Advances in Neural Information Processing Systems 37 (2024): 22418-22440."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "V6ap5AvNsS", "forum": "UiATTlpNLz", "replyto": "UiATTlpNLz", "signatures": ["ICLR.cc/2026/Conference/Submission6359/Reviewer_rUAF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6359/Reviewer_rUAF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6359/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972636871, "cdate": 1761972636871, "tmdate": 1762918649580, "mdate": 1762918649580, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits Mixout through the lens of implicit ensemble regularization, conceptually similar to stochastic regularization such as Dropout.\nBy doing this, this paper proposes GMixout, a generalized variant that improves supervised fine-tuning (SFT) OOD robustness under distribution shift.  \nThe authors argue that Mixout’s random parameter replacement implicitly forms an ensemble of subnetworks sharing the same backbone weights, and that controlling this stochastic process can enhance out-of-distribution (OOD) generalization.  \nA sparse CUDA implementation further enables scaling to large ViT/CLIP backbones.\nReported image classification experiments across various benchmarks demonstrate consistent OOD robustness improvements compared to Mixout and other baseline methods, without sacrificing in-distribution (ID) accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This method empirically improves the OOD robustness.\nThe authors evaluate across multiple OOD settings and achieves superior OOD robustness in most settings.\nhe sparse CUDA implementation makes Mixout-style regularization feasible on modern large-scale vision models, demonstrating fair engineering contribution."}, "weaknesses": {"value": "The method is effective but not very well motivated. Where does the improvement come from, why the adaptive anchor and the resampling frequence method is effective.  It will add to great value if more in-depth analysis could be made about the `implicit ensemble` feature of the GMixout process, instead of just describing them intuitively.\n\nGMixout primarily modifies Mixout via some hyperparameters (EMA anchor and resampling frequency). While effective, it may be viewed as an engineering refinement rather than a conceptual breakthrough.\n\nAll reported experiments are conducted on vision classification tasks (ViT, CLIP).\nHowever, the SFT-based algorithms, especially those PEFT methods, have also been primarily deployed to those more advanced models and/or tasks. For example, it is expected to report GMixout performance on LLM, VLM, or even those reasoning models, to justify its universal effectiveness and efficiency."}, "questions": {"value": "Why model soup performs better on Cifar100?\nThe results in Table 4 seems not to be favor to the proposed method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "243coZFO7R", "forum": "UiATTlpNLz", "replyto": "UiATTlpNLz", "signatures": ["ICLR.cc/2026/Conference/Submission6359/Reviewer_WqZb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6359/Reviewer_WqZb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6359/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982255490, "cdate": 1761982255490, "tmdate": 1762918649267, "mdate": 1762918649267, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits Mixout, a stochastic regularizer for finetuning pretrained models, and reinterprets it as a single run implicit ensemble mechanism. Based on this new perspective, the authors identify three core factors influencing robustness：1、Masking anchor：the reference weights that Mixout reverts to. 2、Resampling frequency：how often random masks are refreshed. 3、Mask sparsity：the proportion of weights replaced or retained. Building on this, the paper proposes GMixout, which (i) replaces the fixed pretrained anchor with an exponential moving average (EMA) of weights during training, and (ii) introduces a resampling frequency hyperparameter that controls how frequently subnetworks are resampled.The authors also present a sparse kernel GPU implementation that enables large scale finetuning on consumer GPUs without inference time cost. Extensive experiments on benchmarks such as ImageNet, DomainNet, iWildCam, CIFAR100 C, and ImageNet LT show that GMixout improves out of distribution (OOD) robustness while maintaining or improving in domain (ID) accuracy compared with LoRA, Random Mask, and Model Soups."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The work provides a novel theoretical reinterpretation of Mixout as an implicit ensemble in weight space；The proposed EMA based adaptive anchor and mask resampling frequency control are conceptually simple yet innovative extensions that directly improve robustness；The analysis using bias variance covariance–locality (BVCL) decomposition is insightful, linking ensemble theory to parameter efficient finetuning (PEFT).The experiments are comprehensive and rigorous, covering covariate shift, corruption, and class imbalance.Ablation studies (Figure 3，4) systematically examine how EMA coefficient, resampling frequency, and sparsity affect IDOOD trade offs.Results are consistent across multiple datasets and model sizes, showing strong empirical support.The insights may inspire further exploration of ensemble theoretic views of other finetuning methods (e.g., LoRA or adapters)."}, "weaknesses": {"value": "Limited exploration on language or multimodal tasks：Although the authors claim GMixout is general, all experiments are on vision datasets. Demonstrating its applicability on language or vision–language tasks would reinforce generality.\n\nComparison with newer PEFT baselines：The baselines include LoRA and Random Masking, but recent adapter free PEFT approaches (e.g., DoRA, AdaLoRA, and QLoRA) are not discussed empirically. Including would provide stronger positioning. Although the ensemble based bias，variance，covariance，locality analysis is conceptually appealing, the theoretical derivation is mostly heuristic. A more formal proof or tighter bounds on the expected OOD error under Mixout/GMixout would strengthen the argument."}, "questions": {"value": "1. refer to weakness\n\n2. Can GMixout be applied to text based or multimodal foundation models (e.g., CLIP, LLaVA, or language- only transformers)? If so, are there any expected differences in behavior? and how sensitive is performance to λ and k when scaling to larger models like ViT-L/14 or other architectures (e.g., ResNet backbones)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5oMM2Geqez", "forum": "UiATTlpNLz", "replyto": "UiATTlpNLz", "signatures": ["ICLR.cc/2026/Conference/Submission6359/Reviewer_EpdY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6359/Reviewer_EpdY"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission6359/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984648459, "cdate": 1761984648459, "tmdate": 1762918648635, "mdate": 1762918648635, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}