{"id": "U3DENarFX8", "number": 1371, "cdate": 1756876373571, "mdate": 1759898212208, "content": {"title": "Adaptive parameter-efficient fine-tuning via multi-task optimization on subset selection", "abstract": "Parameter-efficient fine-tuning (PEFT) is a highly effective approach for adapting large pre-trained models to downstream tasks with minimal computational overhead. At the core, PEFT methods freeze most parameters and only trains a small subset (say $<0.1\\%$ of total parameters). Notably, different PEFT methods select different subsets of parameters and result in varying performances. This variation prompts a key question: how to adaptively select the most influential subset?\n\nWe formulate the subset selection as a multi-task problem: maximizing the performance and minimizing the number of trainable parameters, which consists of both discrete and continuous objectives. We leverage a series of transformations -- including $\\epsilon$-constraint method and second-order Taylor approximation -- to arrive at the classical 0-1 knapsack problem, which we solve via the lens of Pareto optimality. Consequently, we propose AdaPEFT, an efficient and scalable algorithm for PEFT that adapts to various tasks, in which our subset selection is consistent as the training horizons and model sizes scale up over $50\\times$.", "tldr": "", "keywords": ["parameter-efficient fine-tuning", "multi-task optimization", "subset selection", "Pareto optimal"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/85e227d87618022e0d404ff532e4593f6f45bf7f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes AdaPEFT, which frames parameter-efficient fine-tuning as a multi-task problem (utility vs. number of trainable parameters), reduces it via ε-constraint and second-order Taylor expansion to a 0–1 knapsack over parameter groups, and scores each group with a Hessian-informed Per-Parameter Influence (PPI/APPI). A small “probe” run (FMT on a small model for ~10% steps) selects groups; the chosen subset is then transferred to larger models as PEFT. Experiments claim near-Pareto selections and cross-size transferability."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear formalization from bi-objective subset selection to knapsack; neat use of ε-constraint and a closed-form second-order proxy for loss reduction. \n\n2. Practical scoring routine that avoids explicit Hessian-vector backprop; “lazy” updates limit overhead. \n\n3.  Coherent narrative around Pareto frontiers; the visualization of PPI/APPI is informative and may inspire diagnostic tooling."}, "weaknesses": {"value": "1. Approximation stack is fragile/not validated: The chain—ε-constraint ⇒ path-restricted GD ⇒ local 2nd-order fit ⇒ knapsack—rests on strong locality assumptions and positivity of $g^\\top H g$; the method discards non-convex neighborhoods by positivity/R² checks, risking biased selection. No stress tests on highly non-convex regimes or adversarial losses.\n\n2. Evaluation scope is dated and light: LLM tests use GPT-2 and small NLU benchmarks; no modern LLMs (LLaMA-2/3, Qwen, Mixtral), no instruction/code/math or long-context settings where PEFT behavior diverges. \n\n3. Baselines are incomplete. Missing comparisons to stronger PEFT families (e.g., DoRA, PiSSA/LoRA+ variants, VeRA, prefix/prompt-tuning at scale, QLoRA-style quantized PEFT). The study largely contrasts against LoRA/BitFit/LayerNorm/linear probing, which is insufficient in 2025/26\n\n4. The wall-clock/Flops plots conflate a small-model FMT “Part I” plus large-model PEFT “Part II” for AdaPEFT, but compare to single-phase LoRA/FMT; it is unclear whether overall tuning budget and data passes are matched."}, "questions": {"value": "1. Why not evaluate layer-wise grouping (per attention/MLP block) to show genuine adaptivity? What happens to runtime and accuracy if K is increased by 10–100?\n\n2. Can APPI be replaced by cheaper proxies (Fisher info, SNIP/GRASP-style saliency, gradient norm) with similar selection? A simple ablation would clarify the value of Hessian fitting."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hGAKeoa6ch", "forum": "U3DENarFX8", "replyto": "U3DENarFX8", "signatures": ["ICLR.cc/2026/Conference/Submission1371/Reviewer_BkSU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1371/Reviewer_BkSU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1371/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761537852692, "cdate": 1761537852692, "tmdate": 1762915751514, "mdate": 1762915751514, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces AdaPEFT, which searches optimal combinations of multiple parameter-efficient fine-tuning (PEFT) modules per task and model. The authors first discuss a method for formulating the Pareto optimization of the number of parameters (a discrete value) and accuracy (a continuous value) as a 0-1 knapsack problem. The number of parameters is simplified to binary choices—whether to use each of several PEFT methods. The importance of each PEFT method is then estimated, and combinations of PEFT methods are incrementally constructed in the order of importance (using the best PEFT, then using the best and second-best PEFTs, and so on), which are considered to form the Pareto front. To estimate the importance of each PEFT method, the paper proposes a novel approach that approximates the Hessian matrix in the importance factor using only multiple forward calculations, enabling practical computation. Through experiments, the authors claim that their proposed APPI metric can effectively identify Pareto-optimal combinations of PEFT methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Mathematically formulating the importance of each PEFT using the Hessian matrix is quite intriguing. While the mathematical transformation might be a common practice in other domains, such as data curation, the mathematical building for PEFT is interesting and will motivate future research. \n- The Hessian matrix approximation is an interesting and efficient approach.\n- The experimental results are appealing and prove that the proposed approximation works well."}, "weaknesses": {"value": "#### Major Weakness\n- Adaptive PEFT itself is not unique, but there are no citations or comparisons with previous methods. For example, S_4 [1], BIPEFT [2], and MambaPEFT [3] utilize evolutionary search methods with several steps to optimize the combination of PEFT methods in addition to the hyperparameters. PrunePEFT [4], AutoPEFT [5], and NOAH [6] utilized supernet-based neural architecture search. The former methods might be time consuming, but the latter methods (PrunePEFT, AutoPEFT, and NOAH) just need the same steps as AdaPEFT.  \n- The Pareto front discovered by AdaPEFT is not above LoRA, based on Fig. 5 and Fig. 6. It should be important to show the parameter-accuracy trade-off curve of LoRA by changing the rank to prove that AdaPEFT has a better trade-off with other parameter counts.  \n- The accuracy information of vision models is missing. Also, what pre-trained models are used, especially with the ImageNet finetuning setting?  \n- Although the formula is interesting, the experiments are very simple, with just deciding whether to use 4 or 5 PEFT methods with pre-defined hyperparameters.  \n\n#### Minor Weakness\n- The citation style is weird. If you are using LaTeX, it would be better to use \\citep{}.  \n- The statement “some existing PEFT methods are far from the frontier, indicating the potential failure of non-adaptive PEFT” in L434-435 can be incorrect. If PEFT methods far from the frontier are different per task or model, it can be true. However, across all experimental settings, there is a tendency that LoRA is closer to the frontier, while BitFit and LayerNorm tuning are farther from it, suggesting that BitFit and LayerNorm tuning are simply weaker methods.  \n- Typo  \n  - L013) only trains -> only train  \n  - L262) No equation numbering.  \n\n\n[1] Chen, J., Zhang, A., Shi, X., Li, M., Smola, A., & Yang, D. Parameter-Efficient Fine-Tuning Design Spaces. In The Eleventh International Conference on Learning Representations.  \n[2] Chang, A., Wang, J., Liu, H., Bhatia, P., Xiao, C., Wang, T., & Ma, F. (2024). BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models. In 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024 (pp. 7429-7440). Association for Computational Linguistics (ACL).  \n[3] Yoshimura, M., Hayashi, T., & Maeda, Y. MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba. In The Thirteenth International Conference on Learning Representations.  \n[4]  Lawton, N. G., Kumar, A., Thattai, G., Galstyan, A., & Ver Steeg, G. (2023, July). Neural Architecture Search for Parameter-Efficient Fine-tuning of Large Pre-trained Language Models. In The 61st Annual Meeting Of The Association For Computational Linguistics.  \n[5] Zhou, H., Wan, X., Vulić, I., & Korhonen, A. (2024). Autopeft: Automatic configuration search for parameter-efficient fine-tuning. Transactions of the Association for Computational Linguistics, 12, 525-542.  \n[6] Zhang, Y., Zhou, K., & Liu, Z. (2024). Neural prompt search. IEEE Transactions on Pattern Analysis and Machine Intelligence."}, "questions": {"value": "- Please see major weakness.  \n- In L262, why is fitting with minus learning rates needed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rVLqe9dYa6", "forum": "U3DENarFX8", "replyto": "U3DENarFX8", "signatures": ["ICLR.cc/2026/Conference/Submission1371/Reviewer_Qzt2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1371/Reviewer_Qzt2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1371/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761658247481, "cdate": 1761658247481, "tmdate": 1762915751173, "mdate": 1762915751173, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introducesa technique to adaptively select the most effective subsets of parameters for fine-tuning. The key idea is that they formulate the subset selection of parameters as a multi-task optimization problem consisting of a discrete objective ( over the subsets) and a continuous objective (minimization of loss). The goal is to maximize model performance while minimizing the number of trainable parameters. This problem is then transformed into a 0-1 knapsack problem, where the \"value\" of each parameter group is its potential for loss reduction, calculated using Hessian (second-order) information. The key finding is that these \"influential\" parameter groups can be identified early in training on small models and effectively transferred to optimize the fine-tuning of large models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This is an interesting paper and the formulation makes sense. To me, the strengths are\n  1. the formulation of the multi-task optimization problem (ie maximizing performance and minimizing trainable model parameters) as a classical 0-1 knapsack problem is nice and an approach that is novel and appealing.\n  2. the authors use a Hessian-informed analysis to measure the value of a different parameter groups. This is a nice principled and data-motivated way to determine the most important parameters for fine-tuning. \n  3. Their framework is scalable to large models and not expensive in terms of compute budget"}, "weaknesses": {"value": "- If I understand correctly, their method AdaPEFT relies on groupings of parameters. So that, a suboptimal grouping strategy may fail to lead to good performance. However, this technique can't determine influential parameters within a group or determine new, more advantageous smaller groupings. \n - This method relies on the Hessian to determine loss-reduction. The Hessian is second order and the algorithm requires multiple forward passes (if I understand, $4k+1$ passes where $k$ is the number of subset parameter groups). This is quite a lot of computational overhead compared to other off-the-shelf PEFT methods."}, "questions": {"value": "I have a few questions related to the weaknesses described above\n\n - Is it correct that this technique performs some kind of optimization on the group level but not within group level. How does this hinder or affect results? How sensitive are the results to the choice of parameters subsets from the beginning. \n - What is the comparison of computation required for AdaPEFT vs the other PEFT methods described in the paper; eg in terms of FLOPs? As mentioned above, the Hessian approximations require multiple forward passes. I understand the performance improvements but how much do these come at a cost of computation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9HEws60Vwb", "forum": "U3DENarFX8", "replyto": "U3DENarFX8", "signatures": ["ICLR.cc/2026/Conference/Submission1371/Reviewer_fTk5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1371/Reviewer_fTk5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1371/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927359745, "cdate": 1761927359745, "tmdate": 1762915750123, "mdate": 1762915750123, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}