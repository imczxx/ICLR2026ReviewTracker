{"id": "KBN6oUx5uL", "number": 4511, "cdate": 1757692581829, "mdate": 1759898028921, "content": {"title": "SR-Scientist: Scientific Equation Discovery With Agentic AI", "abstract": "Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveraging their embedded scientific knowledge for hypothesis generation. However, current methods typically confine LLMs to the role of an equation proposer within search algorithms like genetic programming. In this paper, we present SR-Scientist, a framework that elevates the LLM from a simple equation proposer to an autonomous AI scientist that writes code to analyze data, implements the equation as code, submits it for evaluation, and optimizes the equation based on experimental feedback. Specifically, we wrap the code interpreter into a set of tools for data analysis and equation evaluation. The agent is instructed to optimize the equation by utilizing these tools over a long horizon with minimal human-defined pipelines. Empirical results show that SR-Scientist outperforms baseline methods by an absolute margin of 6\\% to 35\\% on datasets covering four science disciplines. Additionally, we demonstrate our method's robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning framework to enhance the agent's capabilities.", "tldr": "We present SR-Scientist, a framework with a corresponding RL training strategy, in which an autonomous agent discovers scientific equations through long-horizon, tool-driven data analysis and equation evaluation.", "keywords": ["Symbolic regression", "Equation Discovery", "Large Language Models", "Agentic AI"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9248aff2ec3e844e37e0dcf4f8eca942cb999209.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces SR-Scientist, an agentic framework for scientific equation discovery through data-analysis and equation-evaluation tool calling. The authors also develop an RL training pipeline that improves agent performance. The method outperforms baselines on LLM-SRBench [1].\n\n[1] Shojaee et al. \"LLM-SRBench: A new benchmark for scientific equation discovery with large language models.\" (2025)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The method is simple and clear. The task of scientific equation discovery is important, and the problem formulation is concise.\n- SR-Scientist consistently outperforms state-of-the-art baselines on all models and across all tested scientific fields. The selected baselines make sense.\n- The paper successfully demonstrates a path forward towards self improvement of the agent through an end-to-end RL pipeline."}, "weaknesses": {"value": "- The work appears to be heavily inspired by SR-LLM [2]. Several key components, such as the equation-evaluator tool or the experience buffer, closely resemble those introduced in [2]. While the reframing of the problem as an agentic framework is probably useful, it is not a novel idea and has been widely used in many recent works.\n- Results are evaluated solely on synthetic data (LSR-Synth, a synthetic subset of [1]). This limits the assessment of the method for practical applications. Adding experiments on real-world datasets or use cases where data often includes noise, outliers, etc., could provide a stronger evidence. Also, designing new tools to handle such challenges would strengthen the paper.\n- The current design of the experience buffer ablation (Table 3) only confirms that accumulating knowledge over long horizons is better than constantly starting from scratch. Instead, this ablation should isolate the contribution of the suggested fetch-top-K buffer (for example, against a baseline that randomly selects equations).\n\n[2] Shojaee et al. \"LLM-SR: Scientific equation discovery via programming with large language models.\" (2024)."}, "questions": {"value": "1. Have the authors considered the use of broader tools for data analysis, such data visualization or graphical analysis? Do you think that expanding the framework's tool capabilities could be useful?\n2. Could the authors please elaborate on the mechanisms that allow the framework to obtain a long-horizon behavior?\n3. Do the authors plan to evaluate their method on real-world datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "39tZkF4l5j", "forum": "KBN6oUx5uL", "replyto": "KBN6oUx5uL", "signatures": ["ICLR.cc/2026/Conference/Submission4511/Reviewer_ewF1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4511/Reviewer_ewF1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762036352868, "cdate": 1762036352868, "tmdate": 1762917412955, "mdate": 1762917412955, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SR-Scientist, an agentic large-language-model (LLM) framework for symbolic regression. It combines two tools (a data analyzer and an equation evaluator) in a long-horizon reasoning loop with an experience buffer and a reinforcement-learning (RL) fine-tuning stage based on GRPO. Experiments on the LSR-Synth benchmark across four scientific domains show solid empirical gains over existing SR and LLM baselines, supported by ablations and robustness analyses."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "+ The paper is well motivated and clearly framed, presenting the idea of turning LLMs into autonomous “scientists” that iteratively refine hypotheses through data analysis and reasoning.\n+ The evaluation covers multiple domains, five different LLM backbones, and includes analyses for noise robustness, out-of-domain generalization, and symbolic accuracy.\n+ The modular two-tool framework with memory buffering is versatile and adaptable to other discovery tasks beyond symbolic regression.\n+ The empirical results are consistently strong across settings and supported by detailed ablation studies.\n+ The framework provides a practical system contribution that can serve as a foundation for other research works in scientific AI agents."}, "weaknesses": {"value": "- The work mainly integrates existing components such as tool use, GRPO-based RL, and memory buffering, without introducing new learning principles. The proposed mechanisms are largely heuristic and not deeply analyzed.\n- The RL fine-tuning stage performs worse than inference-only variants and is limited to a single backbone. Its “one-iteration” setup contradicts the long-horizon reasoning concept and lacks convergence or stability analysis.\n- The comparison with baselines is not compute-normalized. SR-Scientist executes up to 25 turns × 40 iterations, while non-LLM baselines are capped at 100k equations, leading to possible resource imbalance.\n- The metric choice emphasizes Accτ with a 5% trimming rule and omits standard regression metrics like RMSE or MAE. Results are averaged over only three runs, which weakens statistical confidence.\n- Symbolic accuracy remains around 7%–8%, much lower than numeric accuracy (>60%), suggesting improved curve fitting but not genuine symbolic recovery.\n- The paper lacks qualitative examples illustrating how the agent refines equations through multi-step reasoning, making the “scientific inspiration” claim speculative.\n- Several parameters and mechanisms, such as K in the experience buffer, the MAPE goal threshold, and the exclusive use of BFGS for optimization, are presented without sensitivity analysis or justification.\n- The dataset evaluation omits LSR-Transform due to contamination concerns, but does not demonstrate that LSR-Synth is free of memorization. There are no experiments on real-world scientific data.\n- Figures are dense, tables inconsistent, and citations incomplete, which affects readability.\n- In summary, the lack of algorithmic novelty, limited RL justification, resource imbalance, and weak interpretability analysis reduce the overall impact. The current version of the paper stands as a well-executed system but needs stronger methodological contributions, fairer comparisons, and deeper reasoning analysis to meet the bar for ICLR."}, "questions": {"value": "- Why does RL underperform? Was training unstable or reward scaling flawed?\n- How is data contamination avoided in LSR-Synth?\n- Try to do an apples-to-apples comparison. Would SR-Scientist still outperform if all methods were given the same compute budget or wall-clock time?\n- Why restrict the framework to two tools instead of adding others, like dimensional checks or simplification modules?\n- What causes the observed drop in performance beyond 25 turns?\n- Can you provide qualitative examples of reasoning trajectories that refine equations step by step?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iQo3nIbksA", "forum": "KBN6oUx5uL", "replyto": "KBN6oUx5uL", "signatures": ["ICLR.cc/2026/Conference/Submission4511/Reviewer_E5Ep"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4511/Reviewer_E5Ep"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762102479782, "cdate": 1762102479782, "tmdate": 1762917412387, "mdate": 1762917412387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel framework, SR-Scientist, for LLM-based scientific equation discovery. Unlike prior approaches that primarily treat LLMs only as equation proposers within search algorithms, SR-Scientist extends their role to act as agentic AI scientists capable of performing complementary pre- and post-processing tasks such as data analysis, equation implementation, and submission for evaluation. The framework integrates a set of wrapped tools (e.g., data analysis and equation evaluation) that are used in an agentic and long-horizon manner to autonomously navigate the full equation discovery process.\nEmpirical results demonstrate that the proposed approach outperforms existing baselines on standard benchmarks, exhibits improved robustness to noise, and shows better generalization across diverse tasks. The paper also includes experiments with a smaller Qwen-30B model augmented with end-to-end RL fine-tuning which shows their results could even be strengthen with the fine-tuning and adaptation of LLM backbone."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The paper is well-written and clearly motivated, making it an engaging read.\n- The experiments are comprehensive on recent benchmarks and with thorough analysis. \n- The reported results demonstrate substantial performance improvements over state-of-the-art baselines."}, "weaknesses": {"value": "- The proposed data analysis tool is well-motivated and conceptually sound. However, I am unclear about the necessity of using an LLM as an equation evaluator, given that evaluation in this task is typically data-driven and follows a consistent procedure. Introducing an agentic LLM into the evaluation loop could potentially introduce unnecessary variability or LLM generation errors. I would appreciate clarification on why this component is needed and what advantages it offers over standard predefined evaluation methods for generated hypotheses. Additionally, Table 3 seem to not include an ablation for this tool (T2), making its specific role and impact questioning. \n\n- I think additional qualitative examples would help clarify what the agentic steps contribute beyond the baseline LLM-SR approach. Showing intermediate output such as snippets of generated code or key decision points the agent follows during the discovery process would help to understand how these steps influence the final discovered equations.\n\n- For the results reported in Table 2 and Figure 3, it is unclear whether they are evaluated on all LLM-SRBench tasks or only a specific subset or category. It would be helpful to include this information explicitly in the captions."}, "questions": {"value": "Included in the weaknesses section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "JdTsqFFm6I", "forum": "KBN6oUx5uL", "replyto": "KBN6oUx5uL", "signatures": ["ICLR.cc/2026/Conference/Submission4511/Reviewer_FL8G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4511/Reviewer_FL8G"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762119716965, "cdate": 1762119716965, "tmdate": 1762917412003, "mdate": 1762917412003, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SR-SCIENTIST, a framework for applying large language models (LLMs) to the scientific equation discovery (SED) process. The framework integrates evolutionary search with an LLM-as-heuristic component but offers greater flexibility than prior methods by allowing LLMs to perform a wider range of actions in each iteration. The paper demonstrates that enabling LLMs to interact directly with observational data (via tool use) and to engage in multi-turn interaction improves performance on SED tasks. Additionally, it explores finetuning LLMs with GRPO for this domain."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The experiments present strong results across multiple metrics and settings, consistently favoring the proposed approach.\n2. Comprehensive ablation studies highlight the effects of two key components - tool calls and experience buffer - as well as the influence of interaction length and the distribution of tool usage.\n3. The paper provides a detailed discussion of the reinforcement learning (RL) process, including the methodology for constructing synthetic training data and a comparative analysis of different reward function designs.\n4. The writing is clear, well-structured, and easy to follow."}, "weaknesses": {"value": "1. The contribution in terms of novelty is somewhat incremental. The framework closely resembles prior approaches such as LLM-SR, particularly in its use of an experience buffer, evaluation module, and parameter optimization function. The main components - tool use and multi-turn interaction - can be seen as adaptations of existing agentic LLM paradigms (e.g., GPT-OSS, Qwen3-Coder) to the symbolic regression task, rather than a fundamentally new agentic framework. The RL fine-tuning pipeline largely follows established practices, including synthetic data construction and the use of the GRPO loss."}, "questions": {"value": "1. Figure 6 shows that Equation Evaluation dominates tool usage. Does this suggest that the agents primarily engage in a “guess-and-check” process rather than deriving insights from observation data through the Data Analyzer tool?\n2. The analysis indicates that increasing the maximum number of turns beyond 25 results in stagnating or slightly declining performance. Is this due to context length limitations, or does it reflect the agent’s inability to explore new strategies (e.g., requiring periodic resetting or reinitialization)?\n3. Could the authors include representative failure cases? A qualitative analysis of typical failure modes - such as difficulties with specific mathematical structures, high noise levels, or certain data domains - would provide valuable insights into the framework’s limitations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N0KEFRVqDh", "forum": "KBN6oUx5uL", "replyto": "KBN6oUx5uL", "signatures": ["ICLR.cc/2026/Conference/Submission4511/Reviewer_zbXv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4511/Reviewer_zbXv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4511/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762280759996, "cdate": 1762280759996, "tmdate": 1762917411661, "mdate": 1762917411661, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}