{"id": "ygSTMCq1YY", "number": 9547, "cdate": 1758126992229, "mdate": 1759897712849, "content": {"title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "abstract": "Large Language Models (LLMs) increasingly rely on external tools to perform complex, realistic tasks, yet their ability to utilize the rapidly expanding Model Contextual Protocol (MCP) ecosystem remains limited. Existing MCP research covers few servers, depends on costly manual curation, and lacks training support, hindering progress toward real-world deployment. \nTo overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training. \nMCP-Flow collects and filters data from 1166 servers and 11536 tools, producing 68733 high-quality instruction-function call pairs and 6439 trajectories, far exceeding prior work in scale and diversity. \nExtensive experiments demonstrate MCP-Flow's effectiveness in driving superior MCP tool selection, function-call generation, and enhanced agentic task performance. \nMCP-Flow thus provides a scalable foundation for advancing LLM agents' proficiency in real-world MCP environments.", "tldr": "We propose MCP-Flow, a comprehensive pipeline, data and model suite that automatically constructs datasets from real-world, diverse and continuously scaling MCP servers, thereby facilitating more effective utilization of MCP tools by LLM agents.", "keywords": ["Model Contextual Protocol", "Large Language Model", "Tool Learning", "Funcation Calling", "Dataset Construction"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e3c3bfd2096bb1a8c356e7d1e13f4701f148e487.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces MCP-Flow, an automatic pipeline to collect MCP tools and construct corresponding function calling datasets for improving LLM capability when facing real-world MCP tools. The pipeline includes web-agent server crawling, tool processing, data generation (with methods including few-shot prompting and instruction evolution), data filtration. The experiments are conducted on the collected data, around 70k in total, with data split to seen set, unseen tools and unseen servers. Results reveal that models with smaller size trained with their data outperform large models, and generalize well to unseen tools and unseen servers. Moreover, the data can also serve as database for sample retrieval, improving larger models in training-free manner."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. A new pipeline which has been proven that effectively enables MCP tool crawling and data generation.\n\n2. The release of a new dataset containing around 70k real-world MCP tool samples, which exceeds the size of most currently available function-calling datasets.\n\n3. Interesting findings regarding data utilization in a training-free manner."}, "weaknesses": {"value": "1. The pipeline description appears largely engineering-oriented, and it lacks innovative design that is interesting or distinct from existing work.\n\n2. The experiments are conducted only on the authors’ generated function calling data. Given the availability of many existing synthetic or MCP-based benchmarks (e.g., BFCL, $\\tau$-bench, MCP-Universe, etc.), it is not acceptable that no results on established benchmarks are reported.\n\n3. The dataset seems to focus mainly on single-turn instructions. While this is important, recent work has shown that multi-turn scenarios are more representative of real-world applications, so corresponding data construction and evaluation are expected.\n\n4. The pipeline heavily relies on DeepSeek-V3 for quality checking, but it lacks analysis of agreement between human annotators and the model.\n\n5. The pipeline simply leverages WizardLM-like evolution operations to increase complexity, while tool candidates are randomly sampled. It is therefore difficult to assess whether the resulting instructions are sufficiently complex, especially considering that similar tools can increase tool-selection difficulty."}, "questions": {"value": "1. What is difference between metrics Param and AST? As far as I know, AST already evaluates both tool selection and parameter filling. \n\n2. Why large models without training also perform worse on the unseen data? If I understand correctly, All test sets should be unseen for models without training."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Aehz1KqZ3X", "forum": "ygSTMCq1YY", "replyto": "ygSTMCq1YY", "signatures": ["ICLR.cc/2026/Conference/Submission9547/Reviewer_qUzx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9547/Reviewer_qUzx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9547/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761644277413, "cdate": 1761644277413, "tmdate": 1762921107587, "mdate": 1762921107587, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work focuses on collecting MCP tool-calling trajectories that can be used to fine-tune LLMs. The authors propose MCP-Flow, an automated, web-agent–driven pipeline that integrates large-scale server discovery, data synthesis, and model training. MCP-Flow consists of two major components:  server discovery and data synthesis, and the data synthesis pipeline comprises two main stages: data generation and data filtration.\n\nExperimental results demonstrate that agents fine-tuned with MCP-Flow significantly outperform baseline models in tool selection, function call accuracy, and overall task success."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper tackles a highly practical problem — enabling LLMs to effectively operate within the rapidly expanding MCP ecosystem of real-world tools.\n\n- The proposed dataset provides valuable large-scale resources for the research community, covering 1k+ MCP servers, 11k+ tools, and 68k instruction–function call pairs."}, "weaknesses": {"value": "- Diversity metrics rely on embedding cosine distances and LLM-based judge scores, but no human annotator agreement is reported.\nIncorporating even a small-scale human evaluation would strengthen the claim that the synthetic data aligns with human quality judgments.\n\n- The paper does not sufficiently discuss how the dataset handles multi-turn interactions, which are essential for realistic agentic tasks.\n\n- The introduction section could be improved for smoother narrative flow — some transitions between motivation and methodology are slightly disjointed."}, "questions": {"value": "- Is there any human verification or manual validation involved during Server Discovery stage?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JCvzJ3g4a6", "forum": "ygSTMCq1YY", "replyto": "ygSTMCq1YY", "signatures": ["ICLR.cc/2026/Conference/Submission9547/Reviewer_4k2X"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9547/Reviewer_4k2X"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9547/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761798751514, "cdate": 1761798751514, "tmdate": 1762921107131, "mdate": 1762921107131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses limitations in LLMs’ utilization of the MCP ecosystem, small server coverage, costly manual curation, and lack of training support. It introduces MCP-Flow, an automated web-agent-driven pipeline for large-scale MCP server discovery, data synthesis, and model training. MCP-Flow collects data from 1,166 servers and 11,536 tools across 6 marketplaces, generating 68,733 high-quality instruction-function call pairs and 6,439 trajectories. It includes two key components: web-agent-based server crawling (with deduplication and local deployment) and scalable data synthesis (few-shot generation, slot-fill revision, WizardLM evolution, and rigorous filtration). Experiments show MCP-Flow outperforms SOTA LLMs (e.g., GPT-4o, Claude-4-Sonnet) in MCP tool selection/formatting (even with small models like Qwen3-0.6B), enhances closed models via retrieval augmentation, and improves agent performance on the GAIA benchmark while reducing costs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper constructs a large-scale MCP dataset with broad coverage, including 1,166 servers, 11,536 tools, 68,733 instruction-function call pairs, and 6,439 trajectories—far exceeding the scale of existing MCP-related works and truly reflecting the complexity of the real-world MCP ecosystem.\n2. This paper proposes a web-agent-driven automated pipeline for server discovery and data synthesis, eliminating costly manual curation. The pipeline supports incremental updates for new servers, adapting to the rapid evolution of the MCP ecosystem while reducing time and computational costs."}, "weaknesses": {"value": "1. Limited analysis of tool quality variance and standardized MCP server evaluation.\n2. More OOD evaluation is needed, eg. MLE-Bench."}, "questions": {"value": "As shown in the Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NO59PtKz5t", "forum": "ygSTMCq1YY", "replyto": "ygSTMCq1YY", "signatures": ["ICLR.cc/2026/Conference/Submission9547/Reviewer_xeKy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9547/Reviewer_xeKy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9547/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987251652, "cdate": 1761987251652, "tmdate": 1762921106816, "mdate": 1762921106816, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a data synthesis framework for multiple MCP tools. The authors collect a variety of real MCP tools from the official MCP server and construct a tool graph to represent their relationships. By sampling candidate tools from this graph, the method leverages an LLM to synthesize instruction–response trajectories. A combination of rule-based and LLM-based filtering is then applied to refine the generated data. The final dataset is released together with the code, aiming to facilitate further research in multi-tool data synthesis."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and clearly organized, with professional presentation and figures.\n2. The release of code and data is commendable, as it provides valuable resources for the community and may stimulate further research in MCP-related data generation and tool-use modeling."}, "weaknesses": {"value": "1. The contribution appears somewhat incremental, resembling an extension of ToolACE that integrates the MCP server into a similar data synthesis pipeline. The paper would benefit from a clearer articulation of its unique insights or methodological advances beyond existing frameworks.\n\n2. In Section 3.1, the authors describe the MCP tool collection process. However, MCP tools are continuously updated or deprecated on the server. The paper does not discuss how such versioning and temporal drift are handled during data collection and maintenance, which raises concerns about dataset reproducibility.\n\n3. During instruction synthesis, the method focuses solely on problems that explicitly require tool usage. Real-world interactions, however, often involve queries solvable without tools. Ignoring such cases may bias the dataset and limit the model's ability to decide when not to call a tool.\n\n4. The current synthesis process appears restricted to single-step tool calls. It does not consider multi-round dependencies, such as inter-tool data flow or user clarification when parameters are missing. These aspects are essential for building realistic multi-turn tool-use data.\n\n5. Experiments are only conducted on the self-synthesized dataset. To validate generalization and robustness, the model trained on this dataset should be evaluated on existing public tool-use benchmarks, demonstrating transferability to unseen tools and domains.\n\n6. The paper would be improved by analyzing the domain coverage of the synthesized dataset (e.g., tool types, functional categories).\n\n7. No ablation studies are provided to quantify the impact of important components such as the tool-graph construction and filtering strategies. A systematic analysis of these steps would strengthen the empirical evidence for the proposed design choices."}, "questions": {"value": "Please refer to the weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RCcPwZMNXg", "forum": "ygSTMCq1YY", "replyto": "ygSTMCq1YY", "signatures": ["ICLR.cc/2026/Conference/Submission9547/Reviewer_wn4G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9547/Reviewer_wn4G"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9547/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992195378, "cdate": 1761992195378, "tmdate": 1762921106314, "mdate": 1762921106314, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}