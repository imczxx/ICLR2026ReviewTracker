{"id": "Y8oiuzaAxl", "number": 15662, "cdate": 1758253679150, "mdate": 1759897290479, "content": {"title": "Towards a Theoretical Understanding of In-context Learning: Stability and Non-I.I.D Generalisation", "abstract": "In-context learning (ICL) has demonstrated significant performance improvements in transformer-based large models. This study identifies two key factors influencing ICL generalisation under complex non-i.i.d. scenario: algorithmic stability and distributional discrepancy. First, we establish a stability bound for transformer-based models trained with mini-batch gradient descent, revealing how specific optimization configurations interact with the smoothness of the loss landscape to ensure the stability of non-linear Transformers. Next, we introduce a distribution-level discrepancy measure that highlights the importance of aligning the ICL prompt distribution with the training data distribution to achieve effective generalisation. Building on these insights, we derive a generalisation error bound for ICL with asymptotic convergence guarantees, which further reveals that token-wise prediction errors accumulate over time and even lead to generalisation collapse if the prediction length is not properly constrained. Finally, empirical evaluations are provided to validate our theoretical findings.", "tldr": "This paper establishes generalisation bounds for Transformer-based models in in-context learning under non-i.i.d. scenarios.", "keywords": ["In-context Learning", "Generalisation Error"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8eaff4dc01b00ef84e76123cc63039f35ad20653.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper studies the ICL generalization of Transformers by characterizing the algorithmic stability and distributional discrepancy. The authors especially establish comprehensive discussion in different scenarios, including smooth or non-smooth loss functions, and i.i.d. or non-i.i.d. data. Some experiments are conducted for supporting the theory."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The theoretical analysis is impressive and looks solid. \n\n2. The discussion is comprehensive enough to cover many cases."}, "weaknesses": {"value": "1. The practical insight of the analysis is unclear. I am not sure how the proposed results can be used to explain any phenomenon or improve performance. This makes this work less interesting to me. \n\n2. This paper mainly focuses on Transformers with multiple heads and multiple layers. However, it is not clear how the number of heads and layers affects the theoretical results. I don't know whether the derived bounds are tight and can be quantitatively verified by experiments. It is also not clear how and why the results and the analysis of Transformers differ from non-Transformer models. Therefore, I cannot specifically evaluate the novelty of the analysis.\n\n3. The message from Section 4.1 is quite awkward. It combines both a brief introduction of the theoretical results and the main proof technique. However, a proof sketch should introduce the logic chain of establishing the proof rather than only mentioning the theoretical tools used in the proof."}, "questions": {"value": "1. I don't quite get the discussion of Figure 2 (b). I cannot see why the generalization error increases following a \"logarithmic\" trend with sequence length. \n\n2. It seems experiments in Section I are more interesting to justify the theoretical results. Why not put them in the main body?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kY849nY0WJ", "forum": "Y8oiuzaAxl", "replyto": "Y8oiuzaAxl", "signatures": ["ICLR.cc/2026/Conference/Submission15662/Reviewer_rUZ4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15662/Reviewer_rUZ4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15662/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761514337216, "cdate": 1761514337216, "tmdate": 1762925919447, "mdate": 1762925919447, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper derives generalization guarantees for non-linear multi-layer/multi-head Transformers under ICL, by coupling mini-batch-GD-dependent uniform stability with a hypothesis-space-independent discrepancy measure; the bounds highlight (i) optimization- and smoothness-aware choices of step-size/batch/iterations, (ii) the need to align prompt distributions between training and inference, and (iii) error accumulation across generated tokens implying an at-most logarithmic growth of prediction length for reliable generalization, corroborated by experiments."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The theoretical results are seemingly sound and cover both smooth and non-smooth regimes."}, "weaknesses": {"value": "* The definitions of $\\zeta_1$ and $ \\zeta_2 $ are missing or unclear around lines 295–305. Please specify them explicitly for completeness.\n\n* It is counter-intuitive that the non-smooth counterpart allows ( Q ) to be exponentially smaller than that in the smooth case (Corollary 2 vs. Corollary 1). The theoretical intuition behind this discrepancy should be clarified.\n\n* The claim in lines 300–302 remains vague without quantitative support. A more formal analysis is needed to characterize the continuous Pareto frontier of the purported trade-off.\n\n* The manuscript does not clearly explain why small-batch SGD achieves better generalization than its large-batch counterpart. A brief theoretical sketch in the proposed framework would strengthen the argument. Similarly, the Remarks section could more clearly outline how the asymptotic behaviors arise from the assumed settings, rather than only restating theorems.\n\n* (Relatively minor point) Experiments on realistic datasets would make the findings more convincing and demonstrate the applicability of the theory."}, "questions": {"value": "It would be good to include the discussions of arXiv:2508.09820 and arXiv:2411.02199, which consider generalization analysis over non-orthogonal data."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PMAvKcXfJk", "forum": "Y8oiuzaAxl", "replyto": "Y8oiuzaAxl", "signatures": ["ICLR.cc/2026/Conference/Submission15662/Reviewer_bLpF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15662/Reviewer_bLpF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15662/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761655559419, "cdate": 1761655559419, "tmdate": 1762925918769, "mdate": 1762925918769, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper develops a theoretical framework for understanding the generalisation behavior of in-context learning (ICL) in Transformers under non-i.i.d. settings. The authors derive a generalisation error bound for the algorithmic stability and distributional discrepancy measure and conduct empirical evaluations to validate their theoretical findings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper studies an interesting and important question regarding the stability and non-i.i.d. generalization of in-context learning (ICL), and it may offer valuable practical insights.\n\n2. According to Table 1, this work considers more general and realistic settings compared to prior theoretical studies.\n\n3. The paper is well-presented, featuring clear illustrative figures, concise proof sketches, and well-organized comparisons with related works (e.g., Table 1)."}, "weaknesses": {"value": "1. The experiments are purely synthetic and do not include realistic NLP or multimodal datasets. This limits practical impact.\n\n2. Boundedness and Lipschitz smoothness may not hold for real Transformer loss landscapes; discussion of how these assumptions approximate practice would help.\n\n3. It seems that these assumptions (boundedness and Lipschitz smoothness) are very general and could apply to any neural network architectures or tasks. Therefore, it is unclear whether the theoretical results in this paper truly provide any insights that are specific to the Transformer architecture or the in-context learning (ICL) problem."}, "questions": {"value": "1. Could the authors include more realistic ICL tasks in the experiments to better support and validate their theoretical claims?\n2. Could the authors provide a more detailed discussion on the practicality and justification of the boundedness and Lipschitz smoothness assumptions in real-world settings?\n3. These assumptions (boundedness and Lipschitz smoothness) appear to be quite general and could potentially apply to many neural network architectures or tasks. Do the theoretical results in this paper offer insights that are specific to the Transformer architecture or the ICL problem in particular?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qOK6PgZUDZ", "forum": "Y8oiuzaAxl", "replyto": "Y8oiuzaAxl", "signatures": ["ICLR.cc/2026/Conference/Submission15662/Reviewer_gCrj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15662/Reviewer_gCrj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15662/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959221851, "cdate": 1761959221851, "tmdate": 1762925918036, "mdate": 1762925918036, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, generalization of in-context learning is studied using the tools of algorithmic stability. First a stability bound for transformer based architecture is derived, and then such a stability bound is coupled with discrepancy measure and provides the generalization guarantees for i.i.d sequences and non i.i.d sequences. Empirical investigation on synthetic tasks are provided to support the theory."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles an important question of generalization of language models and proposes a general framework and approach for generalization bound for incontext learning using algorithmic stability and discrepancy measure. The flexible approach can also handel non i.i.d data scenario's with discrepancy measure and is interesting."}, "weaknesses": {"value": "A following things limit the applicability or significance of the result. \n\ni) A key limitation of the paper is that its results lack clear interpretability, and the novelty of the proposed approach is not effectively communicated to the reader. The work would be significantly strengthened by presenting a concrete example, such as one involving in-context learning. This would provide a practical scenario where the derived generalization bounds are tangible and make intuitive sense, helping to ground the paper's theoretical contribution \n\nii) What is the specificity of the result to incontext learning or transformer architecture ?\n\niii) The exteme dependence on  the iteration number, the stability becomes worse and worse with the  number of iterations (Q) and it is sometimes logarithmic in the Q meaning the result is not applicable for a single pass over the data."}, "questions": {"value": "i) In the context of Theorem 2, do you give an example of scenario when $\\beta \\| q\\|_2 N \\to 0$ ?\n\nii) In table 2, the paper presents the convergence rate, does it not take into account the convergence of training loss ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "E8EZNHs5TH", "forum": "Y8oiuzaAxl", "replyto": "Y8oiuzaAxl", "signatures": ["ICLR.cc/2026/Conference/Submission15662/Reviewer_J7sq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15662/Reviewer_J7sq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15662/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762170075927, "cdate": 1762170075927, "tmdate": 1762925917637, "mdate": 1762925917637, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}