{"id": "p1nNATFKRm", "number": 21597, "cdate": 1758319462391, "mdate": 1759896913181, "content": {"title": "Continuous Symmetry Discovery and Enforcement for Image Data", "abstract": "Symmetry is an often-desired quality of machine learning models, leading, among other things, to more predictable model generalization. Continuous symmetry detection and enforcement for machine learning are two related topics that have recently been explored using the Lie derivative along vectors fields, which vector field approach has led to improved outcomes. However, though image data is replete with continuous symmetries under which image classifiers are meant to be invariant, the application of the Lie derivative for the detection and enforcement of continuous symmetries for image data remains under-explored. In this work, we derive vector field infinitesimal generators for various continuous symmetries for image data. We then use these generators to enforce continuous symmetry in image classifiers. We also demonstrate vector field symmetry detection in image data, obtaining close similarity with the ground truth symmetry.", "tldr": "In this paper, we enforce continuous symmetry in image classification, and we discover continuous symmetry from training image data.", "keywords": ["Image Processing", "Image Classification", "Symmetry", "Infinitesimal Generators", "Invariance", "Group Actions", "Symmetry Discovery", "Symmetry Enforcement"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c0969e197974f6726532543dc5713679f8b8b956.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper discusses several potential issues in discovering and enforcing continuous symmetries for image data, including algebraic nonclosure and other violations of algebraic constraints from the discovered infinitesimal generators, the exponential growth of the number of transformations required for data augmentation with respect to non-Abelian symmetry groups, etc. The experiments evaluate some relevant methods, such as regularization and data augmentation for the power law symmetry in MNIST, and a preliminary result of symmetry discovery by inspecting the gradient of a trained predictor and finding its orthogonal vector field."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper reviews and discusses some important related works in symmetry discovery and enforcement, particularly for image data. A detailed background section is provided for vector fields as infinitesimal generators of continuous symmetry, so readers with relatively little experience in this field can understand the subject easily."}, "weaknesses": {"value": "This paper, in my opinion, is mostly a review of existing methods. The contributions, if any, are very unclear. To see this, the related work section spans up to four pages, and even in the methodology section, Sec 3.1 and 3.2 are still restatements from existing work. The **contribution** paragraph at the end of Sec 1 states that the paper \"provides a mathematical framework for the extension of continuous symmetry discovery and enforcement for image data\", but no such framework is clearly presented in the current paper. Also, the paper is titled \"... for image data\", but most of the contents do not specify what is special about the symmetry in image data. Also, there is no explanation why existing methods would not work on image data. In fact, a lot of related work, whether mentioned in this paper or not, already showed results of symmetry discovery on image datasets as parts of their experiments.\n\nFrom the narrative of the paper, Sec 3.3 and 3.4 is supposed to introduce some new methods for symmetry enforcement and discovery. However, I regret not finding any valuable new insights. For multi-parameter symmetry groups, stacking the tensors from multiple generators is a standard and straightforward technique which is already used in past works [1, 2]. For data augmentation w.r.t non-Abelian groups, I agree that augmenting with parameters on a fixed grid can result in at most combinatorial and exponential sample complexity. However, a simple yet effective alternative approach would be to randomly sample the group parameters. Finally, Sec 3.4 is titled \"symmetry discovery\", but the content of the subsection focuses elsewhere and has not clearly described any method for symmetry discovery.\n\nApart from the previously mentioned ones, there are other important missing references in this paper. For symmetry discovery, LieGG [3] trains a predictor and solves the symmetry of the predictor algebraically; LaLiGAN [4] parameterizes vector field symmetry by a composition of an autoencoder and a linear action. These are closely related to the subject of this paper and should be discussed and possibly compared against in the experiments.\n\n### References\n\n[1] Symmetry-Informed Governing Equation Discovery. NeurIPS, 2024.\n\n[2] Symmetry Discovery for Different Data Types. Neural Networks, 2025.\n\n[3] Liegg: Studying Learned Lie Group Generators. NeurIPS, 2022.\n\n[4] Latent Space Symmetry Discovery. ICML, 2024."}, "questions": {"value": "none"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "j6wcoxbWi8", "forum": "p1nNATFKRm", "replyto": "p1nNATFKRm", "signatures": ["ICLR.cc/2026/Conference/Submission21597/Reviewer_SbJc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21597/Reviewer_SbJc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760984178747, "cdate": 1760984178747, "tmdate": 1762941849070, "mdate": 1762941849070, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper extends Lie‑derivative methods to image data by deriving infinitesimal generators for transformations and using them for　symmetry regularization and discovery. The framework covers non‑invertible semigroup transforms such as Gaussian blur and supports multi‑parameter, non‑commuting combinations. Experiments on MNIST and ImageNet show that regularization can improve robustness and sometimes approach or improve over unregularized baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "S1. The generator‑based formulation is interesting and applies even to non‑invertible semigroup transforms like Gaussian blur, widening applicability. It is also appealing that combinations of non‑commuting transformations can be handled efficiently through the multi‑parameter setup.\n\nS2. The background and preliminaries are clearly written, making the paper accessible to readers without a deep prior in differential geometry or Lie theory."}, "weaknesses": {"value": "W1. The empirical improvements are modest. In Table 1, augmentation outperforms regularization in all reported settings, and in Table 2 regularization beats augmentation in only two of five settings. Other metrics beyond accuracy, such as training efficiency or compute overhead, are not evaluated.\n\nW2. In the more realistic ImageNet experiment (Section 4.1.3), results are not compared against an augmentation baseline, so the practical significance of the method is unclear.\n\nW3. The method relies heavily on prior vector‑field symmetry work (e.g. Shaw et al., 2025); the paper’s distinct technical contribution appears concentrated in Sections 3.3 and 3.4 and may not be substantial enough as currently presented."}, "questions": {"value": "Q1. In Table 1, why does Reg+Aug underperform Aug alone? A simple intuitive explanation would help.\n\nQ2. Can replacing augmentation with regularization reduce the amount of labeled data needed to reach a target accuracy (sample efficiency)?\n\nQ3. Do you have results when combining several non‑commuting transformations in the same run, rather than one at a time?\n\nQ4. Section 4.2 uses synthetically applied transformations. Can you demonstrate discovery on real data where such transformations occur naturally?\n\nMinor comments\n- Line 247: “Section 2.4” appears to be a typo for “Section 3.3”.\n- Section 3.4 is text‑only and difficult to follow; a pseudocode or algorithm box would improve clarity."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P0mayFQJYI", "forum": "p1nNATFKRm", "replyto": "p1nNATFKRm", "signatures": ["ICLR.cc/2026/Conference/Submission21597/Reviewer_sigs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21597/Reviewer_sigs"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761619112452, "cdate": 1761619112452, "tmdate": 1762941848809, "mdate": 1762941848809, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Our specialization to image transformations is not a trivial contribution"}, "comment": {"value": "Our first general comment relates to the large efficiency gains from our methodology. The suggestion to compare with LieGAN, LieGG, and related methods, coupled with the notion that our contribution offers only a limited improvement to (Shaw et al., 2024 \\& 2025) indicates that our paper, as currently written, does not explain the issue at hand explicitly enough. And so, we consider the task of detecting Gaussian blur for MNIST images anew. The Gaussian blur transformation is an affine transformation of the pixel values, since the pixel values are updated to become a linear combination of their neighbors, and so we may consider, in a thought experiment, other approaches. The matrix-based method of LieGAN would require matrices of an astounding size of $784\\times 784$ simply to parameterize the space of affine symmetries, on top of the computational overhead of matrix exponentiation, explicitly transforming the images, measuring divergences, and otherwise training a GAN. To put this number of parameters (over $600,000$) into perspective, that is an order of magnitude above the number of training points in the dataset, and closer to two orders of magnitude above the number of parameters in a typical classifier for this data. And the problem would be much worse if we considered ImageNet: the $224 \\times 224$ images yield matrix transformations having over 2.5 **billion** entries (not even considering separate RGB channels), which is $1-3$ orders of magnitude larger than the number of parameters needed to train an image classifier (and larger still than the number of training images). Even the method introduced in (Shaw et al., 2024 \\& 2025) cannot escape the large search space, despite cutting out much of the computational overhead employed by matrix-based approaches. Meanwhile, the experiment in our paper discovers this symmetry using a mere 49 parameters--learnable weights of a 7x7 kernel. The flexibility in how the components of the vector field infinitesimal generators can be specified allows us to restrict the initially-large search space of symmetries so that only image-specific transformations--such as those accomplished by means of convolutions--can be considered."}}, "id": "wFRFSHUc0R", "forum": "p1nNATFKRm", "replyto": "p1nNATFKRm", "signatures": ["ICLR.cc/2026/Conference/Submission21597/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21597/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21597/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763716034779, "cdate": 1763716034779, "tmdate": 1763716034779, "mdate": 1763716034779, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework for discovering and enforcing continuous symmetries in image data using the Lie derivative along vector fields. The key contribution is extending existing vector field-based symmetry methods (previously limited to affine transformations or tabular data) to common image transformations like power law correction and Gaussian blur. The authors derive infinitesimal generators (vector fields) for these transformations and show that symmetry can be enforced via regularization without data augmentation. They demonstrate: (1) symmetry enforcement via regularization achieves comparable performance to augmentation on MNIST and ImageNette, (2) the learned vector field generators can be discovered from augmented data with high accuracy (0.9998 cosine similarity for Gaussian blur), and (3) the approach scales to large models (ResNet50). The framework relies on diagonal group actions—where transformations act on each image channel or sample independently—and uses the model's gradient with respect to input images."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Clear problem motivation: The paper articulates well why vector field-based symmetry enforcement is desirable for image data—avoiding explicit augmentation and enabling use of discovered symmetries.\n\nMathematical framework: The extension from general vector field methods to diagonal group actions (Section 2.5) provides theoretical justification for the approach, and is easy to follow and also understand. The infinitesimal generators for power law and Gaussian blur transformations is interesting.\n\nMulti-parameter symmetry handling: Section 3.3 discusses practical considerations for multiple non-commuting transformations, noting that augmentation faces combinatorial explosion ($m!·n^m$ augmentations) while regularization scales linearly.\n\nThe ResNet50/ImageNette experiment (Section 4.1.3) demonstrates scalability beyond toy problems, showing 8.85% absolute accuracy improvement with regularization (47.87% vs 39.02%). The results demonstrate 0.9998 cosine similarity between learned and ground-truth Gaussian blur generator (Section 4.2) shows the discovery framework can work."}, "weaknesses": {"value": "Incomplete theoretical development: Diagonal action assumption not justified or validated empirically. No analysis of approximation error when generators are estimated (Gaussian blur is an \"estimate\").\n\nDataset limitations: Only MNIST (28×28, 1-channel, simple) and ImageNette (10 classes). No CIFAR-10/100, no full ImageNet, no other computer vision benchmarks.\n\nRegularization often underperforms augmentation: At extreme parameter values (Table 1: γ=0.1, Table 2: σ=6.0), regularization significantly worse than augmentation.\n\nDiscovery experiment limitations: Only demonstrates recovery of known transformation from explicitly augmented data. Only single transformation tested (Gaussian blur). No analysis of failure modes or limitations.\n\nThis only works for transformations with tractable infinitesimal generators. Unclear how to discover vs enforce symmetries. No analysis of memory requirements or GPU utilization.\n\nLimited novelty: The contribution is primarily applying existing vector field regularization methods to specific image transformations. The discovery experiment only shows recovery of known transformations from augmented data, not true discovery."}, "questions": {"value": "Diagonal action validation: Can you provide empirical evidence that the diagonal action assumption holds for your target transformations? Have you tested on transformations where channels are coupled (e.g., RGB to grayscale, color temperature shifts)?\n\nGenerator derivations: Can you provide the complete derivations for the power law and Gaussian blur infinitesimal generators? Why is the Gaussian blur generator an \"estimate\" rather than exact?\n\nWhen does regularization fail?: In Table 2, regularization dramatically underperforms at σ=6.0 (62.88% vs 89.98% for augmentation). Can you characterize when/why regularization fails? Is there a theoretical or empirical criterion?\n\nTheoretical guarantees: Under what conditions does minimizing the regularization loss (Eq. 14) guarantee that the model will be invariant to the transformation? Are there cases where regularization can fail even with perfect optimization?\n\nBaseline comparisons: LieGAN, Augerino can be usefule additions as baselines and this is missing.\n\nBeyond cosine similarity, how can you validate that discovered generators are correct? Visualize the flow they generate?\n\nHow does the method scale to higher resolution images (224×224×3 for ImageNet)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XX6VoqHlBH", "forum": "p1nNATFKRm", "replyto": "p1nNATFKRm", "signatures": ["ICLR.cc/2026/Conference/Submission21597/Reviewer_a4Zt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21597/Reviewer_a4Zt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761871260687, "cdate": 1761871260687, "tmdate": 1762941848509, "mdate": 1762941848509, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "An experiment with multiple symmetries"}, "comment": {"value": "In response to reviewers a4Zt and sigs, though for the benefit of each reviewer, we consider symmetry enforcement on MNIST using both Gaussian blur and the power law transform. Regularization, Augmentation, and the baseline are each trained for 10 epochs. For augmentation, Gaussian blur is applied before the power law transform, with $\\gamma \\in \\{ 0.25, 1.0 \\}$ and $\\sigma \\in \\{ 0.1, 3.0 \\}$. For regularization, $\\lambda = 0.2$ for the final 8 epochs (it begins as 0). Only one repetition is conducted for each method. Each method is evaluated twice (and has two tables): once for evaluating the power law transform before the Gaussian blur, another for switching that order.\n\nThese results show regularization dominating in the \"upper right\" section--that is, closer to the actual test data--while augmentation maintains more consistent scores throughout. Both methods uniformly outperform the baseline. While regularization and the baseline have lower scores for evaluating Gaussian blur first, the augmentation method flips this trend, probably owing to the fact that the data was augmented by first applying the Gaussian blur transformation before the power law transformation.\n\n**Regularization**\n\n| $\\gamma$, $\\sigma$   | $\\gamma = 0.1$ | $\\gamma = 0.2$ | $\\gamma = 0.25$ | $\\gamma = 0.5$ | $\\gamma = 1.0$ |\n|-----------|---------------------------|---------------------|---------------------|---------------------|---------------------|\n| $\\sigma = 0.1$ | $0.9012$ | $0.9662$ | $0.9693$ | $0.9716$ | $0.9718$ |\n| $\\sigma = 1.0$ | $0.8527$ | $0.9579$ | $0.9642$ | $0.9683$ | $0.9684$ |\n| $\\sigma = 2.0$ | $0.7869$ | $0.8907$ | $0.9227$ | $0.9445$ | $0.9469$ |\n| $\\sigma = 3.0$ | $0.7323$ | $0.8170$ | $0.8616$ | $0.9107$ | $0.9158$ |\n| $\\sigma = 6.0$ | $0.6797$ | $0.7743$ | $0.8016$ | $0.8699$ | $0.8777$ |\n\n| $\\sigma$, $\\gamma$   | $\\gamma = 0.1$ | $\\gamma = 0.2$ | $\\gamma = 0.25$ | $\\gamma = 0.5$ | $\\gamma = 1.0$ |\n|-----------|---------------------------|---------------------|---------------------|---------------------|---------------------|\n| $\\sigma = 0.1$ | $0.9012$ | $0.9662$ | $0.9693$ | $0.9716$ | $0.9718$ |\n| $\\sigma = 1.0$ | $0.7970$ | $0.9183$ | $0.9407$ | $0.9644$ | $0.9684$ |\n| $\\sigma = 2.0$ | $0.6070$ | $0.7374$ | $0.7854$ | $0.9200$ | $0.9469$ |\n| $\\sigma = 3.0$ | $0.5326$ | $0.6590$ | $0.7022$ | $0.8626$ | $0.9158$ |\n| $\\sigma = 6.0$ | $0.4869$ | $0.6027$ | $0.6411$ | $0.7989$ | $0.8777$ |\n\n**Augmentation**\n\n| $\\gamma$, $\\sigma$   | $\\gamma = 0.1$ | $\\gamma = 0.2$ | $\\gamma = 0.25$ | $\\gamma = 0.5$ | $\\gamma = 1.0$ |\n|-----------|---------------------------|---------------------|---------------------|---------------------|---------------------|\n| $\\sigma = 0.1$ | $0.9407$ | $0.9463$ | $0.9481$ | $0.9510$ | $0.9463$ |\n| $\\sigma = 1.0$ | $0.9299$ | $0.9417$ | $0.9455$ | $0.9490$ | $0.9459$ |\n| $\\sigma = 2.0$ | $0.8989$ | $0.9249$ | $0.9302$ | $0.9397$ | $0.9381$ |\n| $\\sigma = 3.0$ | $0.8768$ | $0.9110$ | $0.9202$ | $0.9306$ | $0.9298$ |\n| $\\sigma = 6.0$ | $0.8516$ | $0.8967$ | $0.9072$ | $0.9220$ | $0.9207$ |\n\n| $\\sigma$, $\\gamma$   | $\\gamma = 0.1$ | $\\gamma = 0.2$ | $\\gamma = 0.25$ | $\\gamma = 0.5$ | $\\gamma = 1.0$ |\n|-----------|---------------------------|---------------------|---------------------|---------------------|---------------------|\n| $\\sigma = 0.1$ | $0.9407$ | $0.9463$ | $0.9481$ | $0.9510$ | $0.9463$ |\n| $\\sigma = 1.0$ | $0.9446$ | $0.9501$ | $0.9516$ | $0.9533$ | $0.9459$ |\n| $\\sigma = 2.0$ | $0.9389$ | $0.9492$ | $0.9506$ | $0.9509$ | $0.9381$ |\n| $\\sigma = 3.0$ | $0.9288$ | $0.9435$ | $0.9468$ | $0.9479$ | $0.9298$ |\n| $\\sigma = 6.0$ | $0.9186$ | $0.9395$ | $0.9426$ | $0.9438$ | $0.9207$ |\n\n**Baseline**\n\n| $\\gamma$, $\\sigma$   | $\\gamma = 0.1$ | $\\gamma = 0.2$ | $\\gamma = 0.25$ | $\\gamma = 0.5$ | $\\gamma = 1.0$ |\n|-----------|---------------------------|---------------------|---------------------|---------------------|---------------------|\n| $\\sigma = 0.1$ | $0.7958$ | $0.8781$ | $0.8836$ | $0.8883$ | $0.8886$ |\n| $\\sigma = 1.0$ | $0.6796$ | $0.8641$ | $0.8731$ | $0.8836$ | $0.8855$ |\n| $\\sigma = 2.0$ | $0.4252$ | $0.7673$ | $0.8018$ | $0.8449$ | $0.8533$ |\n| $\\sigma = 3.0$ | $0.3864$ | $0.6929$ | $0.7382$ | $0.7980$ | $0.8106$ |\n| $\\sigma = 6.0$ | $0.3737$ | $0.6168$ | $0.6841$ | $0.7482$ | $0.7636$ |\n\n| $\\sigma$, $\\gamma$   | $\\gamma = 0.1$ | $\\gamma = 0.2$ | $\\gamma = 0.25$ | $\\gamma = 0.5$ | $\\gamma = 1.0$ |\n|-----------|---------------------------|---------------------|---------------------|---------------------|---------------------|\n| $\\sigma = 0.1$ | $0.7958$ | $0.8781$ | $0.8836$ | $0.8883$ | $0.8886$ |\n| $\\sigma = 1.0$ | $0.5542$ | $0.7908$ | $0.8254$ | $0.8726$ | $0.8855$ |\n| $\\sigma = 2.0$ | $0.3600$ | $0.5933$ | $0.6659$ | $0.7889$ | $0.8533$ |\n| $\\sigma = 3.0$ | $0.3368$ | $0.5107$ | $0.5778$ | $0.7382$ | $0.8106$ |\n| $\\sigma = 6.0$ | $0.3270$ | $0.4643$ | $0.5220$ | $0.6945$ | $0.7636$ |"}}, "id": "lpQ5Vwbos9", "forum": "p1nNATFKRm", "replyto": "p1nNATFKRm", "signatures": ["ICLR.cc/2026/Conference/Submission21597/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21597/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21597/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763716144554, "cdate": 1763716144554, "tmdate": 1763716144554, "mdate": 1763716144554, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper adapts the flow regularization method for enforcing symmetries, introduced in Shaw et al 2024, to images. The idea is to enforce continuous symmetries by requiring that their infinitesimal action preserves the loss. \nThey adapt this idea to images by assuming a \"diagonal action\" which means it acts on each image channel separately, or in image data, say it acts on each image independently. \n\nThey test their regularizer on predefined flows, such as gamma correction and gaussian blur on MNIST and ImegeNette. The results are a bit mixed. gamma correction seems to work, but for Gaussian blur their method seems to perform worse."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. Enforcing continuous symmetries using infinitesimal generators is in principle a good idea and can make them tractable.  \n2. Using their method for symmetry discovery, they recover the ground truth generator for gaussian blur.\n3. some experimental results on gamma correction in MNISt seem good."}, "weaknesses": {"value": "1. Most of the theory is almost verbatim repetition of Shaw 2024, 2025. \n2. The contribution seems to be adapting an existing method to images, but in a very limited way. The diagonal action seems quite restrictive to me and only captures a very small class of symmetries in images. Importantly, it shouldn't be able to handle spatial or steerable symmetries (right?).   \n3. Experiments are limited. The baseline should have included at least LieGG (Moskalev Neurips 2022), which also uses infinitesimal symmetry regularization, and LieGAN for the symmetry discovery part. \n4. Some experimental results, like gaussian blur on MNIST, Table 2, seem to show regularization actually hurts at high noise levels, and dramatically worse than baseline or augmentation. And this is not even symmetry discovery, rather a know symmetry where augmentation is actually possible. If your argument is augmentation would be expensive or must be done many times, this table isn't showing that."}, "questions": {"value": "1. What are the distinguishing theoretical contributions of this work compared to Shaw 2024? \n2. Table 2: the fact that your method leads to worse results at high noise, is you method somehow not mixing neighboring pixel data enough? Are you kernels too small? Are they 7x7? That seems quite big."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cu7CJmOJCu", "forum": "p1nNATFKRm", "replyto": "p1nNATFKRm", "signatures": ["ICLR.cc/2026/Conference/Submission21597/Reviewer_V48H"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21597/Reviewer_V48H"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762055623550, "cdate": 1762055623550, "tmdate": 1762941848208, "mdate": 1762941848208, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}