{"id": "WnYPeKNPhM", "number": 22976, "cdate": 1758337723441, "mdate": 1759896837881, "content": {"title": "An Explainable 3D Convolutional Neural Network with Reliable Feature Selection and Hybrid 3D Image Block Ranking", "abstract": "An explainable 3D imaging challenge is effectively interpreting the rational relationship among top-ranked 3D image blocks, relevant features selected from extracted 3D feature maps, and decisions of a 3D convolutional neural network (CNN). We propose an explainable 3D CNN that integrates a robust feature selection (FS) method with a new hybrid block ranking algorithm to uncover the spatial relationship among 3D image blocks, selected features, and clinical diagnosis. The 3D image block ranking pipeline begins with a multi-FS procedure that removes irrelevant features that are out of an object and produces diverse selected feature sets. Then the selected feature sets are used to construct complementary 3D distribution, ranking, and average-ranking feature matrices that quantify importance levels for both relevant 3D image blocks and decisions. Finally, the novel hybrid 3D image block ranking algorithm leverages the complementary 3D feature matrices to reliably generate a block ranking map (BRM) with 3D block ranking numbers. Simulation results using 982 3D ADNI data for Alzheimer’s disease (AD) diagnosis (3-class classification) indicate that the top-ranked 3D image blocks contain brain areas associated with AD diagnosis for two different simulations using overlapping neighboring and non-overlapping neighboring 3D image blocks. A medical doctor may conveniently use the BRM’s top-ranked 3D image blocks of a patient’s 3D image visualized by axial 2D patches, coronal 2D patches, and sagittal 2D patches to efficiently make an explainable and correct medical diagnosis. Importantly, the new 3D CNN with FS is better than the traditional 3D CNN without FS in terms of test accuracy, F1-score, AUC, and model size for both AD diagnosis and autism diagnosis (binary classification). Thus, the new 3D CNN with the reliable FS and the hybrid 3D image block ranking is more effective than the traditional 3D CNN for explainable, accurate, and memory-efficient 3D image classification applications.", "tldr": "", "keywords": ["computer vision; convolutional neural networks; feature selection; explainability; hybrid; image classification"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d902908f3022171fc933acabd8673328e7b09724.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes an explainable 3D convolutional neural network (3D-CNN) framework for the diagnosis of Parkinson’s Disease (PD) using T1-weighted structural MRI. The authors aim to improve both classification performance and interpretability of deep learning models in neuroimaging-based PD diagnosis. The authors report improved classification accuracy and demonstrate that the attention maps produced by the model correspond to clinically relevant brain regions such as the basal ganglia and substantia nigra."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The integration of explainable methods (Grad-CAM) provides interpretability, which is essential for medical deployment.\n- Using full 3D convolution allows the model to capture spatial dependencies lost in 2D slice-based approaches."}, "weaknesses": {"value": "- The abstract and introduction overly emphasize procedural details but fail to clearly articulate the main methodological contributions and novel insights.\n- The technical contribution is limited. The 3D-CNN design and Grad-CAM integration are both standard in existing neuroimaging literature.\n- The study appears to use only the PPMI dataset without external validation, limiting generalizability.\n- The paper does not compare against modern explainable architectures or graph-based neuroimaging models."}, "questions": {"value": "- How stable are the Grad-CAM heatmaps across folds or random seeds?\n- How does the proposed model compare with self-supervised or transformer-based MRI encoders?\n- Are the activation regions consistent with clinical evidence from PD pathology studies?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "x0qyujIm4p", "forum": "WnYPeKNPhM", "replyto": "WnYPeKNPhM", "signatures": ["ICLR.cc/2026/Conference/Submission22976/Reviewer_NDVi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22976/Reviewer_NDVi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22976/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761332859056, "cdate": 1761332859056, "tmdate": 1762942461132, "mdate": 1762942461132, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a method for creating an explainable 3D CNN by integrating feature selection (FS) with a hybrid 3D image block ranking algorithm. The core idea of linking feature importance back to specific 3D image blocks for medical diagnosis is commendable and has significant potential for clinical interpretability. The application to Alzheimer's Disease (AD) and autism diagnosis is relevant and important. However, the paper in its current form suffers from several critical weaknesses that preclude its acceptance. The most severe issues relate to the validation of the proposed method's \"explainability\" and the experimental setup, which raise substantial doubts about the claims made."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The integration of a dedicated FS layer and a multi-step hybrid algorithm for ranking 3D image blocks is a novel contribution to the field of explainable AI (XAI) for 3D imaging. The attempt to move beyond 2D heatmaps to a 3D block-based importance measure is a step in the right direction.\n2. The focus on medical imaging, specifically AD and autism diagnosis, addresses a pressing need for interpretable deep learning models in healthcare. The method's output (Block Ranking Map - BRM) is designed to be clinician-friendly, which is a significant practical strength."}, "weaknesses": {"value": "1. The paper's central claim is \"explainability,\" but this is not validated in a meaningful way. The primary validation method is a post-hoc literature search: top-ranked blocks are identified, and then references are cited to show that the brain areas within those blocks are \"associated with AD diagnosis\". This is circular reasoning and does not prove that the model learned these associations.\n2. Incomplete and Potentially Biased Feature Selection Process:​​ The first step of Algorithm 1  eliminates features not associated with \"a rational image region defined by an expert.\" The rules for this elimination  appear to be manually defined based on average brain images. This process is highly subjective and risks introducing a strong confirmation bias. The model is effectively prevented from looking outside the pre-defined \"rational\" regions, which may ignore potentially novel or counter-intuitive biomarkers. This undermines the objective nature of the feature selection and the subsequent explainability claims.\n3. The description of the methods, particularly the algorithms, is dense and difficult to follow."}, "questions": {"value": "1. Explainability Validation:​​ Beyond correlating your results with existing literature, what concrete experiments can be conducted to provethat the top-ranked blocks are truly important for your model's decision? For example, have you considered performing an ablation study where you set the voxel values in the top-K ranked blocks to zero and measuring the change in prediction confidence?\n2. ​Feature Selection Bias:​​ Could you elaborate on the process of defining the \"rational image region\" for the initial feature pruning? How can you ensure that this manual step does not discard features that might be genuinely informative but located in areas not traditionally associated with the disease? Would the method work without this step?\n3.Algorithmic Complexity:​​ The hybrid ranking algorithm involves many parameters (number of FS methods, feature set sizes, weights w_h). Was any hyperparameter optimization performed? Can you show that the full hybrid approach is significantly better than a baseline that uses a single, strong FS method (like RFE) and ranks blocks simply by the count of selected features (a_ijkfrom matrix A)?\n4.Comparison to Baselines:​​ How does the explanatory power of your BRM compare to applying a standard explanation method like Grad-CAM directly to the feature maps of your 3D CNN? A qualitative comparison of the saliency maps would be very informative."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "nCl9DCrUse", "forum": "WnYPeKNPhM", "replyto": "WnYPeKNPhM", "signatures": ["ICLR.cc/2026/Conference/Submission22976/Reviewer_Bywb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22976/Reviewer_Bywb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22976/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791002816, "cdate": 1761791002816, "tmdate": 1762942460678, "mdate": 1762942460678, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents an explainable 3D CNN integrating robust FS and a hybrid 3D image block ranking algorithm to address the challenge of interpreting relationships among top-ranked 3D image blocks, selected features, and model decisions. The evaluation of the model is performed on 3D brain MRI scans from the ADNI dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The proposed framework involves:\n\n* Multi-FS Procedure: eliminates irrelevant features and generates diverse feature sets.\n* Informative 3D feature matrices: constructs complementary matrices to quantify block/feature importance.\n* hybrid block ranking algorithm: leverages these matrices to generate a block ranking map with 3D block rankings, enabling spatial interpretation."}, "weaknesses": {"value": "* The structure of the experiment section is difficult to follow. It does not clearly present a comparison with traditional 3D FS methods. For instance, which baseline methods were included? Revising the layout or presenting the results in a three-line table could make this section more intuitive and concise.\n\n* While the study primarily validates the model on ADNI data for Alzheimer's disease and shows promise in assisting physicians to identify promising candidates, further experimentation on more diverse datasets is needed to enhance its generalizability."}, "questions": {"value": "* the traditional 3D CNN without FS is used as a baseline, but comparisons to state-of-the-art explainable 3D models (Grad-CAM for 3D, attention-based methods) are missing, It is unclear if the proposed approach outperforms existing interpretable alternatives.\n\n* cPlease clarify the logical progression of the innovations in Section 3.2. Specifically, explain how they collectively form a cohesive, step-by-step framework that culminates in the Hybrid 3D Image Block Ranking Algorithm presented in Section 4."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "89CsJOrksc", "forum": "WnYPeKNPhM", "replyto": "WnYPeKNPhM", "signatures": ["ICLR.cc/2026/Conference/Submission22976/Reviewer_pVND"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22976/Reviewer_pVND"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22976/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879114660, "cdate": 1761879114660, "tmdate": 1762942460350, "mdate": 1762942460350, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an explainable framework for 3D CNNs, combining a robust feature selection (FS) method and a new hybrid 3D image block ranking algorithm. It first uses a multi-step FS algorithm (Algorithm 1) to remove \"irrelevant features\" (e.g., outside the brain) and generate feature subsets. Then three 3D feature matrices (distribution, ranking, average-ranking) quantify feature importance, and a hybrid algorithm (Algorithm 2) uses them to create a \"Block Ranking Map\" (BRM) for spatial explainability. Key contributions: (1) Multi-FS and hybrid algorithms. (2) BRM correlates with AD-relevant anatomy. (3) 3D CNN with FS outperforms traditional ones in accuracy, F1-score, AUC and memory. (4) Validation on ADNI (3-class AD) and autism datasets."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-structured, clearly outlining the problem (3D CNN explainability), the proposed solution (FS Layer + Hybrid Ranking), technical details (Sections 3, 4), and experimental validation (Sections 5, 6)."}, "weaknesses": {"value": "$$Technical:$$\n\n1. The paper repeatedly refers to a new \"FS Layer\". However, based on the descriptions in Algorithm 1, 2, and Section 5.1, the feature selection (FS) appears to be a post-hoc process performed offline on features extracted from a pre-trained 3D CNN. This process (esp. Alg 1, Step 1) uses the entire training dataset and expert knowledge (average brain images ). This is not a \"layer\" in the sense of an end-to-end trainable component. This ambiguity confuses post-hoc explanation with an intrinsically explainable model.\n\n2. Step 1 of Algorithm 1, which is critical to the method's success (removing ~70% of features ), relies on an \"expert-defined\" region created by averaging the training set images. This raises two concerns: (a) Does this hard feature elimination risk overfitting to the training data's specific morphology? (b) For 3D images without a clear \"object of interest\" (e.g., fluid dynamics), this first step would fail, limiting the method's generality.\n\n$$Experimental:$$\n\n3. The paper compares the \"3D CNN with FS\" to a \"3D CNN without FS\". However, the \"without FS\" baseline is a very simple 3D CNN (2 Conv3d layers) followed by an MLP that must handle 32,768 features. This architecture is highly susceptible to overfitting, and its poor performance (e.g., 0.614 Test Acc ) is unsurprising. A fairer, stronger baseline would apply strong regularization (e.g., Dropout) to the MLP when processing all 32k features.\n\n4. As an XAI paper, it is a major omission to not compare the proposed BRM against any existing 3D XAI method (e.g., 3D Grad-CAM, 3D Guided Backpropagation, 3D LIME/SHAP). The paper claims its method is superior but provides no experimental evidence to support this.\n\n5. Evaluation is limited to ADNI and one autism dataset. Testing on other 3D medical domains (e.g., lung CT, cardiac MRI) would better demonstrate generalizability.\n\n$$Writing:$$\n\n6. The core of Alg 2, the \"block ranking score\" θ, is defined as a weighted average. In both simulations, the weights are simply set to wh= 1/3. How are these weights chosen? Are they fixed? Tuned? The choice of weights is critical to the final ranking, and this is not discussed.\n\n7. The paper mentions resizing ADNI images from various sizes (e.g., 192* 192 *160) down to 64 * 64*64. This is an aggressive downsampling that will severely distort anatomical structures and lose key information, which likely contributes to the very low baseline accuracy. This decision needs to be justified in detail\n\n8. The “ebrains” tool is mentioned but not described in terms of accessibility or reproducibility."}, "questions": {"value": "$$Technical:$$\n\n1. The authors must clarify the exact implementation of the \"Feature Selection Layer\". Is this a layer that operates during training (e.g., a learnable gating layer)? If so, please provide details on its forward and backward propagation. If it is a post-hoc process applied after feature extraction, please revise the terminology throughout the paper (e.g., \"FS process\" or \"FS module\") to avoid confusion.\n\n2. How stable is the BRM ranking across different FS method combinations? Could you report Jaccard similarity or Kendall’s τ between top-k block lists from different FS runs?\n\n$$Experimental:$$\n\n3. To prove the superiority of the proposed \"CNN + FS\" model, the authors need to compare it against a stronger baseline. Please compare your model (e.g., MLP on 1000 features ) against an MLP baseline trained on all 32,768 features but which includes strong, optimized regularization (e.g., tuned Dropout rate and L2 penalty).\n\n$$Writing:$$\n\n4. Consider releasing BRM visualization code or pseudocode in the appendix."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ClaWeOaWoS", "forum": "WnYPeKNPhM", "replyto": "WnYPeKNPhM", "signatures": ["ICLR.cc/2026/Conference/Submission22976/Reviewer_oiGM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22976/Reviewer_oiGM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22976/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969020020, "cdate": 1761969020020, "tmdate": 1762942459873, "mdate": 1762942459873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}