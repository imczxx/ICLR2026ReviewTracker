{"id": "ixr5Pcabq7", "number": 15480, "cdate": 1758251754679, "mdate": 1763697967477, "content": {"title": "The Geometry of Reasoning: Flowing Logics in Representation Space", "abstract": "We study how large language models (LLMs) “think” through their representation space. \nWe propose a novel geometric framework that models an LLM’s reasoning as flows—embedding trajectories evolving where logic goes. \nWe disentangle logical structure from semantics by employing the same natural deduction propositions with varied semantic carriers, allowing us to test whether LLMs internalize logic beyond surface form. \nThis perspective connects reasoning with geometric quantities such as position, velocity, and curvature, enabling formal analysis in representation and concept spaces. \nOur theory establishes: (1) LLM reasoning corresponds to smooth flows in representation space, and (2) logical statements act as local controllers of these flows’ velocities. \nUsing learned representation proxies, we design controlled experiments to visualize and quantify reasoning flows, providing empirical validation of our theoretical framework. \nOur work serves as both a conceptual foundation and practical tools for studying reasoning phenomenon, offering a new lens for interpretability and formal analysis of LLMs' behavior.", "tldr": "", "keywords": ["Reasoning", "Theory", "Interpretability", "Representation", "Geometry", "Formal Logic", "LLMs"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3a6dc5704ad7a46b643577a7566f289fd722e0ed.pdf", "supplementary_material": "/attachment/a5a717e5dc2ca0dce746aa462152c926afbbc887.zip"}, "replies": [{"content": {"summary": {"value": "The paper analyzes “reasoning” in LLMs, particularly the reasoning flows (trajectories) in representation space. \nLogic is posited to act as a local controller of velocity along these flows, with Menger curvature used to capture second-order structure. \nThe authors construct a dataset that keeps formal logical skeletons fixed while varying topical and linguistic “carriers”, then extract hidden states from Qwen3/LLaMA3 to compare position, first-order/second-order differences and similarities. They report that while positions cluster by surface semantics, velocity/curvature similarities align by logic, supporting the claim that logic governs flow dynamics."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- An interesting work on reasoning, the authors view logic as a carrier-invariant framework for reasoning, and they test if LLMs have learned these structural invariants in their own embedding space.\n\n- Empirical comparisons across model sizes support qualitative claims.\n\n- Some interesting findings, for example, in the representation space, sentences on the same topic cluster together. However, when looking at the differences of curvature, logical structure emerges as the dominant factor even across unrelated topics and languages."}, "weaknesses": {"value": "- The paper is not easy to follow. Many key notions are introduced before being properly defined or motivated, which makes it difficult for readers outside the narrow intersection of geometry and logic to follow the argument. For example, the term “flow” appears early (Abstract, intro) for many times, but its formalization as a sequence of hidden states, or its mapping to logical entailment steps, is only explained several pages later (Sec. 4.2). Similarly, “menger curvature” is used as a core analytic measure before the geometric intuition or connection to reasoning trajectories is established. Also, it is often mentioned without details: what the Menger curvature is, how it is calculated, or at least some intuition should be provided. A short schematic or example trajectory would help. Recent ICLR/ICML papers have handled similar conceptual density more clearly, see, for instance, “The Geometry of Categorical and Hierarchical Concepts in LLMs” (Park et al., ICLR 2025) and “Tracing the Representation Geometry of Language Models from Pretraining to Post-training” (Zhang et al., ICML 2025).\n\n- The paper cites several strands but does not sufficiently contrast contributions with recent, closely related geometry/trajectory work at ICLR/ICML.\n\n- Its evidential basis is correlational and methodologically fragile in its current form. For example, the smoothness hypothesis needs independent validation. Hyp. 4.6 is asserted with a construction in App. C.1, but the fitted smooth curve could be an artifact. Maybe consider reporting results on shuffled/phase-randomized controls as baseline. \nMaybe also consider adding causal tests, stronger statistical treatment, external benchmark dataset validation, and clearer positioning/discussion vs. recent ICLR/ICML work; this submission could become a citable contribution to the geometry-of-reasoning literature. But I'm not sure if it can or will be done in the CR."}, "questions": {"value": "- It is not clear that the dataset isolates formal logic from its semantic context. There is a lack of systematic analysis, e.g., statistical analysis, to demonstrate the separation. In other words, how to ensure the disentanglement of the logic format and the semantic context?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ili80Ib40I", "forum": "ixr5Pcabq7", "replyto": "ixr5Pcabq7", "signatures": ["ICLR.cc/2026/Conference/Submission15480/Reviewer_xzaB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15480/Reviewer_xzaB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15480/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760563398606, "cdate": 1760563398606, "tmdate": 1762925772142, "mdate": 1762925772142, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global Response"}, "comment": {"value": "We sincerely thank the reviewers for their thoughtful engagement with our work! We are encouraged that multiple reviewers recognize the **novelty, clarity, and conceptual contribution** of our geometric framework for analyzing reasoning in LLMs. \n\nReviewers (`p3p6, 2CaL, umD2, xzaB`) highlight that our paper presents an **interesting and original** perspective by modeling reasoning as flows in representation space, with logic acting as a structural controller of these flows. Reviewers (`p3p6, 2CaL, umD2`) find our **mathematical formalization precise and well-motivated**, noting that our definitions of velocity and curvature provide a rigorous basis for analyzing reasoning dynamics. Reviewer `p3p6` appreciates that our **dataset design**—fixing natural-deduction templates while varying semantic carriers across topics and languages—enables a controlled test of logical invariance. Reviewers (`p3p6, 2CaL, umD2, xzaB`) further emphasize that our **empirical findings are compelling**: position reflects surface semantics, whereas velocity and curvature robustly track underlying logical structure. \n\nHere we provide the updates (in **blue**) that we made during the rebuttal in the global response. We will answer questions for each reviewer individually.\n\n## Writing Update:\nWe have revised several parts of the manuscript for clarity and precision:\n- Line 302-306: **Remark 4.8:** We added an explicit clarification that global injectivity of $\\Gamma$ over natural language is not assumed. Instead, we note that $\\Gamma$ only needs to be injective on a **restricted semantic domain** (e.g., paraphrase classes) for the alignment map $A = \\tilde{\\Psi} \\circ \\Gamma^{-1}$. We also highlight that global injectivity remains an open problem in AI and formal semantics.\n- Line 338–340: We added more words to emphasize that Proposition 4.11 captures structural influence of logic on flow dynamics, rather than implying a one-to-one mapping between inference rules and vector-field operators.\n- Line 366–368: We added more explanation of disentangling logic from semantics to explicitly articulate why cross-carrier consistency indicates internalization of logical structure.\n- Line 476–485: **Significance paragraph:** We expanded the discussion of the stochastic parrot argument, explicitly acknowledging that stochastic-parrot critiques claim LLMs cannot acquire meaning solely from next-token prediction. We then clarify how our geometric evidence **challenges** this view by demonstrating logical invariants in higher-order flow geometry.\n- Line 488–497: **Discussion on Understanding, Not Generation:** We strengthened the scope justification, emphasizing why our framework focuses exclusively on **natural language understanding**. We clarified that our reasoning geometry framework is a **post-hoc, model-agnostic, training-algorithm-agnostic law**, and explained why linking our measures to generation-specific metrics (e.g., output accuracy) is outside scope.\n- Line 867-917: **Comparison with Prior Work:** Added detailed comparisons with Park et al. (2025) and Li et al. (2025a) in Appendix A to clearly situate our contributions and address reviewer concerns about positioning relative to recent geometric-interpretability work.\n\n## Experiment Update:\nWe have expanded the experiments with more analysis:\n- Line 378-393: **Table 1 update:** We added more experiments including Random Shuffle Baseline and Qwen1.5 and Qwen2 results. \n\n- Line 453-458: **Random Shuffle:** We added a baseline where the logical step order is randomly permuted using Qwen3 0.6B. Shuffled trajectories exhibit near-zero velocity and curvature similarities, demonstrating that correct logical order is essential for stable reasoning flows. In contrast, position similarity remains high, confirming that topic/language drive surface semantics. \n\n- Line 461-466: **Scaling Effect:** We analyze two scaling axes: (1) model size (Qwen3 0.6B → 1.7B → 4B) and (2) model family (Qwen1.5/2/3 vs. LLaMA3 8B). Similarity patterns remain remarkably stable across both scaling directions. Increasing parameter count or switching families does *not* materially alter position/velocity/curvature similarities. This consistency suggests a more **general, and possibly universal**, property of how LLMs internalize logical structure independent of size or training recipe. \n\n- Line 926-937: **Fig 6 and $C^1$ Continuity Test:** To empirically support the smooth-flow assumption in Hypothesis 4.6, we provide finite-difference–based smoothness diagnostics. For a context-cumulative trajectory, we compute velocities $v_t = y_{t+1} - y_t$ and examine their norms $\\\\|v_t\\\\|$. As shown in Figure 6, six different answers to the same MATH500 problem exhibit consistent velocity-norm patterns with no abrupt jumps, visually supporting the plausibility of a $C^1$ interpolation."}}, "id": "r7tnTFNAhL", "forum": "ixr5Pcabq7", "replyto": "ixr5Pcabq7", "signatures": ["ICLR.cc/2026/Conference/Submission15480/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15480/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15480/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763698492107, "cdate": 1763698492107, "tmdate": 1763702090369, "mdate": 1763702090369, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework to analyze reasoning in large language models by viewing a chain of thought as a trajectory in representation space. The trajectory is described with three geometric descriptors: position, velocity, and curvature. Using this framework, the authors analyze reasoning traces in Qwen3 and LLaMA3 models. They synthetically generate multi-step logical sequences that share the same logical skeleton while varying topic and language. Applying their analysis, they find that velocity and curvature are more similar for traces that follow the same logic and remain low across different logics even when topic and language match. By contrast, position is more similar for inputs written in the same language. The authors interpret this as evidence that models encode logical structure in the dynamics of their representations, while static position reflects surface form."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- The paper Introduces a relatively novel geometric perspective on reasoning, modeling chains of thought as trajectories in representation space.\n- The authors provide a clear formalization of curvature and reasonable metrics to estimate it.\n- The paper includes convincing evidence that first- and second-order properties (velocity, curvature) track logic, while position reflects surface form or semantics."}, "weaknesses": {"value": "1. Lack of scaling analysis. The paper does not analyze how similarity patterns should evolve with model size. Table 1 shows no clear trend across Qwen3 0.6B, 1.7B, 4B and LLaMA3 8B. Position, velocity, and curvature similarities fluctuate rather than improving systematically with scale. The authors should discuss whether this is expected and what theory or diagnostics would predict size effects.\n2. Traces are not self-generated by the evaluated models. The reasoning sequences are produced by a much larger model and then fed to smaller models for analysis. This can introduce a distribution shift and may mask effects that would appear if each model were analyzed on its own traces. The paper should discuss how results might change under self-generated or mixed setups.\n3. Limited link to performance and disentanglement. Related to point 2, the paper does not examine whether models with stronger reasoning performance exhibit a clearer disentanglement between logic-driven dynamics (velocity, curvature) and surface-driven position. A mild suggestion is to correlate the geometric measures with task accuracy and to repeat the analysis on self-generated traces to see if better-performing models show stronger disentanglement."}, "questions": {"value": "1. How should similarity patterns for position, velocity, and curvature change with model size? Table 1 shows no clear trend across Qwen3 0.6B, 1.7B, 4B and LLaMA3 8B. Is the absence of a trend expected? \n2. How would the results differ if trajectories were computed on self-generated traces rather than sequences authored by a much larger model? \n3. Do better-performing models exhibit stronger disentanglement between logic-driven dynamics (velocity, curvature) and surface-driven position? Can you correlate the geometric measures with task accuracy and repeat the analysis on self-generated traces to test this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "k85qBZkSCW", "forum": "ixr5Pcabq7", "replyto": "ixr5Pcabq7", "signatures": ["ICLR.cc/2026/Conference/Submission15480/Reviewer_umD2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15480/Reviewer_umD2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15480/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761057652946, "cdate": 1761057652946, "tmdate": 1762925771298, "mdate": 1762925771298, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a new framework to mathematically model what happens when LLM's reason. \nIt is hypothesized that reasoning traces can be characterized by the geometric properties of the path that the reasoning tokens trace through an LLM's latent space.\nEvidence is presented suggesting that the latent 'reasoning flows' for similar kinds of reasoning (following a certain template) also exhibit similarities on the second and third order geometric properties of velocity and curvature.\nThis evidence is based on studying the given geometric properties for activations of various models when forwarded on a novel dataset where the same logical template is used to construct different chains-of-thought in various domains and languages."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Interesting new framework for thinking about reasoning in LLMs.\n\nThe concepts that are appealed to are made mathematically precise, and the math is introduced step-by-step in a way that is easy to follow (relative to the complexity of the subject matter).\n\nThe results show that when an LLM reasons according to the same logical pattern/template (but about different topics and in different languages), its activations move through latent space with similar curvature (how small or large is the angle made between triples of subsequent token activation vectors). And, to a lesser extent also with similar velocity (how far apart is each subsequent token activation vector). This is an interesting finding."}, "weaknesses": {"value": "There is one claim I believe is too strong, on line 429-431: \"Together, these results show that LLMs internalize latent logical structure beyond surface form. They are not mere stochastic parrots (Bender et al., 2021): whereas humans formalized logic only in the 20th century (Bochenski & Thomas, 1961), LLMs acquire it emergently from large-scale data—a hallmark of genuine intelligence.\"  I'm not sure these results really provide much evidence against the 'stochastic parrot theory'. The results, as I understand them, show that the same logical structure elicits similar trajectories (in the second- and third-order geometric sense) through latent space. But the logic is not just similar, it is identical. Wouldn't we need to show that the LLM correctly identifies the (vast majority of) instances as instantiations of the logical problems (in an exact, not fuzzy sense).  And as for the second part, the experiments use Qwen models, which are not merely pre-trained on large-scale data, but also mid- and post- trained, right? so the observations might be due to those training stages, which quite likely involve supervised/reinforcement training on logic problems. Finally, the juxtaposition between discovering-from-data and human-discovery, seems mistaken. Even if the model 'discovers' it from the data, that is likely due to the human discovery being described/present in the data.\n\nIf this is addressed, I'm happy to increase my score."}, "questions": {"value": "What can we learn from the fact that logics B and C are very similar in curvature? Does this suggest that the LLM uses the same mechanisms for both? Is the similarity a surprise to you, would you expect it from looking at the templates?\n\nPresumably, not the entire latent space is relevant for (logical) reasoning. Would you expect there to be a subspace in which the correlation between (the velocity/curvature of) samples of the same logic template is even stronger, perhaps much stronger (close to one)?\n\nWhat are the individual rows/columns within the blocks (L:E through L:A) in Figure 2, are they the different topics and languages?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZeBleKuSfa", "forum": "ixr5Pcabq7", "replyto": "ixr5Pcabq7", "signatures": ["ICLR.cc/2026/Conference/Submission15480/Reviewer_2CaL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15480/Reviewer_2CaL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15480/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761735614754, "cdate": 1761735614754, "tmdate": 1762925769580, "mdate": 1762925769580, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a geometric framework for analyzing reasoning in LLMs. The core idea is to treat reasoning as smooth trajectories (“flows”) in representation space, where logical operations act as differential controllers of the embedding’s local velocity and curvature."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- the topic of reasoning as continuous geometric flows within embedding space is interesting and the proposed formulation combining mapping and alignement provide a good abstraction linking reasoning to symbolic representation. \n\n- The construction of continuous C^1 trajectories via the relaxed prefix-mask mechanism (Proposition C.4) is both novel and technically precise\n\n- the proposed dataset and empirical results show good results."}, "weaknesses": {"value": "- the proposition 4.10 that connects logic to the integral of velocity. It is not clear on how it maps between inference rules and specific vector-field constraints on v(s). It is not clear  how logical connectives translate into geometric operations or basis directions in representation space?\n\n- in the mapping A = \\Psi \\circ \\Gamma^{-1}, does\\ Gamma injective? \n\n- how the mapping D_R : \\Psĩ \\mapsto (\\Delta y_t) preserve logical equivalance?\n\n- The logical dataset is generated with GPT-5 templates. How the validation is performed and logical equivalence are guaranteed.\n\n- How empiracly C^1 interpolation is validaded?"}, "questions": {"value": "see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dXEd26rnO0", "forum": "ixr5Pcabq7", "replyto": "ixr5Pcabq7", "signatures": ["ICLR.cc/2026/Conference/Submission15480/Reviewer_p3p6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15480/Reviewer_p3p6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15480/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834835264, "cdate": 1761834835264, "tmdate": 1762925768910, "mdate": 1762925768910, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}