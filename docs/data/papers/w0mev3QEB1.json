{"id": "w0mev3QEB1", "number": 16685, "cdate": 1758267625759, "mdate": 1763366059454, "content": {"title": "Wavescale Neural Audio Codec: Bidirectional Multiscale Residual Quantization for High-Fidelity Audio Compression", "abstract": "Modern AI systems need audio representations that are efficient in bandwidth and friendly to models. Neural codecs learn discrete token streams optimized for perceptual and task goals, unifying compression with generation, editing, retrieval and multimodal reasoning. Neural compression with residual vector quantization (RVQ) achieves low bitrates at high quality by encoding audio as discrete latents. Recent multiscale RVQ variants (e.g., SAT, SNAC) distribute quantization across multiple temporal scales to reduce token rate and computational cost; however, a purely upscale hierarchy assigns coarse (low-rate, slowly varying) structure to early stages where typically low-frequency components are assigned and fine (high-rate, rapidly varying) detail to later stages where typically high-frequency components are assigned. This works well for speech but often fails for music and environmental audio: in music, early stages can carry fine detail, whereas in environmental audio, periodicity is weak. We introduce the Wavescale Neural Audio Codec (WNAC), which replaces the pure upscale flow with a downscale then upscale path. By inserting fine-to-coarse stages before coarse-to-fine, WNAC preserves early low frequency information. We also add a scale-aware waveloss that aligns quantized outputs at the same temporal resolution across stages, improving reconstruction sharpness and stability. Experiments show higher accuracy and efficiency across speech, music, environment and a mixed general set, outperforming single-scale DAC while keeping the speed benefits of multiscale RVQ.", "tldr": "A multiscale RVQ-VAE based neural audio codec that improves compression and reconstruction of general sounds by introducing a downscale-upscale quantization framework with stage-wise alignment loss.", "keywords": ["Neural Audio Compression", "Variational AutoEncoder", "Multiscale Residual Vector Quantization", "Codebook", "Wavescale", "Waveloss"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b7080eaa68017be77fb75c8b514d9fe559671a8e.pdf", "supplementary_material": "/attachment/84f23035104a559c6f4a8bdada35b6476033101b.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces a novel neural audio codec, termed the Wavescale Neural Audio Codec (WNAC), which aims to address the limitations of existing high-fidelity audio compression methods. The central motivation stems from a key limitation of contemporary multiscale Residual Vector Quantization (RVQ) models (e.g., SAT, SNAC), which typically employ a unidirectional coarse-to-fine upscaling hierarchy. The authors persuasively argue that this assumption—that coarse, low-frequency information can be adequately captured in early, low-resolution stages—often fails for non-speech audio such as music and environmental sounds, where fine details can be present in low-frequency components, leading to information loss."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Clear and Well-Supported Motivation: The paper provides a compelling critique of the standard coarse-to-fine paradigm in multiscale audio codecs, supported by domain-specific analysis showing its failure on non-speech audio.\n\nNovel and Well-Tailored Methodology: The proposed Wavescale architecture, a symmetric \"downscale-then-upscale\" flow, is a highly innovative solution. It is effectively complemented by a scale-aware waveloss that enforces representational consistency and improves reconstruction stability.\n\nRigorous and Convincing Experiments: The experimental design systematically evaluates the method across diverse domains. The results convincingly demonstrate SOTA performance on main benchmarks (Table 1), strong subjective listening scores (Figure 3), and the necessity of each core component through ablation studies.\n\nHigh-Quality Presentation and Downstream Validation: The paper is well-written with intuitive visualizations (e.g., Figure 1). The validation on a downstream ASR task (Table 8) further strengthens the claim of producing useful representations."}, "weaknesses": {"value": "Unclear Low-Frequency Preservation Mechanism: The paper claims the initial fine-scale processing preserves low-frequency information (Line 29), which is counter-intuitive and lacks a clear technical explanation.\n\nIncompatibility with Autoregressive Generation: The proposed top-down quantization flow breaks the assumptions of existing next-scale prediction methods (e.g., in SAT, SNAC), limiting the codec's immediate applicability for popular autoregressive generation tasks.\n\nNotational Ambiguity in Loss Function: The summation symbols in the VQ-VAE loss equations for L_cb and L_cm (Lines 192-193) lack indices, which is a minor but important notational error."}, "questions": {"value": "Following up on the point raised in Weakness #1, could the authors elaborate on the mechanism by which the initial fine-resolution stages of WNAC effectively preserve low-frequency information, which typically dominates the signal energy? Is this an inherent property of the encoder architecture, or is there a specific design element that facilitates this?\n\nRegarding the waveloss, which is computed between q_i and q_{n-i}, does this imply that the total number of quantization stages n must be odd to have a central pivot? How are cases with an even n handled? Furthermore, did the authors experiment with alternative consistency-enforcing losses, such as a cycle-consistency loss or a direct constraint on the latent residuals z?\n\nIn the downstream ASR evaluation (Table 8), was the ASR model applied to the reconstructed waveform from WNAC, or was it fine-tuned/evaluated directly on the discrete token sequences generated by the codec? Clarifying this would help in better understanding the quality of the latent representation itself.\n\nLine 46: The citation Jiang et al., 2025 refers to a future publication. Please verify if this is a typographical error for the year or if the paper is indeed accepted for a 2025 venue.\nLines 192-193: The summation symbols in the equations for L_cb and L_cm are missing their indices (e.g., Σ_{i=0}^{n-1}). This is a notational error that should be corrected for mathematical rigor."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Y6HeU7LDXX", "forum": "w0mev3QEB1", "replyto": "w0mev3QEB1", "signatures": ["ICLR.cc/2026/Conference/Submission16685/Reviewer_Cbcn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16685/Reviewer_Cbcn"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16685/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761730170899, "cdate": 1761730170899, "tmdate": 1762926740308, "mdate": 1762926740308, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces the Wavescale Neural Audio Codec (WNAC), a modification of multiscale residual vector quantization that reverses the conventional coarse-to-fine quantization order. The authors motivate this design by arguing that coarse-first quantization can discard semantically important low-frequency content in music and environmental audio. To address this, WNAC first quantizes high-resolution features, progressively downsamples, and then refines via upsampling. A scale-aware loss (“waveloss”) is further introduced to encourage consistency across stages operating at the same temporal resolution. The paper provides objective and subjective evaluation across several audio domains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* Extends RVQ in an interesting way.\n* The proposed waveloss ablates well: intermediate scales improve in stability, and final reconstruction modestly improves.\n* Evaluation includes subjective MUSHRA testing as well as domain-specific analysis.\n* Experiments are generally well-run, and there are ablations"}, "weaknesses": {"value": "* Although the paper compares reconstruction quality across systems, it does not report bitrate in standard units (bits/s). Instead, it introduces metrics such as “code length (relative to encoder output)” and “bitrate efficiency” (Table 2) without grounding them in true bitrates. However, different models could still produce different numbers of tokens per second. For example, WNAC uses far more residual stages than SNAC, which could imply (assuming the same frame rate) that effective bitrate differs substantially. Without fixed or matched bitrate configurations, the fairness of the comparisons is completely unclear and the reported numbers do not mean much. This is a fundamental issue that needs to be addressed as it puts all empirical results into question.\n\n* The motivation that coarse-first quantization discards low-frequency detail in music and environmental audio is not substantiated and questionable. The paper does not quantify perceptual degradation attributable to this phenomenon. Without any data to support this, the justification remains high-level speculation. Appendix plots show broad domain differences, but they do not directly prove the proposed architectural fix addresses this.\n\n* The authors explicitly note in that the reversed quantization order is incompatible with next-scale prediction autoregressive models. This is not just a minor limitation as it could mean that the codec is not suitable at all for modeling in downstream tasks. Thus, while the introduction highlights “compression with generation, editing, retrieval” as motivating applications, it’s questionable whether this is actually possible. There is no alternative generative strategy proposed to handle token streams for this codec, neither is it validated on any downstream tasks.\n\n* “Code length” first appears in Table 2 without prior explanation, and only later is it implicitly tied to token count. It should be clearly introduced earlier and formally connected to bitrate. As written, the role of code length in determining bitrate is easy to misunderstand."}, "questions": {"value": "* Can you report actual bitrate (bits/s) and tokens/s for all models, rather than relative code length or bitrate efficiency, to ensure fair comparison?\n\n* How does WNAC perform when bitrate is matched to SNAC?\n\n* Is the performance gain attributable to the reversed scale order, or primarily to the increased number of quantization stages?\n\n* Can you clarify how “code length” is computed and how it maps to true bitrate?\n\n* Given incompatibility with next-scale prediction, what is the intended strategy for autoregressive/generative modeling?\n\n* It is a bit concerning to me that the wavescale loss is necessary/helps. Doesn't it incentivize many codebooks to have similar content and thus reduce the amount of encoded information?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DDGKAKqIux", "forum": "w0mev3QEB1", "replyto": "w0mev3QEB1", "signatures": ["ICLR.cc/2026/Conference/Submission16685/Reviewer_F8o4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16685/Reviewer_F8o4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16685/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761767254117, "cdate": 1761767254117, "tmdate": 1762926739385, "mdate": 1762926739385, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose Wavescale Neural Audio Codec (WNAC), a multiscale residual vector quantization framework that modifies the traditional bottom-up (coarse-to-fine) structure used in multiscale RVQ-VAE codecs. WNAC adopts a fine-to-coarse downscaling followed by an upscaling approach, aiming to preserve high-resolution information early in the quantization process. The authors also use a scale-aware waveloss to enforce consistency across quantizers operating at the same temporal resolution to improve reconstruction quality and latent coherence. Experimental results show that WNAC outperforms existing multiscale codecs such as SAT and SNAC across multiple domains (speech, music, and environmental audio) in both objective and subjective evaluations, while maintaining competitive inference efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors identify a key limitation of the coarse-to-fine strategy in modeling non-speech audio within multiscale RVQ-VAEs, providing a reasonable and timely motivation. \n2. The design of the downscale-upscale quantization flow is conceptually sound and appears easy to integrate into existing architectures. \n3. The experiments are comprehensive, including extensive ablation studies such as domain robustness and codebook efficiency, which demonstrate the effectiveness of the wavescale RVQ design."}, "weaknesses": {"value": "1. No actual bitrate or token rate for the main reconstruction results (Tables 1 and 3) are provided. Consistent bitrate is crucial for fair comparison of reconstruction performance across codecs.\n2. The definition of code length is ambiguous. Sometimes it appears to be a relative measure, and at other times absolute. This makes it difficult to interpret quantitative comparisons."}, "questions": {"value": "1. Figure 6 shows improved codebook utilization, but it is unclear whether this improvement stems from the waveloss or the wavescale quantization. The figure’s caption and explanation are vague. Additionally, what does a code length smaller than 1 signify in this context? \n2. Although WNAC demonstrates improved overall performance, can the authors provide more empirical evidence that the fine-to-coarse upscale quantization indeed preserves more low-frequency content?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "wE7tKhOA9G", "forum": "w0mev3QEB1", "replyto": "w0mev3QEB1", "signatures": ["ICLR.cc/2026/Conference/Submission16685/Reviewer_V9n7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16685/Reviewer_V9n7"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16685/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902788359, "cdate": 1761902788359, "tmdate": 1762926738691, "mdate": 1762926738691, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores the problem of multi-scale quantization in neural audio compression. The authors present the Wavescale Neural Audio Codec (WNAC), which integrates both downscaling and upscaling within the quantization layers. In addition, they propose a scale-aware wave loss designed to align quantized outputs across stages at consistent temporal resolutions. Experimental results demonstrate that WNAC achieves superior accuracy and efficiency across speech, music, environmental, and mixed audio datasets, outperforming single-scale quantization methods while maintaining the speed advantages of multi-scale RVQ."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe proposed approach is interesting, conceptually simple, and easy to follow.\n2.\tThe authors present both objective and subjective evaluations across multiple audio domains, with results indicating that the proposed method outperforms the compared baselines."}, "weaknesses": {"value": "1.\tIt is unclear how the proposed method could be adapted for streaming applications, and what its associated latency or lookahead requirements would be.\n2.\tSeveral claims made in the paper are not sufficiently supported or justified.\n3.\tThe primary contribution of the work is the downscaling and upscaling pattern, which is not well motivated or theoretically explained."}, "questions": {"value": "1.\tIn the first equation (note: equation numbers are missing), the authors define the interpolation method S. However, it is unclear what specific interpolation technique is used.\n2.\tThe main contribution of the proposed approach appears to be the downscaling and upscaling pattern. Yet, the rationale behind why this design should lead to improved performance is not well explained. The authors are encouraged to provide further details or theoretical insights to support this choice.\n3.\tThe paper states that “by inserting fine-to-coarse stages before coarse-to-fine, WNAC preserves early low-frequency information.” However, no experimental evidence is presented to validate this claim.\n4.\tFigure 4 and Table 3 demonstrate that the proposed method performs well across different domains, but it remains unclear what specifically contributes to its robustness. Is the improvement simply due to overall model quality, or is there a domain-generalization property inherent to the design?\n5.\tThe bitrate of the proposed method is not reported and should be specified.\n6.\tWhile the authors report inference speed and latency, which is commendable, it is unclear whether the proposed method can be adapted for streaming scenarios, and if so, what its lookahead would be. Given the stated limitations regarding applicability to large language models, the practical use of this codec for streaming applications remains uncertain.\n7.\tMinor comment: Using paragraph breaks within the abstract is unconventional and should be avoided.\n8.\tThere are no samples. \n9. Can the authors share a comparison to a non multi-scale codecs as well? I believe it would be valuable to understand the gap in performance and usability compared to a others non multi-scale codecs"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QLrDWWnHDr", "forum": "w0mev3QEB1", "replyto": "w0mev3QEB1", "signatures": ["ICLR.cc/2026/Conference/Submission16685/Reviewer_TNzH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16685/Reviewer_TNzH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16685/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762197449137, "cdate": 1762197449137, "tmdate": 1762926738326, "mdate": 1762926738326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}