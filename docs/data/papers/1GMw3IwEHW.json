{"id": "1GMw3IwEHW", "number": 12631, "cdate": 1758209134728, "mdate": 1759897497184, "content": {"title": "Protection against Source Inference Attacks in Federated Learning", "abstract": "Federated Learning (FL) was initially proposed as a privacy-preserving machine learning paradigm. However, FL has been shown to be susceptible to a series of privacy attacks. Recently, there has been concern about the Source Inference Attack (SIA), where an honest-but-curious central server attempts to identify exactly which client owns a given data point which was used in the training phase. Alarmingly, standard gradient obfuscation techniques with Differential Privacy have been shown to be ineffective against SIAs, at least without severely diminishing the accuracy.\n\nIn this work, we propose a defense against SIAs within the widely studied shuffle model of FL, where an honest shuffler acts as an intermediary between the clients and the server. First, we demonstrate that standard naive shuffling alone is insufficient to prevent SIAs. To effectively defend against SIAs, shuffling needs to be applied at a more granular level; we propose a novel combination of parameter-level shuffling with the residue number system (RNS). Our approach provides robust protection against SIAs without affecting the accuracy of the joint model and can be seamlessly integrated into other privacy protection mechanisms.\n\nWe conduct experiments on a series of models and datasets, confirming that standard shuffling approaches fail to prevent SIAs and that, in contrast, our proposed method reduce the attack’s accuracy to the level of random guessing.", "tldr": "The paper discusses a defense against Source Inference Attacks using the shuffle model of Federated Learning. It proposes RNS-based parameter-level shuffling that preserves accuracy and reduces attack success to random guessing.", "keywords": ["Federated Learning", "Source Inference Attack", "Shuffle Model", "Residue Number System"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/41123370bb5a7b80b3549870aae1254852c1c82e.pdf", "supplementary_material": "/attachment/d3af303c894ffa81e084c2c0ace027b744323737.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates source inference attacks (SIAs) in federated learning, where an honest-but-curious server aims to identify which client owns a given training sample, and proposes both new reconstruction attacks and a defense mechanism under the shuffle model. The authors first demonstrate that standard model-, layer-, and parameter-level shuffling are insufficient to prevent SIAs by designing effective remapping attacks. To counter these, they introduce a parameter-level bit-wise shuffling strategy combined with residue number system (RNS) encoding, which theoretically ensures that only aggregated information is revealed to the server and empirically reduces attack accuracy to random guessing while maintaining model performance. Extensive experiments on MNIST, CIFAR-10, and CIFAR-100 validate the approach, showing strong protection with reasonable communication overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper targets the relatively unexplored source inference attack (SIA) in federated learning, extending beyond traditional membership or gradient inversion attacks, and contributes both new attack formulations and corresponding defenses within the shuffle model framework.\n2. The authors provide a systematic exploration of reconstruction attacks at different granularities (model-, layer-, and parameter-level), clearly demonstrating the limitations of naive shuffling and motivating the need for a more fine-grained defense.\n3. Experimental results on multiple benchmarks (MNIST, CIFAR-10, CIFAR-100) show that the proposed method consistently reduces SIA success rates to the level of random guessing, while maintaining comparable accuracy and reasonable communication overhead."}, "weaknesses": {"value": "1. The reconstruction attacks heavily rely on a shadow dataset that is directly obtained from the attacked clients or from data sources with a similar distribution. This assumption is impractical in most real-world scenarios, and moreover, it introduces severe privacy leakage risks in sensitive domains such as healthcare or finance. The paper should also provide a comprehensive analysis of the impact of shadow data quality, for example, when the shadow dataset does not come from the specific attacked client or exhibits significant distributional bias, or contains noisy data.\n2. The proposed attack and defense assumptions are overly idealized. The attacker is assumed to be an honest-but-curious server with a small shadow dataset, while the defense relies on the existence of a fully or partially trusted MixNet shuffler. Both assumptions seem contradicted or are difficult to guarantee in realistic federated learning settings.\n3. The limitations of numerical precision in encoding may significantly affect both model convergence and potential information leakage, especially in complex models or datasets. For example, in the CIFAR-100 experiments, achieving lossless precision requires several times higher communication overhead.\n4. All experimental datasets and models are designed for vision tasks, which limits the generalizability of the proposed approach to other modalities, such as medical tabular data.\n5. The proposed defense is only applicable to sum-based aggregation scenarios, which represents a major limitation given the existence of numerous non–sum-based secure aggregation algorithms designed to counter adversarial attacks.\n6. The aggregation formula of FedAvg mentioned around Line035 lacks mathematical rigor regarding aggregation weights.\n7. The overall paper structure could be improved. For example, Section 6.1 appears as the only subsection under Section 6."}, "questions": {"value": "1. How can the authors clearly differentiate the real contributions of this work from the previously submitted (under-review) reference [3]?\n2. Could the authors provide a quantitative analysis of the communication cost required to achieve lossless precision on the CIFAR-100 dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7hmlmqyDVg", "forum": "1GMw3IwEHW", "replyto": "1GMw3IwEHW", "signatures": ["ICLR.cc/2026/Conference/Submission12631/Reviewer_nh8m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12631/Reviewer_nh8m"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761774442147, "cdate": 1761774442147, "tmdate": 1762923477252, "mdate": 1762923477252, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies source inference attacks (SIA) in cross-silo FL and argues that naïve shuffling at different granularity (model/layer/parameter) does not protect against a curious server equipped with a small shadow dataset. The authors then propose a hybrid encoding–shuffling defense: fixed-point quantization, RNS decomposition, unary encoding, and per-bit shuffling, aiming to leak only the aggregated sum. Experiments on CNN/ResNet over MNIST/CIFAR claim to suppress SIA to random chance without model degradation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Clearly identifies that basic shuffling in FL still leaks client identity.\n\n2. Proposes a new bit-level encoding + shuffling defense, not just adding noise.\n\n3. Shows strong privacy improvement with almost no accuracy loss.\n\n4. Provides both attack and defense experiments to support claims."}, "weaknesses": {"value": "1. Shadow-dataset assumption is strong; needs sensitivity analysis under distribution shift.\n\n2. Relies on a trusted shuffler, not obvious in many deployments.\n\n3. No evaluation on text/LLM/tabular medical/time-series with only CV toy setups.\n\n4. Multi-round leakage not addressed (momentum, clipping signals, correlated updates).\n\n5. Communication claims hinge on compression + trust assumption, which is not apples-to-apples vs secure aggregation."}, "questions": {"value": "1. What if the shadow data distribution does not match exactly?\n\n2. Can a server correlate updates across rounds and break anonymity?\n\n3. Comparison to threshold secure aggregation under the same drop-rate constraints?\n\n4. Does this work for Transformers/LLMs or non-image workloads?\n\n5. How realistic is the trusted shuffler assumption? Any decentralized variant?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "EhFyfSFGtZ", "forum": "1GMw3IwEHW", "replyto": "1GMw3IwEHW", "signatures": ["ICLR.cc/2026/Conference/Submission12631/Reviewer_jeWK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12631/Reviewer_jeWK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761796211948, "cdate": 1761796211948, "tmdate": 1762923476897, "mdate": 1762923476897, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses Source Inference Attacks (SIAs) in Federated Learning (FL)—attacks where a central server identifies which client owns specific training data. It highlights that traditional defenses (e.g., Differential Privacy, regularization) and conventional shuffling (model-level, layer-level, parameter-level) fail to block SIAs without harming model accuracy.\nA new defense combining parameter-level shuffling and Residue Number System (RNS) is proposed: parameters are scaled, RNS-encoded, unary-encoded, bit-wise shuffled, then decoded/aggregated by the server. Validated on MNIST/CIFAR-10/CIFAR-100 with CNN/ResNet-18, it reduces SIA accuracy to random guessing, preserves model performance, integrates seamlessly into shuffle-model FL, and has controllable communication costs.\nKey Contributions:\n1. Identifies vulnerabilities of conventional shuffling via 3 reconstruction attacks.\n2. Proposes the first shuffle-model FL defense to neutralize SIAs (random-guess accuracy).\n3. Extends defense to resist Data Reconstruction Attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. First systematic defense against Source Inference Attacks (SIAs) in Federated Learning, introducing a novel parameter-level shuffling and RNS-based mechanism that reduces SIA accuracy to random guessing.\n2. Well-structured “problem–proposal–verification” format with clear explanations, visual aids, and comprehensive appendices.\n3. Addresses a core privacy challenge in cross-silo FL, offering compatible, low-cost protection against both SIAs and DRAs. Expands FL privacy theory and establishes a new paradigm for noise-free privacy amplification."}, "weaknesses": {"value": "1. Lack of Discussion on Detailed Synergistic Optimization Between the Mechanism and Differential Privacy (DP)：\nThe paper claims that the proposed mechanism can be \"seamlessly integrated with other privacy mechanisms such as DP\" (meeting Specification S.2), yet it fails to verify the actual performance after integration or provide a specific integration scheme. DP requires adding noise to protect privacy, but the RNS encoding of the mechanism may interact with the noise distribution (e.g., noise could cause parameters to exceed the RNS encoding range). Additionally, the balance among \"privacy gain, accuracy loss, and communication cost\" after integration has not been quantified. As a result, this feature remains at the theoretical level and lacks practical guiding significance.\n2. Improvement: Design an integrated \"RNS + DP\" scheme where clients first add DP noise to parameters, followed by RNS encoding and shuffling. Test the SIA defense effect, model accuracy, and communication cost under different DP noise intensities (ε= 1, 2, 5) on the MNIST dataset to identify the optimal integration parameters (e.g., when ε= 2, the mechanism + DP can reduce the SIA accuracy to below 10% while maintaining 95% model accuracy)."}, "questions": {"value": "It is suggested to supplement the \"quantitative correlation analysis between RNS modulus selection, communication cost, and model accuracy\" and clarify the decision-making basis for the optimal modulus combination under different scenarios."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "30giA5rfbJ", "forum": "1GMw3IwEHW", "replyto": "1GMw3IwEHW", "signatures": ["ICLR.cc/2026/Conference/Submission12631/Reviewer_kvmB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12631/Reviewer_kvmB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895740660, "cdate": 1761895740660, "tmdate": 1762923476492, "mdate": 1762923476492, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigate the defense against source inference attacks in FL in the shuffle model. On a high level, if the server knows a subset of the target client's training data, it can use that to identify the target client's share from the shuffled results it receives. To address this, the authors propose to do bit-level shuffling for each parameter of the client. The authors argue that this means that after reconstructing the server knows nothing more than the aggregated result. Empirical results demonstrate the effective of such defense."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Interesting setting and important problem to study.\n1. Theoretical results on the security of the proposed shuffling algorithm.\n1. Comprehensive discussions on different trust models and different variations of the proposed method.\n1. A lot of experiments of different settings.\n1. Comparison to secure aggregation."}, "weaknesses": {"value": "1. Unclear settings for the experiments in Section 7.\n1. I would like more clarification on the trust model of the shuffler.\n1. Discussions of the security of the proposed method beyond SIA."}, "questions": {"value": "1. In the experiments, how are the coprimes set? Does this affect security?\n1. There are different levels of trust for the shuffler. This should be clarified and explained in a clearer way. If it is completely trusted, then we can send the model weights or bits in plaintext to the shuffler and trust it to perform shuffling. We can also only trust it to perform shuffling and then hide the plaintext weights or bits from it, i.e., it is a trusted shuffling router of encrypted messages (like Cloudfare). It can further be malicious where we would need ZKPs. In section 7, is the shuffler trusted? i.e., are the bits/models sent to the shuffler in plaintext and it shuffles without verification and sends the shuffled results to the server? I understand that we need an honest shuffler for the compression technique to work, but for the other experiments, is the shuffler also trusted? If we are encrypting messages to the shuffler, then doing more granular shuffling would means more overhead for the client and the server.\n1. Compared to secure aggregation, I understand that each client's message size do not increase with the number of clients, and the assumptions on the server/shuffler can be different. However, is the security guarantees the same? Does the shuffling with encoding scheme provide cryptographic semantic security? If so, its power shouldn't be limited to SIAs."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "rpABk20G9N", "forum": "1GMw3IwEHW", "replyto": "1GMw3IwEHW", "signatures": ["ICLR.cc/2026/Conference/Submission12631/Reviewer_79dB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12631/Reviewer_79dB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12631/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761944902660, "cdate": 1761944902660, "tmdate": 1762923476254, "mdate": 1762923476254, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}