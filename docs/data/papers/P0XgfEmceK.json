{"id": "P0XgfEmceK", "number": 23599, "cdate": 1758346127081, "mdate": 1759896805334, "content": {"title": "Diffusion Models Improve Adversarial Robustness by Compressing Image Space", "abstract": "Recent work suggests that diffusion models significantly enhance empirical adversarial robustness. While several intuitive explanations have been proposed, the precise mechanisms remain unclear. In this work, we systematically investigate how diffusion models improve adversarial robustness. First, we observe that diffusion models intriguingly increase, rather than decrease, the $\\ell_p$ distance to clean samples—challenging the notion that purification denoises inputs closer to the clean data. Second, we find that the purified images are heavily influenced by the internal randomness of diffusion models. When the randomness of the diffusion model is fixed, diffusion models substantially compress the image space. Importantly, we discover a lawful relationship between the adversarial robustness gain and the model’s ability to compress the image space, quantified by the expected compression rate (CR). Further theoretical analyses show that (i) convergent score fields encoded in diffusion models explain these compression effects, and (ii) under a low-dimensional data manifold hypothesis, the expected CR captures the compression along off-manifold directions. Our findings uncover the precise mechanisms underlying diffusion-based purification and offer guidance for developing more effective and principled adversarial purification systems.", "tldr": "", "keywords": ["Diffusion Models", "Adversarial Purification", "Compression"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d93116b164441c35034d79606e15444d0f6f73ad.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates how diffusion-based purification methods improve adversarial robustness. First, a counterintuitive phenomenon is observed that diffusion-based purification increases the distance to clean samples rather than decreases it, shifting the perturbed samples around the clean image to a new space around an anchor point. Then, by disentangling the variability in the input perturbation and purification stochasticity, it is identified that the image space is compressed when the system's random states are fixed. Further empirical and theoretical analyses attribute the improved robustness under fixed random states to the compression effect, especially along off-manifold directions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper provides new insights into the mechanism of diffusion-based adversarial purification methods, including the counterintuitive finding of increased image distance after purification, and the disentanglement of the contribution of stochasticity and image space compression. These insights may also motivate other research on diffusion models.\n1. The viewpoint that EOT should be understood as a transfer attack is interesting and reasonable.\n1. The main ideas of the paper are clearly illustrated by the figures and supported by both empirical and theoretical analyses."}, "weaknesses": {"value": "1. My major concern is the **relation between compression rates and adversarial robustness**. Although Fig. 3a empirically suggests the monotonic relation between robustness and compression rate, and this relation can potentially be explained by the distribution of minimal adversarial perturbation plotted in Fig. 3b, it cannot be concluded that compression contributes to the non-trivial robustness under fixed randomness. The key issue is that **the compressed space is around the shifted anchor points $f(x_0)$, while Fig. 3b is plotted based on the clean images $x_0$** according to Lines 369-371. If the distribution of minimal adversarial perturbation for anchor points is statistically similar to that of the clean images, then compressing the space can indeed increase the robustness.\n2. The clarity of the figures and tables should be improved:\n- The notation \"Reverse\" in Fig. 1, Table 1, and others is not clearly defined.\n- In Fig. 2f, the bars for \"fixing input\" are almost completely covered by those for \"varying both\", which could lead to confusion.\n- The details for fitting the robustness-compression curve in Fig. 3 should be clarified.\n- The \"PGD (Robust)\" and \"PGD (Non-robust)\" in Table 2 are not explained and are confusing. If these refer to the compression rates along some adversarial directions, then it seems to contradict with the conclusions in Sec. 6.\n- The notations \"Compress\" and \"PGD (Fix)\" in Table 3 should also be better clarified.\n3. It would be better to provide more qualitative examples of clean and purified images to support the arguments in Sec. 3.\n4. Table 1 is weak evidence for the non-monotonic relation between distributional distances and adversarial robustness, as it only incorporates three data points.\n5. The timestep values for the reverse process in Sec. D (e.g., 100-200) are inconsistent with those in the main text (e.g., 100-0)."}, "questions": {"value": "1. The expected compression rate is computed based on isotropic noise. However, adversarial noises are not likely to be isotropic. Would this issue affect the analyses and conclusions?\n1. While designing a compression-based purification system can be a promising direction, the existing results for diffusion-based methods (e.g., those in Sec. B) suggest that stochasticity may be more effective for adversarial defense. Is there any specific evidence or rationale that supports the potential superiority of compression-based methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SJzG7hJ8F5", "forum": "P0XgfEmceK", "replyto": "P0XgfEmceK", "signatures": ["ICLR.cc/2026/Conference/Submission23599/Reviewer_xbFW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23599/Reviewer_xbFW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23599/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761732640669, "cdate": 1761732640669, "tmdate": 1762942730769, "mdate": 1762942730769, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper challenges conventional views on diffusion-based purification (DBP) robustness by proposing a compression-based perspective. The authors show that diffusion models compress image space when randomness is fixed, and introduce the compression rate metric to quantify this effect. They establish a sigmoidal relationship between CR and robustness, providing theoretical insights that compression primarily affects off-manifold perturbations through convergent score fields."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is clearly written. It identifies flaws in existing explanations, proposes a novel compression-based framework, and substantiates it with both theoretical analysis and empirical evidence. The visualizations effectively assists in conveying the key ideas.\n\n2. The paper provides a fresh perspective in shifting the focus from \"denoising\" to \"space compression\" as the mechanism underlying DBP robustness. The introduction of compression rate linkes purification behavior to adversarial robustness, and the distinction between on-manifold and off-manifold perturbation behavior provides insights.\n\n3. The proposed compression rate offers potential value—it can be adopted as a tool to evaluate adversarial robustness of purification models, facilitating more efficient model robustness assessment."}, "weaknesses": {"value": "1. The experimental validation is conducted on a relatively narrow set of models and datasets, this makes it difficult to assess whether the compression-robustness relationship holds universally or only under specific conditions.\n\n2. The paper lacks implementation details for computing the compression rate metric, also no ablation studies are presented to demonstrate CR's stability with respect to hyperparameters. Without these analyses, it is unclear whether CR is a robust and reliable metric in practice or sensitive to implementation choices."}, "questions": {"value": "How are on-manifold and off-manifold perturbations mathematically connected to CR in the derivation? What specific property distinguishes them such that compression selectively affects off-manifold perturbations while preserving on-manifold components?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1VGlA55O8N", "forum": "P0XgfEmceK", "replyto": "P0XgfEmceK", "signatures": ["ICLR.cc/2026/Conference/Submission23599/Reviewer_x1cW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23599/Reviewer_x1cW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23599/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761748256663, "cdate": 1761748256663, "tmdate": 1762942730522, "mdate": 1762942730522, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how diffusion models improve adversarial robustness. The key contributions are: (1) showing that diffusion models surprisingly increase rather than decrease distances to clean samples, with internal randomness dominating the output; (2) proposing a compression framework where robustness follows a lawful sigmoidal relationship with the compression rate (CR) when randomness is fixed; (3) proving theoretically that compression arises from the convergent score field, with CR capturing off-manifold compression while preserving on-manifold perturbations."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and logically organized, guiding the reader from intuitive hypotheses to formal derivations and validation. Figures effectively illustrate the core ideas.\n\n2. The introduction of the expected compression rate (CR) as a measurable quantity connecting diffusion dynamics to robustness is elegant and potentially generalizable to other generative purification systems."}, "weaknesses": {"value": "1. In practical scenarios, an attacker cannot fix the random noise in the defender's diffusion model. The ability to defend against adversarial attacks through randomness is precisely one of the major highlights of diffusion-based purification. However, the paper states \"we focus on understanding robustness improvements in diffusion models without randomness.\" The paper's conclusions may not be applicable to diffusion models with randomness, making them far from practical reality. The paper should verify whether the conclusions hold under diffusion models with randomness (with EOT).\n\n2. Figure 4 suggests that diffusion models perform strong compression off-manifold and weak compression on-manifold. However, Figure S4 shows that clean accuracy also decreases rapidly as the compression rate decreases, indicating that on-manifold are also strongly compressed, which contradicts the conclusion in Figure 4. This suggests that high compression rates may merely be a manifestation of overfitting in the diffusion model.\n\n3. Some ideas (e.g., deterministic evaluation and fixed randomness settings) are closely related to prior work such as DW-Box (Liu et al., 2025). The paper could better clarify its novelty and distinction from concurrent findings.\n\n4. **Limited practical guidance:** While the paper identifies compression as the key mechanism, it provides limited actionable insights for designing better purification systems beyond the two criteria mentioned in the discussion (high clean accuracy and strong compression). For instance, how can one directly optimize for compression during training? Are there architectural choices that promote better compression properties?"}, "questions": {"value": "Can you provide purified image example with different compression rate? Does the lower compression rate means the worse visual quailty?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Av8KcSJVXh", "forum": "P0XgfEmceK", "replyto": "P0XgfEmceK", "signatures": ["ICLR.cc/2026/Conference/Submission23599/Reviewer_EPK2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23599/Reviewer_EPK2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23599/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898119258, "cdate": 1761898119258, "tmdate": 1762942730260, "mdate": 1762942730260, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how diffusion models improve adversarial robustness through purification. Contrary to the common belief that purification \"denoises\" adversarial examples closer to clean images, the authors find that diffusion models actually increase the distance to clean samples. They argue that the robustness gain comes from compression of the image space, not from alignment with clean data. The authors propose a compression rate (CR) metric and show a sigmoidal relationship between CR and adversarial robustness under fixed randomness. Theoretical analysis further supports that diffusion models compress off-manifold perturbations while preserving on-manifold structure."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tOriginality: The paper challenges two prevalent intuitive hypotheses regarding diffusion models' adversarial robustness and proposes a novel image space compression framework. The introduced compression rate (CR) and its sigmoidal relationship with robustness are original findings.\n2.\tQuality: Extensive experiments across datasets, attacks, and sampling methods support the claims.\n3.\tClarity: The paper is clearly written and well-structured, with intuitive presentations of data and results that facilitate understanding.\n4.\tSignificance: The work provides a principled understanding of diffusion-based purification mechanisms and offers practical insights for designing more robust models, making it a valuable contribution to the field."}, "weaknesses": {"value": "1.\tInsufficient Analysis of Sampling Methods: The paper lacks a thorough comparative analysis of the compression rates and robustness of sampling techniques, such as VPSDE (DDPM++) [1] and DPEDM [2]. A more in-depth evaluation of these methods would strengthen the empirical contributions of the work.\n2.\tLack of Semantic Similarity Analysis: While the paper discusses the increase in distance measures and emphasizes perceptual similarity using SSIM, it does not investigate semantic similarity. It is recommended to include CLIP-based similarity metrics to assess whether the outputs of diffusion models are semantically closer to the clean images.\n3.\tUnverified Manifold Hypothesis: The theoretical analysis is grounded in the assumption of a low-dimensional manifold structure, yet this hypothesis is not empirically validated using real image data. \n4.\tIncomplete Visualization: The compelling relationship in Figure 3 could be further strengthened by incorporating all data points from Table 3. Including more DDIM results would also help better illustrate the generalizability of the sigmoidal trend across different model configurations.\n\n\n[1] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations.\n[2] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. Advances in Neural Information Processing Systems, 35:26565–26577, 2022."}, "questions": {"value": "1.\tHow does the compression rate (CR) metric behave beyond the infinitesimal perturbation regime? Does the sigmoidal relationship between CR and adversarial robustness remain valid for larger perturbation magnitudes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JkRYnQr7vl", "forum": "P0XgfEmceK", "replyto": "P0XgfEmceK", "signatures": ["ICLR.cc/2026/Conference/Submission23599/Reviewer_rBUd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23599/Reviewer_rBUd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23599/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928273850, "cdate": 1761928273850, "tmdate": 1762942730041, "mdate": 1762942730041, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}