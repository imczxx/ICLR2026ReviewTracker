{"id": "t33kMzEAg8", "number": 20430, "cdate": 1758306046081, "mdate": 1763589118381, "content": {"title": "SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs", "abstract": "Recent work shows that, beyond discrete reasoning through explicit chain-of-thought steps, which are limited by the boundaries of natural languages, large language models (LLMs) can also reason continuously in latent space, allowing richer information per step and thereby improving token efficiency. Despite this promise, latent reasoning still faces two challenges, especially in training-free settings: 1) purely latent reasoning broadens the search distribution by maintaining multiple implicit paths, which diffuses probability mass, introduces noise, and impedes convergence to a single high-confidence solution, thereby hurting accuracy; and 2) overthinking persists even without explicit text, wasting tokens and degrading efficiency. To address these issues, we introduce SwiReasoning, a training-free framework for LLM reasoning which features two key innovations: 1) SwiReasoning dynamically switches between explicit and latent reasoning, guided by block-wise confidence estimated from entropy trends in next-token distributions, to balance exploration and exploitation and promote timely convergence. 2) By limiting the maximum number of thinking-block switches, SwiReasoning curbs overthinking and improves token efficiency across varying problem difficulties. On widely used mathematics and STEM benchmarks, SwiReasoning consistently improves average accuracy by 1.5%–2.8% across reasoning LLMs of different model families and scales. Furthermore, under constrained budgets, SwiReasoning improves average token efficiency by 56%-79%, with larger gains as budgets tighten. The code will be released publicly.", "tldr": "SwiReasoning is a training-free framework for LLM reasoning that dynamically switches between explicit and latent thinking, plus a switch count control mechanism to suppress overthinking.", "keywords": ["LLM", "Reasoning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/169d32898eb1c811baa982c0e6775730bd54cfdc.pdf", "supplementary_material": "/attachment/b3f25e59fb2e29b76a70faa26b83fbc1cfb5b1fc.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents **SWiReasoning**, a training-free framework that dynamically switches between **explicit (token-based)** and **latent (hidden-space)** reasoning based on entropy-derived confidence trends. A switch-count control prevents overthinking, improving both accuracy and token efficiency. Across multiple math and STEM reasoning benchmarks (GSM8K, Math500, AIME24/25, GPQA) and three reasoning LLMs (Qwen3-8B, Qwen3-1.7B, DeepSeek-R1), the method yields +1.5–2.8% Pass@1 improvement and up to +80% token efficiency gains without retraining."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **Practical and training-free**: Improves reasoning efficiency entirely at inference time.  \n- **Comprehensive experiments**: Consistent gains across models and reasoning benchmarks.  \n- **Well-analyzed switching mechanism**: Includes ablations on window size, confidence, and signal mixing.  \n- **Clear motivation**: Tackles overthinking and token inefficiency in CoT reasoning."}, "weaknesses": {"value": "- **Moderate novelty**: Combines existing ideas (latent reasoning + token control) with minor algorithmic extensions.  \n- **Pipeline complexity**: The overall system involves multiple heuristic components (entropy tracking, switching windows, signal mixing), making the pipeline heavy and less theoretically elegant.  \n- **System-oriented nature**: The contribution is more of a practical inference-time system design than a fundamentally new reasoning principle.  \n- **Marginal improvement**: Accuracy gains are modest given the added complexity."}, "questions": {"value": "1. How robust is the entropy-based switching to unseen data or noisy prompts?  \n2. Could the switching mechanism be learned rather than manually tuned?  \n3. How does this compare to dynamic decoding methods such as COCONUT or Long⊗Short?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "T45NKr2Pcx", "forum": "t33kMzEAg8", "replyto": "t33kMzEAg8", "signatures": ["ICLR.cc/2026/Conference/Submission20430/Reviewer_JcUf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20430/Reviewer_JcUf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20430/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761889998030, "cdate": 1761889998030, "tmdate": 1762933873831, "mdate": 1762933873831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SWIREASONING, a training-free framework that dynamically switches between explicit and latent reasoning based on entropy-driven confidence signals in the next-token distribution. The key idea is that staying purely in latent space can diffuse probability mass and cause slow or noisy convergence, so the model alternates modes to balance exploration and exploitation. A second mechanism caps the number of thinking-block switches to reduce “overthinking” and save tokens. The authors conduct some experiments and show the performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper proposes a method that flexibly combines latent reasoning with explicit reasoning, effectively reusing intermediate embeddings as inputs to enable denser thinking steps.\n2.\tThe authors provide experiments on several standard reasoning benchmarks to demonstrate the applicability of the approach."}, "weaknesses": {"value": "1.\tThe overall performance gains are relatively small, and the efficiency story is not fully convincing — a clearer, more direct metric is needed, and Appendix Table 8 suggests that long generations are still required to reach good accuracy.\n2.\tThe paper should further explain why switching between latent and explicit modes improves performance, and clarify whether (and how) the latent trajectories can be decoded or inspected in text for interpretability.\n3.\tThe experimental scope is limited; results on larger models and on other task types (e.g., coding), where latent reasoning may be less naturally applicable, would make the empirical claims more convincing."}, "questions": {"value": "Please chek the weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "OGEfV2qZBz", "forum": "t33kMzEAg8", "replyto": "t33kMzEAg8", "signatures": ["ICLR.cc/2026/Conference/Submission20430/Reviewer_BFnL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20430/Reviewer_BFnL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20430/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762128196160, "cdate": 1762128196160, "tmdate": 1762933873211, "mdate": 1762933873211, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SwiReasoning, a training-free framework for improving reasoning in large language models by dynamically switching between explicit chain-of-thought (CoT) and latent reasoning modes. The core innovation lies in using entropy trends from next-token distributions as block-wise confidence signals to guide mode transitions: when confidence increases (entropy drops), the system switches to explicit reasoning to consolidate progress; when uncertainty persists (entropy rises), it switches to latent reasoning for exploration. Additionally, a switch count control mechanism limits the maximum number of mode transitions and enables early answer generation at natural checkpoints, suppressing overthinking and improving token efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The insight that reasoning should adaptively switch based on confidence is intuitive yet underexplored in training-free settings, thereby making the idea and approach of the paper novel. \n\n2. The evaluation is comprehensive and spans multiple model families, scales (1.7B–8B parameters), training paradigms, and five diverse benchmarks. The consistency of improvements across all settings (13 out of 15 evaluations achieve highest token efficiency) provides strong empirical support.\n\n3. The methodology is well-structured with intuitive explanations, formal algorithmic descriptions (Algorithm 1), and effective visualizations (Figures 1–5). The paper is well written."}, "weaknesses": {"value": "Enumerating a few weaknesses here\n\n1. While the convergence and termination triggers are intuitive, the specific thresholds (½Cmax for convergence, Cmax for termination) appear arbitrary. Why these specific fractions? How sensitive is performance to these choices? The paper doesn't ablate these design decisions.\n\n2. Limited failure case analysis and the modes of failure. It would be good to add the cases or categories of questions where the proposed approach fails. \n\n3. The results reported for soft thinking approach appear to be lower than standard CoT, which is contrary to the claims in the original Soft-thinking paper. This raises concerns about implementation correctness and whether comparisons are on equal footing."}, "questions": {"value": "1. How is entropy computed during latent steps when no explicit token is selected? Is it from the softmax over the last hidden state projected through the LM head?\n\n2. In ablation Table 3, window size 512 is optimal. Given typical generation lengths (e.g., ~2000 tokens for GSM8K), does this mean most problems only switch 2–4 times? If so, is this really \"dynamic\" switching, or just a staged approach (latent -> explicit -> latent -> explicit) Can you show histograms of actual switch counts across problem difficulties?\n\n3. The paper claims \"Pareto-superior\" results. However, in some cases (e.g., AIME24 in Fig. 4), CoT appears to match or exceed SwiReasoning's accuracy at similar token budgets. Can you clarify where strict Pareto dominance holds vs. where there are trade-offs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dWPG3dYIa0", "forum": "t33kMzEAg8", "replyto": "t33kMzEAg8", "signatures": ["ICLR.cc/2026/Conference/Submission20430/Reviewer_eVQp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20430/Reviewer_eVQp"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20430/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762147237193, "cdate": 1762147237193, "tmdate": 1762933872126, "mdate": 1762933872126, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SwiReasoning, a training-free framework for LLM reasoning that dynamically switches between explicit chain-of-thought and latent reasoning modes. The switching is guided by block-wise confidence estimated from entropy trends in next-token distributions. The method also includes a switch count controller to suppress overthinking and improve token efficiency. Experiments on mathematical and STEM benchmarks show consistent accuracy improvements and token efficiency gains across different model families and sizes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The idea of dynamically switching between explicit and latent reasoning based on confidence signals is intuitive and addresses limitations of pure latent reasoning approaches.\n- The experimental evaluation is comprehensive across multiple models and benchmarks, including various token budget settings and Pass@k analysis that shows the method overall improves the performance with better efficiency.\n- The ablation studies analyze key design choices and provide insights into how different components contribute to performance."}, "weaknesses": {"value": "- The method introduces many heuristic design choices and hyperparameters (window sizes W_E→L and W_L→E, signal mixing coefficients α₀ and β₀, switch count limits C_max, convergence/termination triggers), and it appears from the ablations that these are tuned on the test sets, which raises concerns about generalization and fair comparison.\n\n- It seems unclear whether the latent reasoning mode genuinely enables the claimed \"exploration\" of multiple reasoning paths, since Soft-Thinking simply weights tokens by probability, and the pretrained LLM likely still concentrates probability mass on similar natural language tokens. It would be beneficial to provide some analysis of the probability distributions within the latent tokens or other evidence that meaningful exploration is occurring beyond what explicit sampling would achieve.\n\n- There are quite a few citations that are wrong and appear to be LLM-hallucinated, even including the most important \"Soft-Thinking\" paper that this work is primarily built on top of - the citation in the draft is ```Bowen Zhang, Yanzhuo Li, Shuohang Wang, Yu Tu, Jason Wei, Ashish Vaswani, Shikun Liu, Chenlu Yu, Deli Chen, Hongyi Li, Zhihua Zhang, and Chen Liang. Soft thinking: Training-free\nlatent reasoning for large language models.``` while the actual one should be ```Zhen Zhang, Xuehai He, Weixiang Yan, Ao Shen, Chenyang Zhao, Shuohang Wang, Yelong Shen, Xin Eric Wang. Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space```."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vgfL5oaxqP", "forum": "t33kMzEAg8", "replyto": "t33kMzEAg8", "signatures": ["ICLR.cc/2026/Conference/Submission20430/Reviewer_dZdK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20430/Reviewer_dZdK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20430/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762203770600, "cdate": 1762203770600, "tmdate": 1762933871273, "mdate": 1762933871273, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Summary\nThis paper introduces SWIREASONING, a training-free reasoning approach that integrates latent and explicit chain-of-thought (CoT) modes. Instead of committing to token-level reasoning at every step, the method forms latent reasoning states via weighted token embeddings, allowing the model to retain uncertainty and explore multiple hidden trajectories.\nA block-wise entropy reference is used as a switching criterion: when the entropy decreases (confidence rises), the model switches from latent to explicit reasoning immediately; when entropy increases, switching from explicit back to latent requires a dwell window to prevent oscillation. To signal mode transitions more explicitly, the method injects fused embeddings of  < think > / </ think > tokens during switch steps.\nAdditionally, switch counters and termination triggers are employed to avoid unbounded “over-thinking” and encourage timely final answer production.\nExperiments show that, particularly for smaller models (≤8B) and token-budget-constrained settings, SWIREASONING delivers higher reasoning accuracy and efficiency compared to standard CoT and soft-thinking baselines. Ablation studies on signal mixing and dwell window length further support the design choices."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. The approach does not require model updates and can be applied directly at inference time, making it practical for deployment on existing models.\n2.The entropy based switching between latent and explicit reasoning, combined with a dwell window to avoid oscillation, is conceptually simple and computationally lightweight.\n3. The method shows consistent gains over standard CoT on math reasoning benchmarks, particularly for ≤8B models under constrained token budgets, with ablation studies supporting key design choices."}, "weaknesses": {"value": "1. Latent reasoning contribution unclear at small budgets\nIn short-budget settings, the method typically switches to explicit mode immediately and does not enter latent reasoning due to the dwell window. Yet it still outperforms CoT, suggesting the improvements largely come from early confidence-based stopping and < think >/< /think > embedding conditioning rather than latent reasoning itself. Ablation isolating these effects would clarify the true source of gains.\n2. Scope limited to math-focused tasks\nExperiments are concentrated on math reasoning, and it remains unclear whether the method benefits broader domains (e.g., multi-hop QA, code, commonsense reasoning). Reasoning dynamics can differ significantly across tasks.\n3. Large-model scaling and SoftThinking baseline discrepancy\nThe original SoftThinking results indicate improvements over CoT primarily for ≥32B models. Here, the reproduced SoftThink baseline is weaker than CoT on ≤8B models. Given that SwiReasoning is training-free, extending evaluation to ≥32B models would help verify baseline fidelity and clarify whether the proposed method scales beyond the small-model setting.\nHeuristic hyperparameters + no runtime reporting\n4.Heuristic switching and lack of runtime analysis\nThe switching logic, dwell window, and mixing schedule are manually designed. While intuitive, their tuning behavior across models and tasks remains unclear, and no wall-clock or FLOP analysis is provided, making deployment efficiency uncertain."}, "questions": {"value": "1 In small budget settings, the model often does not actually enter latent mode due to the dwell window, yet achieves strong gains. Can you provide ablations where latent reasoning is disabled but the early-exit and <think> conditioning remain, to isolate the effect of latent reasoning itself?\n\n2 Token efficiency does not necessarily imply inference-time efficiency. Can you report wall-clock latency or FLOPs vs CoT and SoftThinking to demonstrate practical gains?\n\n3 The SoftThinking baseline underperforms CoT in your ≤8B experiments, whereas the original paper shows gains mainly at ≥32B scale. Can you confirm your implementation matches the original, and provide results on a ≥32B model to ensure fairness?\n\n4 Could you clarify whether your latent update uses the full vocabulary distribution or a top-k truncation (as in SoftThinking)?\n\n5 Could you provide a systematic component-wise ablation (turning each mechanism on/off) to quantify the marginal contribution of:  (i) dwell window (incl. 0) and asymmetry, (ii) < think >/< /think > mixing, (iii) switch-count cap/termination triggers。"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8sN7g6TXom", "forum": "t33kMzEAg8", "replyto": "t33kMzEAg8", "signatures": ["ICLR.cc/2026/Conference/Submission20430/Reviewer_hrDS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20430/Reviewer_hrDS"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission20430/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762217903555, "cdate": 1762217903555, "tmdate": 1762933870628, "mdate": 1762933870628, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}