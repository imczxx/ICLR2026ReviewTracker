{"id": "gkf81Ciu9K", "number": 3659, "cdate": 1757492573550, "mdate": 1763740189274, "content": {"title": "Learning Hierarchical Domain Models through Environment-Grounded Interaction", "abstract": "Domain models enable autonomous agents to solve long-horizon tasks by producing interpretable plans. However, in open-world environments, a single general domain model cannot capture the variety of tasks, so agents must generate suitable task-specific models on the fly. Large Language Models (LLMs), with their implicit common knowledge, can generate such domains, but suffer from high error rates that limit their applicability. Hence, related work relies on extensive human feedback or prior knowledge, which undermines autonomous, open-world deployment. In this work, we propose LODGE, a framework for autonomous domain learning from LLMs and environment grounding. LODGE builds on hierarchical abstractions and automated simulations to identify and correct inconsistencies between abstraction layers and between the model and environment. Our framework is task-agnostic, as it generates predicates, operators, and their preconditions and effects, while only assuming access to a simulator and a set of generic, executable low-level skills. Experiments on two International Planning Competition ( IPC) domains and a robotic assembly domain show that LODGE yields more accurate domain models and higher task success than existing methods, requiring remarkably few environment interactions and no human feedback or demonstrations.", "tldr": "", "keywords": ["Domain Model Learning", "Neurosymbolic AI", "LLMs"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/50cc28ef7d3a8697b9aa0c531bb0e7b6ecbdf7e6.pdf", "supplementary_material": "/attachment/c5e48188e18da1b65c73514c7e2d054b1c192fea.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces LODGE, a framework for learning hierarchical planning domain models using LLMs and environment-grounded interaction. LODGE autonomously generates, refines, and empirically grounds domain knowledge through hierarchical abstraction, operator decomposition, predicate invention, and data-driven learning of predicate classifiers. Its core novelty lies in avoiding reliance on human feedback or prior skill annotation. The framework is evaluated on two International Planning Competition domains and a robotic assembly benchmark."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper investigates an important problem: how to enable agents to automatically generalize to new domains without human annotations.\n\n2. The idea is sound, and the experimental results demonstrate its effectiveness."}, "weaknesses": {"value": "1. Scalability: Can LODGE be extended to more complex tasks or dynamically changing environments? How does it handle partially observed environments? Moreover, the experiments in this paper are conducted in simulated environments, which allow LODGE to perform frequent trial and error. How can LODGE be adapted to the real world, where trial-and-error costs are much higher and the environment is difficult to reset?\n\n2. Dependence on model capability: From the experimental results, it can be seen that although a self-correction mechanism is proposed, the LLM may still generate incorrect operators, predicates, or code, particularly when using smaller models (e.g., GPT-4o mini), which struggle with handling \"side effects\". In addition, the classifier's learning relies on pseudo-labels generated by the VLM. If the VLM labels are inaccurate, they could mislead the classifier’s optimization.\n\n3. Although LODGE does not rely on manual annotations, the feedback process typically incurs a large token cost. Could the authors compare the total token consumption of LODGE with that of the baselines (e.g., Mahdavi)?\n\nIf the authors can address these points, I would raise my score."}, "questions": {"value": "1. Can LODGE be combined with manual annotations, for example, using a small amount of human-labeled data to improve its learning efficiency?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vC9SKFP1x7", "forum": "gkf81Ciu9K", "replyto": "gkf81Ciu9K", "signatures": ["ICLR.cc/2026/Conference/Submission3659/Reviewer_p9vb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3659/Reviewer_p9vb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3659/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761750715860, "cdate": 1761750715860, "tmdate": 1762916905008, "mdate": 1762916905008, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an autonomous domain learning framework that generates hierarchical PDDL domains and corrects inconsistencies using environment feedback. The proposed method is evaluated on two IPC domains and a robotic assembly domain. While the overall idea is intriguing, the novelties are weak in general. Critical experiments are missing as detailed in the following weakness session."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well written overall. The messages are conveyed clearly.\n2. The proposed hierarchical domain models can be interesting if supported by more thorough experiments."}, "weaknesses": {"value": "The three novelties claimed by this paper are fairly weak for the following reasons:\n\n1. Novelty 1 \"Domain learning from planning feedback\": While this paper claims only minimum prior knowledge is required, the initial domain and some critical predicates are provided by the user as shown in Appendix H1. The idea of using model-based environment feedback to optimize predicates is similar to the prior paper [1], which compromises the novelty of this paper.\n\n2. Novelty 2 \"Hierarchical domain models\": This paper proposes a hierarchical domain generation framework that iteratively breakdown the high-level operator (e.g., grasp(bulb)) to lower-level operators like approach(bulb) etc. However, using multi-level operators with finer abstraction will significantly increase the complexity of PDDL searching, which might degrade the success rate of task planning. Trade-off between abstraction levels and planning success is not discussed. There is no experiment result to support that the proposed hierarchical PDDL domain promote planning success rate.\n\n3. Novel 3 \"Predicate invention and online classifier learning\": The idea is very close to the paper [1]. Although this paper uses slightly-different pseudo-labeled environment interaction, it is not compared to the model-based feedback used in [1]. Critical ablation study is missing. \n\n4. Real robot experiment is missing. Given the noise in object localization and less accurate feedback from the proposed pseudo-labeled environment interactions, the proposed method will face serious challenges in real robot experiment.\n\n5. Typos and grammar errors:\nLine 253: \".If\"\nLine 283, 284: \"f1 score\" should be \"F1 score\"\n\n[1] VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning https://arxiv.org/abs/2410.23156"}, "questions": {"value": "1. Can you provide experiment results of planning success rate using finer operators from the proposed hierarchical domain versus high-level operators?\n2. Only predicate grounding results are provided in Table 2. Can you provide planning success rates of the proposed method versus InterPreT and Pix2Pred?\n3. Have you tried to run any real robot experiment?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nArdX1azAs", "forum": "gkf81Ciu9K", "replyto": "gkf81Ciu9K", "signatures": ["ICLR.cc/2026/Conference/Submission3659/Reviewer_MNNh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3659/Reviewer_MNNh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3659/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761849455458, "cdate": 1761849455458, "tmdate": 1762916903907, "mdate": 1762916903907, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors propose LODGE, a framework that uses LLMs to generate domain models in a hierarchical way for planning.  It iteratively decomposes high-level task descriptions into low-level robot skills, invents and refines predicates via Python-based classifiers, and repairs model errors through execution validation. Experiments on 3 domains show that LODGE achieves higher task success rates than baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper aims to automatically generate planning domains to reduce manual engineering efforts, which is a valuable goal for the field. The proposed framework, which contains hierarchical generation and error recovery, is a reasonable design that can effectively improve the accuracy of the generated domain models.\n2. The paper is well organized."}, "weaknesses": {"value": "1. The experimental evaluation is limited. Although the FurnitureBench dataset contains multiple assembly tasks, the experiments only report results for the lamp assembly case. To demonstrate the robustness and generalizability of the proposed approach, experiments should be conducted across all available task categories in FurnitureBench. In addition, more tasks, such as those introduced in [1], should be used to further evaluate the method’s general applicability.\n2. The paper overlooks several closely related studies that explore the integration of large language models (LLMs) with task planning. For example, [1] proposes leveraging LLMs to infer object affordances, dynamically generate affordance-based domain and problem files, and solve them via a classical planner. [2, 3] discuss how LLMs can refine domain models for open-world planning.\n3. The paper should report quantitative metrics on the number of LLM invocations required per task. Such statistics are essential for understanding the efficiency of the proposed approach.\n\nReference:\n[1] AutoGPT+P: Affordance-based Task Planning using Large Language Models, RSS 2024.\n[2] Language-augmented Symbolic Planner for Open-world Task Planning, RSS 2024.\n[3] Integrating Action Knowledge and LLMs for Task Planning and Situation Handling in Open Worlds, Autonomous Robots 2023."}, "questions": {"value": "1. If an execution failure arises from low-level control errors (rather than incorrect domain models), would the proposed recovery module still be triggered? If so, does this risk incorrectly modify a valid domain model?\n2. If the system is allowed to interact with the environment and re-plan without any limits, is it possible to generate a fully accurate domain model? In that case, how many LLM invocations would be required on average?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Q5tVvc3fN4", "forum": "gkf81Ciu9K", "replyto": "gkf81Ciu9K", "signatures": ["ICLR.cc/2026/Conference/Submission3659/Reviewer_3u2N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3659/Reviewer_3u2N"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3659/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942547196, "cdate": 1761942547196, "tmdate": 1762916903678, "mdate": 1762916903678, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes LODGE, a framework designed to refine planning models generated using LLMs. The paper particularly focuses on robotics settings, where the system has access to the low-level state and a set of primitive actions. Here, the grounding of the predicates generated by the system is performed through classifiers coded up as Python functions, which are refined via a dataset generated through pseudo-labeling and hyper-parameter tuning. They evaluate their method on IPC domains and a robotic domain, and also perform an ablation study."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is looking at an important problem, and something that can't currently be solved by simply calling an LLM. The automatic generation of valid symbolic models can allow the use of provably sound planners in many mission-critical settings. The evaluation also shows that the proposed system does provide some advantages over some existing alternatives."}, "weaknesses": {"value": "The method described here is just relying on repeated invocation of LLMs to perform refinement and model generation (and in the case of pseudo-labeling, a VLM). The hope is that, given the right feedback, the LLM should be able to find the right models and symbols. However, apart from the limited empirical evidence they can show, I cannot imagine the approach being able to provide any kind of  theoretical guarantees. \n\nMore importantly, the paper completely overlooks many of the most important aspects of hierarchical planning, many of which are quite relevant to the paper at hand. It is very unfortunate that the authors have chosen to overlook all of them and have tried to rely on their own simplistic notions of hierarchical planning. To start with, I would recommend that the authors start by looking at hierarchical task networks. One could see a textbook-level introduction to these models in most introductory planning books, but the book “Automated Planning and Acting” [1] is an excellent starting point. A particularly important notion that shows up within this context is the idea that a higher-level task could be refined into multiple possible sequences of atomic actions. While the planning literature also points to the notion of macros [2], where each macro refines into a single unique action sequence, they cannot capture the kind of hierarchies the paper alludes to. For example, if one wants to capture an abstraction action of picking up an object. The refinement of this action could potentially involve multiple kinds of grasp positions, and as such, corresponds to different kinds of refinements. However, once you have such refinements, a subset relationship isn’t enough. You would need more complex mechanisms to capture the semantics of the intermediate actions. Here are some papers that provide some sample methods to associate semantics to such abstractions [3,4]. \n\nI believe the paper looks at an interesting problem, but the work itself is quite preliminary, and the authors seem to overlook a lot of foundational work in hierarchical planning. I would recommend that the authors read up on this larger body of literature and try to place their work in this broader context.\n\nSmaller comments:\nThe paper keeps talking about interpretability. However, this is never justified or expounded upon. I would probably leave out claims like planning leads to “interpretable plans”, particularly from the motivation part of the work.\n\n[1] Ghallab, Malik, Dana Nau, and Paolo Traverso. Automated planning and acting. Cambridge University Press, 2016.\n\n[2] Botea, Adi, Martin Müller, and Jonathan Schaeffer. \"Learning partial-order macros from solutions.\" Proceedings of the Fifteenth International Conference on Automated Planning and Scheduling. 2005.\n\n[3] Marthi, Bhaskara, Stuart Russell, and Jason Andrew Wolfe. \"Angelic Semantics for High-Level Actions.\" ICAPS. 2007.\n\n[4] Srivastava, Siddharth, Stuart Russell, and Alessandro Pinto. \"Metaphysics of planning domain descriptions.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 30. No. 1. 2016."}, "questions": {"value": "I would request the authors to respond to my concerns regarding the lack of theoretical guarantees and the inability to support multiple refinements of higher-level actions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "znn7YBd95M", "forum": "gkf81Ciu9K", "replyto": "gkf81Ciu9K", "signatures": ["ICLR.cc/2026/Conference/Submission3659/Reviewer_PUwn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3659/Reviewer_PUwn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3659/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963414307, "cdate": 1761963414307, "tmdate": 1762916903407, "mdate": 1762916903407, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}