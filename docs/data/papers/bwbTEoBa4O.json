{"id": "bwbTEoBa4O", "number": 2508, "cdate": 1757128681310, "mdate": 1759898144076, "content": {"title": "PartnerMAS: An LLM Hierarchical Multi-Agent Framework for Business Partner Selection on High-Dimensional Features", "abstract": "High-dimensional decision-making tasks, such as business partner selection, involve evaluating large candidate pools with heterogeneous numerical, categorical, and textual features. While large language models (LLMs) offer strong in-context reasoning capabilities, single-agent or debate-style systems often struggle with scalability and consistency in such settings. We propose \\name, a hierarchical multi-agent framework that decomposes evaluation into three layers: a Planner Agent that designs strategies, Specialized Agents that perform role-specific assessments, and a Supervisor Agent that integrates their outputs. To support systematic evaluation, we also introduce a curated benchmark dataset of venture capital co-investments, featuring diverse firm attributes and ground-truth syndicates. Across 140 cases, \\name consistently outperforms single-agent and debate-based multi-agent baselines, achieving up to 10–15\\% higher match rates. Analysis of agent reasoning shows that planners are most responsive to domain-informed prompts, specialists produce complementary feature coverage, and supervisors play an important role in aggregation. Our findings demonstrate that structured collaboration among LLM agents can generate more robust outcomes than scaling individual models, highlighting \\name as a promising framework for high-dimensional decision-making in data-rich domains.\nOur implementation is available at https://anonymous.4open.science/r/Partner-MAS-7DCE.", "tldr": "", "keywords": ["Multi-agent Systems", "Large Language Models", "Business Partner Selection"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/61734a450e93e51767a705966d3761430cce53c7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the challenge of high-dimensional, heterogeneous decision-making, using business partner selection as a representative task. The authors argue that existing single-agent or simple debate-based multi-agent (MAS) LLM systems struggle with the scalability and consistency required for such complex evaluations.\n\nThe primary contributions are twofold:\n(1) A new benchmark dataset. The authors curated a dataset of 140 venture capital co-investment scenarios, featuring a large candidate pool and diverse (numerical, categorical, textual) features.\n(2) The PARTNERMAS framework. A novel hierarchical, three-layer multi-agent system designed to decompose and manage the evaluation process.\n\nThe PARTNERMAS architecture consists of:\n(1) A Planner Agent: Analyzes the task context to design an evaluation strategy and configure a team of specialists.\n(2) Specialized Agents: Each agent is assigned a specific role and evaluates the entire candidate pool from its narrow perspective, implicitly performing feature selection and producing a ranked shortlist.\n(3) A Supervisor Agent: Aggregates the multiple shortlists from the SAs. It first identifies consensus picks and then uses strategic guidance and agent importance weighting to resolve conflicts and produce the final shortlist."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper tackles a practical, high-stakes problem that is an excellent fit for LLM-based reasoning. The proposed PARTNERMAS architecture is well-motivated and logical. The decomposition of the problem into \"Planner,\" \"Specialist,\" and \"Supervisor\" roles mirrors high-level human expert workflows and is a clean, valuable contribution.\n\nThe strongest result is that a well-structured MAS (PARTNERMAS) using a smaller, more efficient model can outperform a larger, more expensive model in a simpler configuration (Figs 2 & 3). This \"architecture over scale\" finding is an important one for the field, highlighting the value of structured collaboration versus brute-force scaling."}, "weaknesses": {"value": "A dataset of 140 cases is very small. While curating such data is difficult, this small sample size calls into question the statistical robustness of the 10-15% improvement. It is hard to be confident that the results will generalize, especially given the high variance in individual specialist agent performance (Fig 5). The dataset is also confined to a single, niche domain (US VC).\n\nThe Supervisor is identified as the most critical and failure-prone component, yet its mechanism is the most opaque. The paper describes a \"Consensus\" and \"Conflict Resolution\" step (Sec 3.2), but the prompts in Appendix F.4 show three distinct potential strategies: \"by Importance,\" \"by Weight,\" and \"by Majority Vote.\" The main paper does not specify which of these was used for the main experiments."}, "questions": {"value": "Your analysis in Table 2 shows the Planner's strategy is not adaptive to the specific case context. Is this the intended behavior? Have you considered alternative prompting strategies (e.g., chain-of-thought, few-shot) to encourage the Planner to dynamically select or even generate novel specialist roles based on the specific target company's profile.\n\nGiven the small dataset of 140 cases and the high variance in specialist agent performance (e.g., \"Risk & Compliance\" at 83% vs. \"Investment Stage\" at 38% for gpt-4.1-mini), how concerned are you about overfitting? Is it possible that the \"best\" supervisor strategy is simply the one that, by chance, happened to correctly weight the high-performing (but lucky?) specialists for this specific set of 140 cases?\n\nCould you please clarify the \"feature selection\" mechanism used by the Specialized Agents?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "epkki2AIlt", "forum": "bwbTEoBa4O", "replyto": "bwbTEoBa4O", "signatures": ["ICLR.cc/2026/Conference/Submission2508/Reviewer_pLGN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2508/Reviewer_pLGN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966037354, "cdate": 1761966037354, "tmdate": 1762916260193, "mdate": 1762916260193, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Unified Response on Evaluation Metrics"}, "comment": {"value": "We thank the reviewers for questions regarding evaluation metrics. We provide a unified response below.\n\n**Retrieval-Based Metrics (Accuracy, Recall, Precision, F1)**\n\nOur task is formulated as a fixed-size shortlist retrieval problem (Section 3.1, line 154). We mention the one-third shortlist ratio in Section 3.1, but we agree that the connection between this ratio and the evaluation metrics was not clearly explained. In practice, our setup follows a common business shortlisting heuristic where the ground-truth co-investor set, the shortlist, and the initial candidate pool follow an approximate 1:3:9 layering structure. Concretely, using the notation in Eq. (1) and Eq. (2), for each case, if the ground-truth syndicate has |G| firms, the candidate pool size is roughly 9|G|, and the shortlist size is 3|G|. This yields the relation that $m=3|F|=9|G|$, where $m$ is the entire number of candidates.\n\nUnder this fixed-ratio design, all retrieval metrics become tightly coupled.\nMatch_rate = Recall = $|F \\cap G|/|G|$, Precision=$|F \\cap G|/|F|=\\frac{1}{3} \\text{Recall}$.\n\nAs a result, precision, recall, and F1 score do not provide different conclusions—they follow the exact same trend. This is why Match Rate (recall) is fully representative of retrieval performance in our setup.\nWe have added this explanation more clearly in our updated manuscript.\n\n**Ranking-Based Metrics (MRR, nDCG@3, nDCG@5)**\nOur primary formulation treats business partner selection as a retrieval task, where the goal is to correctly include the true co-investors in the shortlist regardless of order (Section 3.1). In real VC workflows, shortlisting is set-based, the list is typically handed to human experts, and the final decisions depend on expert review rather than the internal ranking produced by an automated system. However, because our system outputs a list rather than an unordered set, ranking-based metrics can definitely be computed. Following the reviewers’ suggestions, we therefore report MRR, nDCG@3, and nDCG@5 as complementary measures. These ranking metrics exhibit the same performance trends as our retrieval metrics, and they further confirm the advantage of PartnerMAS over alternative baselines. Below we provide the results on there backbones as an example. All comprehensive results are added in the Appendix of our updated manuscript.\n\n***gpt-5-mini (medium effort)***\n\n| Setting | Match Rate | MRR | nDCG@3 | nDCG@5 |\n|---|---|---|---|---|\n| Single – w/o Bus. Guide | 54.8% | 0.455 | 0.265 | 0.318 |\n| Single – w. Bus. Guide | 57.2% | 0.472 | 0.279 | 0.330 |\n| Debate – w/o Bus. Guide | 56.5% | 0.530 | 0.360 | 0.405 |\n| Debate – w. Bus. Guide | 58.4% | 0.555 | 0.345 | 0.395 |\n| PartnerMAS – w/o Bus. Guide | 63.2% | 0.554 | 0.392 | 0.437 |\n| PartnerMAS – w. Bus. Guide | 64.2% | 0.541 | 0.342 | 0.391 |\n\n***gpt-4o-mini***\n| Setting | Match Rate | MRR | nDCG@3 | nDCG@5 |\n|---|---|---|---|---|\n| Single – w/o Bus. Guide | 55.5% | 0.458 | 0.277 | 0.334 |\n| Single – w. Bus. Guide | 57.8% | 0.450 | 0.283 | 0.348 |\n| Debate – w/o Bus. Guide | 55.3% | 0.505 | 0.340 | 0.385 |\n| Debate – w. Bus. Guide | 58.9% | 0.545 | 0.365 | 0.420 |\n| PartnerMAS – w/o Bus. Guide | 61.9% | 0.524 | 0.361 | 0.406 |\n| PartnerMAS – w. Bus. Guide | 64.4% | 0.525 | 0.353 | 0.414 |\n\n\n***gpt-4.1-mini***\n\n| Setting| Match Rate | MRR   | nDCG@3 | nDCG@5 |\n| ----------------------------------- | ---------- | ----- | ------ | ------ |\n| Single – w/o Bus. Guide             | 56.0%     | 0.505 | 0.311  | 0.355  |\n| Single – w. Bus. Guide              | 61.0%     | 0.553 | 0.346  | 0.392  |\n| Debate – w/o Bus. Guide             | 59.1%     | 0.565 | 0.395  | 0.435  |\n| Debate – w. Bus. Guide              | 64.9%     | 0.630 | 0.440  | 0.490  |\n| PartnerMAS – by importance w/o Bus. Guide | 66.1%     | 0.585 | 0.422  | 0.453  |\n| PartnerMAS – by importance w. Bus. Guide  | 71.2%     | 0.654 | 0.461  | 0.509  |\n| PartnerMAS – by majority w. Bus. Guide  | 74.2% | 0.641 | 0.455 | 0.493 |"}}, "id": "eIyslXVjXQ", "forum": "bwbTEoBa4O", "replyto": "bwbTEoBa4O", "signatures": ["ICLR.cc/2026/Conference/Submission2508/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2508/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2508/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763768137131, "cdate": 1763768137131, "tmdate": 1763768137131, "mdate": 1763768137131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PartnerMAS, a hierarchical multi-agent system for business partner selection in high-dimensional settings. The framework decomposes the partner selection task across three layers: (1) a Planner Agent that designs evaluation strategies, (2) Specialized Agents that perform domain-specific assessments, and (3) a Supervisor Agent that aggregates outputs. The authors propose a benchmark dataset of 140 venture capital co-investment cases and demonstrate improvements of 10-15% in match rates over single-agent and debate-based baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper raises an interesting topic about business partner selection. It's a real-world business problem that is underexplored in the MAS. The application to VC co-investment selection is well-motivated and practically relevant.\n\n2. The paper evaluates different LLM backbones and prompt strategies. The author did the ablation study and provided a detailed analysis of agent behavior, feature selection patterns, and component contributions.\n\n3. The author introduces a new VC investment dataset with diverse features (numerical, categorical, textual)."}, "weaknesses": {"value": "1. I have several questions about the evaluation metrics.  Firstly, the Match Rate is essentially recall only. What about other metrics? such as precision. The paper doesn't discuss whether non-matched selections in the shortlist are reasonable alternatives. Secondly, Ground truth is actual co-investors, but this has survivor bias. It doesn't mean they were necessarily the best choices, just that they were selected.\n\n2. I also have concerns about the experiment design part. Firstly, there is a lack of comparison with traditional ML methods. Secondly, Single Agent with k=4 self-reflections vs. MAS with ~4 agents uses similar computation but very different strategies. This doesn't cleanly isolate the benefit of multi-agent collaboration.\n\n3. Business guidance is manually designed with only two conditions tested (with/without). Could the author provides more explaination on this point?\n\n4. Encourage authors to do some failure case analyses. If the proposed framework fails, what consequences will it bring? Or what types of cases are challenging?"}, "questions": {"value": "See in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CR0j92XOQP", "forum": "bwbTEoBa4O", "replyto": "bwbTEoBa4O", "signatures": ["ICLR.cc/2026/Conference/Submission2508/Reviewer_cNaW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2508/Reviewer_cNaW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976224368, "cdate": 1761976224368, "tmdate": 1762916259889, "mdate": 1762916259889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Unified Response on Traditional ML Methods"}, "comment": {"value": "We appreciate the reviewer’s helpful suggestion and agree that adding traditional ML models strengthens the contribution of our work. In response, we have included a set of both supervised and unsupervised machine learning models as additional baselines.\n\n**Supervised ML Methods**:\nAll supervised models follow an 80/20 split for training and testing.\n- *Random Forest*: Constructs an ensemble of decision trees that learn feature-based decision rules and predicts the co-investor probability for test cases by averaging the outputs of all trees.\n- *Logistic Regression*: Uses L2-regularized maximum likelihood estimation to learn model coefficients and predicts the co-investor probability for each candidate in the test set.\n\n**Unsupervised ML Methods**:\n- *KNN (Euclidean)*: Ranks candidates based on Euclidean distance to the lead VC in the feature space, where smaller distances indicate greater similarity.\n- *Cosine Similarity*: Ranks candidates by the cosine similarity of their feature vectors to that of the lead VC, where higher similarity values indicate a closer match.\n- *K-Means Clustering*: Partitions VCs into clusters and selects candidates from the cluster to which the lead VC is assigned.\n\nPerformance is listed below. \n\n| Method | Cases | Match Rate | MRR | NDCG@3 | NDCG@5 |\n|--------|-------|------------|-------|--------|--------|\n| **Supervised Methods** | | | | | |\n| Logistic Regression | 28 | 74.4% | 0.485 | 0.419 | 0.542 |\n| Random Forest | 28 | 74.7% | 0.506 | 0.421 | 0.538 |\n| **Unsupervised Methods** | | | | | |\n| KNN (Euclidean) | 140 | 28.1% | 0.273 | 0.125 | 0.147 |\n| Cosine Similarity | 140 | 42.1% | 0.348 | 0.175 | 0.230 |\n| K-Means Clustering | 140 | 31.0% | 0.289 | 0.142 | 0.173 |\n| **PartnerMAS** | | | | | |\n| gpt-4.1-mini (by importance w/ Bus.) | 140 | 71.2% | 0.654 | 0.461 | 0.509 |\n| gpt-4.1-mini (by majority w/ Bus.) | 140 | 74.2% | 0.641 | 0.455 | 0.493 |\n| gpt-5-nano (by importance w/ Bus.) | 140 | 64.4% | 0.602 | 0.408 | 0.448 |\n\nOur PartnerMAS demonstrates several key advantages over traditional ML methods: \n- No training data required: Unlike supervised methods, our MAS operates in a zero-shot manner. This is crucial in real-world scenarios where companies often cannot access much other VCs' historical data due to confidentiality. \n- Comparable performance: Our best PartnerMAS configuration (gpt-4.1-mini (by majority): 74.17%) achieves match rates comparable to supervised methods and significantly outperform unsupervised methods. This demonstrates that LLM-based reasoning can capture complex co-investment patterns without explicit feature engineering or historical examples. \n- Better Top-K recommendation: Our PartnerMAS outperforms ML methods in ranking metrics in MRR and NDCG@3. \n- Interpretable reasoning: LLM agents can explain their recommendations, unlike black-box ML models, which is important for real-world decision-making process."}}, "id": "rTqDEWNdG7", "forum": "bwbTEoBa4O", "replyto": "bwbTEoBa4O", "signatures": ["ICLR.cc/2026/Conference/Submission2508/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2508/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2508/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763768475810, "cdate": 1763768475810, "tmdate": 1763768475810, "mdate": 1763768475810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a Multi-Agent System (MAS) approach for selecting business partners / co-investors, which are represented by numerical, categorical or textual features. The approach consists of a planner agent, specialized agents and a supervisor agent.\n\nThe approach is compared to a single agent setup and a debtate MAS setup, using the  London Stock Exchange Group dataset. The result show that the approach is superior. The authors show that the pure debtate approach is not enough, making it important to model more complex MAS."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Sensible approach, extending single agents and debate MAS with more complex MAS\n- Comparison to debate MAS successful for the dataset, showing superior performance\n- Helpful ablation studies"}, "weaknesses": {"value": "- Missing grounding in MAS research. There are many more general approaches to building/designing MAS. The proposed approach is a manually tailored MAS to a single dataset. How does the approach then behave wrt [1,2] or other seminal MAS LLM papers? These should be at least mentioned and thoroughly compared to in related works. It should therefore be made clear what added value the current paper makes and why one does not have to empirically compare against them.\n- In a similar vein, it should be made clear what research in tabular LLMs is available in similar direction, especially single agent / LLM approaches.\n\n[1] Ke, Z., Xu, A., Ming, Y., Nguyen, X.P., Xiong, C. and Joty, S., 2025. MAS-ZERO: Desi\n[2] Li, J., Zhang, Q., Yu, Y., Fu, Q. and Ye, D., 2024. More agents is all you need. arXiv preprint arXiv:2402.05120."}, "questions": {"value": "- How does your approach relate to mentioned recent works on MAS / automating MAS design / tabular LLMs?\n- How does your approach benefit related domains or tasks?\n- Would your approach generalize to the general downstream task of ranking tabular data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NgKJPxNa6Z", "forum": "bwbTEoBa4O", "replyto": "bwbTEoBa4O", "signatures": ["ICLR.cc/2026/Conference/Submission2508/Reviewer_oAJG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2508/Reviewer_oAJG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989675476, "cdate": 1761989675476, "tmdate": 1762916259634, "mdate": 1762916259634, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PARTNERMAS, a hierarchical multi-agent system for business partner selection based on high-dimensional firm features. The framework consists of three layers—a Planner Agent that analyzes context and creates evaluators, multiple Specialized Agents that assess candidate firms from different perspectives, and a Supervisor Agent that integrates results for the final decision. The authors also introduce a tabular benchmark for co-investor selection reflecting real-world, multi-criteria decision-making. Experiments show that PARTNERMAS improves performance by about 15% over single-agent and debate-based baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) The paper is well-written and clearly organized, with informative visualizations that effectively illustrate the experimental outcomes.\n\n2) The topic of business partner selection is intriguing and addresses a real-world challenge that has been relatively underexplored within the MAS domain. The application to VC co-investment selection is well-motivated and carries strong practical relevance.\n\n3) The setup of the ablation studies is rasonable, and the detailed analyses help to better illustrate the contribution of each component."}, "weaknesses": {"value": "1） One major concern is from the experimental set-up: Although the experimental evaluation includes several LLM backbones, the study would be strengthened by incorporating fair comparisons with alternative approaches, such as classical machine learning and deep learning methods designed for the same task.\n\n\n2） While the paper presents a clear experimental setup, one potential limitation lies in the relatively simple choice of evaluation metrics. The authors primarily assess system performance using match rate, which, although intuitive, may not fully capture the multifaceted nature of business partner selection tasks. To more comprehensively evaluate the robustness and reliability of the proposed MAS framework, I suggest incorporating a broader range of metrics.  For example,  metrics such as F1-Score could provide a more balanced view of both accuracy and completeness. Ranking-based metrics like Mean Reciprocal Rank (MRR) and Normalized Discounted Cumulative Gain (nDCG) can be also valuable to be included into evaluation metric set."}, "questions": {"value": "Same as what I mentioned in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MaR36oPGd3", "forum": "bwbTEoBa4O", "replyto": "bwbTEoBa4O", "signatures": ["ICLR.cc/2026/Conference/Submission2508/Reviewer_ek9A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2508/Reviewer_ek9A"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762040639474, "cdate": 1762040639474, "tmdate": 1762916259354, "mdate": 1762916259354, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}