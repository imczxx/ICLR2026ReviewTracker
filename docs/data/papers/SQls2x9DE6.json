{"id": "SQls2x9DE6", "number": 11872, "cdate": 1758204409648, "mdate": 1759897549508, "content": {"title": "T-3DGS: Removing Transient Objects for 3D Scene Reconstruction", "abstract": "Transient objects in video sequences can significantly degrade the quality of 3D scene reconstructions. To address this challenge, we propose T-3DGS, a novel framework that robustly filters out transient distractors during 3D reconstruction using Gaussian Splatting. Our framework consists of two steps. First, we employ an unsupervised classification network that distinguishes transient objects from static scene elements by leveraging their distinct training dynamics within the reconstruction process. Second, we refine these initial detections by integrating an off-the-shelf segmentation method with a bidirectional tracking module, which together enhance boundary accuracy and temporal coherence. Evaluations on both sparsely and densely captured video datasets demonstrate that T-3DGS significantly outperforms state-of-the-art approaches, enabling high-fidelity 3D reconstructions in challenging, real-world scenarios.", "tldr": "", "keywords": ["gaussian splatting", "transient distractors", "static reconstruction"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/242e78bfc4ec3c3cb50c25bdcce1a76a707f30b2.pdf", "supplementary_material": "/attachment/dfd9f90ac244ae17285d3a100710b6f9d4caa032.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces T-3DGS, which reconstructs static 3D scenes from monocular videos that contain transient objects. The pipeline begins with a Reconstruction Uncertainty Predictor (RUP) that uses DINOv2 features to produce a binary transient mask, which is then refined spatially with SAM and temporally with SAM2. During 3D Gaussian splatting, masked regions are excluded so optimization focuses on static content. The paper also introduces the T-3DGS dataset, a more challenging benchmark than prior sets. Experiments on three datasets show that T-3DGS achieves state-of-the-art performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is easy to follow, the idea of detecting transient objects with feature extraction and refining them with SAM and SAM2 is reasonable and demonstrates good performance.\n2. The proposed new dataset, T-3DGS, is more challenging than previous benchmark for evaluating models' performance on this task, and it is useful for the community.\n3. Each contributions are properly evaluated through ablation studies."}, "weaknesses": {"value": "1. My main concern is that this method is a combination of existing foundation models DINO, SAM and SAM2. It provides little novelty or inspirations, given these models are already well-explored in this community.\n2. The comparison with Easi3R seems unfair, because as a feed-forward based method,  Easi3R is good for its inference speed and generality, and as optimization based method, the proposed method is expected to have better per-scene performance.\n3. The TMR module comprises two components—SAM for spatial refinement and SAM2 for temporal refinement. What are the respective contributions of each to the refinement process, qualitatively or quantitatively?\n4. Table 2 suggests most of the gains come from TMR. Since TMR leverages off-the-shelf SAM/SAM2, the novelty and impact of RUP are not convincingly demonstrated."}, "questions": {"value": "1. Is the model structure of RUP introduced in supplementary material B?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hwzAyCwqhs", "forum": "SQls2x9DE6", "replyto": "SQls2x9DE6", "signatures": ["ICLR.cc/2026/Conference/Submission11872/Reviewer_nxFn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11872/Reviewer_nxFn"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11872/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761430153329, "cdate": 1761430153329, "tmdate": 1762922890702, "mdate": 1762922890702, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes T-3DGS, a framework for robust 3D scene reconstruction that removes transient and semi-transient objects from video sequences during 3DGS optimization. The key contribution is an unsupervised Reconstruction Uncertainty Predictor (RUP) that identifies transient distractors using multivariate uncertainty modeling with KL divergence and a Transient Mask Refiner (TMR) that enhances mask spatial and temporal consistency. Extensive experiments show that the proposed method outperforms baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well motivated, addressing a practical problem in 3DGS-based scene editing. \n2. The proposed T-3DGS dataset fills a gap for semi-transient object evaluation."}, "weaknesses": {"value": "1. Limited novelty: The main contribution seems to be a combination of existing techniques (uncertainty estimation, semantic guidance, and SAM-based propagation), rather than addressing the deeper underlying issue of poor extrapolation and generalization in 3DGS.\n2. Insufficient analysis: The paper lacks detailed sensitivity studies for key thresholds and hyperparameters, and the divergence-based uncertainty formulation remains largely heuristic without strong theoretical or empirical justification.\n3. Dependence on SAM: Further evaluation is needed regarding the method’s reliance on SAM; segmentation noise or boundary inaccuracies may significantly influence transient detection and overall reconstruction performance."}, "questions": {"value": "Does the SAM-based refinement introduce temporal artifacts or error propagation in long sequences?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5Vt6n3oSxH", "forum": "SQls2x9DE6", "replyto": "SQls2x9DE6", "signatures": ["ICLR.cc/2026/Conference/Submission11872/Reviewer_Zdxa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11872/Reviewer_Zdxa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11872/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761537409452, "cdate": 1761537409452, "tmdate": 1762922889841, "mdate": 1762922889841, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents T-3DGS, a framework for reconstructing static 3D scenes from monocular video containing transient objects. T-3DGS is based on 3DGS, and introduces two key components: 1) reconstruction uncertainty predictor (RUP) that detects transient regions using semantic features and KL-divergence–based uncertainty modeling; 2) transient mask refiner (TMR) leveraging SAM/SAM2 for spatial refinement and temporal propagation. The combination allows 3DGS to focus on static content, which improves the reconstruction quality in real-world conditions. The authors conduct experiments on several datasets, and show better performance over existing methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors study an interesting problem of transient object, which is important for real-world scene reconstruction.\n2. The method is well-designed and theoretically grounded.\n3. The pipeline utilize DINOv2 features to provide robustness against color similarity and high-frequency textures.\n4. The experiments compare against several baseline approaches and ablate key modules. The authors also introduce a new dataset with transient objects.\n5. The authors provide qualitative results to clearly demonstrate better reconstructions."}, "weaknesses": {"value": "1. The training pipeline is too heavy, which uses DINOv2 to extract features, use SAM for spatial refinement and SAM2 for temporal refinement.\n2. Each submodule is adapted from existing techniques.\n2.1 RUP uses DINOv2 features for semantic understanding, follows WildGaussians to build per-pixel residual with FeatUP and DSSIM, follows NeRF-W use uncertainty in 3DGS and separate static and transient objects.\n2.2 The first part of the TMR uses SAM to clean up the noisy binary masks predicted by RUP.\n2.3 The second part of TMR uses SAM2 to propagate masks.\n3. The ablations do not fully separate the effects of KL, semantic feature, and TMR propagation."}, "questions": {"value": "1. What happens if SAM or SAM2 produces incorrect boundaries?\n2. What is the training interaction between RUP and 3DGS?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N3FX8IYLWG", "forum": "SQls2x9DE6", "replyto": "SQls2x9DE6", "signatures": ["ICLR.cc/2026/Conference/Submission11872/Reviewer_dopq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11872/Reviewer_dopq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11872/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761913526388, "cdate": 1761913526388, "tmdate": 1762922889350, "mdate": 1762922889350, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the task of removing transient objects from a video. The transient objects break the assumption of static scenes that most 3D reconstruction approaches rely on. To mitigate this issue, the authors propose an uncertainty modeling-based approach to detect whether a mask is transient or not. Further, to ensure temporal consistency, the authors propose to use temporal refinement to enhance the mask quality. Experiments on various datasets demonstrate the effectiveness of the proposed approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- originality-wise: the idea of utilizing uncertainty modeling and mask propagation to handle dynamic objects is interesting.\n- quality-wise: qualitative and quantitative results demonstrate the effectiveness of the proposed approach.\n- clarity-wise: the paper is well-written in general.\n- significance-wise: the problem of removing transient objects is important for downstream tasks of 3D reconstruction from in-the-wild videos."}, "weaknesses": {"value": "1. For temporal refinement (L315): can we just use forward or backward propagation? How bad will the performance be qualitatively and quantitatively?\n\n2. Can authors provide some runtime analysis?\n\n3. How to determine the extent of dilation (L290) as it seems important from Tab. 3?\n\n4. From the Fig. 2, it seems like RUP is not updated, which contradicts L170. Can authors clarify?\n\n5. For Fig. 9, the T-3DGS's results do not seem to be from the same camera as the other methods or GT. Is this a bug or using the wrong one?\n\n5. Please add a colorbar to Fig. 3. I am not sure which color means high uncertainty."}, "questions": {"value": "See \"Weakness\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tkvRvi3gHs", "forum": "SQls2x9DE6", "replyto": "SQls2x9DE6", "signatures": ["ICLR.cc/2026/Conference/Submission11872/Reviewer_Sz53"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11872/Reviewer_Sz53"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11872/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961137629, "cdate": 1761961137629, "tmdate": 1762922888697, "mdate": 1762922888697, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}