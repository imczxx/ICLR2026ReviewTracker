{"id": "FXu4G5T5QZ", "number": 6729, "cdate": 1757993663518, "mdate": 1759897898460, "content": {"title": "Autoregressive-based Progressive Coding for Ultra-Low Bitrate Image Compression", "abstract": "Generative models have demonstrated significant results in ultra-low bitrate image compression, owing to their powerful capabilities for content generation and texture completion. Existing works primarily based on diffusion models still face challenges such as limited bitrate adaptability and high computational complexity for encoding and decoding. Inspired by the success of Visual AutoRegressive model (VAR), we introduce AutoRegressive-based Progressive Coding (ARPC) for ultra-low bitrate image compression, a progressive image compression framework based on next-scale prediction visual autoregressive model. Based on multi-scale residual vector quantizer, ARPC efficiently encodes the image into multi-scale discrete token maps and controls the bitrates by selecting different scales for transmission. For decompression, ARPC leverages the prior knowledge inherent in the visual autoregressive model to predict the unreceived scales, which is naturally the autoregressive generation process. To further increase the compression ratio, we target the VAR as a probability estimator for lossless entropy coding and propose group-masked bitwise multi-scale residual quantizer to adaptively allocate bits for different scales. Extensive experiments show that ARPC achieves state-of-the-art perceptual fidelity at ultra-low bitrates and high decompression efficiency compared with existing diffusion-based methods.", "tldr": "", "keywords": ["lossy image compression", "autoregressive model"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/90318019bf36395604033929548a361a87074a28.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel framework for ultra-low bitrate image compression , which utilizes a Visual AutoRegressive model (VAR) to encode images into multi-scale discrete tokens. Decompression is achieved by autoregressively generating (predicting) the unreceived scales."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper achieves variable bitrate by combining VAR with lossless compression across different scales, effectively integrating image compression with existing pre-trained models.\n\nThe paper is well-organized and easy to understand."}, "weaknesses": {"value": "1. The encoding time increases with the bitrate. Additionally, the encoding process requires a caption model to generate captions, making the encoder relatively \"heavy.\" Could the authors provide the parameter counts for the models used at both the encoder and decoder ends?\n\n2. The ablation study in Figure 7 shows that while each proposed module contributes some improvement, the individual gains are relatively modest. Could it be that directly using VAR for encoding and decoding already offers a performance advantage over other generative compression methods?\n\n3. Further experiments are needed to investigate the impact of different specific mask choices for the Group-Masked (GM-BMSRQ) method."}, "questions": {"value": "see weakness. My main point of interest is whether VAR itself is already sufficiently effective when used as a codec, and what the performance improvement of this paper's method is compared to a baseline VAR."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Ls94primQv", "forum": "FXu4G5T5QZ", "replyto": "FXu4G5T5QZ", "signatures": ["ICLR.cc/2026/Conference/Submission6729/Reviewer_t8Sb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6729/Reviewer_t8Sb"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6729/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761636483293, "cdate": 1761636483293, "tmdate": 1762919017609, "mdate": 1762919017609, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an ultra-low bitrate image compression method based on the VAR model. Specifically, it introduces group-masked bitwise multi-scale residual quantization (GM-BMSRQ) and lossless re-encoding (LRE) techniques to improve compression ratio. The scale random dropout (SRD) strategy enhances the representation capability of earlier scales. The proposed ARPC method achieves superior perceptual and statistical fidelity on benchmark datasets."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This paper proposes an innovative extreme image compression method based on VAR. The manuscript is well-organized and original."}, "weaknesses": {"value": "1.The Kodak dataset is a commonly used benchmark in image compression. However, the authors do not provide quantitative or qualitative comparisons of it. Please add these comparisons.\n2.The paper does not compare the ARPC method with representative methods, such as token-based and one-step diffusion methods. The former includes the GLC [1] and DLF [2] methods, while the latter includes the RDEIC [3], OSCAR [4], and StableCodec [5] methods. Please add these comparisons for a comprehensive evaluation.\n[1]Jia Z, Li J, Li B, et al. Generative latent coding for ultra-low bitrate image compression[C]. CVPR 2024.\n[2]Xue N, Jia Z, Li J, et al. DLF: Extreme Image Compression with Dual-generative Latent Fusion[J]. ICCV 2025.\n[3]Li Z, Zhou Y, Wei H, et al. RDEIC: Accelerating Diffusion-Based Extreme Image Compression with Relay Residual Diffusion[J]. TCSVT2025.\n[4]Guo J, Ji Y, Chen Z, et al. OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates[J]. NeurIPS2025.\n[5]Zhang T, Luo X, Li L, et al. StableCodec: Taming One-Step Diffusion for Extreme Image Compression[J]. ICCV2025.\n3.The related work lacks one-step, diffusion-based extreme image compression methods.\n4.What is the bitwise multi-scale residual quantizer? Please explain how it works in detail.\n5.Please explain how the scale random dropout strategy work and introduce it in detail.\n6.Please explain the symbol d() in line 221 of the manuscript. Is it the MSE function?\n7.For qualitative comparisons, the authors should select results for which the ARPC has the smallest BPP values compared to other competing methods. Please modify it (Fig. 4 and 5.).\n8. Would you release the source code and pretrained models? We hope you can also release them to help us understand the ARPC."}, "questions": {"value": "See the part of weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "YOywPK1IJi", "forum": "FXu4G5T5QZ", "replyto": "FXu4G5T5QZ", "signatures": ["ICLR.cc/2026/Conference/Submission6729/Reviewer_1Hec"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6729/Reviewer_1Hec"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6729/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761647909574, "cdate": 1761647909574, "tmdate": 1762919017097, "mdate": 1762919017097, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ARPC (Autoregressive-based Progressive Coding) for ultra-low bitrate image compression. An image is quantized into K multi-scale residual token maps; the encoder transmits only the first k (coarse→fine), and a visual autoregressive (VAR) model predicts the untransmitted scales at the decoder (next-scale generation). ARPC also treats the VAR as a probability estimator for arithmetic (lossless) entropy coding of the transmitted tokens and introduces a group-masked bitwise multi-scale residual quantizer (GM-BMSRQ) to reduce bits at coarse scales."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Dual use of VAR . Using VAR both to compress transmitted bits losslessly (arithmetic coding) and to generate untransmitted scales is technically neat and principled.\n- Good progressive design. Encoding into hierarchical residual scales and stopping transmission at k aligns naturally with bitrate adaptation; the decoder’s next-scale VAR completes missing scales, yielding progressive reconstruction. The pipeline (lossless arithmetic decode → VAR generation → image decoder) is clearly illustrated."}, "weaknesses": {"value": "- Complexity accounting. The claim of 2–6× faster decompression than diffusion is compelling, but a fuller wall-clock/compute-memory breakdown across image sizes and k values would strengthen the efficiency story. \n- The impact analysis of missing text on reconstruction is lacking. The paper mentions using BLIP2 to extract image captions to assist reconstruction, but it does not analyze how the absence of text affects the final results, which is an incomplete approach.\n- A more detailed baseline comparison is needed. Recently, numerous diffusion-based image compression methods have emerged, such as StableCodec[1] and ResULIC[2]. These methods have significantly improved decoding speed and performance, particularly StableCodec, which can complete image generation in a single step. This demonstrates that multi-step denoising is no longer a common limitation of diffusion-based methods. The authors need to conduct a more detailed performance and complexity comparison with these methods to highlight the significance of VAR-based approaches.\n\n[1] Zhang, Tianyu, et al. \"StableCodec: Taming One-Step Diffusion for Extreme Image Compression.\" arXiv preprint arXiv:2506.21977 (2025).\n\n[2] A. Ke, X. Zhang, T. Chen, M. Lu, C. Zhou, J. Gu, and Z. Ma, “Ultra Lowrate Image Compression with Semantic Residual Coding and Compression-aware Diffusion,” in Proc. Int. Conf. Mach. Learn. (ICML), 2025."}, "questions": {"value": "- In your introduction, I noticed the term \"Infinite shared randomness.\" What exactly does this refer to? Is it about the impact of random seeds in diffusion models on the denoising process? This doesn’t seem to have a very significant impact."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fH2faphSjU", "forum": "FXu4G5T5QZ", "replyto": "FXu4G5T5QZ", "signatures": ["ICLR.cc/2026/Conference/Submission6729/Reviewer_gRQE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6729/Reviewer_gRQE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6729/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761747499694, "cdate": 1761747499694, "tmdate": 1762919016707, "mdate": 1762919016707, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ARPC (AutoRegressive-based Progressive Coding), which leverages a Visual Autoregressive Model (VAR) based on next-scale prediction to for image compression. The VAR also serves as a probability estimator for near-lossless entropy coding. To further improve compression efficiency and semantic representation, the authors propose a Group-Masked Bitwise Multi-Scale Residual Quantizer (GM-BMSRQ) and a Scale Random Dropout (SRD) strategy. Experiments on DIV2K-val and CLIC2020 demonstrate that ARPC surpasses both diffusion-based and VQ/GAN-based baselines in perceptual metrics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "By transmitting only the first k scales and autoregressively completing the rest with VAR, it enables progressive transmission and adaptive bitrate control. The VAR module serves both as a generator and a probability estimator, reducing overall bitrate while supporting lossy and lossless compression. GM-BMSRO further enhances the bitwise multi-scale residual quantizer by group masking to early scales, while SRD encourages these scales to capture richer semantic information. Extensive evaluations across diverse datasets and metrics demonstrate the robustness and practical effectiveness of these techniques."}, "weaknesses": {"value": "(1) The structural diagram (Figure 2) fails to explicitly show the image caption’s presentation form and functional mechanism. While the text states captions (generated via BLIP2) act as global semantic context to guide VAR’s autoregressive prediction of unreceived scales, Figure 2 lacks labels for the caption generation module.\n(2) The grouping logic and parameter settings of GM-BMSRQ lack sufficient justification. The paper proposes dividing the K scales into three groups and masking the last c/2 channels of the first group and the last c/4 channels of the second group to reduce bit cost. However, the rationale behind these key design choices is not explained: (i) the basis for selecting the specific channel masking numbers (e.g., c/2) is unclear, as no experiments compare different masking configurations; (ii) the logic for dividing scales into three groups rather than two or four, and the criteria for allocating scales to each group, is not discussed; (iii) the effect of different channel configurations (e.g., 8, 12, 16 channels) on compression performance is only partially explored through comparisons of c=32 and c=16, leaving the module’s design insufficiently validated and its optimality unproven.\n(3) The paper exhibits notable deficiencies in evaluating decoding efficiency and comparing with baseline methods. On one hand, although the ARPC decoding time is reported as 5.39s and claimed to be 2–6× faster than diffusion-based methods, the breakdown of this runtime is not provided—key steps such as VAR autoregressive prediction, arithmetic decoding, and image reconstruction are not individually profiled, making it difficult to identify efficiency bottlenecks and guide further optimization. More importantly, this decoding time is not compared against the current state-of-the-art in ultra-low bitrate image compression. On the other hand, the selection of baseline methods is limited and does not include recent mainstream approaches. To fully validate ARPC’s performance, comparisons should be extended to methods such as DLF[1] (Extreme Image Compression with Dual-generative Latent Fusion), GLC[2], and single-step diffusion methods like StableCodec[3], thereby providing a more comprehensive evaluation and clarifying ARPC’s position relative to the current research frontier.\n\n[1] N. Xue, Z. Jia, J. Li, B. Li, Y. Zhang, and Y. Lu, “DLF: Extreme Image Compression with Dual-generative Latent Fusion,” ICCV, 2025.\n[2] Jia, Zhaoyang, et al. \"Generative latent coding for ultra-low bitrate image compression.\" CPVR, 2024.\n[3] Zhang, Tianyu, et al. \"StableCodec: Taming One-Step Diffusion for Extreme Image Compression.\" ICCV, 2025."}, "questions": {"value": "(1)\tAre the bits used for text encoding included in the reported bpp statistics? How much bitrate do the captions contribute to the total bpp?\n(2)\tThe paper states that scale random dropout (SRD) is applied with a probability of 0.2 from the fourth scale during training—why is the fourth scale chosen as the starting point for SRD, and how does adjusting the dropout probability (e.g., 0.1 or 0.3) affect the model’s ability to preserve semantic information in earlier scales?\n(3)\tFor images with complex textures (e.g., dense text or fine-grained patterns), does ARPC require adjusting hyperparameters (e.g., number of scales K, channel dimensions of GM-BMSRQ groups) to maintain reconstruction quality, and if so, what guidelines exist for such adjustments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WLQ1zUmwLf", "forum": "FXu4G5T5QZ", "replyto": "FXu4G5T5QZ", "signatures": ["ICLR.cc/2026/Conference/Submission6729/Reviewer_joRB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6729/Reviewer_joRB"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission6729/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763348636234, "cdate": 1763348636234, "tmdate": 1763348636234, "mdate": 1763348636234, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Extremely irresponsible reviewer joRB (copy other comments first and then replace with an AIGC version)"}, "comment": {"value": "Dear AC, reviewers, and readers from the community,\n\nPlease let us rephrase what happened:\n1. When review release, we found the **comments from reviewer joRB and gRQE are EXACTLY THE SAME**. \n2. We did not report in the beginning but then, it is ridiculous that **reviewer joRB deleted the repeated comments and upload an AIGC version today** to pretend nothing just happened.\n\nEvidence see: https://anonymous.4open.science/r/Submission6729-4834/Readme.md\n\nWe have no idea how this could happen. I used to try to find some reviewer's policy or guideline to prove this behavior violated something. But then I realized that **this is way too much**. Never heard such an operation (**copy comments and then replace with an AIGC one**) in the past many years.\n\nWe have **only one appeal** as follows. \n**Please mark reviewer joRB as irresponsible reviewer and desk reject reviewer joRB's submission (refers to previous year's CVPR experience) and further consider to ban reviewer joRB for following venues.**\n\nIn the end, we know if we deal with this privately maybe our paper has a higher chance to be accepted (e.g. report to AC with humble message like please ignore this review...). But I’m really at the end of my rope with this so I have decided to make this open in this OpenReview system.\n\nOn behalf of Authors of submission 6729."}}, "id": "yo2MmVMEBe", "forum": "FXu4G5T5QZ", "replyto": "FXu4G5T5QZ", "signatures": ["ICLR.cc/2026/Conference/Submission6729/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6729/Authors"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission6729/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763354077116, "cdate": 1763354077116, "tmdate": 1763354077116, "mdate": 1763354077116, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}