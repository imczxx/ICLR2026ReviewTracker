{"id": "HArdYL2hez", "number": 8438, "cdate": 1758083560301, "mdate": 1763618658070, "content": {"title": "Mining Valuable Sub-Expressions for Symbolic Regression", "abstract": "Symbolic Regression (SR) aims to discover mathematical expressions from data, but classical methods are hampered by an immense search space. This inefficiency stems from their tendency to construct expressions atom-by-atom using basic operators and variables, overlooking the power of reusing meaningful sub-expressions. To address this challenge, we introduce Mining Sub-Expression Symbolic Regression (MSSR), a novel framework that discovers and leverages valuable sub-expressions to efficiently search for the correct symbolic form. MSSR employs a cooperative multi-agent reinforcement learning framework, augmented with genetic programming, to intelligently sample sub-expressions from a dynamically evolving library, combining them into a mathematical expression. A pruning mechanism based on the coefficient of variation is utilized to remove redundant terms, promoting the discovery of the parsimonious expression. We conduct extensive experiments on the SRBench and fluid dynamics benchmarks. The results demonstrate that, compared to 24 baseline methods, MSSR recovers more ground-truth expressions and achieves a superior balance between predictive accuracy and model simplicity.", "tldr": "", "keywords": ["Symbolic regression", "Reinforcement learning"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6d10c96cbc39c44312a58ad0d547e6b09132e0fc.pdf", "supplementary_material": "/attachment/d657c9c4cedaa4ff567173dabb30e7dba3665c33.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces MSSR, a novel framework for symbolic regression that leverages sub-expressions within a multi-agent reinforcement learning framework. While the idea of reusing sub-expressions is promising, the manuscript has several limitations in methodological justification, experimental rigor, and contextualization within the existing literature. Below are detailed comments and suggestions for improvement."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Robust and Adaptive Library Management​**\n\n​Dynamic Library Updates: The sub-expression library Lis not static; it evolves using GP based on mutual information (MI) with the target. This ensures the library remains relevant and enriched with components that have high predictive utility, especially under noisy conditions.\n\n​Information-Theoretic Sub-expression Evaluation: Using MI to evaluate sub-expressions provides a noise-resistant measure of relevance, contributing to the method's robustness in noisy data scenarios."}, "weaknesses": {"value": "**1. Limitations in Expression Form Assumption​**\n\nThe proposed method inherently assumes that target expressions can be decomposed into a weighted sum of sub-expressions. This design may favor expressions naturally adhering to this form (e.g., additive models) but could struggle with expressions that do not decompose additively. In such cases, MSSR might overcomplicate the solution by forcing a sum-of-terms structure, potentially leading to less parsimonious fits than methods without this structural bias.\n\n**2. Insufficient Coverage of Related Work​**\n\nThe literature review lacks depth in several key areas:\n\n​GP-based methods with similar ideas: Techniques like Genetic Programming with Automatically Defined Functions (GP-ADF) or modular GP explicitly evolve and reuse sub-expressions but are not discussed.\n\n​RL-based symbolic regression methods: Prior works such as GP-RL or hierarchical RL approaches for expression construction are not adequately compared.\n\n**3. Methodological Clarifications Needed​**\n\n​Sub-expression selection via Mutual Information (MI)​: The manuscript mentions using MI to evaluate sub-expressions but omits critical details: How is MI computed between a sub-expression and the target? What is the exact formulation? Are continuous outputs discretized? Clarification is essential for reproducibility.\n\n​Agent coordination and scalability: The framework employs 3 agents per sub-expression, implying 3×n agents for an expression with n terms. It is unclear how the search space scales with term count or how inter-term dependencies are handled. Since agents update independently, the approach may overlook synergies between terms, potentially hindering global optimization.\n\n**​4. Experimental Comparisons and Baselines​**\n\n​Comparison with state-of-the-art: The omission of PySR (a recently published and widely recognized SR tool) undermines the credibility of claimed advancements. PySR should be included in benchmarks.\n\n​Ablation study limitations: The ablation experiments are limited to a few datasets, which may coincidentally align with the method’s structural assumptions. To demonstrate generalizability, ablations should cover all benchmark categories (PMLB, FSRB, Strogatz).\n\n​Lack of comparison with GP-ADF and pretrained methods: GP-ADF directly addresses sub-expression reuse and should be included. Additionally, pretrained approaches like SNIP or NeSymReS, which excel in model complexity reduction, are not evaluated."}, "questions": {"value": "The questions are described in the \"Weakness\" section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VhaXXZCdBT", "forum": "HArdYL2hez", "replyto": "HArdYL2hez", "signatures": ["ICLR.cc/2026/Conference/Submission8438/Reviewer_5Pwr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8438/Reviewer_5Pwr"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8438/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761644259359, "cdate": 1761644259359, "tmdate": 1762920329074, "mdate": 1762920329074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MSSR (Mining Sub-Expression Symbolic Regression) — a novel framework for symbolic regression that aims to reduce the massive combinatorial search space by reusing valuable sub-expressions rather than building expressions from atomic operators."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear and Innovative idea. The paper identifies an under-explored direction — reusing sub-expressions to shrink the symbolic search space. This idea is well justified both theoretically and empirically."}, "weaknesses": {"value": "1. **Unclear modeling justification.**\n   The rationale for modeling the problem as a *cooperative Multi-Agent Reinforcement Learning (MARL)* setup is unclear. There appears to be a significant conceptual gap between the motivation of *mining valuable sub-expressions* and the decision to formulate it as a MARL problem. A stronger conceptual or mathematical justification for this modeling choice is needed to make the approach more convincing.\n\n2. **Lack of integration with other frameworks.**\n   The proposed idea of reusing sub-expressions should, in principle, be applicable beyond GP—such as within Deep RL, MCTS, or LLM-based symbolic regression frameworks. However, the paper presents results only on a GP-style setup without demonstrating or even discussing how MSSR could be extended or adapted to these other paradigms. Including such discussions or preliminary experiments would substantially strengthen the contribution.\n\n3. **Presentation and formatting issues.**\n\n   * The paper lacks sufficient background on symbolic regression and (multi-agent) reinforcement learning. A concise overview of these topics—along with brief introductions to genetic programming and mutual information—should be added before Section 3.\n   * The citation format is inconsistent. All instances of `\\cite{}` should be replaced with `\\citep{}` to ensure proper inline citation style.\n   * Mathematical notation is inconsistent—for example, line 161 uses `\\mathcal{R}` while line 163 uses `\\mathbf{\\mathcal{R}}`. This should be standardized throughout.\n   * *Theorem 1* is mislabeled; it is not a formal theorem but rather a derived gradient equation. It should be presented as an equation or proposition with a derivation, **not** as a theorem accompanied by a proof.\n   * In Table 5, the variable should be written as `$u_0$` (not `u0`). All mathematical operators should use LaTeX commands such as `$\\sin$`, `$\\log$`, etc., for proper typesetting consistency."}, "questions": {"value": "Overall, the idea is novel and promising. However, I strongly recommend that the authors carefully proofread the entire manuscript during the rebuttal phase. Without first addressing the numerous writing and formatting issues, additional technical feedback will have limited impact on improving the overall quality of the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "L1ZFZhIXoC", "forum": "HArdYL2hez", "replyto": "HArdYL2hez", "signatures": ["ICLR.cc/2026/Conference/Submission8438/Reviewer_XfqF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8438/Reviewer_XfqF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8438/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761775913803, "cdate": 1761775913803, "tmdate": 1762920328639, "mdate": 1762920328639, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MSSR, a new symbolic regression algorithm that explicitly identifies and reuses sub-expressions. MSSR trains 3 cooperative agents, tasked with sampling the left sub-expression, operators and right sub-expression in a specific formulation they present in Eq. (1)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Novel engineering solution that utilizes a variety of techniques (i.e., information theory, evolutionary computation, reinforcement learning) in an appropriate manner that is competitive.\n\nPaper is organized in an easy-to-read way and is intuitive.\n\nExcept for the main results in 4.1.1., Ablation results and PDE discovery case study is a nice addition and is acceptable as-is in my opinion."}, "weaknesses": {"value": "What is the definition of “symbolic recovery rate” defined? There are different definitions in SR literature, it should be stated clearly in the paper. How are the constants treated for equality (i.e., is 0.999 treated effectively the same as 1 in an equation)?\n\nSeem to be missing SR algorithms published post-2021. Can the paper comment on this?\n\nThe paper claims that other SR approaches tend to be “overlooking the power of reusing meaningful sub-expressions”. However, it is well-known that SR algorithms, especially evolutionary approaches, reuse meaningful sub-expressions via mechanisms like crossover. Thus, I think the discussion and definition of “overlooking the power of reusing meaningful sub-expressions” needs to be more specific and nuanced to accurately reflect current SR literature.\n\nContradictory/inconsistent results. Figure 2 and Figure 3 contradict each other. For example, in PMLB, MSSR has the best R2 test, and the model size is smaller than Operon. By the definition of Pareto-optimality, Operon cannot be Pareto optimal, yet it is Pareto optimal in Figure 3. This applies to other algorithms as well. I suspect the issue stems from plotting the average ranks instead, which is not the standard practice for Pareto fronts in general and has been proven to suffer from \"rank inversion paradox\" for SR benchmarking [1]. An easy fix would be to plot the absolute metrics on the axis instead of the ranks of the metrics.\n\n[1] Fong, K. S., & Motani, M. Pareto-Optimal Fronts for Benchmarking Symbolic Regression Algorithms. In Forty-second International Conference on Machine Learning."}, "questions": {"value": "Please address the weaknesses above. In addition to the weaknesses, below are some questions that could possibly justify a further increase in recommendation score.\n\nCan the paper clarify what happens to the sub-expression library when there is an optimized constant in the sub-expression (e.g., x^2.5)? The examples given in the paper do not have constant in the sub-expression.\n\nWhat algorithm is used to estimate MI (e.g., KSG [2])? Please discuss and cite the algorithm used along with the settings, because while the definition of MI is not ambiguous, there are many variants of MI estimators, each with potentially very different outputs. And, was the choice of MI estimator justified via experimentation?\n\n[2] Kraskov, A., Stögbauer, H., & Grassberger, P. (2004). Estimating mutual information. Physical Review E, Statistical, Nonlinear, and Soft Matter Physics, 69(6), 066138.\n\nOthers:\n\nInstead of MI, would another concept in information theory, unique relevance (UR), be more applicable? This is because 2 sub-expressions with high MI could have high overlap/redundancy."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "PmKL92fi74", "forum": "HArdYL2hez", "replyto": "HArdYL2hez", "signatures": ["ICLR.cc/2026/Conference/Submission8438/Reviewer_WFLM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8438/Reviewer_WFLM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8438/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803531525, "cdate": 1761803531525, "tmdate": 1762920328100, "mdate": 1762920328100, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We thank all reviewers for their valuable comments. Due to the time constraints of this round, our current response includes only part of the extended experimental results. Based on these available results, we have addressed the questions related to the extended experiments, and we have incorporated the corresponding partial results into the revised manuscript. Before the deadline for submitting the final manuscript (December 3, 2025), we will include the complete extended experimental results in the final revised version of the paper."}}, "id": "rvFI2kpWVQ", "forum": "HArdYL2hez", "replyto": "HArdYL2hez", "signatures": ["ICLR.cc/2026/Conference/Submission8438/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8438/Authors"], "number": 9, "invitations": ["ICLR.cc/2026/Conference/Submission8438/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763618979313, "cdate": 1763618979313, "tmdate": 1763618979313, "mdate": 1763618979313, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}