{"id": "xAtYHNe0Ey", "number": 24022, "cdate": 1758351825673, "mdate": 1759896785912, "content": {"title": "KG-DG: Knowledge-Guided Domain Generalization via Neuro-Symbolic Fusion", "abstract": "Abstract. Domain generalization remains a critical challenge in medical imaging, where models trained on single sources often fail under real-world distribution shifts. We propose KG-DG, a neuro-symbolic framework for diabetic retinopathy (DR) classification that integrates vision transformers with expert-guided symbolic reasoning to enable robust generalization across unseen domains. Our approach leverages clinical lesion ontologies through structured, rule-based features and retinal vessel segmentation, fusing them with deep visual representations via a confidence-weighted integration strategy. The framework addresses both single-domain generalization (SDG) and multi-domain generalization (MDG) by minimizing the KL divergence between domain embeddings, thereby enforcing alignment of high-level clinical semantics. Extensive experiments across four public datasets (APTOS, EyePACS, Messidor-1, Messidor-2) demonstrate significant improvements: up to a 5.2% accuracy gain in cross-domain settings and a 6% improvement over baseline ViT models. Notably, our symbolic-only model achieves a 63.67% average accuracy in MDG, while the complete neuro-symbolic integration achieves the highest accuracy compared to existing published baselines and benchmarks in challenging SDG scenarios. Ablation studies reveal that lesion-based features (84.65% accuracy) substantially outperform purely neural approaches, confirming that symbolic components act as effective regularizers beyond merely enhancing interpretability. Our findings establish neuro-symbolic integration as a promising paradigm for building clinically robust, and domain-invariant medical AI systems. Keywords: Domain Generalization, Neuro-Symbolic Learning, Medical Imaging, Diabetic Retinopathy, Vision Transformers, Out-of-Distribution Robustness", "tldr": "Single and Cross Domain Generalization in Medical Classification: A Neuro-Symbolic Learning Approach", "keywords": ["Neuro-Symbolic Learning"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/387f347a0cbd6674d1ced45970754b5bfbcf5e75.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes KG-DG, a neuro-symbolic framework designed to tackle the domain generalization problem in medical imaging, with a specific application to Diabetic Retinopathy (DR) classification. The core issue addressed is the performance degradation of deep learning models when deployed in clinical environments with data distributions different from the training set (domain shift). The KG-DG framework integrates a deep learning branch, which uses a Vision Transformer (ViT) to learn visual representations from fundus images, with a symbolic reasoning branch. This symbolic branch explicitly extracts and quantifies clinically-defined biomarkers, such as hemorrhages and exudates using a YOLO-based model, and vascular features via a segmentation network. The predictions from these two parallel branches are then combined using a confidence-weighted fusion strategy to yield a final, more robust classification. Through extensive experiments on four public DR datasets under both single-domain and multi-domain generalization protocols, the authors demonstrate that their method significantly outperforms various baselines, improving cross-domain accuracy by up to 5.2%. A key contribution is showing that the symbolic component acts as a powerful regularizer, with the symbolic-only model achieving strong generalization performance on its own."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses a highly significant and practical challenge in medical AI. The lack of model robustness to domain shifts is a primary obstacle to the widespread, reliable deployment of diagnostic AI in real-world clinical settings, and this work offers a well-motivated solution.\n- The neuro-symbolic design is a strong and original contribution. By explicitly encoding domain-invariant clinical knowledge (e.g., lesion counts and area) into the model, the framework is guided by expert reasoning rather than relying solely on data-driven patterns that may contain spurious correlations specific to a single domain. This approach provides a clinically relevant inductive bias that enhances generalization.\n- The experimental evaluation is rigorous and comprehensive. The authors adhere to the standard DomainBed benchmark protocol, evaluating their method in both single-domain (SDG) and multi-domain (MDG) generalization scenarios against a wide array of strong CNN and Transformer-based baselines. This ensures the comparisons are fair and the results are convincing.\n- The ablation studies provide compelling insights that strongly support the paper's claims. The demonstration that the symbolic-only classifier performs competitively highlights the inherent value and robustness of the encoded clinical knowledge. Furthermore, the finding that lesion-based features are more generalizable than retinal vein features is an important, practical discovery that helps refine which types of expert knowledge are most useful for this task."}, "weaknesses": {"value": "- The framework's dependence on specialized, pre-trained modules for symbolic feature extraction presents a scalability challenge. The method requires separate, supervised models (e.g., YOLO for lesions, U-Net for veins) that must be trained on expert-annotated data, which the paper notes involved approximately 500 images. This reliance on detailed, pixel-level or bounding-box annotations for each desired biomarker may limit the framework's applicability to other medical tasks where such granular data is unavailable or prohibitively expensive to obtain.\n- The fusion mechanism for combining the neural and symbolic branches is relatively simple and static. The paper explores several fixed strategies, but the best-performing one varies depending on the training domain, suggesting that a static approach is suboptimal. A more sophisticated, dynamic fusion mechanism, perhaps a learned gating network that adaptively weights the two branches based on sample characteristics or model uncertainty, could potentially provide more consistent and powerful results."}, "questions": {"value": "- Could you elaborate on the annotation effort required for the symbolic feature extractors? Specifically, how sensitive is the performance of the YOLO and segmentation modules to the quantity and quality of annotated data? Understanding this could help gauge the effort required to adapt the KG-DG framework to new medical imaging tasks.\n- The paper cites \"YOLOv11\" but the provided reference (Wang et al., 2022) is for YOLOv7. Could you please clarify the exact architecture of the object detection model used in your pipeline?\n- Given that the optimal fusion strategy varied across different experimental settings, did you consider implementing a dynamic fusion mechanism? For example, an attention-based or gating module that learns to weigh the neural and symbolic predictions on a per-sample basis could potentially improve performance and robustness further.\n- The ablation study in Table 9 compellingly shows that adding retinal vein features harmed generalization performance. This suggests that not all forms of \"expert knowledge\" are equally beneficial for domain generalization. Does your framework include a methodology for systematically identifying and selecting which symbolic features are truly domain-invariant and beneficial, versus those that might be domain-specific distractors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LhDUUU3MZD", "forum": "xAtYHNe0Ey", "replyto": "xAtYHNe0Ey", "signatures": ["ICLR.cc/2026/Conference/Submission24022/Reviewer_S1CR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24022/Reviewer_S1CR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24022/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761780474009, "cdate": 1761780474009, "tmdate": 1762942901761, "mdate": 1762942901761, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces KG-DG, a neuro-symbolic domain generalization framework for diabetic retinopathy (DR) grading that integrates deep visual features with clinically grounded symbolic knowledge. It employs a dual-branch design—one using a Vision Transformer (ViT) for image representation and another using expert-defined lesion and vascular features processed by gradient boosting classifiers. A confidence-based fusion mechanism dynamically combines predictions from the two branches to enhance robustness under domain shifts. Comprehensive experiments on four DR datasets demonstrate that KG-DG achieves superior cross-domain accuracy and interpretability compared to state-of-the-art baselines. The study highlights that embedding explicit clinical knowledge improves out-of-distribution generalization, suggesting a promising direction for interpretable and transferable medical AI."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel neuro-symbolic formulation: This work proposes a dual-branch framework that explicitly integrates deep visual representations from a Vision Transformer with symbolic features derived from clinical lesion knowledge, offering a principled way to inject domain-specific medical reasoning into data-driven models.\n\n2. Clinically grounded feature design: This work proposes the use of expert-annotated lesion and vascular attributes as structured symbolic inputs, bridging the gap between image-level learning and clinically interpretable decision rules, which enhances transparency and clinical feasibility.\n\n3. Strong cross-domain evaluation: This work provides extensive single-domain and multi-domain generalization experiments across four real-world DR datasets, demonstrating consistent performance gains and robustness under distribution shifts, thereby validating the method’s practical applicability in diverse clinical settings."}, "weaknesses": {"value": "1. Lack of clarity in the role of KL divergence: The paper claims to “minimize KL divergence between domain embeddings” as part of its core learning objective, yet the methodology section provides no explicit formulation or integration of this term into the loss function. It remains unclear whether KL divergence is used for training or merely as a post-hoc evaluation metric. This ambiguity weakens the theoretical contribution and should be clarified through explicit mathematical definition and ablation.\n\n2. Lack of rigor in the neural baseline configuration: The ViT branch is frozen during training, which underrepresents the true capacity of deep domain generalization models. Without end-to-end fine-tuning or comparison against state-of-the-art DG-ViT variants (e.g., MixStyle, SWAD, SAM-ViT), it is difficult to attribute performance gains to the proposed neuro-symbolic integration rather than suboptimal baselines.\n\n3. Lack of justification for the “YOLOv11” component: The paper repeatedly references “YOLOv11” for lesion detection, but no corresponding publication or implementation detail is cited. This raises reproducibility concerns and undermines the reliability of the symbolic feature extraction process. The authors should specify whether this refers to a custom version, and provide architecture differences or open-source access."}, "questions": {"value": "1. How is KL divergence operationalized in training? Could the authors clarify whether the KL term is directly optimized as part of the loss function or only computed for evaluation? If optimized, please provide its explicit formulation, weighting coefficient, and gradient flow path within the network.\n\n2. Why was the Vision Transformer kept frozen? Given that most domain generalization benchmarks fine-tune or partially unfreeze the backbone, could the authors explain the motivation for freezing it, and whether this decision affects the fairness of the comparison with pure deep baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sHu8MCmHYt", "forum": "xAtYHNe0Ey", "replyto": "xAtYHNe0Ey", "signatures": ["ICLR.cc/2026/Conference/Submission24022/Reviewer_oBvR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24022/Reviewer_oBvR"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24022/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761802151808, "cdate": 1761802151808, "tmdate": 1762942901525, "mdate": 1762942901525, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes KG-DG, a framework for domain generalization in diabetic retinopathy (DR) classification. The method is presented as a neuro-symbolic approach that combines a deep learning branch (a Vision Transformer) with a symbolic reasoning branch. The symbolic branch uses auxiliary models (YOLO, U-Net) to extract pre-defined clinical features (e.g., lesion counts, vessel morphology), which are then fed into a machine learning classifier. The predictions from the two branches are combined using a late-fusion strategy. The authors evaluate their method on four public DR datasets in both single- and multi-domain generalization settings, claiming improved robustness and performance over existing baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.  The motivation to incorporate explicit clinical knowledge to guide deep learning models is well-founded and important for building robust and interpretable systems.\n\n2. The authors conduct experiments across four datasets and two different domain generalization setting, comparing against several established baselines.\n\n3. The idea of using a separate symbolic branch provides a degree of interpretability."}, "weaknesses": {"value": "1. The framing of the method as \"Neuro-Symbolic Fusion\" is a overstatement of its novelty. The proposed architecture is a classic two-stream ensemble model with late fusion, where two entirely independent models are trained separately and their outputs are combined post-hoc. There is no tight integration.\n\n2. The framework's performance is critically dependent on auxiliary, pre-trained \"knowledge extractor\" models (YOLOv11, U-Net). The robustness and generalization capability of these extractors are questionable, and their performance directly creates an upper bound for the entire symbolic branch. The paper lacks a thorough analysis of the performance and potential biases of these crucial auxiliary modules.\n\n3. On the SGD setting, in terms of the APTOS and  EYEPACS dataset, the superiority of the proposed method is not clear.\n\n4. The evaluation only focuses on DR datasets, its effectiveness and generalization for other domains remains unexplored in the paper."}, "questions": {"value": "Please see the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zgardwB0Dt", "forum": "xAtYHNe0Ey", "replyto": "xAtYHNe0Ey", "signatures": ["ICLR.cc/2026/Conference/Submission24022/Reviewer_pzLv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24022/Reviewer_pzLv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24022/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902799899, "cdate": 1761902799899, "tmdate": 1762942901171, "mdate": 1762942901171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper integrates structured clinical knowledge with deep learning to improve domain generalization for diabetic retinopathy classification. Specifically, the authors leverage a YOLOv11 model for lesion detection, retinal vein segmentation model, and established clinical guidelines to formulate rule-based diagnostic cues. These knowledge-driven predictions are then combined with deep model outputs using several fusion strategies, yielding a hybrid classifier that aims to enhance robustness and interpretability across domains."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The overall approach is simple and straightforward."}, "weaknesses": {"value": "1.The paper contains several writing and formatting issues (e.g., “effectively” in Line 52, repeated citation in Lines 79–80, and citation formatting problems around Line 82). These should be corrected for clarity and professionalism.\n2.The method diagram appears incomplete and difficult to follow. For instance, the role of the Random Block Selector is unclear and requires further explanation or justification.\n3.The knowledge-based classifier design is not described in sufficient detail. The rule formulation and integration process need a clearer, more systematic explanation to allow reproducibility and proper evaluation.\n4.The overall methodological contribution is limited. Combining rule-based signals with deep learning predictions is intuitive and has been explored in prior literature, which reduces the novelty for a top-tier venue.\n5.The presented results are not particularly strong or convincing, and the reported improvements do not clearly demonstrate significant advantages over existing approaches.\n6.There are incorrect or inconsistent citations (for example, the SDViT author names are wrong). The authors should carefully verify every reference entry and in-text citation for accuracy and correct formatting."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BGWPFvucpE", "forum": "xAtYHNe0Ey", "replyto": "xAtYHNe0Ey", "signatures": ["ICLR.cc/2026/Conference/Submission24022/Reviewer_A8En"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24022/Reviewer_A8En"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24022/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762062695455, "cdate": 1762062695455, "tmdate": 1762942900956, "mdate": 1762942900956, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}