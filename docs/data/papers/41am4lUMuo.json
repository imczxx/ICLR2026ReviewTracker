{"id": "41am4lUMuo", "number": 18844, "cdate": 1758291397909, "mdate": 1759897078142, "content": {"title": "Crime Prediction using Adaptive Quadtrees", "abstract": "Urban crime prediction demands scalable methods for large, skewed spatio-temporal data. We introduce SMART-CARE, an adaptive quadtree-based hierarchical framework that dynamically partitions urban spaces and refines local predictors. Given $\\mathcal{D}=\\{(\\mathbf{x}_i,t_i,c_i)\\}_{i=1}^N$, SMART-CARE learns $f:(\\mathbf{x},t)\\mapsto\\hat{c}$ through: (i) variance-driven median splitting with adaptive capacity $T_{\\max}$ and depth $L_{\\max}$, (ii) periodic local re-tuning with leaf merging to prevent over-fragmentation, and (iii) parent→child knowledge transfer for model fine-tuning. Experiments on NYC and Chicago crime data show SMART-CARE outperforms uniform grids, static quadtrees, and standard baselines in accuracy and efficiency while enabling fine-grained localized forecasts.", "tldr": "", "keywords": ["Scalable Hierarchical Crime Prediction", "Adaptive Quadtree", "Regression", "Ensemble Modelling", "Clustering"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/732b684246af248f184852f3f41f1876495f5e06.pdf", "supplementary_material": "/attachment/c9413898320fb7709b13ec028720b6ca713d3041.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a dynamic partitioning algorithm of urban spaces for scalable crime prediction. It utilizes an adaptive quadtree framework with node/capacity thresholds derived from available data, performs spatial balancing through median-based splitting on longitudes/latitudes, retains parent point data for knowledge transfer by referencing from child nodes, and employs density-based small-leaf merging to prevent partitioned regions from being too fine. Additionally, it uses a hierarchical regression scheme for node-level predictions, instantiated with both tree and neural architectures."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper focuses on spatial partitioning of complex geometries for crime prediction. \n\nIt is well-written with an appropriate level of detail. \n\nThe results as compared to other works in crime prediction using spatial partitions are promising, noting an improved ability to parse complex relationships in large datasets like NYC and Chicago."}, "weaknesses": {"value": "The proposed approach is a bit dated, focusing on the spatial dimension. Spatial partitioning has been studied well before.\n\nThe work doesn't address current SOTA in spatiotemporal forecasting, which focus more on neural approaches. Contemporary methods also model spatiotemporal crime dynamics using probabilistic models such as self-exciting point processes for more accurate forecasting. \n\nThe connection to ICLR in terms of insights into learning representations is not clear."}, "questions": {"value": "Can you add comparison to more contemporary spatiotemporal works?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "z0QZ5PmwlC", "forum": "41am4lUMuo", "replyto": "41am4lUMuo", "signatures": ["ICLR.cc/2026/Conference/Submission18844/Reviewer_9B6w"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18844/Reviewer_9B6w"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18844/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959601632, "cdate": 1761959601632, "tmdate": 1762930811981, "mdate": 1762930811981, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SMART-CARE, a novel framework for urban crime prediction that combines an adaptive quadtree (SMART-QT) for spatial partitioning and a hierarchical prediction mechanism (CARE). The quadtree adaptively partitions space based on crime variance and data density, while the CARE ensemble refines predictions at each level using parent-child knowledge transfer. Evaluated on large-scale NYC and Chicago datasets, SMART-CARE outperforms prior methods including clustering, static trees, and deep learning-based transfer learning, with superior accuracy (MAE = 0.92 average) and efficiency. The framework supports both tree-based and neural instantiations, demonstrating flexibility and scalability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* Proposes a well-structured and scalable spatio-temporal prediction framework (SMART-CARE) combining adaptive quadtree partitioning with hierarchical model refinement.\n* Effectively utilizes feature propagation and model inheritance to transfer knowledge across spatial scales, enabling fine-grained yet stable local predictions.\n* Demonstrates consistent and strong empirical performance on two large-scale, real-world datasets, outperforming several baselines including SARIMA, BiLSTM, static quadtrees, and clustering methods.\n* Offers architectural flexibility, supporting both tree-based models (e.g., XGBoost) and neural networks (e.g., GRU, LSTM, Transformer), indicating generalizability.\n* Provides thorough implementation details and visualizations to support reproducibility and interpretability."}, "weaknesses": {"value": "* The model inheritance mechanism plays a central role in the proposed framework but lacks an explicit ablation study isolating its effect. Current comparisons (e.g., with AMB-LNPM) involve simultaneous changes in spatial partitioning, making it difficult to assess the independent contribution of inheritance.\n* Neural network variants are only lightly analyzed. While the framework claims support for NN models, most discussions and evaluations focus on tree-based models. More detailed analysis on how neural models behave (e.g., with respect to sequence length, stability, hierarchy depth) is missing.\n* Most figures and tables use very small fonts, which affects readability and weakens the overall presentation.\n* More importantly, the paper’s contribution is primarily in the design of an application-specific forecasting pipeline, with limited connection to representation learning questions. The lack of discussion or analysis around representation learning makes the relevance to ICLR questionable."}, "questions": {"value": "* Have you conducted ablation studies that isolate the effect of model inheritance while keeping the spatial partitioning fixed? This would help clarify how much of the performance gain is specifically attributable to inheritance.\n* What role do neural models (GRU, LSTM, Transformer) play within SMART-CARE beyond demonstrating generality? Are there scenarios where they outperform tree-based models or provide unique advantages? Further discussion on performance trade-offs, convergence behavior, and architectural compatibility would be valuable.\n* Do you consider any aspect of your method as contributing to general representation learning, or transferable feature learning, beyond the specific domain of crime prediction?"}, "flag_for_ethics_review": {"value": ["Yes, Discrimination / bias / fairness concerns"]}, "details_of_ethics_concerns": {"value": "Since the proposed model is applied to crime prediction, there may be risks of reinforcing societal bias or potential misuse, such as discriminatory targeting or misinterpretation of predictions."}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "RUyr1yiuE4", "forum": "41am4lUMuo", "replyto": "41am4lUMuo", "signatures": ["ICLR.cc/2026/Conference/Submission18844/Reviewer_WzmL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18844/Reviewer_WzmL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18844/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984354582, "cdate": 1761984354582, "tmdate": 1762930811662, "mdate": 1762930811662, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "I voted for desk reject; see the extensive private discussion among reviewers prior to review."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "see above"}, "weaknesses": {"value": "* Methodologically, the proposed algorithm is not a representation learning approach but rather a partitioning algorithm that offers limited novelty and is largely consistent with existing methods. IMHO: The fit with ICLR is weak, as the paper does not engage with or advance core topics in representation learning.\n* The code provided is not reproducible: key components such as hyperparameter tuning procedures are missing / not reported, and several data files are absent. There is also no README nor documentation, making replication impossible.\n* Moreover, the paper fails to situate its work within relevant literature. For example, in the domain of crime forecasting, there are extensive theoretical frameworks on spatio-temporal crime dynamics, including self-exciting processes and related models. (The spatial dimension is treated via the partioning but SOTA method often use convolutional / ResNet layers that keep the spatial structure in tact and then predict ahead-of-time) None of these are cited or discussed.\n* The empirical evaluation is also insufficient: the baselines and benchmarks (see previous points) are largely missing.\n* The benchmarking setup is not realistic (see appendix D.4). It's unclear whether the temporal order is intact; but I think it could predict \"previous crime\" from \"feature \"events\", leading to information leakage over time.\n\nOverall, the submission lacks novelty, rigor, and relevance, and does not meet the minimum standards for ICLR. I therefore recommend desk rejection to save everyone unnecessary workload."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "yCI6yyHspW", "forum": "41am4lUMuo", "replyto": "41am4lUMuo", "signatures": ["ICLR.cc/2026/Conference/Submission18844/Reviewer_dAMW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18844/Reviewer_dAMW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18844/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762085683460, "cdate": 1762085683460, "tmdate": 1762930810865, "mdate": 1762930810865, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SMART-CARE, combining an adaptive quadtree for variance-aware median splitting with a hierarchical predictor that propagates parent predictions as features and warm-starts child models. Experiments on NYC and Chicago datasets show large gains, along with O (log n) inference via at-most-one model per tree level."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Clear idea of combining adaptive spatial partitioning with hierarchical residual refinement. The design aims for O(log n) routing at inference.\n- Practical top-down training and inference procedure with clear pseudocode; parent-to-child feature propagation and parameter inheritance are easy to implement.\n- Evaluated on public datasets and conducted some efficiency discussion;"}, "weaknesses": {"value": "- Clarity and writing quality are poor: frequent typos, duplications and inconsistent naming (e.g., line 41“Butt et al. (2021)”; “QREPM” appears once without definition; “AMB_LNPM/SMID-LNPM” introduced but not clearly motivated; “Appendex” spelling). These issues make the paper difficult to follow and cast doubt on rigor.\n- Inconsistencies in data description: NYC size is variously “7.8M” and “7.9M”.\n- Method novelty is incremental: adaptive quadtrees and warm-starting models are known ideas; the paper mainly aggregates heuristics (variance-aware thresholds, IQR-merging, parent-prediction feature). The contribution is more engineering than a new learning principle, but it’s framed as a major algorithmic advance. \n- Baselines are weak, stronger recent spatio-temporal baselines (e.g., GNN, transformer and Mamba) are missing. \n- The claimed O (log n) inference depends on enforcing a max depth L_max, not on a proven property of the adaptive quadtree, under skewed spatial distributions there’s no guarantee depth is logarithmic, so the complexity claim isn’t theoretically secured. And the empirical timing results omit key methodological details such as hardware specifications, batch.\n- Evaluation protocol is under-specified and risks leakage: the paper uses generic 80/20 split, but for spatiotemporal forecasting one expects time-ordered splits and region-held-out tests. The method heavily uses parent predictions as features; with random splits or standardization done on node-level data that inadvertently includes test points, leakage is plausible. The “D_t = ⋃_{i=1}^t Y_i” description does not clearly state how test years are held out and how lagged features are computed strictly from past data only. \n- Feature-importance results raise concerns: “Prediction” (the inherited, model-generated feature) dominates importance, paired with unclear data splits, which could be symptomatic of leakage or target-driven shortcuts rather than robust spatiotemporal reasoning. \n- Reproducibility: The paper gives insufficient detail on data processing."}, "questions": {"value": "- How exactly are split thresholds chosen at each node? What are the precise stopping rules beyond minimum leaf size, and are they validated per node or globally?\n- What is the principled criterion for merging? Is merging applied once after the tree is grown or iteratively during growth? Does merging depend on label distribution or only counts?\n- What is the exact normalization behind MAE ≈ 0.92 / 0.23? Are errors per-leaf, per-day, or normalized by region size? \n- Why are strong spatiotemporal MLP, GNN, Transformer and Mamba baselines absent? \n- When you standardize the parent predictions “within Dν,” are the statistics computed only on the training subset of that node? How is this handled for test points routed to the same node?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ocpneAjp6L", "forum": "41am4lUMuo", "replyto": "41am4lUMuo", "signatures": ["ICLR.cc/2026/Conference/Submission18844/Reviewer_nTGr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18844/Reviewer_nTGr"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18844/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762235222334, "cdate": 1762235222334, "tmdate": 1762930810321, "mdate": 1762930810321, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}