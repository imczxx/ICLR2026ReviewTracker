{"id": "gTVWb28meX", "number": 5901, "cdate": 1757944588756, "mdate": 1763749825217, "content": {"title": "Approximate Inference Suffices for Statistical Distance Estimation", "abstract": "Statistical distance (also known as total variation distance) and probabilistic inference are fundamental notions, widely used in machine learning, information theory, and high-dimensional statistics.\nWhile there are efficient algorithms that can estimate statistical distance or probabilistic inference in some specific settings, it has remained an open problem to see whether these two notions can be approximately reduced to each other.\nIn this work, we take the first step in addressing this problem, and show that estimating statistical distance can be reduced to estimating probabilistic inference, via an efficient structure preserving randomized reduction.\nThis allows us to use approximate inference algorithms to multiplicatively estimate statistical distance in directed graphical models.", "tldr": "", "keywords": ["statistical distance", "probabilistic inference", "reductions"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f4e999c7feab0de40328ce26874e75e689a393f2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors consider the problem of estimating statistical distance between two Bayes nets using approximate probabilistic inference queries. Roughly, the problem is defined as follows. \n\nFirst, the probability distribution of a Bayes net is as follows: Given a directed graph and a collection of conditional probability tables, the probability of a labeling of the vertices is given by the product of the conditional probabilities of all vertex labels. \nThe statistical distance between two distributions is the $\\ell_1$ distance between two distributions viewed as vectors.\nThe goal is to compute statistical distance using approximate probabilistic inference queries: for any arbitrary sets S_1, …, S_n, compute (up to approximate multiplicative error), the probability $X_i \\in S_i$ for all $I$.\n\nThe general approach of previous works was to define an estimator $f$ and distribution $\\pi$ such that the expected value of $f$ over $\\pi$ is the statistical distance (possibly normalized by some easy to compute constant $Z$). The authors compute an auxiliary Bayes net where the labels are distributed over a joint distribution $(X, Y)$ with $X \\sim P, Y \\sim Q$. The two key steps are then to construct the appropriate $f, \\pi$ and estimate $Z$. In this work, the authors show how to sample from and estimate parameters of the relevant distributions using approximate probabilistic inference oracles, rather than exact oracles.\n\nConclusion\n\nOverall, the paper studies an interesting question and finds a nice reduction between two well studied problems. For this reason, I tend towards accept. However, as I am not a domain expert, I found the paper a bit hard to follow (see below comment on usage of prior work) and thus assign a low confidence score. While I did not check the details very closely, the claims seem reasonable and the proofs I did check seem correct."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "The paper considers the natural problem of estimating statistical distance in Bayes nets. They establish an interesting result, that statistical distance can be estimated with approximate probabilistic inference queries. This can be viewed both positively and negatively: 1) hardness results in statistical distance estimation can imply that probabilistic inference is hard, or 2) algorithms for probabilistic inference can directly by applied to statistical distance estimation."}, "weaknesses": {"value": "Perhaps due to the fact that I am not very familiar with the techniques in the paper, the algorithm are a bit hard to follow. Many details seem to be elided over: 1) what is importance sampling? (Yes a standard technique, but good to define and motivate). 2) How do you “carefully” define the CPT to ensure the condition required in 152? 3) Why is $Z = \\Pr(X \\neq Y)$? And this seems crucial so it is strange there is no justification for this. More generally, it feels that this paper builds off Bhattacharya et al 2024 in a significant way, but does not do so in a self-contained way, assuming the reader has read the prior work."}, "questions": {"value": "It seems to me that the joint distribution $(X, Y)$ is supposed mimic coupling such that $\\Pr(X \\neq Y) \\sim TVD(P, Q)$ i.e. the optimal coupling. If this is the case, why not just estimate $Z$? \n\nMinor Comments \n\n110 - should running time of FPRAS by polynomial in $\\log(1/\\delta)$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "u9IaqqsjCD", "forum": "gTVWb28meX", "replyto": "gTVWb28meX", "signatures": ["ICLR.cc/2026/Conference/Submission5901/Reviewer_DM9u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5901/Reviewer_DM9u"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761280761385, "cdate": 1761280761385, "tmdate": 1762918337265, "mdate": 1762918337265, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors prove that estimating total variation distance between probability distributions over the same underlying directed acyclic graph (DAG) can be reduced to approximate probabilistic inference while previous work by Bhattacharyya et al. (2024) showed this reduction was possible with exact probabilistic inference.\nThe main idea is to perform normalization estimation, approximate sampling and Monte Carlo estimation and hence construct the reduction by designing an FPRAS (Fully Polynomial-time Randomized Approximation Scheme).\nThe authors show that one only needs $O(n^3\\ell^2\\epsilon^{-2} \\log \\delta^{-1})$ approximate inference queries where $n$ is the number of nodes in the DAG and $\\ell$ is the range of the random variables to approximate the total variation distance up to an $(1\\pm \\epsilon)$ factor with probability $1-\\delta$."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The result extends the previous limitation that such a reduction can be done with exact probabilistic inference."}, "weaknesses": {"value": "- The result may be incremental that the main idea is from the previous work (Bhattacharyya et al.)"}, "questions": {"value": "- Line 137: I am not sure what we are normalizing with $Z$.\n\n- Line 144: It may be helpful to mention that $g$ is the surrogate function for $g^\\ast$"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "SxkfLY6qaH", "forum": "gTVWb28meX", "replyto": "gTVWb28meX", "signatures": ["ICLR.cc/2026/Conference/Submission5901/Reviewer_ZwwX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5901/Reviewer_ZwwX"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761547189853, "cdate": 1761547189853, "tmdate": 1762918336921, "mdate": 1762918336921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the computational relationship between two fundamental problems—statistical distance estimation (specifically total variation distance) and probabilistic inference in Bayesian networks. Building on recent work (Bhattacharyya et al., 2024), which showed a reduction from statistical distance estimation to exact probabilistic inference, this paper proposes a reduction to approximate probabilistic inference instead. The main claim is that there exists an FPRAS for estimating total variation distance using approximate inference queries, potentially broadening the applicability of such methods to practical settings where exact inference is infeasible."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper targets an important and fundamental question in computational learning theory, i.e., linking statistical distance estimation and probabilistic inference"}, "weaknesses": {"value": "- The paper is entirely theoretical with no numerical experiments or case studies to demonstrate how the proposed algorithms might perform in realistic scenarios.\n\n- While technically detailed, the paper is difficult to follow. Algorithmic steps (especially in Algorithms 2 and 3) are densely described without clear intuition or illustrative examples. The exposition would benefit from diagrams or toy examples linking the theory to intuitive settings."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "UIVgIj5wsM", "forum": "gTVWb28meX", "replyto": "gTVWb28meX", "signatures": ["ICLR.cc/2026/Conference/Submission5901/Reviewer_MD4a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5901/Reviewer_MD4a"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761633661156, "cdate": 1761633661156, "tmdate": 1762918336196, "mdate": 1762918336196, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors study the problem of computing the total variation distance between two probability distributions $P$ and $Q$, each represented as Bayesian networks defined on the same directed acyclic graph (DAG) $G$. The objective is to estimate the total variation distance $d_{TV} (P,Q)$ between these two distributions.\n\nIn their ICML 2024 paper, Bhattacharyya et al. established a key connection between total variation distance estimation and probabilistic inference. They showed that if one has access to an exact probabilistic inference oracle, the total variation distance between two Bayes nets can be computed in polynomial time via an exact reduction. However, this reduction critically depends on exact computation of certain normalization constants such as $Z=Pr⁡[X\\neq Y]=1-Pr⁡[X=Y]$. When only approximate inference is available, multiplicative errors in estimating $Pr⁡[X=Y]$ can amplify dramatically in its complement $1-Pr⁡[X=Y]$, especially when $Pr⁡[X=Y]$ is close to $1$. As a result, even small relative errors in inference can lead to unbounded relative errors in the estimated total variation distance.\n\nThe present paper overcomes this instability by introducing a new, structure-preserving randomized reduction that avoids direct dependence on such complements. It demonstrates that access to a $(1+\\varepsilon)$–relative approximate inference oracle suffices to obtain a $(1+\\varepsilon)$–approximation of $d_{TV}(P,Q). This establishes the first reduction from total variation distance estimation to approximate probabilistic inference, thereby strengthening the algorithmic connection between the two problems.\n\nTo obtain this result, the authors adapt the classical Jerrum–Valiant–Vazirani paradigm that connects approximate counting and sampling, extending it to the setting of Bayesian networks. They develop an importance-sampling framework that estimates normalization constants and draws approximate samples using only approximate inference queries, while carefully controlling the propagation of multiplicative errors."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper makes an interesting contribution by strengthening the connection between two classical and well-studied problems in machine learning, namely, statistical distance estimation and probabilistic inference. The technical approach appears non-trivial."}, "weaknesses": {"value": "My main concern is that the result feels somewhat incremental relative to prior work. Since both exact and relative approximate inference, as well as total variation distance estimation, are known to be #P-hard, the strengthened reduction does not yield new tractable cases. Consequently, the practical algorithmic implications of this improved connection appear limited."}, "questions": {"value": "Are there specific classes of models or structural assumptions under which approximate inference is known to be tractable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Qul5CPnxtp", "forum": "gTVWb28meX", "replyto": "gTVWb28meX", "signatures": ["ICLR.cc/2026/Conference/Submission5901/Reviewer_pxw5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5901/Reviewer_pxw5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761848011615, "cdate": 1761848011615, "tmdate": 1762918335406, "mdate": 1762918335406, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the relation between learning total variation distance and probabilistic inference in Bayesian nets. The authors show that total variation distance can be approximated in polynomial time using an approximate probabilistic oracle for Bayesian nets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The authors establish a strong theoretical connection between probabilistic inference and estimating total variation distance in Bayesian nets. The authors prove that it is possible approximate the total variation distance between Bayes nets in fully polynomial time using approximate oracles for probabilistic inference, which estimates the probability of any given event. This improves upon the work of Bhattacharya et.al. 2024 which required exact probabilistic inference oracles."}, "weaknesses": {"value": "The writing and presentation needs improvement. While many results are developed from the previous work, Bhattacharya et.al. 2024, it is important to make the proof and statements self-contained."}, "questions": {"value": "1. Are there time complexity lower bounds for the reduction? I guess a $\\Omega(n^2)$ lower bound is trivial which is the time to write down the nodes and edges. Could one argue something better than this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UTmDWJLGLX", "forum": "gTVWb28meX", "replyto": "gTVWb28meX", "signatures": ["ICLR.cc/2026/Conference/Submission5901/Reviewer_qjsT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5901/Reviewer_qjsT"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission5901/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762646566872, "cdate": 1762646566872, "tmdate": 1762918334918, "mdate": 1762918334918, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}