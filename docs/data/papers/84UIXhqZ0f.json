{"id": "84UIXhqZ0f", "number": 23368, "cdate": 1758342728603, "mdate": 1759896818725, "content": {"title": "A Benchmark and Pair-Level 4PL-IRT Framework for Reliable Evaluation of LLM Reasoning", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet reliably evaluating their reasoning ability, particularly in symbolic reasoning, remains an open challenge. In this work, we introduce a novel evaluation framework based on Item Response Theory (IRT), applied at both the pair level and instance level, and compare its effectiveness against traditional metrics such as Accuracy, F1, and MCC. Through extensive experiments across multiple LLMs, we show that while conventional metrics provide limited and sometimes misleading signals, IRT-based measures---especially under the 4PL model at the pair level---offer more stable and reliable insights into the reasoning competence of LLMs. Our study further presents a new benchmark suite for symbolic reasoning, along with a principled methodology for its generation and evaluation. This framework not only highlights the shortcomings of standard metrics, but also establishes IRT as a more trustworthy foundation for assessing the reasoning abilities of LLMs. We argue that such rigorous evaluation methods are essential for guiding the future development of LLMs toward robust reasoning performance.", "tldr": "A novel IRT-based evaluation method to measure LLMs’ symbolic reasoning ability at pair and instance levels.", "keywords": ["large language models", "reasoning", "evaluation", "symbolic reasoning", "benchmarks", "item response theory"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/25aba4ebae727cb0c5f33f6cfead1126b7e6f731.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper argues that standard metrics for evaluating Large Language Models (LLMs)—such as Accuracy, F1-score, and MCC—are unreliable and often misleading, especially for complex symbolic reasoning tasks. To solve this, the authors propose a new evaluation framework based on Item Response Theory (IRT), a sophisticated statistical model used in psychometrics (e.g., standardized testing) to measure a subject's \"latent ability\" (their true skill level). The authors conclude that the 4PL-IRT model is the most stable and reliable method. It avoids the pitfalls of simple accuracy and, by accounting for both guessing and ceiling effects, provides a much more trustworthy assessment of an LLM's true reasoning competence. The paper introduces a new symbolic reasoning benchmark to test this framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. its direct and well-supported critique of using simple accuracy to measure reasoning. It clearly shows (in Figures 1-5) how metrics like Accuracy and F1 are unstable and fail to capture the nuances of a model's ability.\n\n2. applying IRT to LLM evaluation is a novel and powerful idea. Instead of just a simple score, IRT provides a model-based estimate of a model's \"ability\" that is separate from the \"difficulty\"  of the questions, which is far more insightful.\n\n3. the comparison of 2PL, 3PL, and 4PL models makes a compelling case for the 4PL model, as it uniquely accounts for both random \"guessing\" at the low end and \"ceiling effects\" (inconsistent success) at the high end. This provides a much more realistic picture of a model's behavior.\n\n4. it contributes a new benchmark suite specifically for symbolic reasoning (2SAT, 3D packing, Vertex Cover), which is essential for rigorously testing its new evaluation framework."}, "weaknesses": {"value": "1. the proposed 4PL-IRT framework is vastly more complex to implement and interpret than simply calculating accuracy. This presents a significant barrier to adoption for many researchers and developers who may lack the necessary psychometric background.\n\n2. more complex statistical models like 3PL and 4PL require more data to produce stable and reliable parameter estimates. The paper notes this (lines 204-209), suggesting this framework may be unsuitable for small-scale benchmarks or quick evaluations."}, "questions": {"value": "Is the complexity of the 4PL-IRT model truly necessary? Could simpler, more interpretable metrics (perhaps improved versions of traditional ones or specific behavioral tests) achieve similar reliability without the high statistical overhead?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HHkHaYdtpE", "forum": "84UIXhqZ0f", "replyto": "84UIXhqZ0f", "signatures": ["ICLR.cc/2026/Conference/Submission23368/Reviewer_eh42"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23368/Reviewer_eh42"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23368/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761451745949, "cdate": 1761451745949, "tmdate": 1762942630964, "mdate": 1762942630964, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper intends to introduce a new evaluation framework for symbolic reasoning based on Item Response Theory (IRT). However, the paper appears to be incomplete, missing substantial sections that describe the proposed framework and the experiments conducted. Given that only one of the six chapters contains text (in bullet points), it is not possible to properly assess its content or contributions."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "N/A — Given the current state of the paper, it is not possible to assess the strength of its contributions.\n\nThis should have been a desk reject IMO."}, "weaknesses": {"value": "As mentioned before, the paper appears to be incomplete. Since substantial parts are missing and its content and contributions cannot be properly assessed, as such and mentioned above I suggest (desk-)rejecting this paper."}, "questions": {"value": "n/a"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "RNKOGqx5mC", "forum": "84UIXhqZ0f", "replyto": "84UIXhqZ0f", "signatures": ["ICLR.cc/2026/Conference/Submission23368/Reviewer_bfV1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23368/Reviewer_bfV1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23368/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761720150576, "cdate": 1761720150576, "tmdate": 1762942630167, "mdate": 1762942630167, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a novel framework for evaluating the reasoning abilities of large language models (LLMs) using Item Response Theory (IRT), with a focus on symbolic reasoning tasks. The authors propose a pair-level 4PL-IRT model for more reliable and interpretable assessment of model performance. They compare this new framework against traditional metrics (such as accuracy, F1, and MCC) and demonstrate that IRT-based evaluations, especially at the pair level, provide more stable and insightful analysis. Through extensive experiments, the paper shows how different IRT models (2PL, 3PL, 4PL) capture varying aspects of model performance, offering more nuanced insights into LLM capabilities."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The authors provide a thorough explanation of the IRT models (2PL, 3PL, and 4PL) and how they differ in their ability to capture various aspects of LLM performance. The comparison across these models is well-detailed, highlighting the benefits of the 4PL model in dealing with guessing and ceiling effects."}, "weaknesses": {"value": "1.While the paper focuses on IRT models, it could benefit from further exploration of other evaluation frameworks or hybrid models that combine traditional metrics with IRT for more comprehensive insights. The focus on symbolic reasoning tasks could also be expanded to include other domains.\n\n2.The paper does not address the computational overhead of using IRT, especially the more complex 4PL model. This could be a concern when applying the methodology to large-scale LLMs or tasks with a high volume of data. Further discussion on the scalability of the approach would enhance its practical value.\n\n3.The experiments focus heavily on comparing models within specific tasks, but there is limited exploration of how generalizable the IRT framework is across diverse problem domains. It would be useful to see how well this approach extends to tasks outside symbolic reasoning, such as natural language understanding.\n\n4.The paper would greatly benefit from a framework diagram to clearly illustrate the proposed methodology. While the experiments are comprehensive, the analysis of the experimental results could be more detailed. The paper presents a lot of data but doesn’t provide an in-depth breakdown of how the results vary across models and tasks. A more qualitative analysis discussing the significance of the observed patterns, and a deeper dive into the implications of these results for model development, would enhance the paper’s contribution."}, "questions": {"value": "please see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "K2aqFEv4n9", "forum": "84UIXhqZ0f", "replyto": "84UIXhqZ0f", "signatures": ["ICLR.cc/2026/Conference/Submission23368/Reviewer_8H81"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23368/Reviewer_8H81"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23368/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974666118, "cdate": 1761974666118, "tmdate": 1762942629267, "mdate": 1762942629267, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "I think a crucial mistake was made by the authors when they composed the manuscript - Many paragraphs of many sections are missing."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "In complete submission."}, "weaknesses": {"value": "Incomplete submission."}, "questions": {"value": "Is it only me that failed to see so many paragraphs in the pdf?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5lh7iTatW5", "forum": "84UIXhqZ0f", "replyto": "84UIXhqZ0f", "signatures": ["ICLR.cc/2026/Conference/Submission23368/Reviewer_XcMH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23368/Reviewer_XcMH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23368/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762061678777, "cdate": 1762061678777, "tmdate": 1762942628920, "mdate": 1762942628920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}