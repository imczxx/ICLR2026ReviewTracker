{"id": "aKltXivka4", "number": 21591, "cdate": 1758319383263, "mdate": 1759896913494, "content": {"title": "Improving  Autoencoder Performance on Sparse Binary Data through Sparsity-Aware Loss Functions", "abstract": "Conventional reconstruction losses for autoencoders such as mean squared error (MSE) and binary cross-entropy (BCE) are poorly suited for sparse binary data. These measures can achieve deceptively low loss by trivially predicting the dominant zeros, while failing to capture the rare but informative non-zero entries. Prior work has primarily focused on architectural modifications or training heuristics to address this issue, leaving the design of loss functions largely overlooked. In this work, we shift focus to the reconstruction loss itself, exploring sparsity-aware reconstruction losses by extending focal loss, dice loss, and related formulations to the autoencoder setting. We evaluate their effect on both reconstruction fidelity and embedding quality across multiple sparse datasets, showing that these alternatives outperform MSE and BCE on metrics sensitive to rare events. Our results demonstrate that the choice of loss function is a critical but underappreciated factor in learning effective representations from sparse binary data.", "tldr": "Incorporating sparsity-awareness into reconstruction losses enhances autoencoder fidelity, representation quality, and downstream utility on sparse binary data.", "keywords": ["Autoencoders", "sparse binary data"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/dfae01a540e89380856980753503d4b8e2573857.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents the results of an extensive experimental study in which the authors seek to understand which existing losses for training autoencoders are more suitable (according to various evaluation criteria) in a setting where the inputs are binary and sparse."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The experimental section considers multiple different AE methods and a broad range of evaluation metrics.\n- Some of the experimental results could be important to a relevant audience, provided that they are presented and motivated appropriately."}, "weaknesses": {"value": "- The motivation for the setting considered in the paper could be improved. In particular, it is unclear why obtaining a sparse latent representation is important. The only two downstream tasks being considered (linear regression and classification) can be adapted to work well with sparse data by incorporating sparsity-inducing regularization.\n- The paper should be better positioned in the existing literature. Currently, the manuscript has a rather limited literature review of about 15 references, despite the area of (sparse) representation learning being a rich and active area of research.\n- The extensive experimental results could be presented in an easier-to-digest way that highlights more clearly what the main takeaways are. Currently, the main contribution seems to be the conclusion that some losses are better suited for certain evaluation criteria, which is a somewhat expected outcome of any extensive empirical study such as the one presented in this paper. It would help if the paper formulated hypotheses about what the likely causes for the mixed results presented in Table 6 are.\n\n**Minor issues**\n\n- Some of the claimed contributions are not sufficiently justified. For example, contribution 1 (lines 47-48) claims “a formal analysis of how sparsity affects standard reconstruction objective”, however, the paper only presents empirical analyses (no formal statements). Moreover, in line 151 it is stated that “To assess our claims experimentally, we train AEs for each dataset on each loss”. However, it is unclear at this point what the claims are.\n- Figure 1 is never referenced in the text. Moreover, its setting is never thoroughly described."}, "questions": {"value": "- How do the numbers in figure 5 compare to running LASSO linear/logistic regression in input space?\n- Are there any consistent phenomena revealed by the rather extensive experiments that were run for the paper? For instance, are there classes of losses that consistently show certain behaviors, and what are the explanations for them? Can additional ablations or theoretical analyses suggest potential causes for some of the observations in Table 6?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "y9PflQzdgX", "forum": "aKltXivka4", "replyto": "aKltXivka4", "signatures": ["ICLR.cc/2026/Conference/Submission21591/Reviewer_JLiz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21591/Reviewer_JLiz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21591/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761498707619, "cdate": 1761498707619, "tmdate": 1762941847453, "mdate": 1762941847453, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The current paper studies the application of Dice loss (Sudre et al. (2017)) and Focal loss (Lin et al. (2017)) together with weighted variants of Binary Cross-Entropy (BCE) and Mean Squared Error (MSE) within the context of training autoencoders on sparse binary data. Evaluations are performed on the Netflix, IMDB and Rheumatic datasets to assess the impact of each loss in terms of the quality of the reconstructions, the embedding structure and the impact upon downstream performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The paper is clearly written and easy to follow  \n- The evaluation features multiple criteria and multiple metrics are employed for each criteria. Average Precision and the Non-trivial Pairwise Contingency Score are used to measure reconstruction quality. The embedding structure is evaluated in terms of trustworthiness and the Calinski–Harabasz Score. Downstream utility is measured for both classification and regression tasks."}, "weaknesses": {"value": "The main weakness of the current work is the lack of novelty. As it stands, the paper presents a straight-forward evaluation of existing losses specifically designed for the task at hand, i.e. to address significant imbalances. Given the fact that the paper does not propose a novel approach (in terms of either the loss function, the architecture or the training regime) a new challenging and realistic benchmark that could be interesting or useful for the community and because it does not present any new insights (i.e. the chosen losses are expected to work well in these scenarios are they are specifically designed to address imbalances), the work is not competitive with the existing ICLR submissions."}, "questions": {"value": "- Can the authors propose a new loss function?\n- Can the authors describe the revelance of sparse binary autoencoders within the current literature?\n- Are there any new benchmarks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PCuHSVooMq", "forum": "aKltXivka4", "replyto": "aKltXivka4", "signatures": ["ICLR.cc/2026/Conference/Submission21591/Reviewer_6a69"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21591/Reviewer_6a69"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21591/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761840977796, "cdate": 1761840977796, "tmdate": 1762941847248, "mdate": 1762941847248, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper performs a comparison of different sparsity-aware loss function for autoencoders using binary input features."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "N/A"}, "weaknesses": {"value": "1. I don't understand the contribution of the paper. In its current form, the paper simply performs a comparison of different loss functions that are well-known in the literature. \n\n2. The motivation behind the problem setup is unclear. Why are binary input features an important setting for autoencoders? The experimental setting doesn't provide any insight into this issue as only classification datasets are explored. The paper doesn't provide comparison with classifiers.\n\n3. Why is this task important to study in the current regime of powerful models? Each of these tasks could be easily solved using LLMs or embedding-based retrievers. The paper should provide comparison with the state-of-the-art methods in each setting."}, "questions": {"value": "1. What is the proposed method in this paper? Currently, it appears to be an ablation study of different losses. \n2. The paper should provide clarification about what tasks necessitate the use of autoencoders using binary features. What are the limitations of existing machine learning frameworks in solving such tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PGJfTYWTAX", "forum": "aKltXivka4", "replyto": "aKltXivka4", "signatures": ["ICLR.cc/2026/Conference/Submission21591/Reviewer_do7a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21591/Reviewer_do7a"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21591/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761934650523, "cdate": 1761934650523, "tmdate": 1762941846930, "mdate": 1762941846930, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to modify reconstruction losses for sparse data reconstruction. The authors analytically show that BCE and MSE are not well-suited for highly sparse data due to the imbalance between class 0 and 1. They introduce class weighting for MSE and BCE, and also explore the use of Focal Loss and Dice Loss for this problem. Experiments are conducted using autoencoders to reconstruct five different high-sparsity datasets (derived from three datasets but with different sparsity thresholds). Results show a trade-off between sparsity-aware losses and MSE/BCE in terms of average precision score and contingency score. Experiments also indicate that sparsity-aware losses are better for downstream tasks that use embeddings from the autoencoder models.\n\nClaimed Contributions:\n\n1. Demonstrates that BCE/MSE are not suitable for sparse datasets.\n\n2. Introduces class weighting and the use of Focal & Dice Loss for sparse data reconstruction.\n\n3. Experiments on sparse datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper addresses a well-known and meaningful problem.\n\n2. Figure 6 clearly highlights which losses are best for which tasks, improving readability, and can be useful for other researchers for their own research!"}, "weaknesses": {"value": "0. This is a well-known problem, and many existing works already address class imbalance using weighting schemes, L1 norms, etc. The paper lacks comparison to these existing methods; related work and experimental comparisons are very limited.\n\n1. Limited novelty: using class weighting and well-known losses like Focal and Dice Loss are minor modifications.\n\n2. Unclear goal: The paper title suggests \"improving autoencoder performance,\" but experiments show that sparsity-aware losses have worse average precision. Downstream utility is better for Weighted MSE, but it is arguable whether this truly improves autoencoder performance. The authors should demonstrate strong performance across multiple aspects of autoencoders.\n\n3. Unclear contribution: Weighting schemes and Focal/Dice losses are already well-known solutions.\n\n4. Limited dataset variety: Only three datasets are tested, and results are not very strong."}, "questions": {"value": "I have one main question for the authors: It is unclear how the embeddings from the autoencoder models are used for downstream tasks. Are they taken from the latent space?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eRfgrhMMSb", "forum": "aKltXivka4", "replyto": "aKltXivka4", "signatures": ["ICLR.cc/2026/Conference/Submission21591/Reviewer_DyiF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21591/Reviewer_DyiF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21591/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762037191463, "cdate": 1762037191463, "tmdate": 1762941846708, "mdate": 1762941846708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}