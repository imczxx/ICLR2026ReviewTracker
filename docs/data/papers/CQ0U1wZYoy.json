{"id": "CQ0U1wZYoy", "number": 18346, "cdate": 1758286706023, "mdate": 1763609375275, "content": {"title": "PRISM: Controllable Diffusion for Compound Image Restoration with Scientific Fidelity", "abstract": "Scientific and environmental imagery are often degraded by multiple compounding factors related to sensor noise and environmental effects. Existing restoration methods typically treat these compound effects by iteratively removing fixed categories, lacking the compositionality needed to handle real-world mixtures and often introducing cascading artifacts, overcorrection, or signal loss. We present PRISM (Precision Restoration with Interpretable Separation of Mixtures), a prompted conditional diffusion framework for expert-in-the-loop controllable restoration under compound degradations. PRISM combines (1) compound-aware supervision on mixtures of distortions and (2) a weighted contrastive disentanglement objective that aligns compound distortions with their constituent primitives to enable high-fidelity joint restoration. We outperform image restoration baselines on unseen complex real-world degradations, including underwater visibility, under-display camera effects, and fluid distortions. PRISM also enables selective restoration. Across microscopy, wildlife monitoring, and urban weather datasets, PRISM enhances downstream analysis by letting experts remove only degradations that hinder analysis, avoiding black-box “over-restoration.” Together, these results establish PRISM as a generalizable, controllable framework for high-fidelity restoration in domains where scientific utility is a priority.", "tldr": "", "keywords": ["prompted diffusion", "image restoration", "expert-in-the-loop", "scientific imaging"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/21ba921754225e0dc693d39d4a01f4e7623e0ec8.pdf", "supplementary_material": "/attachment/1a5e3c3d06a5fbdebfbdf0f4bd5baf9bc978b4dc.pdf"}, "replies": [{"content": {"summary": {"value": "The authors argue that the current unified processing pipeline adopted for image restoration in the scientific field may introduce redundant restoration types, which could counter productively lead to the loss of authentic information. Therefore, the authors aim to provide a controllable mechanism, Controllable Diffusion,  to enable experts to select specific restoration types to avoid the aforementioned dilemma."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "A.The authors present a novel perspective in addressing the issue. \n\nB. The amount of work undertaken is solid.\n>- They constructed a brand-new dataset and employed the latest relevant methods (mostly works from 2024) to demonstrate the superiority of the proposed approach."}, "weaknesses": {"value": "I think subjective assumptions and the unconvincing problem-solving approach are the most prominent issues.\n\nA.Subjective assumptions\n>-  A.1 Taking underwater image restoration, as mentioned in the article, as an example. The authors identify three types of distortions: low light, scattering, and wavelength dependency. Since these distortions act on the same image, any single restoration method may inadvertently damage useful information. Therefore, the core of fidelity preservation should lie in the precision of each restoration. However, the authors' equivalence of precision with controllability over the quantity and types of restoration is a unconvincing subjective assumption.\n\n>- A.2 It is possible that the most appropriate combination of restoration types has already been implicitly learned by the model through training. However, the authors have neither experimentally nor theoretically refuted the aforementioned viewpoint nor provided substantive support for their own hypothesis.\n\n>- A.3 The authors arbitrarily set the number of distortion types to 3, which is overly simplistic and lacks justification. This approach may fails to flexibly handle complex scenarios.\n\nB.Unconvincing problem-solving approach\n>- B.1 The core idea of artificial intelligence is to employ machine intelligence to replace human thinking. When encountering problems, the focus should be on solving them directly, rather than reversely introducing human labor costs to empower machines.\n\n>- B.2 Although the experimental results show some improvement, these enhancements are not significant. Moreover, there is a lack of relevant analysis regarding the extent to which such improvements stem from the investment in human labor costs and whether they offer cost-effectiveness. Additionally, the ablation experiments fail to fully elucidate the impact of distortion type settings and their dependence on accurate expert guidance.\n\n>- B.3 Assuming your hypothesis is correct, why not just solve the problem in a software engineering way? Let a single model specialize in removing a single type of noise,  we design control codes to allow experts to manually execute several actions to process the images. Therefore, what is the point of incorporating NLP models for processing opinions of experts and coupling the problem together to train a model?"}, "questions": {"value": "The same as the above analysis in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TURVHvF6JI", "forum": "CQ0U1wZYoy", "replyto": "CQ0U1wZYoy", "signatures": ["ICLR.cc/2026/Conference/Submission18346/Reviewer_dhPx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18346/Reviewer_dhPx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761050293668, "cdate": 1761050293668, "tmdate": 1762928056126, "mdate": 1762928056126, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PRISM (Precision Restoration with Interpretable Separation of Mixtures), a prompted conditional diffusion framework for expert-in-the-loop controllable restoration of images with compound degradations. PRISM integrates two key components: (1) compound-aware supervision trained on mixtures of distortions, and (2) a weighted contrastive disentanglement objective that aligns compound distortions with their constituent primitives. This approach enables high-fidelity joint restoration."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-structured and the motivation is clear.\n2. The framework leverages compound-aware supervision and a contrastive disentanglement objective across a diverse set of primitive tasks. This produces separable embeddings of distortions, enabling robust restoration, even for unseen real-world mixtures.\n3. This work proposes a novel benchmark for scientific utility, spanning remote sensing, ecology, biomedical, and urban domains."}, "weaknesses": {"value": "1. The method is devised on the basis of CLIP and Latent Diffusion Model. Moreover, Semantic Content Preservation Module is also relatively simple.\n2. There is no physical information being incorporated into the training process. In other words, it is a general method that is used for scientific domains.\n2. The dataset is constructed by integrating existing datasets, which is not very solid."}, "questions": {"value": "1. Collecting a dataset from existing datasets is not very convincing. Have the authors collected any data?\n2. It is a general method that is applied as a unified model for scientific and environmental images. More domain-specific priors, such as physical information, should be considered.\n3. The text prompt is also short for benefiting these domains."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4VR02LhtyE", "forum": "CQ0U1wZYoy", "replyto": "CQ0U1wZYoy", "signatures": ["ICLR.cc/2026/Conference/Submission18346/Reviewer_jZpm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18346/Reviewer_jZpm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762048378214, "cdate": 1762048378214, "tmdate": 1762928055397, "mdate": 1762928055397, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PRISM, a controllable diffusion framework for compound image restoration, primarily targeting scientific applications. The method involves a two-stage process: first, fine-tuning a CLIP image encoder using a novel weighted contrastive loss to create a compositional embedding space for degradations , and second, training a latent diffusion model conditioned on these embeddings and user prompts to perform selective restoration."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The work compellingly argues for the necessity of controllable, selective restoration over automated 'full' restoration for scientific applications, demonstrating significant gains in downstream task utility."}, "weaknesses": {"value": "The primary methodological concern is the limited novelty. The core idea of fine-tuning a CLIP encoder to be degradation-aware heavily relies on prior work (e.g., DA-CLIP). The main novelty appears to rest on the Jaccard distance weighting in the contrastive loss, but the paper lacks a direct ablation comparing this to an unweighted compound contrastive loss, making it difficult to isolate its true impact. \n\nSecond, the two-stage training pipeline  is computationally complex, and the choice of a diffusion backbone introduces significant inference latency. This efficiency trade-off is not sufficiently justified, especially as the performance gains over other recent diffusion methods  are notable but not transformative. \n\nFinally, the framework's generalization to real-world, unseen degradations is questionable. The model is trained exclusively on synthetic composites , and it is unclear if the model is truly learning compositional physics or rather a powerful interpolation across its massive synthetic training domain when faced with the complex, non-linear physics of real-world degradations."}, "questions": {"value": "What is the inference time of PRISM compared to the baselines (e.g., MPerceiver, AutoDIR, and the non-diffusion NAFNet), and how do the authors justify this computational cost for the observed performance gain?\n\nGiven the reliance on synthetic data , how can we be sure the model is learning robust compositional reasoning for real-world physics  rather than a complex interpolation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "x8jTXV3TII", "forum": "CQ0U1wZYoy", "replyto": "CQ0U1wZYoy", "signatures": ["ICLR.cc/2026/Conference/Submission18346/Reviewer_ztwF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18346/Reviewer_ztwF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762063762191, "cdate": 1762063762191, "tmdate": 1762928054331, "mdate": 1762928054331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a framework for controllable restoration of images that underwent multiple primitive distortions. The restoration of the degradations happens at once, rather than consecutive restorations that may introduce artifacts, yet enables defining which degradation to restore in order to preserve necessary signals.\n\nAs part of the training process, a restoration benchmark with tuples of a clean and a degraded image, along with a natural language prompt that describes the degradation is used, which is made public. Given a prompt, the framework includes using a frozen CLIP text encoder for multi-label classification from a set of primitive degradation, which are then formatted to a predefined form of prompt. This prompt is then used to restore the image by applying a finetuned version of SD 1.5, where the CLIP image encoder was finetuned to cluster embeddings by degradation, followed by an additional model trained to preserve semantic content.\n\nThe overall framework is evaluated on a benchmark with images that underwent distortions as the ones in the training process (up to 3 primitive distortions) and on unseen distortions. Furthermore, its usage for four downstream tasks is evaluated, showing scientific utility."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* Image restoration is a critical task, particularly for scientific applications. This paper demonstrates the method's effectiveness through general purpose image restoration, evaluated using fidelity and perceptual metrics, and its application for downstream scientific tasks.\n* The motivation is written clearly, and the figures (although 1 and 2 are not referenced) support the understanding of the general approach.\n* Although the number of consecutive distortions in the training set is limited to 3, section 4.2 shows that the method archives good results also for unseen degradations that are not necessarily a combination of the degradation in the train set, or are a combination of more than 3 primitive distortions."}, "weaknesses": {"value": "* While the fine tuning of CLIP image encoder is explained thoroughly, the following steps of how SD 1.5 is used as the backbone and the suggested SCPM module are explained only briefly. This impairs the understanding of the entire framework, and while the code is submitted, the text itself is not sufficient to reproduce the code.\n* The concept of automatic restoration needs clarification. While the paragraph on prompting (line 207) describes the automatic transformation of natural prompts to fit the required format, the method for generating these automatic prompts remains unclear. Possibly related, it is unclear which prompts were used in the experiments in Sec. 4.1.\n* The motivation of controlled restoration for expert in the loop scenarios could be further evaluated by comparing images that underwent multiple distortions but PRISM is prompted to restore only a partial set (as in Sec. 4.3.1 on synthetically) where the control of the restorations suggests different restorations for specific images / use cases rather than a predefined subset for all images in the same domain.\n\n**Minor:**\n* Indices are not explained and somewhat confusing. It seems $d_{i_j}$ in Eq. 1 denotes a specific distortion and $d^i$ in row 180 denotes a set of distortions, yet the notations are explained only after being used ($d_j$ is explained in line 200).\n* Using the Jacard distance between degradation sets neglects how some distortions are more similar than others.\n* Should mention how the prompts in the dataset are auto generated (line 157)."}, "questions": {"value": "* In addition to PSNR reported in Fig 3, what was the effect on other discussed metrics?\n* What value is used for the number of variants $m$ ? And what is the minibatch size? If these values are not similar there might be added values in weighing the two terms in the denominator of the per-variant contrastive loss to control the effect of repelling from other degradations and that of repelling from other images.\n* Is there a difference between the dataset described in Sec.3.1 and the benchmark described in 3.2 (MDB)? If so, what is included in MDB?\n* In Sec. 4.2, did PRISM identify the same set of primitive distortions for different images from each domain where images probably went through similar degradation?\n* Which images were used to create the visualization of the scatter plot in Fig. 5?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dWSGaN4RwM", "forum": "CQ0U1wZYoy", "replyto": "CQ0U1wZYoy", "signatures": ["ICLR.cc/2026/Conference/Submission18346/Reviewer_S4VD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18346/Reviewer_S4VD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762084689448, "cdate": 1762084689448, "tmdate": 1762928053729, "mdate": 1762928053729, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global Response to All Reviewers"}, "comment": {"value": "We thank the reviewers for their insightful, thoughtful feedback! We appreciate that they found that:\n\n* The paper's **framing was novel** and the **motivation was clear** (reviewers atD5, S4VD, jZpm, and dhPX).\n* The approach was well-structured and **results were strong**, particularly in the generalization to complex or unseen test cases (reviewers atD5, jZpm, and S4VD).\n* The **evaluation framework was diverse and strong**, with the construction of a novel benchmark dataset (reviewers atD5, S4VD, jZpm, and dhPx).\n\nBelow, we highlight key clarifications/revisions, and include reviewer-specfic repsponses to address remaining feedback. We refer the reviewers to our updated PDF and supplementary materials for revised analysis and figures. Any major **updates are highlighted in blue** in our revised PDF.\n\n## Re-Emphasizing Novelty & Contributions\nWhile PRISM builds on CLIP and latent diffusion, our core contribution lies not in isolated algorithmic novelty, but in reframing restoration as a controllable, compositional process for scientific use cases. This framing emphasizes the importance of prompt-guided controllability for selective restoration, compound-aware supervision for real-world mixed distortions, scientific fidelity over aesthetics. PRISM's novelty lies in the compositional generalization of degradation-aware embeddings combined with prompt-driven, expert-controllable diffusion-based restoration, which have not been jointly addressed in prior work. The contributions of our work also lie introducing novel benchmark over real-world use cases of restoration, and nuanced analysis on the importance of controllability. We **clarified this framing in our discussion, and revised wording to better distinguish our contributions from prior work.** Some reviewers commented that PRISM's performance gains on traditional benchmarks or standard metrics appear modest. We agree this is true in low-complexity settings (e.g., single distortions), where existing baselines are strong. However, we emphasize that PRISM excels under *compound*, *unseen*, and *zero-shot* degradations (Table 2, Fig. 3), which are especially relevant to scientific deployment. We have clarified this point in our analysis and **added references to SSIM and FID scores in Appendix F** to show that improvements generalize across metrics.\n\n## Controllability for Precision\nMultiple reviewers expressed concern around the paper’s use of the term “precision,” particularly regarding whether it refers to prompt controllability or output fidelity. To clarify, we do not conflate controllability with precision. Rather, we argue that controllability (the ability to specify selective restoration) is a mechanism that enables *precision* in scientific settings, where over-restoration risks suppressing subtle but critical features (e.g., in microscopy or remote sensing). **We have revised the framing and clarified this in Section 2.1 and Section 4.3.1.** The reviewers requested stronger or more illustrative evaluations of PRISM’s controllability and prompt adherence. We appreciate this feedback and have **expanded our evaluation of prompt faithfulness on the held-out MDB benchmark,** which includes full, partial, and negative prompts. As detailed in Appendix Table 9, we achieve 87.7% adherence to the restoration task specified in the test prompts. **In Section 4.3.1, we also highlight practical use cases** (e.g., selective haze removal) to motivate how controllability supports scientific goals. These changes aim to strengthen the rigor and clarity of our controllability evaluation.\n\n## Efficiency and Computational Costs of PRISM\nWhile diffusion-based restoration models inherently incur greater computational cost than encoder–decoder baselines, we find that PRISM maintains competitive runtime efficiency relative to comparable diffusion frameworks. **Table 8 in Appendix Section E (under \"Cost and Latency Analysis\") summarizes inference benchmarks (FLOPs, memory usage, runtime)** on an NVIDIA A100 GPU at $256 \\times 256$ resolution. Despite incorporating SCPM and compositional prompting modules, PRISM achieves similar FLOPs, memory usage, and latency as other Stable Diffusion-based image editing methods such as DiffPlugin, MPerceiver, and AutoDIR despite the additional SCPM module (6–7ms per image). That said, we argue that in many scientific workflows, inference time and computational cost are not the primary bottlenecks, the inability to handle real-world mixtures, black-box pipelines, and low downstream fidelity are. **We have updated our discussion at the end of the paper to reflect our analysis on the tradeoffs between latency and fidelity.**"}}, "id": "qS9UB1stiU", "forum": "CQ0U1wZYoy", "replyto": "CQ0U1wZYoy", "signatures": ["ICLR.cc/2026/Conference/Submission18346/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18346/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18346/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763608690064, "cdate": 1763608690064, "tmdate": 1763608690064, "mdate": 1763608690064, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents PRISM, a prompted, controllable diffusion framework for restoring images suffering from compound degradations. The training setup uses mixtures of up to three distortions and introduces a weighted contrastive disentanglement stage to make embeddings separable and compositional. Inference accepts free-form prompts that are mapped to a fixed set of restoration labels; a latent-diffusion backbone performs restoration and a Semantic Content Preservation Module (SCPM) refines fine detail. Experiments cover a new Mixed Degradations Benchmark (MDB), zero-shot evaluation on real datasets (UIEB, under-display camera, and fluid lensing), and downstream tasks across remote sensing, ecology, microscopy, and urban scenes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) Clear objective and method design. The paper argues for simultaneous rather than sequential restoration, emphasizes expert control, and focuses on scientific fidelity rather than aesthetics. The architecture coherently combines contrastive disentanglement, prompt-conditioned latent diffusion, and SCPM for detail recovery.  \n2) Good reported performance and breadth. On MDB, PRISM outperforms representative all-in-one and diffusion/composite baselines (e.g., AirNet, Restormer, NAFNet, PromptIR, OneRestore, DiffPlugin, MPerceiver, AutoDIR) on PSNR/SSIM and perceptual metrics.  \n3) Generalization beyond the synthetic training setup. The paper reports zero-shot gains on real distortions (underwater, under-display camera, and fluid distortions) and shows that performance scales well as the number of simultaneous degradations increases.  \n4) Practical value for scientific analysis. Selective, prompt-guided restoration improves downstream tasks in several domains, supporting the utility of controllability."}, "weaknesses": {"value": "1) Control granularity and evaluation scope:\n  The evaluation largely uses manual prompting with a pre-defined set of distortion types, not open-ended language or fine-grained controls. The paper itself notes that extending controllability beyond “which distortions to remove” to specifying intensity and spatial extent is left for future work. This leaves unanswered how robust the system is to realistic prompt variations or local/severity-aware edits.\n\n2) Synthetic-to-real gap and capped composition complexity:\n   Training relies on synthetic mixtures and explicitly caps each sample at up to three distortions for efficiency and interpretability. The authors acknowledge that these synthetic augmentations cannot fully capture real distortions. While results on real datasets are encouraging, this cap and reliance on synthetic compositing may underrepresent harder real-world compound effects.\n\n3) Efficiency and deployability are not quantified in the main text:\n   The paper does not provide main-text wall-clock, throughput, or memory comparisons versus strong diffusion baseline. Without standardized timing/FLOP/peak-memory profiles at a fixed resolution, it is difficult to assess practical deployability or the overhead of the added control and SCPM modules."}, "questions": {"value": "."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UvJWgjSybg", "forum": "CQ0U1wZYoy", "replyto": "CQ0U1wZYoy", "signatures": ["ICLR.cc/2026/Conference/Submission18346/Reviewer_atD5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18346/Reviewer_atD5"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission18346/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762236573522, "cdate": 1762236573522, "tmdate": 1762928053366, "mdate": 1762928053366, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}