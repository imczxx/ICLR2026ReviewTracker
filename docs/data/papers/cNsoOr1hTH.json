{"id": "cNsoOr1hTH", "number": 16647, "cdate": 1758267246271, "mdate": 1763547463178, "content": {"title": "Overshoot and Shrinkage in Classifier-Free Guidance: From Theory to Practice", "abstract": "Classifier-Free Guidance (CFG) is widely used in diffusion and flow-based generative models for high-quality conditional generation, yet its theoretical properties remain incompletely understood. By connecting CFG to the high-dimensional framework of diffusion regimes, we show that in sufficiently high dimensions it reproduces the correct target distribution—a “blessing-of-dimensionality” result. Leveraging this theoretical framework, we analyze how the well-known artifacts of mean overshoot and variance shrinkage emerge in lower dimensions, characterizing how they become more pronounced as dimensionality decreases. Building on these insights, we propose a simple nonlinear extension of CFG, proving that it mitigates both effects while preserving CFG’s practical benefits. Finally, we validate our approach through numerical simulations on Gaussian mixtures and real-world experiments on diffusion and flow-matching state-of-the-art class-conditional and text-to-image models, demonstrating continuous improvements in sample quality, diversity, and consistency.", "tldr": "", "keywords": ["Diffusion", "flow-matching", "classifier-free guidance"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/093bf16abca39405c9bfd1ffc1313b47ece8aac8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper shows that the CFG artifacts of overshoot and variance shrinkage that have been observed in low dimensions vanish in high dimensions, via a theoretical analysis of dynamical regimes. They then propose a nonlinear extension of CFG that mitigates the low dimensional artifacts while preserving the high dimensional behavior."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is clear and well-written. The problem is well-positioned within the literature (particularly wrt Chidambaram and Biroli). It is nice to see the question of why CFG 'works' despite the known issues in low dimensions being addressed. The dynamical regimes analysis is interesting. The improved diversity on ImageNet is promising."}, "weaknesses": {"value": "Please see questions.\n\nAs the authors note in the limitations, although the theory can help improve diversity while maintaining fidelity/quality, it still cannot explain how CFG improves fidelity/quality."}, "questions": {"value": "The Biroli dynamical regimes analysis applied to the CFG deals with a mixture of two Gaussians. How can we be sure the conclusions carry over to more complex multimodal distributions?\n\nHow does this analysis relate to the common empirical observation that conditional diffusion models often start to behave like unconditional denoisers at low noise levels? (Does the analysis actually rely on that behavior? Or can it help explain it?)\n\nL328: Do you require $0 < \\alpha \\le 1$ or can $\\alpha$ be greater than zero?\n\nClarification: (L332) When the difference between conditional and unconditional scores is zero, CFG automatically reproduces the conditional score. So the goal of the power-law is to further (nonlinearly) damp small (but nonzero) score differences?\n\nWhy is Power-Law CFG helpful in high-dimensional settings like ImageNet? I thought the analysis showed that CFG is already \"correct\" in high dimensions (i.e. recovers conditional distribution without distortion)?\n\nMinor edits:\nL 82-83 did you swap descriptions of mean overshoot and variance shrinkage?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EHgchchgnj", "forum": "cNsoOr1hTH", "replyto": "cNsoOr1hTH", "signatures": ["ICLR.cc/2026/Conference/Submission16647/Reviewer_QJyR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16647/Reviewer_QJyR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16647/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761080495165, "cdate": 1761080495165, "tmdate": 1762926709253, "mdate": 1762926709253, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes Classifier-Free Guidance (CFG) for diffusion/flow generative models. Using a high-dimensional dynamical-regime framework, it proves that in sufficiently large dimensions CFG reproduces the correct conditional distribution and accelerates convergence before “speciation” (transition between Regime I and II). In finite dimensions, it formally characterizes mean overshoot and variance shrinkage and attributes them to a more confining effective potential. Motivated by this, it introduces a nonlinear “power-law” CFG that scales the score difference by $|\\cdot|^\\alpha$, which provably mitigates both artifacts while preserving the high-dimensional guarantee. Experiments span Gaussian-mixture simulations and ImageNet/T2IM models (DiT, EDM2, MMDiT), showing improved FID/recall and robustness to $\\omega$."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper's main theoretical punch is the \"blessing-of-dimensionality\" result. The authors formally prove for the first time that CFG can generate the exact target distribution under appropriate conditions (infinite dimensions).This is a huge deal because it formalizes why this heuristic is so stable and effective in high-dimensional domains like images. (Eq. (4)–(6); Sec. 4.1; Appx. B–D).\n\n2.  The authors' theory also provides a clear explanation for well-known flaws in CFGs. They show that they are mathematically necessary consequences of finite dimensionality and directly relate them to the curvature of the effective potential (Section 4.2; Equation (35)).\n\n3.The authors propose a theoretically derived solution, the power-law CFG, which is very simple. It requires only the addition of a `$|\\cdot|^\\alpha$` term, and it also has theoretically driven reassurances (Equation (7))."}, "weaknesses": {"value": "1. Theoretical assumptions regarding accurate scores; practical mismatch issues remain unresolved.\nThe paper obtains true scores under high-dimensional guarantees and finite-dimensional analysis assumptions. The paper acknowledges that it cannot explain why (linear) CFGs perform well with imperfect estimators (Section 3.2, last paragraph; Conclusions/Limitations). Direct robustness analysis of the scores to the error/noise of nonlinear rules (e.g., perturbation bounds) is also lacking.\n\n2. The scope of the study focuses on Gaussian mixture structures.\nThe core derivation of this paper relies on mixture models with isotropic covariances and separable scaling (Section 4; Appendices B-D); extensions to non-GMM real data are controversial but unproven. While Appendix C discusses multi-component and non-centered mixture models, empirical validation of multi-class schemes focuses primarily on standard vision datasets rather than controlled non-isotropic cases.\n\n\n3. While $\\alpha$ is considered robust ($\\alpha \\approx 0.9$), the method introduces a second hyperparameter; more extensive ablations (dataset, sampling step size, $omega$ range) are shown in Appendix G, but some edge cases (e.g., extremely small $omega$ or very low step size) require minimal exploration. (Figure 4; Appendix G).\n\n4.  I note that you cite an extension of flow matching with velocity prediction (Appendix G.2.1 notes), but the main theoretical section does not provide a complete derivation."}, "questions": {"value": "refer to weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RpjvH99UE1", "forum": "cNsoOr1hTH", "replyto": "cNsoOr1hTH", "signatures": ["ICLR.cc/2026/Conference/Submission16647/Reviewer_hSQr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16647/Reviewer_hSQr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16647/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761836553714, "cdate": 1761836553714, "tmdate": 1762926708852, "mdate": 1762926708852, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper provides a theoretical analysis of how CFG affects the generation of mixtures of Gaussians via diffusion models. The authors arrive at the result that in the scenario of exact score estimation the effect of CFG on the generated distribution tends to zero as the number of data dimensions tends to infinity. Conversely, they find that in finite/small dimensional cases CFG causes the generated means to shift and the variances to shrink. The authors propose to adjust CFG according to the norm of the score difference in order to mitigate the above effects and evaluation on various image generation models/datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The theoretical contributions advance the understanding of CFG.\n- The presentation of the paper is clean and professional. Theoretical results are presented in a structured and understandable manner.\n- The scale and variety of the experiments are appropriate."}, "weaknesses": {"value": "The paper load for ICLR this year has been large, and so I have not been able to spend as much time as I would like on reviewing. I encourage the authors to correct any errors/misunderstandings I may have with regards to the paper.  \n\n\n1. **weak motivation for proposed approach**\n    1. The authors motivate their Power-Law CFG as a method to reduce mean overshoot and variance shrinkage (implying generation is in the *finite dim* regime), but then justify their approach by saying it retains the *high dim* properties of CFG that they've derived. It seems like they are suggesting that their approach won't \"break\" the nice high-dimensional properties of CFG, but then are focused on addressing a problem that only exists in low/finite dim regime. I find this link between the theoretical and practical part of the paper quite weak.   \n    1. It is unclear to me how the proposed approach reduces the mean overshoot and variance shrinkage, as the authors don't provide an explanation in the main body of the paper. \n    1. From what I can tell, any heuristic scaling of CFG [1] (e.g. according to timestep) will also retain the nice theoretical properties, which hardly makes power-law scaling unique. Besides, practically speaking it seems like the proposed approach behaves similarly to existing heuristics, gradually increasing CFG as generation progresses [1].\n    1. The intuitive description of power-law scaling is misleading. First of all the assertion that score difference large -> reliable, small -> unreliable is not clearly explained or motivated. Secondly, $x_t=\\alpha_t x_0 + \\sigma_t \\epsilon$, $S_\\theta = -\\epsilon_\\theta/\\sigma_t$, that is to say from a noise prediction perspective the magnitude of the score estimate depends on the noising schedule. As noise level $\\sigma_t$ decreases over the course of generation this will have a direct impact on the power-law scaling. Importantly, the $\\sigma$ scaling has nothing to do with the actual difference in spatial content predicted by the conditional and unconditional models and is instead dependent on the diffusion time. In fact, the authors acknowledge that applying their scaling directly to flow velocity results in different behaviour, but do not offer much additional insight. \n\n\n2. **Tepid experimental results**\n    1. Although improvements over vanilla CFG seem notable, improvements over other improved CFG methods are much more marginal. Moreover, due to the aforementioned weak motivation there isn't really a clear explanation for why to prefer power-law scaling to competing approaches. \n\n3. **Lack of intuition to support theory (minor)**\n   1. For a general reader interested in using/improving CFG, I feel like this paper would benefit from more intuitive explanations to help understanding. Personally, I still have not been able to build an intuition for why the effect of CFG disappears when dimensionality tends to infinity, making it harder to appreciate the contribution. (I have some vague ideas of distributions tending to hyperspherical shells, leading to different behaviour, but nothing concrete.)\n\n[1] Wang et al, Analysis of Classifier-Free Guidance Weight Schedulers, TMLR 2024."}, "questions": {"value": "See above\n\nMy main issues with the paper are (according to my current understanding)\n1. The proposed approach is weakly linked with the theoretical contribution.\n2. The concrete form of the power-law CFG is not well motivated.\n\nI'm open to increasing my score if the authors can help me understand better the above issues. I have also not read the appendices in detail.\n\nAdditionally, I would like to clarify, is the score difference a vector norm or an elementwise difference?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8oMARq0ymj", "forum": "cNsoOr1hTH", "replyto": "cNsoOr1hTH", "signatures": ["ICLR.cc/2026/Conference/Submission16647/Reviewer_DodZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16647/Reviewer_DodZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16647/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923620465, "cdate": 1761923620465, "tmdate": 1762926708273, "mdate": 1762926708273, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper observes the problem of mean overshooting and variance shrinkage resulted by classifier-free gudiance during Diffusion Sampling process. The main results are drawn from the connection of dynamical regimes and classifier-free guidance. Main observations are conducted on  the mixture of Gaussian (2 modes) with the same weight and variance. This gives us the division of CFG into three distinct steps (1) guidance before speciation (2) align before exiting regime I (3) follow unguided path. However, when the dimensionality is limited, the observation (2) is no longer correct and over push the conditional information. To solve this problem in lower-dimension setting, the authors propose power-law guidance where it will enhance the guidance when the guidance signal is strong, and purging the guidance when the guidance is weak. The results show the significant improvement"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written\n2. The theoretical part is well-written\n3. The experiments are comprehensive and up-to-dated.\n4. The improvement is quite significant\n5. The proposed method is simple"}, "weaknesses": {"value": "The main drawback of the paper lies in its over-complication. In my opinion, simplicity should be viewed as a strength rather than a weakness. The proposed method is inherently simple, and the results are largely empirical. Therefore, I strongly suggest simplifying the presentation and avoiding unnecessary theoretical analysis that does not contribute to the core message.\n\n1. **Overly Strong Assumptions:**  \n   The assumptions made in the paper are excessively restrictive and unrealistic.  \n   - The use of a mixture of two Gaussians is not representative of most real-world datasets.  \n   - The assumption that both Gaussians share the same variance is also impractical and lacks justification.  \n   - Furthermore, assuming the means to be +m and –m is arbitrary and overly specific.  \n   In contrast, *Biroli (2024)* assumes only the existence of two classes without making any assumptions about their distributions, means, or variances. The authors may want to consider relaxing or revising these assumptions to enhance realism and generalizability.\n\n2. **Unnecessary First Key Finding:**  \n   The first key finding adds confusion rather than clarity. It does not appear essential to the overall narrative or conclusions. The paper would benefit from removing this section and instead starting directly from the second finding (e.g., Figures 8 and 12), focusing on the proposed method for addressing low-dimensional cases.\n\n3. **Weak Connection to Previous Findings:**  \n   The third key finding seems only loosely connected to the earlier results. It is unclear how the concepts of “Regime I” and “Regime II” relate to the presented equation. This section requires clearer logical linkage and explanation.\n\n4. **Experimental Results and Resolution:**  \n   The experiments report results for resolutions of 512 and 256. According to the paper’s own claims, one might expect the method to perform even better on lower resolutions such as 64×64 or 32×32. If this is indeed the case, the authors should provide empirical evidence to support this claim."}, "questions": {"value": "Please see the weakness. I would encourage the authors to simplify the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JoZvf5inet", "forum": "cNsoOr1hTH", "replyto": "cNsoOr1hTH", "signatures": ["ICLR.cc/2026/Conference/Submission16647/Reviewer_canA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16647/Reviewer_canA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16647/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762112153430, "cdate": 1762112153430, "tmdate": 1762926707841, "mdate": 1762926707841, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}