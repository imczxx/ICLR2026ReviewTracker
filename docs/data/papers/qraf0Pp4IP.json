{"id": "qraf0Pp4IP", "number": 1144, "cdate": 1756850497367, "mdate": 1759898225108, "content": {"title": "Data-Free Knowledge Exchange for Aggregation-Free Heterogeneous Federated Learning", "abstract": "Heterogeneous Federated Learning (HFL) is a decentralized machine learning paradigm that enables participants to leverage distributed knowledge from diversified environments while safeguarding individual privacy. Recent works that address both data and model heterogeneity still require aggregating model parameters, which restricts architectural flexibility. Knowledge Distillation (KD) has been adopted in HFL to circumvent direct model aggregation by aggregating knowledge, but it depends on a public dataset and may incur information loss when redistributing knowledge from the global model. We propose Federated Knowledge Exchange (FKE), an aggregation-free FL paradigm in which each client acts as both teacher and student, exchanging knowledge directly with peers and removing the need for a global model. To remove reliance on public data, we attach a lightweight embedding decoder that produces transfer data, forming the Data-Free Federated Knowledge Exchange (DFFKE) framework. Extensive experiments show that DFFKE surpasses nine state-of-the-art HFL baselines by up to 18.14%. Code is available in the supplementary material. Anonymous Repo: https://anonymous.4open.science/r/DFFKE-0E0B.", "tldr": "A bidirectional knowledge exchange technique for heterogeneous federated learning.", "keywords": ["Knowledge Distillation", "Federated Learning", "Data Heterogeneity", "Model Heterogeneity"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b2bf1da83aee2a740172600511cabf188582c943.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel Federated Learning (FL) framework named Data-Free Federated Knowledge Exchange (DFFKE). The core innovation lies in its aggregation-free paradigm, which facilitates direct knowledge exchange between clients without relying on a global model. It tackles both data and model heterogeneity by introducing three key components: an embedding space unification mechanism using a global classifier, a lightweight embedding decoder for generating synthetic data, and a memory buffer to mitigate knowledge forgetting. The framework is designed to operate without public datasets and supports heterogeneous client model architectures. Extensive experiments demonstrate that DFFKE achieves superior performance compared to several state-of-the-art baselines across various FL settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. It proposes a novel FL framework that eliminates the need for public datasets, model aggregation, or knowledge aggregation into a global model.\n\n2. It supports model heterogeneity, allowing clients to employ architectures tailored to their local data without any form of model parameter exchange."}, "weaknesses": {"value": "1. The claimed novelty over existing methods is questionable. Data-free knowledge distillation (DFKD) based FL methods that do not rely on public datasets were proposed as early as 2021. Furthermore, methods like FedIOD [1] (2023) already support model heterogeneity and data-free knowledge distillation. In comparison, DFFKE's design, which stacks components like a global classifier, an embedding decoder, and a memory buffer, appears to be a complex amalgamation of existing techniques rather than a fundamentally novel breakthrough.\n\n2. The requirement for clients to share their data embeddings with the central server for space unification and decoder training presents a significant privacy concern. Embeddings are projections of raw data in a high-dimensional feature space and could be leveraged by a malicious server or other clients to infer sensitive attributes of the original data through model inversion or membership inference attacks. While the authors suggest applying differential privacy (DP) or opting out of sharing, the effectiveness of the L_fid loss alone in generating high-quality, knowledge-transferable synthetic data from heavily noised or absent embeddings is doubtful and not sufficiently proven.\n\n3. The framework's performance is highly dependent on the successful alignment of the client embedding spaces. If this unification is suboptimal, the quality of the synthetic data generated by the decoder will degrade, subsequently impairing the knowledge exchange process.\n\n4. The memory buffer, while crucial for performance, introduces additional storage and computational overhead for clients. The buffer size is a critical hyperparameter that requires careful tuning, as a small buffer leads to knowledge forgetting while a large one increases the client's burden. The marginal performance gain on CIFAR-10 in Table 3, despite this added complexity, raises questions about the cost-benefit trade-off in certain scenarios.\n\n5. The experimental evaluation lacks comparison with several prominent and high-performing DFKD-based FL methods, such as FedFTG [2] and DENSE [3]. Their absence makes it difficult to comprehensively assess DFFKE's standing within the most relevant field of research.\n\n[1] Xuan Gong, et al. Federated Learning via Input-Output Collaborative Distillation.\n\n[2] Lin Zhang, et al. Fine-tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning.\n\n[3] Jie Zhang, et al. DENSE: Data-Free One-Shot Federated Learning."}, "questions": {"value": "1. On page 8, Table 4 reports that on the TinyImageNet dataset with α=1.0, adding DP noise seemingly improves performance compared to the no-DP baseline (from 31.74% to 32.17%). Could you please explain this counter-intuitive result? Does the injected noise act as a regularizer in this specific context, and if so, why is this effect not consistently observed across all datasets and heterogeneity settings?\n\n2. Given that the memory buffer introduces non-trivial client-side burden, how do you recommend practitioners strategically determine the optimal buffer size to balance performance gains against storage and computational costs, especially considering the seemingly modest improvements on datasets like CIFAR-10?\n\n3. What is the rationale for not including comparisons with contemporary and high-performing DFKD-FL methods like FedFTG and DENSE? A comparison with these methods is crucial to firmly establish the state-of-the-art performance of DFFKE.\n\n4. The paper removes the commonly used diversity loss from traditional DFKD, relying primarily on the fidelity loss (L_fid). Without an explicit diversity-promoting loss, how does your method effectively ensure the diversity of the generated synthetic samples, which is critical for comprehensive knowledge transfer?\n\n5. Could you provide visual examples (e.g., in the appendix) of what these synthetic samples look like? This would help in assessing their quality and semantic meaningfulness.\n\n6. Does the act of distributing the generator/embeddings to create a common set of synthetic samples across all clients introduce a new attack vector or privacy concern, even if the raw data is never shared?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "FoOyHv4oQ7", "forum": "qraf0Pp4IP", "replyto": "qraf0Pp4IP", "signatures": ["ICLR.cc/2026/Conference/Submission1144/Reviewer_EQ9a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1144/Reviewer_EQ9a"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1144/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761642390484, "cdate": 1761642390484, "tmdate": 1762915690176, "mdate": 1762915690176, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Federated Knowledge Exchange (FKE), an aggregation-free FL method designed for data and model heterogeneity. Building on the challenge of effective knowledge transfer without access to shared data or requiring model aggregation, the authors propose the Data-Free Federated Knowledge Exchange (DFFKE) framework, where each client both teaches and learns directly from peers via synthetic data generated by a shared embedding decoder. The framework utilizes a unification mechanism for embedding spaces and employs differential privacy to support privacy-preserving knowledge exchange. Extensive experimental results on standard federated learning benchmarks demonstrate that DFFKE outperforms multiple state-of-the-art methods in both classic and personalized heterogeneous FL scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. DFFKE eliminates the dependency on public data, which is a long-standing challenge in realistic FL scenarios. Furthermore, its aggregation-free design and support for model heterogeneity allow it to adapt effectively to complex FL environments, demonstrating strong real-world applicability.\n2. DFFKE is consistently superior to the best available competitors, often by wide margins (e.g., +18.14% over the best baseline on CIFAR-100 under severe heterogeneity in Table 2). In particular, after incorporating the differential privacy mechanism, the performance remains consistently superior to the baselines, indicating that the framework effectively facilitates the exchange of private knowledge among clients and enables joint model optimization.\n3. The paper is well-written, with a clear line of reasoning, comprehensive analysis, and solid theoretical guarantees."}, "weaknesses": {"value": "- Only toy-level datasets (CIFAR-10, CIFAR-100, and TinyImageNet) are used. More challenging datasets (such as DomainNet) are needed for the evaluation. Moreover, the study considers only the image modality; incorporating additional modalities would be necessary to demonstrate the generality of the proposed method.\n- Although Section 4.3 discusses the integration of differential privacy, the privacy guarantees—particularly against known attacks such as membership inference, gradient inversion, and reconstruction attacks—are neither empirically tested nor demonstrated, leaving the privacy effectiveness partly speculative. Therefore, an empirical evaluation of DP’s protective capability against specific privacy attacks is needed.\n- As Figure 2 and Table 5 show, DFFKE’s performance depends heavily on an unbounded or very large memory buffer of synthetic data. This raises concerns regarding storage demands and potential privacy leakage, especially as the number of clients or rounds increases. Memory buffer management strategies are not discussed (e.g., eviction, sampling, privacy-compromised retention)."}, "questions": {"value": "- Since the datasets and models used in the experiments are relatively simple, the cost of transmitting embeddings and logits is not significant. However, when the number of classes becomes very large, for example, 100,000, the communication cost of transmitting logits would increase dramatically (as more logits need to be transmitted and each individual logit becomes larger), potentially even exceeding the cost of transmitting the entire model. How does this method address or consider this issue?\n- The reviewer may miss some details, but why are experiments with model heterogeneity not conducted under strong data heterogeneity (as in Table 2)? Additionally, why are experiments with a large number of clients not performed under strong data heterogeneity (as in Table 3)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "oqpd5mTmxt", "forum": "qraf0Pp4IP", "replyto": "qraf0Pp4IP", "signatures": ["ICLR.cc/2026/Conference/Submission1144/Reviewer_dgdU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1144/Reviewer_dgdU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1144/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911785521, "cdate": 1761911785521, "tmdate": 1762915689827, "mdate": 1762915689827, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose Federated Knowledge Exchange (FKE) to address data and model heterogeneity in federated learning. FKE consists of four procedures in each communication round: knowledge sharing, embedding space unification, synthetic data generation, and federated knowledge exchange. The authors have conducted extensive experiments to verify the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The method is clearly presented, and the paper is well-organized and easy to follow.\n\n2. The proposed method is technically sound.\n\n3. Extensive experiments have been conducted under different settings."}, "weaknesses": {"value": "1. The novelty of the proposed method is a major concern, as bidirectional knowledge distillation is a well-established technique. Moreover, several data-free federated knowledge distillation approaches have been proposed in recent years. It is therefore unclear what the key insight and technical novelty of this paper are.\n\n2 Some experimental settings are unclear. For example, how is model heterogeneity tested?"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jf3vidc5Fs", "forum": "qraf0Pp4IP", "replyto": "qraf0Pp4IP", "signatures": ["ICLR.cc/2026/Conference/Submission1144/Reviewer_B22i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1144/Reviewer_B22i"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1144/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989874377, "cdate": 1761989874377, "tmdate": 1762915689475, "mdate": 1762915689475, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Data-Free Federated Knowledge Exchange (DFFKE), a novel aggregation-free framework designed for heterogeneous federated learning that eliminates the need for both a global model and public datasets by enabling clients to directly exchange knowledge with each other using synthetic data generated from a lightweight embedding decoder, and extensive experiments demonstrate that DFFKE significantly outperforms nine state-of-the-art baselines by up to 18.14% across various levels of data and model heterogeneity while maintaining computational and communication efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The writing is smooth and the readers can easily follow.\n2. Extensive experiments are conducted to verify the effectiveness of the proposed method."}, "weaknesses": {"value": "1. The proposed method essentially achieves knowledge transfer through uploading embeddings, which is not novel. Furthermore, compared to prototype-based methods, it introduces significant additional communication overhead and poses a substantial risk of privacy breaches.\n2. To my knowledge, even with heterogeneous models, the experimental results shouldn't be that bad. Cifar10 is a very simple dataset, but its results are still very low with HtFE-1 and a=0.1, so the results are questionable."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "weLpAKKo6j", "forum": "qraf0Pp4IP", "replyto": "qraf0Pp4IP", "signatures": ["ICLR.cc/2026/Conference/Submission1144/Reviewer_dBun"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1144/Reviewer_dBun"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1144/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762068632243, "cdate": 1762068632243, "tmdate": 1762915689152, "mdate": 1762915689152, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}