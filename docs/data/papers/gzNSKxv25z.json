{"id": "gzNSKxv25z", "number": 20150, "cdate": 1758303069382, "mdate": 1759896998855, "content": {"title": "Pairwise explanations: towards a new task-agnostic paradigm in explainable artificial intelligence", "abstract": "In this study, we introduce Pairwise-IBISA (P-IBISA), a novel extension of the Information Bottleneck with Input Sampling for Attribution (IBISA). Unlike traditional approaches, P-IBISA generates explanations directly from encoder representations, eliminating the need for task-specific logits. This design enables interpretability across a wide range of applications, including image retrieval and vision–language grounding, and is compatible with models trained for classification as well as those pre-trained using self-supervised learning strategies. P-IBISA operates by computing a mask over the input image using a pairwise loss that aligns the embeddings of the masked image with a target embedding. This target can be derived from another image, the image itself, or a different modality—such as text in models like CLIP. We conducted a quantitative evaluation of P-IBISA on models designed for three distinct tasks: image classification, vision–language grounding, and image retrieval. Across these tasks, P-IBISA consistently demonstrated superior or competitive performance compared to state-of-the-art methods, despite being task- and model-agnostic. Qualitative analysis further reveals that P-IBISA produces sharper and semantically richer saliency maps, effectively highlighting meaningful features in both CNNs and ViTs pre-trained on unlabeled data. By decoupling explanations from final outputs, P-IBISA advances the field of xAI beyond task-specific evaluation, offering a unified framework for attribution across diverse scenarios.", "tldr": "", "keywords": ["Explainable AI", "Pairwise attributions", "Model agnostic methods"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7937379f9076f22e18d7702f8ee1aaa6a2ffac4c.pdf", "supplementary_material": "/attachment/fc6604e2c7d3e39833e9b500d21397f2223092aa.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes P-IBISA (Pairwise-Information Bottleneck with Input Sampling for Attribution), a task-agnostic explainability framework that extends the IBISA method.\nUnlike prior XAI techniques relying on task-specific outputs (e.g., logits), P-IBISA produces saliency maps directly from encoder embeddings, enabling explanations for classification, self-supervised, and vision–language models.\nIt optimizes differentiable input masks to align masked embeddings with a target embedding, balancing sparsity and smoothness through parameters (β, ϕ).\nExperiments on ImageNet, MS-COCO, Flickr8k, MS-CXR, and a private medical dataset show competitive or state-of-the-art performance, especially in visual-language grounding."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The idea of generating explanations entirely in the embedding space, independent of output logits, broadens interpretability to non-classification and multimodal tasks.\n\n- The method is tested on classification, retrieval, and visual-language grounding tasks with both CNN and ViT architectures, demonstrating generality.\n\n- Quantitative gains (especially for CLIP) and qualitative saliency maps show sharper, semantically coherent explanations than prior methods."}, "weaknesses": {"value": "- The link between the modified loss (Eq. 8) and the Information Bottleneck principle is intuitive but not formally justified; claims about negative losses and stability remain heuristic.\n\n- Improvements lack statistical validation; comparisons may favor P-IBISA due to differing hyperparameter schemes (learnable vs. fixed). Human or perceptual validation is absent.\n\n- The approach still requires a differentiable encoder, so “task-agnostic” is limited to models with accessible gradients; text-side explanations are unsupported.\n\n- Although the paper claims low computational cost, no runtime comparisons are presented. Sampling multiple masks and optimizing via Adam could be nontrivial."}, "questions": {"value": "- How faithful are embedding-space explanations to model decisions, especially when the task head introduces non-linear transformations? Could P-IBISA highlight features irrelevant to the downstream output?\n\n- What is the actual cost of optimizing multiple masks vs. sampling-based methods like RISE? Are there convergence or stability issues when learning β, ϕ?\n\n- Could P-IBISA generalize to non-visual encoders (e.g., language or audio models)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "53O7BcfZJL", "forum": "gzNSKxv25z", "replyto": "gzNSKxv25z", "signatures": ["ICLR.cc/2026/Conference/Submission20150/Reviewer_M1SE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20150/Reviewer_M1SE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761640202363, "cdate": 1761640202363, "tmdate": 1762999986292, "mdate": 1762999986292, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed an explanation method for black-box models which generates a saliency map to localize the important features on the instance image. The basic idea is to find a coupled image for the instance adopt the information bottleneck criteria to extract the important embedding features that share between both images. The authors also extend the method to achieve image-to-text explanations."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The authors combined previous metrics adopted in information bottleneck explanation methods which reached a more comprehensive scoring function that may be potentially advantageous.\n\nThe idea of adopting IB to achieve cross-modal alignment is interesting."}, "weaknesses": {"value": "The method requires a real sample image with known mask (saliency) to serve as the target for alignment, which poses two limitations. Firstly, the initial inaccuracy for the target mask will hinder the outcome. Secondly, the background variances between samples will degrade the accuracy.\n\nThe experiment part is flawed. Firstly, the method is based on IBISA, so IBISA should be compared for ablation study. Secondly, the authors should not compare only information bottleneck methods, but should also include SOTA xAI methods of other categories that can also generate a saliency map, such as counterfactual generation methods which also adopt paired comparisons and are more powerful in tackling background variances."}, "questions": {"value": "The initial choice of paired image and generation of target masks are crucial for the results but was not described at all. Could you elaborate both of them?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gwOjhPdqH0", "forum": "gzNSKxv25z", "replyto": "gzNSKxv25z", "signatures": ["ICLR.cc/2026/Conference/Submission20150/Reviewer_ZtuP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20150/Reviewer_ZtuP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761986129813, "cdate": 1761986129813, "tmdate": 1762999986240, "mdate": 1762999986240, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces P-IBISA (Pairwise Information Bottleneck with Input Sampling for Attribution), a novel model-agnostic eXplainable AI (XAI) method that extends the Information Bottleneck Principle (IBP) to generate saliency maps. Unlike traditional attribution methods that rely on task-specific logits, P-IBISA works directly on the encoder's embedding space by optimizing a mask over the input image to align its masked embedding with a target embedding (which can be derived from another image, text, or a different task model). The method is positioned as a task-agnostic framework capable of providing explanations across image classification, visual-language grounding (e.g., CLIP), and image retrieval tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. P-IBISA successfully demonstrates its ability to generate saliency maps for various models (CNNs and ViTs) and tasks (classification, VLM grounding, retrieval) using a unified, model-agnostic approach based purely on the encoder's embedding. \n\n2. The method achieves state-of-the-art performance on the quantitative Confidence Drop (CD) metric across all three evaluated tasks (MS-CXR, Flickr8k, MS-COCO), suggesting the generated saliency maps effectively capture the most crucial predictive regions.\n\n3. The generated saliency maps, particularly in the image retrieval and visual grounding tasks, appear visually coherent and semantically relevant to the paired concepts, supporting the claim of generating \"pairwise explanations.\""}, "weaknesses": {"value": "1. The core weakness is the conceptual ambiguity of the \"task-agnostic\" claim. While the method uses the encoder embedding (which is \"task-agnostic\" to the classifier head), the target embedding ($h_t$) must still be provided by a task-specific mechanism (e.g., a text encoder for VLM, another image's encoder for retrieval). This dependency means the method is only decoder-agnostic, not truly task-agnostic, and the complexity introduced is not fully justified over simpler model-specific techniques.\n\n2. The method is highly complex, involving mask optimization, two sparsity and smoothness regularizers ($\\beta$ and $\\phi$), and the need to optimize masks over multiple random initializations and average them. This significant computational overhead and complexity are not adequately justified by the incremental performance gains over existing, simpler model-agnostic baselines like Integrated Gradients or Saliency Map.\n\n3. The paper claims a significant advantage over methods like M2IB and NIB because those methods cannot generate explanations for text inputs. However, this is an unfair comparison since those methods were not designed for multimodal tasks. The appropriate comparison should focus on whether P-IBISA is the best XAI approach for the image portion of the VLM task, which is not clearly demonstrated. \n\n4. The reliance on multiple random mask initializations to ensure robustness (Sec 3.1) suggests a fundamental stability issue in the core optimization problem. A more rigorous analysis of why the single-initialization optimization fails or why this averaging is necessary is missing. Moreover, the lack of an ablation study on the $\\beta$ and $\\phi$ hyperparameters, which control crucial sparsity and smoothness, leaves the method highly vulnerable to practitioner use."}, "questions": {"value": "1. Please clarify the computational cost of P-IBISA relative to simpler gradient-based methods. Given that P-IBISA requires optimizing the mask $m$ for multiple random initializations (Equation 2) and uses an iterative optimization loop (Algorithm 1), how does the total runtime (per explanation) compare to baselines like Integrated Gradients?\n\n2. The \"task-agnostic\" claim is highly ambitious. Could the authors refine this claim to \"decoder-agnostic\" and discuss the practical limitations that arise from the dependency on a pre-calculated target embedding ($h_t$)? Specifically, how is $h_t$ obtained in a truly novel, unseen task setting?\n\n3. The paper uses a weighted combination of three terms in the total loss $\\mathcal{L}_{\\text{P-IBISA}}$ (Equation 6). An ablation study on the loss terms and the $\\beta$ and $\\phi$ hyperparameters is crucial. What is the impact of varying the coefficients of the sparsity/smoothness terms on the MoRF and CD metrics?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7T9bfSNMzM", "forum": "gzNSKxv25z", "replyto": "gzNSKxv25z", "signatures": ["ICLR.cc/2026/Conference/Submission20150/Reviewer_sx2L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20150/Reviewer_sx2L"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762011724833, "cdate": 1762011724833, "tmdate": 1762933178766, "mdate": 1762933178766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes P-IBISA (Pairwise-IBISA), an extension of the Information Bottleneck with Input Sampling for Attribution (IBISA) framework, designed to generate task-agnostic explanations directly from encoder representations rather than output logits. The method aims to provide a unified framework for explainability across tasks such as image classification, vision–language grounding, and image retrieval."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The topic is timely and practically important, addressing the increasing need for unified, model-agnostic interpretability methods applicable across diverse architectures and tasks.\n\nThe proposed pairwise formulation introduces a flexible perspective that can potentially apply to tasks like image retrieval or cross-modal alignment."}, "weaknesses": {"value": "The proposed approach mainly extends IBISA by substituting logits with encoder embeddings and introducing learnable regularization terms. This is a modest technical modification rather than a fundamentally new framework. The paper does not clearly articulate how P-IBISA advances the state of the art beyond prior information bottleneck–based and model-agnostic explanation techniques. The claimed “task-agnostic” property is somewhat overstated since the method still depends on task-specific embedding structures.\n\nMany reported results are only marginally better or even comparable to baselines. In some cases, the choice of baselines omits more recent explainability methods, making the reported superiority claims unconvincing. The paper asserts consistent state-of-the-art performance, but quantitative results do not consistently demonstrate clear or statistically significant improvements over baselines.\n\nThe qualitative results presented are limited and largely anecdotal. The paper would benefit from more visual examples, including failure or ambiguous cases, to help readers understand the model’s strengths and limitations.\n\nSeveral aspects of the method, such as the rationale for allowing negative loss values and the stability of learnable sparsity parameters, lack rigorous justification or ablation studies.\n\nKey figures (especially Figure 1) are difficult to interpret, and the roles of different components (e.g., pair image, target embedding, masked image) are not clearly delineated.\n\nThe field of attribution and explainability is already well-explored, and without clearer differentiation or deeper insights, the paper’s contribution risks being perceived as incremental.\n\nI found several typos throughout the paper. Please proofread."}, "questions": {"value": "How does P-IBISA fundamentally differ from the original IBISA framework beyond replacing logits with encoder embeddings? Could you clearly articulate the theoretical or algorithmic innovation that makes this a new paradigm rather than an incremental variant?\n\nWhy were more recent or advanced xAI methods (e.g., LRP variants, concept-based explainers, or feature steering approaches) not included as baselines? Would incorporating these methods change the relative performance claims of P-IBISA?\n\nSome experimental results show only marginal or inconsistent improvements. Have you performed statistical tests (e.g., significance or confidence intervals) to ensure the observed differences are meaningful and reproducible?\n\nCan you include additional qualitative examples, especially failure or ambiguous cases, to better illustrate when P-IBISA succeeds or fails? This would provide readers with a more comprehensive understanding of the method’s behavior across contexts."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FicAPDOn6I", "forum": "gzNSKxv25z", "replyto": "gzNSKxv25z", "signatures": ["ICLR.cc/2026/Conference/Submission20150/Reviewer_mT9S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20150/Reviewer_mT9S"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762013480983, "cdate": 1762013480983, "tmdate": 1762933176926, "mdate": 1762933176926, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Pairwise-IBISA (P-IBISA), an extension of the Information Bottleneck with Input Sampling for Attribution (IBISA). The method generates saliency maps directly from encoder representations instead of model outputs, allowing attribution across different tasks such as image classification, vision–language alignment, and image retrieval. The authors evaluate P-IBISA on several benchmarks and report competitive or state-of-the-art performance on quantitative metrics including MoRF, LeRF, Confidence Drop, and Confidence Increase.\nThe methodological contribution of moving from task-specific to encoder-based attribution is an interesting technical step and represents a modest but genuine improvement over previous work.\n\nThis paper presents an interesting technical extension of IBISA and shows credible quantitative improvements. However, it suffers from overstated interpretability claims, unclear qualitative evidence, confusing figures, and a lack of ethical transparency concerning the medical dataset. The work represents an incremental technical advance but does not substantiate its broader claims about explainability or human understanding."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-\tThe paper presents a coherent technical advancement by making IBISA encoder- and task-agnostic. This may be useful for understanding models where the output layer is not directly accessible.\n-\tThe experiments are broad in scope and demonstrate the method across several domains, with consistent implementation and comparison to relevant baselines.\n-\tQuantitative results indicate good performance and reduced computational cost relative to some existing gradient-based approaches."}, "weaknesses": {"value": "Overstated claims of explainability - The paper repeatedly overstates its contribution to explainable artificial intelligence. While P-IBISA provides a novel attribution mechanism, the authors make strong claims about improved human interpretability that are not supported by evidence. No user study or structured qualitative analysis is conducted. The abstract and Section 6 refer to a “qualitative analysis”, but the paper only includes example saliency maps without much evaluation.\nThe paper also states “P-IBISA also reveals that models trained with only unlabelled data learn human-relatable features” which is not particularly supported by evidence. The presented saliency maps only show that self-supervised models focus on object regions, which does not demonstrate human-relatable feature learning… This observation is already well established in self-supervised learning literature and does not result from the proposed explainability method.\nConfusing and inconsistent figures - Several figures are unclear or contain errors. I.e. \nFigure 2 has a caption that is grammatically incorrect and largely unintelligible (“we the are models… others cases are care for models…”), which makes interpretation difficult.\nThe contrastive explanation examples in Appendix A are confusing and seemingly counterintuitive – the same image is compared with itself showing only erroneous similarities and, more interestingly, strong contrast. \nReferences to additional qualitative examples, such as those supposedly in Appendix B, do not correspond to any actual figures.\nOverall, the visual presentation does not effectively support the claims about interpretability. \nMissing or unclear supplementary materials (as mentioned above) – mentioned in the caption of figure 3.\nUse of private medical data - \nSection 6.3 introduces a private dataset of breast photographs used for a medical image retrieval experiment. This seems unmotivated and raises a few questions. Firstly, there is no ethics statement, institutional approval, or information about patient consent. Secondly, the dataset is private and therefore no reproducible. The inclusion of this material is not well motivated and does not clearly relate to the main technical focus of the paper (why not use a publicly available medical dataset?). Furthermore, the resulting saliency maps highlight the obvious breast regions, which provides no meaningful clinical insight. This choice seems rather out of place from the rest of the paper."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "18bTpweByC", "forum": "gzNSKxv25z", "replyto": "gzNSKxv25z", "signatures": ["ICLR.cc/2026/Conference/Submission20150/Reviewer_6qZz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20150/Reviewer_6qZz"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission20150/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762343640652, "cdate": 1762343640652, "tmdate": 1762933175804, "mdate": 1762933175804, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}