{"id": "J2peqXPQbB", "number": 13033, "cdate": 1758212878039, "mdate": 1763760415175, "content": {"title": "In-Context Algebra", "abstract": "We investigate the mechanisms that arise when transformers are trained to solve arithmetic on sequences where tokens are variables whose meaning is determined only through their interactions. While previous work has found that transformers develop geometric embeddings that mirror algebraic structure, those previous findings emerge from settings where arithmetic-valued tokens have fixed meanings. We devise a new task in which the assignment of symbols to specific algebraic group elements varies from one sequence to another. Despite this challenging setup, transformers achieve near-perfect accuracy on the task and even generalize to unseen algebraic groups. We develop targeted data distributions to create causal tests of a set of hypothesized mechanisms, and we isolate three mechanisms the models learn: commutative copying where a dedicated head copies answers, identity element recognition that distinguishes identity-containing facts, and closure-based cancellation that tracks group membership to constrain valid answers. Complementary to the geometric representations found in fixed-symbol settings, our findings show that models develop symbolic reasoning mechanisms when trained to reason in-context with variables whose meanings are not fixed.", "tldr": "", "keywords": ["Interpretability", "In-Context Learning", "ICL", "Algebra", "Grokking", "Symbolic Reasoning"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9e60daed61a867f7be7ec9dc5c65be24380c59ba.pdf", "supplementary_material": "/attachment/5dd34147a1676a42dbdcd4d7941d4f5604f6b4ac.zip"}, "replies": [{"content": {"summary": {"value": "The paper investigates the mechanisms transformers learn to solve arithmetic problems defined by finite algebraic groups. Critically, the task is set in an in-context learning format where the meaning of tokens (their assignment to specific group elements) is variable and defined only within the current sequence. This contrasts with prior work (e.g., on \"grokking\" modular arithmetic) which used fixed token-to-value mappings and found the emergence of geometric, Fourier-based representations.\n\nThe authors find that in their variable-token setting, the model achieves high accuracy and generalizes to unseen groups. Through causal analysis (activation patching, subspace analysis), they identify a different set of mechanisms: not geometric embeddings, but \"symbolic\" operations. These include a dedicated head for verbatim and commutative copying, a two-part mechanism for identity element recognition (query promotion + identity demotion), and a subspace-based mechanism for closure-based cancellation (tracking group membership and eliminating invalid answers). The paper concludes that geometric representations may be an artifact of fixed-symbol tasks and that models default to symbolic reasoning when meanings are context-dependent."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The \"in-context algebra\" task is a novel and interesting probe for mechanistic interpretability. By forcing token meanings to be sequence-local, it creates a clean setting to study how transformers perform reasoning when they cannot rely on pre-trained, fixed-meaning embeddings.\n\n- The paper goes beyond simple performance metrics and attempts a rigorous mechanistic decomposition of the learned algorithm. The use of causal interventions (patching) to isolate specific heads (e.g., Head 3.6 for copying) and the PCA/subspace analysis to understand identity and closure mechanisms are commendable.\n\n- The finding that mechanisms are multi-part (e.g., identity recognition being a combination of \"query promotion\" and \"identity demotion\") is insightful and adds a layer of depth beyond just \"this head does X.\""}, "weaknesses": {"value": "- The paper's central thesis is that its contribution is \"challenge the hypothesis that geometric embeddings are the primary mechanism\" for algebraic problems. This framing may be slightly marginal for a conference. The prior work on geometric/Fourier-basis representations documented the phenomenon specific to a task with fixed token meanings. It might be more constructive to frame this paper's findings as a complement to that work, showing an expected and important contrast: when the pre-conditions for geometric embeddings are removed (i.e., by making token meanings variable), models develop a different, symbolic-like strategy. This distinction is a valuable contribution in itself, showing how task design dictates the learned mechanisms.\n\n- *Weak Experimental Analysis*: The paper's mechanistic analysis is a great start, but feels incomplete in a few areas that would make the claims more robust.\n  - **Omission of Associativity**: The authors hypothesize five mechanisms (Sec 4) but find their model performs poorly on \"Associative Composition\" (60.2% accuracy at k=50, Fig 3c). Associativity is arguably the most fundamental property of a group. The paper would be much stronger if it included a causal analysis of this failure. Why does the model fail at associativity? What partial or heuristic-based mechanism does it learn instead? Analyzing this failure mode could offer even deeper insights than analyzing the successes.\n  - Because the analysis (understandably) focuses on the learned mechanisms, it's less clear what generalizable insights this task provides. The mechanisms (copying, identity, elimination) are powerful heuristics, but they aren't unique to group theory. It would be great if the authors could further discuss whether the model has learned \"algebra\" or a set of clever, task-specific heuristics.\n\n- *Ablation Studies*: The analysis is based on a single \"toy\" model (4-layer, 8-head) trained from scratch. The findings would be more generalizable if the authors could provide some ablation studies. For example, how do these mechanisms change with model depth/width, or other hyperparameters? This would help confirm that these mechanisms (e.g., Head 3.6) are a general solution rather than an artifact of one specific architecture.\n\n- \"From Scratch\" vs. Pre-trained: Relatedly, the \"from scratch\" setting is interesting, but a very relevant follow-up would be to explore how a pre-trained LLM tackles this task. Would it develop these same mechanisms, or would it repurpose existing in-context learning circuits? Exploring this could bridge the gap between toy models and real-world LLMs.\n\n- **Tokenization Details**: A small but important detail that would be good to clarify is tokenization. The paper implies each variable is a single token. It would be helpful to explicitly confirm this and perhaps discuss how the task difficulty might change if variables were multi-token strings, which is a common scenario in natural language.\n\n- I also notice authors may also may be great mention some relevant work like [Language Models are Symbolic Learners in Arithmetic](https://arxiv.org/abs/2410.15580) which they use subgroups to derive symbolic behaviors in LM and a concurrent work [Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls](https://arxiv.org/abs/2510.00184) (concurrent). Situating this paper's findings relative to these would be very interesting for the community."}, "questions": {"value": "- The model's difficulty with \"Associative Composition\" (Fig 3c) is very interesting, as this is a core algebraic property. I was surprised to see it wasn't included in the causal analysis. Could the authors elaborate on why this was omitted, and perhaps share any preliminary findings on why the model struggles here? This seems like a fascinating area for future work.\n- Could the authors provide more mechanistic detail on the \"Closure-Based Cancellation\" (Sec 5.4)? The text describes it as a set difference $S_{closure}$ - $S_{cancel}$. How are these sets represented in their respective subspaces, and how is the \"set difference\" operation mechanistically computed by the model? The high-level concept is clear, but a deeper dive into the \"how\" would be fantastic.\n- The model's ability to generalize to unseen groups (Fig 2c) while failing at associativity is a curious result. Does this suggest to the authors that the model has learned general heuristics (copying, identity, cancellation) that work for many group-like structures, rather than a deep, rule-based understanding of group axioms? The generalization to non-groups (semigroups, magmas) seems to support this, and I'd be interested in the authors' take."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZWDEUxf5UB", "forum": "J2peqXPQbB", "replyto": "J2peqXPQbB", "signatures": ["ICLR.cc/2026/Conference/Submission13033/Reviewer_9LQ5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13033/Reviewer_9LQ5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13033/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761451561576, "cdate": 1761451561576, "tmdate": 1762923768331, "mdate": 1762923768331, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to all Reviewers (1/2)"}, "comment": {"value": "We would like to thank each of the reviewers for their thoughtful and constructive feedback. We have made several improvements and additions to the manuscript based on reviewer comments. We provide a summary of the key changes we have made here, and also respond to individual reviewers in separate comments.\n\nWe are also running more experiments related to questions asked by XJFb, 9LQ5 and will update this thread with more information as they finish.\n\n**Changes to the Main Paper:** \n\n- **Relating to fourier arithmetic representation work:** Our findings are distinct and complementary to prior work studying fourier representations, as we investigate a new setting where tokens lack fixed meaning;  We have updated the Conclusion section to clarify this focus  (Reviewer 9LQ5)\n\n- **Associative Law Modeling (Figure 3):** We have updated Figure 3 in the main paper and corresponding text in Section 4.1 to include associativity coverage (shown in blue) for both train and hold-out data. (Reviewer XJFb, 9LQ5)\n\n- **Mechanism-specific loss curves (now numbered Figure 6):** One of the most interesting findings of the paper is the fact that drops in loss correspond to learning different mechanisms/skills throughout the course of training. We have clarified this by updating Figure 6 and moving it to Section 6 in the main paper, which we have renamed “Phase Transitions Correspond to Learning of Discrete Skills”.\n\n- **Related Work:** Thank you for pointing out additional related work; we have added additional references to both section 7 (Related Work) and the appendix to address reviewer comments (Reviewer Cayz, XJFb, 9LQ5)\n\n- **Correction to Figure 2c:** We wish to clarify for the reviewers that hold-out performance on semigroups is very good, similar to hold-out performance on unseen groups, while hold-out performance on (non-group) quasigroups and magmas is low, suggesting that the model has learned to exploit particular abstract algebraic structure seen in training.  We have updated Figure 2c and corresponding text in Section 3 to show model performance on the three groups of order 8 that were not seen during training. Plots for non-group algebraic structures have been moved to Appendix B.3. (Reviewer 9LQ5)"}}, "id": "Rn5d9ThHcZ", "forum": "J2peqXPQbB", "replyto": "J2peqXPQbB", "signatures": ["ICLR.cc/2026/Conference/Submission13033/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13033/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13033/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763759792873, "cdate": 1763759792873, "tmdate": 1763759851186, "mdate": 1763759851186, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Overall, this work is thorough, well-written, well-motivated, and is strongly situated in the literature. The causal experiments broadly support the claims made in the paper. While the scope of transformer models is limited (I would like to see how and if model depth changes the ability of the model to make completions of different type), the paper offers a deep dive into how transformers accomplish in-context reasoning in this scenario. This paper would be useful and interesting to those in the mechanistic interpretability field, and it should be accepted to ICLR.\n\n\nThe authors design a novel experiment in which small transformer models learn to complete algebraic facts where the meaning of individual symbols is new (and only defined by the context) each time. This is significant because it helps researchers understand mechanisms by which transformers learn from context rather than from pre-determined world knowledge or structure when completing tasks. The authors report that small transformers can achieve near-perfect accuracy on the task and generalize to new samples. Most of the accuracy can be attributed to five known strategies for the completions, but a small percentage of performance remains unexplained. They find three causal mechanisms by which transformers complete the task: identity element recognition, commutative copying, and closure-based cancellation. The causal experiments involve measuring IE when patching specific attention layers from completions where the strategy is possible to completions where the strategy is not possible. They find specific attentions are responsible for implementing specific strategies. These attention heads tend to deactivate (attend to themselves) when the strategy is not possible. The authors describe a clear multi-step method by which identity facts are recognized and promoted to form the completion. Lastly, the authors investigate mechanisms for closure-based cancellation, leveraging probes to track the model’s knowledge of candidate completion elements given incomplete information and subspace models which generate counterfactual answers. The mechanisms are verified with causal experiments.\n\n\nThe work is well-motivated and grounded in relevant literature on mechanistic interpretability and LLM arithmetic problem solving. \n\nMinor Comments:\nLine 409 “can encoding” -> “can encode”\nLine 481 typo \"transformner\" -> \"transformer\""}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The work is well-motivated and grounded in relevant literature on mechanistic interpretability and LLM arithmetic problem solving. \n\nThe claims regarding learning learning mechanisms are largely validated using causal experiments.\n\nThe experiment design is thorough and sound. There is sufficient reproducibility information.\n\nThe paper is well-written and easy to follow for those in the field."}, "weaknesses": {"value": "The scope of transformer model is limited to one architecture and size. It would be interesting to see how the results change as different numbers of layers (but also attention heads, representation dimension) are considered. One might predict that transformer layer depth allows for more complex sequential operations. For example, depth might lead to better performance on associative composition, which did not appear to benefit from more in-context examples.\n\n\nThere is limited to no discussion of ways in which the results *might* extend beyond this abstract problem setting"}, "questions": {"value": "How does transformer size impact the mechanisms learned? How does size (mostly depth) impact the performance on this task?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CSWzIAjmay", "forum": "J2peqXPQbB", "replyto": "J2peqXPQbB", "signatures": ["ICLR.cc/2026/Conference/Submission13033/Reviewer_sQQh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13033/Reviewer_sQQh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13033/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932874772, "cdate": 1761932874772, "tmdate": 1762923768052, "mdate": 1762923768052, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work explores how transformers learn to perform certain types of symbolic manipulations, where tokens have no fixed meaning but rather have meaning that is context-dependent. This is done through an in-context learning algebra task where the model is prompted with a sequence of $k$ facts from a set of groups whose elements are randomly mapped to tokens in the vocabulary, then asked about some product in one of the groups. This design makes it so that the learned embeddings for each token cannot themselves represent the identities of the group elements. Instead, the model must learn the corresponding algebra in-context. The authors identify five simple strategies (verbatim copying, commutative copying, identity element recognition, associative composition, and closure-based cancellation) that account for some of the model's performance. They then identify how the model implements four out of five of these mechanisms in causal intervention techniques."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The problem is interesting and well-motivated. The paper is generally well-written and clearly presented. \n- The methodology is sound, and the conclusions are moderate and well-supported by the empirical evidence.\n- The in-context algebra task provides a reasonable testbed for studying symbolic reasoning, which ablates the effect of learned geometric embeddings.\n- The analysis of the closure-based cancellation mechanism is technically solid and one of the paper’s strongest contributions."}, "weaknesses": {"value": "- The task probes a narrow type of symbolic reasoning. The five hypothesized strategies are relatively simple and do not fully capture the richer “meaning-free” symbolic manipulation motivating the study. The contribution would be stronger if the task enabled the discovery of more complex or novel mechanisms.\n- The causal analysis fails to identify a concrete mechanism for associative composition, arguably the most conceptually interesting of the five. The mechanisms that are identified for the other strategies are similar to transformer circuits that were identified in previous work.\n- The five hypothesized mechanisms do not fully explain model performance, especially for contexts with fewer facts $k$ (which is the more challenging and more interesting case)\n\nSee also the questions below."}, "questions": {"value": "- Is the task designed to be solvable for all numbers of facts $k$? I.e., does there exist a unique solution for each prompt sequence? From the random nature of the data generation process described, it seemed like the answer is no. If so, it would be interesting to compare the model performance to the ideal algorithmic performance. How close does the transformer model get to this optimal level of performance?\n- Why is the \"associative composition\" strategy missing from Figure 3?\n- What was the purpose of having the task be composed of multiple groups? I can imagine an alternative (simpler) task where, in each sequence, a group structure is randomly generated with group elements being randomly assigned tokens in the vocabulary. What would the difference be between these two tasks for the purposes of the investigation?\n\nMinor comments:\n- the bold \"=\" sign does not render very nicely (the spacing is a bit off) in Eqs (2) and (3). It makes the two equations appear a bit out of alignment.\n- In Fig. 2a, you can use different colors rather than line styles for different lines to improve readability.\n- The \"Task Description\" section was a bit unclear on the first read. I'd suggest revising it. For example, the sentence in lines 95-96 was phrased in a confusing way (needed to look at the figure to understand). I'd also recommend explicitly mentioning that the mapping $\\phi_s$ is one-to-one and that $|H_s| < |V|$"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ep10Dn7UbW", "forum": "J2peqXPQbB", "replyto": "J2peqXPQbB", "signatures": ["ICLR.cc/2026/Conference/Submission13033/Reviewer_XJFb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13033/Reviewer_XJFb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13033/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969955416, "cdate": 1761969955416, "tmdate": 1762923767570, "mdate": 1762923767570, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper examines how transformers solve algebraic problems. Unlike the standard setting, however, the meaning of the symbols are not fixed, and must be inferred from their context. In this setting, and unlike previous mech interp work that showed that models used geometric embeddings (famously the Fourier basis) to do arithmetic, models use symbolic reasoning in this setting. The authors use e.g. causal ablations to show that models develop three mechanisms to do this: attention heads to verbatim/commutative copying, a mechanism for identity element recognition, and something they term “closure-based cancellation” where models track groups membership to constrain valid answers."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- There are a large number of experimental results. The models design a novel in-context algebra task, and perform lots of experiments. Unlike previous settings, this task isolates in-context arithmetic. It elicits symbolic mechanisms; the authors very convincingly show this.\n- Likewise, the authors bring a number of methods to bear to prove out the mechanisms described above, including computing the indirect effects at the level of attention heads."}, "weaknesses": {"value": "- This task is novel, however it strikes me as contrived and very toy. I struggle to see (a) how these findings will generalize to more interesting settings, (b) what this tells us about models that we did not already know, or (c) how this work convincingly tests interpretability methods."}, "questions": {"value": "- How generalizable are the symbolic mechanisms might the symbolic mechanisms identified here? For example, how might these interact with the geometric mechanisms found robustly in prior work? In a mixed task with both fixed-symbol and variable-symbol arithmetic, would the model would the geometric strategy dominate?\n- It is maybe an over-claim that the PCA direction \"causally controls identity recognition”? Namely, the described modification changes the \"query-promotion\" component and must be paired with a second, separate intervention (inserting a false identity fact) for the full identity-demotion step."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "48AHxkLrby", "forum": "J2peqXPQbB", "replyto": "J2peqXPQbB", "signatures": ["ICLR.cc/2026/Conference/Submission13033/Reviewer_Cayz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13033/Reviewer_Cayz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13033/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762895787632, "cdate": 1762895787632, "tmdate": 1762923767215, "mdate": 1762923767215, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}