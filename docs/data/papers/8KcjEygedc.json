{"id": "8KcjEygedc", "number": 22045, "cdate": 1758325274143, "mdate": 1763699700575, "content": {"title": "Why Less is More (Sometimes): A Theory of Data Curation", "abstract": "This paper introduces a theoretical framework to resolve a central paradox in modern machine learning: When is it better to use less data? This question has become critical as classical scaling laws suggesting ``more is more'' (Sun et al., 2025) are challenged by methods like LIMO (``less is more'') and s1 (Ye et al., 2025; Muenighoff et al., 2025), which achieve superior performance with small, aggressively curated datasets. Here, we study data curation strategies where an imperfect oracle selects the training examples according to their difficulty and correctness. Our results provide exact scaling law curves for test error under both label-agnostic and label-aware curation rules, revealing when and why keeping only a subset of data can improve generalization. In contrast to classical scaling laws, we show that under certain conditions, small curated datasets can outperform full datasets, and we provide analytical conditions for this by deriving precise phase transition curves tied to data size and quality. We validate these theoretical claims with empirical results on ImageNet, confirming our predictions about when curation improves accuracy and can even mitigate model collapse. Furthermore, our framework provides a principled explanation for the contradictory curation strategies recently observed in LLM mathematical reasoning.", "tldr": "We provide an exact analysis of data curation and reveal striking phenomena regarding scaling laws and also mitigating model collapse. Our results reconcile LIMO and MIMO, two different philosophies regarding data curation.", "keywords": ["data curation; LIMO (Less Is More); MIMO(More is More); synthetic data; beating scaling laws; mitigating model collapse; random matrix theory"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/768a2fef691a4170e055510d4a53969374d65ce8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a principled theoretical framework for data curation, trying to figure out when less data actually works better than more, to challenge the classical \"more is more\" scaling laws with comprehensive experiments. It derives exact scaling laws for test error under label-agnostic and label-aware curation rules, showing that strategically pruned small datasets can outperform full datasets under conditions like strong generators and abundant data, while also mitigating model collapse."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1.  The first paper tries to theoretically explain when and why LIMO happens in machine learning by developing a principled theoretical framework for data curation, enabling practitioners to design data-centric pipelines instead of blindly scaling datasets.\n2. Also provides a unifying explanation for contradictory curation strategies.\n3. The writing and presentation look perfect to me."}, "weaknesses": {"value": "1. While the paper links theory to LLM math reasoning (AIME benchmark in Table 1&2), it would be better to discuss other LLM-critical tasks (e.g., code generation, natural language understanding, or multi-step reasoning benchmarks) where curation is also widely used. Additionally, the authors do not investigate how the pruning ratio or oracle quality affects performance across different model sizes (e.g., 7B vs. 70B LLMs), leaving uncertainty about whether the LIMO principle holds consistently across LLM scales."}, "questions": {"value": "1. The theory is framed around binary classification, but multi-class tasks are definitely more common in practice. Could you discuss whether the optimal pruning strategies could extend to multi-class settings?\n2. In the ImageNet experiment, the generator and pruner are the same pre-trained ViT, which ensures alignment, but real-world CV pipelines may use separate generators (e.g., a synthetic data model) and pruners (e.g., a human-in-the-loop verifier). Could you discuss how misalignment between generator and pruner (e.g., low ρ₊ relative to ρ) would impact the optimal curation strategy, and whether this differs from the LLM case (where generator and pruner are often separate)?\n3. I have another question for the authors, but not necessarily to be answered: LLM training encompasses pre-training, post-training, and stages such as SFT and RL within the fine-tuning process, with distinct training data used for each stage. For the LIMO method discussed in the paper, in which of these training stages is its principle more likely to be reflected?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "xNVfNUJt12", "forum": "8KcjEygedc", "replyto": "8KcjEygedc", "signatures": ["ICLR.cc/2026/Conference/Submission22045/Reviewer_dewW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22045/Reviewer_dewW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753053204, "cdate": 1761753053204, "tmdate": 1762942033488, "mdate": 1762942033488, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper develops a teacher–student, high-dimensional model of learning from curated data in order to reconcile two empirically observed regimes in modern LLM/vision training: \"More is more\" regime (classical scaling laws) in Kaplan et al. (2020) and Hoffmann et al. (2022), where performance improves monotonically with dataset size vs. \"Less is more\" regime (LIMO/s1–style curation), when the generator is strongly aligned with the target, then selectively keeping only the most informative/hard examples yields strictly lower test error than training on the full set. Formally, the authors setup a theoretical model with Gaussian inputs and labels generated by a linear teacher with known alignment, and the learner as a ridge (square-loss) estimator trained on a pruned sample whose selection is governed by an oracle with its own alignment parameter. Using random-matrix/deterministic-equivalent techniques, the authors derive closed-form high-dimensional limits for the test error after curation. The authors show numerical simulations of their theory and corroborated with empirical simulations."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is clearly written and well-organized. The paper has both solid theoretical side and empirical evidence.\n* The paper has deep theoretical building blocks with high dimensional asymptotics of linear models and classification problems. Using both RMT techniques and tools from Feng et al. for classification problems to study the effects of pruning by the oracle. The conclusions are sound as far as I have checked, and the results appear novel to me.\n* The paper's conclusion provides an alternative to neural scaling laws: it is possible to perform with higher accuracy with fewer data with an expert pruner. This also gives a potential remedy to the neural collapse phenomenon where the training procedure seeks to scale with self-generated data---perhaps by scrutiny using the synthetic data (instead of training on them) and picking only harder/easier problems we can avoid model collapse from synthetic data."}, "weaknesses": {"value": "Major comments:\n* I think the main inconsistency between the main message and theory is that: both \"KE\" and \"KH\" strategies are effectively \"less is more\". It is just what data should be picked. I think it is a bit of stretch to say \"KE\" is equivalent to \"more is more\", while the neural scaling laws scenario should correspond to a very small $\\phi$ instead of the \"KE\" strategy. \n* The theory relies on linear model with Gaussian covariates, and is limited to the binary classification setup with proportional asymptotics. This is, definitely limited, as is acknowledged also by the authors in the limitation discussions, a good starting point for study the pruning and data curation in large datasets. I think this is only a minor weakness.\n\nMinor comments:\n* A general style suggestion: use \\eqref instead of \\ref for equations.\n* Page 19, \"Corollary xyz\". I think this is a placeholder or typo."}, "questions": {"value": "* My main questions are in the weaknesses section. I would especially like to see more discussions between \"KE\" and \"more is more\". \n* The paper uses deterministic equivalence to obtain risk asymptotics for the problem (2). While in general, when l is a convex loss function, using the CGMT techniques the similar asymptotics can also be obtained. See Karoui (2013). What do authors think the behavior in this setup? Would the same behavior also be expected?\n\nKaroui, Noureddine El. \"Asymptotic behavior of unregularized and ridge-regularized high-dimensional robust regression estimators: rigorous results.\" arXiv preprint arXiv:1311.2445 (2013)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "204fZl2qeG", "forum": "8KcjEygedc", "replyto": "8KcjEygedc", "signatures": ["ICLR.cc/2026/Conference/Submission22045/Reviewer_tAw9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22045/Reviewer_tAw9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875628736, "cdate": 1761875628736, "tmdate": 1762942033286, "mdate": 1762942033286, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work seeks to develop a theoretical framework for understanding data curation. In other words, they seek a theory that can predict when it is best to use less data (filtered/curated) versus all data (no filtering/curation). The authors are motivated by the fact that there are cases where small datasets have been shown to be beneficial, like LIMO and s1. Their theoretical results assume a Gaussian feature model under a binary classification setting."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors use their theory to show that it can predict empirical results to a surprising degree (mean relative error of 1.8% according to App. B), and within these empirical results live the settings they sought to understand: when all data is needed (\"more is more\") and when curation is needed (\"less is more\")\n2. Authors consider both label-agnostic and label-aware data curation in their theory\n3. Significant extra detail for figures and proofs are provided in appendix, answering a few of my early questions"}, "weaknesses": {"value": "1. Arguably the most important feature of the paper is that their theory is predictive of empirical results in a very realistic dataset (ImageNet training of a ViT), but it is not clear from the writing how to use this in practice. In particular: how does someone measure the quality of the generator $\\rho$ for a dataset you are given? No commentary on this is given. A bonus would be if the authors gave a step-by-step appendix section for a practitioner on how to use their theory (willing to raise score for clarity on this)\n2. \"the base LLM is a strong generator\" based on what? how is this claim measured? \n3.  Why is $n=5000$ considered the \"large data\" setting in Figure 1? How was this number chosen? That $n$ is smaller than the CIFAR-10 training set...\n\nMinor: \n- capitalize PDF and CDF on L184"}, "questions": {"value": "1. Why is the Gaussian feature model noted as a limitation? Wouldn't we expect gaussian distributions of features according to central limit theorem? The authors mention real-world data is \"structured\" but I find that vague.\n2. How does someone measure the quality of the generator $\\rho$ for a dataset you are given?\n3. Is it possible to know the quality of pruning? For example, suppose I curate a dataset of text by removing duplicates, how would a \"quality\" be assigned to that?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "84A8c8Dr05", "forum": "8KcjEygedc", "replyto": "8KcjEygedc", "signatures": ["ICLR.cc/2026/Conference/Submission22045/Reviewer_CgiU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22045/Reviewer_CgiU"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966994534, "cdate": 1761966994534, "tmdate": 1762942032373, "mdate": 1762942032373, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a rigorous theoretical framework to analyze the efficacy of data curation strategies in high-dimensional learning. It addresses a central paradox in modern ML: When does aggressive data pruning (\"Less is More,\" exemplified by methods like LIMO and s1) outperform training on the full dataset (\"More is More\")?\n\nThe paper model this scenario using high-dimensional binary classification and regression with Gaussian covariates. The setup captures the interactions between a data generator ($w_g$), the ground truth ($w_*$), and a pruning oracle ($w_o$), allowing for label shift. They analyze both label-agnostic (based on difficulty/margin) and label-aware (based on difficulty and correctness) curation.\n\nUsing RMT, the paper derive exact asymptotic expressions for the test error in the proportionate scaling limit ($d/n \\to \\phi$). The central theoretical finding (Theorem 2) identifies a precise phase transition: \"Less is More\" (specifically, keeping hard examples) is optimal iff data is abundant AND the generator is strong. In all other regimes (scarce data or weak generator), using more data or keeping easy examples is superior.\n\nWhile the paper is primarily theoretical, it tries rounding itself off with some simulations and Imagenet experiments."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- **Theoretical Rigor and Exactness:** The primary strength is the sophisticated mathematical analysis. By leveraging RMT, the paper derive *exact* asymptotic formulas for the generalization error (Theorems 1, 3). This allows for a precise characterization of the interplay between data quality ($\\rho$), oracle quality ($\\rho_*$), and data scale ($\\phi$), moving far beyond bounds or heuristics. The derivation of how pruning \"deforms\" the Marchenko-Pastur law governing the data spectrum is technically impressive and commendable. \n\n- **Good Resolution of the \"Less vs. More\" question:** The paper provides a clear and elegant resolution to conflicting empirical observations regarding data scaling. Fig. 1 beautifully illustrates the four key regimes of learning. The insight that the optimal strategy is fundamentally tied to the generator's strength relative to the task difficulty is a major conceptual contribution.\n\n- The framework successfully unifies several recent lines of work, including data pruning strategies and model collapse mitigation. The analysis of label-aware curation (Section 3.2) is highly relevant to modern SFT/RL*F pipelines where reward models filter policy outputs. The demonstration that strategic pruning prevents model collapse (Fig. 3) is practically significant for the stability of iterative training loops.\n\n- The authors provide some practical validation. Synthetic experiments show strong agreement with the theory (App. B, Fig. 4). Crucially, the ImageNet experiments confirm that the qualitative insights transfer to deep learning settings (ViT), and the analysis in Sec. 4.2 provides a compelling explanation for recent contradictory LLM results."}, "weaknesses": {"value": "**Linear Models:** The theoretical results are derived under the assumption of linear models and Gaussian covariates. This is a known standard simplification for RMT analysis but limits the direct quantitative applicability to deep neural networks on structured data. However, the empirical results do point towards potential qualitative transfer, but would warrant a more complete exploration. \n\n**Fixed Oracle:** The framework assumes a fixed pruning oracle ($w_o$). In practice, oracles (e.g., reward models) are often learned and may evolve adaptively during training (e.g., iterative RLHF), which is not captured in the current analysis. Extending the theory to adaptive oracles would be an important future direction.\n\n\nI am **highly skeptical** that this constitutes the explanation for \"Less is More\" in modern deep learning. The assumptions are too strong, the dynamics of optimization (like SGD) and feature learning are ignored, and the empirical validation is not sufficiently robust to confirm that the mechanisms identified by the theory are the ones driving results in practice."}, "questions": {"value": "- There is an inherent balance/tradeoff between optimal strategy vs model collapse mitigation. Could the authors further clarify the contradictory observation between Theorem 2(b) and Fig.3 ? To be more specific, does the optimal strategy shift from Keeping easy back to Keeping Hard when moving from label-agnostic curation to label-aware curation? Maybe an equivalent Theorem 2 for label-aware setting could help.\n\n- An important practical consideration is to identify which of the four regimes in Fig. 1 is one operating in. Practically where ground truth is scarse and strength of model is difficult to estimate, how would the paper suggest reliably diagnose this? I guess there needs to be a detector for this crossover point when KH > KE?\n\n- The RMT analysis relies on linear models, while experiments elude to ImageNet teasing the qualitative transfer, but the theoretical boundaries remain tied. Can the paper describe the mechanisms they believe enable this transfer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7rKg8moJNA", "forum": "8KcjEygedc", "replyto": "8KcjEygedc", "signatures": ["ICLR.cc/2026/Conference/Submission22045/Reviewer_UCRG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22045/Reviewer_UCRG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762038804114, "cdate": 1762038804114, "tmdate": 1762942032126, "mdate": 1762942032126, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response to All Reviewers."}, "comment": {"value": "We thank the reviewers for their useful insights. Below, we address the questions of each reviewer. We have also made minor changes to the manuscript (highlighted in magenta color)."}}, "id": "ECaEsp0ci9", "forum": "8KcjEygedc", "replyto": "8KcjEygedc", "signatures": ["ICLR.cc/2026/Conference/Submission22045/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22045/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22045/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763699746279, "cdate": 1763699746279, "tmdate": 1763699746279, "mdate": 1763699746279, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}