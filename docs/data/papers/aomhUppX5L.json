{"id": "aomhUppX5L", "number": 14271, "cdate": 1758231719537, "mdate": 1759897379734, "content": {"title": "On the Dynamics of Learning Linear Functions with Neural Networks", "abstract": "This paper studies the gradient descent training dynamics of fitting a one-hidden-layer network with multi-dimensional outputs to linear target functions. That is, we focus on a realizable model where the inputs are drawn i.i.d. from a Gaussian distribution and the labels are generated according to a planted linear model with multiple outputs. This framework serves as a good model for a variety of interesting problems including end-to-end training in inverse problems and various auto-encoder models in machine learning. Despite the seemingly simple formulation, understanding training dynamics is a challenging unresolved problem. This is in part due to the fact that the training landscape contains multiple non-strict saddle points and it is completely unclear why gradient descent from random initialization is able to escape such bad stationary points. In this work, we develop the first comprehensive analysis of the gradient descent dynamics for learning linear target functions with ReLU networks. We show that gradient descent with moderately small random initialization converges to a global minimizer at a linear rate. To rigorously show that GD avoids non-strict saddle points, we develop intricate techniques to decompose the loss and control the GD trajectory, which may have broader implications for the analysis of non-convex optimization problems involving non-strict saddles. We corroborate our theoretical results with extensive experiments with various configurations.", "tldr": "", "keywords": ["non-convex optimization", "feature learning", "global convergence", "relu networks"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/12aa539667b410c568dc826364c375f5d43250f0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper is concerned with studying gradient descent on one-hidden layer ReLU networks, to learn linear functions.  The inputs are normally distributed, and the loss is mean square.  There are two main theoretical results, in both of which: the output dimension is 1; the width of the network is 2; the output layer is fixed, i.e., only the hidden layer is trained; and convergence to a global optimum with a linear rate is shown.  The two results differ in that the first is for population loss, and the second for empirical loss and also shows that a linear number of samples in the input dimension suffices.  The paper aso reports several experiments in similar or slightly extended settings compared to the two theoretical results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is generally well written.  The statements of the theoretical results and their discussion are clear.  The settings of the experiments are also clearly conveyed, and the plots are not difficult to understand."}, "weaknesses": {"value": "The theoretical results are very restricted.  Learning a linear function by a width-2 one-hidden layer ReLU network does not seem substantially different from learning a single ReLU neuron by a single two-layer ReLU neuron.  In addition, only the hidden layer is trained, which substantially simplifies the dynamics.  And moreover, the gradient descent considered in the paper is non-standard due to the modification of multiplying by the reciprocal squares of the fixed output weights.\n\nMost of the papers discussed as related work are several years old.  Also many relevant works are omitted, such as:\n- Yehudai and Shamir \"Learning a Single Neuron with Gradient Methods\" COLT 2020;\n- Vardi, Yehudai, and Shamir \"Learning a Single Neuron with Bias Using Gradient Descent\" NeurIPS 2021;\n- Chistikov, Englert, and Lazic \"Learning a Neuron by a Shallow ReLU Network: Dynamics and Implicit Bias for Correlated Inputs\" NeurIPS 2023;\n- Zhu, Liu, and Cevher \"How Gradient descent balances features: A dynamical analysis for two-layer neural networks\" ICLR 2025;\n- Boursier and Flammarion \"Simplicity bias and optimization threshold in two-layer ReLU networks\" ICML 2025.\n\nI also remark some typos etc.\n- Grammatically correct is \"optimum\" for singluar and \"optima\" for plural.\n- In the third last line of Theorem 1, $v_1$ and $v_2$ should not be bold.\n- In section 4.1, there is a reference to Figure 1 (right), however Figure 1 has parts (a), (b), and (c)."}, "questions": {"value": "I do now see how the middle sentence in the paragraph after Theorem 1 shows that \"two hidden nodes are necessary\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ETBNu1OfJb", "forum": "aomhUppX5L", "replyto": "aomhUppX5L", "signatures": ["ICLR.cc/2026/Conference/Submission14271/Reviewer_57Ps"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14271/Reviewer_57Ps"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14271/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760644948508, "cdate": 1760644948508, "tmdate": 1762924724006, "mdate": 1762924724006, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work studies the learning of a linear teacher by a one hidden layer ReLU network, with exact parametrization (ie 2 neurons in the theoretically studied case of univariate output). For this problem, the authors show that both population GD and GD (with $n\\gtrsim d$) with empirical data recovers the teacher function."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The question of whether a one hidden layer ReLU network can learn a linear teacher remains an open question from a general aspect. The authors provide a nice answer to this question in the case of exact parametrization and no label noise, by giving a nice characterization of the training dynamics."}, "weaknesses": {"value": "My main concern about this work is its relation with the existing literature and how novel it is. In particular, the authors omit to mention the papers [1] and [2] which characterize the training dynamics of a two neurons two layer network when the teacher is itself a two neuron ReLU network. Since a linear function can be seen as the difference of two ReLUs, these two papers clearly fit the scope of learning a linear teacher. In consequence, they deserve to be mentioned, but also to be discussed in detail.\n\nEven if the results of [1] and [2] might not be applied directly to the linear case, I believe that the proof techniques are very similar. In consequence, the authors would also need to discuss to what extent their proof techniques are new and what are the major challenges that were not addressed in previous works. \n\nMy other concern is about the limited aspect of the problem. The authors consider strong assumptions that strongly simplify the analysis (and even denature the final message) : no label noise, exact parametrization, fixed second layer and $r=1$. In particular, the no label noise assumption allows a perfect recovery of the teacher possible even in the presence of a finite number of data points, which would clearly not be possible with label noise. In consequence, I find the abstract/introduction particularly overstating.\n\n-----------------\n# Minor remarks\n- [3] also studied how a two layer ReLU newtork can learn from a linear teacher. Although their exact setting and analysis is somehow different, I think it deserves to be cited.\n- Figures 1. (a) and (b) are not very clear. The axes are not labeled\n- the multiplication by $\\text{diag}(v)^-2$ in the GD step makes me think of the Hessian preconditioning. Is there any relation to it?\n- I disagree that this work can be seen as a generalization of Xu and Du (2023) (line 413). Their paper precisely aims at studying the overparameterized case, not the exactly parameterized one\n- line 405: you mention local optima, but in the problem here, it seems there is no suboptimal local optima, only saddle points\n\n\n----------\n# References\n[1] Zhong, Kai, et al. \"Recovery guarantees for one-hidden-layer neural networks.\" International conference on machine learning. PMLR, 2017.\n\n[2] Zhang, Xiao, et al. \"Learning one-hidden-layer relu networks via gradient descent.\" The 22nd international conference on artificial intelligence and statistics. PMLR, 2019.\n\n[3] Boursier, Etienne, and Nicolas Flammarion. \"Simplicity Bias and Optimization Threshold in Two-Layer ReLU Networks.\" Forty-second International Conference on Machine Learning, 2025."}, "questions": {"value": "How novel are your result and analysis wrt [1] and [2] ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MenzFjP3kF", "forum": "aomhUppX5L", "replyto": "aomhUppX5L", "signatures": ["ICLR.cc/2026/Conference/Submission14271/Reviewer_pG4V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14271/Reviewer_pG4V"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14271/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761218057318, "cdate": 1761218057318, "tmdate": 1762924723633, "mdate": 1762924723633, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the dynamics of the generalization error resulting from learning a linear function using a one-hidden layer neural network with two neurons and ReLU activation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an important question by studying how the generalization error evolves with the number of steps for two-layer neural networks."}, "weaknesses": {"value": "The setting appears too restrictive. First of all, if the target function is linear, does it even make sense to learn it using a neural network. Second, usually the width of the hidden layer is comparable with the input dimension, while in this case the hidden width is 2. Third, the last layer is not trainable and is just frozen instead. I would suggest adding much more motivation to explain why this setting is interesting."}, "questions": {"value": "1) What is the justification for considering the setting presented in the paper?\n2) What are the assumptions regarding c_7 in Theorem 2 and how does it depend on the other parameters from the statement? I find it counterintuitive that the generalization error would converge towards 0 for **any** c_7 without extra quantitative assumptions. \n3)  Can one generalize the results to an arbitrary number of neurons and / or more general activation functions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GNDoWMtcCT", "forum": "aomhUppX5L", "replyto": "aomhUppX5L", "signatures": ["ICLR.cc/2026/Conference/Submission14271/Reviewer_s1xV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14271/Reviewer_s1xV"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14271/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761740128008, "cdate": 1761740128008, "tmdate": 1762924723167, "mdate": 1762924723167, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes gradient-descent (GD) training dynamics of one-hidden-layer ReLU networks when the ground-truth mapping is linear. The authors mainly focus on the one dimensional case where the ground truth is a single vector and identify the existence of saddle points in this regime. They prove global convergence of GD for the small initialization and extend the result from population loss to empirical loss. Experiments are conducted to demonstrate the problem’s optimization landscape. They also briefly discuss the multi-dimensional output case in the appendix."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper proves global convergence of two layer ReLU networks for learning linear mappings. It also discusses how GD avoids saddle points along the optimization trajectory.  \n2. Extensive experiments are conducted on the optimization landscape. The observed pairing behaviour in the multi-dimensional setting might be helpful for understanding feature learning of neural networks."}, "weaknesses": {"value": "The main result considers learning a single linear vector as the teacher, which is overly simple. The single neuron learning problem is extensively studied in previous literature (e.g., see \\[1\\], \\[2\\]). Although these results cannot be directly transferred to the linear teacher setting, I believe a widely-used early-alignment technique (e.g., see \\[3\\], \\[4\\]) can still be applied. When initialization is small, the gradient (equation (8)) is almost parallel with the ground truth, forcing students to align with the teacher and converge globally. Therefore, the analysis techniques used in the paper seem not very novel to me. That being said, I am happy to change my mind if I missed anything.\n\nReferences:\n\n1. Yehudai, Gilad and Ohad Shamir. “Learning a Single Neuron with Gradient Methods.” ArXiv abs/2001.05205 (2020): n. Pag.  \n2. Wu, Chenwei, Jiajun Luo, and Jason D. Lee. \"No spurious local minima in a two hidden unit relu network.\" (2018).  \n3. Soltanolkotabi, Mahdi. \"Learning relus via gradient descent.\" Advances in neural information processing systems 30 (2017).  \n4. Brutzkus, Alon, and Amir Globerson. \"Globally optimal gradient descent for a convnet with gaussian inputs.\" International conference on machine learning. PMLR, 2017\\."}, "questions": {"value": "The multi-dimensional case in Appendix B seems interesting, but the assumption on initialization is restricted. What is the initialization scheme used in Theorem 6? Can a convergence proof be constructed for the random initialization setting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4z5tCAVuSr", "forum": "aomhUppX5L", "replyto": "aomhUppX5L", "signatures": ["ICLR.cc/2026/Conference/Submission14271/Reviewer_wEhk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14271/Reviewer_wEhk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14271/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762069107085, "cdate": 1762069107085, "tmdate": 1762924722845, "mdate": 1762924722845, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper analyzes the gradient descent dynamics of training a single-hidden-layer ReLU network to fit linear target functions under Gaussian inputs. Despite the simplicity of the setup, the optimization landscape includes numerous non-strict saddle points, making convergence uncertain. Under this setting, the authors prove that gradient descent with small random initialization converges with a linear rate to the global minimum in two cases: population and empirical loss. Under the empirical loss, they recover the optimal sample complexity. The theoretical findings are supported by experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper studies an interesting question of learning a simple function by a complex model that is over-expressive. This scenario arises, for example, in training autoencoders, where the end-to-end scheme should implement the identity transform. In such cases, the natural question is whether the learning algorithm can recover the simple function that we are after."}, "weaknesses": {"value": "Under the setting considered in the paper, there is only one minimum, which corresponds to the underlying (ground truth) linear transform. Many works in the past showed that GD can minimize the loss while training neural networks, e.g., [R1]. So, it is not surprising that it happens here as well.\n\nMoreover, the particular setting studied in the paper does not match the practice. For example:\n1. Only the weights of the first layer are optimized.\n2. The paper considers a preconditioner that uses the weights of the second layer as normalization.\n3. The width of the hidden layer is exactly two\n\nFinally, the two settings considered in the paper, empirical and population loss, don't add much more information and look repetitive to me (even though the proof technique is different, and we also get the sample complexity in the empirical setting).\n\n**References**:\n[R1] - Gradient Descent Finds Global Minima of Deep Neural Networks"}, "questions": {"value": "1. Could we derive **similar** results from prior work? For example, using the same architecture but with SiLU activation and applying [R1].\n2. Can we extend the analysis to fully connected layers with bias?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MQuTDQAbU6", "forum": "aomhUppX5L", "replyto": "aomhUppX5L", "signatures": ["ICLR.cc/2026/Conference/Submission14271/Reviewer_QmsM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14271/Reviewer_QmsM"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission14271/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762812451209, "cdate": 1762812451209, "tmdate": 1762924722479, "mdate": 1762924722479, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}