{"id": "U4LVqUIXlh", "number": 22644, "cdate": 1758333884067, "mdate": 1759896855094, "content": {"title": "FedSal: Enhancing Federated Graph Classification Through Saliency Aware Client Clustering", "abstract": "Graph Neural Networks (GNNs) are essential for analyzing structured data but face significant challenges in federated learning (FL) environments, where non-IID client distributions and structural heterogeneity impede convergence and performance. To address these issues, we introduce Federated Saliency Aggregation Learning (FedSal), the first framework to apply saliency maps in GNN-based FL on graph classification tasks. FedSal replaces full-gradient uploads with compact saliency activations, enabling dynamic clustering of clients via simple thresholds (\\(\\epsilon_{\\mathrm{mean}}, \\epsilon_{\\max}\\)) and cluster-wise model averaging. We further propose FedSal+, which augments node features with positional and random-walk encodings to inject structural priors without exposing raw graph data. Extensive experiments on thirteen molecular, protein, and social-network benchmarks under extreme non-IID splits show that FedSal and FedSal+ achieve higher accuracy, converge faster, and reduce communication cost compared to state-of-the-art methods. These results demonstrate the SOTA performance of saliency-driven clustering for personalized, robust, and communication-efficient federated graph classification tasks.", "tldr": "ChatGPT said:  FedSal is the first federated GNN using client-side saliency maps for adaptive clustering under severe non-IID heterogeneity. In experiments it consistently outperforms SOTA FedGNN baselines in graph classification.", "keywords": ["Federated Learning", "Graph Neural Network", "Saliency Maps", "Federated Graph Neural networks"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/772154c915acd3add265efbe55779f35cd81ebac.pdf", "supplementary_material": "/attachment/b1484c276fbb0c2eeabc3c82fc9dbacf5889b2b8.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a federated learning model that exploits saliency maps/scores for client clustering and aggregation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper uses saliency maps to perform clustering of clients in a federated learning setting before applying the standard FedAvg method in each cluster. The use of saliency maps seems to be novel in the context of federated learning."}, "weaknesses": {"value": "1. The novelty of the work mainly lies in the use of saliency maps, which is a common concept from various branches of machine learning like computer vision. The definition of this important saliency map is also unclear.\n\n1. The assumptions required for the theoretical results to hold are very limiting.\n\n1. Baseline benchmarks are not up to date."}, "questions": {"value": "1. It is unclear why the proposed approach is restricted to graph federated learning when the approach does not actually utilize anything specific to graphs, except for FedSal+, which integrates features from FedStar. It is curious why the authors chose to position the paper on federated graph learning.\n\n1. Assumptions made for the theoretical results should be stated upfront and discussed. At the minimum, readers should have been alerted to these instead of having to find out from the appendix that the results are actually extremely limited. For example, the requirement that the feature matrix has full column rank makes the results impractical. In small graphs, this is automatically not satisfied. In big graphs with feature dimensions smaller than the number of nodes, it is not obvious we will have full column rank. Numerical evidence based on common graph datasets can be provided to check this.\n\n1. I am unclear why Prop. 3 implies that FedSal can capture task heterogeneity when it says the differences between saliency maps are bounded. Don't we want the saliency maps to be very different if the tasks are different? Won't similar saliency maps lead to wrong clustering?\n\n1. To compute the saliency value in Section 2.1.3, is there an implicit assumption that the loss is differentiable w.r.t. the sample value $x$ and $x$ is a continuous variable? How do you deal with the case where $x$ has categorical components? Furthermore, it is unclear how this saliency can be computed easily. The formula as written is not explained properly: does $|\\cdot |$ denote determinant or elementwise absolute value?\n\n1. Does the feature $x$ have to be the same dimensions for all clients? If so, does this not mean that local client models have the same architecture?\n\n1. The comparison is missing many important baselines like FedPer, pFedGraph, FedSheafHN, Flow, HeteroFL, FedRolex, etc."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ONZVPwaibl", "forum": "U4LVqUIXlh", "replyto": "U4LVqUIXlh", "signatures": ["ICLR.cc/2026/Conference/Submission22644/Reviewer_zjh8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22644/Reviewer_zjh8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760597134544, "cdate": 1760597134544, "tmdate": 1762942317328, "mdate": 1762942317328, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FedSal (Federated Saliency Aggregation Learning), a GNN-based federated learning framework designed to mitigate performance degradation under non-IID and structurally heterogeneous conditions. FedSal replaces full gradient uploads with saliency maps, and employs two thresholds (ϵ_mean, ϵ_max) to trigger dynamic client clustering and intra-cluster aggregation. An extended version, FedSal+, further incorporates positional and random-walk encodings to inject structural priors. Experiments on thirteen molecular, protein, and social-network datasets show that FedSal/FedSal+ achieve smoother convergence and an average accuracy improvement of about +1.5-2.0pp under extreme non-IID settings, though the overall gain is limited."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel concept: Introduces saliency maps into federated graph learning and proposes a threshold-triggered dynamic clustering mechanism.\n\n2. Broad experimental coverage: Evaluated on thirteen diverse datasets and compared against multiple strong baselines.\n\n3. Stable performance under non-IID conditions: Shows smoother and faster convergence trends when data heterogeneity is high."}, "weaknesses": {"value": "1. The average gain (+1.5–2.0pp) is small and comparable to the reported standard deviation. Only accuracy (ACC) and communication time are reported; lacks F1, AUC, or Recall for a more comprehensive evaluation.\n\n2. The paper does not provide any time or space complexity for the main procedures, including similarity graph construction, Stoer–Wagner min-cut, and recursive clustering."}, "questions": {"value": "1. Could the authors provide a theoretical convergence analysis or at least an empirical justification of the claimed “faster and smoother convergence”?\n\n2. What is the computational complexity of the clustering and aggregation process as a function of client number and feature dimension?\n\n3. Have the authors considered adding statistical significance tests (e.g., t-test) to verify whether the observed accuracy gains are meaningful?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2ky9lCfpCz", "forum": "U4LVqUIXlh", "replyto": "U4LVqUIXlh", "signatures": ["ICLR.cc/2026/Conference/Submission22644/Reviewer_xEN8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22644/Reviewer_xEN8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761536081163, "cdate": 1761536081163, "tmdate": 1762942317086, "mdate": 1762942317086, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FedSal, a novel framework that uses saliency maps to cluster clients in Federated Graph Neural Networks (FedGNNs), addressing non-IID data challenges that cause instability and slow convergence in federated learning. Evaluated on 13 graph classification tasks (molecular, protein, and social networks), FedSal and its enhanced version outperform state-of-the-art methods in accuracy, convergence speed, and communication efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Using saliency maps for clustering in FedGNNs is a novel approach that enhances interpretability and robustness. The framework effectively tackles non-IID data challenges, improving model convergence."}, "weaknesses": {"value": "1.FedSal reduces communication costs versus some SOTA methods but has higher latency than simpler approaches like FedAvg.\n2.Experiments focus on classification; generalization to other graph tasks (e.g., regression, link prediction) is unexplored.\n3.Dynamic clustering requires careful tuning of thresholds (ϵ-mean, ϵ-max), posing a barrier for users lacking parameter-tuning expertise."}, "questions": {"value": "1. How does the framework performs in large-scale, real-world deployments, considering real-time adaptation of the model to constantly changing client data distributions?\n2. How does the framework address potential privacy issues in detail, even though it deals with federated learning, which is often implemented in privacy-sensitive environments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iWYRXUhL3Z", "forum": "U4LVqUIXlh", "replyto": "U4LVqUIXlh", "signatures": ["ICLR.cc/2026/Conference/Submission22644/Reviewer_4TUg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22644/Reviewer_4TUg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761914461445, "cdate": 1761914461445, "tmdate": 1762942316799, "mdate": 1762942316799, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript proposes FedSal and FedSal+, two novel federated graph neural network frameworks that leverage saliency activation maps for client clustering to address non-IID data distribution and structural heterogeneity challenges in federated graph learning. The work is well-motivated, with rigorous theoretical analysis, comprehensive experiments across 13 benchmarks, and clear articulation of technical innovations. The proposed methods demonstrate superior performance in accuracy, convergence speed, and communication efficiency compared to state-of-the-art baselines, making a valuable contribution to the federated graph learning field."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The use of saliency activation maps (instead of raw gradients) for client clustering is a novel and effective design. Saliency maps capture feature importance for predictions, providing more stable and representative client summaries than noisy raw gradients, which directly mitigates the impact of non-IID data and structural heterogeneity. \n2. Extensive experiments not only compare accuracy but also analyze communication overhead and convergence speed, providing a holistic assessment of the proposed methods’ performance. Ablation studies further validate the necessity of saliency maps and dynamic clustering.\n3. The manuscript provides solid theoretical support, including proofs for the structural, feature, and task sensitivity of saliency maps, ensuring the method’s theoretical soundness. Additionally, FedSal+ extends the core framework with positional and random-walk encodings, demonstrating the flexibility and scalability of the proposed architecture to integrate structural priors without exposing raw data."}, "weaknesses": {"value": "1. The manuscript mentions aggregating per-sample saliency maps for each client but does not explicitly clarify how saliency is computed for graph-structured data (e.g., node-level vs. graph-level saliency aggregation, handling of edge features). More details on this implementation would improve reproducibility.\n2. The baselines in this manuscript are mainly from 2024 or earlier. I am not very familiar with this field, but I believe that new baselines have likely been proposed in 2025. The authors should include comparisons with these recent methods to demonstrate that their approach remains state-of-the-art.\n3. While the hyperparameter study ($ϵ_{mean}$, $ϵ_{max}$) shows optimal mid-range values, the analysis is limited to specific datasets. It would be valuable to discuss how these thresholds generalize across different graph types (e.g., sparse vs. dense graphs) or provide adaptive tuning strategies for real-world applications."}, "questions": {"value": "Note: Here are some questions I have after reading the manuscript. Since I am not very familiar with this field, the authors may choose to answer selectively, focusing on issues related to the manuscript's contributions. I will also take into account comments from other reviewers when forming my final rating.\n\n1. For graph-level classification tasks, how is the per-sample saliency map aggregated to form the client-level saliency summary? Is there a weighting mechanism for different graphs (e.g., based on graph size or classification confidence)?\n\n2. The manuscript mentions that FedSal+ injects structural priors via positional and random-walk encodings. How do these encodings interact with the original node features, and is there any redundancy or interference between them? Could the authors provide quantitative analysis of this interaction?\n\n3. In the multi-dataset setting, how does FedSal handle domain shifts between different types of graphs (e.g., molecular vs. social network graphs)? Does the clustering mechanism automatically separate domain-specific clients, and if so, how is this verified?\n\n4. For minority-label clients, the manuscript states that the adaptive protocol provides significant benefits. Could the authors elaborate on how the clustering thresholds (ϵmean, ϵmax) specifically protect minority clients from being marginalized in the aggregation process?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QvOHWPZqkP", "forum": "U4LVqUIXlh", "replyto": "U4LVqUIXlh", "signatures": ["ICLR.cc/2026/Conference/Submission22644/Reviewer_QTnp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22644/Reviewer_QTnp"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22644/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927088714, "cdate": 1761927088714, "tmdate": 1762942316643, "mdate": 1762942316643, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}