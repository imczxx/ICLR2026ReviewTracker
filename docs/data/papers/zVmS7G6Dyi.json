{"id": "zVmS7G6Dyi", "number": 20709, "cdate": 1758309239345, "mdate": 1759896962590, "content": {"title": "Generalization Below the Edge of Stability: The Role of Data Geometry", "abstract": "Understanding generalization in overparameterized neural networks hinges on the interplay between the data geometry, neural architecture, and training dynamics. In this paper, we theoretically explore how data geometry controls this implicit bias. This paper presents theoretical results for overparametrized two-layer ReLU networks trained *below the edge of stability*. First, for data distributions supported on a mixture of low-dimensional balls, we derive generalization bounds that provably adapt to the intrinsic dimension. Second, for a family of isotropic distributions that vary in how strongly probability mass concentrates toward the unit sphere, we derive a spectrum of bounds showing that rates deteriorate as the mass concentrates toward the sphere. These results instantiate a unifying principle: When the data is harder to “shatter” with respect to the activation thresholds of the ReLU neurons, gradient descent tends to learn representations that capture shared patterns and thus finds solutions that generalize well. On the other hand, for data that is easily shattered (e.g., data supported on the sphere) gradient descent favors memorization. Our theoretical results consolidate disparate empirical findings that have appeared in the literature.", "tldr": "", "keywords": ["neural networks", "deep learning theory", "gradient descent", "representation learning", "generalization"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fe17715885f6253040e49dcb03012c71718b0436.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel prospective on how data geometry influences the implicit bias of overparameterized two-layer ReLU networks, with a number of theoretical results demonstrating that solutions below the edge of stability have various generalizability properties that can be desirable or undesirable depending on the setting. They provably show that below the edge of stability solutions can adapt to intrinsic lower dimension subspaces within an ambient space and that a spectrum of generalizability occurs determined by the implicit regularization induced by the \"shatterability\" of the data. Further empirical results are given to validate their theoretical claims and proof techniques."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides a novel perspective on how the final solutions of the edge of the stability regime will generalize, while avoiding the dynamics of the rich regime. This formulation allows for intriguing new insights into how the structure of the data affects the implicit bias within the training of these models.\n- This work has interesting implications for a number of different areas as outlined in appendix B and helps foster further work into the emerging direction of data shatterability.\n- The empirical results are presented nicely with subsection 4.2 adding substantive support to practically verifying the effect of theorems on the form of the representations learnt in two-layer ReLU networks.\n- The discussion and further work section is well written and suggests good follow-up directions on the topic."}, "weaknesses": {"value": "- Data shatterability is not concretely defined or explained as a concept in the paper. While it can be roughly gleaned from previous work, a clear and concrete definition or explanation of the concept within the paper would substantially improve it.\n- Definition 2.1 claims to be for \"Isotropic Beta-radial distributions\" but then proceeds to define \"Isotropic alpha-powered distributions\". It is unclear what isotropic beta-radial distributions are in this work as I do not believe they are defined.\n- The theoretical claims are stated, but not much intuition or interpretation is given other than the overall message stated in the abstract and the introduction. A more fleshed out narrative and explanation between the theorems would have helped a deeper understanding of the work presented.\n- The empirical results in subsection 4.1 could be improved by giving a more complete explanation of how to interpret them.\n- For the right panel in figure 3 it is unclear why the correlation coefficient is given when the magnitude of the coefficient is so small. Additionally, the current figure provides no sense of how many of the points are in the bottom left corner.\n- There are some linguistic issues such as: the first sentence in the \"Disclaimers and Limitations\" does not make sense, \"deffered\" on page 4."}, "questions": {"value": "- Is it possible to run experiments on other architectures ideally to hypothesise how one could extend these results beyond the two-layer ReLU networks?\n- Could further experiments be conducted to help elucidate the potential benefit of batch normalization through data shatterability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "99RofwdCId", "forum": "zVmS7G6Dyi", "replyto": "zVmS7G6Dyi", "signatures": ["ICLR.cc/2026/Conference/Submission20709/Reviewer_9RWh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20709/Reviewer_9RWh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760979342903, "cdate": 1760979342903, "tmdate": 1762934100284, "mdate": 1762934100284, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies how data geometry (especially intrinsic dimension and shatterablity) determines generalization under the edge of stability implicit bias.\nThe paper shows that (1) for features from mixtures of low-dimensional balls, such bias provably drives two-layer ReLU networks's generalization to be controlled by the intrinsic instead of the ambient dimension; (2) for isotropic data, its concentration toward boundary / shatterablity controls the generalization.\nSuch theoretical predictions are verified by experiments. \nIn a finer-grained level, in both proofs and empirical results, the implicit path norm regularization induced by EoS mainly regularizes the harder-to-shatter samples, improving generalization on them, and ignores the easier-to-shatter samples. As a result, data geometry of less shatterablity improves generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper proves the adaptation of low-dimensionality and the spectrum of generalization wrt to data concentration under EoS implicit bias. The latter is also equipped with a lower-bound to show tightness.\n- The results are verified by empirical results.\n- The sketch of proof is clearly discussed. Combined with the empirical results, it also clarifies on finer-grained roles of EoS implicit regularization and clarifies why and how data geometry affects controls generalization under EoS. Such results emphasize the data-dependent nature of EoS regularization and provides explanations on the highly data-dependent behaviour of overparameterized neural networks.\n- The two main theoretical results and empirical results point to a promising shatterablity principle."}, "weaknesses": {"value": "- In Sec 4.1, the experiments use label noise instead of I.I.D. sampling to construct training set and measures MSE losses instead of difference between the empirical and population risks. Such choice makes it more difficult to compare with theoretical results. What is the motivation for such choices?\n- Minor:\n  - Line 289: \"g is the population version of the *weighted*.\""}, "questions": {"value": "- In Figure 1a, the slope of theoretical prediction is not marked and compared to the actual slope. They seem to be actual≈-0.9 vs theoretical=-1/6, where a gap is still observed. What is the source of this gap? Does it come from looseness of bounds or that the experimented problem is not the worst case to reach the upperbound (eg, the directions of the $J$ lines are not worst-case)? Or is it beyond the (B)EoS bias, similar to Sec 3.3, and is governed by some bias else? Can this question be answered by some experiments, eg, searching the worst BEoS models and comparing their slopes with the actual and the theoretical? Maybe this question demands too much efforts. But I would greatly appreciate it because it may offer a clear view on the limit as well as relation of EoS biases with other biases.\n- The discussion in Sec 4.3 seems quite generic. Is it possible to develop more general generalization bounds for BEoS weights assuming shatterablity instead of specific assumptions like low-dimensionality that leads shatterablity."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dDY6qpP9TU", "forum": "zVmS7G6Dyi", "replyto": "zVmS7G6Dyi", "signatures": ["ICLR.cc/2026/Conference/Submission20709/Reviewer_M57z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20709/Reviewer_M57z"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761594784427, "cdate": 1761594784427, "tmdate": 1762952249939, "mdate": 1762952249939, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the role of data geometry in shaping the generalization behavior of overparameterized two-layer ReLU networks trained below the edge of stability (BEoS). Building on recent studies on the implicit bias of gradient descent, the authors propose a unifying principle termed data shatterability, which measures how easily data geometry allows ReLU thresholds to separate samples. The main theoretical contributions include:\n(1) A generalization bound for data supported on a mixture of low-dimensional subspaces, showing adaptation to the intrinsic dimension (Theorem 3.2);\n(2) A family of generalization bounds for isotropic distributions parameterized by a concentration parameter α (Theorem 3.5), together with lower bounds (Theorem 3.6) and a constructive example demonstrating perfect interpolation on the sphere (Theorem 3.7).\nEmpirical experiments on synthetic data and MNIST illustrate how data geometry affects generalization and representation structure."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation is clear and well-grounded in contemporary discussions around implicit regularization and the edge-of-stability regime.\n2. The notion of data shatterability offers an elegant conceptual synthesis that connects data geometry, implicit bias, and generalization."}, "weaknesses": {"value": "1. Definition and formalization of “data shatterability.”\nWhile the paper emphasizes shatterability as the central concept, it is not clearly or formally defined in a mathematical sense. The text gives intuitive descriptions (“harder to shatter data generalizes better”), but the precise operational definition is vague. \n\n  (1) Can the authors introduce a rigorous definition or metric of shatterability, perhaps analogous to VC dimension or some geometric measure of separability?\n\n  (2) Why do the authors choose the beta-radial distributions with a parameter $\\alpha$ to characterize this data property?\n\n  (3) There is a gap between the rates in Theorem 3.5 and 3.6. How are they related to the general claim?\n\n  (4) Would a toy mode concretely showing how different data geometries affect generalization make the concept more intuitive?\n\n2. Clarity and logical structure of results.\nThe theoretical results (Theorems 3.2–3.7) are presented in isolation, and their interconnections are not fully clear. The reader may struggle to see how they jointly establish a unified principle.\n\n(1) How do the results for subspace mixtures and isotropic distributions fit into a single theoretical framework?\n\n(2) Is there an overarching theorem or lemma that ties them together through the concept of shatterability?\n\n(3) A high-level diagram or summary of theoretical dependencies would help to improve readability and logical coherence.\n\n3. Lack of dynamics analysis.\nThe paper claims to study generalization “below the edge of stability,” yet the analysis focuses entirely on static properties of stable minima rather than on the gradient descent dynamics that give rise to them.\n\n(1) Without examining the time evolution of GD (e.g., curvature oscillations, stability trajectories), the results seem closer to a stability condition rather than a genuine characterization of the EoS regime.\n\n(2) The current framework could be better described as a stability-based generalization bound rather than an analysis of edge-of-stability generalization.\n\n4. Relation to prior work.\nTheorems 3.2 and 3.5 resemble results in [Wu & Su, 2023] and related stability-based analyses, with the main difference being the explicit dependence on data geometry. However, the paper does not clearly articulate the essential technical innovation over these works.\n\n(1) What are the key mathematical difficulties introduced by considering non-isotropic or low-dimensional data distributions, and how are they overcome here?\n\n(2) A more explicit comparison or ablation (possibly in the appendix) would strengthen the contribution."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0FO6yIMdTr", "forum": "zVmS7G6Dyi", "replyto": "zVmS7G6Dyi", "signatures": ["ICLR.cc/2026/Conference/Submission20709/Reviewer_PDwN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20709/Reviewer_PDwN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933873760, "cdate": 1761933873760, "tmdate": 1762934098003, "mdate": 1762934098003, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work studies the interaction between data geometry and the implicit bias of edge of stability.\nIt shows that EoS bias can drive two-layer ReLU networks to adapt low-dimensionality for mixture of low-dim balls data, and that for isotropic data, its shatterablity determines generalization.\nExperiments verify the theoretical predictions.\nThis work then proposes the principle of shatterablity, where the shatterable data points attract specialized neurons, which are less regularized by the implicit weighted path norm in below the edge of stability."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Based on the algorithmic bias of EoS, this work provides the data dependence aspect of neural network generalization, a valuable problem in modern data- and algorithm-dependent theory for generalization. \n- The work picks two representative examples of interest, where the first one is related to how neural network overcomes curse of dimensionality and the second one novelly reveals the role of shatterablity. The results are verified by empirical results. \n- This work also reveals that under EoS regularization, the network may still overfits, and it is data geometry with low shatterablity that helps resisting overfitting. \n- This work provides principled lens for studying feature learning and data geometry reflected in it, eg, neuron activation rate that impacts regularization strength of EoS bias and affects generalization."}, "weaknesses": {"value": "- The paper supports the shatterablity principle using two proved cases, followed by intuitive interpolation/extrapolation. However, a formal results is missing, leaving shatterablity relying on intuitive definition and restricting its application to more complicated data. Is it possible to derive formal definition of shatterablity and provide more abstract generalization bounds with shatterablity and BEoS as parameters?      \n- In experiments, the training data is constructed by perturbing the label instead of IID sampling. How does this setting fits into the assumption of theories? Under standard setting, what will be low-dimension adaptation like?"}, "questions": {"value": "- Some works have emphasized the surprising importance of (benign) memorization for generalization, especially under long-tailed data distribution. Then is there any connection from lon-tailedness and memorization to shatterablity and neuron specialization? If so, what benign memorization looks like in the framework of shatterablity? At what threshold does memorization becomes harmful?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7s2ppc1or8", "forum": "zVmS7G6Dyi", "replyto": "zVmS7G6Dyi", "signatures": ["ICLR.cc/2026/Conference/Submission20709/Reviewer_M2En"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20709/Reviewer_M2En"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976261587, "cdate": 1761976261587, "tmdate": 1762934093547, "mdate": 1762934093547, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how the geometry of the training data fundamentally controls the implicit bias of gradient descent (GD) and the resulting generalization performance of overparameterized two-layer ReLU networks trained in the \"Below Edge of Stability\" (BEoS) regime."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The author claims that  \"The less shatterable the data geometry, the stronger the implicit regularization of EoS becomes.\" and illustrates this observation via two specific example.\n\nI thought this is a very interesting result and made a serious try to understand the performance neural network comparing with other \"not even wrong\" work."}, "weaknesses": {"value": "I have not checked the whole proof. The results sound reasonable to me. However, to broad its impacts, it would be more beneficial if the author could make more implications of their theoretical results. e.g., its connection with some exiting theories?  Moreover, the rates stated in theorems are more less to technical,  could the authors  make it more comparable with some existing results?"}, "questions": {"value": "Same to the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mRUf0Xaqk5", "forum": "zVmS7G6Dyi", "replyto": "zVmS7G6Dyi", "signatures": ["ICLR.cc/2026/Conference/Submission20709/Reviewer_h9Wg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20709/Reviewer_h9Wg"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission20709/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761989270149, "cdate": 1761989270149, "tmdate": 1762934092229, "mdate": 1762934092229, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}