{"id": "j3htU5i01r", "number": 7763, "cdate": 1758035239697, "mdate": 1763658603492, "content": {"title": "Compositional meta-learning through probabilistic task inference", "abstract": "To solve a new task from minimal experience, it is essential to effectively reuse knowledge from previous tasks, a problem known as meta-learning. Compositional solutions, where common elements of computation are flexibly recombined into new configurations, are particularly well-suited for meta-learning. Here, we propose a compositional meta-learning model that explicitly represents tasks as structured combinations of reusable computations. We achieve this by learning a generative model that captures the underlying components and their statistics shared across a family of tasks. This approach transforms learning a new task into a probabilistic inference problem, which allows for finding solutions without parameter updates through highly constrained hypothesis testing. Our model successfully recovers ground truth components and statistics in rule learning and motor learning tasks. We then demonstrate its ability to quickly infer new solutions from just single examples. Together, our framework joins the expressivity of neural networks with the data-efficiency of probabilistic inference to achieve rapid compositional meta-learning.", "tldr": "We use probabilistic inference in a learned generative model to rapidly compose test task solutions from reusable computations across training tasks", "keywords": ["meta-learning", "composition", "modular", "recurrent", "inference"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8b21cf1646d388c65ef4511f41c416f8bca4da84.pdf", "supplementary_material": "/attachment/d5ed96c8e7d4c2a5df5dd906036a0ea5f059856f.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose to recast meta-learning as a probabilistic inference problem. They develop a RNN model, learning specific “subtasks” or motifs of a master task, acting as a task-solving backbone. In parallel, they implement a gating network that allows to guide information processing in the backbone model and select the appropriate RNN module sequence to solve a given task. At test time, their model can infer the best potential sequence of motifs to execute to solve a novel instance of a given task. They apply their model to (abstract) rule learning and motor learning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is clearly structured and well written.\n\n2. The authors tackle a timely issue for intelligent systems. Proposing novel methods that can improve the ability of AI models to adapt quickly and learn from fewer examples by re-using previous motifs is an interesting, alternative direction to brute force scaling, which has been the leitmotif of bigtechs. I believe more research should go towards this direction."}, "weaknesses": {"value": "Although I am extremely sympathetic with the type of work proposed by the authors, I have three main concerns with the current state of the paper. I will delineate these concerns below not any order of importance: \n\n1. The authors do not properly position their paper, and a comprehensive comparison with previous methods is lacking. In particular, I would greatly encourage the authors to have a look at the following papers: Zhen et al. (2024 - https://www.nature.com/articles/s41467-024-52289-3), Hurtado et al. (2021 - https://proceedings.neurips.cc/paper/2021/file/761e6675f9e54673cc778e7fdb2823d2-Paper.pdf), Hummos (2023 - https://arxiv.org/abs/2205.11713) , and perhaps more crucially Hummos et al. (2024 - https://arxiv.org/pdf/2407.17356). Such papers are extremely closely related to the proposal of the authors, especially the last one, which also proposes to cast meta-learning as a probabilistic inference problem. Moreover, Hummos et al. (2024) provides a much more detailed description of the link between their model and probabilistic inference. In sum, I believe that the current version of the proposed manuscript should substantially improve positioning the paper with respect to previous and related work. \n\n2. The authors assume a certain temporal structure in the tasks, and propose adaptive behavior as recombining “closed” learned motifs in a specific sequential order. Whereas this might make sense in the tasks they propose, the usefulness of compositional learning far extends this setting, and is particularly powerful when you can select which “parts” of these motifs need to be recombined to solve a novel task. For instance, if I learn to play football, I learn to infer that the goal of this sport is to put the ball in the goals. If I learn to play basketball, I learn that I have to play with my hands and put the ball in the net. Now, if I see people playing handball, I can directly infer that the rule is to put the ball in the goals. Here, inferring the goal of handball is not tied to sequentially structuring the motifs of basketball and football, but rather to re-combing parts of these motifs. Such recombinations are tackled in Hummos et al. (2024). In contrast, the authors propose a recombination that has been tackled in previous work (see Logiaco et al., 2021, Cell reports). I do however acknowledge that in this work, the authors do not require task IDs for flexible recombination, similar to Hummos (2023, ICLR).\n\n3. The authors assess their model in simplified “toy” tasks that can hardly convince on the usefulness of this approach at the practical scale. Whereas I typically do not “condemn” papers for using toy tasks, similar approaches have shown value in vision (CIFAR-10) and language (BabyLM challenge) (see Hummos et al., 2024), which sets an expectation over what tasks would (at the very least) be evaluated by such proposals. Indeed, whereas gating mechanisms are useful in these toy settings, they are notoriously hard to scale when backbone models increase in parameter size of architecture complexity."}, "questions": {"value": "1. Can the authors explain how their work differs from that of Hummos et al. (2024)? In particular, highlighting why their proposed method would lead to potentially more robust results in specific tasks? It would be interesting to compare both models, and understand if and in which settings one model would outperform the other.\n\n2. Have the authors tried to apply their model to tasks that could show promise at the practical scale (e.g., language modeling?).\n\n3. The graphs in figure 2 and figure 4, are particularly cryptic. It would be good if some effort is put into unfolding them with more clarity. Could the authors describe the figure with “pointers”  and add the x and y dimension labels when there are none?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "IWZ3zzeZvw", "forum": "j3htU5i01r", "replyto": "j3htU5i01r", "signatures": ["ICLR.cc/2026/Conference/Submission7763/Reviewer_Gbhf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7763/Reviewer_Gbhf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761605911541, "cdate": 1761605911541, "tmdate": 1762919807539, "mdate": 1762919807539, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a new proof of principle for compositional meta-learning through probabilitistic task inference. The underlying design choices are studied and compared to a base architecture."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper actually cites references from before the deep learning revolution which is nice to read for once. \n\nThe paper is well written and easy to read. The proposal seems technically sound. \n\nIn its style it is for sure an unusual paper (which could be something positive or negative)."}, "weaknesses": {"value": "The paper seems to be a very limited proof of concept. While there are claims that other approaches can not solve these tasks e.g. \"This is in stark contrast to traditional meta-learning approaches  ...\" i.e there i no baseline comparison to any other approach. \n\nIt would indeed be nice to see that no other approach is able to solve the tasks beyond just stating it. At least to me that is not obvious. \n\nOr if it is indeed a proof of principle for one model class then at least it should be scaled up. As it is it sounds very narrow in its placement for readership."}, "questions": {"value": "What are the precise claims that other meta learning approaches can not do? Is it accurate posteriors? Is it the tasks? What precisely is impossible to solve with SOTA meta learning approaches? The studied dimension of the examples are not huge, is it a data problem, a zero-shot problem or what precisley is the bottleneck for existing approaches."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "HSlbUsZh3h", "forum": "j3htU5i01r", "replyto": "j3htU5i01r", "signatures": ["ICLR.cc/2026/Conference/Submission7763/Reviewer_hQoD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7763/Reviewer_hQoD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920222904, "cdate": 1761920222904, "tmdate": 1762919807054, "mdate": 1762919807054, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a proof of principle for a novel compositional meta-learning approach that uses a gating mechanism to train, sequentially select and combine different experts. The paper demonstrates its effectiveness in two cases: (1) rule learning and (2) motor learning tasks. It performs well, especially in scenarios with sparse feedback signals, and generalizes effectively to unseen test data with longer time horizons compared to the training data."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed method is novel, and the experiments are well done and show excellent results. It shows that the proposed method can perfectly recover individual tasks, and their composition achieves strong performance on the overall tasks. \n- The paper is very well written. The supplementary code is also well prepared, demonstrating the paper’s reproducibility."}, "weaknesses": {"value": "- The main weakness of the paper, is that as a proof-of-principle paper, the bigger picture is not emphasized enough. Specifically, what main principles it proposes when considering architectures other than LSTMs. For example, which parts of the proposed method are transferable to other architectures? say a Transformers for example. However, I think this is more a matter of clarity rather than a fundamental flaw. \n- The number of experiments is somewhat limited, but for a proof-of-principle paper, the experiments presented are well executed and thoroughly analyzed. So, while this could be seen as a weakness, I don’t think it diminishes the overall value of the paper."}, "questions": {"value": "__Q1.__ Could you comment on the scenario where the number of expert modules or the operation chunk is misspecified? For instance, when the number of expert modules is substantially smaller than the number of true operations in the dataset? How crucial is this for the method’s effectiveness?\n\n__Q2.__ The main limitation of the amortized method, despite its advantage of not requiring parameter updates when new datasets arrive, is its tendency to perform poorly on out-of-distribution test data. Could you comment on how this issue might be addressed when using the proposed method? For instance, is it possible or straightforward to detect test data that lie completely outside the composition of the training data using this method (or a potential extension of it)?\n\n__Q3.__ In Figure 3b, how is the task input specified? During testing, does the experiment include task inputs that were not seen during training? If that’s the case, what about introducing a “wild card token” task input during training, which is assigned to a random task, and then using it during the testing phase on new unseen test data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "127Pzx52FV", "forum": "j3htU5i01r", "replyto": "j3htU5i01r", "signatures": ["ICLR.cc/2026/Conference/Submission7763/Reviewer_6GAZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7763/Reviewer_6GAZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929718079, "cdate": 1761929718079, "tmdate": 1762919806436, "mdate": 1762919806436, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed a generative modeling approach to address the meta-learning problem. Inspired from the mixture of experts, the proposed method consists of a gating model that selects which module (e.g., another model) should handle a training sample. In addition, the whole modeling follows a time series, in which the hidden state calculated in a previous sample is used in the calculation of the model selection for the next training sample. Particle filtering is used to infer the parameter of the proposed generative model.  Because the paper is hard to understand, this is what I have been understood about the paper so far."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper employs the idea of modularity from mixture of experts to address the learning problem in meta-learning. In addition, the modeling relies on recurrent neural networks, which takes the temporal effect into the modeling."}, "weaknesses": {"value": "The current presentation of the paper is hard to understand, causing the difficulty to interpret the contribution of the paper. I will make further comments after having the authors clarify. Please refer to the questions below for further clarification to improve the paper.\n\n**Minor**\nSince the paper proposes to decompose tasks, one related paper should also be discussed is: Nguyen, C.C., Do, T., Carneiro, G.. (2021). Probabilistic task modelling for meta-learning. In Conference on Uncertainty in Artificial Intelligence."}, "questions": {"value": "The paper is unclear on how a task is defined at line 77. According to the definition specified in the paper, a task is a data generation process yielding multiple episodes. Could the authors make it clear that $\\\\{(x\\_{t}, y\\_{t})\\\\}\\_{t = 1}^{T}$ represents $T$ episodes, in which each episode is an input-output pair, or the whole set is represented as an episode as what has been defined in existing meta-learning? Given the subscript $t$ in the notations, I believe it is the former one. In that case, the ordering of samples within a training task will have a major influence on the inference of the generative model's parameters because the modeling depends on time series assumption. However, it does not mention or discussed.\n\nIt is unclear how to get Eqs. (7) and (8). Could the authors provide more details on how to arrive at these equations? In addition, the objective function in learning is often either maximizing likelihood or minimizing loss. Eq. (8) is a likelihood and according to the paper: \"is used as the training loss\". Should it be the other way around, in which the negative log-likelihood is the training loss?\n\nAre the notations used in section 2,2 completely different from previous sections? Since $x_{t}$ and $y_{t}$ are used in previous sections, using them again with different meaning causes confusion.\n\nThe paragraph after Eq. (9) is confusing and requires further clarification. For example, why is suddenly a process of **6 shift operations**  introduced? Why is it **6**?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ew0oyciCVl", "forum": "j3htU5i01r", "replyto": "j3htU5i01r", "signatures": ["ICLR.cc/2026/Conference/Submission7763/Reviewer_rx9b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7763/Reviewer_rx9b"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996361321, "cdate": 1761996361321, "tmdate": 1762919804795, "mdate": 1762919804795, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}