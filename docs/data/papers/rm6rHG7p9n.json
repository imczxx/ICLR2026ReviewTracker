{"id": "rm6rHG7p9n", "number": 19668, "cdate": 1758298150671, "mdate": 1759897027131, "content": {"title": "GAUSS: Graph-Assisted Uncertainty Quantification using Structure and Semantics for Long-Form Generation in LLMs", "abstract": "In high-stakes domains such as clinical reporting, legal analysis, and policy drafting, large language models (LLMs) are increasingly tasked with generating extended, fact-rich narratives rather than isolated sentences. Accurately quantifying uncertainty in these long-form outputs is essential for ensuring their reliability. Prior approaches either assign a single confidence score to an entire paragraph, often using other LLMs or assess factual consistency by comparing discrete atomic facts derived from the paragraphs across multiple generations. Some recent methods also incorporate graph-based representations, modeling fact–paragraph structures as bipartite entailment graphs and derive uncertainty  from node centrality of the facts. However, these methods overlook the interdependencies among atomic facts within a paragraph, as well as the explicit organizational, structural and semantic variation across multiple paragraphs generated by an LLM for the same query, thereby missing a key source of uncertainty inherent specifically to long-form generation. In this work, we introduce GAUSS (Graph-Assisted Uncertainty Quantification using Structure and Semantics for Long-Form Generation in LLMs), a principled framework for measuring uncertainty in long-form LLM outputs through graph-based alignment. Each generated paragraph is modeled as a semantic graph, where nodes represent atomic facts about the paragraph and edges capture inter-fact relationships. We hypothesize that uncertainty arises from structural and semantic discrepancies among these graphs across different generated paragraph samples. GAUSS formalizes this intuition by computing an uncertainty score as the expected alignment cost between the semantic graph of an anchor paragraph and those of alternative reference paragraphs generated by the LLM. By jointly capturing both semantic content and structural coherence of the generated texts, GAUSS moves beyond coarse sentence-level scores to offer a more interpretable and theoretically grounded approach to uncertainty quantification.", "tldr": "", "keywords": ["uncertainty quantification", "graph alignment", "paragraph uncertainty"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/15eb0f30c7cb23b79903e6c2b518c06ebdac00c9.pdf", "supplementary_material": "/attachment/5a5794f0dd1d8422545a3e43e7aa09e09202434e.pdf"}, "replies": [{"content": {"summary": {"value": "In this work, the authors propose a framework GAUSS for measuring uncertainty in long-form LLM outputs through graph-based alignment. The uncertainty is estimated with graph alignment distance between semantic graphs. The authors provide a theoretical justification for GAUSS’s convergence and uncertainty preservation and evaluate it on three benchmarks—bios, LongFact, and WildHallu. Experimental results show that GAUSS significantly improves ."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Strong motivation and interesting idea:\nQuantifying uncertainty at the structural level rather than only at token or sentence granularity. The framing is conceptually fresh and highly relevant to factuality and reliability research. The use of semantic graphs coupled with fused Gromov–Wasserstein distances elegantly captures both content overlap and relational coherence among generated facts.\n\n2. Clear methodological exposition.\nThe pipeline—from atomic fact extraction to graph construction, fusion metric computation, and uncertainty aggregation—is logically structured and well-explained. Pseudo-code and formulas are readable and reproducible.\n\n3. Improved correlation with factuality.\nGAUSS achieves notably higher Pearson/Spearman correlations between uncertainty and factual accuracy compared to semantic-only baselines (e.g., SBERT similarity, perplexity-based variance)."}, "weaknesses": {"value": "1. Dependence on accurate atomic fact extraction, high cost.\nThe method’s reliability heavily depends on the quality of factual unit extraction (likely using an entailment or parsing model). Errors in decomposition may propagate and distort both graph structure and distance computation. Fused Gromov–Wasserstein computations are cubic in the number of nodes, making GAUSS computationally heavy for paragraphs with many atomic facts or when using numerous reference generations.\n\n2. Absence of human correlation studies.\nThe evaluation relies on automatic factuality metrics. Correlating GAUSS scores with human judgments of factual correctness or coherence would strengthen claims of interpretability and practical usefulness.\n\n3. The method relies on a small number of alternative generations (e.g., k = 4–8). While the paper shows concentration theoretically, there’s limited empirical analysis of how uncertainty estimates stabilize with increasing k."}, "questions": {"value": "1. How reliable of the verifier model (Qwen2-32B-Instruct)? The factuality score computation is base on the verifier model.  Do you have human analysis of this verifier model on the three datasets?\n\n2. What are the number of sampled independent paragraph-length response in your experiments? Usually the more , the better. However, if N is large, the computation cost is very high."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5Kf8qL95yl", "forum": "rm6rHG7p9n", "replyto": "rm6rHG7p9n", "signatures": ["ICLR.cc/2026/Conference/Submission19668/Reviewer_9EAH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19668/Reviewer_9EAH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19668/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761694945712, "cdate": 1761694945712, "tmdate": 1762931515049, "mdate": 1762931515049, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors derive better calibrated uncertainty quantification scores by modeling facts as semantic graphs"}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The motivation is clear and natural. The experimental set up is clear, and their method outperforms prior methods in most cases.\n\nIn general, I am not very familiar with this space of papers that try to come up with new and better uncertainty scores for LLMs. While I think this is a nice contribution, there could be prior work outside of those that the authors directly compare to that I do not know about."}, "weaknesses": {"value": "My weaknesses are minor\n- The writing could be improved. The writing feels a little cramped and clumsy, which sometimes made it difficult to parse through everything.\n- The general idea of framing facts as graphs for LLM uncertainty is not new (as stated by the authors)\n- There are cases where GAUSS underperforms prior methods"}, "questions": {"value": "1. Could you also report expected calibration error (let's say for 10 bins) and Brier score? I find that those metrics are easier to interpret, and I think certain groups are researchers for uncertainty quantification who are more used to those metrics would appreciate seeing those results as well.\n2. You mention in the limitations that your method is computationally expensive. Could you quantify and compare the computational costs for your experiments (perhaps in terms of just compute time for your machine)?\n\nSuggestion:\n1. use 3 instead of 4 decimal places for Table 1\n2. Citing [1] - similar in that they also consider graph structures of LLM outputs (reasoning chains) for uncertainty quantification (post-hoc, conformal prediction)\n\n[1] Rubin-Toles, Maxon, et al. \"Conformal Language Model Reasoning with Coherent Factuality.\" The Thirteenth International Conference on Learning Representations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "d7i3jlA3eP", "forum": "rm6rHG7p9n", "replyto": "rm6rHG7p9n", "signatures": ["ICLR.cc/2026/Conference/Submission19668/Reviewer_yDmm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19668/Reviewer_yDmm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19668/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936757506, "cdate": 1761936757506, "tmdate": 1762931514439, "mdate": 1762931514439, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the author introduces an Uncertainty quantification method: Graph-Assisted Uncertainty Quantification Using Structure and Semantics (GAUSS), it is a framework for measuring uncertainty in long-form LLM generation by representing each paragraph as a semantic graph that encodes both factual content and inter-fact structure. Uncertainty is computed as the fused Gromov–Wasserstein distance between an anchor and reference graphs; this way, the author shows that it can capture both semantic and structural variation. The author tries to include the theoretical guarantees on robustness and convergence of the method, and by experiment, it achieves state-of-the-art correlation and calibration with factual accuracy across multiple datasets and models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a framework, GAUSS, that quantifies uncertainty in long-form LLM generation using semantic graphs. \n2. It integrates both semantic meaning and inter-fact structural relations through a fused Gromov–Wasserstein distance, which could provide an angle to measure paragraph-level variability across generations.\n\n\n3. The experimental results are thorough and convincing, covering multiple datasets and models, and demonstrate that GAUSS achieves stronger correlation with factual accuracy and better calibration than existing baselines such as LUQ and Gen-Binary."}, "weaknesses": {"value": "1. GAUSS relies on an auxiliary LLM for fact decomposition, which may introduce extra uncertainty unrelated to the base model’s generation, and the paper lacks analysis of its sensitivity to different decomposition models or prompts.\n\n\n2. The constructed semantic graph seems fully connected, with edges defined by pairwise semantic similarities, raising doubts about whether it captures structural characteristics beyond aggregated semantics.\n\n\n3. The work lacks the majority of the baselines that are classic in the UQ for the LLM domain, such as semantic uncertainty, degree-based sparsity / confidence measurement, it would be good to see more standard evaluation to emphasize the contribution of the proposed method."}, "questions": {"value": "1. GAUSS depends on an auxiliary LLM $M_{atomic}$ to decompose paragraphs into atomic facts before computing graph-based uncertainty. Since this step alters the original outputs, how can authors be sure that GAUSS measures the generation uncertainty of the base LLM rather than the decomposition uncertainty introduced by $M_{atomic}$ ? Have the authors tested the sensitivity of results to different decomposition models or prompts?\n\n\n2. The paper states that GAUSS constructs a semantic graph where nodes are atomic facts and edges encode pairwise semantic relationships. Is this graph fully connected (i.e., every node pair linked by a weighted edge)? If so, could the resulting structure simply reflect pairwise semantic similarities rather than the structural characteristics? In that case, how does GAUSS ensure that its “structural” component captures more than just aggregated semantic similarity?\n\n\n3. The paper claims that GAUSS captures “structural uncertainty” by modeling paragraphs as semantic graphs and measuring alignment via the fused Gromov–Wasserstein distance. However, since the edges are defined through pairwise semantic similarities between atomic facts, the resulting graph structure seems derivative of semantics. Could the authors clarify what constitutes the structural representation in GAUSS and what it actually represents?\n\n\n4. The paper uses various terms and can be misleading sometimes, e.g., could the author confirm if the factuality score holds the same meaning as the correctness? It is suggested to use one consistently. \n\n\n5. If the description of $C_i​$ as in line 253 suggests a fully connected graph, however, the presentation in Figure 1 (Semantic Graph Creation from Atomic Facts), and Figure 3 all illustrate partially connected edges, which is confusing. Could the authors clarify the actual connectivity of the nodes within the semantic graph?\n\n\n6. Literature and related work: \n\n\n- There seems like a very similar existing work [1], which also leverages the structural and semantic meaning to quantify the uncertainty of the LLMs. Could the author discuss the difference from this related work? Especially, this work applies the structural measure for the reasoning topology. How does the author’s work differ?\n\n\n[1] Da, Longchao, et al. “Understanding the Uncertainty of LLM Explanations: A Perspective Based on Reasoning Topology.” Proceedings of the Second Conference on Language Modeling (COLM 2025).\n\n\n- There is no comparison from any of the work on semantic uncertainty [2] or uncertainty quantification methods from work [3], which is a widely acknowledged baseline method group in the uncertainty quantification of LLMs, raising concerns about the actual performance of the proposed method. \n\n\n[2] Kuhn, Lorenz, Yarin Gal, and Sebastian Farquhar. \"Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation.\" arXiv preprint arXiv:2302.09664 (2023).\n\n\n[3] Lin, Zhen, Shubhendu Trivedi, and Jimeng Sun. \"Generating with confidence: Uncertainty quantification for black-box large language models.\" arXiv preprint arXiv:2305.19187 (2023)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hz5f2cjWYz", "forum": "rm6rHG7p9n", "replyto": "rm6rHG7p9n", "signatures": ["ICLR.cc/2026/Conference/Submission19668/Reviewer_GxGz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19668/Reviewer_GxGz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19668/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946512572, "cdate": 1761946512572, "tmdate": 1762931513804, "mdate": 1762931513804, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}