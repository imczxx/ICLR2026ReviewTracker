{"id": "Vz7iyOD8QM", "number": 12489, "cdate": 1758208173145, "mdate": 1759897506426, "content": {"title": "Dynamical system reconstruction from partial observations using stochastic dynamics", "abstract": "Learning stochastic models of dynamical systems underlying observed data is of interest in many scientific fields. Here we propose a novel method for this task, based on the framework of variational autoencoders for dynamical systems. The method estimates from the data both the system state trajectories and noise time series. This approach allows to perform multi-step system evolution and supports a teacher forcing strategy, alleviating limitations of autoencoder-based approaches for stochastic systems. We demonstrate the performance of the proposed approach on six test problems, covering simulated and experimental data. We further show the effects of the teacher forcing interval on the nature of the internal dynamics, and compare it to the deterministic models with equivalent architecture.", "tldr": "The work proposes a novel method for stochastic dynamical system reconstruction using double projection approach to system space and noise space.", "keywords": ["Dynamical system reconstruction", "State space model", "Dynamical Variational Autoencoders"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/69eaab8789bf51bf1161bc99374b4f3da6fd20d4.pdf", "supplementary_material": "/attachment/8f38fa2dd88ca0aa43af38064a6216146d4b8e85.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose a training method called DPDSR (Double Projection Dynamical System Reconstruction). The framework focuses on a generative model where, at each time step, the input consists of the previous latent state (deterministic) and stochastic noise (probabilistic). The observation model is implemented as a simple MLP that takes the latent state and adds observation noise.\n\nThe key contribution lies in motivating a new training algorithm, with the loss inspired by the standard ELBO formulation but modified in three main ways:\n\nThe noise is modeled probabilistically, while the latent state remains a point estimate.\n\nThe prior model is applied for $\\tau$ steps before being replaced by the estimated latent state.\n\nAn additional regularization term is introduced."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Revisiting the classical ELBO formulation in the context of latent variable models is of broad interest to the community.\n\nThe attempt to explore a hybrid treatment of latent states (deterministic) and noise (probabilistic) is an interesting angle."}, "weaknesses": {"value": "Overall, the paper introduces a series of heuristics that deviate from a principled ELBO-based training framework. These raise concerns about both theoretical soundness and novelty:\n\nThe use of teacher forcing for $\\tau$ steps does not correspond to the correct posterior distribution.\n\nIt is unclear how Equations (6) and (7) can be formally derived from the original ELBO formulation.\n\nThe claimed novelty is limited: estimating noise instead of latent states has been studied in a principled way in prior work (e.g., Mind the Gap When Conditioning Amortized Inference in Sequential Models).\n\nThe experimental evaluation is weak and raises questions about reproducibility and fairness."}, "questions": {"value": "Without a proper theoretical foundation, I cannot recommend acceptance. To strengthen the paper, I suggest the following clarifications and additions:\n\nCan you provide a rigorous theoretical discussion of the training algorithm, motivating each design choice? Ablation studies would also help disentangle the contributions of individual components.\n\nCan you include detailed and reproducible evaluation metrics instead of aggregate scores that cannot be verified? Benchmarking against established datasets would also make the results more credible.\n\nCan you demonstrate your method using more flexible and competitive architectures? At present, restricting the analysis to very simple MLPs undermines the applicability and strength of your claims."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1QpZG2Hy1E", "forum": "Vz7iyOD8QM", "replyto": "Vz7iyOD8QM", "signatures": ["ICLR.cc/2026/Conference/Submission12489/Reviewer_MPg2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12489/Reviewer_MPg2"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761398794531, "cdate": 1761398794531, "tmdate": 1762923364157, "mdate": 1762923364157, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a method to learn dynamics of stochastic systems. They propose to use an encoder structure that infers both a state variable z and noise variables epsilon. The authors claim that their proposed encoder is able to infer partially observable dynamics. To improve training, they use a teacher-forcing strategy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-\tI think its an interesting idea to estimate the noise with an encoder, and make it fit to a standard gaussian prior.\n-\tI think your approach of evaluating your training results as described in section 4 is promising."}, "weaknesses": {"value": "-\tDifferentiation from other methods is unclear, and why this approach should be better. The authors do   not clearly asses which limitations of VAE based frameworks they addres with the proposed methods.\n-\tIt would make the paper better if the research gap you are trying to fill would be better described. For example, you write in Line 59 ‚ÄúBut these approaches were not yet sufficiently explored, in particular their performance with algorithms used for training stochastic dynamical systems.‚Äù Please be more specific. Is there any work on partially observed systems? Can you improve your literature review and exactly define the research gap you are trying to fill? In return, you could try to shortend line 24- 56. Also, in line 15 in the abstract you talk about limitations, it would be good, to be specific.\n-\tNot clear what the authors mean by observed and unobserved variables exactly, i.e. how they are included in the framework, and which datasets have which unobserved variables. It would be good to describe the differences between observations x and states z and how this differs in the dataset. It seems like that the states z describe actually the states of the dynamic system and that a ground truth for them (partially) exists. However, how do you choose which variables of a dataset are states? \n-\tIn contrast to the also mentioned continuous-time methods, the proposed method is depended on a regualarily spaced time-scale.\n-\tThey say, that they evaluated noise is only on one variable, making the method not that performant?\n-\tIs Line 28: ‚ÄúCompared with the related task of time series prediction, the problem of dynamical system reconstruction (DSR) is distinguished by the following aspects: Compared with the related task of time series prediction, the problem of dynamical system reconstruction (DSR) is distinguished by the following aspects:‚Äù a definition by you, or can it be referenced by some sources? This would make the paper stronger as you often refer to it.\n-\tI think in line 77 ongoing, you talk about Dynamical Variational Autoencoders. You should name them after the Kingma citation, and refer to Girin‚Äôs review. \n-\tIn line 127ff., you talk about ‚Äúdiscretize-then-differentiate‚Äù and continuous-time models. As you don‚Äôt employ a continuous-time model, this is not really necessary. Additionally, ‚Äúdiscretize-then-differentiate‚Äù is usually named ‚Äúdiscretize-then-optimize‚Äù and a citation for this, e.g. the PhD thesis of Kidger, should be given. \n-\tDescription of the model (section 3.1): hard to understand. What do authors mean by observed an unobserved variables? Where is the identy function the talk about in equations 5-7? Why do you name only epsilon a latent variable? I think, z would also be latent variables, as they are inferred. \n-\tIn you description of your model you follow the structure proposed in Girin et. Al. Please cite that. \n-\tIn line 180 you say that you only use one-dimensional noise in the last dimension in your presented examples. To me, this seems is the method is not really performant in predicting stochastic systems. Can you say anything against that, or why you did this?\n-\tIn your motivation for you new methods in line 151-160: \n-\tI would disagree that Dynamical Variational Autoencoders only make 1-time-step predictions (around line 153). It just depends on how you specify the exact training strategy. \n-\tIn line 158, you claim that teacher-forcing strategies are ‚Äúcrurical‚Äù for training deterministic systems. I would disagree, as we do it in our research without it. Can you a) explain better, what teacher forcing does, and b) why you see so much promise in employing this?\n-\tThe motivation would better be used in the introduction or review of related work.\n-\tCompared methods (3.2): Why do you not test more methods of the review of Girin et al, only DKF? I don‚Äôt understand how a standard LSTM has a probabilistic output?  It would be good to provide a reference where you describe in more detail the used architectures.\n-\tUsed datasets: No citations for datasets 3-6. It would be good to know which other studies used this dataset as well. \n-\tThe authors say that they adapt the weights for the overall score depending on the dataset. This raises the question, if weights are adjusted to achieve that the proposed methodology achieves the best performance, making it hard for the reader to evaluate the performance properly. \n-\tIt would be good to describe what infromation the maximal Lyapunov exponent describes and which numerical values describe which behaviour, as it is hard to understand the following evaluation.\n-\tIt seems like the discussion paragraph wasn‚Äôt finished. Lines 463-485 reads like a literature review and its contents might be better suited to the related works section.\n-\tA conclusion is missing.\n\nMinor:\n-\tLine 77 no ‚Äúthe‚Äù before data\n-\tLine 53, what do you mean by ‚Äúautonomous‚Äù?\n-\tLine 107, what is ‚ÄúEuler-Maruyama‚Äù discretization? Isn‚Äôt it just  Euler?\n-\tExplanation of the abbreviation PECUZAL is missing (line 242)"}, "questions": {"value": "-\tIs teacher forcing comparable to multiple-shooting in Neural ODEs? Would it be possible to employ growing horizon techniques, e.g. start by predicting short sequence length and slowly increasing the prediction lengths?\n-\tWhy is the double projection approach necessary and do other publications do the same? \n\nIf the authors address my concerns, especially by better explaining the need for this work, its setting in the related literature, improve the presentation of the method itself, and add a proper conclusion, I‚Äôm willing to increase my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "U6EPmmwY8q", "forum": "Vz7iyOD8QM", "replyto": "Vz7iyOD8QM", "signatures": ["ICLR.cc/2026/Conference/Submission12489/Reviewer_mmdr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12489/Reviewer_mmdr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761569248301, "cdate": 1761569248301, "tmdate": 1762923363572, "mdate": 1762923363572, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DPDSR (Double Projection Dynamical System Reconstruction), a VAE-based method for learning stochastic dynamical systems from partially observed time series. The key idea is to encode observations into both estimated state trajectories and noise time series, then use teacher forcing on states while treating noise as latent variables. The authors test on six problems, including synthetic chaos (Lorenz, cell cycle), noise-driven systems (double well, RNN), and real data (neuron voltage, ECG). Results show the method handles stochastic systems better than deterministic alternatives, though with high variance across initialisations.\nThe core contribution is reasonable: existing methods either can't do multi-step evolution (Deep Kalman Filter) or can't use teacher forcing (STORN). This dual-encoding approach aims to get the best of both worlds."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- Using two separate encoders‚Äîone for states (enabling teacher forcing) and one for noise (enabling proper stochastic modeling)‚Äîis a neat solution to a genuine problem. The motivation is clear, and the approach makes intuitive sense.\n\n- The dynamical analysis in Fig. 5 and S6 is genuinely insightful. Showing how the teacher forcing interval œÑ controls whether you get deterministic chaos vs. noise-driven dynamics is interesting. \n\n- Six test problems with different characteristics (deterministic chaos, noise-driven, experimental) are a decent scope. The ECG analysis revealing \"skipped beats\" as a failure mode is the kind of honest reporting that's useful.\n\n- Including both stochastic (DKF, AR-LSTM) and deterministic (GTF, SPDSR) baselines makes sense for understanding where stochastic modelling helps"}, "weaknesses": {"value": "- Four random initialisations are not enough, period. Look at your own Fig. 3‚Äîthe variance is huge. Some methods have error bars spanning the entire range. You're making claims about which method is \"better\" based on the means of 4 samples with massive variance. Same with Figure 4D.\n\n- You're setting different weights (w1, w2, w3, w4) in the score function for each dataset. Why? The weights seem arbitrary and thus could arbitrarily favour your method.\n\n- Why WaveNet? We need an additional ablation study to demonstrate the method's value, or switch to a more standard model for those tasks."}, "questions": {"value": "- You claim PECUZAL \"fails\" on stochastic systems, but the original paper explicitly says it handles noisy time series. Why the discrepancy?\n\n- Tanh is applied on both the diffusion term and the drift (eq. 1). This doesn't sound standard, as tanh on the noise does change its property. Is that what you are doing?\n\n- DKF performs terribly on everything, including problems where it should work reasonably well. Can you comment on that? \n\n- Can you increase statistical power?  Even if computational cost is high, you need more than four initialisations for the final version.\n\n- How sensitive are results to the score weights? Show what happens when you use uniform weights (1,1,1,0) across all datasets."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PsMASRyUW9", "forum": "Vz7iyOD8QM", "replyto": "Vz7iyOD8QM", "signatures": ["ICLR.cc/2026/Conference/Submission12489/Reviewer_qXcw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12489/Reviewer_qXcw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761673174970, "cdate": 1761673174970, "tmdate": 1762923363191, "mdate": 1762923363191, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel method for Dynamical System Reconstruction (DSR) from partially observed data, named Double Projection Dynamical System Reconstruction (DPDSR). The core idea is to use a variational autoencoder (VAE) framework to jointly estimate both the latent system state trajectories and the stochastic driving noise time series from the observed data. A key feature is the integration of a teacher forcing strategy, where the simulated state is periodically reset to the encoder's state estimate, which helps in training the stochastic dynamics over long horizons. The paper demonstrates that DPDSR performs competitively across all problem types, whereas existing methods (deterministic or stochastic) excel only on specific subsets. A further analysis investigates how the teacher forcing interval influences the nature of the learned dynamics, revealing a transition from deterministic-chaotic regimes (low $\\tau$) to noise-driven regimes (high $\\tau$)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The \"double projection\" concept is a novel solution to a known limitation in stochastic VAE-based DSR. By encoding both states and noise, it bridges the gap between methods that use states as latents and those that use noise as latents. \n\n* The experimental evaluation is extensive and robust. The use of many distinct datasets, the fair and careful matching of model parameters, the multi-criteria evaluation score, and the analysis of the learned attractors' properties all lead to a high-quality empirical study.\n\n* One of the paper's greatest strengths is that it does not stop at reporting error metrics. The analysis in Figure 5, which uses Lyapunov exponents to probe the internal dynamics of the learned models, provides a deep and significant scientific insight: deterministic models \"fake\" noise with chaos, while the proposed stochastic model can learn the true, simpler, noise-driven dynamics .\n\n* The paper provides strong evidence that DPDSR is a versatile and robust DSR method. The analysis of the $\\tau$-dependent regime shift (chaotic vs. noise-driven) offers valuable insights into the training dynamics."}, "weaknesses": {"value": "* The method's performance and fundamentally the nature of its learned solution (chaotic vs. noise-driven) are critically dependent on the teacher forcing interval ($\\tau$). The authors correctly identify this as a limitation, as it requires an expensive hyperparameter sweep. \n\n* The authors note that the DPDSR model for the ECG data can \"skip a beat\" and that this behavior is sensitive to initialization. This suggests the learned attractor, while good, may have minor instabilities or undesired properties, which is a slight weakness in the method's robustness. However, again this was correctly identified and acknowledged by the authors."}, "questions": {"value": "* The authors are transparent about the \"skipped beat\" phenomenon in the ECG model. Have you investigated the cause of this? Does it correspond to a specific, unstable region of the learned limit cycle, or a particular sequence of inferred noise that pushes the trajectory off-attractor? Does this issue persist with different noise regularizations? \n\n* About the analysis of the $\\tau$-dependent regimes: does the DPDSR model with a very small $\\tau$ (e.g., $\\tau=1$) and its correspondingly low noise KL-divergence (Fig 5) effectively \"shut off\" the stochastic component and converge to the same solution as the deterministic SPDSR model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "yhmTRWlE96", "forum": "Vz7iyOD8QM", "replyto": "Vz7iyOD8QM", "signatures": ["ICLR.cc/2026/Conference/Submission12489/Reviewer_M7Jh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12489/Reviewer_M7Jh"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761705672802, "cdate": 1761705672802, "tmdate": 1762923362921, "mdate": 1762923362921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Double Projection Dynamical System Reconstruction (DPDSR), a stochastic variational framework for learning latent dynamical systems from partial and noisy observations. Unlike standard VAE-based state-space models (e.g., Deep Kalman Filters), DPDSR performs two parallel projections:\n\n- An encoder that infers latent system states $ùëß_ùë°$. \n- A second encoder that infers latent driving noise $\\epsilon_t$. \nThe method is trained end-to-end using teacher forcing over multi-step rollouts, allowing it to balance deterministic and stochastic dynamics.\n\nA systematic evaluation is carried out on six datasets‚Äîthree synthetic (Lorenz, Cell Cycle, Double-Well) and three empirical (RNN, Neuron, ECG)‚Äîand compared against deterministic reconstruction (SPDSR, Generalized Teacher Forcing), stochastic baselines (Deep Kalman Filter), and AR-LSTM. The model consistently performs competitively or best across all datasets, with detailed dynamical analysis of the learned attractors (Lyapunov spectra, noise-driven vs. chaotic regimes)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The double-projection idea (state + noise) is original within the DSR context. It disentangles deterministic evolution from stochastic excitation, which aids interpretability of noise-driven dynamics.\n\n- By varying the teacher-forcing interval, the method interpolates between deterministic chaos and noise-driven behavior. This dual regime analysis provides useful insight into the transition between chaotic and stochastic attractors.\n\n- Six diverse datasets, including empirical ones, make the benchmarking solid. The multi-criteria score (distribution, spectral, prediction errors) captures both long-term and short-term fidelity.\n\n- Estimation of Lyapunov exponents and attractor structures is uncommon in ML papers and adds insight.\n\n- The combination of autoregressive posterior, WaveNet-based encoders, and teacher forcing improves stability and expressivity, especially for partially observed systems."}, "weaknesses": {"value": "- Despite the ‚Äúdouble projection‚Äù framing, DPDSR remains close to stochastic latent-state VAEs (DMM, SRNN, VRNN). The argument that DKF/DMM cannot capture long-term dependencies because they are trained with one-step losses is not fully convincing; multi-step or rollout training is straightforward to integrate into DMM-style frameworks (and is usually avoided in favor of near real time frameworks).\n\n- Key related baselines such as Deep Markov Models, Latent SDEs, or Neural ODE variants are discussed but not empirically compared. This omission weakens claims of general superiority.\n\n- Model performance seems sensitive to the forcing interval $\\tau$. The paper acknowledges this but offers no principled criterion or adaptive strategy; tuning œÑ by sweep undermines the method‚Äôs autonomy.\n\n- Dual encoders, autoregressive posteriors, and repeated multi-step rollouts increase training cost substantially relative to DKF or DMM, without a clear demonstration of efficiency gains.\n\n- Despite the motivation of reconstructing interpretable dynamics, the fully connected neural parameterization offers little structural insight beyond what DMMs already provide. Scalability to high-dimensional continuous systems is not addressed.\n\n- The method is presented as a distinct stochastic reconstruction framework, yet in practice it is a specific instance of a variational state-space model with multi-step reconstruction loss."}, "questions": {"value": "- It would help to elaborate on how the DPDSR differ mathematically from the Deep Markov Model (DMM) or Stochastic RNN (SRNN)?\n- Could a DMM trained with multi-step rollout and teacher forcing achieve equivalent performance?\n- Why is the double-projection (state + noise) necessary if the latent state in DMM can already encode both deterministic and stochastic components?\n- How interpretable are the learned ‚Äúnoise‚Äù variables? Do they correspond to actual process disturbances, or are they simply a learned residual? Is there any quantification (e.g., mutual information) showing that $\\epsilon_t$ encodes meaningful stochastic forcing?\n\n- Since both $ùëß_ùë°$ and  $\\epsilon_t$ are learned from data, is the decomposition unique? Could their roles be swapped or entangled during training?\n- Are there constraints ensuring identifiability (e.g., orthogonality, disentanglement penalties)?\n\n- Can the model generalize to unseen rollout lengths?\n\n- As learning the noise is an important part of this work, I would expect a more systematic examination of performance on various levels of additive measurement noise or non-Gaussian corruptions?\n\n- How does performance scale with increasing system dimension $ùëë_ùëß$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zeTIrfpN6z", "forum": "Vz7iyOD8QM", "replyto": "Vz7iyOD8QM", "signatures": ["ICLR.cc/2026/Conference/Submission12489/Reviewer_5GmW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12489/Reviewer_5GmW"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission12489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761933588069, "cdate": 1761933588069, "tmdate": 1762923362378, "mdate": 1762923362378, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}