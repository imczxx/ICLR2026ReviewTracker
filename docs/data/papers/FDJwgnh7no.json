{"id": "FDJwgnh7no", "number": 24030, "cdate": 1758351968472, "mdate": 1759896785391, "content": {"title": "A Two-Character Change in Transformer Architecture Promotes Ideal Token Geometry", "abstract": "We hypothesize that in the optimal geometric configuration of token embeddings for transformers, tokens should collapse to single points according to their classes, and these points themselves should exhibit Neural Collapse. We study whether current transformers achieve this configuration through principal component projections, cosine similarity measurements, analysis of variance on token embeddings, and Neural Collapse measurements, and find that they fall far short of the conjectured ideal. To address this, we introduce a simple modification to attention that brings token embeddings markedly closer to the conjectured configuration and yields consistent performance improvements across benchmarks.", "tldr": "We conjecture that ideal transformers collapse tokens, but we find that current transformers don't collapse tokens well, so we modify attention to achieve more collapse and better performance.", "keywords": ["Transformers", "Neural Collapse", "Attention"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ce41a2cf17e4661f3a7bb2e0078be423533d4b0f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a Laplacian-based modification to the transformer attention mechanism that encourages token embeddings to evolve toward a beneficial geometric structure called Neural Token Collapse (NTC). By interpreting attention as diffusion on a graph, the method introduces a Laplacian “head” that smooths token representations along meaningful variance directions rather than averaging them, improving both representation structure and classification accuracy. Experiments on CIFAR-10, CIFAR-100, and ImageNet-1k show consistent performance gains over standard Vision Transformers. The authors connect their approach to related concepts such as neural collapse, rank collapse, and oversmoothing in graph neural networks, suggesting that controlled token collapse can enhance model efficiency and separability rather than hinder it."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Originality: There are a few points of novelty in this paper: exploiting token collapse as an improvement of the transformer architecture, rather than an issue, is surely a clean idea that I have not seen before. Along this line, the physical interpretation as graph Laplacian diffusion makes it more grounded to known concepts.\n- Clarity: The problem is stated clearly in the introduction and raised questions and goals are well referenced when addressed along the whole text.\n- Quality: This paper proposes an hypothesis grounded on the understanding of how transformers works, implements a modification to the architecture that verify the hypothesis and, importantly, as a result improve the performance of the model. This is how a paper on interpretating neural networks should be structured.\n- Significance: Principled improvements to transformers architectures are highly relevant in a moment where available human training datasets are being saturated."}, "weaknesses": {"value": "1. The discussion in 2.1 and 2.2 has been heavily motivated by Figure 2. While the figure neatly conveys the idea of how a single attention block modifies the token’s relative positions, it is not clear to me that this would work as neatly in high-dimensional spaces. Some empirical support or citations for the statements made in 2.1 and 2.2 can improve the presentation.\n2. The experiment part seems a little bit underdeveloped: the authors consider only one vision model and three datasets, which are used both for training and for showing results. It would also seem natural to discuss what would be the result of applying this method to language models/next token prediction tasks.\n3. Presentation-wise, the authors might make a slight effort in improving how they present their experimental results (see questions below for more detail)."}, "questions": {"value": "1. While the authors give some details about training, since the method involves a different paradigm, some comparison on the training metrics with the base model (like just the number of epochs) could be useful?\n2. The mixing of attention and laplacian seems a bit arbitrary. Appendix D seems to discuss more mixing trials, but I wonder if there is a way of framing this in a more principled way? Would this mixing have to be adapted at each task?\n3. Some discussion on extending this framework to next token prediction/autoregressive tasks can be helpful for a more impactful paper. Do the authors think such an extension is possible, i.e., is NTC ideal for next token prediction? Some empirical validation by training small transformers using Laplacian heads would be great.\n4. Some figures might benefit a little bit more cosmetics: \n- Figure 3 has two diagrams with identical labels and no reference to top/bottom in neither text nor caption\n- Figure 4 some labels are cut.\n- Figure 5 the legend for “M” and “W” is explained in the caption but might be made more explicit in the plot. Y labels are not in latex despite using equations.\n5. In the classification performance part, the datasets used are the same ones used in training. Would it be possible to see this on an unseen dataset? \n6. This paper https://arxiv.org/pdf/2408.15417 seems relevant and I haven’t seen it in the relevant works sections."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "L7HwZ1l6W5", "forum": "FDJwgnh7no", "replyto": "FDJwgnh7no", "signatures": ["ICLR.cc/2026/Conference/Submission24030/Reviewer_XAcD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24030/Reviewer_XAcD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24030/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831523094, "cdate": 1761831523094, "tmdate": 1762942904707, "mdate": 1762942904707, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work presents a method for obtaining better token embeddings, as motivated by the neural collapse phenomenon in the existing literature. Extensive empirical evidence is presented to backup the idea that current token embeddings are suboptimal, and a simple fix can be done to mitigate this. In particular, experiments on vision transformers are done on CIFAR classification tasks, as well as probing into the geometry of the existing embeddings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The work provides an interesting perspective on how to improve token embeddings, which can only be beneficial transformer/language model pipelines.\n- Experiments showing the existing geometry of embeddings and neural token collapse are shown, as well as improvements on image classification tasks.\n- The visualizations given are very useful for the reader."}, "weaknesses": {"value": "- Experiments are run on image classification tasks only; it would be interesting to see if such improvements hold for generative models as well."}, "questions": {"value": "- On the classification tasks, it seems that the improvement is not extremely significant. I wonder if it is strictly necessary to have better token embeddings (e.g. the ones that satisfy this analogue of neural collapse).\n- Following up on my above comment (see weaknesses) for generative models: in current LLMs there are positional embeddings that encode the tokens in addition to the token embeddings themselves; is there any reason to believe that the marginal improvement towards the NTC regime will be significant enough for the case where we apply positional embeddings?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "UrG9NiUJDx", "forum": "FDJwgnh7no", "replyto": "FDJwgnh7no", "signatures": ["ICLR.cc/2026/Conference/Submission24030/Reviewer_3TuH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24030/Reviewer_3TuH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24030/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945032305, "cdate": 1761945032305, "tmdate": 1762942904443, "mdate": 1762942904443, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the concept of Neural Token Collapse (NTC) as a desirable geometric property for token embeddings in transformers. They show that standard transformer architectures fail to achieve the so called ideal token geometry. To address this, the authors introduce a a simple modification to the standard attention mechanism where the output PV is changed to V−PV. The paper demonstrates through experiments on CIFAR-10, CIFAR-100, and ImageNet that this modification not only brings the token geometry closer to the ideal NTC but also yields consistent and significant improvements in classification accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "-The proposed idea seems to be novel and simple. It simply modified the attention output from PV to V - PV. It offers a practical and low-effort way to improve existing transformer models without adding parameters or significant computational cost.\n\n-The proposed method achieves meaningful performance improvements across all tested datasets, including a 5% absolute improvement on CIFAR-100. \n\n-Interesting theoretical insights. The paper provides a compelling theoretical interpretation of the proposed change by connecting it to graph theory."}, "weaknesses": {"value": "- It is unclear that why the proposed NTC is the ideal token geometry. \n\n- Limited Scope of evaluation. All experiments are conducted on image classification. While the theory is general, the paper lacks evidence of its applicability to other domains, most notably Natural Language Processing. It is an open question whether forcing this kind of NTC would be beneficial for other tasks.\n\n- The paper proposes mixing standard Attn heads with the new Laplacian L heads to further improve performance. However, the strategies for this mixing (e.g., \"1P\", \"3P\", \"Mix-Depth\") feel somewhat heuristic and are not as well-motivated as the core Laplacian idea itself."}, "questions": {"value": "The authors are encouraged to provide evaluation results in NLP."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "CPPi6bHOUr", "forum": "FDJwgnh7no", "replyto": "FDJwgnh7no", "signatures": ["ICLR.cc/2026/Conference/Submission24030/Reviewer_5VSE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24030/Reviewer_5VSE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24030/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762129647084, "cdate": 1762129647084, "tmdate": 1762942904233, "mdate": 1762942904233, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes neural token collapse (NTC) as an ideal token geometry for transformers in the setting of classification. Inspired by the neural collapse line of work, this work focuses on the specific case of transformer architectures and proposes simple architectural fixes to the attention mechanism to promote NTC. Experiments are conducted on image classification tasks to verify the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. The proposed method is very simple and can be incorporated into standard transformers easily.\n2. The geometric framing is straightforward and the ANOVA approach makes the results easy to analyze and interpret.\n3. The connection to diffusion over graphs is interesting and aligns well with the experimental results."}, "weaknesses": {"value": "1. It is very questionable whether achieving zero variance among tokens within the same sequence is truly desirable. Note self-attention precisely promotes dynamic weighting between tokens as a mechanism to propagate information. Removing the variance among tokens leads to a trivial weighting and effectively makes self-attention no better than a mean aggregation. To test this, one can add another baseline with just a simple mean operator to perform token mixing, without any self-attention.\n2. The method only makes sense for classification, and I find it hard to extend the method to the vast amount of tasks transformers do well in: causal language modeling, dense segmentation, masked image modeling and other self-supervised visual modeling.\n3. In experiments, the authors only tested the model with the hybrid approach described in Sec.2.3. It is not clear what the performance would be if using only the proposed method in Sec 2.2. This makes it hard to understand the behavior of the proposed method.\n4. Related to the previous point, the results are not truly convincing, as the classification performance gain on ImageNet-1k is very small. It is questionable whether the proposed fix alone is worth incorporating into any existing ViTs."}, "questions": {"value": "Please see above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HAmpn5OtO1", "forum": "FDJwgnh7no", "replyto": "FDJwgnh7no", "signatures": ["ICLR.cc/2026/Conference/Submission24030/Reviewer_aBvF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24030/Reviewer_aBvF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24030/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762136146041, "cdate": 1762136146041, "tmdate": 1762942903888, "mdate": 1762942903888, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}