{"id": "GtjELGHkPB", "number": 24301, "cdate": 1758355128564, "mdate": 1759896772039, "content": {"title": "Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation", "abstract": "Graph-based retrieval-augmented generation (RAG) enables large language models (LLMs) to ground responses with structured external knowledge from up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground truth, the retriever is often trained on weak supervision, which often introduces spurious signals to the LLMs. II) Due to the abstraction of graph data, the retrieved knowledge is often presented in unorganized forms. To mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM feedback to get rid of spurious signals and improve the quality of the supervision. Meanwhile, ReG introduces a structure-aware reorganization module to refactor the retrieval results into logically coherent evidence chains. Experiments on prominent benchmarks demonstrate that ReG significantly and consistently brings improvements across different LLM backbones by up to 10%. The improved supervision quality enables ReG to match the state-of-the-art performance with 5% training data and to transfer to out-of-distribution KGs. Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token cost by up to 30% and improves the performance by up to 4%.", "tldr": "", "keywords": ["Large Language Models", "Graph-based Retrieval Augmented Generation"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c5e8e77a5aa5bc31e6c9bf338d52f21d3fc42675.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Refined GraphRAG, which leverage refined retrieval graph to train a retriever for GraphRAG. Specifically, the authors first generate a multi-faced candidate with the shortest path, query neighbors and answer neigbors. Then, LLMs would refine the candidate graph to reduce the size. Finally, a retriever is trained based on the refined graph. Experimental results demonstrate the effectiveness of the proposed ReG."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It is reasonable that using better retrieval graph leads to better  performance.\n2. The paper is well-written and easy to follow."}, "weaknesses": {"value": "1. The proposed approach appears ad-hoc for multi-faceted candidate generation. The authors argue that previous methods relying on shortest paths suffer from a lack of reasoning signal. However, simply including the neighbors of the query and answer nodes does not adequately address this issues, particularly for multi-hop QA.\n\n2. The LLM-Guided Candidate Refinement introduces unfairness in the comparison. This refinement step effectively performs part of the generation process, as the LLM may directly identify the correct answer for the query. As a result, comparing this approach with baselines that lack such refinement is not entirely fair.\n\n3. The experiments do not convincingly demonstrate the generalizability of the proposed method to OOD KGs. Both CWQ and GrailQA are based on Freebase. I suggest that the authors include experiments on datasets with different underlying KGs, such as MetaQA, to strengthen their claims."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "x8xvoxkRqA", "forum": "GtjELGHkPB", "replyto": "GtjELGHkPB", "signatures": ["ICLR.cc/2026/Conference/Submission24301/Reviewer_iAfW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24301/Reviewer_iAfW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761596168976, "cdate": 1761596168976, "tmdate": 1762943035940, "mdate": 1762943035940, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of aligning weak retrievers with LLMs in graph-based RAG systems. The authors identify two key problems: (1) weak supervision signals from heuristic methods (e.g., shortest paths) that introduce spurious connections or miss critical evidence, and (2) misorganized representation of retrieved graph information. They propose ReG (Refined graph-based RAG), which uses LLM feedback to refine supervision signals and employs structure-aware reorganization to present retrieved information in logically coherent chains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper clearly articulates the limitations of current graph-based RAG approaches. The method also achieves state-of-the-art performance across benchmarks."}, "weaknesses": {"value": "1. Limited novelty in core techniques: While the combination is effective, the individual components are relatively standard. Using LLM feedback to filter/refine candidates is not new (acknowledged in related work). BFS-based chain expansion is a straightforward graph traversal technique. The main contribution appears to be the specific application to graph-based RAG rather than methodological innovation\n2. No analysis of retrieval quality independent of QA performance (e.g., precision/recall of retrieved triples vs. oracle)"}, "questions": {"value": "Same as above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KfpQKXBJb0", "forum": "GtjELGHkPB", "replyto": "GtjELGHkPB", "signatures": ["ICLR.cc/2026/Conference/Submission24301/Reviewer_cVAD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24301/Reviewer_cVAD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761798922563, "cdate": 1761798922563, "tmdate": 1762943035700, "mdate": 1762943035700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ReG to improve traditional KGQA by using LLMs to refine weak supervision signals and train the retriever and to reorganize retrieved knowledge into logical chains. The core claim is that this aligns \"weak\" retrievers with \"strong\" LLMs. While the experimental results on KGQA benchmarks are solid, the paper suffers from fundamental conceptual and methodological problems that make it low-quality."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 1}, "strengths": {"value": "- It solves a practical problem since heuristic-based supervision like shortest paths for graph retrievers is noisy and misaligned with LLM reasoning.\n- The results are promising.​​ The method demonstrates strong performance gains on traditional KGQA datasets (WebQSP, CWQ) and shows impressive data efficiency, matching SOTA performance with only 5% of training data."}, "weaknesses": {"value": "- The title and claims are misleading. This is indeed an LLM-based KGQA paper, not GraphRAG. The community refers GraphRAG as a complete pipeline, similar to but more than RAG, that involves ​​constructing a graph from raw documents​​ and then retrieving from it. This work operates purely on ​​existing KGs​​ in a traditional LLM-based KGQA setting, let lone not comparing against real GraphRAG baselines, the paper addresses a much narrower problem than it claims.\n- It is a very important prerequisite that we use KGs to enhance LLMs for unseen or difficult domain-specific scenarios. This arouses two major problems of this paper:\n    - There lacks the zero-shot performance of LLMs. If LLMs could already achieve good accuracy, what is the advantage of this paper? This is also a concern to the entire KGQA task, it is not generalizable and applicable for LLMs nowadays. Therefore, the contribution of this paper is not enough.\n    - Weak-to-strong is a good hypothesis but should not be static. LLMs are treated as oracle, but the feedback should be used to iteratively refine the signal for better loop. The design lacks enough consideration to make it a real 'weak-to-strong'."}, "questions": {"value": "- What is the advantage of training a specialized retriever compared to directly using the powerful zero-shot LLM? also any comparisons?\n- If the alignment is not iteratively achieved, how do you ensure LLM is a reliable oracle since we often aim to solve the hallucination and domain knowledge lacking problem in GraphRAG?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "XfmDqDDfnc", "forum": "GtjELGHkPB", "replyto": "GtjELGHkPB", "signatures": ["ICLR.cc/2026/Conference/Submission24301/Reviewer_zMjD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24301/Reviewer_zMjD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891074596, "cdate": 1761891074596, "tmdate": 1762943035346, "mdate": 1762943035346, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper uses LLMs to refine input graphs and then trains retrievers via supervised learning. Experiments show that ReG achieves state of the art performance using only 5% of the training data and transfers well to out of distribution KGs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tTackles an important and timely problem.\n2.\tThorough experimental evaluation, including an analysis of the proposed “overthinking” problem.\n3.\tMaintains high performance even when trained on just 5% of the data."}, "weaknesses": {"value": "1.\tSome parts of the text are hard to follow and would benefit from rewriting for clarity.\n2.\tKey methodological details are omitted and should be added.\n3.     The use of LLM to evaluate each candidate P is expensive."}, "questions": {"value": "1.\tFigure 1 does not make the ReG workflow clear. Please redraw the diagram to more explicitly show the end to end pipeline and the role of each component.\n2.\tThe motivation for introducing Definition 3.1 is unclear, since prior work has already formalized graph based RAG. Please clarify how Definition 3.1 differs from or complements existing formalisms (e.g., Peng et al., 2024, \"Graph Retrieval Augmented Generation: A Survey\").\n3.\tFor graph refinement, the query centric neighborhood construction is well described, but the paper does not explain how answer centric neighborhoods are built in practice—only that they enable comparisons across answer candidates using numeric or categorical attributes. How are answer centric neighborhoods generated when entities lack attributes in the KG? Please provide concrete procedures or fallback strategies for such cases."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "9xLEJR4iSj", "forum": "GtjELGHkPB", "replyto": "GtjELGHkPB", "signatures": ["ICLR.cc/2026/Conference/Submission24301/Reviewer_bXzL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24301/Reviewer_bXzL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24301/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762410696394, "cdate": 1762410696394, "tmdate": 1762943035014, "mdate": 1762943035014, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}