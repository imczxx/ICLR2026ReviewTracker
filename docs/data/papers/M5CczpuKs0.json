{"id": "M5CczpuKs0", "number": 12619, "cdate": 1758209035538, "mdate": 1759897497926, "content": {"title": "Never Skip a Batch: Continuous Training of Temporal GNNs via Adaptive Pseudo-Supervision", "abstract": "Temporal Graph Networks (TGNs), while being accurate, face significant training inefficiencies due to irregular supervision signals in dynamic graphs, which induce sparse gradient updates. We first theoretically establish that aggregating historical node interactions into pseudo-labels reduces gradient variance, accelerating convergence. Building on this analysis, we propose History-Averaged Labels (HAL), a method that dynamically enriches training batches with pseudo-targets derived from historical label distributions. HAL ensures continuous parameter updates without architectural modifications by converting idle computation into productive learning steps. Experiments on the Temporal Graph Benchmark (TGB) validate our findings and an assumption about slow change of user preferences: HAL accelerates TGNv2 training by up to 13$\\times $ while maintaining competitive performance. Thus, this work offers an efficient, lightweight, architecture-agnostic, and theoretically motivated solution to label sparsity in temporal graph learning.", "tldr": "", "keywords": ["Temporal Graph Networks", "Pseudo-Labeling", "Training Efficiency", "Dynamic Graph Learning", "Gradient Sparsity"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fbd807558304ab24fb8af998b20cbf41f0f2dfd5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Node-level labels for node property prediction tasks in the TGB benchmark appear irregularly, resulting in a large proportion of training batches that lack ground-truth labels. Existing training procedures typically only perform memory state updates for these unlabeled batches, without updating model weights, leading to sparse gradient updates and consequently slow convergence.\n\nThis work introduces History-Averaged Labels (HAL), which augments batches with few or no true labels by generating pseudo-targets from historical data, thereby converting idle computation into productive gradient-based learning steps."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper proposes a simple yet effective solution to the critical problem of sparse and irregular training signals in the node property prediction task in temporal graph learning on the TGB benchmark.\n\n- The proposed History-Averaged Labels (HAL) method is architecture-agnostic, requiring no changes to the underlying model and no additional training parameters, making it broadly applicable and practical for diverse models.\n\n- The paper provides a rigorous theoretical analysis, demonstrating that HAL reduces the variance of gradient estimates and accelerates the convergence of stochastic gradient descent.\n\n- Empirical experiments on two advanced models (TGNv2 and DyRepv2) across multiple TGB node property prediction datasets show substantial improvements in convergence speed, with no degradation in model performance."}, "weaknesses": {"value": "**W1.** The authors claim that the proposed method, HLA, is architecture-agnostic. However, this claim is not sufficiently substantiated, as the evaluation is limited to only two models, TGNv2 and DyRepv2. To convincingly demonstrate architecture independence, the authors should validate HLA on a broader range of temporal graph models, such as DyGFormer[1], TPNet[2] , TGAT[3], GraphMixer[5] and AGCRN[6]. Including results on these diverse architectures would provide stronger empirical evidence for the architecture-agnostic property of HLA.\n\n**W2.** Lines 151–152 state\n> Forward pass: A graph neural network (GNN) processes the subgraph to compute context-aware node embeddings.\n\nWhile this description applies to a subset of temporal graph network (TGN) models that explicitly employ GNN modules for structural encoding, it does not generalize to a broader class of models, such as DyGFormer[1], DyGMamba[4], GraphMixer[5]. Given that the proposed method claims to be architecture-agnostic, this explanation should be reframed in a more general context, avoiding focusing on specific to GNN-based variants of TGNNs and better reflecting the diversity of temporal graph architectures.\n\n**W3.** The overall readability of the paper could be significantly improved by rearranging and rewriting certain sections.\n\n- Lines 98–107, which contain critical information about the problem formulation, should be separated into a section or subsection to clearly and explicitly define the problem statement and the task addressed by this work.\n\n- The term “unsupervised batch” used in Line 132 to describe batches without training signals is misleading. In standard terminology, “unsupervised” implies learning from unlabeled data without explicit output labels, which is not synonymous with simply lacking training signals in batches. Clarification or alternative wording would prevent confusion.\n\n- Several important terminologies, such as “Default” in Table 1, are introduced without clear definitions or explanations.\n\n- Some statements are ambiguously phrased. For instance, in the sentence “As long as it is unbiased, we can estimate its variance,” the pronoun “it” lacks a clear reference, which makes the meaning uncertain.\n\n- There is inconsistency in dataset naming across the manuscript. Datasets are referred to as “genre,” “reddit,” and “token” (e.g., Lines 379–380 and Table 1), while elsewhere the names “tgbn-trade,” “tgbn-genre,” “tgbn-reddit,” and “tgbn-token” are used.\n\n**W4.** Reproducibility: The paper does not provide the source code or specify the hyperparameter settings (e.g., learning rate, weight decay, etc.) used in the experiments, raising concerns about the reproducibility of the work.\n\n**W5.** Missing Citation: The datasets used in this work were not properly cited. I recommend that the authors include the appropriate references for each dataset, as listed in the [TGB datasets documentation](https://tgb.complexdatalab.com/docs/nodeprop/), to ensure proper attribution.\n\n---\n\n[1] Yu, Le, et al. \"Towards better dynamic graph learning: New architecture and unified library.\" *Advances in Neural Information Processing Systems* 36 (2023): 67686-67700.\n\n[2] Lu, Xiaodong, et al. \"Improving temporal link prediction via temporal walk matrix projection.\" *Advances in Neural Information Processing Systems* 37 (2024): 141153-141182.\n\n[3] Xu, Da, et al. \"Inductive representation learning on temporal graphs.\" *arXiv preprint arXiv:2002.07962* (2020).\n\n[4] Ding, Zifeng, et al. \"Dygmamba: Efficiently modeling long-term temporal dependency on continuous-time dynamic graphs with state space models.\" *arXiv preprint arXiv:2408.04713* (2024).\n\n[5] Cong, Weilin, et al. \"Do we really need complicated model architectures for temporal networks?.\" *arXiv preprint arXiv:2302.11636* (2023).\n\n[6] Bai, Lei, et al. \"Adaptive graph convolutional recurrent network for traffic forecasting.\" *Advances in neural information processing systems* 33 (2020): 17804-17815."}, "questions": {"value": "- Lines 176–177: What is the definition of $\\alpha$, and what is its range? Additionally, which distribution mean are the authors referring to in this context?\n\n- Line 169: The authors mention “non-zero for almost all nodes and batches.” Why “almost”? In what cases would the pseudo-label be zero?\n\n- Lines 172–173: The authors state that pseudo-targets are computed only for nodes participating in the current batch $B_t$. Are nodes involved in edge events also considered, or only those involved in node events?\n\n- TGBN-Token: Why does the performance peak appear around both window sizes 2–4 and 10–12, unlike TGBN-Trade and TGBN-Genre, which favour either short or long windows? Why does TGBB-token favour both?\n\n- Figure 4: This figure shows the correlation between NDCG@10 and the moving average window size for the TGNv2 model. Is the same trend observed for DyRepv2?\n\n- It is unclear why refining the training regime by retaining only the last 5% of chronologically ordered edges in the original training set is necessary. Could the authors elaborate on this choice? If all models can converge within a single epoch, why is HLA needed?\n\n- In the Order Importance Check with Target Shuffling experiment, the setup of the ablation study is not clearly explained. How are the targets shuffled? Are targets shuffled between nodes, or is the order of targets for each node shuffled?\n\n- Table 1: Why is $X = 4$ used for TGBN-Genre and TGBN-Reddit, while $X = 2$ is used for TGBN-Token?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "G7ZfBoTyHh", "forum": "M5CczpuKs0", "replyto": "M5CczpuKs0", "signatures": ["ICLR.cc/2026/Conference/Submission12619/Reviewer_WadU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12619/Reviewer_WadU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12619/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760750373838, "cdate": 1760750373838, "tmdate": 1762923466955, "mdate": 1762923466955, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the inefficiency of training Temporal Graph Networks under sparse supervision. The authors propose a lightweight pseudo-labeling approach called History-Averaged Labels (HAL), which continuously generates supervision signals for unlabeled batches by aggregating historical labels. Three variants are introduced: (1) Historical Average (HA), (2) Moving Average (MA), and (3) Persistent Forecast (PF).\n\nThe paper provides a theoretical analysis showing that label aggregation reduces gradient variance in stochastic gradient descent, leading to faster convergence by a factor of approximately min(h, k) (history length and number of classes). Empirical results on four datasets from the Temporal Graph Benchmark (TGB) demonstrate up to 13× faster training of TGNv2 and DyRepv2 without performance degradation, measured by NDCG@10."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) The paper Introduces a simple yet novel approach to handle sparse supervision in temporal GNNs via History-Averaged Labels, enabling continuous training even on unlabeled batches.\n\n2) It adapts historical averaging concepts from time-series forecasting to pseudo-labeling in dynamic graphs.\n\n3) The method is easy to integrate into existing models without architectural changes.\n\n4) Well-written, logically organized, and supported by informative figures and ablation studies.\n\n5) Addresses an important and practical bottleneck in a growing area of research."}, "weaknesses": {"value": "1) The experiments are restricted to only two architectures of similar type (TGNv2 and DyRepv2), which limits the evidence for generality. Broader testing across diverse temporal GNN frameworks would better support the “architecture-agnostic” claim.\n\n2) The fact that the method achieves strong performance using only 5% of the training data is encouraging and highlights its data efficiency. However, the presentation of this result is somewhat confusing and potentially misleading, as it is framed as a “13× faster convergence” rather than as an advantage in low-supervision settings. Clarifying that the speedup reflects data efficiency rather than pure computational acceleration would make the contribution more transparent and credible. This clarification should be explained from the beginning.\n\n\n3) The method critically relies on the assumption that node dynamics evolve slowly over time, yet this is never verified empirically. Without evidence that the assumption holds in real-world datasets, the general applicability remains uncertain.\n\n4) The paper does not compare HAL against standard pseudo-labeling or semi-supervised learning approaches. This makes it difficult to assess how much of the observed benefit comes from the temporal design versus general pseudo-supervision effects."}, "questions": {"value": "1) The theoretical section assumes convexity and independence between pseudo-labels and true labels. Could the authors clarify how these assumptions hold (or are approximated) in the context of deep non-convex models such as TGNs? A brief discussion on the limitations of the proof or its empirical verification would be useful.\n\n2) The paper assumes that node preferences evolve slowly over time. Have the authors measured or quantified this stability in the datasets (e.g., via label autocorrelation or distribution drift)? Providing such evidence would strengthen the motivation for HAL.\n\n3) The experiments only consider two architectures (TGNv2 and DyRepv2), both memory-based. Could the authors explain why other models—such as TGAT, CAW, or GraphMixer—were excluded? This would help readers assess the claimed architecture-agnostic property.\n\n4) The method performs well using only 5% of the training data, which is a notable result. However, it is presented as a “13× faster convergence” rather than as a demonstration of data efficiency. Could the authors clarify this framing and make it explicit from the start that the reported speedup is achieved in a reduced-data regime? This clarification should be explained from the beginning.\n\n5) HAL is conceptually related to pseudo-labeling approaches (e.g., self-training, label smoothing). Why were such baselines not included? A discussion or small-scale comparison would help position the method more precisely within the broader literature.\n\n[minor] \n\n6) Figure 1 illustrates only the Moving Average variant. Could the authors expand this figure or add supplementary visualizations for the Historical Average and Persistent Forecast variants to clarify their operational differences?\n\n7) The absence of code or pseudo-code limits reproducibility. Do the authors plan to release an anonymized implementation for review purposes? If not, could they explain the motivation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iyhD8Mn5wJ", "forum": "M5CczpuKs0", "replyto": "M5CczpuKs0", "signatures": ["ICLR.cc/2026/Conference/Submission12619/Reviewer_kYKi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12619/Reviewer_kYKi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12619/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761735318374, "cdate": 1761735318374, "tmdate": 1762923466524, "mdate": 1762923466524, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper, “Never Skip a Batch: Continuous Training of Temporal GNNs via Adaptive Pseudo-Supervision,” introduces a pseudo-labeling strategy for temporal graph neural networks (TGNv2, DyRep). The idea is to generate pseudo-supervision signals for unlabeled batches using historical labels, enabling continuous training when ground-truth labels are sparse. Theoretical analysis claims reduced gradient variance and faster SGD convergence, while experiments on four Temporal Graph Benchmark (TGB) datasets report significant speedups with similar accuracy.\nThe topic is relevant and the problem is practically important. However, the contribution is relatively incremental, as the proposed method mostly modifies existing TGN-based architectures by adding three pseudo-labeling variants (HAL, MA, PF). The motivation and experimental analysis require clearer support."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tPractical and timely problem. Temporal GNNs indeed suffer from sparse supervision, where many batches lack labels. Addressing this inefficiency is valuable for real-world streaming systems.\n2.\tImplementation simplicity. The proposed pseudo-labeling (HA/MA/PF) is easy to integrate into existing TGN pipelines, which enhances reproducibility.\n3.\tInitial theoretical analysis. The paper attempts to formalize the benefit of pseudo-labels through reduced gradient variance, offering a conceptual link between theory and empirical gains.\n4.\tEmpirical evidence of faster convergence. Reported 2–13× training speedups are promising, though validation is limited."}, "weaknesses": {"value": "1.\tLimited novelty. The contribution lies mainly in adding pseudo-label updates to existing temporal GNNs (TGNv2, DyRep). No new architecture, optimization mechanism, or learning paradigm is introduced. And the proposed pseudo-labeling methods are kind similar to the “Moving Average” method mentioned in paper Temporal Graph Benchmark for Machine Learning on Temporal Graphs.\n2.\tPseudo-label initialization unclear. When there is insufficient history (early timesteps), how are pseudo-labels initialized?\n3.\tLack of quantitative motivation. The claim that “most batches contain sparse labels” is not empirically demonstrated. A motivating figure or table showing label density over time would make the motivation concrete.\n4.\tPossible conflict with the prediction goal. The task predicts a node’s current-time preference, yet HAL aggregates historical labels (shown in Figure 1). For fast-changing dynamics, this could blur the current signal. \n5.\tInsufficient baselines. The comparison includes only “Default,” “Default-X,” and HAL variants. Stronger baselines (DyGFormer, NAVIS etc) exist within the TGB framework. Without them, it is unclear whether HAL provides consistent benefits. \n6.  Evaluation protocol. The experiments only use the most recent 5 % of interactions.  Would HAL still help on full datasets? Given that HAL relies on historical averaging, using a short time window may implicitly favor the method by limiting temporal drift and ensuring that historical pseudo-labels remain close to current preferences. Would HAL’s benefit diminish or vanish if the full dataset were used?  If the performance improvement disappears in that setting, it would imply that temporal GNNs like TGNv2 and DyRep already learn adequately. This would substantially narrow the scope of the proposed contribution.\n7.\tPresentation and citation issues. Missing Related Work section and lack of direct comparisons with pseudo-labeling, self-training, and temporal KG methods. Citations are incomplete and incorrectly formatted. The “General Pipeline” figure oversimplifies TGN frameworks; not all temporal GNNs follow this structure. Proper citations are required."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IWzPwRNRcQ", "forum": "M5CczpuKs0", "replyto": "M5CczpuKs0", "signatures": ["ICLR.cc/2026/Conference/Submission12619/Reviewer_hhx9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12619/Reviewer_hhx9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12619/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761793152908, "cdate": 1761793152908, "tmdate": 1762923465524, "mdate": 1762923465524, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles the problem of sparse supervision in Temporal Graph Networks (TGNs), where only a small fraction of node interactions are labeled. It proposes a history-based pseudo-labeling method that generates pseudo-targets for unlabeled batches using historical information, mainly through a Moving Average (MA) strategy. The approach allows continuous training rather than skipping unlabeled steps. The authors provide theoretical proof of faster SGD convergence and show experiments on four Temporal Graph Benchmark datasets, achieving 2–13× faster training while maintaining or improving accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a simple but effective pseudo-labeling method based on exponential moving averages of past labels. This approach reduces label sparsity and allows continuous training on temporal graphs.\n\n2. The authors provide a clear theoretical analysis proving faster SGD convergence under historical label aggregation, with a quantified improvement factor of min(h, k). This adds rigor and supports the method’s validity.\n\n3. The approach is implemented on both TGNv2 and a modified DyRep v2, showing up to 13× faster training without loss of accuracy across four benchmark datasets. This demonstrates the method’s practicality and generality."}, "weaknesses": {"value": "1. In Section 2.2, the paper states: “For each batch Bt we compute pseudo-targets only for nodes v participating in Bt.” It is unclear what “unlabeled” means for these nodes — are they naturally without supervision at this timestep, or is this due to missing ground truth? If it is the former, using historical pseudo-labels might distort the temporal dynamics of infrequent or slowly changing nodes, whose past labels may no longer represent their current state. Could this affect model stability or prediction accuracy in such cases?\n\n2. For new or long-inactive nodes, the MA and PF strategies cannot rely on any past labels. How are these cases handled — ignored, initialized uniformly, or inferred in some other way? \n\n3. Storing historical pseudo-labels for all nodes may introduce additional memory and synchronization overhead. As training progresses, this cache could grow substantially. It would be helpful to include an analysis or discussion of the memory and runtime impact of maintaining this history."}, "questions": {"value": "1. Could using historical pseudo-labels distort the behavior of infrequent or slowly changing nodes?\n\n2. How are new or long-inactive nodes handled when no past labels are available?\n\n3. Does maintaining historical pseudo-labels for all nodes add noticeable memory or runtime overhead?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "z2U592flcL", "forum": "M5CczpuKs0", "replyto": "M5CczpuKs0", "signatures": ["ICLR.cc/2026/Conference/Submission12619/Reviewer_mzER"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12619/Reviewer_mzER"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12619/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904120457, "cdate": 1761904120457, "tmdate": 1762923464339, "mdate": 1762923464339, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}