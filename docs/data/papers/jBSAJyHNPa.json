{"id": "jBSAJyHNPa", "number": 4570, "cdate": 1757708406478, "mdate": 1763126379360, "content": {"title": "Efficient Training for Human Video Generation with Entropy-Guided Prioritized Progressive Learning", "abstract": "Human video generation has advanced rapidly with the development of diffusion models, but the high computational cost and substantial memory consumption associated with training these models on high-resolution, multi-frame data pose significant challenges. In this paper, we propose Entropy-Guided Prioritized Progressive Learning (Ent-Prog), an efficient training framework tailored for diffusion models on human video generation. First, we introduce Conditional Entropy Inflation (CEI) to assess the importance of different model components on the target conditional generation task, enabling prioritized training of the most critical components. Second, we introduce an adaptive progressive schedule that adaptively increases computational complexity during training by measuring the convergence efficiency. Ent-Prog reduces both training time and GPU memory consumption while maintaining model performance. Extensive experiments across three datasets, demonstrate the effectiveness of Ent-Prog, achieving up to 2.2× training speedup and 2.4× GPU memory reduction without compromising generative performance.", "tldr": "", "keywords": ["Efficient training", "human video generation", "Progressive learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/1245087684c4cdfc9ef83f3ade0a3e3a46f2d45a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Entropy-guide prioritized progressive learning (Ent-Prog) for efficient pose-guided human video generation with diffusion. The idea is to identify the importance of each block in the model, then adopt a progressive training scheme to train from these blocks. A metric call conditional entropy inflation (CEI) is proposed to score the importance of blocks, which is defined as the entropy difference of skip the block or not. Then, according to CEI, prioritized progressive learning is adopted, which starts with the top highest priority blocks unfrozen, then progressively unfreeze more blocks in CEI order. Experiments on several datasets are conducted to shown the effectiveness of the method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The method can largely reduce the training cost and memory without quality degradation.\n\n2. The proposed CEI metric can measure the importance of each layer block."}, "weaknesses": {"value": "1. While the CEI is defined as difference of entropy, in practice it is implemented by calculating the ratio of standard deviation in a statistical way, where about 1k samples are sampled. This seems to be inaccurate and the samples are too few. In addition, the author should compare the proposed CEI with other model pruning or layer scoring methods.\n\n2. Another major concern is in experiments. There is no comparison to other competitive methods, like animate anyone, champ, stable animator, etc. Also lack the comparison to other model pruning methods comparing to CEI.\n\n3. Some results in experiments are quite weird. In Table 2, the LPIPS and FID in stage 2 are higher than in stage 1, indicating the results were getting much worse in stage 2. Why that happens?\n\n4. In all experiments, the results of full training are worse than the proposed progressive training. It seems to be a little strange, as I think the proposed method only contribute to the training efficiency, not the performance.\n\n5. As a generation work, there are no videos in supplementary material, making it hard to identify the quality of the generated videos.\n\n6. Minor (non-exhaustive): many typos, e.g. L87, L93, L95 ... Figure 4(a) ..., L176, inproves,etc."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "krrtJzRSUt", "forum": "jBSAJyHNPa", "replyto": "jBSAJyHNPa", "signatures": ["ICLR.cc/2026/Conference/Submission4570/Reviewer_irRC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4570/Reviewer_irRC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4570/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761375795974, "cdate": 1761375795974, "tmdate": 1762917447337, "mdate": 1762917447337, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "H8t1nXiNkY", "forum": "jBSAJyHNPa", "replyto": "jBSAJyHNPa", "signatures": ["ICLR.cc/2026/Conference/Submission4570/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4570/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763126378625, "cdate": 1763126378625, "tmdate": 1763126378625, "mdate": 1763126378625, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, authors propose Ent-Prog, an efficient training framework for diffusion models for pose-guided human video generation. Ent-Prog aims to reduce computational costs with CEI, which prioritizes the training of critical network blocks, with an adaptive progressive schedule that adjusts the number of unfrozen blocks based on convergence efficiency. Experiments across three human video datasets show that Ent-Prog achieves up to a 2.2× training speedup and a 2.4× GPU memory reduction while maintaining or enhancing generative performance compared to full training."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method delivers impressive practical benefits, achieving up to a 2.2× training speedup and a 2.4× GPU memory reduction. \n2. CEI is a new metric for assessing the importance of blocks. \n3. The introduction of the adaptive progressive schedule using a Nested Diffusion Supernet to dynamically select the optimal number of blocks to unfreeze based on convergence efficiency is well-motivated and demonstrates superior performance compared to simply removing the schedule."}, "weaknesses": {"value": "1. Missing CEI Distribution Analysis: The paper lacks an in-depth analysis or visualization of CEI distribution to confirm whether only a few blocks truly have high priority scores, which is crucial.\n2. Missing details of baseline\n3. Missing comparison to LoRA-based finetuning and other related works.\n4. Missing the comparison on training time (hours)\n5. How is the proposed method special for human video generation? This seems to be a general training accelration method to me.\n6. How does the proposed method generalize among different baseline methods? Authors should test the model on different base models."}, "questions": {"value": "1. Line 093/95/87: Is figure 4 actually figure 2?\n2. Since in FIgure 2 (a/b/c), blocks are randomly selected, there should be variance on the results right?\n3. See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "smqTv2fikf", "forum": "jBSAJyHNPa", "replyto": "jBSAJyHNPa", "signatures": ["ICLR.cc/2026/Conference/Submission4570/Reviewer_PNbY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4570/Reviewer_PNbY"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4570/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902078130, "cdate": 1761902078130, "tmdate": 1762917446981, "mdate": 1762917446981, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper develops an efficient fine-tuning method for the specific task of human video. It introduces CEI-based prioritized progressive learning, which quantifies the training priorities of different blocks, enabling efficient and high-quality fine-tuning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Leveraging CEI for PPL demonstrates a certain level of insight and novelty.\n- The experimental results show a significant improvement, balancing both quality and training efficiency.\n- The paper is well-organized and easy to read."}, "weaknesses": {"value": "I am concerned that there may be a critical factual error in the paper. The authors claim in line 206,207 that `Since diffusion models are trained to predict Gaussian noise, we expect the distribution of ε to be approximately Gaussian`, which is the key to applying CEI in practice. However, the epsilon-prediction in diffusion models does not follow a Gaussian distribution. On the contrary, it is highly related to the data distribution [1]. Given this, how can the authors use Eq. (2) to approximate the true CEI?\n\nThis is the main reason why I gave a rating of 4. If the authors can provide a theoretical clarification, I'm open to raising the rating.\n\n[1] Score-Based Generative Modeling through Stochastic Differential Equations\n## Questions\nCEI should be applicable to any conditional model, so the question arises whether the method presented in this paper can be generalized to other controllable generation tasks, such as camera-pose [2]. If the paper can symbolically demonstrate the method's generalizability on a toy dataset, it would significantly enhance the contribution of the work.\n\n[2] CameraCtrl: Enabling Camera Control for Video Diffusion Models"}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SibdYOu7Iq", "forum": "jBSAJyHNPa", "replyto": "jBSAJyHNPa", "signatures": ["ICLR.cc/2026/Conference/Submission4570/Reviewer_CXVX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4570/Reviewer_CXVX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4570/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977375156, "cdate": 1761977375156, "tmdate": 1762917446649, "mdate": 1762917446649, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the high computational cost of training human video generation and proposes Entropy-Guided Prioritized Progressive Learning (Ent-Prog), which estimates block importance via Conditional Entropy Inflation (CEI) to progressively unfreeze high-priority blocks and uses a Nested Diffusion Supernet to adapt the unfreezing width based on convergence efficiency. Experiments on human-video benchmarks show faster training and lower GPU memory while maintaining or improving visual quality and pose adherence."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The idea of estimating block importance and progressively unfreezing from high-priority blocks is intuitive and straightforward, and its ease of being retrofitted to existing models makes it practically useful.\n- This adaptive scheduling reduces trial-and-error, balances quality and compute under a fixed budget, and is validated by experiments, highlighting its practical utility."}, "weaknesses": {"value": "- While the paper focuses on human video generation, the proposed approach, estimating block importance and progressively unfreezing high-priority components, appears domain-agnostic. The authors should clarify what adaptations, if any, are specific to the human-video setting (e.g., choices tied to identity preservation or pose adherence). Alternatively, if the method is intended to be general, its effectiveness should be validated on additional video generation tasks beyond humans.\n- The paper reports internal baselines and ablations, but it does not compare against representative parameter-efficient tuning methods (e.g., LoRA/Adapters) or other progressive/elastic training schemes. Without side-by-side comparisons on both model performance and total training cost against these, it is difficult to conclude that the proposed method is preferable in practice. In addition, the paper lacks a clear section that situates the work relative to existing literature and articulates its advantages over prior methods.\n- The paper uses CEI to rank blocks by training priority, yet it does not provide a principled or empirical justification for why CEI, specifically, should be preferred. Figure 2 shows a correlation between CEI and loss changes when freezing blocks during training, but correlation under a shared intervention does not establish that CEI is uniquely appropriate; similar phenomena could arise for other reasonable metrics (e.g., gradient norm/energy, Fisher information, Hessian approximations, mutual information with conditioning signals, or SNR-style measures). To avoid circular reasoning, the authors should clarify the theoretical basis for adopting CEI over other metrics.\n- Several presentation issues hinder readability and reproducibility (assuming these observations are accurate):\n  - The introduction refers to “Figure 4 (a),” but Figure 4 contains no panel (a).\n  - Figure 1 is never cited in the text.\n  - CEI is mentioned in the paragraph before the paper states “we introduce CEI,” which breaks the flow of the introduction."}, "questions": {"value": "Regarding the weaknesses noted above, please respond and include additional experiments to address them."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LArB2HzNi9", "forum": "jBSAJyHNPa", "replyto": "jBSAJyHNPa", "signatures": ["ICLR.cc/2026/Conference/Submission4570/Reviewer_ZVpD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4570/Reviewer_ZVpD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4570/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762130408972, "cdate": 1762130408972, "tmdate": 1762917446280, "mdate": 1762917446280, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}