{"id": "0ACUx9pMWJ", "number": 9620, "cdate": 1758130722525, "mdate": 1759897708604, "content": {"title": "Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning", "abstract": "We run a controlled compositional generalization experiment in the ARC-AGI domain: an open-world problem domain in which the ability to generalize out-of-distribution is, by design, an essential characteristic for success. We compare neural program synthesis and test-time fine-tuning approaches on this experiment. We find that execution-guided neural program synthesis outperforms all reference algorithms in its ability to compose novel solutions. Our empirical findings also suggest that the success of TTFT on ARC-AGI lies mainly in eliciting in-distribution knowledge that the LLM otherwise fails to rely on directly.", "tldr": "Comparing the OOD generalization performance of execution-guided neural program synthesis with test-time fine-tuning on the ARC-AGI domain", "keywords": ["ARC-AGI", "Neural program synthesis", "test-time fine-tuning"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4edd49acd88859d69d21513a344c02a728179996.pdf", "supplementary_material": "/attachment/066fe09216496bc466dccf7dd77ae7519d72640a.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose to study the ability of execution-guided program synthesis approach and transduction approaches with test-time training to generalize to new ARC-AGI-like tasks at test time. Train and test tasks are designed by hand to involve different compositions of the same set of predefined primitives. \n\nOverall, the paper asks an interesting and timely question about compositional generalization in ARC-like domains and provides a well-controlled experimental setup. The execution-guided synthesis results are solid and the TTFT analysis is carefully done. However, the scope of the comparison is narrow: both methods rely on hand-crafted DSLs and synthetic data, the OOD tasks are simple, and the advantage of EG-NPS may mostly reflect its explicit search and verification loop rather than deeper generalization. The study is informative within its controlled sandbox but limited in how much it says about solving the broader ARC-AGI challenge or about generalization in pretrained LLMs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "I liked that the paper carefully controlled their experiments by designing all tasks by hand, making sure test tasks involved new combinations of primitives that were not encountered at training time.\n\nThe test-time training experiment is particularly well designed, controlling for different possible factors explaining its success in prior work.\n\nThis kind of question is interesting and deserves more investigation, and ARC-AGI might be an interesting domain to conduct such experiments."}, "weaknesses": {"value": "**Missing related work:**\n\nThe related work section (and intro) miss significant related work:\n* CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay: https://arxiv.org/abs/2402.04858v2\n* Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI: https://arxiv.org/pdf/2507.14172\n* Combining Induction and Transduction for Abstract Reasoning: https://arxiv.org/abs/2411.02272\n\n“Execution-guided, neural program synthesis has not yet been attempted”: The second paper above applies a genetic algorithm to solve ARC, with mutation operators conditioned on previous solutions and their execution feedback. In general, any LLM-based GA method (FunSearch, AlphaEvolve, etc.) is “execution-guided”. The authors seem to use a different meaning — more about search within program execution rather than post-execution feedback. Did I get this right? This should be clarified.\n\n\n\n**Test-time training and program synthesis are orthogonal**\nThe third paper above already separates program synthesis (induction) from direct generation (transduction). This axis is orthogonal to test-time training. One can have a program-synthesis model that also learns at test time (as in the last two papers above), or a transductive model without any TTT. So opposing “program synthesis” and “TTT” doesn’t seem to be the key conceptual split here.\nIn the discussion of Akyürek et al., it says “they generate tasks synthetically … that can overlap with validation data.” I think that’s fine — if a system can imagine validation-like data and improve from it, that’s still generalization. It only becomes a problem if augmentations are designed knowing the validation set.\n\n**Solving ARC-AGI ≠ recombining known primitives**\nThis paper studies recombination, but ARC-AGI itself doesn’t come with a DSL. True generalization may require inventing new operations at test time, not just reusing old ones. The DSL here can only solve ~18 ARC-AGI-2 tasks, so conclusions about full ARC-AGI generalization are limited. Moreover, the “OOD” tasks (flips, shifts, recolors) cover a narrow subset of ARC reasoning.\n\n**Dependence on hand-crafted DSL and synthetic data**\nBoth methods depend on a fixed DSL and synthetic training data. The DSL defines what “generalization” means: no new primitives can be invented. The training distribution (types of transformations, grid sizes, augmentations) also determines what counts as OOD. No ablation checks sensitivity to DSL or data design. Code and primitive lists are missing, making reproduction complicated: \n* What are the DSLs with 34 and 45 primitives?\n* What are the training tasks?\n* What are the training tasks and primitives which were added for the ARC-AGI-2 experiment, and why?\n\n**TTT interpretation**\nThe claim that TTFT only surfaces pre-existing abilities is more of an interpretation rather than demonstrated. It may simply be that pre-training + TTT together enable generalization. Without knowing the pre-training corpus of course, this can’t be verified.\nFor the same reason, the study can’t say much about LLM-based program-synthesis methods that rely on large pretrained models (like the ones developed in the two last papers of the above list): these would be hard to train from scratch under a controlled setup.\n\n**Other points**\nThe claim that humans solve these tasks should be supported by data (e.g. http://arxiv.org/pdf/2409.01374). Can any human solve them, or at least some? I think in ARC-AGI 2 it’s more of “out of a group of N, at least 2 can solve the task”."}, "questions": {"value": "* What exactly is meant by “open-world” in this context? ARC-AGI seems quite closed in scope.\n* What are the different DSL and training tasks?\n* Could the observed advantage of EG-NPS be mostly due to its explicit search and verification loop, which the TTT baselines can’t really do?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0ka5y62Il9", "forum": "0ACUx9pMWJ", "replyto": "0ACUx9pMWJ", "signatures": ["ICLR.cc/2026/Conference/Submission9620/Reviewer_dP2F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9620/Reviewer_dP2F"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9620/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760967031603, "cdate": 1760967031603, "tmdate": 1762921157858, "mdate": 1762921157858, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates out-of-distribution (OOD) generalization on the ARC-AGI benchmark by comparing execution-guided neural program synthesis (EG-NPS) with test-time fine-tuning (TTFT). The authors introduce a novel EG-NPS algorithm alongside a custom domain-specific language (DSL). Through controlled experiments, EG-NPS significantly outperforms non-execution-guided methods and TTFT on a series of experimental setups. The results demonstrate that execution-guided synthesis enables stronger compositional reasoning and more robust OOD generalization than fine-tuning-based approaches in the ARC-AGI domain."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is overall well-written: \n- Focus on compositional and OOD generalization.\n- Novel tree search algorithm for execution-guided neural program synthesis.\n- Diverse empirical setups: include baselines and ablations."}, "weaknesses": {"value": "The paper’s main weaknesses include scale, scope, and generalizability of the experiments:\n- Requires ground-truth programs as training data.\n- Requires a DSL, and the implemented one is very limiting.\n- Limited scale and empirical scope: for instance, experiments on ARC-AGI include only 18 tasks out of the 1000+ available.\n- Other fully neural baselines could have been tested against: e.g., [Ouellette, 2024] or [Bonnet & Macfarlane, 2024]."}, "questions": {"value": "How would you think of scaling the proposed approach? Suggesting a few directions for future work could improve the paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7qUgrLkTWn", "forum": "0ACUx9pMWJ", "replyto": "0ACUx9pMWJ", "signatures": ["ICLR.cc/2026/Conference/Submission9620/Reviewer_RKf8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9620/Reviewer_RKf8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9620/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947607875, "cdate": 1761947607875, "tmdate": 1762921157490, "mdate": 1762921157490, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper target the problem of solving out-of-distribution (OOD) tasks in the ARC-AGI-2 visual reasoning benchmark. The approach extends the line of work on execution-guided program synthesis with an approach the paper calls EG-NPS. It uses a simple DSL which integrates with a standard encoder-decoder transformer as the program generator. The idea is to generate instructions and to partially evaluate them, exposing both of these as execution trace to program generator. This informs the search procedure, which is a tree search with tunable randomness, to complete the program that reaches the end goal. The system is trained on ground truth programs that successfully solve some task. The evaluation is on different tasks in the same visual domain. \n\nThe experiments compare with other competing approaches which do not carry all the features of EG-NPS. The results show significant gains on 7 task that were evaluated during tests."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is well written and explains enough details to understand the distinction to prior approaches.\n\n* The ablation study is focused and explains where EG-NPS improves over prior works evaluated.\n\n* The gains on the programs evaluated in success rate are significant. The approach solves about 83% of the few (1.5%) of ARC-AGI-2 tasks within scope of the current DSL considered in the work.\n\nThe paper's proposed methods combines a number of pre-existing ideas, but in a systematic way. The analysis and design of experiments is performed carefully to understand where the gains are coming from."}, "weaknesses": {"value": "* The paper is relatively weak on explaining how the expressiveness of the DSL is a stumbling block to a broader evaluation. The paper briefly mentions in Section 6.4 that the DSL had to expanded to deal with just 1.5% of ARC-AGI-2 benchmarks. It is known that the search space explodes and there is work characterizing the input-output samples needed therein. Please see the work by Wang et al. [a]. It will be useful if the paper talks about the issue of DSL design, state explosion, and expected sample complexity.\n\n* The paper is scoped to a particular benchmark. While this is a completely reasonable way to devise a better program synthesis technique, the resulting ideas are in no way restricted to visual tasks. Clearly the tree-search method, transformer for synthesis, equipped with a DSL can be targeted to other real-world tasks. Did you consider evaluating your proposed methods on any other non-ARC-AGI-2 task? For example, you could take a standard DSL (e.g. FlashFill), architectural instruction set, or any other minimal programming language and try to solve coding tasks. This kind of experiments reduce the risk of ideas being overfit to a benchmark or set of tasks.\n\n* The paper references Lavon et al. (2025). This is execution-guided technique too. I understand that EG-NPS is targeting ARC-AGI-2, but at the technical level both are execution-guided techniques. As such, it would be useful to see a comparison on common benchmarks. To understand the advance presented by EG-NPS, it is useful to run it on Lavon et al.'s evaluated benchmarks.\n\n[a] \"SynGuar: Guaranteeing Generalization in Programming by Example\", Wang et al., In ESEC/FSE 2021: Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering."}, "questions": {"value": "Questions are raised in the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cLTuQKHk1M", "forum": "0ACUx9pMWJ", "replyto": "0ACUx9pMWJ", "signatures": ["ICLR.cc/2026/Conference/Submission9620/Reviewer_2M9h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9620/Reviewer_2M9h"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9620/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998389757, "cdate": 1761998389757, "tmdate": 1762921157167, "mdate": 1762921157167, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper considers compositional generalization within the the ARC-AGI domain. The authors demonstrate that execution-guided program synthesis performs best, beating out other neural program synthesis approaches as well as test-time fine-tuning of LLMs. To achieve this, the authors developed a DSL for the ARC-AGI domain."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Compositional generalization is an important yet underexplored problem. The setup the authors considered in ARC-AGI will be generally useful for evaluating compositional generality of future approaches. \n\n2. The authors demonstrate that fine-tuning is primarily useful for unlocking latent in-distribution knowledge and not OOD generalization. This is an interesting finding as such fine-tuning approaches are very popular in practice.\n\n3. The authors develop (to my knowledge) the first instance of execution-guided neural program synthesis for the ARC-AGI domain with its own DSL. This will be a useful baseline to compare against for this benchmark."}, "weaknesses": {"value": "1. While execution-guided program synthesis is proven to be effective at compositional generalization, its applicability seems to be limited due to the requirement of designing a DSL that covers all theoretically solvable tasks. In particular, the DSL the authors designed does not cover the full scope of ARG-AGI tasks. So it is unclear how useful such approaches will be in general. \n\n2. The entropy term added to search did not seem particularly effective. It is unclear if the search algorithm implemented was suboptimal.\n\n3. Furthermore, my understanding is that neural program synthesis and fine-tuning consider very different test-time search algorithms. This makes the results a bit more difficult to parse, as it is unclear how important the choice of search algorithm was."}, "questions": {"value": "1. Have the authors considered training neural program synthesis from a pretrained LLM rather than from scratch? While one would expect it to not make much of a difference, it would be nice to disentangle the base architecture from the training algorithm. \n\n2. If I understand correctly, the other neural program synthesis approach GridCoder uses a different DSL than EG-NPS. What would happen if the DSL used between the two approaches were the same?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XXoFlgDP50", "forum": "0ACUx9pMWJ", "replyto": "0ACUx9pMWJ", "signatures": ["ICLR.cc/2026/Conference/Submission9620/Reviewer_ocig"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9620/Reviewer_ocig"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9620/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762308056473, "cdate": 1762308056473, "tmdate": 1762921156934, "mdate": 1762921156934, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}