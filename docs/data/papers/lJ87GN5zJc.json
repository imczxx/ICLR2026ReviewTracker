{"id": "lJ87GN5zJc", "number": 19849, "cdate": 1758299957500, "mdate": 1759897016017, "content": {"title": "Graph Diffusion Transformers are In-Context Molecular Designers", "abstract": "In-context learning  lets large models adapt to new tasks from a few demonstrations, but it has shown limited success in molecular design, where labeled data are scarce and properties span millions of biological assays and material measurements. We introduce demonstration-conditioned diffusion models (DemoDiff), which define task contexts through molecule–score examples instead of texts. These demonstrations guide a denoising Transformer to generate molecules aligned with target properties.  For scalable pretraining, we develop a new molecular tokenizer with Node Pair Encoding that represents molecules at the motif level, requiring 5.5$\\times$ fewer nodes. We pretrain a 0.7B parameter model on datasets covering drugs and materials. Across 33 design tasks in six categories, DemoDiff matches or surpasses language models 100–1000$\\times$ larger and achieves an average rank of 3.63 compared to 5.25–10.20 for domain-specific approaches. These results position DemoDiff as a molecular foundation model for in-context molecular design.", "tldr": "", "keywords": ["Inverse Molecular Design", "In Context Learing", "Diffusin Models", "Transformers"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/faa18d0d09f92d6b045fb18096cc344bbd3fa41c.pdf", "supplementary_material": "/attachment/a29dbf55870ae0c7a141c326e146c3541531d9bb.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a new paradigm for molecular design, named DemoDiff, which combines in-context learning with graph diffusion models to tackle property-guided molecular generation. The authors' core idea is to use molecule-property score pairs (demonstrations) to define a task, guiding a Graph Diffusion Transformer during the generation process. To support this framework, the paper also designs Node Pair Encoding, which compresses molecules from the atom level to the motif level, significantly increasing the context length the model can handle. This work is novel in its conception and experimentally thorough, demonstrating its potential as a foundation model for molecular design."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- A Novel and Inspired Framework: The idea of using \"demonstrations\" as a condition to guide a diffusion model is highly inspiring. DemoDiff dynamically defines the task context through molecule-score pairs, which is not only more flexible and scalable but also enables the model to learn and generalize to new, data-scarce tasks. \n- An Efficient and Innovative Graph Tokenizer: NPE is a purely data-driven motif learning algorithm that adaptively discovers high-frequency patterns from the pre-training data. Experiments show that this method achieves an average compression ratio of 5.5x , which directly supports the conclusion that the model performs better with longer contexts.\n- Comprehensive and In-depth Experimental Evaluation: The paper conducts a comprehensive test on 33 tasks across 6 major categories, including drug and materials design. It compares DemoDiff against 13 baselines, including traditional optimization algorithms, conditional generation models, and even general-purpose large language models with 100-1000x more parameters."}, "weaknesses": {"value": "- Regarding Consistency Score: According to the appendix, the core performance metrics (Table 1) are not derived directly from DemoDiff's output but are obtained by first generating 1000 candidates and then using the consistency score to filter for the top 100 for evaluation. This introduces a significant confounding variable, making it impossible to determine the model's inherent generative capability. Also, Figure 5 shows this score has a very low correlation with the true oracle score for key tasks like Drug MPO and Materials Design (correlation coefficient close to 0), which questions its validity as an effective filtering metric.\n- NPE Tokenizer's Robustness and Limitations: While the paper showcases the excellent compression efficiency of the NPE tokenizer, one of its core contributions, it fails to discuss its performance when handling rare chemical motifs or molecules that deviate significantly from the pre-training data distribution. As a component intended to be the core of a foundation model, its reliability in out-of-distribution (OOD) scenarios is crucial. Furthermore, the claim of \"lossless reconstruction\" remains a qualitative description, lacking quantitative reconstruction accuracy metrics on a standard dataset, which makes it difficult to assess its reliability."}, "questions": {"value": "1. Regarding model scaling (Table 2), the data shows that for the \"Structure Constrained\" task, the small (78M) and medium (311M) models outperform the large (739M) model (0.59/0.63 vs. 0.56). This contradicts the paper's conclusion that \"the benefits of parameter scaling become more evident at the large scale\". How do you explain this performance degradation? \n2. The core advantage of ICL is its ability to generalize to new tasks with few shots. The paper states that the 33 evaluation tasks are distinct from the pre-training data. However, given the scale of the pre-training data, I am concerned about the degree of this distinctness. To what extent are the chemical spaces, property targets, or molecular scaffolds in the evaluation tasks truly unseen during pre-training? \n3. In the baseline comparison, the paper includes general-purpose LLMs like GPT-4O but does not compare against LLMs pre-trained on chemical texts or molecular sequences (e.g., SMILES), which possess domain-specific knowledge. Why were these models not included in the comparison?\n4. The introduction states that directly applying the autoregressive framework of LLMs is \"infeasible\", thus justifying the choice of GraphDiT as the backbone. However, molecules can be represented as sequences like SMILES or SELFIES, and some baselines are indeed based on them. Is there any evidence to support that GraphDiT is superior to a powerful Transformer decoder trained on SMILES sequences within this ICL framework?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Fl7nTnB7PC", "forum": "lJ87GN5zJc", "replyto": "lJ87GN5zJc", "signatures": ["ICLR.cc/2026/Conference/Submission19849/Reviewer_WQjW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19849/Reviewer_WQjW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19849/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761012381708, "cdate": 1761012381708, "tmdate": 1762932022590, "mdate": 1762932022590, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Through this paper, the authors propose DemoDiff, a demonstration-conditioned diffusion model that has a Graph DiT as the backbone, to construct a molecular generative model under in-context learning. In addition, the authors also propose a molecular tokenizer trained with Node Pair Encoding (NPE) for motif-level representation to support efficient pretraining of DemoDiff."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The authors provided the codebase.\n- The introduction of a motif-level tokenizer using Node Pair Encoding, which reduced the node count by 5.5×, is a reasonable approach in terms of both efficiency and performance.\n- The proposed DemoDiff was evaluated across 33 design tasks spanning 6 categories, achieving SOTA performance in most of them."}, "weaknesses": {"value": "Weaknesses\nI will combine the *Weaknesses* section and the *Questions* section. My concerns are as follows:\n- There is little discussion on how sensitive the demonstration/context selection is to performance and how well the derived context applies to diverse new tasks.\n- SOTA molecular optimization baselines such as GenMol [1] and Genetic GFN [2] are missing. Comparisons with these baselines are necessary for the results to be considered meaningful.\n- No computational or memory efficiency was reported. This would be an effective method to demonstrate that the proposed DemoDiff is more efficient compared to larger generalist LLMs.\n\n---\n\n**References:**\n\n[1] Lee et al., GenMol: A Drug Discovery Generalist with Discrete Diffusion, ICML 2025.\n\n[2] Kim et al., Genetic-guided GFlowNets for Sample Efficient Molecular Optimization, NeurIPS 2024."}, "questions": {"value": "Please see the *Weaknesses* section for my main concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wRi6dyHHkx", "forum": "lJ87GN5zJc", "replyto": "lJ87GN5zJc", "signatures": ["ICLR.cc/2026/Conference/Submission19849/Reviewer_t5zC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19849/Reviewer_t5zC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19849/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761447233824, "cdate": 1761447233824, "tmdate": 1762932022147, "mdate": 1762932022147, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel molecular design framework, DemoDiff, which integrates diffusion models with in-context learning. By introducing a Node Pair Encoding (NPE) tokenizer for molecular graphs, the model achieves efficient pretraining with motif-level representations. A 0.7B-parameter model is pretrained on large-scale, multi-task data covering 155K properties and millions of molecules. DemoDiff achieves an average rank of 3.63 across 33 molecular design tasks, outperforming ten baseline models and several LLMs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. DemoDiff implicitly embeds task information into the diffusion denoising process. The proposed Node Pair Encoding (NPE) is a substantive contribution to molecular graph tokenization, eliminating the need for handcrafted reaction rules and enabling automatic motif discovery.\n2. Extensive evaluation on 33 tasks demonstrates that DemoDiff significantly outperforms both domain-specific baselines and ICL-based LLMs. Despite having only 0.7B parameters, the model matches or even surpasses general-purpose LLMs.\n3. The paper provides detailed descriptions of the pretraining task design, motif tokenizer, context consistency score, and diffusion inversion inference. The experiments offer comprehensive analyses of parameter scale, context length, positive/negative sample ratios, and consistency filtering."}, "weaknesses": {"value": "1. Lack of theoretical analysis. Although the paper mentions an implicit Bayesian interpretation, it lacks formal proofs or theoretical analysis on how the diffusion trajectories reflect “posterior inference of task concepts.” The comparison with ICL in language models remains largely analogical, without quantitative or interpretable mechanism-level parallels.\n2. Potential bias in data and task construction.\n- The pretraining tasks mainly rely on ChEMBL and polymer datasets, whose property distributions are highly skewed (Zipf-like). While the authors claim this facilitates ICL ability, no systematic study is provided on the relationship between task frequency and generalization performance.\n- The oracle evaluation for generation tasks depends on human scoring and predictor models, which may introduce noise.\n3. Insufficient validation of NPE’s chemical semantic consistency. The paper lacks statistical verification of motif interpretability or chemical validity. Although DemoDiff outperforms Graph-DiT, no strictly fair comparison (e.g., controlled parameter size or identical token count) is presented.\n4. High pretraining cost. The work lacks small-scale, reproducible experiments or an ablation-only release."}, "questions": {"value": "1. What does the “Total sum” represent — which scores are included in this total? In Eq. 6, what is the function denoted by T?\n2. The authors interpret DemoDiff’s in-context learning as implicit Bayesian inference. Could this interpretation be validated via attention pattern or diffusion trajectory visualizations?\n3. NPE is a frequency-driven motif discovery algorithm. Do these automatically learned motifs correspond to known chemical functional groups or reaction fragments? How well does NPE generalize to out-of-distribution (OOD) chemical spaces? PRODIGY [1] also applies in-context learning on graphs — please provide a comparison.\n4. The authors mention that the property distribution follows Zipf’s law (Figure 3a). Has the effect of this long-tailed distribution on the model’s ICL ability been evaluated? Does DemoDiff maintain strong performance on low-frequency property tasks? Since the number of examples per assay is imbalanced, could this lead to training bias toward high-frequency tasks?\n5. The authors use consistency score and related metrics. Could evaluation be extended to include metrics more closely tied to molecular properties, such as QED or SA score?\n\nReference:\n\n[1] PRODIGY: Enabling In-context Learning Over Graphs"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MCmgmDxJAA", "forum": "lJ87GN5zJc", "replyto": "lJ87GN5zJc", "signatures": ["ICLR.cc/2026/Conference/Submission19849/Reviewer_Nsot"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19849/Reviewer_Nsot"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19849/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761616421575, "cdate": 1761616421575, "tmdate": 1762932021419, "mdate": 1762932021419, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose DemoDiff, a generative model that uses molecule-score examples for in-context molecular design. The authors also develop Node Pair Encoding (NPE), a strategy to represent molecules at the motif level, which requires 5.5x fewer nodes on average. DemoDiff achieves impressive performance across 33 molecular design tasks spanning 6 categories."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The proposed NPE reduces the number of nodes by 5.5x, which is impressive and is a generally useful contribution even outside the context of DemoDiff. \n- The proposed in-context learning approach is novel and a unique contribution to the ML molecular design literature \n- DemoDiff demonstrates promising results on the drug/material design categories and is able to generate more diverse samples than baseline methods\n- The authors provide extensive ablation and case studies"}, "weaknesses": {"value": "I am not very convinced by the main experimental results and I think Table 1 is somewhat misleading. Firstly, it is a bit unfair to compare to LLMs given that DemoDiff is trained on >1M molecule-property pairs and LLMs are not designed for this specific task. A more fair comparison would be to finetune the LLMs to do in-context molecule generation in the same way as DemoDiff. Secondly, and more importantly, after looking at the results in the Appendix, it appears that DemoDiff only achieves SOTA performance on 13 out of the 33 tasks (based on the Top-10 Harmonic Mean results). In particular, outside the drug/material design categories, DemoDiff does not reliably outperform baseline LLMs. Given that DemoDiff success is limited to a small subset of tasks it is difficult to support the claim that this is a generalizable method."}, "questions": {"value": "LLMs are not necessarily trained to do in-context learning or to do molecular design, which makes it difficult to compare to your proposed method which is trained on a large and specialized dataset of molecule-spectra pairs. Did the authors consider finetuning LLMs to do in-context molecular design on the same dataset used for DemoDiff pretraining? Do you think DemoDiff would outperform such a finetuned LLM?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zQweiYhvci", "forum": "lJ87GN5zJc", "replyto": "lJ87GN5zJc", "signatures": ["ICLR.cc/2026/Conference/Submission19849/Reviewer_aBww"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19849/Reviewer_aBww"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19849/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761701807750, "cdate": 1761701807750, "tmdate": 1762932020915, "mdate": 1762932020915, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces a conditional generative model for molecules based on a graph diffusion transformer.\nTo reduce the context size, atoms are grouped together using a BPE-like algorithm adapted to graphs.\nConditioning is done by using pairs of molecules with normalised scores as _property_ inputs to the graph diffusion transformer.\nExperiments on a dataset extracted from ChEMBL and a collection of polymer datasets show favourable performance in terms of oracle and diversity scores."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Overall, the paper is well written.\n - Most reported results come with error bars.\n - Reported results seem to be competitive.\n - Being able to control molecule generation on activity levels seems relevant."}, "weaknesses": {"value": "- The proposed node pair encoding feels similar in spirit to how (extended connectivity) fingerprints are computed.\n   However, the relation to these possibly related methods seems to be underexplored in the current version of the manuscript.\n   It would be good to have an explanation how NPE is similar/different from fingerprint computations.\n   If there is enough similarity, also an empirical verification of NPE vs fingerprint features would be meaningful.\n   I also feel that NPE has some similarities with virtual nodes used in some GNNs (e.g. Hwang et al., 2022).\n   A discussion on possible similarities/differences in this regard might be useful as well.\n - There is little to no motivation on why molecular graphs are used instead of e.g. SMILES.\n   I have often heard that GNNs bring little to no performance advantage over working with SMILES (e.g. Renz et al., 2024).\n   Furthermore, GNNs are typically much more complex to work with than models that work with SMILES.\n   Given that the core Graph DiT idea seems transferrable to non-graph architectures as well,\n   it would have been interesting to investigate how important the _graph_ aspect of this model is.\n - It is not entirely clear how strong the provided baselines are.\n   Most notably, there is little information on how the LSTM was used to operate on the NPE encodings.\n   Also, it seems hard to imagine that there are no more specialised models that are able to generate molecules in-context.\n   Especially in the context of autoregressive SMILES generation (e.g. Renz et al., 2024; Schmidinger et al., 2025)\n - Figure&nbsp;2 confuses me more than it helps me to understand the method.\n   I understand that molecules are encoded by grouping sub-structures,\n   but there is no explanation for what $S_\\mathrm{ingle}$ is supposed to be,\n   or what the digits in the brackets are supposed to mean.\n   Furthermore, the inputs ($[?, S0]$ and $[?, S5, S4, S7]$) to the transformer,\n   which I would have assumed are on top of the demo tokens,\n   seem to be the sub-motifs from the tokenized molecule illustrated to the right.\n   However, this tokenized molecule should be part of the demo tokens.\n   This all seems to make little sense and is hard to connect to the explanations in the main text.\n\n### Minor Issues\n - The expression \"molecule-assay pair\" (line 257) seems to be a bit weird.\n   Could it be that you mean \"molecule-activity pair\",\n   i.e., a molecule with its activity value for a particular assay (a.k.a. the context)?\n - In the main text (line 302) _10_ novel, unique and valid molecules are mentioned for evaluation,\n   but in the appendix, line 1054 mentions _100_ molecules for evaluation.\n - Table&nbsp;1 is claimed to report two scores (oracle and diversity),\n   but there is only a single value for each model-task combination.\n\n### Additional References\n - Hwang et al. (2022). [An analysis of virtual nodes in graph neural networks for link prediction](https://openreview.net/forum?id=dI6KBKNRp7). In The first learning on graphs conference.\n - Renz et al. (2024). [Diverse hits in de novo molecule design: Diversity-based comparison of goal-directed generators](https://pubs.acs.org/doi/full/10.1021/acs.jcim.4c00519). Journal of Chemical Information and Modeling, 64(15), 5756-5761.\n - Schmidinger et al. (2025). [Bio-xLSTM: Generative modeling, representation and in-context learning of biological and chemical sequences](https://openreview.net/forum?id=IjbXZdugdj). International Conference on Learning Representations."}, "questions": {"value": "1. Is there any/What is the relation between NPE and the computation of molecular fingerprints?\n 2. Is there any/What is the relation between NPE and the use of virtual nodes (cf. Hwang et al., 2022) in GNNs?\n 3. Could the proposed model architecture also work with non-graph (e.g. SMILES) inputs?\n 4. How was the LSTM applied to the NPE-encoded graphs?\n 5. Are there no other (e.g. SMILES-based) specialised generative models that could be used as baselines?\n 6. Can you explain what is happening in Figure&nbsp;2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "QqYC8uQ5gC", "forum": "lJ87GN5zJc", "replyto": "lJ87GN5zJc", "signatures": ["ICLR.cc/2026/Conference/Submission19849/Reviewer_v13C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19849/Reviewer_v13C"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission19849/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762018913526, "cdate": 1762018913526, "tmdate": 1762932020260, "mdate": 1762932020260, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}