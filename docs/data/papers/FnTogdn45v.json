{"id": "FnTogdn45v", "number": 399, "cdate": 1756738048549, "mdate": 1763700393546, "content": {"title": "Deceptive Humor: A Synthetic Multilingual Benchmark Dataset for Bridging Fabricated Claims with Humorous Content", "abstract": "In the evolving landscape of online discourse, misinformation increasingly adopts humorous tones to evade detection and gain traction. This work introduces Deceptive Humor as a new research direction, emphasizing how false narratives, when coated in humor, become more difficult to detect and more likely to spread. To support research in this space, we present the Deceptive Humor Dataset (DHD), a multilingual collection of humor-infused comments derived from fabricated claims using the ChatGPT-4o model. Each entry is annotated with a Satire Level (from 1 for subtle satire to 3 for overt satire) and categorized into five humor types: Dark Humor, Irony, Social Commentary, Wordplay, and Absurdity. The dataset spans English, Telugu, Hindi, Kannada, Tamil, and their code-mixed forms, making it a valuable resource for multilingual analysis. Building on this foundation, we propose DH-MTL (Deceptive Humor Multi-Task Learning), a lightweight neural framework that jointly models satire intensity and humor type through a two-stage training pipeline that first adapts the encoder to deceptive humor patterns and then refines task-specific reasoning. Together, DHD and DH-MTL establish both a benchmark resource and a methodological baseline for studying how false narratives are framed, normalized, or obscured through humor.", "tldr": "The Deceptive Humor Dataset (DHD) is a 9K-sample synthetic multilingual benchmark of humor-infused comments tied to fabricated claims, introducing a new research direction at the intersection of humor and misinformation.", "keywords": ["Deceptive Humor Detection", "Multilingual Benchmark Dataset", "Humor-Driven Misinformation"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/15c7d80d60ab6190c270235a8c3a4ff3a3a45c56.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces the Deceptive Humor Dataset (DHD), a multilingual corpus designed to study the intersection of humor and misinformation through two discriminative tasks: satire intensity prediction and humor attribute classification. It employs large language models to generate humorous variations of false claims and incorporates human evaluation to assess quality and coherence. To model the tasks, the authors propose a multi-task learning framework (DH-MTL) that integrates ordinal regression for satire levels, label smoothing and entropy regularization to handle ambiguity, and contrastive learning to structure humor representations. The study presents quantitative and qualitative analyses demonstrating the framework’s performance across humor-related subtasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper presents a well-constructed dataset that defines two discriminative tasks: satire intensity prediction and humor attribute classification, with human-in-the-loop evaluation and multilingual coverage\n2. The inclusion of contrastive learning within the loss objective is a thoughtful and interesting design choice, reflecting the authors’ insight into structuring humor representations."}, "weaknesses": {"value": "1. Although the paper’s main motivation is to bridge the gap between humor and misinformation research, the evaluation focuses solely on humor-related subtasks (satire intensity and humor type) without testing whether models trained on the dataset can actually detect or reason about misinformation. Without experiments on factuality or false claim recognition, it remains unclear whether the dataset truly advances misinformation detection or merely adds a humor annotation layer on top of existing fake claims.\n2. Since the dataset is entirely generated by safety-aligned LLMs, the resulting humor is likely less offensive but also less natural than real-world humor. The linguistic patterns, cultural cues, and humor-misinformation dynamics may also not accurately reflect real-world misinformation humor. While Appendix G includes human evaluations of humor quality, there are no human-written or real-world baselines for comparison, making the reported scores difficult to interpret. A comparison against genuine human-authored deceptive humor would better support the claim that the dataset achieves both linguistic fluency and authentic humor style.\n3. The proposed DH-MTL model combines multiple losses (ordinal regression, label smoothing, contrastive, and entropy regularization), each with its own weighting coefficient. However, the absence of hyperparameter sensitivity studies leaves uncertainty about how robust the approach is. The approach risks appearing as a collection of heuristics rather than a cohesive, well-justified modeling design.\n4. Both proposed tasks are discriminative classification problems, which limits the broader applicability of the framework. In the current LLM-driven era, incorporating generative or reasoning-based tasks such as generating humorous deceptive claims, explaining humor mechanisms, or verifying factuality, would provide stronger evidence of the dataset’s practical value. Without such generative evaluations, the contribution feels constrained to traditional supervised settings rather than aligned with contemporary language model capabilities."}, "questions": {"value": "1. Humor is inherently human-grounded and context-dependent. Could the authors clarify why they believe that LLM-generated deceptive humor examples pose potential harm or real-world impact? Given that these examples are synthetic and produced by safety-aligned models, it would be helpful to understand the rationale or evidence supporting their claim that such content could meaningfully affect human perception or misinformation spread.\n2. The appendices contain critical details about dataset construction, annotation design, and statistical distributions that are essential to fully understanding the work. Would the authors consider integrating some of these methodological insights and statistics into the main text, rather than treating them as supplementary material?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XCPv0QVDLJ", "forum": "FnTogdn45v", "replyto": "FnTogdn45v", "signatures": ["ICLR.cc/2026/Conference/Submission399/Reviewer_rXsS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission399/Reviewer_rXsS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761533786574, "cdate": 1761533786574, "tmdate": 1762915511537, "mdate": 1762915511537, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces an important area of research in deceptive humor detection, but it has several weaknesses that could affect the practical application and broader adoption of its findings. Addressing issues with dataset generalization, clarity in task definitions, and model evaluation would significantly strengthen the paper's contributions. Additionally, expanding on the ethical and societal implications of using such models in real-world settings would offer a more rounded perspective on the potential consequences of deceptive humor in online discourse."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper introduces two primary tasks: Satire Intensity Classification and Humor Attribute Classification.\n- The paper briefly touches on ethical concerns related to using synthetic humor that embeds deception. While the data is restricted to academic research, it doesn’t delve into the potential real-world harms of misusing this data, such as generating harmful, politically charged misinformation disguised as humor .\n- The paper provides some examples of misclassifications. More in-depth discussion on why certain humor forms (such as indirect satire) are particularly challenging would be beneficial for understanding how to better train models ."}, "weaknesses": {"value": "- The paper makes extensive use of synthetic data generated by the ChatGPT-4o model to create the Deceptive Humor Dataset (DHD). While this approach is innovative and necessary due to the elusiveness of deceptive humor in natural settings.  The paper mentions several languages, but the evaluation of models on code-mixed and non-English datasets (e.g., Hindi, Telugu) shows that performance significantly drops. The claim that the synthetic dataset is fully representative of real-world humor across languages is weak given these disparities .\n- The Humor Attributes (e.g., irony, absurdity, social commentary, dark humor, and wordplay) are well-defined, but the paper does not offer enough clarity or justification regarding the overlaps between them. For instance, humor types like absurdity and social commentary, which can share similar characteristics, often lead to classification errors in the experiments. The model struggles to distinguish them, suggesting that the categories might be too broad or not sufficiently defined .\n- The evaluation of different models (small and large language models) highlights some significant limitations in generalizing deceptive humor detection, The results show that even state-of-the-art models, including LLaMA and Qwen, struggled with detecting deceptive humor, particularly in zero-shot settings. While this is to be expected, the paper could further discuss the reasons why models underperform, particularly in non-English or code-mixed languages .\n- The paper claims that models should identify varying levels of satire, but it doesn't provide clear guidelines on how models can handle satire that relies on cultural or societal context. The Satire Level Classification may require additional clarifications or examples to make it more accessible and effective ."}, "questions": {"value": "see the Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0y7EBbAUXy", "forum": "FnTogdn45v", "replyto": "FnTogdn45v", "signatures": ["ICLR.cc/2026/Conference/Submission399/Reviewer_8CL2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission399/Reviewer_8CL2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761734276857, "cdate": 1761734276857, "tmdate": 1762915511413, "mdate": 1762915511413, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Overall, the paper presents the DHD dataset, exploring how misinformation can be conveyed through humor. However, the defined tasks Satire Level and Humor Attribute only focus on humor characterization rather than detecting misinformation within humor, creating a conceptual gap."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.The multilingual setting is novel for me.\n\n2. The constructed dataset maybe useful for this community."}, "weaknesses": {"value": "However, there is no empirical evidence or real-world example provided in the paper, which makes the motivation unconvincing. There is no discussion about the potential geographical and cultural biases since the data sources are all India-based. In addition, no existing humor classification models are included in the baselines. The baseline comparison is unfair that the LLMs used in baselines are small-scale models, while the DHD dataset is generated by ChatGPT-4o. Specifically,\n\n1.\tThe overall motivation of the paper is that misinformation increasingly adopts humorous forms to evade detection. However, the proposed 2 tasks (Satire Level and Humor Attribute) seem misaligned with this motivation. These tasks primarily capture the style or intensity of humor, rather than assessing whether a model can recognize and detect misinformation when humor is present, which is the key challenge implied by the motivation.\n\n2.\tThe topic and setting of this work is interesting but the motivation is insufficiently substantiated in the paper. It would strengthen the paper if the authors could provide empirical evidence or examples demonstrating that humorous framing is indeed becoming a dominant or growing trend in misinformation dissemination.\n\n3.\tSince the proposed DHD is entirely generated by ChatGPT-4o, there is a potential concern regarding the representativeness of the data. AI-generated humor and deception might differ from how humans naturally produce humorous misinformation in real-world online contexts. Discussions of the differences between the synthetic data and a small sample of real-world humorous misinformation (e.g., from previous datasets) can strengthen the empirical credibility of the work.\n\n4.\tWhile the data collection procedure described in Section 3.1 is systematic and well motivated, it should be noted that all the fact-checking sources (mentioned as AltNews, Boom FactCheck, FactChecker.in, and FACTLY) are India-based organizations. This geographical and cultural concentration may introduce potential bias in the identification and interpretation of fake narratives, especially in politically sensitive domains. Differences in cultural context, linguistic framing, and national political perspectives could affect how misinformation is labeled or interpreted.\n\n5.\tWhile the paper evaluates several LLMs, it does not include comparisons with existing humor detection or humor classification models as similar with the proposed task Humor Attribute, such as Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis and The Naughtyformer: A Transformer Understands Offensive Humor.\n\n6.\tIn Section 5 (line 355), the authors claim that LLMs face significant challenges in classifying humorous content, highlighting the performance of proposed DH-MTL. However, this claim appears methodologically inconsistent with the dataset construction process: all instances in DHD are generated by LLM ChatGPT-4o. The paper does not address how the potential limitations of the generative model might bias or constrain the humor representations in DHD. In addition, the baselines only involve relatively small-scale models (up to 3B parameters). Given that DHD is generated using a much larger LLM (ChatGPT-4o), the fairness and informativeness of the comparison are questionable. It remains unclear whether the observed performance gaps reflect genuine task difficulty or simply the limited capacity of smaller baselines."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["Yes, Discrimination / bias / fairness concerns", "Yes, Privacy, security and safety", "Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)", "Yes, Potentially harmful insights, methodologies and applications", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LIgjZHZhI4", "forum": "FnTogdn45v", "replyto": "FnTogdn45v", "signatures": ["ICLR.cc/2026/Conference/Submission399/Reviewer_z6ht"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission399/Reviewer_z6ht"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761878156592, "cdate": 1761878156592, "tmdate": 1762915511198, "mdate": 1762915511198, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Deceptive Humor as a new research area combining misinformation and computational humor. The authors came up with the Deceptive Humor Dataset (DHD), which is a synthetically generated corpus of humorous comments in English, Telugu, Hindi, Kannada, Tamil, and their code-mixed variants. Each instance is associated with a false claim and then annotated with satire levels and humor types. The authors benchmark this dataset by proposing DH-MTL, which is multi-task learning framework that jointly learns satire intensity and humor type."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- I like the new problem direction of deceptive humor. With social media being used in all aspects of our daily lives, it does influence our thinking a lot and this study which deals with how affective traits like humor are being used to manipulate/persuade humans is interesting to me.\n- Not limiting the study to just the English language is also a good decision. Especially, incorporating code-mixed input since that is how most natural conversations take place for multilingual folks.\n- The way humans are involved in the loop is also interesting. As the authors did not just ask humans to evaluate responses, rather used the feedback to iterate the models. I think this is especially useful for multilingual settings to incorporate the sense of \"cultural humor\"."}, "weaknesses": {"value": "Although the paper is well written and is easy to follow, there are still some weaknesses that the paper can improve upon:\n- The paper defines deception as repeating known false claims. It assumes that if a joke includes a debunked statement (like “China made COVID as a bioweapon”), then the joke is deceptive. But mentioning a false claim is not the same as supporting it, especially when the statements can be satirical. That is, the dataset currently treats every mention of a false claim as deceptive, even when the joke is actually mocking or criticizing that claim. This could wrongly label satire or political humor as harmful misinformation.\n- Enforcing the above point, The paper says deceptive humor is harmful but never explains what deceptive means in this context. Is it about the writer trying to fool people or how readers understand it or just the false facts in it? The notion of deception is confusion right now.\n- Although synthetic data is the easiest and fastest way to get data, but there is a big issue, especially when using languages other than English and dealing with extremely subjective problems like satire and humor. Table 7 shows that languages like Hindi and Tamil score lower on cultural nuance, which suggests these examples don't fully capture real humor."}, "questions": {"value": "- How do you tell apart jokes that make fun of false claims (like mocking conspiracy theories) from jokes that actually spread them? Could DHD mark the first type as deceptive (which would be a mistake)? Same for satire, can the proposed method punish real satire that is actually criticizing the misinformation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rU5xSFYH7O", "forum": "FnTogdn45v", "replyto": "FnTogdn45v", "signatures": ["ICLR.cc/2026/Conference/Submission399/Reviewer_kjsY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission399/Reviewer_kjsY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission399/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923621645, "cdate": 1761923621645, "tmdate": 1762915511079, "mdate": 1762915511079, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}