{"id": "lj1qwU6Gxs", "number": 11157, "cdate": 1758191400087, "mdate": 1762933459929, "content": {"title": "Multi-Agent Adversarial Time Series Forecasting", "abstract": "Time series forecasting is critical across finance, energy, and healthcare, yet remains challenged by the complexity and non-stationarity of real-world data. Although deep learning has advanced performance, single-model architectures often struggle with temporal volatility and limited generalization. Multi-agent collaborative training offers a promising path forward by leveraging diverse model strengths; however, existing methods mostly rely on simple ensembles, lacking deeper structural interaction and probabilistic alignment. In this paper, we propose Multi-Agent Adversarial Time Series Forecasting (MAA-TSF), a framework that orchestrates heterogeneous generators and discriminators into a dynamic, competitive–cooperative system, akin to a multi-force formation adapting to evolving terrains. It integrates intra-group dynamic knowledge alignment and cross-group adversarial training to enhance joint distribution modeling and resilience to distribution shifts, while solving adversarial baseline instability. By evaluating nineteen real-world financial assets in six distinct market categories and six well-known datasets, we find that it consistently outperforms both the ERM and GAN under different time-specific backbones , achieving MAE reductions of 10% – 70%, while delivering 5% – 25% gains in the accuracy of directional prediction across most datasets and models, verifying adversarial multi-agent coordination as a robust paradigm for complex time series.", "tldr": "", "keywords": ["Multi-agent prediction; Time Series; Joint Distribution Modeling; Distribution shift"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/1ec4809343a87e8a540c785ac670f8e4e00e1488.pdf", "supplementary_material": "/attachment/2758735681e931b5c7627382d3a67be423b4ed49.zip"}, "replies": [{"content": {"summary": {"value": "This paper designs a dynamic, adversarial framework MAA-TSF to adaptively apply heterogeneous models for modeling complex time series. Leveraging intra-group alignment and cross-group adversarial training, the framework improves joint distribution modeling and robustness to distribution shift. Meanwhile, it is more stable than other adversarial baselines. Experiments span 19 financial assets across six market categories and six public time-series datasets and show consistent gains in MAE and directional accuracy, outperforming baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The research problem is well-motivated, targeting critical challenges in time series modeling.\n    \n- MAA-TSF is designed to model complex time series data by employing multiple models in an adversarial manner, aligning with recent trends in time series research.\n    \n- Evaluation spans diverse datasets, providing a comprehensive verification of the effectiveness of the proposed approach."}, "weaknesses": {"value": "- This paper does not compare the proposed approach to strong baselines. In particular, simple ensemble methods are missing, which is specifically mentioned and compared to in the Introduction.\n    \n- The attached codebase is not accessible.\n    \n- [Minor] Figure 2 (a) is not readable enough for general audience unfamiliar with adversarial training, particularly the right-hand side part for the real distribution. A brief, self-contained caption may improve readability.\n    \n- [Minor] There are some small typos regarding the spacing, particularly before citations. No impact on my rating."}, "questions": {"value": "- Are all experiments conducted with strictly chronological splits? Do the model performance and conclusions hold when using different train-test splits? Would its effectiveness be dependent on specific regimes?\n    \n- Can you compare MAA-TSF to the essential baselines, such as simple ensembles?\n    \n- Please interpret how and why MAA-TSF effectively addresses the distribution shifts between training and test data, using S&P 500 as an example? This is not clearly verified in the experiments.\n    \n- How do you determine the key hyperparameters, like $\\lambda$s and $\\kappa$? And how to interpret their impact?\n\nI'm willing to raise my rating if my concerns are well-addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZSbRr0jZao", "forum": "lj1qwU6Gxs", "replyto": "lj1qwU6Gxs", "signatures": ["ICLR.cc/2026/Conference/Submission11157/Reviewer_HCSC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11157/Reviewer_HCSC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11157/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988510612, "cdate": 1761988510612, "tmdate": 1762922912211, "mdate": 1762922912211, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "FTY9Dt9gMW", "forum": "lj1qwU6Gxs", "replyto": "lj1qwU6Gxs", "signatures": ["ICLR.cc/2026/Conference/Submission11157/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11157/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762933272116, "cdate": 1762933272116, "tmdate": 1762933272116, "mdate": 1762933272116, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This submission aims to address the distribution shift problem in time series forecasting. To tackle this challenge, the manuscript proposes MAA-TSF, a framework designed to generate artificial training data. To evaluate the effectiveness of the proposed approach, fiveforecasting models combined with two data generation methods are tested across 25 datasets."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "This submission presents a solid experimental evaluation, employing multiple baseline models and testing across more than 20 datasets to comprehensively assess the proposed method."}, "weaknesses": {"value": "1. The submission is not well-written and lacks consistency in formatting. For example, the use of parentheses is inconsistent. In some instances, there is a space before “(”, while in others there is not. In addition, the formatting of figures and tables does not adhere to standard conventions; for instance, table titles should appear above the tables rather than below. Such issues detract from the overall readability and presentation quality of the paper.\n\n2. The motivation of this submission is not sufficiently supported. The stated research goal is to address the issue of distribution shift, but the paper does not clearly explain why existing approaches, such as federated learning, reinforcement learning, or normalization techniques, among others, are inadequate for this purpose. Furthermore, it remains unclear why generating more data is a necessary or effective strategy for mitigating distribution shift. A clearer justification and theoretical or empirical evidence are needed to establish the significance of the proposed approach."}, "questions": {"value": "Clarification of “Agent”: The paper should clearly define what an agent represents in the context of time series forecasting. It is currently unclear whether the agent refers to an individual forecasting model, a specific learning module, or a decision-making component within the proposed framework.\n\nDefinition of Joint Distribution Variables: The manuscript should explicitly specify the variables involved in the joint distribution mentioned in line 083. It is unclear what random variables or components this distribution models, for example, whether it involves the time series inputs, model predictions, latent representations, or other factors."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qNwQ2iKWlm", "forum": "lj1qwU6Gxs", "replyto": "lj1qwU6Gxs", "signatures": ["ICLR.cc/2026/Conference/Submission11157/Reviewer_5f99"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11157/Reviewer_5f99"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11157/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998439978, "cdate": 1761998439978, "tmdate": 1762922322232, "mdate": 1762922322232, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Multi-Agent Adversarial Time Series Forecasting (MAA-TSF), a new framework to address the problem of the non-stationarity of real-world data in time series forecasting. MAA-TSF employs multiple generators and discriminators to learn the joint distribution and is robust to distribution shifts. MAA-TSF is experimented on 19 (12 in main paper) real-world datasets and shown to have better performance than competing baselines in terms of both point forecasting (MAE) and directional accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of multi-agent adversarial training for time series forecasting is novel. The paper explores under-studied aspects such as distribution shifts and directional prediction, which are relevant and valuable problems in practical forecasting.\n\n2. Experimental results on multiple datasets show promising performance."}, "weaknesses": {"value": "1. The paper claims to address distributional shifts, but it is not evident how multi-agent adversarial training achieves this. No experiment explicitly evaluates performance under shifted distributions.\n\n2. The roles of Elite-Guided Adversarial Refinement and Multi-Agent Prior Alignment with Knowledge Distillation are not clearly justified or empirically validated.\n\n3. The paper does not directly compare with strong SOTA forecasting models. The competitiveness of results is unclear.\n\n4. The paper is hard to read with convoluted explanations.\n\n(i) Input to the discriminator is inconsistent between Eq. (3) and Eqs. (10–11).\n\n(ii) Eq. (9) is confusing—why include part of the lookback window as generator output when it is already input to the discriminator?\n\n(iii) Eq. (8) lacks justification for requiring lookback > forecast horizon.\n\n(iv) Fig. 3 is unclear. Also, the font is too small in the figures.\n\n(v) $\\mathbf{F}_i$ (l. 160–161) is undefined.\n\n(vi) Eq. (6) seems incorrect ($\\sum_j \\log(D_j(\\mathbf{O}_{i})$?)"}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5O6cnA0V0L", "forum": "lj1qwU6Gxs", "replyto": "lj1qwU6Gxs", "signatures": ["ICLR.cc/2026/Conference/Submission11157/Reviewer_GYSc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11157/Reviewer_GYSc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11157/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762183319139, "cdate": 1762183319139, "tmdate": 1762922321741, "mdate": 1762922321741, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}