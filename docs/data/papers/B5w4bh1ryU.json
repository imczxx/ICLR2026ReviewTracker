{"id": "B5w4bh1ryU", "number": 1783, "cdate": 1756922425234, "mdate": 1759898187121, "content": {"title": "Local Uncertainty Smoothing For Few-shot OOD Detection", "abstract": "Few-shot out-of-distribution (OOD) detection has become a critical research direction for the practical deployment of machine learning systems. Existing approaches commonly rely on auxiliary outlier data derived from in-distribution (ID) samples, such as using local image patches from training data to simulate OOD features. However, these artificially constructed OOD samples differ substantially from real OOD instances, leading to unstable learning when trained with hard OOD labels. To address this challenge, we propose a Local Uncertainty Smoothing (LUS) framework for few-shot OOD detection. Our method incorporates label smoothing and local uncertainty measure to facilitate a smooth transition between the reference distribution of local image categories, based on a general knowledge model and the target OOD distribution. This approach ensures strong OOD detection performance while preserving the model’s ability to capture detailed local-level semantic features. Furthermore, we theoretically analyze the relevance of local uncertainty from the perspective of a generalization error bound (GEB). This reveals a concrete relationship between our local uncertainty measure and the KL divergence observed during training. Accordingly, we propose a patch-wise local uncertainty to effectively identify suitable soft labels for the model throughout the learning process, achieving superior OOD detection performance. Extensive experiments on real-world OOD benchmarks validate the effectiveness of our approach. Code will be made publicly available.", "tldr": "", "keywords": ["Few-shot OOD Detection", "Local Uncertainty", "Label Smooth", "Generalization Error Bound", "Soft label"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/79cc7d39fac02d51a5187eb2e00df2854bde7278.pdf", "supplementary_material": "/attachment/0b0ebf64590e7af65c5c04896a0ed587dfe54c92.pdf"}, "replies": [{"content": {"summary": {"value": "The authors propose a novel framework addressing the problem of few-shot out-of-distribution (OOD) detection. They tackle the limitations of previous methods that relied on pseudo-OOD labels with uniform distribution by introducing label smoothing and local uncertainty techniques. The paper provides a theoretical proof for the Generalized Energy Bound (GEB) and conducts experimental validation on the task."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and easy to follow.  \n\n2. It correctly identifies a key limitation in existing methods that use a uniform distribution for pseudo-OOD labels.  \n\n3. The proposed solution of using label smoothing and local uncertainty effectively addresses this issue and leads to a measurable performance improvement."}, "weaknesses": {"value": "1. The ablation study lacks removing uniform pseudo-OOD distribution in EQ.4 \n\n2. The novelty and scope of the proposed framework is constrained. The experimental comparisons are not fully conclusive. The benchmarked methods are not state-of-the-art, and there is a notable absence of comparisons with recent, strong contenders such as SCT (NeurIPS 2024) and Local-Prompt (ICLR 2025). Furthermore, the reported performance gains, while present, are not overwhelming against the older baselines, raising questions about the method's competitiveness.\n\n3. The design and purpose of the fg in EQ4 are ambiguous and require further elaboration. The description suggests it involves re-processing low-similarity patches through a model pre-trained on ImageNet-21k, using ID labels. Several critical questions arise:\n- What is the underlying intuition? The authors should clarify the theoretical or empirical motivation behind this specific operation. Is it intended as a form of knowledge distillation? If so, the connection should be explicitly stated and justified.  \n- How can it provide meaningful guidance? Since the label space of ImageNet-21k is largely unrelated to the ood patches, the logits produced by fg may not offer semantically relevant guidance for the target domain. \n\n4. There is a minor typo in line 252 of the paper: \"uis\" is missing a space."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "R8rk1rfjJx", "forum": "B5w4bh1ryU", "replyto": "B5w4bh1ryU", "signatures": ["ICLR.cc/2026/Conference/Submission1783/Reviewer_PHB6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1783/Reviewer_PHB6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1783/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761460832621, "cdate": 1761460832621, "tmdate": 1762915889090, "mdate": 1762915889090, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose an adaptive label-smoothing method to increase prompt-learning-based OOD detection with VLMs. The strength of the smoothing depends on the ratio between the KL divergence of the predicted distribution to the uniform distribution and to a general knowledge model. In this way, patches that are unrelated to the ground truth label can be used as stronger OOD samples than more relevant patches. The method is evaluated against other prompt learning baselines on a range of standard datasets."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The idea to adapt the label strength of OOD patches is clear and makes sense.\n- Figure 1 clearly illustrates the core idea behind the proposed method. \n- Various aspects of the proposed system are ablated."}, "weaknesses": {"value": "The presentation of the paper has several issues. First, LLM-like output not only appears in many sections but is also completely unrelated in some cases. For instance, the text suddenly talks about how the proposed OOD detection method \"enhances object detection performance\" (L412) or adopts \"a methodology that explores enhanced object detection\" (L780). Another example is on L712-713, which suddenly mentions a KDE strategy for the first time: \"The following presentation will outline the output results of the model under the KDE strategy. The results of the study are presented in tabular form.\"\nSecond, the clarity of the method section should be improved. For instance, f_g is never explained beyond being \"a general knowledge model that denotes the semantic understanding of patch-level OOD data\", the distributions used as input to the KL divergences in Figure 2 are different from the text, and notation contains some issues in cases such as Eq. 3, where it should be specified that x is sampled from the ID and OOD distributions, or the repetition of KL(U, fθ(x)) in Theorem 1.\nThird, there are still many typos/mistakes in the text. Some examples are \"This offers a new understand\" (L89), \"we propose local uncertainty smoothing method which refining the label distribution\" (L215), \"value of uis critical\" and \"between uand the model\" (L252-254), \"And and\" (L266), \"The more result can see the Appendix G\" (L444) and so on. \nOverall, these issues combined make the manuscript and its proposed contributions far less clear.\n\nThe related work and benchmark also miss some more recent works that improve upon LoCoOp, such as [1, 2], which should be included in the comparison. The numbers reported for methods such as NegPrompt are also (far) lower than those reported in their original paper, where they outperform the proposed method, which should be explained.\n\n[1] Lafon, Marc, et al. \"Gallop: Learning global and local prompts for vision-language models.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024.\n[2] Zhang, Yabin, and Lei Zhang. \"Adaneg: Adaptive negative proxy guided ood detection with vision-language models.\" Advances in Neural Information Processing Systems 37 (2024): 38744-38768."}, "questions": {"value": "- Why is the comparison in Table 3 only done w.r.t. LoCoOp, which version is it, and which version of LUS is used? How come the gap in performance between the proposed method and LoCoOp is much larger than on other Near-OOD cases, such as ImageNet:SSB-Hard in Table 8?\n- The motivation of the method is not justified appropriately. Why is the uncertainty of the model being trained a good signal for how strongly a patch should be considered as OOD? \n- The method section should make clear what LUS_MCM and LUS_GL are.\n- It is unclear what exactly is ablated in the ablation analysis of Table 5. Moreover, f_g does not seem to have a real benefit.\n- The best performing models should be bolded for Texture in Table 1.\n- How sensitive is the proposed method to the chosen hyperparameters?\n- It is unclear what the additional computational cost is for training compared to LoCoOp."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "P0FgcSCFPD", "forum": "B5w4bh1ryU", "replyto": "B5w4bh1ryU", "signatures": ["ICLR.cc/2026/Conference/Submission1783/Reviewer_6xLL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1783/Reviewer_6xLL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1783/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761565969879, "cdate": 1761565969879, "tmdate": 1762915888890, "mdate": 1762915888890, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the problem of assigning uniform labels to extracted local OOD features in existing few-shot OOD detection methods. It proposes a Local Uncertainty Smoothing (LUS) framework that adaptively determines optimal soft label assignments for each local OOD patch. Experiments on the ImageNet-1k OOD benchmark are conducted to evaluate the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. It’s an interesting research problem that assigning uniform labels to local OOD features can degrade ID classification accuracy.\n\n2. This paper provides a theoretical analysis of the proposed method."}, "weaknesses": {"value": "1. **This paper lacks a direct experimental comparison with two highly relevant and strong baselines, SCT [1] and Local-Prompt [2].** The performances of these two methods, reported in their papers, are significantly better than LUS on ImageNet-1k OOD benchmark.\n2. **This paper doesn’t present clear mathematical formulations for some key modules of the proposed framework**, which makes it harder for readers to understand the technical details. To be exact, there are no mathematical formulations for $f_\\theta(x)$ and $f_g(x)$ in the main text and the term “general knowledge model” is not clearly defined. In addition, the meaning of $\\omega$ in Equation (6) is not explained.\n3. **There are many typing errors, grammar errors or confusing expressions in the main text,** which makes it harder for readers to understand the proposed framework. For instance: “while enhance” in Line 81, “a new understand of the ood local features” in Line 89, “one-shot distributions” in Line 214, “which refining” in Line 215, Line 231 says “$u$ denotes an uncertainty method”, “uand” in Line 254, and so on.\n4. The reviewer suggests that the authors **add experiments on different CLIP backbone architectures and more hard OOD detection tasks,** as in [1], to provide a more comprehensive evaluation of the proposed method.\n\n[1] Geng Yu, et al. Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection.\n\n[2] Fanhu Zeng, et al. Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "The reviewer doesn't notice any ethical issues with this paper."}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0WqLUY2QOE", "forum": "B5w4bh1ryU", "replyto": "B5w4bh1ryU", "signatures": ["ICLR.cc/2026/Conference/Submission1783/Reviewer_vNYK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1783/Reviewer_vNYK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1783/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880278747, "cdate": 1761880278747, "tmdate": 1762915888642, "mdate": 1762915888642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel Local Uncertainty Smoothing (LUS) framework for few-shot out-of-distribution (OOD) detection. Current approaches often rely on auxiliary OOD data derived from in-distribution (ID) samples (e.g., local image patches), but such artificially constructed OOD instances can differ significantly from real OOD data, leading to unstable learning. LUS addresses this by integrating label smoothing and a patch-wise local uncertainty measure. Theoretically, the paper analyzes the relationship between local uncertainty and KL divergence from a generalization error bound (GEB) perspective, providing a foundation for dynamic soft label assignment. Experimentally, the method is validated on benchmarks like ImageNet-1K, iNaturalist, and hard OOD datasets, showing state-of-the-art performance in few-shot settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The LUS framework introduces a fresh perspective on OOD detection by moving beyond hard labels (e.g., uniform distributions) to soft labels based on general knowledge and uncertainty. \n2. The paper provides a solid theoretical foundation through Theorem 1, which connects local uncertainty to KL divergence via a generalization error bound. \n3.  The experimental evaluation is thorough, covering multiple OOD benchmarks and metrics (FPR95, AUROC, ID accuracy)."}, "weaknesses": {"value": "1. The paper identifies the temperature coefficient $\\tau$ as critical for balancing KL divergence terms. While $\\tau$=1 is optimal in experiments, tuning it for new datasets may be non-trivial and computationally expensive, potentially hindering plug-and-play use.\n2.  Experiments focus on image data and near-OOD scenarios, lacking cross-domain tests (e.g., text or video). This reduces insights into generalizability.\n3. This paper's foundational motivation aligns with prior research in OOD detection. A notable example is the Energy-based method, which demonstrates the inadequacy of uniform distributions and advances an energy-bound solution [1] to optimize detection performance.\n4. The paper does not discuss efficiency trade-offs, which could be critical for resource-constrained environments.\n\n[1] Liu, Weitang, et al. \"Energy-based out-of-distribution detection.\" Advances in neural information processing systems 33 (2020): 21464-21475."}, "questions": {"value": "1. How does LUS perform on \"far-OOD\" data (e.g., adversarial OOD examples)? \n2. Is the method adaptable to non-visual domains (e.g., NLP, video) ? \n3. How about the efficiency of the proposed method?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YUNEbgT6Vr", "forum": "B5w4bh1ryU", "replyto": "B5w4bh1ryU", "signatures": ["ICLR.cc/2026/Conference/Submission1783/Reviewer_aoub"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1783/Reviewer_aoub"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1783/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916681167, "cdate": 1761916681167, "tmdate": 1762915888400, "mdate": 1762915888400, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}