{"id": "PFseU5D5t9", "number": 16109, "cdate": 1758260123141, "mdate": 1759897261397, "content": {"title": "Reasoning as an Attack Surface: Adaptive Evolutionary CoT Jailbreaks for LLMs", "abstract": "Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in reasoning and generation tasks and are increasingly deployed in real-world applications. However, their explicit chain-of-thought (CoT) mechanism introduces new security risks, making them particularly vulnerable to jailbreak attacks. Existing approaches often rely on static CoT templates to elicit harmful outputs, but such fixed designs suffer from limited diversity, adaptability, and effectiveness. To overcome these limitations, we propose an adaptive evolutionary CoT jailbreak framework, called AE-CoT. Specifically, the method first rewrites harmful goals into teacher-style prompts and decomposes them into semantically coherent reasoning fragments to construct a pool of CoT jailbreak candidates. Then, within a structured representation space, we perform multi-generation evolutionary search, where candidate diversity is expanded through fragment-level crossover and a mutation strategy with an adaptive mutation-rate control strategy. An independent scoring model provides graded harmfulness evaluations, and high-scoring candidates are further enhanced with H-CoT-style templates to induce more destructive generations. Extensive experiments across multiple models and datasets demonstrate the effectiveness of the proposed AE-CoT, consistently outperforming state-of-the-art jailbreak methods.", "tldr": "", "keywords": ["Jailbreak", "LLM"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3b358961c58583d17142d2b949c774c386e0cbc1.pdf", "supplementary_material": "/attachment/a6017203fd2e9f0af76ed1c3a5d1fbb3a6505071.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes AE-CoT, an adaptive evolutionary framework designed to jailbreak Large Reasoning Models by exploiting CoT mechanism. The method first reframes a harmful goal into a ``teacher-style'' prompt. It then uses a genetic algorithm with an adaptive mutation rate to search a structured space of CoT fragments, aiming to find the most effective adversarial reasoning path. The authors report that AE-CoT achieves better performance in attack success rate and harmfulness score across various models."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "This paper is built upon a sound idea that defines a structured search space for CoT fragments and using an evolutionary algorithm to find effective attack vectors, which seems a reasonable strategy for this problem."}, "weaknesses": {"value": "1. The writing and presentation are poor. In the abstract, a term like *H-CoT-style* is used without any definition. The first two paragraphs of the introduction are missing essential citations for fundamental concepts like *Large Reasoning Model*, *CoT*, and *Jailbreaking*. When the paper claims on lines 44-45 that prior work has major limitations, it does so without citing any specific papers. Are these the authors' own conclusions, or are they based on previous findings? Without references, these are just unsubstantiated claims. I also found that key terms like *mutation-rate* and *population convergence* are used without proper introduction, which makes the paper very hard to follow. Furthermore, there are numerous instances of inconsistent abbreviation usage for both LLMs (e.g., Line 38, 91, 146, 168) and CoT (e.g., Line 13， 33， 122， 134， 145， 154， 177， 202， 236， 237， 290. ), which shows a lack of careful proofreading. If you have introduced the abbreviation before, you don't need to repeatedly reintroduce it.\n\n2. Insufficient related work section. The paper discusses too few related articles. It's clear that it has missed a significant body of work, both on jailbreaking Large Reasoning Models in general [1-5] and specifically on attacks that leverage the CoT and reasoning process [3,6-7]. This suggests an incomplete literature review.\n\n[1] Jinx: Unlimited LLMs for Probing Alignment Failures\n\n[2] ExtendAttack: Attacking Servers of LRMs via Extending Reasoning\n\n[3]  Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models\n\n[4]  OverThink: Slowdown Attacks on Reasoning LLMs\n\n[5]  BoT: Breaking Long Thought Processes of o1-like Large Language Models through Backdoor Attack\n\n[6] Response Attack: Exploiting Contextual Priming to Jailbreak Large Language Models\n\n[7] Atoxia: Red-teaming Large Language Models with Target Toxic Answers\n\n3. Confusing expression in Section 3. In Equation 6, the symbols on the right-hand side are not defined. Do they represent sets of attributes? If you put them in the Appendix and Table 6, you should refer to them. Most critically, there is a severe error of symbol reuse: on line 178, $\\tau$ is used for a *rewriting template,* but it seems to be used for something entirely different in the evolutionary selection process. Maybe the authors can re-check this entire section for symbol definitions, usage, and consistency. \n\n\n4. The experimental description also lacks basic scholarly practice. On line 346, baseline methods like ArtPrompt and PAP are mentioned without any citations, leaving the reader to guess which papers are being referred to. \n\n\n5.  While the high-level idea is sound, the components themselves (evolutionary search, teacher-style rewriting, structured search spaces) are common techniques in the field of adversarial attacks and prompt refinement. The paper fails to adequately position its specific combination of these ideas against prior work, thus overstating its novelty. \n\n\n6. I have concerns about the computational cost, which is not adequately discussed. The optimization process, as I understand it, relies on a black-box evaluation that requires multiple expensive API calls to both the target and a judge model for every single candidate in every generation. This process seems prohibitively expensive for any practical, large-scale application. While the paper claims to be more *efficient* than another method, this doesn't change the fact that the absolute cost is very high, a crucial limitation that is largely ignored."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "g5lHqbRB1p", "forum": "PFseU5D5t9", "replyto": "PFseU5D5t9", "signatures": ["ICLR.cc/2026/Conference/Submission16109/Reviewer_LHXc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16109/Reviewer_LHXc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16109/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761625651776, "cdate": 1761625651776, "tmdate": 1762926286352, "mdate": 1762926286352, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces AE-CoT, an adaptive evolutionary framework designed to use the chain-of-thought (CoT) mechanism in large models as an attack surface for jailbreaking. The method begins by rewriting a harmful objective into a \"teacher-style\" prompt. It then decomposes the CoT into structured semantic fragments and employs an evolutionary algorithm with an adaptive mutation rate to search for an optimal adversarial CoT combination within a predefined, structured space."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper's motivation is clear. Targeting reasoning models with an evolution-based jailbreak attack is a valuable and specific application, and the experimental results appear to validate its effectiveness."}, "weaknesses": {"value": "**I have severe concerns regarding the contribution and novelty of this paper. The formulation and methodology of AE-CoT exhibit a high degree of overlap with a prior work, CL-GSO [1]** (which uses an expandable strategy space for evolutionary search). To be specific:\n\n- Both papers identify the exact same bottleneck in existing jailbreak methods: the \"fixed and limited strategy space.\" More importantly, they propose a virtually identical solution: decompose a holistic attack strategy into multiple independent, interpretable components, and then use an evolutionary/genetic algorithm to search the resulting combinatorial and vastly expanded strategy space to discover more powerful and diverse attacks. This is the foundational methodology for both papers, and it has already been clearly articulated and validated by CL-GSO.\n\n- CL-GSO decomposes its strategies into four dimensions based on the Elaboration Likelihood Model (ELM): Role, Content Support, Context, and Communication Skills. AE-CoT, on the other hand, claims to decompose CoT into nine sub-templates, including reasoning role, context frame, content support, and communication style. While the number and names of the dimensions differ, the core idea—\"to componentize the attack paradigm\"—is exactly the same. There are also clear parallels between some of AE-CoT's dimensions (e.g., role, context) and those in CL-GSO.\n\n- Both papers employ a standard genetic algorithm flow: population initialization, crossover, and mutation, and both emphasize some form of \"adaptive\" adjustment. The \"adaptive mutation rate\" proposed in AE-CoT serves the exact same functional purpose as the \"adaptive crossover and mutation rates with a soft decay strategy\" mentioned in CL-GSO—that is, to balance exploration and exploitation during the search.\n\n\n[1] Huang et.al., Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space, ACL 2025"}, "questions": {"value": "The authors must provide a thorough explanation for the stunning similarity between their methodology and Figures 1 and 2 with CL-GSO's. **I would like to ask the Area Chair to adjudicate on this matter**.\n\nGiven these suspected similarities, I think that this paper does not meet the standard for publication at ICLR."}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "details_of_ethics_concerns": {"value": "The formulation, methodology and main figures of this paper exhibit a high degree of overlap with a prior work, CL-GSO [1] (which uses an expandable strategy space for evolutionary search).\n\n[1] Huang et.al., Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space, ACL 2025, https://arxiv.org/pdf/2505.21277v2"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "j3REs7s7fJ", "forum": "PFseU5D5t9", "replyto": "PFseU5D5t9", "signatures": ["ICLR.cc/2026/Conference/Submission16109/Reviewer_uVzy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16109/Reviewer_uVzy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16109/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828824476, "cdate": 1761828824476, "tmdate": 1762926285753, "mdate": 1762926285753, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an adaptive evolutionary CoT jailbreak framework, called AE-CoT. Specifically, the method first rewrites harmful goals\ninto teacher-style prompts and decomposes them into semantically coherent reasoning fragments to construct a pool of CoT jailbreak candidates. Then, within a structured representation space, we perform multi-generation evolutionary search, where candidate diversity is expanded through fragment-level crossover and a mutation strategy with an adaptive mutation-rate control strategy."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The propsoed AE-CoT, an adaptive evolutionary CoT jailbreak framework, which generates the adversarial CoT traces with teacher-style rewriting and fragment-based decomposition. \n\nThe paper's approach extends this line of research by combining structured CoT optimization with evolutionary search. By explicitly targeting reasoning models’ intermediate thinking space, we demonstrate superior jailbreak success rates compared to prior CoT-based attacks, while also enabling transferable adversarial prompts for non-reasoning models.\n\n Experiments on both reasoning and non-reasoning models demonstrate not only strong effectiveness and transferability, but also improved efficiency compared with existing evolutionary jailbreak approaches."}, "weaknesses": {"value": "I think the idea of the paper is good. My only concern is that can you  generalize your evolutionary  jailbreak approaches AE-CoT to the multi-modality LLMs with more experiments. For example, you verify your AE-CoT with cross-modal tasks."}, "questions": {"value": "see the above comments."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R31UtXytN8", "forum": "PFseU5D5t9", "replyto": "PFseU5D5t9", "signatures": ["ICLR.cc/2026/Conference/Submission16109/Reviewer_snzi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16109/Reviewer_snzi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16109/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958449440, "cdate": 1761958449440, "tmdate": 1762926285150, "mdate": 1762926285150, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}