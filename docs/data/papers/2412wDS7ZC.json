{"id": "2412wDS7ZC", "number": 23935, "cdate": 1758350506395, "mdate": 1759896789776, "content": {"title": "Leveraging Dark Knowledge for Intrinsic Multimodal Out-of-Distribution Detection", "abstract": "Out-of-distribution (OOD) detection is crucial for the safe deployment of deep neural models in applications such as autonomous driving. With the emerging multimodal nature of modern applications, recent attention has shifted toward OOD detection in multimodal settings. However, current multimodal OOD detection methods fail to fully exploit the synergy among modalities: they treat all modalities equally, disregarding their varying detection performance, and they are unable to capture the diverse uncertainty information encoded at the logit level. In this paper, we propose to exploit the dark knowledge within unimodal experts as the key to revealing their synergy. To this end, we introduce a self multimodal OOD distillation framework, which leverages logits as uncertainty-aware soft targets to train a holistic model that operates in the joint embedding space of all modalities. Specifically, the proposed framework accounts for the negative effects of underperforming modalities and effectively fuses both the rich feature-level knowledge and the logit-level knowledge of modalities. As a result, our method improves the performance of current state-of-the-art multimodal OOD detection methods, achieving gains of up to 30% across diverse OOD detection benchmarks, spanning two tasks and five multimodal OOD datasets.", "tldr": "We propose a self multimodal OOD distillation framework that leverages dark knowledge from unimodal experts to enhance multimodal OOD detection.", "keywords": ["Multimodal Out-of-Distribution Detection"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e7cd2a33b0cc3ebd61bde88deb2d763c71bd22c0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work focuses on multi-modality OOD detection with semantic shift. Particularly, it employs a teach-student knowledge distillation framework to perform OOD detection. Specifically, the teacher is constructed as ensemble of pre-trained unimodal classifiers, and the soft targets are calculated as the weighted predictive targets from  pre-trained unimodal classifiers. The corresponding weight for each modality is calculated as modality-specific CE loss over the sum of CE loss across all modalities. The final loss incorporates a standard cross entropy loss and the classical decoupled knowledge distillation loss."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n- The paper is well-written at a high level, and the proposed framework sounds reasonable. \n- It is appreciated that the authors conduct experiments regarding the contribution of target class knowledge distillation (TCKD) and non-target-class knowledge distillation (TCKD) to multi-modal OOD detection.\n- The experiments are comprehensive."}, "weaknesses": {"value": "Weaknesses\n-  The paper is easy to follow at the first glance, but several details are missing when read more. \n   - Figure 2 can be further improved by adding the symbols for each block to improve clarity;\n   - It seems to the feature fusion is implemented by concatenating them directly, correct me if i am wrong. Otherwise, please clarify it in Line 166;\n   - The performance gain is somehow marginal. Particularly, it can be seen from Table 4 that DPU solely achieves the best performance in terms of AUROC.  Moreover, there is a trade-off between AUROC and FPR95 for DPU and FM. \n\n-  The proposed framework is ok to do but I did not see a strong connection with mutli-modal OOD detection. To me, it's more like improving the accuracy of the joint classier, which can be empirically verified by the ID accuracy from Table 4."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "pOavFMxlyW", "forum": "2412wDS7ZC", "replyto": "2412wDS7ZC", "signatures": ["ICLR.cc/2026/Conference/Submission23935/Reviewer_XVtv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23935/Reviewer_XVtv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23935/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761563172363, "cdate": 1761563172363, "tmdate": 1762942863056, "mdate": 1762942863056, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The core contribution of this paper is the application of two existing techniques (Decoupled Knowledge Distillation and Weighted Ensemble Distillation) to the specific task of multimodal OOD detection.  \n1. Decoupled KL Divergence: The $\\mathcal{L}_{KL}$ loss function used for OOD detection, particularly its decomposition into Target Class Knowledge Distillation (TCKD) and Non-Target Class Knowledge Distillation (NCKD) is directly adopted from the work of (Zhao et al., 2022).\n2. Dark Knowledge Analysis: The insights presented in Section 3.4, which claim that TCKD benefits near-OOD and NCKD benefits far-OOD detection , are also primarily derived from the findings of (Zhao et al., 2022).\n3. Teacher Model: The paper's \"teacher\" distribution $p^T$ is obtained by a weighted average of the unimodal expert predictions (Eq. 3). This is, in essence, a standard ensemble distillation technique."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "This paper is well-written and very easy to follow."}, "weaknesses": {"value": "1. The paper claims its method is a \"plug-and-play\" framework that improves the performance of existing SOTA methods (like A2D, AN, DPU, FM). However, this comparison is problematic. The paper explicitly states that when combining with SOTA methods, it keeps the SOTA model backbones fixed and only retrains their final classifier for 10 epochs. The SOTA baselines (A2D, DPU, etc.) are complex strategies that involve end-to-end training of the backbone to learn \"a more discriminative embedding space\". Therefore, the results (e.g., \"A2D\" vs. \"A2D + Ours\" in Table 3 and 4) are actually comparing a \"fully trained SOTA model\" against a \"fully trained SOTA model + additional classifier fine-tuning\". At best, this comparison only proves that fine-tuning the classifier head with the proposed distillation loss can provide a marginal boost to an already-trained model.\n2. The paper assumes that \"poor ID classification performance\" equates to \"poor OOD detection capability,\" but provides no evidence to support this critical assumption. It is entirely possible for a modality (e.g., optical flow in Fig. 1 ) to have acceptable ID classification but poor OOD detection due to overconfidence. This weighting scheme may be penalizing modalities based on the wrong signal.\n3. The paper explicitly states that the hyperparameters $\\alpha$ and $\\beta$ (which balance TCKD and NCKD) must be set differently depending on the task: for the far-OOD task, $\\alpha=0.1, \\beta=0.9$, while for the near-OOD task, $\\alpha=0.8, \\beta=0.2$. In a real-world application, the system cannot know in advance whether the OOD samples it will encounter are \"near\" or \"far.\" \n4.  The paper's title and text use the word \"Intrinsic\", claiming to mine the \"intrinsic OOD detection capability.\" However, the method explicitly introduces and trains a new joint classifier $h$ and a new distillation loss $\\mathcal{L}_{KL}$. This is not mining \"inherent\" capability; it is introducing new knowledge via fine-tuning. \n5. The method is neither a truly training-free post-hoc scoring function like MSP or Energy , nor is it a full end-to-end training method. It is a classifier-head fine-tuning method that requires 10 epochs of training. So, I don't agree that this is a Post-hoc method.\n6. The paper heavily uses the term \"dark knowledge\" , but its core mechanism is simply standard (decoupled) logit distillation. So, what is dark knowledge?"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "n/a"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "98mub5Bexi", "forum": "2412wDS7ZC", "replyto": "2412wDS7ZC", "signatures": ["ICLR.cc/2026/Conference/Submission23935/Reviewer_qzLe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23935/Reviewer_qzLe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23935/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761798619569, "cdate": 1761798619569, "tmdate": 1762942862783, "mdate": 1762942862783, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel framework, self multimodal OOD distillation, to improve out-of-distribution (OOD) detection in multimodal settings. The central problem it addresses is that existing fusion-based methods often fail to account for the varying OOD detection capabilities of different modalities and do not exploit the uncertainty information present in the logits. The core contribution is a method to train a joint classifier. Instead of using one-hot labels, it uses a dynamically generated soft target (dark knowledge) for distillation. The method is presented as a model-agnostic, plug-in module that can be applied on top of existing multimodal OOD methods. The authors demonstrate significant performance gains across five datasets, two tasks, and several state-of-the-art baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper's primary idea is both intuitive and novel. The motivation that different modalities have different intrinsic OOD detection strengths is a key insight.\n\n2. The methodology is well-founded, building logically from a Bayesian-inspired ensemble to a practical and decoupled distillation loss.\n\n3. The paper is well-written and easy to follow.\n\n4. The paper provides extensive experiments, showing the effectiveness and versatility of the proposed method."}, "weaknesses": {"value": "1.  The method needs a priori knowledge of the task (near-OOD vs. far-OOD) to set the α and β hyperparameters (line 409).  In real-world deployment, the type of OOD shift is unknown.\n\n2. The α and β values are fixed values chosen for each task. There is no discussion of how these values were chosen or how sensitive the model's performance is to them."}, "questions": {"value": "1. How would you recommend a practitioner set α and β in a real-world scenario where the type of OOD (near/far) is unknown?\n\n2. A brief sensitivity analysis for the α and β parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "86ouPaOuyR", "forum": "2412wDS7ZC", "replyto": "2412wDS7ZC", "signatures": ["ICLR.cc/2026/Conference/Submission23935/Reviewer_XoF3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23935/Reviewer_XoF3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23935/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917686357, "cdate": 1761917686357, "tmdate": 1762942862438, "mdate": 1762942862438, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}