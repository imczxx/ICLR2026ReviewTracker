{"id": "R3PdluB82U", "number": 17889, "cdate": 1758281654976, "mdate": 1759897147704, "content": {"title": "Few-Shot Idea Auto-Generation: Reasoning Over Idea Representations to Predict New Research Ideas", "abstract": "Large language models have demonstrated powerful reasoning capabilities on user-provided contexts, inspiring researchers to explore their potential for automated research. A critical component of research is idea generation—identifying novel contributions, advantages, and distinctions from existing work. However, we show that naively prompting pre-trained LLMs to generate research ideas produces largely meaningless results.\n\nWe introduce a novel task: few-shot idea auto-generation, where models generate research ideas based on a small set of existing papers. Our key insight is that meaningful ideas typically build upon prior work rather than emerging from scratch—for instance, adapting solutions from one domain to address similar challenges in another, often combined with novel algorithmic approaches. To enable effective few-shot idea generation, we address three fundamental challenges: (1) How can we effectively represent the core ideas of existing papers? (2) How can we generate practical, implementable ideas while filtering out infeasible ones? (3) How can we validate the generated ideas effectively?\n\nOur contributions are threefold. First, we develop an idea representation method that effectively captures papers' core contributions through multi-agent extraction with synopsis and procedural profiling. Second, we design an LLM-agent-based generation framework that performs cross-pollination via systematic gap-bridging between paper pairs. Third, we propose an evaluation methodology using semantic similarity analysis with recency-weighted novelty scoring and construct a benchmark for few-shot idea generation across 3,353 papers from 8 computer science domains.", "tldr": "We present an LLM-agent framework that, given only a few seed papers, represents their core contributions, cross-pollinates them to auto-generate practical research ideas, and quantitatively rates each idea’s novelty and relevance.", "keywords": ["LLM agent", "AI Scientist", "Idea generation", "idea verification"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b23c4d24ea3a8da465b579d6512759dea4f1cb4f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a few-shot, literature-grounded framework for automatic research idea generation. It first builds structured “idea representations” of existing papers—combining task/gap/contribution (T/G/C) synopses with procedural profiling (input–method–output–details). Given a pair of papers, a role assigner picks a base study (problem anchor) and a source study (innovation donor), then a cross-pollination agent composes new procedural steps via integrate/replace/keep/remove operations to form a novel, implementable idea. Evaluation uses (i) semantic similarity between generated ideas and subsequently published papers, (ii) a Unique Paper Ratio measuring methodological diversity among top matches, and (iii) a recency-weighted novelty score. Experiments on 3,353 arXiv papers report higher rates of high-similarity ideas (≈41% relative gain over baselines) while maintaining stable novelty, plus analyses of idea composition across domains and resource/experimental paper ratios."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Moving beyond section summaries to T/G/C plus procedural quadruplets provides traceability from gaps to proposed solutions and improves implementability.\nThe role assignment and component-wise compose operations (integrate/replace/keep/remove) make the generation process controllable, auditable, and easy to analyze.\nCombining similarity with a recency-weighted novelty metric and a Unique Paper Ratio offers a more nuanced picture of relevance vs. originality than single-score rubrics."}, "weaknesses": {"value": "- Limited conceptual novelty of the task framing. The paper positions the problem as few-shot idea generation, but few-shot settings and LLM-based idea generation agents have been widely explored. \n- While the paper reports automatic metrics, the evaluation lacks human expert assessment, which is critical for judging true novelty, feasibility, actionability, and ethical risk.\n- The paper does not establish the reliability of its proposed metrics. Beyond point estimates, the authors should provide sensitivity analyses over key hyperparameters (e.g., k, β, α, λ), bootstrap confidence intervals and significance tests. \n- The paper omits a substantive ethics analysis. Given that the system generates research ideas by recombining prior work, the authors should discuss risks of plagiarism and uncredited appropriation, dual-use or harmful applications, gaming peer review or trending topics, and amplification of dataset and literature biases."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["Yes, Potentially harmful insights, methodologies and applications"]}, "details_of_ethics_concerns": {"value": "Given that the system generates research ideas by recombining prior work, the authors should discuss risks of plagiarism and uncredited appropriation, dual-use or harmful applications, gaming peer review or trending topics, and amplification of dataset and literature biases."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "llkR1AslrD", "forum": "R3PdluB82U", "replyto": "R3PdluB82U", "signatures": ["ICLR.cc/2026/Conference/Submission17889/Reviewer_DfYM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17889/Reviewer_DfYM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17889/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760670772677, "cdate": 1760670772677, "tmdate": 1762927712176, "mdate": 1762927712176, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a framework for few-shot idea auto-generation, aiming to automatically synthesize new research ideas by reasoning over structured representations of existing papers. Using GPT-4o-mini as the main backbone, the system extracts “idea representations” from prior studies—capturing tasks, gaps, contributions, and procedural steps—and performs cross-pollination between a base paper and a source paper to generate research proposals. Evaluation relies on semantic similarity to future publications, unique paper ratio, and time-weighted novelty scores from eight computer-science domains."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles a timely and ambitious problem—automated research ideation—by introducing an interpretable and modular framework based on structured literature representations.\n\n2. The integration of synopsis and procedural profiling is a conceptual improvement over prior “AI Scientist” and “Chain-of-Ideas” approaches, offering clearer traceability between input studies and generated outputs.\n\n3. The dataset construction and evaluation pipeline are carefully described, including retrieval from OpenAlex, embedding computation, and novelty metrics that combine similarity and temporal recency."}, "weaknesses": {"value": "1. The framework depends entirely on GPT-4o-mini for both extraction and generation, but the paper does not discuss temporal control or cutoff validation. Since GPT-4o-mini was released in 2024, it may already contain knowledge of later works that the system claims to “predict.” Without verifying that the model had no access to post-input papers, the prospective evaluation could be confounded.\n\n2. The core extraction functions are conceptually defined but the actual prompts are not provided. The color-boxed examples and Appendix A.5 only explain expected outputs, not the precise prompting templates. This limits reproducibility and makes replication of results difficult.\n\n3. One of the paper’s stated challenges—“How can we generate practical, implementable ideas while filtering out infeasible ones?”—is not concretely solved. The evaluation metrics (similarity, uniqueness, novelty) capture semantic and temporal alignment but not implementability or feasibility. No human or empirical validation supports claims that the generated ideas are genuinely actionable.\n\n4. Figure 1 depicts three parent papers, whereas the formal algorithm (Eq. 1–3) defines generation from exactly two papers. This inconsistency could mislead readers about the input structure.\n\n5. Table 2 shows that the Full System improves high-similarity proportions but yields minimal novelty changes and even small declines in some domains."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nWtwIXBGD6", "forum": "R3PdluB82U", "replyto": "R3PdluB82U", "signatures": ["ICLR.cc/2026/Conference/Submission17889/Reviewer_vVtD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17889/Reviewer_vVtD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17889/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898791498, "cdate": 1761898791498, "tmdate": 1762927711650, "mdate": 1762927711650, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a novel few-shot research idea auto-generation framework that uses a gap-driven cross-pollination approach between existing papers. It solves the issue of generating meaningless ideas by introducing a structured, multi-agent process to create a comprehensive Idea Representation (synopsis and procedural profiling) for source papers. An LLM-agent then systematically integrates the structured components of a 'base study' and an 'innovation source' to generate a novel, implementable research proposal. The framework is evaluated using a rigorous, prospective methodology that validates generated ideas against subsequent published work via semantic similarity, unique paper ratio, and recency-weighted novelty scores, demonstrating superior performance over baselines."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. The framework shifts from opaque, problem-driven methods to a gap-driven, cross-pollination approach. The use of structured procedural quadruplets (<I, M, O, D>) and explicit composition operations (integrate, replace, keep, remove) makes the idea genesis highly traceable, controllable, and inherently more practical.\n2. The multi-agent system extracts a robust and detailed structured representation (R) that captures not just the paper's synopsis (Task, Gap, Contribution) but also detailed procedural profiling. This representation is the technical backbone that enables effective and feasible cross-pollination.\n3. The paper introduces a strong, external validation methodology by matching generated ideas to subsequently published papers to assess relevance and implementability. The system achieves a 41% relative increase in high-similarity, relevant ideas compared to a state-of-the-art baseline."}, "weaknesses": {"value": "1. The entire idea representation and generation pipeline heavily relies on proprietary LLM agents (specifically GPT-4o-mini for extraction, role assignment, and cross-pollination). This dependence introduces reproducibility concerns and limits the generalizability of the proposed framework without access to similar high-end commercial models.\n2. While the structure is transparent, the critical decision-making processes—such as how the Role Assigner determines innovation strength ($G_{A_{r}}$) and how the Integration Agent chooses the specific operation (e.g., integrate vs. replace) for each procedural step—rely on internal LLM reasoning, which may still be subjective or difficult to debug.\n3. The \"gap-driven\" mechanism is strictly defined for cross-pollination between two papers (Base and Source). This binary limitation may fail to capture complex innovations that emerge from the synthesis of three or more foundational concepts or domains, a limitation present in many idea generation systems."}, "questions": {"value": "1. Given the reliance on GPT-4o-mini for multi-agent extraction and generation, what is the performance degradation when substituting this agent with an equivalent, completely open-source LLM (e.g., a high-performing Llama 3 variant)? This would be critical for establishing the true generalizability and accessibility of the framework.\n2. The current evaluation uses similarity to published papers as a proxy for implementability. Did the authors conduct any human-in-the-loop experiments, such as an expert-based feasibility rating, for the generated ideas, especially for those categorized in the \"Novel\" similarity range ($0.3 \\leq \\sigma < 0.5$)? Such a study is essential to validate the core claim of generating \"implementable\" ideas."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "fJCSLu3SX6", "forum": "R3PdluB82U", "replyto": "R3PdluB82U", "signatures": ["ICLR.cc/2026/Conference/Submission17889/Reviewer_6nnf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17889/Reviewer_6nnf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17889/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762257746875, "cdate": 1762257746875, "tmdate": 1762927711171, "mdate": 1762927711171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes few-shot idea auto-generation: represent papers with structured fields (task, gaps, contributions, procedural quadruplets) and generate new ideas by cross-pollinating paper pairs with an LLM agent. Uses GPT-based extractors for representations and a composition process (integrate/replace/keep/remove). Evaluates with similarity + recency-weighted novelty + unique-paper ratio over 3,353 papers / 8 domains; reports a 41% increase in high-similarity ideas while maintaining high novelty (~0.93)"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Clear pipeline with explicit field definitions and role assignment.\n- Procedural profiling improves interpretability and compositional control.\n- Transparent metrics (similarity, novelty, uniqueness) and ablations across multiple domains with adequate analysis\n- Reasonable scale (3.3K papers / 8 domains) and reproducible setup for the experiment."}, "weaknesses": {"value": "- Presence issue: Figure 1 above the abstract breaks the submission instruction.\n- The core idea of cross-paper ideation is conceptually similar to prior frameworks such as SciAgents.\n- Evaluations rely entirely on embedding-based proxies without validation. Similarity is not the guarantee for the quality - the 41% high-similarity gain may reflect retrieval bias rather than true innovation. No human eval of generated ideas. limited human evidence that appendix lacks agreement or statistical analysis\n- Weights (λ, α, β) in the novelty function are not analyzed in the main text."}, "questions": {"value": "- How sensitive are results to the embedding model and novelty weights (λ, α, β)?\n- Why is higher similarity treated as a positive outcome—does it risk penalizing novel ideas?\n- Could citation-graph or causal relations be incorporated to strengthen semantic reasoning beyond surface similarity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "t2yIIAeACm", "forum": "R3PdluB82U", "replyto": "R3PdluB82U", "signatures": ["ICLR.cc/2026/Conference/Submission17889/Reviewer_s2wH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17889/Reviewer_s2wH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17889/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762301610250, "cdate": 1762301610250, "tmdate": 1762927710601, "mdate": 1762927710601, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}