{"id": "BnrIau5IoS", "number": 7450, "cdate": 1758022620266, "mdate": 1759897852245, "content": {"title": "Federated Deblurring as a Jigsaw Puzzle: A Privacy-Preserving Consensus Framework", "abstract": "Multi-observation deblurring seeks to recover a clear image from multiple blurred observations, yet most methods assume centralized access to full-scene data, which is unrealistic in practical scenarios where images are captured by distributed, independent devices. We introduce a more realistic federated setting where each client holds a private, partially overlapping view of a larger scene. This creates an “information jigsaw puzzle” that must be solved under strict privacy and regulatory constraints, without sharing raw images, kernels, or intermediate image estimates. We propose FedDeblur, a principled federated optimization framework based on consensus that decouples client-side local data fidelity updates and a server-side global image prior update. Clients transmit only carefully designed, desensitized variables, while the server coordinates global consensus. The modularity of our framework enables the server to flexibly incorporate diverse image priors, bridging classic regularizers like total variation with modern deep plug-and-play (PnP) denoisers, all transparently to clients. Crucially, all client-side updates admit efficient closed-form solutions, eliminating the need for inner iterations and making our framework practical for resource-constrained edge devices. Experiments demonstrate that FedDeblur seamlessly integrates fragmented information from partial views, effectively solving the jigsaw puzzle and achieving performance close to an idealized, non-private centralized oracle.", "tldr": "", "keywords": ["Federated Optimization", "Image Inverse Problems", "Plug-and-Play (PnP) Priors", "Privacy-Preserving"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0640ec16f46be9b5903f02e8217039d22f519ea6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies federated deblurring with multiple observations. Several clients each hold a blurred view of the same scene, and some views cover only part of the scene. The goal is to recover a clean global image without sending raw images, kernels, or masks. The proposed framework, FedDeblur, follows a consensus design: each client performs the data fidelity step locally, and the server applies a light proximal update to a shared proxy that protects privacy. The method supports partial field of view, allows plug and play priors on the server, and works with partial client participation. Under convex regularizers, the authors also provide convergence guarantees."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper targets a relevant privacy-constrained collaboration setting and defines it clearly. The consensus design is simple and practical: data-fidelity updates stay on device, priors are applied on the server, and only a sanitized proxy is communicated, which creates a natural privacy boundary. The framework is modular and supports both classical TV priors and plug-and-play denoisers without changing the interface. It also handles partial field of view and partial client participation with the same protocol. The algorithm admits closed-form local updates and a lightweight server step, and the authors provide convergence guarantees under convex regularizers. Empirical results are close to a centralized oracle and stronger than non-collaborative and Fed-averaging baselines, with useful robustness studies over participation rate, noise level, and hyperparameters."}, "weaknesses": {"value": "I acknowledge that I am not a domain expert in federated imaging, but from a generalist technical perspective several aspects feel underdeveloped. The practical value proposition and concrete deployment scenarios are not specified clearly enough to justify the added complexity of the federated setup; the privacy claim remains qualitative, lacking a precise threat model, leakage experiments, or formal guarantees. Basic systems evidence is missing, including latency per image, communication volume per round, and memory or compute footprint, which makes operational feasibility hard to judge. The experiments appear toy-scale, relying on low-resolution synthetic data, regular grid crops, and known blur kernels, with no tests on irregular partial views, blind deblurring, or diverse real devices. Robustness to stragglers, unreliable networks, or adversarial and low-quality clients is not examined. Clearer reproducibility materials and a brief end-to-end walkthrough would also help non-specialists and practitioners validate and adopt the method."}, "questions": {"value": "I’m not a domain expert here, so I’d appreciate clarification on a few essentials: the concrete deployment scenarios where the federated design clearly beats a centralized upload; a precise threat model plus any attack tests or formal guarantees showing the shared proxy doesn’t leak content or device fingerprints; basic efficiency numbers (per-round communication, latency, memory/compute, time-to-convergence); and broader validation on real multi-device data, blind deblurring, irregular/sparse FOV, and higher resolutions, including robustness to stragglers or adversarial/low-quality clients and the stability of the PnP variant. I’ll weigh your rebuttal and the other reviewers’ input before finalizing my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "gwyLmZHopk", "forum": "BnrIau5IoS", "replyto": "BnrIau5IoS", "signatures": ["ICLR.cc/2026/Conference/Submission7450/Reviewer_eUZt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7450/Reviewer_eUZt"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761691894288, "cdate": 1761691894288, "tmdate": 1762919564050, "mdate": 1762919564050, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of recovering a sharp picture from multiple crops of that image (each one blurred by its own blur kernel), possibly captured by multiple devices, in a federated computation framework, addressing in particular privacy issues."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses what is, as far as I know, a new problem, and the proposed approach appears to be sound, with classical components such as ADMM, proximal updates, etc., as well as a genuine effort to propose a privacy preserving approach in a distributed effort, and some theoretical analysis in the case where all clients have access to (a blurry version of) the whole image."}, "weaknesses": {"value": "It is difficult for me to envision a practical application scenario for the proposed approach. Unless I missed something, the blur kernels are assumed to be known. This may be true for astronomy or microscopy applications, but they typically are unknown for the photography applications that appear to be the focus of the paper. In addition, defocus blur normally varies within an image, including image crops unless they are quite small.  Motion blur often does, and it is unclear how the multiples images used as input are supposed to be synchronized in a dynamic setting. Multiple devices (or the same device over time) induce images motions that are not accounted for in the paper, where, unless I am mistaken, all input images are assumed to be prealigned. Of course, one could just distribute deblurring of a single image with (known) spatially varying levels of blur across multiple processors processing individual crops, with one kernel associated with each crop, but the images under consideration are very small (256x256) and it is unclear why a federated algorithm is needed for such images. It should also be noted that the CenDeblur baseline appears to do at least as well as the proposed method in quantitative evaluations. Finally, there is no qualitative evaluation on real images."}, "questions": {"value": "I would appreciate if the authors clarified the issues raised in the \"weaknesses\" section of this review."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WEOYvcbcAJ", "forum": "BnrIau5IoS", "replyto": "BnrIau5IoS", "signatures": ["ICLR.cc/2026/Conference/Submission7450/Reviewer_2hPc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7450/Reviewer_2hPc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761760107837, "cdate": 1761760107837, "tmdate": 1762919563189, "mdate": 1762919563189, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FedDeblur, a novel federated optimization framework for multi-observation image deblurring under privacy constraints.\nUnlike conventional centralized deblurring approaches that assume full data access, this work considers a realistic setting where each client holds a private, partially overlapping view of a larger scene. The problem is formulated as an “information jigsaw puzzle” solved through a federated consensus mechanism based on ADMM. The proposed method decouples local data fidelity (client-side) and global image prior (server-side), enabling privacy-preserving collaboration without sharing raw images, blur kernels, or intermediate estimates.\nAll local updates admit closed-form solutions, ensuring computational efficiency on edge devices."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1 The paper clearly defines federated multi-observation deblurring as a new research problem, bridging image restoration and federated optimization in a meaningful and practically relevant way.\n\n2 The FedDeblur framework is elegantly built on the consensus form of ADMM, with rigorous variable decoupling that enforces privacy at multiple levels (raw data, intermediate estimates, field of view).\n\n3 Both complete and partial observation scenarios are tested, using multiple priors. FedDeblur consistently matches or nearly matches centralized baselines while outperforming naïve federated alternatives."}, "weaknesses": {"value": "1 The theoretical convergence proof assumes convex regularizers, but the experiments include deep PnP priors, which are typically non-convex. The paper could better clarify empirical convergence behavior in such settings.\n\n2 While the results are convincing, the experiments are confined to relatively small synthetic datasets. Evaluation on more realistic or higher-resolution images would strengthen the empirical claims.\n\n3 Since the paper emphasizes efficiency and privacy for edge deployment, demonstrating actual runtime, communication cost, or real-device experiments would improve credibility.\n\n4 The baselines include only classical methods and a FedAvg-style variant. Comparisons with recent distributed or privacy-aware image restoration methods would enhance completeness."}, "questions": {"value": "1 How sensitive is FedDeblur to the ADMM penalty parameter ρ? The appendix mentions stability, but a systematic ablation could be informative.\n\n2 Could the framework support asynchronous or partial participation (e.g., stragglers)? This would be important for scalability in real federated systems.\n\n3 Have the authors considered extending FedDeblur beyond deblurring (e.g., super-resolution or denoising)? Given the modularity, it seems straightforward."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JSiSZTg63z", "forum": "BnrIau5IoS", "replyto": "BnrIau5IoS", "signatures": ["ICLR.cc/2026/Conference/Submission7450/Reviewer_hdyJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7450/Reviewer_hdyJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927663730, "cdate": 1761927663730, "tmdate": 1762919562868, "mdate": 1762919562868, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a federated learning approach to image deblurring, where each client observes a sub-region of the image blurred with their own blur kernel and corrupted by additive noise. The optimization is solved in a distributed manner via an ADMM framework, so that each client solves their own problem in a lightweight procedure while preserving their privacy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is overall well written and fairly easy to understand. The main optimization problem in equation (1) follows the traditional variational setup, with an L2-norm fidelity term and a regularization term. Privacy is considered in a federated learning setup, so that local variables are not shared, only shared variables."}, "weaknesses": {"value": "1. The main issue is that the posed optimization problem is very contrived, and entirely impractical and unrealistic. How is it possible that different clients observe subsets of the EXACLTLY the image (with different blurs and additive noise) of a 3D scene, using different cameras with different settings? First of all, different perspectives of the 3D scene mean very different composed images, due to occlusion, motion parallax, alignment, etc. Is the scene even Lambertian, so that a 3D point observed from different perspectives yield the same color? There are common non-Lambertian surfaces like mirrors and reflections of coffee shop windows. Second, different camera settings mean different image resolutions, aperture, shutter speed, ISO, resulting in very different captured images. How can one guarantee even the lighting conditions are the same? Third, different built-in camera pre-processing means different demosaicking, color calibration, contrast enhancement algorithms, etc, resulting in different reconstructed images. Finally, there is also a temporal aspect: under what scenario would all the cameras be activated at exactly the same time? if the photos are taken at even slightly different times, then object motion, scene lighting etc would change the scene composition. Simply ignoring all of that into formulation in equation (1), with a single blur kernel $h_k$ and additive noise $y_k$ is not realistic at all. \n\n2. It is very well known that ADMM can introduce auxiliary variables so that the sub-problems can be solved in a distributed manner; this was described in the original Boyd's ADMM paper back in 2011. This is the core idea behind the proposed optimization in the paper, so it is difficult to discern novelty here above and beyond existing convex optimization techniques. \n\n3. One of the key issues in an ADMM approach is the potential slow rate of convergence. This was not addressed in the paper.\n\n4. In the experiments, each test image is just cropped into different sub-regions and then blurred with different kernels and added with noise. This bears no resemblance to the multi-camera setting by different clients that the authors motivated in the introduction."}, "questions": {"value": "1. How would the authors account for all the heterogenous conditions in practice from capturing images by different clients from different perspectives, using different cameras, with different camera settings, at different times? \n\n2. Given that it is known for well over a decade that ADMM can be solved distributedly, what exactly is the key novelty in the distributed optimization algorithm proposed in the paper, above and beyond existing ADMM optimization in the literature?\n\n3. Please comment on the convergence rate of the proposed ADMM algorithm, along with theoretical rate of convergence guarantees (if any). \n\n4. How can the experiments be improved to render a more realistic setting closer to reality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BUwht45jwp", "forum": "BnrIau5IoS", "replyto": "BnrIau5IoS", "signatures": ["ICLR.cc/2026/Conference/Submission7450/Reviewer_eZwt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7450/Reviewer_eZwt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951693678, "cdate": 1761951693678, "tmdate": 1762919562249, "mdate": 1762919562249, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}