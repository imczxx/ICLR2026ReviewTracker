{"id": "n9cGjk78RK", "number": 12197, "cdate": 1758206276401, "mdate": 1763645310902, "content": {"title": "Synergizing Large Language Models and Task-specific Models for Time Series Anomaly Detection", "abstract": "In anomaly detection, methods based on large language models (LLMs) can incorporate expert knowledge by reading professional document, while task-specific small models excel at extracting normal data patterns and detecting value fluctuations from training data of target applications. Inspired by the human nervous system, where the brain stores expert knowledge and the peripheral nervous system and spinal cord handle specific tasks like withdrawal and knee-jerk reflexes, we propose CoLLaTe, a framework designed to facilitate collaboration between LLMs and task-specific models, leveraging the strengths of both models for anomaly detection. In particular, we first formulate the collaboration process and identify two key challenges in the collaboration: (1) the misalignment between the expression domains of the LLMs and task-specific small models, and (2) error accumulation arising from the predictions of both models. To address these challenges, we then introduce two key components in CoLLaTe: a model alignment module and a collaborative loss function. Through theoretical analysis and experimental validation, we demonstrate that these components effectively mitigate the identified challenges and achieve better performance than both LLM-based and task-specific models.", "tldr": "Inspired by human nervous system, formulate the collaboration between LLM and task-specific anomaly detection model and solve involved challenges", "keywords": ["Unsupervised Anomaly Detection", "Time Series", "Large Language Model", "Task-specific Small Model", "Model Collaboration"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0d0df78460f8b15a72bd1e67d425910f9469ba6e.pdf", "supplementary_material": "/attachment/c0d42f966479f981e3f8da6052bb3c4e47eba934.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes CoLLaTe, a framework that integrates a task-specific time-series anomaly detector (TSADM) with a large language model (LLM) for enhanced anomaly detection. The core idea is to combine the numerical pattern recognition strength of TSADMs with the domain knowledge reasoning capability of LLMs. CoLLaTe introduces two main components:\n(i) an alignment module that harmonizes the anomaly-score ‚Äúexpression domains‚Äù of the two models by fitting a half-Gaussian density to the LLM‚Äôs score distribution and learning a mapping that makes the TSADM scores follow this distribution; and\n(ii) a fusion module that combines both scores through a conditional network trained with a collaborative loss, designed to mitigate the ‚Äúerror accumulation‚Äù observed with MSE-based objectives.\n\nThe paper provides theoretical analysis of the proposed loss and presents empirical results on four datasets, showing strong F1-score improvements and robustness to distribution shifts. Ablation studies further validate the contributions of each module."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "S1: The paper‚Äôs identification of two key integration challenges, score misalignment and error accumulation are is both insightful and practically relevant for fusing heterogeneous detectors such as LLMs and TSADMs. The qualitative evidence in Fig. 1(b‚Äìd) (p. 3) effectively illustrates the semantic gap between their scoring behaviors and motivates the proposed alignment mechanism.\n\nS2: The proposed architecture (Fig. 2, p. 3) is lightweight and modular, using a small conditional MLP that can be flexibly applied to various TSADM‚ÄìLLM pairs. The reported memory footprint and the manageable training/inference latency demonstrate strong engineering efficiency and potential for real-world integration.\n\nS3: The evaluation covers four datasets and includes module ablations, hyperparameter sensitivity analyses, and distribution-shift tests, consistently showing improved performance. This breadth of experimentation strengthens confidence in the method‚Äôs robustness and generality.\n\nS4: The discussion on how MSE objectives can propagate bias when both sources are imperfect‚Äîand how the proposed pairwise collaborative loss mitigates such accumulation‚Äîis well reasoned. The theoretical properties, such as preserving relative ordering differences (Theorem 2), add useful interpretability to the optimization behavior."}, "weaknesses": {"value": "W1: Selecting the best GPT-4 run for collaboration (p. 20) introduces potential selection bias, giving the fused model an unfair advantage and likely inflating reported performance. A more rigorous evaluation would use fixed or randomly sampled LLM outputs, or report mean and variance across multiple runs to ensure fairness.\n\nW2: The assumption that the LLM‚Äôs score distribution follows a half-Gaussian form, and aligning the TSADM outputs to this distribution appears brittle and under-justified. The paper does not specify the parameterization of the mapping function M(‚ãÖ) or enforce monotonicity constraints. As a result, the alignment objective in Eq. (3) risks overfitting to an arbitrary density rather than learning a semantically meaningful correspondence.\n\nW3: The paper omits precise mathematical definitions for ùê∑_intra and ùê∑_inter, referencing them only through qualitative visualizations in Fig. 3. Without explicit formulas or explanations of their metrics, scaling across variates, or windowing behavior, it is difficult to reproduce or interpret the reported sensitivity analyses."}, "questions": {"value": "Q1: What is the functional class of M(‚ãÖ)? Is it constrained to be monotone? How do you avoid degenerate mappings (e.g., many inputs mapped to a single bin)? Please provide the exact architecture (layers/activations) and regularizers.\n\nQ2: How many LLM runs were attempted per subset before picking the ‚Äúbest‚Äù? What were the decoding parameters? \n\nQ3: In Table‚ÄØ3 (unseen distributions), did you tune hyperparameters on held‚Äëout subsets only? Please clarify the selection protocol to ensure no test information was used."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "O7mDU3NzRy", "forum": "n9cGjk78RK", "replyto": "n9cGjk78RK", "signatures": ["ICLR.cc/2026/Conference/Submission12197/Reviewer_ct8Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12197/Reviewer_ct8Q"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761629259817, "cdate": 1761629259817, "tmdate": 1762923144619, "mdate": 1762923144619, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces CoLLaTe, a collaborative framework that integrates Large Language Models (LLMs) with task-specific anomaly detection models (TSADMs) to improve time-series anomaly detection."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper explicitly identifies two bottlenecks‚Äîdomain misalignment and error accumulation‚Äîand addresses them through clearly designed modules backed by theoretical proofs.\n2. CoLLaTe achieves state-of-the-art F1 scores on multiple datasets and shows robustness to distribution shifts, which strengthens the practical relevance of the framework.\n3. The theoretical results (Theorem 1, Lemma 1, Theorem 2) are well-connected to experimental observations, lending credibility to the proposed loss design."}, "weaknesses": {"value": "1. While the idea of combining LLMs and specialized models is timely, the actual implementation‚Äîalignment + weighted fusion‚Äîis relatively straightforward.\n2. LLM inference is computationally heavy; integrating it with TSADM could raise latency issues.\n3. The proofs rely on smoothness and distributional assumptions that may not hold in practice (e.g., half-Gaussian score distribution)."}, "questions": {"value": "1. Are the LLM outputs frozen or fine-tuned jointly with the TSADM and conditional network, and why?\n2. How sensitive is the alignment module to the choice of the fitted distribution (half-Gaussian)? Would a non-parametric mapping (e.g., histogram matching) perform similarly?\n3. Can the aligned scores or the conditional network outputs be interpreted to explain why a specific time point is deemed anomalous?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fFB0DFtGA7", "forum": "n9cGjk78RK", "replyto": "n9cGjk78RK", "signatures": ["ICLR.cc/2026/Conference/Submission12197/Reviewer_2vmL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12197/Reviewer_2vmL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864936686, "cdate": 1761864936686, "tmdate": 1762923143925, "mdate": 1762923143925, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes **CoLLaTe**, a framework that collaborates a task-specific time-series anomaly detector (TSADM) with an LLM. Two main components are introduced:\n1. a **score-alignment module** to map TSADM/LLM anomaly scores into a unified semantic/distributional space;\n2. a **collaborative loss** intended to mitigate ‚Äúerror accumulation‚Äù when combining the two sources.  \n    Experiments on four datasets (two public, two private) show that na√Øve combination can hurt performance, while alignment + collaborative loss recover and sometimes improve results (small gains on Mustang, larger gains on Mackey/Flight). The motivation is practical and the ablations are informative, but related work coverage, key baselines, theoretical rigor, and cost‚Äìbenefit analysis are insufficient."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- **Well-motivated engineering problem:** addresses the real friction of score semantic mismatch and error accumulation when mixing TSADM and LLM signals.\n- **Clear components & useful ablations:** alignment + collaborative loss are shown necessary (na√Øve fusion degrades; adding components repairs performance).\n- **Some empirical gains:** meaningful improvements on several datasets; the workflow matches practical ‚Äúalarm triage / false-positive reduction‚Äù use cases.\n- **Potential for deployment:** conceptually compatible with industrial pipelines."}, "weaknesses": {"value": "1. **Theory: unclear definitions and shaky derivations**\n    \n\n- **Alignment objective.** Main text moves from a binned, non-differentiable objective to a smooth surrogate but skips formalities. Let (f) be the target density (paper uses half-Gaussian). The non-diff objective is essentially  \n$$\n    \\min_{M}; -\\sum_{i=1}^N \\tfrac{c_i}{\\sum_j c_j}\\log!\\Big(\\int_{(i-1)/N}^{i/N} f(S),dS\\Big)  \n    ;+; \\lambda_1!\\Big(\\tfrac{1}{n}\\sum\\nolimits_{k} M(s_k)-\\hat\\mu\\Big)^2  \n    ;+; \\lambda_2(\\cdots)^2,  \n$$\n    where (c_i) counts mapped scores falling in bin (i). The paper then states (for (N!\\to!\\infty)) the surrogate  \n$$\n    \\min_{M}; -\\tfrac{1}{n}\\sum\\nolimits_{k}\\log f(M(s_k)) + \\lambda_1(\\cdots)^2+\\lambda_2(\\cdots)^2.  \n$$\n    However, the derivation omits the constant (\\log(1/N)) term and provides no error bound (e.g., Riemann-sum or dominated-convergence justification) for replacing the binned cross-entropy with the continuous NLL. Please provide a formal proposition with assumptions and a uniform convergence (or at least consistency) statement.\n    \n- **Choice of (f).** Using a half-Gaussian for scores (S $\\ge$ 0) is plausible but not justified. Given scores lie on a bounded interval in practice, Beta / logit-normal or isotonic calibration might be more appropriate. Please provide goodness-of-fit tests (e.g., KS, AD) and a robustness study across families; otherwise alignment risk is model-misspecified.\n    \n- **Collaborative loss / ‚Äúerror accumulation‚Äù theorem.** The paper states the MSE-based combination yields an optimum $\\hat S^\\star = y + \\lambda_1\\varepsilon_s + \\lambda_2\\varepsilon_S$ and then lower-bounds $\\mathbb{E}[(\\hat S^\\star - y)^2]$ by $(\\lambda_1\\mu_s+\\lambda_2\\mu_S)^2$ (Jensen). This ignores variance and covariance:  \n    $$\n    \\mathbb{E}[(\\hat S^\\star-y)^2]  \n    = \\lambda_1^2(\\sigma_s^2+\\mu_s^2)+\\lambda_2^2(\\sigma_S^2+\\mu_S^2)+2\\lambda_1\\lambda_2\\operatorname{Cov}(\\varepsilon_s,\\varepsilon_S),  \n    $$\n    which reduces to $(\\lambda_1\\mu_s+\\lambda_2\\mu_S)^2$ only under **zero variance** (or degenerate) conditions. Moreover the stationarity condition mixes $\\hat S$ as a deterministic function of parameters with random errors $\\varepsilon$. Please **restate the probability space**, clarify whether $\\hat S$ depends on sample noise at optimum, and **include variance/covariance** in the bound (or give conditions‚Äîunbiasedness, independence, bounded variance‚Äîunder which your inequality holds).\n    \n- **Undefined key quantities.** (D_{\\text{intra}}) / (D_{\\text{inter}}) are described verbally (‚Äúwithin-patch / across-patch distances‚Äù) but **lack formulas**. For example, if (x_t) are embeddings and (p(t)) is the patch index,  \n    $$\n    D_{\\text{intra}}(t)=\\tfrac{1}{|P(t)|-1}!\\sum_{j\\in P(t)\\setminus{t}}! d(x_t,x_j),  \n    \\quad  \n    D_{\\text{inter}}(t)=\\tfrac{1}{K-1}!\\sum_{k\\ne p(t)}! d(\\mu_{p(t)},\\mu_k),  \n    $$\n    with (d) (Euclidean/DTW/cosine) and (\\mu_\\cdot) specified. Please provide exact definitions, normalization, and metric choice in the main text.\n    \n- **Convergence claim.** The $(O(T^{-1/4}))$ rate borrowed from prior work requires Lipschitz smoothness, bounded stochastic gradients/noise, step-size schedule, etc. The paper should verify each assumption for the specific loss (including the alignment regularizers) and report constants (at least qualitatively).\n\n2. **Positioning & baselines**    \n- Missing **closest paradigms**: (i) _LLM‚ÜíTSAD distillation_ (training-time guidance; different collaboration locus), (ii) _TSAD‚ÜíLLM two-stage refinement_ (post-hoc vetting). Without these, contribution boundaries blur.\n- Missing **simple fusions**: score avg / max / vote and a learned meta-fuser (e.g., logistic regression/XGBoost on ($S_{\\text{TSADM}},S_{\\text{LLM}}$) with calibration) are standard sanity checks to justify your more complex design.\n\n2. **Evaluation & practicality**\n- **Cost‚Äìbenefit** is unclear: when strong TSADM already yields high F1, LLM adds only +2‚Äì3 points in places, yet latency/API cost appears substantial. Provide throughput/latency/cost vs. gain curves and scenarios where LLM is decisively worth it.\n- Some narrative claims (e.g., ‚ÄúLLM excels at point anomalies‚Äù) are not consistently supported; include a breakdown by anomaly type/length."}, "questions": {"value": "1. **Add closest & simple baselines:** Include _LLM‚ÜíTSAD distillation_, _TSAD‚ÜíLLM two-stage refinement_, and simple score fusion (avg / max / vote). Report gaps relative to CoLLaTe.\n2. **Theory fixes:**\n    - Give formal definitions and computation for $(D_{\\text{intra}})$ and $(D_{\\text{inter}})$.\n    - Re-state/prove the error-accumulation result with a consistent probability space and explicit variance terms.\n    - Justify the alignment distribution with goodness-of-fit tests and robustness analysis.\n3. **Where does LLM truly help?** Provide case studies and breakdowns (point vs. contextual, short vs. long anomalies) showing indispensable improvements.\n4. **Explain weak TSFM baselines:** Document implementations, tuning budgets, and why they underperform here."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2wOB021XwO", "forum": "n9cGjk78RK", "replyto": "n9cGjk78RK", "signatures": ["ICLR.cc/2026/Conference/Submission12197/Reviewer_NniG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12197/Reviewer_NniG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998497558, "cdate": 1761998497558, "tmdate": 1762923143481, "mdate": 1762923143481, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}