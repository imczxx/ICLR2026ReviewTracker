{"id": "Rhvigj4V8R", "number": 4508, "cdate": 1757691338745, "mdate": 1759898029082, "content": {"title": "MarkovScale: Towards Optimal Sequential Scaling at Inference Time", "abstract": "Sequential scaling is a prominent inference-time scaling paradigm, yet its performance improvements are typically modest and not well understood, largely due to the prevalence of heuristic, non-principled approaches that obscure clear optimality bounds. To address this, we introduce a principled framework that models sequential scaling as a two-state Markov process, uncovering its fundamental properties and providing closed-form expressions for key aspects, including the conditions under which sequential scaling enhances accuracy, the theoretical accuracy upper bound, and the convergence rate. Leveraging this formulation, we develop MarkovScale, a practical system that applies these optimality criteria to achieve a theoretically grounded balance between accuracy and efficiency. Comprehensive experiments across 3 backbone LLMs and 5 benchmarks show that MarkovScale consistently outperforms state-of-the-art parallel and sequential scaling methods, representing a significant step toward optimal and resource-efficient inference in LLMs. The source code will be open upon acceptance at https://open-upon-acceptance.", "tldr": "", "keywords": ["Inference-time Scaling", "Markov Decision Process", "Efficiency Optimality", "Probabilistic Framework", "LLM Reasoning"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d15c0e64f625fd31f45564faa44f67d802a49590.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors pose sequential test time scaling for LLMs as a two state Markov chain: Given the present completion from the model (or the question initially) either the model generates a correct (C) or an incorrect (W) completion in the next step of inference. By analyzing this Markov chain they identify the conditions under which scaling is beneficial, neutral and detrimental. They also relate the expected convergence to the probability of the model moving from C->W or from W->C which then enables them to determine upper and lower bounds on performance when scaling in this way. Using this they develop a series of methods that aim to determine when to use scaling, and how much scaling to use. They then compare their methods with other test-time scaling methods, showing it has favorable performance on 3 models and 5 test sets."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- This work is timely and addresses a key question about test-time scaling, namely how much to do and in what circumstances it is beneficial to do so\n- The performance bounds are nice and give a benchmark against which to compare methods\n- Despite some problems with the exposition the central idea in this paper is quite elegant and uncomplicated."}, "weaknesses": {"value": "- Figure 3 could do with some improvement. I think a bar chart or some other chart that doesn't imply an interpolation between benchmarks might be more appropriate.\n- The exposition in section 3.3 is a bit sloppy. For instance, where does this theoretical bias term originate from? What does $q$ represent (a question I'm guessing)? Is $p$ in (6), (7) and (8) $p_0$ or $p_i$?\n- I think the framing around section 3.3 could do with some justification: I'm a bit skeptical about model capability and problem difficulty being disentangled in this way. Surely the models capability is also related to the zero shot probability of correctness, just as the problems difficulty is related to $a$ and $b$? Additionally you frame $a$ and $b$ as being intrinsic to the model, yet you clearly estimate it separately for each dataset (or maybe example if $q$ represents a single question) or how else would the results in figure 2 be different? I would have like a bit more clarity about exactly what $a$ and $b$ represent and how they were estimated.\n- I would have liked to have seen baseline results with no test time scaling."}, "questions": {"value": "All of your methods appear to perform quite similarly, especially on the smaller models, are there any reasons to prefer one over the others?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uJomGyEq3T", "forum": "Rhvigj4V8R", "replyto": "Rhvigj4V8R", "signatures": ["ICLR.cc/2026/Conference/Submission4508/Reviewer_NLpN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4508/Reviewer_NLpN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760972729540, "cdate": 1760972729540, "tmdate": 1762917412007, "mdate": 1762917412007, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new algorithm, based on a discrete Markov process, for inference time scaling of LLMs via sequental scaling. I am no expert in LLMs or methods research on top of LLMs, so I don't have high confidence in my review. What is more, I am short on time due to the semester start. Apologies if my reviews are a bit short. I am happy to engage in reviewer discussion should be concerns not be clear. \nThat said, I think the suggested approach appears sensible, easy to understand and verify, and leads to improved results compared to baselines. So, from my far away perspective, I think this paper is a relevant contribution to the field."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear theoretical framework.\n- Easy to understand approach yet providing good empirical accuracy.\n- Clear and consistent improvements against many benchmarks."}, "weaknesses": {"value": "- I am too far away from the field to judge this in detail"}, "questions": {"value": "- The notation around EQ2 looks a bit messy. Sometimes there is an index i, sometimes there is not. a P seems to be missing in EQ2. Can you double check and fix the notation to be consistent?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "61fNy9nNBE", "forum": "Rhvigj4V8R", "replyto": "Rhvigj4V8R", "signatures": ["ICLR.cc/2026/Conference/Submission4508/Reviewer_puxx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4508/Reviewer_puxx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835715193, "cdate": 1761835715193, "tmdate": 1762917411718, "mdate": 1762917411718, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper first makes an observation that parallel scaling tends provide better performance but is token efficient compared to sequential scaling approaches. The paper aims to optimize the sequential scaling.\nGiven the inference-time scaling, it seems that the paper is trying to formulate the problem of scaling as a two-state Markov process. The work uses this formulation for the correctness probability to get the performance bounds: neutral, upper, and lower and use that as the theoretical basis to directly estimating the convergence accuracy.\nMarkovScale proposed in the paper has several variants: (1) gating strategy, (2) MAP-based optimal scaling, and (3) training-free version. \nThe paper evaluates the MarkovScale approach on combinations of several models and benchmark to compare against several methods including ones based on budget, early stopping, self-consistency, etc.\nThe paper demonstrates that it achieves better results (accuracy) given same token consumption."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is tacking a very important topic of token-efficient inference-time scaling.\n* It seems the paper is trying to move from previous heuristic based approaches to an approach that is a little more backed by theoretical formulation which seems nice."}, "weaknesses": {"value": "* Formulation seems rather oversimplified as overall reasoning process in inference-time scaling is not easy to boil down to simply correct vs incorrect. It is literally a reasoning process where things can go south then use that as a context to later converge on a better outcome. However, the oversimplification of the formulation seems to understate the significance of this.\n* Seems rather unclear how the transition probabilities and zero-shot probability are computed in the MarkovScale."}, "questions": {"value": "* Can you please elaborate how transition probabilities and zero-shot probability are computed in the MarkovScale. Some details would be great.\n* Is there any projection to how this can be generalized to different models of different scale? It seems that the models evaluated in the paper are pretty small.\n* Figure 1 stops the evaluation at around 700k tokens. What happens after that would also be interesting data to show whether the work (as well as the other approaches) are really controlling the inference-time scaling in an optimal manner.\n* It is also interesting to see in Table 1 that MarkovScale0 seems to perform better than other variants a few times. Is this just error margin? Given that the MarkovScale based on MAP could be assumed to provide a good performance, does this mean that MLP was not trained enough? It seems that it is difficult to fully rule out the overfitting?\n* Is there a good results showing how hyperparameters were determined?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SQP52NgLCz", "forum": "Rhvigj4V8R", "replyto": "Rhvigj4V8R", "signatures": ["ICLR.cc/2026/Conference/Submission4508/Reviewer_SX1J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4508/Reviewer_SX1J"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942035079, "cdate": 1761942035079, "tmdate": 1762917409947, "mdate": 1762917409947, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}