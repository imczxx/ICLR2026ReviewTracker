{"id": "uYK6GPVg1O", "number": 21548, "cdate": 1758318823478, "mdate": 1759896916386, "content": {"title": "Estimating Semantic Alphabet Size for LLM Uncertainty Quantification", "abstract": "Many black-box techniques for quantifying the uncertainty of large language models (LLMs) rely on repeated LLM sampling, which can be computationally expensive. Therefore, practical applicability demands reliable estimation from few samples. Semantic entropy (SE) is a popular sample-based uncertainty estimator with a discrete formulation attractive for the black-box setting. Recent extensions of semantic entropy exhibit improved LLM hallucination detection, but do so with less interpretable methods that admit additional hyperparameters. For this reason, we revisit the canonical discrete semantic entropy estimator, finding that it underestimates the \"true\" semantic entropy, as expected from theory. We propose a modified semantic alphabet size estimator, and illustrate that using it to adjust discrete semantic entropy for sample coverage results in more accurate semantic entropy estimation in our setting of interest. Furthermore, our proposed alphabet size estimator flags incorrect LLM responses as well or better than recent top-performing approaches, with the added benefit of remaining highly interpretable.", "tldr": "Semantic alphabet size estimation enhances semantic entropy estimation and black-box LLM incorrectness detection.", "keywords": ["large language model", "uncertainty quantification", "hallucination", "entropy", "alphabet"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7231f11ac593fe12acb3efead7fc8178ade2bfaa.pdf", "supplementary_material": "/attachment/36c33b7455047f6b450e687c8af1373b6e3a61c0.zip"}, "replies": [{"content": {"summary": {"value": "I really like this paper. It takes a fairly simple premise: sampling-based estimators of the clustering distribution will tend to miss the tail, leading to systemic underestimation of semantic entropy. But: We have robust estimators for the size of the tail. So, we can get modified estimators of either the number of semantic clusters, or the semantic entropy. And, these modified estimators lead to improved performance."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "* It’s a simple idea... in a good way. It identifies a clear problem, finds parallels in the species sampling literature for heavy tailed distributions, and proposes a simple, interpretable solution.\n* It leads to improvement. \n* The evaluation is very thoughtful (one of the best discussions of how to evaluate UQ methods I have seen)\n* The paper is clear and well-written"}, "weaknesses": {"value": "* It’s not strictly improving on SoTA... but it is compatible with SoTA using a much simpler and more interpretable paradigm\n* The idea of using a Good-Turing estimator has been explored in related problems in the literature, as acknowledged by the authors."}, "questions": {"value": "* It’s interesting that you find that the adjusted number of sets outperforms the adjusted semantic entropy. It would be nice to see how the “ground truth” number of sets compares with “ground truth” semantic entropy... if in this setting ground truth number of sets outperforms ground truth semantic entropy, it might suggest something interesting about miscalibration of the LLM. \n* I’d like to see (maybe in the discussion) discussion of how one might extend this to white-box SE estimation (which will tend to suffer from the same problem, albeit to a lesser extent)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "XfrKcIvFus", "forum": "uYK6GPVg1O", "replyto": "uYK6GPVg1O", "signatures": ["ICLR.cc/2026/Conference/Submission21548/Reviewer_RUVy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21548/Reviewer_RUVy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761091716094, "cdate": 1761091716094, "tmdate": 1762941830332, "mdate": 1762941830332, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Goal:\n- This paper addresses a specific issue in discrete semantic entropy (DSE), a widely used black-box UQ method.  \n- The authors show that DSE tends to underestimate uncertainty when the response sample size is small, because it often fails to capture all unseen semantic clusters, therefore underestimating the number of distinct meaning clusters in its outputs (**semantic alphabet size**).\n\nEmpirical Validation:\n- To verify this bias, the authors compare DSE values from small-sample settings against 100-sample semantic entropy (treated as ground-truth uncertainty).\n- Across all model–dataset pairs, DSE consistently produces lower uncertainty estimates as sample size decreases.\n\nMethod:\nTo better estimate the semantic alphabet size, the paper considers 2 existing approaches:\n1. A Good–Turing coverage estimator, adapted from population ecology, which corrects for unseen categories in finite samples\n2. A spectral method based on eigenvalue decomposition (Lin et al.), which estimates alphabet size from the number of non-zero eigenvalues of a semantic similarity matrix.\nThe authors then propose a hybrid estimator that combines these two strategies: \n- when Good–Turing coverage becomes unreliable (e.g., each cluster appears only once), the method defaults to the spectral estimate; \n- otherwise, it uses a weighted combination to mitigate underestimation bias.\nUsing this hybrid alphabet size, they further define a hybrid semantic entropy estimator, extending classic ecological entropy formulations to the semantic domain.\n\nEvaluation:\n1. Following standard UQ evaluation protocols, the study benchmarks ten uncertainty estimators across four LLM families and four datasets.\n2. Because raw AUROC scores can vary with model and dataset, the authors adopt a Bradley–Terry latent strength model to aggregate pairwise AUROC comparisons into an overall ranking with confidence intervals—an extension of the win-rate framework proposed by Nikitin et al. (2024).\nOverall, results show that the hybrid semantic alphabet size estimator performs most consistently across settings, while the hybrid semantic entropy estimator reduces but does not fully eliminate the negative bias in DSE."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem itself is important.\n2. The solution is simple.\n3. The evaluation considers the weakness of AUROC and proposes the Bradley-Terry latent strength scores, which make the evaluation more reliable. \n4. The paper is easy to understand and well-structured. I like its simplicity and enjoy reading it."}, "weaknesses": {"value": "1. Limited methodological novelty and analysis.\n- The proposed hybrid estimator mainly combines two existing techniques \n   -  the Good–Turing coverage estimator from population ecology\n   - a spectral eigenvalue-based method\nI am not saying that combining prior ideas is not good, and my point is that it can be done with a deeper analysis of each individual methods and the hybrid operation can be done more adaptively. \n- For example, the Good–Turing approach is well established for ecological sampling, yet the sampling distribution of LLM-generated responses can be very different. It remains unclear why this method should perform reliably in the LLM setting or under what conditions it might fail. \n- Similarly, the hybrid design could be more principled — for instance, by characterizing when each component estimator is more accurate, rather than simply prioritizing the larger estimate under certain cases. This max operation inherently assumes that both the spectral-based method and Good-Turing coverage-based methods are also underestimating the ground truth semantic cluster size. But is this assumption true?\n\n2. Inconsistent motivation and results.\nThe empirical validation (Figure 2 and table 1) assumes that semantic entropy computed with 100 samples represents the ground truth. However, this assumption itself is not rigorously justified. Moreover, the paper’s motivation is to improve DSE-based uncertainty estimation, yet the final results show that DSE-derived methods (including the hybrid entropy estimator) still lag behind KLE and the semantic alphabet size estimator in overall performance (always ranking from 7-10). This weakens the narrative that improving DSE necessarily leads to better uncertainty quantification."}, "questions": {"value": "1. Equation (8) appears to be missing the definition or notation for $p_i$. \n2. I have multiple questions regarding the experiment results (Figure 3): \n- Why was white-box semantic entropy not included in the comparison, since you also consider the PE? \n- In addition, both hybrid semantic entropy ($\\hat{H}_\\text{hybrid}$) and discrete semantic entropy (DSE) show notably lower rankings (around 7–10). Could you elaborate on why these methods perform substantially worse than others? Conceptually, both $\\hat{H}_\\text{hybrid}$ and DSE should still be affected by the same underestimation bias that motivates your paper. If the semantic alphabet size were estimated more accurately, shouldn’t this also mitigate the underestimation problem in DSE to some extent?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "zY1HzgShR2", "forum": "uYK6GPVg1O", "replyto": "uYK6GPVg1O", "signatures": ["ICLR.cc/2026/Conference/Submission21548/Reviewer_SfCH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21548/Reviewer_SfCH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896768359, "cdate": 1761896768359, "tmdate": 1762941830076, "mdate": 1762941830076, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of underestimating semantic entropy (SE) as an uncertainty estimate for black-box LLMs. The authors propose an interpretable semantic alphabet size estimator which, when used to adjust the discrete SE estimator for sample coverage, yields more accurate uncertainty estimation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed semantic alphabet size estimator effectively mitigates the underestimation bias of discrete semantic entropy (DSE) in the few-sample regime.\n- The method is simple and interpretable, avoiding the complexity and hyperparameter dependence of recent SE extensions.\n- Empirically, it improves UQ performance and matches or exceeds the performance of SOTA approaches in the back-box setting."}, "weaknesses": {"value": "- My main concern is that the proposed method is largely an adaptation of existing estimators to the SE setting. While the idea is insightful, it constitutes an incremental improvement over Farquhar et al. (2024) rather than a fundamentally new theoretical contribution.\n- The paper treats semantic clusters as fixed and does not analyze sensitivity to the clustering procedure (e.g., entailment thresholds or NLI model biases). Since clustering quality directly affects entropy estimates, this omission is a potential confounder that limits the scope of the contribution.\n- Experiments are restricted to relatively small models (<10B parameters), which raises questions about generalization to larger, frontier LLMs. Moreover, the paper does not compare against computationally cheaper uncertainty measures that avoid expensive sampling (e.g., G-NLL [1]) and which outperform SE and DSE with a single sample.\nMinor point: The paper inconsistently uses the abbreviations (like SE and DSE), alternating between the abbreviated and full forms without clear rationale, which makes it harder to follow.\n\n---\n\n[1] Lukas Aichberger, Kajetan Schweighofer, and Sepp Hochreiter. Rethinking uncertainty estimation in natural language generation. arXiv preprint arXiv:2412.15176, 2024.\n\n[2] Sebastian Farquhar, Jannik Kossen, Lorenz Kuhn, and Yarin Gal. Detecting hallucinations in large language models using semantic entropy. Nature, 2024."}, "questions": {"value": "- How quickly does the “white-box” SE estimate converge to the \"true\" SE as the number of samples increases? Including this in Figure 2 would be interesting.\n- Are 100 samples sufficient to approximate the true distribution over semantic clusters? An ablation with larger sample sizes (e.g., 1 k) could strengthen the claim that this is a valid reference.\n- How sensitive are the results to the semantic clustering method (e.g., choice of NLI model, thresholding, or entailment aggregation)?\n- The hybrid estimator uses a max(·) rule combining two estimators. Why is this choice theoretically justified versus, say, a weighted or Bayesian combination?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "300HJDQUc5", "forum": "uYK6GPVg1O", "replyto": "uYK6GPVg1O", "signatures": ["ICLR.cc/2026/Conference/Submission21548/Reviewer_foRW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21548/Reviewer_foRW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912624038, "cdate": 1761912624038, "tmdate": 1762941829853, "mdate": 1762941829853, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Authors propose a better (less biased) estimator for semantic-alphabet-size in the semantic-entropy-related methods for UQ estimation in NLG tasks. \nThey show empirically that their semantic-alphabet-size is competitive with some of the SOTA methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. The contribution is principled and to my best judgement technically correct.\n\nS2. The empirical performance of the proposed method is strong.\n\nS3. I find the empirical evaluation methodology sound."}, "weaknesses": {"value": "W1. The evaluation could use more datasets (despite being sound methodologically).   \nThere are codebases available which would make the process rather straightforward, given the method proposed is rather simple to implement once the Semantic-Clustering is computed: https://github.com/AlexanderVNikitin/kernel-language-entropy. + maybe SimpleQA?(https://openai.com/index/introducing-simpleqa/)\n\nW2. Not sure how \"significant\" the contribution will prove to be, but I hate to judge this criterium, so please treat this complaint as secondary. If this was judged by TMLR criteria, my overall score would be an \"accept\"."}, "questions": {"value": "Q1. Would it possible to create a Figure-2-like plot but for semantic-alphabet-size estimators?\n\nQ2. Nitpick: could you please change the font in Fig 1 to a Serif font?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Sf3izCJxxz", "forum": "uYK6GPVg1O", "replyto": "uYK6GPVg1O", "signatures": ["ICLR.cc/2026/Conference/Submission21548/Reviewer_T6sp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21548/Reviewer_T6sp"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762535542151, "cdate": 1762535542151, "tmdate": 1762941829483, "mdate": 1762941829483, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}