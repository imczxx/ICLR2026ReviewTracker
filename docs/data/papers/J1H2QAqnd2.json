{"id": "J1H2QAqnd2", "number": 7197, "cdate": 1758011251867, "mdate": 1759897867206, "content": {"title": "UniAIDet: A Unified and Universal Benchmark for AI-Generated Image Content Detection and Localization", "abstract": "With the rapid proliferation of image generative models, the authenticity of digital images has become a significant concern. While existing studies have proposed various methods for detecting AI-generated content, current benchmarks are limited in their coverage of diverse generative models and image categories, often overlooking end-to-end image editing and artistic images. To address these limitations, we introduce UniAIDet, a unified and comprehensive benchmark that includes both photographic and artistic images. UniAIDet covers a wide range of generative models, including text-to-image, image-to-image, image inpainting, image editing, and deepfake models. Using UniAIDet, we conduct a comprehensive evaluation of various detection methods and answer three key research questions regarding generalization capability and the relation between detection and localization. Our benchmark and analysis provide a robust foundation for future research.", "tldr": "We propose UniAIDet, a unified and universal benchmark for evaluating AI-generated image detection and localization.", "keywords": ["AI-Generate Image Detection and Localization; Benchmark"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1e1d62ea35c7d1ee1999aadcb6e1855be612c7a8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces UniAIDet, a comprehensive benchmark dataset for AI-generated image detection and localization. UniAIDet covers diverse image generation methods such as text-to-image, image inpainting, and  DeepFake, and a wide range of generative models, including both open-source and closed-source ones. By testing existing AI-generated image detection and localization methods on UniAIDet, it is concluded that: (1) their generalization performance is still unsatisfactory; (2) their performance on detection and localization is generally consistent; (3) detection-only methods have poor generalization to partially synthesized images, while multi-task detection and localization methods perform poorly on all types of generated images."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed dataset is diverse and comprehensive. It covers various generative methods (both holistic and partial synthesis), a broad range of generative models, and both realistic and artistic images.\n2. The benchmarking of existing detection and localization methods reveals some interesting phenomena, for example, (1) some methods (e.g., NPR, AIDE) have consistent performance of detecting realistic and artistic images, even though they are trained solely on realistic ones; (2) models trained for fully generated image detection struggle to detect partially generated images."}, "weaknesses": {"value": "1. A major limitation of Sec. 4 is the **lack of in-depth analysis** of the evaluation results and observations. Limited insights are provided regarding the reasons behind the phenomena and possible future directions for improving the detection and localization methods.\n2. The claim that the proposed UniAIDet is \"the **first** large-scale, wide-coverage benchmark AI-generated image content detection and localization\" (Lines 96-97) needs to be more specific about the coverage and uniqueness (e.g., the inclusion of both realistic and artistic images, and the range of generative models). Otherwise, this could seem like an overclaim.\n3. The contributions listed in Lines 96-103 are too general. It would be better to clarify what **new observations** are made based on the proposed dataset, especially those that cannot be revealed by existing datasets.\n4. The conclusion that methods based on the CLIP backbone may not generalize well to artistic images (Lines 322-324) is not sufficiently supported by the results in Table 3. The reason for their inferior performance on artistic images may also be due to the training data and methods, rather than the CLIP backbone. (Suggestion: consider testing the DRCT pre-trained models with ConvB and CLIP backbones for a more rigorous comparison.)\n5. The conclusion that the detection and localization tasks do not conflict with each other (Lines 371-372) is only evidenced in Figure 3, where only the performance of two selected models is shown, and the \"consistency\" is more intuitive and qualitative rather than supported by statistical analysis."}, "questions": {"value": "1. Are the evaluation results in Table 3 possibly affected by the compression bias [1]? Specifically, if the real images are stored with lossy compression formats like JPEG, while the generated images are free from lossy compression, the performance of some generators that learned such compression bias from their training data can be overestimated.\n\n[1] Fake or JPEG? Revealing Common Biases in Generated Image Detection Datasets. ECCV 2024 Workshop."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "r4yxlQ5q3Y", "forum": "J1H2QAqnd2", "replyto": "J1H2QAqnd2", "signatures": ["ICLR.cc/2026/Conference/Submission7197/Reviewer_uwTV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7197/Reviewer_uwTV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761550412538, "cdate": 1761550412538, "tmdate": 1762919350210, "mdate": 1762919350210, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a unified, large-scale benchmark, UniAIDet, aiming to evaluate AI-generated image detection and localization tasks. The core contribution of the paper lies in its systematic integration: covering 20 generative models, 80k images, and two major scenarios: photography and art."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. It mainly covers full synthesis and partial synthesis. It also includes photo, art, and localization tasks, making it very comprehensive.\n\n2. The authors provide clear mathematical definitions for detection vs. localization: centering on the criterion of \"whether pixels are produced by a generative model\" rather than artifact-based methods. This makes the research direction more rigorous."}, "weaknesses": {"value": "1. The paper focuses more on empirical comparisons and lacks mechanistic explanations. Why is partial synthesis particularly difficult to detect? The feature differences across different model types (frequency/spatial/semantic) are not visualized in depth.\n\n2. It primarily considers generalization detection. What about robustness? Attacks like cropping and then re-generation / secondary editing (regeneration attacks)."}, "questions": {"value": "1. Why is partial synthesis particularly difficult to detect?\n\n2. The relationship between feature differences across different model types (frequency/spatial/semantic) and the difficulty of detection.\n\n3. How do these detectors change when facing certain attacks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "bpbRxvPVtF", "forum": "J1H2QAqnd2", "replyto": "J1H2QAqnd2", "signatures": ["ICLR.cc/2026/Conference/Submission7197/Reviewer_XW4i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7197/Reviewer_XW4i"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761577385742, "cdate": 1761577385742, "tmdate": 1762919349698, "mdate": 1762919349698, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a unified benchmark called UniAIDet, designed to jointly evaluate both detection of AI-generated content and pixel-level localization of manipulated regions, covering both fully generated images and partially edited / face-swapped images. The dataset is reported to contain approximately 80,000 real and generated images spanning around 20 generation or editing models, and to include multiple domains such as photographic content and artistic/anime-style content. Using this benchmark, the authors evaluate existing AIGC detection methods and observe that current approaches still exhibit notable weaknesses."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is clearly written. The experiments are presented in an organized and systematic way, with diverse forms of visualization, including a large number of statistical figures.\n- The authors conduct a unified evaluation of multiple existing detectors, and the experimental results are comprehensive."}, "weaknesses": {"value": "- The paper claims UniAIDet as “the first large-scale, wide-coverage benchmark … covering most potential practical scenarios,” emphasizing breadth across both holistic and partial synthesis, plus localization. However, [1] similarly targets localization, cross-domain generalization, and includes explicit explanatory annotations. A more direct comparison with [1] is needed.\n- The dataset construction process involves no human validation. Although an NSFW detector is applied to filter real images, there remains a potential safety/abuse concern for AIGC images.\n- The paper currently only releases an anonymized subset, and the provided link appears to be inactive. Given that the full dataset is not publicly available and that the benchmark may include copyrighted material and face-swapped content with potential privacy implications, it is unclear whether the community can safely reproduce and use this benchmark. The current ETHICS STATEMENT feels too lightweight in this regard.\n- For the instruction-guided editing setting, regions are obtained via pixel-difference thresholding between the original and edited images. Is this region truly equivalent to “the area modified according to the instruction”? Was there any manual verification of this consistency?\n\n[1] So-Fake: Benchmarking and Explaining Social Media Image Forgery Detection"}, "questions": {"value": "- In Table 2, there are two typos in the method names: \"AIGCDetct\" should be corrected to \"AIGCDetect\", and \"Chalmeon\" should be corrected to \"Chameleon\".\n- The title of Section 2 should be revised from \"RELATED WORKS\" to \"RELATED WORK\", which is the conventional form in academic writing.\n- In Equation (4), the denominator contains two repeated TN terms. Please check and correct the expression to avoid duplication."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)"]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "GHRZVXXuwO", "forum": "J1H2QAqnd2", "replyto": "J1H2QAqnd2", "signatures": ["ICLR.cc/2026/Conference/Submission7197/Reviewer_FHFf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7197/Reviewer_FHFf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891210352, "cdate": 1761891210352, "tmdate": 1762919349364, "mdate": 1762919349364, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}