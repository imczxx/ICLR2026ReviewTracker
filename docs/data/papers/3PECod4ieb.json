{"id": "3PECod4ieb", "number": 10946, "cdate": 1758185226936, "mdate": 1759897619480, "content": {"title": "Chronoberg: Capturing Language Evolution And Temporal Awareness In Foundation Models", "abstract": "Large language models (LLMs) excel at operating at scale by leveraging social media and various data crawled from the web. Whereas existing corpora are diverse, their frequent lack of long-term temporal structure may however limit an LLM's ability to contextualize semantic and normative evolution of language and to capture diachronic variation. To support analysis and training for the latter, we introduce Chronoberg, a temporally structured corpus of English book texts spanning 250 years, curated from Project Gutenberg and enriched with a variety of temporal annotations. First, the edited nature of books enables us to quantify lexical semantic change through time-sensitive Valence-Arousal-Dominance (VAD) analysis and to construct historically calibrated affective lexicons to support temporally grounded interpretation. With the lexicons at hand, we demonstrate a need for modern LLM-based tools to better situate their detection of discriminatory language and contextualization of sentiment across various time-periods. In fact, we show how language models trained sequentially on Chronoberg struggle to encode diachronic shifts in meaning, emphasizing the need for temporally aware training and evaluation pipelines, and positioning Chronoberg as a scalable resource for the study of linguistic change and temporal generalization. $\\\\textcolor{red}{Disclaimer:}$ This paper includes language and display of samples that could be offensive to readers. $\\\\textcolor{blue}{Open Access:}$ Chronoberg will be available publicly on HuggingFace.", "tldr": "", "keywords": ["Large Language Models", "Temporal Generalization", "Lexical Semantic Change", "Continual Learning", "VAD Lexicons"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c9de179b727664b9d46bb43912633ef295ab70c2.pdf", "supplementary_material": "/attachment/bcfd8b44c07cad9e1f20748a84d6cf3036bf0b18.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a dataset for evaluating temporal changes of words, which is then used to evaluate LLMs. Temporal change detection is a task that has been researched extensively (see SemEval workshops on this topic over the years for example) but its progress has been hindered by the lack of large-scale time-annotated datasets. This paper fill this important gap."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The creation and release of a large-scale dataset for evaluating temporal changes of VAD of words is the main strength/contribution of this paper.\n- The paper then goes on to evaluate multiple foundation models on this dataset."}, "weaknesses": {"value": "- given the automatic nature of the annotation process, a manual verification (e.g. using a random sample) should be conducted.\n- books are a curated set of texts and might not necessarily express the sentiment held by the broader population. Social media on the other hand would have been a better source for capturing modern VAD of words but cannot be used for historical texts. What is the coverage in terms of the number of authors covered in the corpus? If this number is low then it might not be representing the view point of the general public but an elite and small group of authors. This dataset bias should be investigated further.\n- I am not sure whether all books in this corpus is suitable for this purpose of evaluating diachronic changes. For example, there could be fantasy books which do not reflect a social viewpoint but an imaginary one. Even if a book is written at a particular point in time, it might be handling a historical context that belongs to a different time period (e.g. a book written in 2020 on Edo period of Japan would not be reflecting the modern usage of Japanese language). I am not sure how these complications are handled in this corpus (or the authors are aware of such issues)?\n- Although I appreciate the extensive evaluations conducted in the paper using the CHRONOBERG dataset, those findings will only be valid to the extent of the accuracy of the dataset itself.\n- Moreover, I think this paper is more appropriate for the linguistic resources track at an NLP venue (e.g. LREC or xACL) rather than ICLR."}, "questions": {"value": "- Did you conduct any manual (even at a small scale) evaluation of the VAD scores computed using Eq. (2)?\n- What is the coverage in terms of the number of authors covered in the corpus? If this number is low then it might not be representing the view point of the general public but an elite and small group of authors. This dataset bias should be investigated further.\n- In Table 1, can you explain the shift from neg to pos for `infatuation` and `destinty` please?\n- What would the valency shift look like for a word such as `gay`, which is known to be used positively (happiness) in olden times, whereas more neutral? in modern usage?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Kcao4iESMQ", "forum": "3PECod4ieb", "replyto": "3PECod4ieb", "signatures": ["ICLR.cc/2026/Conference/Submission10946/Reviewer_m7ZD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10946/Reviewer_m7ZD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10946/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760955650422, "cdate": 1760955650422, "tmdate": 1762922139905, "mdate": 1762922139905, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Chronoberg, a large diachronic English corpus (1750–2000, 2.7B tokens) with sentence-level affective annotations and temporally aligned Valence–Arousal–Dominance (VAD) lexicons. The authors detail a pipeline for dating and cleaning Project Gutenberg texts, generate time-specific VAD lexicons via aligned embeddings, and use the resource to test hate-speech detectors and temporal adaptation of LLMs (sequential fine-tuning, EWC, LoRA). Results show severe forgetting and limited handling of historically shifting word valence, highlighting Chronoberg’s potential as a benchmark for temporal robustness and continual learning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Language temporal drift and historical semantics are important for ensuring LLM robustness.\n- The paper presents interesting insights on semantic shift."}, "weaknesses": {"value": "- Narrow domain coverage. Chronoberg is built entirely from Project Gutenberg books, spanning 1750–2000. This makes it a valuable literary resource but also limits generalization to modern or conversational language where current LLMs are deployed .\n\n- Unclear LLM evaluation setup. The paper compares several classifiers, including “OpenAI” models, in its hate-speech evaluation tables . However, it does not describe how those models were prompted or whether they were informed about the historical origin of the text. Without that context, it’s hard to interpret what the observed disagreements actually reflect.\n\n- Limited quantitative evaluation of temporal drift. Section 4.1 and the associated tables mostly illustrate qualitative examples of valence shifts and classifier disagreements. There is no formal metric (e.g., correlation or agreement score) quantifying alignment between the temporal VAD lexicons and model outputs .\n\n- Unsurprising claims without measurement. The authors hypothesize that modern LLMs “rely too heavily on surface-level keywords,” but this remains an intuitive explanation rather than an empirically tested one . Quantifying how much this reliance contributes to misclassification would make the finding stronger.\n\n- Vague notion of “contextualization.” The paper claims that temporally fine-tuned models “struggle with contextualization of historical content,” yet does not specify how contextual information (e.g., time metadata or retrieved examples) was provided during inference .\n\n- Ambiguous terminology. Phrases like “dissonance of ~85% between OpenAI and RoBERTa” are reported without a clear definition of what “dissonance” measures (e.g., disagreement rate or correlation gap) . This makes quantitative interpretation difficult."}, "questions": {"value": "- How do you expect findings from literary English (Chronoberg) to generalize to modern or conversational domains where current LLMs are applied?\n\n- For the “OpenAI” model evaluations, what exact prompts or instructions were used? Was the model told the historical period or context of the text?\n\n- Have you computed any quantitative metrics (e.g., correlation or agreement) between temporal VAD lexicons and classifier outputs, beyond qualitative examples?\n\n- Can you operationalize “contextualization of historical content” — does it mean awareness of time, lexical shifts, or broader discourse cues?\n\n- What precisely does the reported “∼85% dissonance” between OpenAI and RoBERTa measure? Is it disagreement rate, accuracy gap, or another metric?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "M7t73bl5Lf", "forum": "3PECod4ieb", "replyto": "3PECod4ieb", "signatures": ["ICLR.cc/2026/Conference/Submission10946/Reviewer_bh7T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10946/Reviewer_bh7T"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10946/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761743200311, "cdate": 1761743200311, "tmdate": 1762922139462, "mdate": 1762922139462, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MetaDiff, a diffusion-based framework for few-shot adaptation of large vision-language models (VLMs). Traditional few-shot fine-tuning approaches—such as adapter tuning or prompt learning—are limited by overfitting and poor uncertainty estimation when data are scarce. MetaDiff reframes few-shot adaptation as a meta-generative prior learning problem: it learns a conditional diffusion model in the weight or latent embedding space of the VLM such that, given a few examples from a novel task, it can sample adapted model states that generalize better."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. The idea of using a diffusion process in the parameter or embedding space for meta-adaptation is highly creative. Unlike deterministic meta-learners, MetaDiff explicitly models the distribution over adapted models, allowing uncertainty-aware adaptation. This is both novel and well-motivated theoretically.\n2. The paper provides comprehensive experiments across diverse domains (classification, captioning, retrieval), showing that MetaDiff outperforms fine-tuning, adapter tuning, and standard meta-learning baselines under few-shot constraints. Ablations clearly indicate that the diffusion prior contributes significantly to performance."}, "weaknesses": {"value": "1. While the motivation for using diffusion models is strong, the paper does not provide a formal link between the learned generative prior and Bayesian meta-learning or PAC-Bayesian guarantees. A short theoretical justification (e.g., that MetaDiff approximates amortized inference under a hierarchical Bayesian model) would strengthen the contribution.\n2. MetaDiff’s meta-training stage is computationally heavy, involving thousands of diffusion steps across multiple tasks. While test-time sampling can be parallelized, a more detailed cost analysis or discussion on distillation into fewer diffusion steps would be valuable."}, "questions": {"value": "1. It would be useful to see how performance varies with the number of diffusion timesteps. Is MetaDiff’s success primarily due to stochastic regularization or due to the learned generative structure?\n2. When sampling multiple adapted models via diffusion, how diverse are their predictions? Are these samples genuinely capturing task uncertainty or just random noise around a single mode?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PpsPsIZb4Q", "forum": "3PECod4ieb", "replyto": "3PECod4ieb", "signatures": ["ICLR.cc/2026/Conference/Submission10946/Reviewer_Vpi9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10946/Reviewer_Vpi9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10946/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990022980, "cdate": 1761990022980, "tmdate": 1762922139103, "mdate": 1762922139103, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "his paper introduces Chronoberg, a large-scale, temporally structured corpus of ~2.7B tokens spanning 250 years of English books (1750–2000), curated from Project Gutenberg. The dataset includes publication-year inference through bibliographic metadata recovery, extensive filtering for temporal consistency, and—most notably—diachronic lexical and affective annotations."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. This paper has high-quality dataset construction with robust metadata recovery and filtering.\n2. The paper has novel temporal VAD lexicons providing historical sentiment grounding not available in existing resources.\n3. This paper shows strong empirical evidence that sequentially trained LLMs cannot handle semantic drift."}, "weaknesses": {"value": "1. The dependence on modern VAD lexicons for historical inference may introduce systematic anachronisms; although unavoidable, the paper could discuss this more deeply.\n2. Sequential training experiments use only Pythia-1.4B; broader architectural comparisons could contextualize findings."}, "questions": {"value": "1. How often do embedding-based historical VAD scores contradict known historical usage documented in linguistics literature?\n2. Did you evaluate transformer-based contextual embeddings instead of Word2Vec for diachronic analysis?\n3. What hypotheses explain why valence-shifting words degrade forward generalization more than valence-stable ones?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PpsPsIZb4Q", "forum": "3PECod4ieb", "replyto": "3PECod4ieb", "signatures": ["ICLR.cc/2026/Conference/Submission10946/Reviewer_Vpi9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10946/Reviewer_Vpi9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10946/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990022980, "cdate": 1761990022980, "tmdate": 1763062090930, "mdate": 1763062090930, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the crucial problem that most Large Language Models (LLMs) are trained on temporally stationary data, limiting their ability to comprehend the long-term evolution of language, social norms, and semantics (diachronic variation). The introduction of Chronoberg, a large-scale (2.7B tokens) and temporally structured corpus of full-length English book texts (25,061 books from Project Gutenberg) spanning 250 years (1750–2000). Experiments using the dataset show that LLMs trained sequentially struggle significantly with catastrophic forgetting and generalization to future language, particularly concerning words that have undergone affective valence shifts. This positions Chronoberg as a necessary benchmark for temporal generalization, Continual Learning, and evaluating the temporal robustness of AI systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The introduction of Chronoberg is a major contribution, filling a critical gap in LLM training and evaluation. It provides a large-scale (2.7B tokens) and long-horizon (250 years) temporally structured corpus of full-length texts. \n2. The systematic construction of temporally calibrated VAD lexicons for $\\sim$335,000 words is highly innovative."}, "weaknesses": {"value": "1. The temporal structure, which is the foundation of the dataset, relies on an inferred publication date from external sources (OpenLibrary), while validated, this process has an unavoidable Mean Absolute Error (MAE) of $\\pm 3.05$ years.\n\n2. The methodology for constructing the temporal VAD lexicons relies on selecting the Top-K nearest neighbors ($K=20$). However, the main text does not include a systematic ablation study demonstrating how the choice of $K$ (or the effect of the 50-year interval size) impacts the final, crucial results, such as the LLM perplexity gap between valence-stable and valence-shifting test sets."}, "questions": {"value": "1. How did you get the \"positive\" or \"negative\" in Table 1? It is still not clear to me. \n\n2. The paper uses Word2Vec and CADE alignment. Could the authors justify why this combination was chosen over more contemporary diachronic methods?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ek69LlwRXx", "forum": "3PECod4ieb", "replyto": "3PECod4ieb", "signatures": ["ICLR.cc/2026/Conference/Submission10946/Reviewer_GhzC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10946/Reviewer_GhzC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10946/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762492765101, "cdate": 1762492765101, "tmdate": 1762922138678, "mdate": 1762922138678, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}