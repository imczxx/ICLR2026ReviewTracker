{"id": "WlQxDKQpo6", "number": 19548, "cdate": 1758297143886, "mdate": 1759897033277, "content": {"title": "RAG-ENHANCED ASPECT-BASED SENTIMENT ANALYSIS FOR MOBILE APPLICATION REVIEWS: A MULTIAGENT FRAMEWORK FOR DEVELOPER-ORIENTED INSIGHT GENERATION", "abstract": "Mobile app developers encounter a considerable challenge in understanding users' genuine perceptions of their programs. Manual analysis is not feasible, and coarse-grained sentiment labels are not effective, because the number of apps being analyzed and the number of app reviews are both in the millions, and the number of actionable engineering activities is expected to be small, thus a need to explore automated analysis. We introduce an Aspect-Based Sentiment Analysis system with RAG enhancements that directly correlate user complaints with developer fixes that may be made. Our end-to-end system consists of four contributions: (1) a contextual retrieval architecture that links complaints with a history of version and relevant documentation, with a dense retriever + RAG backbone; (2) resource-efficient adaptation with Low-Rank Adapters (LoRA) to LLaMA 3.1 8B, which dramatically reduces the footprint of deployable parameters, but does not affect predictive quality; (3) automated multi-agent orchestration (LangGraph) to refer developer queries to specialized agents helpful in relevant detection, ABSA inference, problem extraction and solution recommendation; and Our end-to-end system achieves good task-level performance (high sentiment accuracy and 82.3% aspect-extraction F1) a sampled set of 41,245 reviews of English apps and produces developer-actionable results, which could be checked through automated test-checks and by human developer study.", "tldr": "RAG-enhanced ABSA system that filters, analyzes, and grounds mobile app reviews to generate developer-actionable bug insights, fixes, and test suggestions using LoRA-adapted LLMs and LangGraph multi-agent orchestration.", "keywords": ["Aspect-Based Sentiment Analysis", "Retrieval-Augmented Generation", "Multi-Agent Systems", "LangGraph", "LoRA Fine-Tuning", "Mobile App Reviews", "Developer Tooling", "Code-Aware Solution Generation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/01884e83e4bea7b74eeef06ea139cfb864a4f664.pdf", "supplementary_material": "/attachment/33e7de6f61f16e6320593d93777852f9894d825c.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a framework for Aspect-Based Sentiment Analysis (ABSA) that integrates Retrieval-Augmented Generation (RAG) and a multi-agent system to provide mobile app developers with actionable insights and code-aware solutions from user reviews. The system is built upon a fine-tuned LLaMA 3.1 8B model with LoRA. Evaluated on a curated dataset of 41,245 app reviews, it reports high sentiment classification accuracy (98.23%) and aspect extraction F1 (82.26%). The authors claim superiority over several existing methods and emphasize the practical, production-ready nature of their system."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "+ Rich System Design: The work describes an end-to-end framework that thoughtfully considers the entire pipeline from data ingestion and ABSA to solution generation.\n+ Resource Efficiency: The use of LoRA and 4-bit quantization to reduce computational footprint is a positive practical contribution for leveraging open-source LLMs.\n+ Valuable Problem Focus: The vision of bridging user feedback directly to code-level solutions is a highly relevant and important direction for the software engineering community."}, "weaknesses": {"value": "- Lack of Novelty and Unclear Contribution: The core components of the proposed method (ABSA, RAG, multi-agent orchestration, LoRA) are widely-used and mature technologies. The paper fails to convincingly demonstrate a fundamental scientific contribution. It appears more as a competent engineering integration of existing tools rather than a novel methodological or theoretical advancement. \n\n- Dataset Issues: The dataset source (45 apps) and composition are described vaguely, are not public, and cannot be verified. \n\n- Technical details are ambiguous. The specific architecture of the \"eight agents\" in multi-agent systems, the communication protocols among them, and the decision-making processes are not described in depth enough. According to Figure 2, the workflow structure has been manually designed. However, the task of Coordinator is workflow orchestration, which leads to confusion."}, "questions": {"value": "-\tWhat is the most core scientific contribution of this paper that distinguishes it from the simple baseline integrated system?\n-\tHow the multi agent work and collaborate?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8sWwGK7qb7", "forum": "WlQxDKQpo6", "replyto": "WlQxDKQpo6", "signatures": ["ICLR.cc/2026/Conference/Submission19548/Reviewer_hE4E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19548/Reviewer_hE4E"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761789739986, "cdate": 1761789739986, "tmdate": 1762931433459, "mdate": 1762931433459, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a well-engineered and highly practical multi-agent framework that connects Aspect-Based Sentiment Analysis (ABSA) of user reviews directly to source-code-aware solution generation. The system's primary strength is this novel and valuable integration, moving beyond mere analysis to provide actionable developer insights. The architecture, which uses LoRA-based SFT of LLaMA-3.1-8B orchestrated by LangGraph, is clearly described and achieves strong sentiment classification accuracy (98.23%). However, the paper suffers from several critical weaknesses. Methodologically, it is a complex integration of existing tools rather than a novel algorithm. The core contribution—code generation—is not rigorously evaluated; it lacks quantitative metrics for code quality and is not compared against any relevant code-generation baselines. Furthermore, the system is evaluated on a custom-built dataset, not a standard public benchmark, limiting claims of generalizability."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- **Novelty and Practicality of Code-Aware Solution Generation.** The paper's most significant strength is its novel \"transforms raw user feedback into actionable developer insights\", which directly addresses a key limitation in prior work that stops at analysis.\n- **Comprehensive and Well-Designed System Architecture.** The system architecture is comprehensive and clearly illustrated, detailing the workflow from data ingestion to insight generation. The use of LangGraph to orchestrate eight specialized agents (e.g., Classifier, Context, Solutions) represents a sound and modular engineering design. This architecture effectively integrates contextual RAG using app changelogs and dual vector databases to flexibly handle different developer queries."}, "weaknesses": {"value": "- **Methodological Integration without Algorithmic Novelty.** The paper presents a sophisticated and complex system but does not introduce new algorithms or fundamental methods. The entire framework is a well-engineered pipeline integrating existing, off-the-shelf components, including LoRA-based fine-tuning, LLaMA models, LangGraph orchestration, and standard RAG techniques.\n- **Lack of Formalism and Mathematical Precision.** The methodology is described entirely in prose, lacking the mathematical formalism. Key components like the RAG retrieval function, the dual knowledge storage strategy, or the LoRA adaptation are not defined with any equations or formal notation, which reduces the technical clarity and precision of the proposed method.\n- **Evaluation on a Non-Standard, Limited Dataset.** The system is evaluated on a custom-built dataset. While extensive, this dataset is not a recognized public benchmark, which makes it difficult to fairly compare the reported performance against other SOTA models."}, "questions": {"value": "- Could you please elaborate on what you consider to be the core scientific or algorithmic contribution of this work, as distinct from the strong engineering integration?\n- The methodology, particularly the RAG pipeline, is described entirely in prose, which can lack technical precision. To improve clarity and reproducibility, could you provide a more formal (perhaps mathematical) definition of your key components?\n- Could you clarify why existing public benchmarks (e.g., SemEval for ABSA) were not used to provide a more direct, head-to-head comparison of the core sentiment and aspect extraction model?\n- How was the claimed \"24.6% improvement in solution implementation accuracy\" measured, and what was the baseline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CHtg1nPg18", "forum": "WlQxDKQpo6", "replyto": "WlQxDKQpo6", "signatures": ["ICLR.cc/2026/Conference/Submission19548/Reviewer_oazG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19548/Reviewer_oazG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898649512, "cdate": 1761898649512, "tmdate": 1762931433019, "mdate": 1762931433019, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a RAG-enhanced, multi-agent Aspect-Based Sentiment Analysis (ABSA) system for mobile app reviews. The system collects ~41k Google Play reviews, fine-tunes LLaMA-3.1-8B using LoRA, integrates dual-DB semantic retrieval (reviews + code), and orchestrates 8 LLM agents via LangGraph to extract aspects, sentiments, and opinions, then generate developer-actionable code fixes (Java/Kotlin/XML). The authors report strong performance (98.23% sentiment accuracy, ~82% aspect F1) and claim the system delivers production-ready developer feedback and code suggestions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Ambitious and practically relevant developer-tool pipeline.\n- Solid data scale and domain focus (mobile apps).\n- Effective engineering: LoRA, quantization, RAG, multi-agent routing."}, "weaknesses": {"value": "1. **No standard ABSA evaluation → weak external validity**\n2. **Self-curated dataset without annotation quality or release**\n3. **Over-claimed novelty** relative to existing ABSA + RAG + code-repair research\n4. **Lack of human study** or code correctness verification\n5. **No ablation quantification** (only qualitative)\n6. **Heavy system-engineering focus**, less scientific contribution\n7. **Possible data leakage** (user reviews from public data → LLM training risk)"}, "questions": {"value": "1. Why not evaluate on SemEval & MAMS?  \n2. How was annotation done? How many annotators? Agreement metrics?  \n3. Is the dataset public? If not, how can others reproduce results?  \n4. How do you verify code suggestions are correct or actionable?  \n5. Did you compare to prompting GPT-4/Claude without multi-agents?  \n6. How much does each component contribute numerically (LoRA, dual DB, agents)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "04eQLtNYWm", "forum": "WlQxDKQpo6", "replyto": "WlQxDKQpo6", "signatures": ["ICLR.cc/2026/Conference/Submission19548/Reviewer_9W2E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19548/Reviewer_9W2E"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761906635776, "cdate": 1761906635776, "tmdate": 1762931432669, "mdate": 1762931432669, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}