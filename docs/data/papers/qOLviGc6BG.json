{"id": "qOLviGc6BG", "number": 7299, "cdate": 1758014772116, "mdate": 1763668096598, "content": {"title": "NeSyGeo: A Neuro-Symbolic Framework for Multimodal Geometric Reasoning Data Generation", "abstract": "Obtaining large-scale, high-quality reasoning data is crucial for improving the geometric reasoning capabilities of multi-modal large language models (MLLMs). However, existing data generation methods, whether based on predefined templates or constrained symbolic provers, inevitably face diversity and numerical generalization limitations. To address these limitations, we propose NeSyGeo, a novel neuro-symbolic framework for generating geometric reasoning data. First, we propose a domain-specific language grounded in the entity–attributes-relations paradigm to comprehensively represent all components of plane geometry, along with generative actions defined within this symbolic space. We then design a symbolic–visual–text pipeline that synthesizes symbolic sequences, maps them to visual and textual representations and generates reasoning path with reverse search and forward validation. Based on this framework, we construct NeSyGeo-CoT and NeSyGeo-Caption datasets, containing 100k samples, and release a new benchmark NeSyGeo-Test for evaluating geometric reasoning abilities in MLLMs. Experiments demonstrate that the proposal significantly and consistently improves the performance of multiple MLLMs under both reinforcement and supervised fine-tuning. With only 4k samples and two epochs of reinforcement fine-tuning, base models achieve improvements of up to +15.8\\% on MathVision, +8.4\\% on MathVerse, and +7.3\\% on GeoQA. Notably, a 4B model can be improved to outperform an 8B model from the same series on geometric reasoning tasks.", "tldr": "We introduces NeSyGeo, a novel neurosymbolic framework for automatically generating multimodal geometric datasets.", "keywords": ["Neuro-Symbolic", "Geometric Problem-Solving", "Multimodal Data Generation", "Multimodal Large Language Models (MLLMs)"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1d3022bf3b86962e7c9a50b409e9f15781ee6703.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces NeSyGeo, a geometry data generation framework that leverages a novel domain-specific language (Geo-DSL) to automatically produce large-scale, high-quality multimodal datasets. The framework encodes geometric entities, relationships, and constraints symbolically, then generates corresponding images and natural language descriptions through an automated pipeline. By utilizing LLMs for chain-of-thought (CoT) reasoning generation and LMMs for cross-validation, NeSyGeo produces two key datasets—NeSyGeo-CoT and NeSyGeo-Caption—that demonstrate significant performance improvements for multimodal large language models on geometric reasoning tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tComprehensive experimental validation: The authors provide extensive experiments including human evaluation (40 experts), ablation studies, contamination analysis, and comparisons across multiple benchmarks.\n2.\tThrough RL and SFT, models trained on NeSyGeo data outperform those using standard and other synthetic datasets."}, "weaknesses": {"value": "1.\tThe individual components (symbolic generation, LLM-based CoT distillation, template-based translation) lack novelty. Compared to AlphaGeometry, TrustGeoGen, and recent symbolic-neural integration works, the advantages are not sufficiently distinct.\n2.\tThe framework heavily relies on DeepSeek-R1 and DeepSeek-V3 for critical reasoning and verification steps. This distillation-like approach may limit both the difficulty ceiling of the generated data and the performance upper bound of trained models.\n3.\tAlthough the authors claim Geo-DSL achieves \"descriptive completeness\" with 37 core statements, the paper lacks formal proof or systematic analysis of its coverage over plane geometry."}, "questions": {"value": "1.\tWhat are the computational requirements for generating 100k samples? How does this compare to other synthesis methods in terms of time and resource consumption?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Nt9yo4ZTMO", "forum": "qOLviGc6BG", "replyto": "qOLviGc6BG", "signatures": ["ICLR.cc/2026/Conference/Submission7299/Reviewer_4nkp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7299/Reviewer_4nkp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761652297907, "cdate": 1761652297907, "tmdate": 1762919416615, "mdate": 1762919416615, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a novel neuro-symbolic framework called NeSyGeo to address the shortcomings of MLLMs in visual reasoning for geometry problems. More specifically, authors made NeSyGeoCoT and NeSyGeo-Caption datasets, containing 100k samples, and also release a new benchmark NeSyGeo-Test (~2.7k samples) to the community. Post-training using RL and SFT via the dataset shows performance boost on multiple benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The core problem identified and solved by authors is quite interesting as models can ignore images while solving geometry questions in the existing datasets because of their text-image redundancy.\n\n2. The framework combines the strength of symbolic Geo-DSL and flexibility of neural models and the Reasoner-Verifier paradigm helps create diverse with correct reasoning paths.\n\n3. Generated data is diverse and has a high quality and training is efficient-- via only 4k samples and two RL epocs, the 4B model outperforms 8B model on multiple datasets. Benchmark is also novel and can be quite helpful for the community.\n\n4. Extensive experiments, failure analysis and detailed implementations make the paper reliable and the framework's reproducibility easier."}, "weaknesses": {"value": "1. My only concern is while the method is quite limited to plane geometry only, it's complexity (multi-stage, API calls, etc.) is high and it heavily depends on powerful large-scale teacher models (e.g., DeepSeek and GPT)."}, "questions": {"value": "Based on the above comments, I have a few questions:\n\n1. How can authors overcome the usability limitation of the method to be able to extend it beyond plane geometry? Detailed explanation would shed light on the future iterations.\n\n2. What happens if we swap the teacher models with smaller models? Does the performance drop drastically? Is there a minimum capability threshold that a model should have to be considered safe? I would recommend adding some experiments to show that.\n\n3. RE information orthogonality in 3.4, what is the optimal balance between text and image modalities? I couldn't find any information RE numerical data in the text, so my bad if it's already there, but how performance would change if we include such data in text?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kzb7uKqZPJ", "forum": "qOLviGc6BG", "replyto": "qOLviGc6BG", "signatures": ["ICLR.cc/2026/Conference/Submission7299/Reviewer_ybzn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7299/Reviewer_ybzn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761860600544, "cdate": 1761860600544, "tmdate": 1762919416055, "mdate": 1762919416055, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents NeSyGeo, a neural-symbolic hybrid framework, for automatically generating multimodal geometric reasoning data. Through self-developed Geo-DSL symbolic language, a question-generation pipeline of reverse search and forward verification, as well as a visual-text decoupling strategy, a 100,000-scale Caption/CoT training set and 2,668 evaluation benchmarks were constructed. 4k sample RL fine-tuning can bring a maximum 15.8% improvement on benchmarks such as MathVision, and a 4B model can outperform its equivalent 8B model."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.For the first time, differentiable neural search was combined with strict symbolic constraints, achieving a balance between diversity and correctness.\n\n2.Geo-DSL can fully express plane geometry with only 37 primitives, and the interpretation is unambiguous.\n\n3.The two-stage generation of reverse search + forward verification significantly reduces hallucinations, and the quality of manual evaluation is leading.\n\n4.The orthogonal design of visual-text information forces the model to truly read the image, alleviating the modal shortcut.\n\n5.Data is plug-and-play, and 4k sample RL can significantly improve performance, with friendly resource utilization."}, "weaknesses": {"value": "1. Geo-DSL only defines the basic elements of planar Euclidean geometry, lacking the symbolic primitives for coordinates, vectors, solid geometry and analytic geometry. This results in a significant disparity between the types of questions generated and those found in real exams and textbooks, especially in terms of comprehensive questions.\n\n2.The lengths and angles are uniformly sampled within a fixed range, and the angles are forced to be multiples of 15°. This results in the frequencies of special angles (30°, 45°, 60°) being artificially increased, while common non-special angles, irrational lengths, and extreme ratios (such as 1:100) rarely appear in the actual test questions. This makes the model's robustness questionable when it truly generalizes to \"irregular\" shapes.\n\n3.The values of the element selection matrix I and the action weight matrix A, the temperature τe/τa, as well as the length/angle discretization intervals were all set by the author based on experience. There was no basis for automatic learning or grid search. Once the geometric domain or difficulty distribution is changed, the parameters need to be manually adjusted again, which reduces the transferability and scalability of the method.\n\n4.The paper emphasizes \"ensuring correctness\", but it has not conducted difficulty equivalence verification with symbol solvers such as AlphaGeometry and InterGPS, nor has it randomly generated questions for the symbol solvers to run and reported the solvable rate and the number of solving steps. The lack of such a comparison makes it difficult to prove that the generated questions indeed have provability and appropriate complexity."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DFNacZ80aq", "forum": "qOLviGc6BG", "replyto": "qOLviGc6BG", "signatures": ["ICLR.cc/2026/Conference/Submission7299/Reviewer_XMfm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7299/Reviewer_XMfm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896395775, "cdate": 1761896395775, "tmdate": 1762919415553, "mdate": 1762919415553, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper propose NeSyGeo, a neural-symbolic framework for generating plane geometry problems. The NeSyGeo use DSL to describe the elements in the plane geometry, which provides an explicit basic problem information for the data generation process. The problem generation algorithm use both reasoner and verifier to ensure the method output the correct problem with CoT solutions, which ensure the usability of the generated problems. Based using the generated dataset to train the model, smaller MLLM get higher accuracy than larger models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tThe definition of the Geo-DSL is reasonable, which covered primitive entities, metric attributes and topological relations.\n2.\tThe problem generation process is reliable, which has backward search and forward verification and finally get the general language description of the CoT process. With the diagram painter to get the entire generated problem text, diagram and solution.\n3.\tBased on the experiments, the generated dataset help model to deeper rely on diagram to solve the problem, different from the previous methods that mainly based on problem text, like shown in Figure 1.\n4.\tThe author contributed to dataset, NeSyGeo-CoT and NeSyGeo-Caption, from the experiments, the proposed dataset and method are effective, and the tuned models based on these datasets achieved increased performance on benchmarks, the 4B MLLM is compatible with largers MLLMs."}, "weaknesses": {"value": "1.\tAs a plane geometry problem generation work, the part of how to translate the DSL into a diagram is missing, how to get the location or coordinates of the points in the diagram? Meanwhile, is it possible to generate diagrams with only lines and no closed geometry shapes in the diagram, like a problem with two parallel lines and another line across them to ask about alternate angles.\n2.\tThe experiments for a dataset generation work are essential to show the effectiveness of the proposed dataset, and the current experiments are not enough, especially for the SFT. It is only comparing with the base MLLMs. Like comparing to R-CoT, from their work the result of SFT on Qwen2.5-VL-7B get 79.2% on GeoQA, which has a huge gap between 71.8 in NeSyGeo, the author needs further experiments on this kind of comparsion.\n3.\tWhy is Geometry3K missing in the experiments? It is also an important foundation dataset for the research of PGP area. Despite the current experiments showing that with the proposed new dataset, MLLMs achieved increased performance, I am wondering about the effectiveness of this method on Geometry3K, as the PGP style of GeoQA and Geometry3K are different. There are some open-source works like EasyR1 provides the GRPO training for Geometry3K, it is better to provide a compression with directly use GRPO to traing MLLM and use the proposed dataset to RL train the MLLM. This experiment will be more convincing to the work.\n4.\tIs it possible to have a further ablation experiment on using different ratios of the proposed dataset to train the model and analyze the model performance, like 20%, 50%, 80%, to show whether the increase in training samples leads to a linear performance increase.\n5.\tSome minor revision points. The dataset name is nor accurate, like for G-LLaVA, the corresponding dataset is Geo170K. For R-CoT, the new version is now named TR-CoT, and the dataset name is TR-GeoMM. Just suggest refining them. Some tables are too large.\n6.\tFinally, my concerns are mainly about the experiments， if the above concerns are tackled by the author, I will lean to accept the paper."}, "questions": {"value": "1.\tWhen draw the visual diagram with annotations, if the diagram is complicated, how do you avoid the annotation is overlapping to the diagram lines.\n2.\tWhat is the upper limit of the method, is it possible to generate complicated problems and diagrams, like diagrams in AlphaGeometry, the IMO level."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ByJmsRfLY2", "forum": "qOLviGc6BG", "replyto": "qOLviGc6BG", "signatures": ["ICLR.cc/2026/Conference/Submission7299/Reviewer_VMe1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7299/Reviewer_VMe1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7299/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997882716, "cdate": 1761997882716, "tmdate": 1762919415054, "mdate": 1762919415054, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}