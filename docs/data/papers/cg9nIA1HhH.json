{"id": "cg9nIA1HhH", "number": 10034, "cdate": 1758157349550, "mdate": 1759897679441, "content": {"title": "Controlling Output Rankings in Generative Engines for LLM-based Search", "abstract": "The way customers search for products, compare options, and decide what to buy is rapidly changing with the introduction of large language models (LLMs). In particular, LLM-based search, also known as generative engines, enables shoppers to obtain direct recommendations instead of performing a conventional Google search. However, the ranking of these recommendations is heavily influenced by the initial order of products retrieved by the LLM. This dependency risks disadvantaging small businesses and independent creators by reducing their visibility and limiting their competitiveness online.\n\nTo address this risk, in this work, we propose CORE, an optimization method that \\textbf{C}ontrols \\textbf{O}utput \\textbf{R}ankings in g\\textbf{E}nerative Engines for LLM-based search. Since the choice of which search engine to query is determined by model developers and cannot be altered by end-users, CORE instead targets the content returned by search engines. Specifically, CORE optimizes retrieved content and appends strategically optimized content to influence the ranking of outputs generated by the LLM. We introduce three representative forms of optimization content: string-based, reasoning-based, and review-based, demonstrating their effectiveness in shaping output rankings. To evaluate the effectiveness of CORE in realistic settings, we construct AmazonCOREBench, a large-scale benchmark comprising 15 product categories with 200 products each, where the top 10 recommendations per product are collected from Amazon’s search interface.\n\nExtensive experiments on four LLMs with search capabilities (GPT-4o, Gemini-2.5, Claude-3.7, and Grok-3) demonstrate that CORE achieves an average Promotion Success Rate of \\textbf{91.4\\% @Top-5}, \\textbf{86.6\\% @Top-3}, and \\textbf{80.3\\% @Top-1} under the best optimization strategy, across 15 product categories, while preserving fluency in optimized content and outperforming existing ranking manipulation methods.", "tldr": "In this work, we propose CORE, an optimization method that \\textbf{C}ontrols \\textbf{O}utput \\textbf{R}ankings in g\\textbf{E}nerative Engines for LLM-based search.", "keywords": ["Large Language Models", "Generative Engines", "Optimization"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/abb9997aee7c90ec61c3cdb23a2e997f9ca60b45.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces CORE, a method designed to manipulate product rankings in LLM-based search systems by appending content to target items. The authors point out that LLM-based search engines heavily depend on the initial retrieval order from search engines and address this through two optimization approaches: (1) a shadow-model solution that uses gradient-based optimization with a surrogate model to approximate the target LLM's ranking behavior, and (2) a query-based solution that employs an iterative generator-optimizer loop without requiring model internals access. To evaluate their method, the authors construct AmazonCOREBench and show experiments on four commercial LLMs to show that CORE achieves promotional success."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper addresses an important problem in modern LLM-based search systems with a realistic black-box threat model that assumes no control over LLM architecture or search engine selection, only modifiable item metadata. The construction of AmazonCOREBench with 15 categories and 3,000 products provides a substantial, domain-relevant benchmark.\n2. The evaluation is thorough, testing across four major commercial LLMs with multiple metrics including Promotion Success Rate, perplexity-based fluency assessment, and human evaluation studies with 20 annotators. The ablation studies systematically examine shadow model choices and other factors.\n3. Especially, the query-based solution represents a significant technical contribution by reformulating gradient-free optimization as an iterative generator-optimizer loop that operates entirely through black-box LLM interactions."}, "weaknesses": {"value": "1. While the paper formulates ranking control as minimizing the loss function in eq. 2, there is no explanation/analysis of why this objective leads to effective ranking manipulation. Also, there is no explanation of how the discrete reconstruction step is performed and how it affects optimization quality. \n2. While Table 10 shows similarity scores of 3.7-4.7 between the shadow model and target LLMs on 10 samples, this validation is limited in scope. The paper does not analyze when the shadow model fails to approximate target LLM behavior, what product types or query styles cause divergence, or how approximation errors compound during 2000 gradient descent iterations.\n3. The paper does not explore whether existing adversarial text detectors, consistency checks across multiple queries, or temporal pattern analysis could identify manipulated content. The ethical implications section is generic and does not propose concrete safeguards.\n4. The transferability across categories and temporal robustness (as LLMs update) remain unexplored."}, "questions": {"value": "Q0: Authors are requested to respond to the weaknesses highlighted in the above section.\nQ1: The addition of Gaussian noise for exploration is mentioned but not systematically evaluated. In the experiments, how was the impact of adding this noise?\nQ2: Have you observed cases where the optimization converges in embedding space but produces poor discrete text that fails to achieve desired rankings?\nQ3: Given the work demonstrates significant ranking manipulation capabilities, what specific technical defenses do you recommend for LLM-based search systems? How might search platforms detect systematic ranking manipulation at scale, and what design changes to generative engines could increase robustness against optimization attacks like CORE while preserving utility for legitimate users?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MBquguMpPl", "forum": "cg9nIA1HhH", "replyto": "cg9nIA1HhH", "signatures": ["ICLR.cc/2026/Conference/Submission10034/Reviewer_8QWw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10034/Reviewer_8QWw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760541780895, "cdate": 1760541780895, "tmdate": 1762921440115, "mdate": 1762921440115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the generative engine optimization problems and proposes CORE, an optimization method that controls output rankings through modifying the content of corresponding items.\nIn this paper, the authors argue that the final ranking list produced by LLMs is heavily influenced by the initial order of retrieved results and CORE can mitigate it.\nCORE provides two solutions to promote the rank of items: a shadow-model optimization method (i.e., string-based strategy) which leverages a proxy model to compute gradients over the content of target items and a query-based optimization method which leverages prompt engineering. \nThe query-based method can be further divided reasoning-based and review-based strategies according to the difference in prompts. \nThe former prompts LLMs to generate recommendation reasons while the latter prompts LLMs to generate review-like narratives.\nTo evaluate their method, the authors construct AmazonCOREBench, which is a large-scale benchmark derived from Amazon search results across 15 product categories. \nExperiments on four major LLMs (GPT-4o, Gemini-2.5, Claude-3.7, Grok-3) demonstrate the effectiveness of CORE."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper tries to address the problem of generative engine optimization (GEO), which is relevant and practical at the intersection of LLMs and information retrieval. Since generative engines become more and more popular, understanding and resolving GEO is crucial, just as the status of SEO in conventional search engine.\n\n2. Experimental results are impressive.  It shows that the final ranking list produced by LLMs is heavily influenced by the initial order of retrieved results and CORE achieves high promotion success rate. Besides, the creation of AmazonCOREBench is a valuable contribution that will benefit the community."}, "weaknesses": {"value": "1. The novelty is limited. The shadow-model optimization method seems a direct application of black-box adversarial attack techniques, and the query-based optimization method seems an iterative prompt engineering framework. While effectively applied, the underlying mechanism or learning paradigm is not novel.\n\n2. It lacks theoretical insights. Theoretical analysis or explanations are needed for understanding the phenomenon that the final ranking list produced by LLMs is heavily influenced by the initial order of retrieved results and why CORE (both shadow-model optimization and  query-based optimization) resolves the problem.\n\n3. The core contribution is focusing on a single and specific domain (i.e., product search). The generalizability is not explored and limits its scope as a foundational contribution. It seems the proposed query-based optimization (especially the review-based strategy) is a dedicated method for product search."}, "questions": {"value": "Overall, this paper tries to address a significant applied data science problem with strong empirical results. However, the proposed approach builds on existing methods straightforwardly without introducing a substantial novel algorithm or theoretical insight. So I think this paper is more aligned with the field of applied data science like KDD, WWW and SIGIR.\n\nThis paper can be further improved, including:\n1. Adding theoretical analysis, e.g., discussing the condition under which the proposed method is guaranteed to work\n2. Adding analysis or experiments to show the generality of CORE beyond product search."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "T17mBPwDjD", "forum": "cg9nIA1HhH", "replyto": "cg9nIA1HhH", "signatures": ["ICLR.cc/2026/Conference/Submission10034/Reviewer_Zxr7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10034/Reviewer_Zxr7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761828424485, "cdate": 1761828424485, "tmdate": 1762921439474, "mdate": 1762921439474, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how rankings in LLM-based search  can be manipulated by modifying product-level textual content that the LLM uses when synthesizing recommendations. The authors propose CORE (Controlling Output Rankings in Generative Engines), a method that iteratively appends optimized content to a target product’s description to raise its rank in the generated list. Two optimization modes are explored: shadow-model optimization, which uses a surrogate model to approximate gradients, and (2) query-based iterative optimization, which works under a black-box constraint. The authors also introduce AmazonCOREBench, a benchmark spanning 15 product categories derived from Amazon’s search interface. Experiments across multiple LLMs show that CORE achieves substantial ranking gains."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- S1: The introduction of AmazonCOREBench provides a reusable benchmark that enhances reproducibility and future comparative studies.\n\n- S2: The reasoning-based and review-based optimization strategies are thoughtfully designed and show realistic manipulation behavior.\n\n- S3: The experimental setup is comprehensive, covering multiple model families and 15 product categories, which strengthens the empirical evidence.\n\n- S4: The sensitivity-to-insertion-order experiment (Section 4.5) is particularly insightful, revealing positional bias in generative ranking and demonstrating how content order interacts with linguistic style."}, "weaknesses": {"value": "- W1: The experimental setting seems to be unrealistic. It assumes a single target product is pre-specified and optimized to improve its rank, while all other products remain static. In real generative search, users do not know which item they want to promote.\n\n- W2: All reported improvements are relative to retrieval order, not to any true relevance judgment. The experiments never verify whether the promoted item is actually better or more relevant.\n\n- W3: The optimized outputs have worse fluency, with higher perplexity and lower human ratings than the original texts. This indicates that the method’s strongest manipulations depend on unnatural or verbose text."}, "questions": {"value": "n/a"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sUU4aP6T39", "forum": "cg9nIA1HhH", "replyto": "cg9nIA1HhH", "signatures": ["ICLR.cc/2026/Conference/Submission10034/Reviewer_ppC2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10034/Reviewer_ppC2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761884986893, "cdate": 1761884986893, "tmdate": 1762921439111, "mdate": 1762921439111, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This paper presents an *original* and *significant* contribution by introducing **CORE** (*Controlling Output Rankings in -gEnerative Engines*), a novel optimization method focused on manipulating the output ranking generated by Large Language Models (LLMs) in search applications. \n\n- The core strength of this approach lies in its practicality and realism: it addresses the critical dependency where LLM recommendations are dictated by the initial retrieval order, potentially *disadvantaging small businesses*. \n\n- CORE successfully operates within a realistic *black-box* setting, where neither the LLM architecture nor the choice of external search engine can be modified by the user. Instead, CORE targets the synthesis stage by appending optimized content (such as *string-based*,  *reasoning-based* or *review-based* text) to influence the LLM's final ranked list.\n\n- The *quality* and *clarity* of the empirical validation is really good. The authors developed **AmazonCOREBench**, a *large-scale benchmark* simulating a realistic product search environment derived from 15 Amazon categories, enhancing the utility of the results for future research. \n\n- Experiments across four prominent LLMs (GPT-4o, Gemini-2.5, Claude-3.7, and Grok-3) demonstrated exceptional effectiveness, achieving an average Promotion Success Rate of **80.3% @Top-1** under the best strategy. \n\n- Furthermore, the evaluation includes a thorough comparison showing CORE's *superior performance and robustness* against existing ranking manipulation methods (STS, TAP, SRP). Crucially, the *review-based* strategy maintains high human-rated fluency (4.6 out of 5) while remaining stealthy, with a low detection rate (18.4%), underscoring the method's effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "*   **Original Problem Formulation:** CORE addresses output ranking manipulation at the LLM *synthesis stage*, distinct from traditional SEO or GEO which focus on retrieval, overcoming the limitation of fixed search engine choice.\n*   **Realistic Threat Model:** The methodology operates successfully under the demanding *black-box assumption*, without requiring access to model internals or gradients.\n*   **High Effectiveness:** CORE achieved high promotion success rates, including an average of **80.3% @Top-1** across 15 categories on four commercial LLMs.\n*   **Novel Optimization Strategies:** The paper introduces effective *reasoning-based* and *review-based* optimization content that leverages how LLMs process information (e.g., Chain-of-Thought reasoning).\n*   **Robustness against Baselines:** CORE consistently and substantially *outperforms* prior ranking manipulation methods like STS, TAP, and SRP across multiple models and categories.\n*   **Creation of AmazonCOREBench:** The development of a robust, large-scale, 15-category benchmark provides a vital resource for evaluating future generative engine optimization techniques in product search.\n*   **Demonstrated Fluency:** The *review-based strategy* proved highly effective while maintaining high fluency (4.6/5 in human evaluation) and low human detectability (18.4%), making the manipulation practical and hard to flag.\n*   **Comprehensive LLM Testing:** Experiments were rigorously conducted across four state-of-the-art, widely deployed LLMs: *GPT-4o, Gemini-2.5, Claude-3.7, and Grok-3*.\n*   **Clear Methodology:** The paper clearly defines the optimization task and provides two distinct solutions: a gradient-based *shadow-model solution* and an iterative *query-based solution* for black-box environments.\n*   **Model Bias Insights:** The results highlight differences in model responsiveness, noting that certain LLMs (like GPT-4o) favor reasoning while others (like Gemini-2.5) favor review-style content."}, "weaknesses": {"value": "The primary weakness of the paper lies in the **practical constraints** and **fragility** of the proposed optimization strategies, particularly in a truly *black-box* environment, coupled with a lack of discussion regarding **mitigation and defense**. \n\n*   **Reliance on Alignment:** Optimal performance (PSR) in the *query-based black-box solution* requires the Generator and Optimizer to be the *same model* as the target synthesizing LLM, suggesting limited robustness if the target LLM is truly unknown or changes frequently. While the *query-based solution* is highly effective, it relies heavily on the iterative interaction of a Generator and Optimizer model that often must be *aligned* with the target synthesizing LLM (e.g., using GPT-4o as both Generator/Optimizer when attacking GPT-4o). When these components are *mismatched*, performance, especially at Top-1 rank, tends to degrade. \n\n*   **Fragility to Hyperparameters:** The iterative black-box optimization depends on a carefully tuned similarity threshold ($\\tau \\ge 0.7$) for effective performance, as lowering the threshold ($\\tau=0.5$) causes success rates to drop sharply. This dependence on high alignment and tuned hyperparameters undermines the robustness implied by the black-box setting. \n\n*   **High Detectability of Reasoning Strategy:** The highly successful *reasoning-based strategy* is easily flagged by human annotators (62.1% detection rate), making it impractical for stealthy, real-world deployment. The *reasoning-based* content, while highly successful in promotion, exhibits a **high human detection rate (62.1%)** compared to the review-based strategy (18.4%), limiting its practical stealthiness as a real-world attack vector.\n\n*   **No Discussion of Defenses:** The paper identifies a significant security threat but provides no mechanisms, suggestions, or baseline evaluations for **mitigating** CORE-style attacks. The paper only compares CORE to existing, less effective attack methods (STS, TAP, SRP) but does not explore how generative engines could be hardened against content-appended manipulation strategies. A significant omission is the complete absence of a discussion on **defenses** against CORE. Given the demonstrated effectiveness (80.3% @Top-1 success) and the high stealth of the *review-based* strategy, CORE represents a non-trivial security threat to generative engines. \n\n*   **Insertion Order Sensitivity:** The effectiveness of the optimization content (both Review and Reasoning) is heavily dependent on the order in which items are presented to the LLM, indicating potential instability in dynamic search environments. Effectiveness of the optimized content is highly sensitive to the **insertion order** of the search results, suggesting that minor variations in upstream search engine output could dramatically reduce CORE's success rate in a live, dynamic environment.\n\n*   **High API Cost:** The successful black-box solution relies on an iterative *Append-and-Query* loop, which implies significant latency and cost associated with repeated API calls to expensive commercial LLMs (GPT-4o, Gemini-2.5, Claude-3.7, Grok-3). There is no mention of either cost or latency in the paper.\n\n*   **Limited Domain Scope:** The entire empirical evaluation is focused exclusively on **product search** within the **Amazon** environment (AmazonCOREBench)."}, "questions": {"value": "1. **Mitigation Strategies**: Given that **CORE** demonstrates a highly effective and **stealthy manipulation** technique (especially the review-based strategy with 18.4% detection rate), what specific defense mechanisms or detection methods did the authors consider or test for hardening generative engines against this type of content-based optimization?\n2. **Scalability and Cost**: The **query-based optimization** involves an iterative Generator–Optimizer loop. Could the authors quantify the average number of iterations/API calls required to achieve the reported **PSR@1**, and estimate the real-world latency and financial cost of deploying CORE successfully against a single user query?\n3. **Black-Box Alignment in Practice**: In a truly **black-box** scenario, how would an attacker determine the optimal choice for the Generator and Optimizer models to match the unknown synthesizing LLM, especially since mismatched configurations lead to performance drops in the **Reasoning strategy**?\n4. **Transferability Beyond Product Search**: The method is evaluated only on **AmazonCOREBench** for product recommendations. How do the reasoning-based and review-based strategies transfer to other generative engine tasks, such as summarizing long documents, creating travel itineraries, or generating **code recommendations**?\n5. **Impact of Retrieval Set Size**: The benchmark collects the **top-10** recommendations from Amazon. What is the expected drop in Promotion Success Rate if the synthesizing LLM were to use only the top-5 or top-3 retrieved items, potentially limiting the LLM’s exposure to the optimized content?\n6. **Addressing Insertion Order Volatility**: Since effectiveness is highly dependent on the optimized content's **position** relative to other candidates (Table 5), how can an attacker ensure or increase the likelihood that their optimized content appears early in the input list provided by the search engine to the LLM, overcoming the **instability** shown in the sensitivity analysis?\n7. **Shadow Model Optimization (Discrete Mapping)**: The shadow model solution uses **gradient descent** in the continuous embedding space, followed by a discrete reconstruction step. Did the authors measure the fidelity loss or **semantic drift** introduced during this reconstruction process, and how does this step potentially limit the performance of the shadow-model solution compared to the query-based solution?"}, "flag_for_ethics_review": {"value": ["Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "- **Ethics statement** clearly mentions adherence to ICLR code of conduct. However, the study does mention employing 20 human annotators for evaluating fluency of generated content and might necessitate a review if desired by Area Chairs and/or other reviewers.\n- **LLM usage** in clearly mentioned that it was used for improving quality of the paper, language, grammar and not for ideation, methodology or research design\n- **Reproducibility statement** is also legitimate as the sample source code is made publicly available at the time of review in an anonymous repository"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "X2tHFHDtdx", "forum": "cg9nIA1HhH", "replyto": "cg9nIA1HhH", "signatures": ["ICLR.cc/2026/Conference/Submission10034/Reviewer_kqGS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10034/Reviewer_kqGS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10034/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992649519, "cdate": 1761992649519, "tmdate": 1762921438781, "mdate": 1762921438781, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}