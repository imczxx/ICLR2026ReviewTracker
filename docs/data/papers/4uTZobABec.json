{"id": "4uTZobABec", "number": 8001, "cdate": 1758050333802, "mdate": 1759897815811, "content": {"title": "Learning a distance measure from the information-estimation geometry of data", "abstract": "We introduce the Information-Estimation Metric (IEM), a novel form of distance function derived from an underlying continuous probability density over a domain of signals.\nThe IEM is rooted in a fundamental relationship between information theory and estimation theory, which links the log-probability of a signal with the errors of an optimal denoiser, applied to noisy observations of the signal.\nIn particular, the IEM between a pair of signals is obtained by comparing their denoising error vectors over a range of noise amplitudes.\nGeometrically, this amounts to comparing the score vector fields of the *blurred* density around the signals over a range of blur levels.\nWe prove that the IEM is a valid global metric and derive a closed-form expression for its local second-order approximation, which yields a Riemannian metric.\nFor Gaussian-distributed signals, the IEM coincides with the Mahalanobis distance.\nBut for more complex distributions, it adapts, both locally and globally, to the geometry of the distribution.\nIn practice, the IEM can be computed using a learned denoiser (analogous to generative diffusion models) and solving a one-dimensional integral.\nTo demonstrate the value of our framework, we learn an IEM on the ImageNet database.\nExperiments show that this IEM is competitive with or outperforms state-of-the-art supervised image quality metrics in predicting human perceptual judgments.", "tldr": "We introduce the Information-Estimation Metric (IEM), a theoretically grounded unsupervised distance measure that adapts to data geometry. It shows competitive performance with supervised perceptual metrics.", "keywords": ["Distance functions", "perceptual metrics", "image quality measures", "proximity measures", "information-estimation relations", "i-mmse", "riemannian metric", "information geometry", "metric learning"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d26b7e936bece585075653c7536a19f79172ab49.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper innovatively proposes the Information-Estimation Metric (IEM), a distance measure derived from the local geometric properties of probability distributions (denoising errors and score vector fields). It breaks through the limitation that traditional supervised perceptual metrics rely on manual annotations, validates its unsupervised learning capability on the ImageNet dataset, and outperforms most existing methods in image quality assessment tasks. The overall theoretical derivation is rigorous and the experimental design is comprehensive."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.Solid Mathematical Foundation. The paper reliably demonstrates the mathematical significance of its work.\n2.Comprehensive Experimental Validation and Credible Conclusions. The paper verifies the advantages of IEM over other metrics through experiments and tests."}, "weaknesses": {"value": "1. The drawback of low computational efficiency of the IEM. \n2.The experimental scope is relatively limited, with insufficient validation of the IEM’s performance across a wide range of noise types."}, "questions": {"value": "More experiments on different datasets should be more convincing.\nCould you provide more evidence of the demand for IEM?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xWGGYNCmKT", "forum": "4uTZobABec", "replyto": "4uTZobABec", "signatures": ["ICLR.cc/2026/Conference/Submission8001/Reviewer_dR9Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8001/Reviewer_dR9Y"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8001/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761475115471, "cdate": 1761475115471, "tmdate": 1762920004674, "mdate": 1762920004674, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes the IEM and primarily validates it on image quality assessment tasks. The core idea involves measuring distribution shifts, and the method is not inherently limited to visual data. The experimental results demonstrate its performance on specific datasets like TQD."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "*   **General Formulation:** The proposed IEM is not fundamentally tied to visual data, suggesting potential applicability to other media types like audio or natural language, as it makes no specific assumptions about the modality.\n*   **Interesting Motivation:** The motivation based on \"humans exhibit complex patterns of sensitivity that vary with the direction of the signal’s perturbation\" is compelling and aligns with nuanced aspects of perception."}, "weaknesses": {"value": "*   **Insufficient Experimental Validation:**\n    *   The paper's core motivation and problem formulation do not appear exclusively focused on Image Quality Assessment (IQA), yet validation is conducted *only* within IQA tasks. This is insufficient. If the goal is a general measure of distribution shift, experiments on other modalities (e.g., sound, text) are necessary to substantiate the claim of generality.\n    *   Within the IQA validation, there is a lack of experiments on real-world images with complex, mixed distortions. This is crucial for verifying the method's ability to assess information changes caused by complicated, realistic impairments.\n*   **Lack of Comparative Analysis:** A critical weakness is the absence of a comparative analysis between IEM and other established information-theoretic distance measures like Kullback-Leibler Divergence (KLD), Jensen-Shannon Divergence (JSD), and Earth Mover's Distance (EMD). Such a comparison is essential for demonstrating IEM's potential superiority or unique advantages.\n*   **Inadequate Explanations:**\n    *   The significant performance discrepancy of `IEM_sq` (poor on photo quality assessment but good on TQD) lacks a thorough explanation from either a theoretical or experimental analysis perspective.\n    *   The notation `IEM_fw` is introduced without a clear explanation.\n*   **Parameter Sensitivity:** The IEM demonstrates high sensitivity to the parameter `Γ` (Gamma), with the \"optimal\" value varying drastically (e.g., from `1/4` to `10^6`) between different IQA tasks (photographic vs. texture images). This instability is a practical concern that needs addressing."}, "questions": {"value": "1.  **Generalizability and Scope:** The paper's motivation seems broader than IQA. Have you considered, or could you perform, validation on non-visual modalities (e.g., audio, text) to truly demonstrate IEM's general applicability for measuring distribution shifts?\n2.  **Theoretical Interpretation and Measurement:** A key motivation relates to sensitivity varying with the *direction* of perturbation. In high-dimensional spaces (e.g., latent spaces), how can the \"direction\" of distributional change be effectively measured? Furthermore, how might the similarity or difference between these \"directions\" of change impact IEM's performance? Is IEM inherently sensitive to this directional information?\n3.  **Application to Generative Models:** Could IEM be applied to quantify the difference between generated and real images, thus serving as a metric for evaluating the performance of generative models?\n4.  **Comparative Advantage:** How does IEM's performance compare directly to other information-theoretic measures like KLD, JSD, and EMD on your tasks? This comparison is vital for establishing IEM's value.\n5.  **Explanation of Results and Definitions:** What explains the contradictory performance of `IEM_sq` (good on TQD, poor on photo quality assessment)? Can you provide a theoretical hypothesis or detailed experimental analysis?\n6.  **Robustness to Parameters:** The performance is highly sensitive to `Γ`. What is the underlying reason for this sensitivity? Are there strategies to make the method more robust to the choice of `Γ`, or to determine an optimal `Γ` in a more principled, task-agnostic way?\n7.  **Sensitivity to Denoiser Choice:** Is the performance of the proposed method sensitive to the selection of the specific denoiser used?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Ysv6bbKdWy", "forum": "4uTZobABec", "replyto": "4uTZobABec", "signatures": ["ICLR.cc/2026/Conference/Submission8001/Reviewer_CAxo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8001/Reviewer_CAxo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8001/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761917952287, "cdate": 1761917952287, "tmdate": 1762920004304, "mdate": 1762920004304, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce a novel distance metric called the Information-Estimation Metric (IEM). The IEM is defined based on fundamental principles connecting probability density with local geometry (i.e., connecting the estimation error to the gradient of the log of the marginal). Authors provide a rigorous theoretical framework, as well as experiments to further explain the usefulness of the proposed metric. Hence, I recommend this paper to be accepted."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is well-written, the motivation is clear and sound. Theoretical framework is thorough, experimental section is provided. While the computational complexity can be an issue, authors still provided experimental results, which is appreciated.\n\nThe paper introduces a new distance metric that relies on the geometry of the distribution. The idea is interesting and useful. One strength is that the method is not informed by any downstream task, and is rather derived directly from the probability distribution of the data. Second, the IEM does not rely on the manifold hypothesis, and is well-defined for any valid probability density.\n\nThe IEM depends directly on the prior $p_{\\mathbf{x}}$, rather than through an observation model, i.e., the representation $p_{\\mathbf{y} | \\mathbf{x}}$, that may or may not be dependent on the prior. And, the IEM is a proper metric, from which the authors derive a local metric $\\mathbf{G}$ such that it is a one-way relationship. I.e., the IEM is not a geodesic distance.\n\nLastly, the experiments show interesting results -- the distance metric can predict human perceptual judgement.\n\nOverall, the paper presents a significant theoretical advancement in connecting information theory, estimation theory, and geometry to derive perceptually meaningful distance metric."}, "weaknesses": {"value": "An obvious weakness, as the authors acknowledge in the Discussion section, is the computational complexity of the approach. Numerical estimation of an integral is expensive, and there exist other works that provide a metric but have a smaller cost. It would be great if authors could come up with a way to make this practical and usable for the community. Also, the method needs training a diffusion model, which is also expensive.\n\nThe paper provides a metric for continuous distributions, which is often not available or well-defined for all types of data.\n\nThe experiments are focused on natural images. One of the strengths that the authors mention is that the IEM does not rely on the manifold hypothesis. While I understand that the theory of IEM does not rely on the manifold hypothesis, it strikes me that natural images \\textit{do} lie on a manifold. It would make the paper stronger to see experiments on data that do not necessarily lie on a manifold (e.g., text).\n\nDespite these limitations, the paper presents a significant theoretical advancement in connecting information theory, estimation theory, and geometry to derive perceptually meaningful distance metrics."}, "questions": {"value": "How do authors expect to solve the computational complexity issue?\n\nHave authors conducted experiments on other types of data?\n\nThe authors show that for Gaussian distributions, the IEM coincides with the Mahalanobis distance. Are there other known probability distributions where the IEM has a closed-form expression?\n\nHow does the IEM relate to other geometrically-informed distance measures like optimal transport distances (e.g., Wasserstein distance)?\n\nThe paper focuses on supervised versus unsupervised approaches. Could a semi-supervised approach yield better results with less labeled data?\n\nHow stable is the IEM to small perturbations in the underlying data distribution? Is there a way to quantify its robustness?\n\nHow might the IEM perform in domains where human perceptual ground truth is unavailable or difficult to obtain?\n\nCould the IEM be applied to other perceptual tasks like anomaly detection or out-of-distribution detection?\n\nHow does the local metric G(x) derived from the IEM compare to other local metrics derived from different principles in manifold learning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ktxwrpbFoe", "forum": "4uTZobABec", "replyto": "4uTZobABec", "signatures": ["ICLR.cc/2026/Conference/Submission8001/Reviewer_o82F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8001/Reviewer_o82F"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8001/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762579614076, "cdate": 1762579614076, "tmdate": 1762920003894, "mdate": 1762920003894, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a well-defined (proper) distance metric called the Information-Estimation Metric (IEM) induced by a probability distribution. Specifically, the metric is computed by comparing the denoising errors between the input signals when subject to varying levels of noise. ​It is built on the pointwise ​I-MMSE and the Tweedie-Miyasawa formulas. Inspiration is also drawn from the generative process in a diffusion model. The metric is shown to be the Mahalanobis metric when the underlying distribution is Gaussian. As an application, it is shown to correlate well with human judgment when applied to image pairs. Other interesting applications are identified for future investigation.\n\nThe paper makes a solid contribution with several potential follow-up avenues. The experiments are both illustrative and convincing, and the writing is top-notch. ​"}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "​The formulation is novel and has many potential applications.\n\n​The exposition and the illustrations are excellent."}, "weaknesses": {"value": "A better connection between IEM and the image quality experiment could be made."}, "questions": {"value": "Could you please provide some intuition on how iso-IEM contours look like at larger scales (or for larger epsilon)?  \n\nAs a follow-up question, can you please comment on the IEM landscape in the context of image quality assessment? Specifically, how do images that lie on an iso-IEM contour or a ball with the reference at the center look like? How do they compare with, say, iso-VIF or iso-LPIPS images?\n\nCan you please point to the prior distribution assumed for the IQA experiments? I may have missed this detail. \n\nWhy does the IEM correlate well with human judgment?\n\nCan you please comment on the motivation for exploring the connection with the KL divergence? From what I understand, the IEM is defined for points drawn from the same underlying prior data distribution. The KL divergence, on the other hand, compares distributions. The translation of p_x does answer this to some extent, but some more insights could help the readers."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4mrW5XZRWp", "forum": "4uTZobABec", "replyto": "4uTZobABec", "signatures": ["ICLR.cc/2026/Conference/Submission8001/Reviewer_hJYw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8001/Reviewer_hJYw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8001/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762584379266, "cdate": 1762584379266, "tmdate": 1762920003467, "mdate": 1762920003467, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}