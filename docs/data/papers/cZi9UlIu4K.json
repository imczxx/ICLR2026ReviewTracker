{"id": "cZi9UlIu4K", "number": 18706, "cdate": 1758290301150, "mdate": 1759897086292, "content": {"title": "FoSSIL: A Unified Framework for Continual Semantic Segmentation in 2D and 3D Domains", "abstract": "Evolving visual environments challenge continual semantic segmentation by\nintroducing the complexities of class-incremental learning, domain-incremental\nlearning, limiting available annotations, and necessitating the use of unlabeled data.\nIn this work, we present the framework FoSSIL (Few-shot Semantic Segmentation\nfor Incremental Learning), which extensively benchmarks continual semantic\nsegmentation, spanning both 2D natural scenes and 3D medical volumes. Our\nevaluation encompasses diverse and realistic settings, leveraging both labeled\n(few-shot) and unlabeled data. Building on this benchmark, we introduce\nguided noise injection to mitigate overfitting due to novel few-shot classes\nfrom various domains. Furthermore, we leverage semi-supervised learning\nfor unlabeled data to augment few-shot novel classes. We propose a filtering\nmechanism to remove highly confident but incorrectly predicted pseudo-labels,\nfurther improving performance. Results across class-incremental, few-shot, and\ndomain-incremental scenarios with unlabeled data validate our strategies for\nrobust semantic segmentation in complex, evolving settings, highlighting both\nthe effectiveness and generality of our approach. Our findings illustrate that the\nproposed framework forms a simple yet powerful recipe for continual semantic\nsegmentation in dynamic real-world environments. Our large-scale benchmarking\nacross natural 2D and medical 3D domains exposes key failure modes of existing\nmethods and offers a roadmap for building robust continual segmentation models.", "tldr": "", "keywords": ["Incremental Learning", "Few shot Learning", "Domain shift", "continual learning", "domain-incremental learning", "semi-supervised learning", "semantic segmentation"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1a1629d142e6775046604acea6416235d6579c10.pdf", "supplementary_material": "/attachment/dccc95c47559393827730425cb53a7c3197b23c6.pdf"}, "replies": [{"content": {"summary": {"value": "This paper presents FOSSIL, a unified framework for continual semantic segmentation that simultaneously addresses class-incremental (CIL), domain-incremental (DIL), and few-shot challenges. The method introduces Guided Noise Injection (GNI) to mitigate overfitting in few-shot settings and Prototype-guided Pseudo-label Refinement (PLR) to effectively leverage unlabeled data. Experiments on a new, comprehensive 2D/3D benchmark show FOSSIL significantly outperforms existing methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles a highly practical and challenging problem by unifying CIL, DIL, and few-shot learning. This problem formulation is novel and critical for real-world applications like autonomous driving and medical analysis. \n2. The validation is extensive, testing against various methods on diverse backbones. The ablation studies in Figure 5 clearly demonstrate the necessity and contribution of both GNI and PLR.\n3. The paper is well-written, with a clear problem definition , methodology, and analysis, making it easy to follow."}, "weaknesses": {"value": "1. This principle of using gradient statistics to modulate network parameters seems not new. In my opinion, it is the core mechanic in adaptive optimizers (e.g., Adam, RMSProp), which use squared gradients to normalize learning rates. While GNI's application differs from optimization, I think the underlying concept is related. The paper needs to provide a discussion comparing GNI to other adaptive regularization schemes or existing noise injection methods (e.g., standard weight decay, dropout, or variational dropout) and justify why this specific gradient-based formulation is superior.\n2. The paper lacks sensitivity analysis for the thresholds in PLR ($\\tau_{conf}$, $\\tau_{sim}$). It is unclear how these were \"empirically determined\" or how robust the model is to their variation.\n3. GNI is only applied to the final classifier layer $F$. The paper needs to justify why it isn't applied to deeper feature extractor layers, which are also prone to overfitting in few-shot settings."}, "questions": {"value": "I hope the authors can address the issues I raised in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BZ3lLinocO", "forum": "cZi9UlIu4K", "replyto": "cZi9UlIu4K", "signatures": ["ICLR.cc/2026/Conference/Submission18706/Reviewer_w3yv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18706/Reviewer_w3yv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761841416503, "cdate": 1761841416503, "tmdate": 1762928410701, "mdate": 1762928410701, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FoSSIL, a unified framework and benchmark for continual semantic segmentation across 2D natural scenes and 3D medical volumes. It targets realistic settings that combine class-incremental (CIL) and domain-incremental (DIL) shifts under few-shot supervision, optionally augmented with unlabeled data. The authors also release five challenging benchmarks (three 3D-medical, two 2D-driving) with multi-session protocols and scarce labels per session."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper has the following strengths:\n\n- The paper ambitiously unifies several learning paradigms - continual, few-shot, and semi-supervised segmentation - under one benchmark suite. \n\n- The proposed benchmarks (Med FoSSIL and Natural FoSSIL) cover realistic multi-session setups and will likely be valuable to the community.  \n\n- The evaluation is broad, including 25+ baselines, multiple backbones (U-Net, DeepLabv3+, SwinUNetr, SAM), and detailed ablations on proposed modules.  \n\n- The paper is generally well organized, with mathematical formulations that are easy to follow."}, "weaknesses": {"value": "I have recognize these cons:\n\n- The core mechanisms - prototype replay, noise-based regularization, and pseudo-label filtering - are adaptations of known techniques. The contribution is mainly in *integration* and *benchmarking*, not in introducing fundamentally new algorithms.\n\n- The paper does not analyze *why* the guided noise injection helps beyond empirical performance. No theoretical link to stability–plasticity balance is made.\n\n- Some baselines were not originally designed for few-shot or semi-supervised continual segmentation (e.g., MiB, MDIL), which could exaggerate FoSSIL’s relative advantage.\n\n- Details of data splits, unlabeled data sampling, and hyperparameter tuning are missing. For a benchmark paper, this is a major weakness.\n\n- The work lacks qualitative examples or discussions of cases where FoSSIL fails, such as severe domain shifts or noisy unlabeled data.  \n\n- The paper repeats motivation and design explanations across sections, and some figures (e.g., Figure 2–4) are not deeply analyzed."}, "questions": {"value": "Some questions should be answered:\n\n1. How is guided noise injection different from existing gradient-based regularization (e.g., SAM, weight perturbation)?  \n\n2. Are prototypes recomputed from all sessions or updated incrementally?  \n\n3. What is the additional computational overhead compared to vanilla training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HWWcuf76fw", "forum": "cZi9UlIu4K", "replyto": "cZi9UlIu4K", "signatures": ["ICLR.cc/2026/Conference/Submission18706/Reviewer_y7bk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18706/Reviewer_y7bk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900473078, "cdate": 1761900473078, "tmdate": 1762928408574, "mdate": 1762928408574, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles continual semantic segmentation in a very real-world way: data arrives in sessions, with a fully supervised base session and then a stream of few-shot increments that either introduce new classes, shift the domain, or both, while unlabeled data is abundant. The proposed FoSSIL framework keeps old knowledge without storing raw images by replaying compact class prototypes, steadies training with a gradient-guided noise injection scheme to curb few-shot overfitting, and makes semi-supervision actually work by filtering pseudo-labels using both confidence and prototype consistency in a mean-teacher setup."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper directly tackles continual semantic segmentation across CIL, DIL, and few-shot learning in one framework. FoSSIL addresses this limitation and leverages unlabeled data to augment scarce few-shot classes.\n2. Extensive evidence across 3D medical and 2D autonomous driving benchmarks, with multi-session protocols, shows consistent gains and robustness over strong baselines.\n3. FoSSIL integrates cleanly with diverse backbones, indicating strong architecture-agnostic generalization rather than narrow tuning.\n4. This paper proposes a readily deployable solution to real-world deployment pain points—privacy, limited annotations, and domain shift."}, "weaknesses": {"value": "1. The paper lacks a clear pipeline/architecture diagram, which would make the method easier to grasp at a glance.\n2. The noise injection module has no analysis of hyperparameters or other strategies (e.g., sensitivity and robustness studies).\n3. In several tables (Table 2, Table 4, Table 6, Table 7), multiple methods report identical Session-0 results; the authors should explain why.\n4. In Table 3, FoSSIL (U-Net) drops to 0.025 at Session 4 and then rebounds to 0.324 at Session 5; this large fluctuation should be verified (typesetting/statistics) or clearly explained.\n5. The paper should report computational costs, including training/inference time and memory/parameter overhead.\n6. Although FoSSIL improves over multiple sessions, the absolute Dice/IoU remains low, which may limit practical applicability; this seems at odds with the paper’s motivation and should be discussed.\n7. How are τ_conf and τ_sim selected/tuned? Are they shared across datasets? Please provide threshold sensitivity and retention/coverage statistics."}, "questions": {"value": "Please refer to the points listed under Weaknesses; if the authors can satisfactorily address these concerns, I will consider raising my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7tFUWesdig", "forum": "cZi9UlIu4K", "replyto": "cZi9UlIu4K", "signatures": ["ICLR.cc/2026/Conference/Submission18706/Reviewer_WWNg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18706/Reviewer_WWNg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761905583239, "cdate": 1761905583239, "tmdate": 1762928408086, "mdate": 1762928408086, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tries to study continual learning in a complex setting that includes class-incremental, domain-incremental, and few-shot learning. To this end, the authors build a benchmark and propose a method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Pros:\n- Continual learning is indeed an important topic in the field.\n- The paper is well written and nicely organized. I can tell the authors put a lot of effort into polishing it, and I appreciate that.\n- The experiments cover a wide range of methods, which is nice to see."}, "weaknesses": {"value": "Cons:\n- Honestly, I don't really like this kind of work. It feels like a mixture of everything — several settings thrown together without a clear focus. While this may have some meaning academically, in real-world scenarios (e.g., in industry), people usually prefer to train a specialized model rather than deal with such a complicated continual setup.\n- Even if we accept the setting, the experimental analysis is not very systematic. The paper doesn't really explore how different setups affect different models, nor does it provide useful insights for choosing models in practice.\n- The paper starts with a quote from Confucius: \"I hear and I forget. I see and I remember. I do and I understand.\" Who is Confucius in this context? Is he a machine learning expert? I don't quite get the connection between this quote and the paper's content.\n- The introduction could be smoother in logic. For example, when guided noise injection first appears, I didn't understand why it suddenly shows up or how it relates to the context. Please consider improving the narrative flow there.\n- As far as I know, many important medical imaging modalities are 2D. Why aren't they included in the experiments?\n- I appreciate that the authors included many methods in the benchmark, but they’re mostly from 2020–2023. There's no mention of newer work (2024–2025), including recent arXiv papers. This weakens the experimental conclusions to some extent.\n- Minor issues: e.g., in the introduction, the numbering goes (i)–(ii)–(ii)–(iii), which should be fixed."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NLQHcGtV4l", "forum": "cZi9UlIu4K", "replyto": "cZi9UlIu4K", "signatures": ["ICLR.cc/2026/Conference/Submission18706/Reviewer_t59L"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18706/Reviewer_t59L"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18706/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995942747, "cdate": 1761995942747, "tmdate": 1762928407348, "mdate": 1762928407348, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}