{"id": "vyeac15K0J", "number": 6335, "cdate": 1757969779290, "mdate": 1759897921438, "content": {"title": "FaCE: Provable Frequency-Aware Convex Enhancement for Training-Free Low-Light Images", "abstract": "We study training-free low-light image enhancement from a provable optimization viewpoint. Building on the Monogenic Fourier transform, we introduce Frequency-Aware Convex Enhancement (FaCE), formulating per-image enhancement as a strictly convex problem with a unique, stable minimizer. To make the frequency modeling reproducible, we (i) define the low-pass prior via the spectral centroid (u_c,v_c) and an energy–cumulative distribution radius r_τ (the smallest radius achieving cumulative spectral energy τ), and (ii) select the number of spectral clusters K with a data-driven model-selection rule. This yields a fully training-free pipeline with clear variables and no learned parameters. We prove that a unique, stable solution exists and verify the guarantees via numerical experiments. On standard benchmarks, FaCE attains competitive quality with a per-image solver, and we include in-the-wild qualitative mosaics on real images to highlight practical usefulness. Rather than competing with large learned priors, FaCE complements them with a provable, interpretable alternative that requires no training and exposes frequency-band attributions.", "tldr": "", "keywords": ["Low-Light Image Enhancement (LLIE); Monogenic Fourier Transform (MFT); Frequency-domain modeling; Convex optimization; Training-free (no learned parameters); Illumination-only enhancement."], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6ffe843eb9ae46ead6803f21b6a6f95aa6471756.pdf", "supplementary_material": "/attachment/2d4a46b26aa761850282454f0bb39c667315cec9.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes FaCE, a frequency-domain unsupervised low-light image enhancement method based on the Monogenic Fourier Transform. The approach clusters spectral components and defines a piecewise-constant enhancement curve using a few scalar parameters, aiming for interpretability and mathematical guarantees (existence, uniqueness, stability) through a convex variational formulation. The pipeline—transform, clustering, weighting, inverse transform—is conceptually simple."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear motivation toward unsupervised and interpretable enhancement: The paper emphasizes physically grounded frequency separation and aims for mathematical rigor in an ill-posed problem setting.\n2. Simple and intuitive pipeline: The proposed framework is easy to understand and implement.\n3. Some positive initial results: Improvements over Multi-Scale Retinex and Zero-DCE on LOL-v1."}, "weaknesses": {"value": "- Although the paper emphasizes rotation, scale invariance and directional sensitivity of the Monogenic Fourier Transform, the implementation uses only the magnitude for clustering and enhancement weight design. Phase and orientation components are entirely ignored. => The claimed advantages of MFT are not substantiated empirically.\n\n- A Key algorithmic step (clustering) in the spectral domain is insufficiently detailed, reproducibility is limited.\n\n- The paper mentions luminance-chrominance separation but lacks spefics, so hard to assess effect on color fidelity.\n\n- Experiments are conducted only on LOLv1 with two older baselines (MSR, ZeroDCE), need more recent LLIE methods (e.g., RUAS, Zero-IG, etc.)\n\n- there's no non-reference metrics (NIQE, BRISQUE, LOE, LPIPS, etc.)\n\n- need runtime and efficiency analysis and evidence for general effectiveness."}, "questions": {"value": "1. Monogenic properties are not used in practice. If the method ultimately relies only on Fourier magnitude, why is the Monogenic Fourier Transform necessary at all? Can you show any measurable benefit from phase/orientation information?\n\n2. How is the clustering performed exactly? Please describe:\n   - feature vector definition, distance metric, initialization and stopping conditions, whether clustering is per-image or global\n\n3. Why is K = 4 used universally? Is there any data-driven rule or analysis supporting this choice?\n\n4. Which luminance–chrominance transform is used? Is the input linearized or gamma-corrected?\n\n5. How is color consistency preserved during reconstruction?\n\n6. Why are recent state-of-the-art low-light methods omitted, especially those also leveraging optimization, frequency, or physical priors?\nWithout comparison, performance claims appear unconvincing.\n\n7. Has the method been tested on other datasets (LOL-v2, DICM, LIME, MEF, VV)? If not, how can generalization and robustness be assessed?\n\n8. What is the precise definition of the “numerical stability” metric? How is variance computed? Why do several entries report zero variance, which seems unrealistic?\n\n9. If the solution is guaranteed to be unique and stable, why is no evidence provided on actual behavior across diverse perturbations?\nWhere is the formal link between the theoretical variable and the parameters actually optimized?\n\n10. What specific part of the enhancement operation is interpretable beyond basic frequency amplification? Can you quantify or demonstrate practical interpretability?\n\n11. Need more ablation studies\n    - monogenic vs. Fourier magnitude\n    - clustering vs. no clustering\n    - low-pass mask vs. none"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "47kS8shjaA", "forum": "vyeac15K0J", "replyto": "vyeac15K0J", "signatures": ["ICLR.cc/2026/Conference/Submission6335/Reviewer_T2c4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6335/Reviewer_T2c4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6335/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761545189704, "cdate": 1761545189704, "tmdate": 1762918629330, "mdate": 1762918629330, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FaCE, a training-free LLIE method centered around the MFT. Unlike mainstream approaches, FaCE formulates the enhancement task as a strictly convex per-image optimization problem to ensure the uniqueness of the solution. Specifically, it defines a low-pass prior using the spectral centroid ($u_c, v_c$) and an energy-cumulative distribution radius ($r_{\\tau}$), while adaptively selecting the number of spectral clusters $K$ via a data-driven model-selection rule. The core idea is to enhance image illumination by constructing a frequency-aware spectral gain map. The method operates in a fully training-free manner, relying solely on MFT for frequency-domain analysis and inverse optimization for reconstruction. The authors provide mathematical proofs for their claims and validate them on several benchmark datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The core strength of this paper lies in its novelty. It innovatively reconstructs the LLIE problem as an MFT-grounded, strictly convex optimization problem, which represents a significant departure from current methods that rely on empirical learning. The writing is clear, the logic is sound, and the experiments effectively validate its claims."}, "weaknesses": {"value": "The implementation details regarding key aspects of the method are not sufficiently transparent. First, the experimental section should include comparisons with more recent and advanced unsupervised or training-free LLIE methods, such as UHDFour and ULEFD, which are already mentioned in the related work section. This would help contextualize FaCE's performance relative to the current state of the art. \n\nFurthermore, the paper claims that key parameters ($K, u_c, v_c, r_{\\tau}$) are determined in a data-driven manner, but the description of the underlying strategy is insufficient. How are these parameters precisely calculated or determined for each image? \n\nAs a per-image optimization method, is its computational overhead practical for real-world applications? The paper lacks a discussion on this crucial aspect in its experiments."}, "questions": {"value": "1.  Could the authors include a comparison with more recent and potentially stronger training-free or unsupervised LLIE methods (e.g., UHDFour, ULEFD) in the experimental section? This would provide a clearer comparison of FaCE's standing within the non-learning paradigm, even if your primary goal is not to compete with learned models.\n\n2.  Could you elaborate on the \"data-driven model-selection rule\" for selecting $K$ and how the low-pass prior parameters ($u_c, v_c, r_{\\tau}$) are chosen based on image frequency? Specifically, what algorithm or heuristic is used to automatically determine these parameters for each input image in a training-free manner?\n\n3.  Could the authors provide an analysis or experimental results on the computational time required for FaCE to process an image of a given resolution?\n\n4.  The paper mentions deriving band-level contribution maps directly from the convex objective, exposing the frequency-to-image pathway. Could you provide an example or a more detailed explanation of how these maps are visualized or used to interpret the enhancement process for a specific image?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "65bnuf3zUq", "forum": "vyeac15K0J", "replyto": "vyeac15K0J", "signatures": ["ICLR.cc/2026/Conference/Submission6335/Reviewer_8d1Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6335/Reviewer_8d1Y"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6335/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920809848, "cdate": 1761920809848, "tmdate": 1762918629022, "mdate": 1762918629022, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes  Frequency-Aware Convex Enhancement, a training-free framework for low-light image enhancement.\nThe key idea is to reformulate the enhancement problem as a strictly convex optimization task in the Monogenic Fourier Transform domain.\nFaCE decomposes illumination and reflection components in the frequency space, constructs a frequency-aware gain map via unsupervised clustering, and theoretically guarantees existence, uniqueness, and stability of the optimal solution.\nThe method claims to outperform traditional Retinex-based and deep learning approaches on LOL-v1/v2 datasets without any training process."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and mathematically consistent.\n2. The framework is training-free and fully deterministic, which makes it reproducible and computationally lightweight.\n3. Implementation is simple, interpretable, and self-contained, offering practical value."}, "weaknesses": {"value": "1. The term “provable” in the paper merely indicates that the formulation is strictly convex and thus solvable, rather than introducing any new optimization principle or convergence scheme. The proofs of existence, uniqueness, and stability rely on standard convex optimization results (strict convexity + lower semicontinuity).\nThe paper does not introduce any new theorem or problem-specific analysis that advances the theory of image enhancement.\n2. Evaluation is restricted to LOL-v1/v2 datasets. The paper does not include comparisons with recent diffusion-based LLIE methods, which are now standard baselines.\n3. The abstract and introduction frame the work as “provable”,” but the core mathematics and methodology remain routine, offering little new insight.\n4. While “training-free” sounds appealing, the method’s applicability to modern imaging tasks (night vision, HDR, IR enhancement) is unclear."}, "questions": {"value": "1. From an algorithmic perspective, the method is merely a standard L2 + TV regularization problem implemented in the frequency domain. What is the substantive difference between your convex formulation and existing variational Retinex models (e.g., Fu et al., TIP 2016)? \n2. Why did you choose the Monogenic Fourier Transform over other common frequency tools such as Gabor or Wavelet transforms?\n3. Have you tested FaCE on non-LOL datasets (e.g., dark natural images, night scenes) to verify generality?\n4. Could FaCE be combined with deep models as a pre/post-processing step, and would it still maintain convexity and theoretical guarantees?\n5. Can you discuss computational complexity compared to typical learning-based enhancement networks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0XY7d02Rcy", "forum": "vyeac15K0J", "replyto": "vyeac15K0J", "signatures": ["ICLR.cc/2026/Conference/Submission6335/Reviewer_HoXq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6335/Reviewer_HoXq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6335/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929692584, "cdate": 1761929692584, "tmdate": 1762918628504, "mdate": 1762918628504, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper is well structured and logically organized, adhering to high academic standards. It presents a clear and coherent progression from motivation through methodology, theoretical formulation, results, and finally to conclusion. All equations are mathematically consistent and theoretically sound within the defined framework.\n\nThe proposed formulation is elegant, and the proofs are built upon established convex optimization principles, ensuring mathematical rigor. The author has provided relevant and appropriate references to prior literature, demonstrating a strong grounding in existing research.\n\nFraming low-light image enhancement as a strictly convex optimization problem is particularly noteworthy, as it provides strong mathematical guarantees of existence, uniqueness, and stability for the solution. Moreover, the approach eliminates the need for large-scale annotated datasets or lengthy training phases.\n\nExperimental results are compelling: the proposed method achieves competitive PSNR and SSIM scores, outperforming well-known baselines such as Zero-DCE and Retinex-based models. The framework also exhibits superior numerical stability under perturbations, consistent with its theoretical foundations. Overall, the results are convincing, clear, and well supported by theory and experimentation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper demonstrates several notable strengths. It is well-structured, logically organized, and supported by a strong theoretical foundation grounded in convex optimization. The formulation of low-light image enhancement as a strictly convex optimization problem is both innovative and mathematically rigorous, ensuring existence, uniqueness, and stability of the solution. The approach eliminates the need for large annotated datasets or extensive training, making it computationally efficient and practical for real-world use. Experimental results further strengthen the contribution, showing higher PSNR and SSIM values compared to established baselines such as Zero-DCE and Retinex, while maintaining superior numerical stability under perturbations. Overall, the paper combines solid theoretical reasoning with clear empirical validation, presenting a reliable and well-referenced contribution to the field."}, "weaknesses": {"value": "The comparison is done only with two models i.e Retinex & Zero DCE . More comparison  data is required to check the sustainability of the proposed model.\nFaCE achieves moderately  PSNR (~17 dB), outperforming other training-free baselines but falling short of modern deep-learning-based low-light enhancement models.\nThe manual dependence on λ₁, λ₂, K  limits FaCE’s efficacy as it reduces consistency, adaptability, and generalization. Without automatic calibration, the model’s enhancement quality can vary significantly between images, reducing its overall practical reliability despite its theoretical strength.\nTests mainly on LOL-v1 and LOL-v2 datasets; broader generalization to diverse real-world illumination or camera domains is unproven\nThe method may serve more as a proof-of-concept than a high-performance system."}, "questions": {"value": "The comparison is done only with two models i.e Retinex & Zero DCE . More comparison  data is required to check the sustainability of the proposed model.\nFaCE achieves moderately  PSNR (~17 dB), outperforming other training-free baselines but falling short of modern deep-learning-based low-light enhancement models.\nThe manual dependence on λ₁, λ₂, K  limits FaCE’s efficacy as it reduces consistency, adaptability, and generalization. Without automatic calibration, the model’s enhancement quality can vary significantly between images, reducing its overall practical reliability despite its theoretical strength.\nTests mainly on LOL-v1 and LOL-v2 datasets; broader generalization to diverse real-world illumination or camera domains is unproven\nThe method may serve more as a proof-of-concept than a high-performance system."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0UphtnUhmZ", "forum": "vyeac15K0J", "replyto": "vyeac15K0J", "signatures": ["ICLR.cc/2026/Conference/Submission6335/Reviewer_Tt6x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6335/Reviewer_Tt6x"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6335/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762059612956, "cdate": 1762059612956, "tmdate": 1762918628133, "mdate": 1762918628133, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}