{"id": "x89r6Mpk66", "number": 11459, "cdate": 1758199568669, "mdate": 1759897573975, "content": {"title": "A Split-Client Approach to Second-Order Optimization", "abstract": "Second-order methods promise faster convergence but are rarely used in practice because Hessian computations and decompositions are far more expensive than gradients. We propose a \\emph{split-client} framework where gradients and curvature are computed asynchronously by separate clients. This abstraction captures realistic delays and inexact Hessian updates while avoiding the manual tuning required by Lazy Hessian methods. Focusing on cubic regularization, we show that our approach retains strong convergence guarantees and achieves a provable wall-clock speedup of order $\\sqrt{\\tau}$, where $\\tau$ is the relative time needed to compute and decompose the Hessian compared to a gradient step. Since $\\tau$ can be orders of magnitude larger than one in high-dimensional problems, this improvement is practically significant. Experiments on synthetic and real datasets confirm the theory: asynchronous curvature consistently outperforms vanilla and Lazy Hessian baselines, while maintaining second-order accuracy.", "tldr": "\\textbf{TL;DR:} We propose an asynchronous split-client framework for cubic Newton methods that overlaps gradient and Hessian computations, yielding a $\\sqrt{\\tau}$ wall-clock speedup and outperforming Lazy Hessian baselines in practice.", "keywords": ["Second-order optimization; Delayed Hessians; Split client"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6d5513ef69d1e6f2b79ced07125bfd1408f1cab7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose a Split-Client approach which delegates computation of second-order Hessian information to a separate client. The authors carry theoretic and experimental analysis on this method and shows that wall-clock time can be reduced."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The motivation is strong, since compute second-order information is slow and is main bottleneck of scaling up second-order optimization. Both theoretic analysis and empirical results are presented. It's a practical method and worths digging into."}, "weaknesses": {"value": "The result is preliminary, there is neither advanced theoretical results nor well-developed useful package. The paper looks more like a proof of concept while the \"split-client\" concept sounds trivial. So everything looks standard and trivial, I don't see any significant contribution in any aspect."}, "questions": {"value": "The \"split-client\" concept looks not surprising at all. Since computing Hessian is expensive, delegating to some outside oracle seems a pretty straightforward thing people should do. The convergence result is also pretty standard.\n\nComparing to lazy Hessian and vanilla hessian is not very valuable since \"split-client\" will definitely be faster, because you just delete all delay in Hessian computation.\n\nI personally feel the most doable way to make this idea to meet NeurIPS standard is to develop some good code packages and optimize it from system side, i.e., how should we distribute work between host machine and worker machine / if we have multiple workers, how can we make \"split-client\" scheme more parallel-efficient, what is the communication cost / etc..."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QKWBNLwP28", "forum": "x89r6Mpk66", "replyto": "x89r6Mpk66", "signatures": ["ICLR.cc/2026/Conference/Submission11459/Reviewer_zqCy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11459/Reviewer_zqCy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11459/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761525196510, "cdate": 1761525196510, "tmdate": 1762922571849, "mdate": 1762922571849, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a split-client cubic regularization framework that decouples gradient and Hessian-related curvature computation into different clients with delayed asynchronous approximate Hessian updates. The delay $\\tau_t$ explicitly models both Hessian evaluation and decomposition time. Theoretical analysis shows a \\sqrt{\\tau} speedup in wall-clock time when \\tau\\!\\gg\\!1. Empirically, on logistic-regression tasks, async split-client update outperforms vanilla cubic Newton and Lazy Hessian."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of splitting gradient and Hessian computation across different clients and using asynchronously delayed Hessians as approximations for speed-up is natural and insightful.\n2. The theoretical wall-clock complexity result provides a guaranteed speed-up for the proposed method."}, "weaknesses": {"value": "1. The experimental evaluation is relatively simple, focusing on convex tasks (logistic regression) at modest scale. There are no deep-learning or genuinely heterogeneous/distributed runs to validate the real-world use case.\n2. The method class is limited to cubic Newton rather than general second-order methods; other widely used examples (e.g., subsampled Newton/sketch, SOAP-style) are not included."}, "questions": {"value": "1. Is the analysis specific to cubic-regularized Newton?\n2. For fairness, since your method requires separate clients, did baselines also run with two clients in parallel (even without splitting gradient/curvature)? Please specify hardware and concurrency per method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "p3rVzy1LHq", "forum": "x89r6Mpk66", "replyto": "x89r6Mpk66", "signatures": ["ICLR.cc/2026/Conference/Submission11459/Reviewer_z2EV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11459/Reviewer_z2EV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11459/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761861792149, "cdate": 1761861792149, "tmdate": 1762922571321, "mdate": 1762922571321, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a central barrier to practical second-order optimization: computing and, in particular, decomposing/factorizing the Hessian is substantially slower than evaluating gradients, so per-iteration advantages often fail to yield wall-clock gains. The goal is to preserve the accuracy and convergence benefits of cubic-regularized Newton while alleviating this runtime bottleneck. In contrast to Lazy Hessian—which reduces recomputation frequency but remains a blocking, hand-tuned scheme that omits decomposition time from its cost model—this work explicitly incorporates decomposition time via a delay parameter and eliminates manual refresh-frequency tuning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The split-client model faithfully captures heterogeneous pipelines (e.g., GPU for gradients, CPU/distributed workers for curvature) and explicitly includes decomposition cost—often the dominant factor—within the delay. This removes the manual tuning required by Lazy Hessian and yields a clean, hardware-aware formulation.\n2. Theoretical results extend cubic regularization to delayed and inexact Hessians, establishing a $\\sqrt{\\tau}$ wall-clock speedup in regimes where curvature computation and decomposition are much slower than gradient steps.\n3. Experiments report loss versus wall-clock time and include time profiling that shows decomposition dominates runtime. Overlapping curvature work delivers tangible gains: the asynchronous method outperforms both vanilla and Lazy baselines with exact and approximate curvature."}, "weaknesses": {"value": "1. The convergence analysis relies on L-Lipschitz Hessians and uniformly bounded delays, which may be violated in practice (e.g., irregular or bursty delays, non-smooth curvature). More critically, Assumption (A4) posits a uniform upper bound on the Hessian approximation error for all $t$, yet the algorithm repeatedly uses inexact curvature (Alg.\\ 1, Step 6), so error accumulation over time is a concern. Verifying these assumptions empirically (e.g., on synthetic setups where delay and error can be controlled) would strengthen the theoretical claims.\n2. The empirical evaluation focuses on logistic regression. Including broader tasks (larger-scale problems, deep learning objectives, structured or constrained optimization) and heterogeneous deployments would better demonstrate generality and scalability.\n3. While wall-clock results are provided, additional resource-normalized metrics (e.g., number of factorizations, matrix–vector products, peak memory, FLOPs) and comparisons under fixed hardware budgets would sharpen the efficiency claims and improve reproducibility."}, "questions": {"value": "Please refer the above parts."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vy14OpHq3U", "forum": "x89r6Mpk66", "replyto": "x89r6Mpk66", "signatures": ["ICLR.cc/2026/Conference/Submission11459/Reviewer_ttUR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11459/Reviewer_ttUR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11459/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980987235, "cdate": 1761980987235, "tmdate": 1762922570801, "mdate": 1762922570801, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper considers second-order methods that focus on the computation problem and proposes a split-client framework to address delays and inexact Hessian updates. Experimental results on synthetic and real datasets demonstrate the effectiveness of the proposed methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper proposes a split-client framework to address delays and inexact Hessian updates, thereby reducing computational costs through asynchronous updates."}, "weaknesses": {"value": "On the assumptions, how can bounded delay be guaranteed? Is it reasonable? Inexact initialization is reasonable, but how can an inexact Hessian be guaranteed?\n\nThe experiments lack practical implementation, and the paper mainly focuses on the logistic problem. Is it possible to extend the method to other problems?\n\nThere is a lack of recent research papers, such as those from 2024 or 2025. Can the approach be extended to trust-region methods?"}, "questions": {"value": "The main question is how to extend this approach to other loss functions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "keJdcbR7NW", "forum": "x89r6Mpk66", "replyto": "x89r6Mpk66", "signatures": ["ICLR.cc/2026/Conference/Submission11459/Reviewer_FSRY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11459/Reviewer_FSRY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11459/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993300676, "cdate": 1761993300676, "tmdate": 1762922570215, "mdate": 1762922570215, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}