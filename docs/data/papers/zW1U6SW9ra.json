{"id": "zW1U6SW9ra", "number": 4518, "cdate": 1757694787510, "mdate": 1759898028571, "content": {"title": "Compressed Map Priors for 3D Perception", "abstract": "Human drivers rarely travel where no person has gone before.\nAfter all, thousands of drivers use busy city roads every day, and only one can claim to be the first.\nThe same holds for autonomous computer vision systems.\nThe vast majority of the deployment area of an autonomous vision system will have been visited before.\nYet, most autonomous vehicle vision systems act as if they are encountering each location for the first time.\nIn this work, we present Compressed Map Priors, a simple but effective framework to learn spatial priors from historic traversals.\nThe map priors use a binarized hashmap that requires only 32 KB/sq km, a 20x reduction compared to storing features densely.\nCompressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.", "tldr": "a framework for learning global spatial features via compact positional embeddings to improve 3D perception in familiar environments", "keywords": ["3D perception", "autonomous driving"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f6374e25adb661d18bd0b9b01b30330b29b0b7ee.pdf", "supplementary_material": "/attachment/83389e49f930778832f6a698f8939bfc4f12d023.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes Compressed Map Priors, a framework that integrates spatial priors from historical traversals into multi-view 3D object detection for autonomous driving. CMP uses binary-quantized hash encoding to achieve extreme memory efficiency. This framework is compatible with both dense grid-based and transformer-based architectures. Experiments on nuScenes show consistent gains, outperforming traditional map priors and learned priors."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. CMP’s binary hash embeddings achieve 32 KB/km² storage, 20× better than dense/GT Map, addressing on-board memory constraints. Its <2% runtime overhead also ensures real-time feasibility.\n2. CMP adapts to both dense and transformer architectures with minimal modifications."}, "weaknesses": {"value": "1. It is not a reasonable configuration to use learned prior map for 3D object detection. If a parked vehicle appears in both the training set and test set, it will be recorded in the prior map during training, making it easier to detect in the testing stage. However, this is meaningless for real-world autonomous driving, as such a vehicle may drive away at any time. Previous methods have not adopted a similar configuration. BEVMap utilizes the map annotations that do not contain object information to improve the accuracy of object detection. NMP leverages learned map priors, but these priors are used for the task of map segmentation.\n2. The authors should provide more comparisons between CMP, NMP, and SOTA map segmentation methods in terms of map segmentation accuracy. The accuracy of \"Val-only\" and \"Both\" scenes can be presented separately."}, "questions": {"value": "1. Why does the memory usage of GT maps much larger than that of CMP in Table 2? Is it possible to compress the GT map in the way of CMP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6TnVDfwPsd", "forum": "zW1U6SW9ra", "replyto": "zW1U6SW9ra", "signatures": ["ICLR.cc/2026/Conference/Submission4518/Reviewer_tZde"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4518/Reviewer_tZde"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4518/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761634482309, "cdate": 1761634482309, "tmdate": 1762917420906, "mdate": 1762917420906, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Compressed Map Priors (CMP)—a multi-resolution spatial hash embedding that stores binarized per-cell features as a persistent prior, fused into standard camera-only 3D detectors. CMP is trained end-to-end (STE for binarization), adds negligible latency (~3%), and claims ~32 KB/km² storage (≈20× smaller than a dense alternative). On nuScenes, CMP consistently improves NDS/mAP across BEVDet, BEVFormer, PETR, and outperforms classical rasterized GT-map priors under a far smaller memory budget."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Pros:\n1. Consistent accuracy gains on nuScenes across three diverse baselines; largest relative lift on BEV-style models.\n2. Simple, detector-agnostic add-on: clean fusion blocks for BEV and transformer stacks (concat+Conv vs. cross-attention). \n3. Thoughtful ablations: traversal count sensitivity and distance-band analysis support the “priors help when signal is weak/far”."}, "weaknesses": {"value": "Cons:\n1. While the method is shown across multiple camera-only 3D detectors, several stronger, recent baselines (e.g., StreamPETR, BEVNext) are missing. Without results on higher baselines, it’s hard to judge headroom and true practical impact.\n2. The approach assumes AVs mostly drive in previously seen areas where priors exist; the conclusion also notes retraining/retuning is needed for new environments, which reduces universality.\n3. No stress tests for prior dropout or corruption. In deployment, parts of the map prior can disappear or become stale. It’s unclear whether the system gracefully falls back to a normal 3D detector.\n4. Train–val spatial leakage risk: Although Appendix details a 50 m overlap rule and a “val-only/both” partition, the main-paper results don’t report metrics conditioned on overlap. If CMP’s benefit concentrates where training traversals exist, the headline numbers could overstate generalization.\nAsk to add: (a) per-split results: val-only vs. both; (b) performance vs. exact nearest-traversal distance (continuous, not bins).\n5. Stale priors / change management :CMP encourages persistence. Lane closures, construction, snow, cones, parked trucks introduce map drift. Random patch masking helps, but it doesn’t simulate systematic stale bias."}, "questions": {"value": "1. I am curious how you gate trust in the prior when sensor evidence contradicts it (e.g., temporary barriers). Is there a learned reliability head or confidence calibration for X_prior?\n2. What is the failure mode when the car localizes off by one grid cell at the finest 1 m resolution? Any qualitative examples? \n3. I am curious whether cross-attention fusion could over-attend to priors in sparse-query detectors. Did you observe reduced reliance when priors are masked at test time?\n4. How much of the total memory footprint (per km²) includes the MLP projector and positional embeddings vs. the hash tables alone? Current reporting appears to count only the tables.\n5. What is the performance about city-transfer: train priors in Boston only and evaluate on Singapore val-only segments; do CMP gains persist? \n6. For fairness, BEVMap uses GT annotations (oracle). Why does CMP beat it on detection? Is it because CMP captures non-semantic cues (texture, curb geometry) that the 6-class raster misses? Could a richer GT (curbs, stop lines, sidewalks) close the gap?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "I54Xlak4jl", "forum": "zW1U6SW9ra", "replyto": "zW1U6SW9ra", "signatures": ["ICLR.cc/2026/Conference/Submission4518/Reviewer_3XPW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4518/Reviewer_3XPW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4518/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761796025540, "cdate": 1761796025540, "tmdate": 1762917420670, "mdate": 1762917420670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Compressed Map Priors (CMP), a data-driven approach for incorporating spatial priors into 3D perception models for autonomous driving. CMP leverages a multi-resolution hash-based embedding scheme with binary quantization to efficiently encode prior knowledge from repeated traversals of the same environment. The compressed prior is fused with standard 3D detection backbones and trained end-to-end with downstream detection losses. Extensive experiments on the nuScenes dataset show that CMP provides consistent detection gains, substantial memory savings (20x reduction), and minimal computational overhead, outperforming both traditional map priors and recent learned priors."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of efficiently leveraging historical traversals to inform 3D perception systems addresses a fundamental inefficiency in current approaches, which often treat every scene as novel despite repeated exposure.\n2. The architecture is modular and demonstrated to work across several leading baselines (BEVDet, BEVFormer, PETR), with minimal intrusion.\nThorough experiments: CMP is compared quantitatively against strong baselines, including modern learned and traditional map priors, across multiple architectures and uses appropriate metrics ."}, "weaknesses": {"value": "1. The method is explicitly described as being beneficial in well-traversed environments (Section 6), but its limitations in places with limited or no prior coverage are only superficially addressed via random patch masking.  No rigorous experiments or quantitative breakdowns for novel/unseen areas are provided, raising concerns for real-world deployment.\n2. Though BEVFormer, PETR, and BEVDet are credible representatives, modern BEV occupancy grid predictors (such as OccFeat or PointBeV, referenced in the related web context) and object-centric methods (e.g., OC-SOP) are not included as comparative baselines in either main results or ablations, potentially missing stronger competitors or alternative design philosophies."}, "questions": {"value": "1. Can the authors provide more rigorous or quantitative evaluations of CMP when applied to environments with entirely novel scenes (not traversed during training), explicitly reporting both absolute and relative performance drops?\n2. Please clarify the impact of the random patch masking augmentation.  Have ablation studies been performed where this is turned off?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "H2vLiV475q", "forum": "zW1U6SW9ra", "replyto": "zW1U6SW9ra", "signatures": ["ICLR.cc/2026/Conference/Submission4518/Reviewer_pzk6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4518/Reviewer_pzk6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4518/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925131173, "cdate": 1761925131173, "tmdate": 1762917419820, "mdate": 1762917419820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a framework for incorporating historical context into perception models with Compressed Map Priors, which employs a multi-resolution hash-based spatial encoding with binary quantization to efficiently store and retrieve prior spatial information."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The map prior encoding method proposed in this paper offers storage advantages compared to previous approaches.\n2. The proposed method enables end-to-end optimization of map priors and perception tasks."}, "weaknesses": {"value": "1. The proposed method was only tested on a single dataset and lacks validation on other mainstream datasets, such as KITTI, Waymo, Argoverse2, etc.\n2. The experimental section compares against outdated methods and lacks comparisons with the latest state-of-the-art approaches.\n3. The proposed method is limited to datasets where the training and testing data have overlapping areas on the map, making it difficult to apply in real-world open scenarios.\n4. The proposed model contains numerous hyperparameters, and ablation studies are lacking for some of them."}, "questions": {"value": "1. Please refer to the Weaknesses section.\n2. Is the proposed method applicable to other 3D perception tasks such as 3D segmentation and tracking?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "73SGddJELt", "forum": "zW1U6SW9ra", "replyto": "zW1U6SW9ra", "signatures": ["ICLR.cc/2026/Conference/Submission4518/Reviewer_wb2r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4518/Reviewer_wb2r"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4518/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929048350, "cdate": 1761929048350, "tmdate": 1762917418907, "mdate": 1762917418907, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}