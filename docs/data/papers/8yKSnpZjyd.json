{"id": "8yKSnpZjyd", "number": 11846, "cdate": 1758204221006, "mdate": 1763761217189, "content": {"title": "Entropy-Guided k-Guard Sampling for Long-Horizon Autoregressive Video Generation", "abstract": "Autoregressive (AR) architectures have achieved significant successes in LLM, inspiring explorations for video generation.  In LLMs, top-$p$/top-$k$ sampling strategies work exceptionally well: language tokens have high semantic density and low redundancy, so a fixed size of token candidates already strike a balance between semantic accuracy and generation diversity. In contrast, video tokens have low semantic density and high spatio-temporal redundancy. This mismatch makes static top-k/top-p strategies ineffective for video decoders: they either introduce unnecessary randomness for low-uncertainty regions (static backgrounds) or stuck in early errors for high-uncertainty regions (foreground objects). Prediction errors will accumulate as more frames are generated and eventually\nseverely degrade long-horizon quality. \nTo address this, we propose Entropy-Guided $k$-Guard (ENkG) sampling, a simple yet effective strategy that adapts sampling to token-wise dispersion, quantified by the entropy of each token’s predicted distribution. \nENkG uses adaptive token candidate sizes: for low-entropy regions, it employs fewer candidates to suppress redundant noise and preserve structural integrity; for high-entropy regions, it uses more candidates to mitigate error compounding.\nENkG is model-agnostic, training-free, and adds negligible overhead. Experiments demonstrate consistent improvements in perceptual quality and structural stability compared to static top-k/top-p strategies.", "tldr": "We propose ENkG, an entropy-guided sampling policy with a k-guard that mitigates error accumulation and preserves structure in long-horizon autoregressive video generation—plug-and-play at inference, no retraining.", "keywords": ["Autoregressive video generation", "discrete tokens", "VQ-VAE", "entropy", "top-p / nucleus sampling", "top-k", "adaptive decoding", "error accumulation", "uncertainty-aware sampling"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d6c37c45a5adec86ce6d9348decc7606f62a9daf.pdf", "supplementary_material": "/attachment/2149f2c43ada90cc09d71b6cd0b02b25292f32b7.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the critical problem of error accumulation in long-horizon autoregressive (AR) video generation. It presents a highly insightful diagnosis, arguing that the root cause is not just model imperfection but a fundamental mismatch between static sampling strategies (e.g., top-k/top-p) and the intrinsic properties of video data. The authors astutely observe that unlike language, video tokens have low semantic density and high spatio-temporal redundancy, leading to spatially structured uncertainty. Static sampling fails by applying a uniform approach to all regions, introducing noise in low-entropy (predictable) areas like clear edges, while prematurely collapsing possibilities in high-entropy (unpredictable) areas like complex textures, leading to a phenomenon the authors term \"entropy collapse.\"\n\nTo resolve this, the paper proposes Entropy-Guided k-Guard Sampling (ENkG), a simple, elegant, and training-free inference-time strategy. ENkG dynamically adapts the sampling process for each token based on its predictive entropy. It uses a small candidate pool (near-greedy) for low-entropy tokens to preserve structure and a larger pool for high-entropy tokens to enrich texture and mitigate errors. This is complemented by a \"k-guard\" mechanism that enforces a minimum level of exploration, preventing the model from becoming overly deterministic and causing motion freezing.\n\nAs a model-agnostic, plug-and-play solution, ENkG is shown to deliver substantial and consistent improvements in perceptual quality and structural stability across multiple state-of-the-art AR video models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. A Highly Insightful and Principled Diagnosis of AR Failure Modes: The paper's most significant contribution is its profound and novel diagnosis of a key failure mode in AR video generation operating on discrete tokens. It provides a principled explanation rooted in the fundamental mismatch between static sampling strategies and the spatially structured uncertainty of video tokens. The identification of \"entropy collapse\" is a novel and valuable insight that clarifies a previously poorly understood phenomenon.\n2. An Elegant, Model-Agnostic, and Highly Effective Solution: Based on its sharp diagnosis, the paper proposes an exceptionally elegant solution in Entropy-Guided k-Guard Sampling (ENkG). As a training-free, model-agnostic, inference-time strategy, it offers immense practical value for the broad class of models operating on discrete representations. The experimental results, showing substantial and consistent gains across multiple SOTA architectures, provide unequivocal evidence of its effectiveness in this domain.\n3. Significant Broader Impact and Inspirational Value: While the proposed method is formulated for discrete token spaces, the core insights of this work have significant inspirational value that transcends this specific implementation. The observation that predictive uncertainty is spatially structured and that sampling strategies must adapt to this is a powerful, generalizable principle. This finding can serve as a critical starting point for developing analogous uncertainty-aware inference techniques for AR models operating in continuous latent spaces, thereby motivating a new line of research."}, "weaknesses": {"value": "1. Limited Applicability to Continuous-Space Autoregressive Models: The proposed ENkG method is fundamentally designed for models that operate on a discrete vocabulary of video tokens. While this is a significant class of models, a substantial and growing body of work in autoregressive video generation operates in continuous latent spaces. The core mechanism of ENkG—truncating a categorical distribution—does not directly transfer to these continuous domains. The paper should more explicitly acknowledge this significant boundary on the direct applicability of its proposed method, even while its insights remain broadly relevant.\n2. Potential Risks of Relying on Entropy as a Homogeneous Signal: The core mechanism assumes that entropy is a uniform indicator of uncertainty that can be addressed with a single, monotonic strategy (higher entropy requires more exploration). This simplification, while effective, has potential theoretical limitations:\na) It may conflate beneficial intrinsic randomness (e.g., in textures) with harmful model ignorance (e.g., on unfamiliar objects). Applying the same \"increase p\" strategy to both could enrich textures but might destabilize the structure of novel objects.\nb) It may be vulnerable to a \"low-entropy trap,\" where the model becomes pathologically overconfident in an incorrect prediction. While the k-guard mechanism provides a partial safety net, it does not solve the underlying issue that entropy, as a metric, can be misleading when the model's confidence calibration is poor. A more robust system might need to disentangle different sources of uncertainty."}, "questions": {"value": "1. Your method is formulated for discrete-token AR models and shows remarkable success. How do you envision the core principle of \"uncertainty-aware adaptive sampling\" being translated to the growing class of continuous-space AR models? Would it involve, for instance, dynamically adjusting the variance of a sampling distribution, and how might one define a robust uncertainty metric in a continuous latent space that is analogous to token entropy?\n2. The current approach treats entropy as a monolithic signal, yet its sources can be varied (e.g., beneficial texture randomness vs. detrimental model ignorance). Have you considered scenarios where this simplification might falter? For example, in the case of a novel, complex object where the model is \"ignorant\" (high entropy), would encouraging more exploration via a high p value risk structural collapse? This speaks to a fascinating future direction of disentangling different types of predictive uncertainty.\n3. The k-guard mechanism is a clever solution to prevent the model from becoming overly greedy in low-entropy regions. This suggests you have identified a failure mode where the model can become pathologically overconfident in a suboptimal prediction. Could you elaborate on this phenomenon? Does this \"low-entropy trap\" primarily lead to static frames, or does it manifest in other ways? Understanding this failure mode better could provide valuable insights into the general behavior of large-scale autoregressive visual models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "o5i8ncT5Px", "forum": "8yKSnpZjyd", "replyto": "8yKSnpZjyd", "signatures": ["ICLR.cc/2026/Conference/Submission11846/Reviewer_22FV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11846/Reviewer_22FV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761722242224, "cdate": 1761722242224, "tmdate": 1762922863157, "mdate": 1762922863157, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Entropy-Guided k-Guard (ENkG) Sampling,  adapts sampling to token-wise dispersion, quantified by the entropy of each token’s predicted distribution. Experiments demonstrate consistent improvements in perceptual quality and structural stability compared to static top-k/top-p strategies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The theoretical analysis of the method is quite thorough.\n2. The comparison metrics are sufficient, but the comparison methods are somewhat lacking."}, "weaknesses": {"value": "1. The paper mentions \"Long-Horizon Autoregressive Video Generation\" but only verifies it with 75-frame data, failing to clarify the effect of ENkG on suppressing entropy collapse for longer sequences (e.g., 100+ frames). It is recommended to: conduct experiments on long sequences of 100-200 frames; supplement entropy change curves under different frame counts (such as averaging entropy statistics every 10 frames); and quantitatively compare the differences in entropy collapse rates between ENkG and static sampling, to more intuitively demonstrate the advantage in \"Long-Horizon\".\n2. Existing baselines only include greedy, top-k, top-p, and PK methods, and do not cover mainstream AR sampling methods in recent years (such as reinforcement learning-based sampling and adaptive temperature-scheduled sampling). It is recommended to supplement with experimental results related to methods from recent years.\n3. The basis for selecting some parameters is unclear, like K_g =3/5/10; whether there will be differences in different scenarios warrants further analysis."}, "questions": {"value": "The paper is generally clearly presented; for specific issues, please refer to the points listed in the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yPY5yPvi43", "forum": "8yKSnpZjyd", "replyto": "8yKSnpZjyd", "signatures": ["ICLR.cc/2026/Conference/Submission11846/Reviewer_Crnm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11846/Reviewer_Crnm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761745721660, "cdate": 1761745721660, "tmdate": 1762922862681, "mdate": 1762922862681, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies a key failure point in autoregressive video generation: static sampling strategies like top-k/top-p, which work well for language, are ill-suited for the low-density, high-redundancy nature of video tokens, leading to error accumulation. To address this, the authors propose Entropy-Guided k-Guard (ENKG) sampling, a training-free, inference-time method. ENKG dynamically adjusts the nucleus sampling probability for each token based on its predictive entropy—using a smaller, more conservative candidate pool for low-entropy (high-confidence) regions and a larger, more diverse pool for high-entropy (uncertain) regions. This is combined with a \"k-guard\" mechanism that ensures a minimal number of top candidates are always included to prevent the model from becoming overly greedy and causing artifacts like frozen frames."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper's primary strength is its clear and insightful diagnosis of the problem, effectively distinguishing the statistical properties of video versus language tokens and identifying the \"entropy collapse\" phenomenon. The proposed ENKG method is simple and highly practical, as it can be applied as a plug-and-play module to existing models without any retraining. The experimental results are convincing, showing consistent and significant improvements across multiple state-of-the-art video models and datasets, well-supported by thorough ablation studies that validate each component of the proposed method"}, "weaknesses": {"value": "The main weakness lies in the potentially limited novelty of the core concepts. While their application to video generation is new and insightful, entropy-guided adaptation and hybrid sampling methods have been explored in other domains. Additionally, the evaluation is heavily focused on autonomous driving scenarios. While effective here, it remains an open question how well this strategy would generalize to more open-domain or creative video generation tasks, which may exhibit different uncertainty structures and benefit from different sampling trade-offs."}, "questions": {"value": "While the related work section mentions some uses of entropy in LLMs, such as for model switching or retrieval, it doesn't discuss entropy-guided sampling for text generation itself. Have similar adaptive, entropy-guided sampling strategies already been investigated in the LLM literature? For example, there is a very similar paper[1], which explores most of the concepts in the proposed method, but in LLM settings.\n\n[1] EDT: Improving Large Language Models’ Generation by Entropy-based Dynamic Temperature Sampling"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wKrdb7p7kc", "forum": "8yKSnpZjyd", "replyto": "8yKSnpZjyd", "signatures": ["ICLR.cc/2026/Conference/Submission11846/Reviewer_esDH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11846/Reviewer_esDH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904968089, "cdate": 1761904968089, "tmdate": 1762922862312, "mdate": 1762922862312, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of error accumulation in long-horizon autoregressive (AR) video generation. The authors identify that standard sampling strategies like top-k/top-p fail in the video domain due to the low semantic density and high spatio-temporal redundancy of video tokens. This mismatch leads to either excessive noise in stable regions or error propagation in complex regions. To solve this, the paper proposes Entropy-Guided k-Guard (ENkG) sampling, a training-free, model-agnostic inference strategy. ENkG dynamically adjusts the size of the candidate sampling pool for each token based on its predictive entropy: using a smaller, more conservative set for low-entropy (high-confidence) tokens and a larger, more diverse set for high-entropy (low-confidence) tokens. A \"k-guard\" mechanism is included to ensure a minimal level of diversity, preventing the model from becoming overly greedy. The authors demonstrate through experiments on several AR video models that ENkG significantly improves perceptual quality, structural stability, and temporal coherence compared to baseline sampling methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written. The proposed method is well-illustrated and easy to follow.\n\n2. **Clear motivation and insightful problem analysis:** The paper provides a very clear and compelling motivation for the work. The analysis of the fundamental differences between language and video tokens, the connection between token entropy and the semantic structure of the image, and the identification of the \"entropy collapse\" phenomenon are insightful and effectively frame the problem.\n\n3. **The solution is simple, practical, and generalizable:** The proposed ENkG method is simple and practical. As a training-free, model-agnostic sampling algorithm, it can be easily integrated into existing AR models with negligible computational overhead, making it a valuable and widely applicable contribution.\n\n4. **Strong and comprehensive empirical validation:** The authors conduct a thorough empirical study, integrating ENkG with three different AR video generation models and evaluating on two datasets. The results show consistent and significant improvements across both quantitative metrics and qualitative examples. The qualitative results in Figures 4, 5, 6, and 7 are particularly effective at illustrating how ENkG mitigates common failure modes like texture degradation and frame-freezing."}, "weaknesses": {"value": "1. **The similar entropy-based method for AR sampling strategies has been explored by previous work** [1], which limits the novelty of this work.\n\n[1] Towards Better & Faster Autoregressive Image Generation: From the Perspective of Entropy. \n\n2. **Lack of hyperparameter sensitivity analysis:** The method introduces a set of new hyperparameters, including `plow`, `phigh`, `Hlow`, `Hhigh`, and `kg`. The paper reports the values used but does not provide any analysis of the method's sensitivity to these choices. A study on how performance varies with these parameters would strengthen the paper's claims of robustness and provide practical guidance for future users."}, "questions": {"value": "1. The experiments are focused on autonomous driving scenarios. How do the authors expect the method to perform on more general and diverse video content, such as complex human actions or dynamic natural scenes, which may have different entropy characteristics?\n\n2. The baseline comparisons use a fixed `k=30` for top-k and `p=0.8` for top-p. How does the performance of these baseline methods change with different values of `k` and `p`? It is important to demonstrate that ENkG outperforms not just a single, potentially arbitrary configuration, but well-tuned baselines.\n\n3. The paper focuses exclusively on fully autoregressive models. Could the proposed ENkG sampling strategy be adapted for semi-autoregressive or block-autoregressive video generation models (e.g., [2])? How would the concept of token-level entropy guidance apply when generating blocks of tokens simultaneously?\n\n[2] Next Block Prediction: Video Generation via Semi-Autoregressive Modeling"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PfUIqmuWQR", "forum": "8yKSnpZjyd", "replyto": "8yKSnpZjyd", "signatures": ["ICLR.cc/2026/Conference/Submission11846/Reviewer_hZ2p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11846/Reviewer_hZ2p"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762016698330, "cdate": 1762016698330, "tmdate": 1762922861816, "mdate": 1762922861816, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}