{"id": "iajaxDd9BO", "number": 7229, "cdate": 1758012312410, "mdate": 1759897864879, "content": {"title": "ReSplat: Learning Recurrent Gaussian Splats", "abstract": "While feed-forward Gaussian splatting models offer computational efficiency and can generalize to sparse input settings, their performance is fundamentally constrained by relying on a single forward pass for inference. We propose ReSplat, a feed-forward recurrent Gaussian splatting model that iteratively refines 3D Gaussians without explicitly computing gradients. Our key insight is that the Gaussian splatting rendering error serves as a rich feedback signal, guiding the recurrent network to learn effective Gaussian updates. This feedback signal naturally adapts to unseen data distributions at test time, enabling robust generalization.\nTo initialize the recurrent process, we introduce a compact reconstruction model that operates in a $16 \\times$ subsampled space, producing $16 \\times$ fewer Gaussians than previous per-pixel Gaussian models. \nThis substantially reduces computational overhead and allows for efficient Gaussian updates.\nExtensive experiments across varying of input views (2, 8, 16), resolutions ($256 \\times 256$ to $540 \\times 960$), and datasets (DL3DV and RealEstate10K) demonstrate that our method achieves state-of-the-art performance while significantly reducing the number of Gaussians and improving the rendering speed.\nOur code and models will be public.", "tldr": "A feed-forward recurrent Gaussian splatting model for iteratively refining 3D Gaussians", "keywords": ["Gaussian Splatting", "Feed-Forward", "Learning to Optimize", "View Synthesis"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ac042acfdabc794a94c664dd24f4ce6f592c9bd9.pdf", "supplementary_material": "/attachment/a011f6b818dd14607c3a3f5e411ec3107c1075fd.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a feed-forward reconstruction paradigm based on 3DGS, whose core contributions include a single-step feed-forward Gaussian reconstruction model with compression capabilities to initialize the recurrent process, as well as a weight-sharing recurrent network that iteratively improves the reconstruction. The authors claim that their method achieves better performance compared to existing works."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This work attempts to address the scalability issues caused by per-pixel Gaussian to effectively reduce the number of Gaussians, which is an important problem for feed-forward reconstruction.\n\n2. The proposed initialization model is effective, achieving both performance improvement and compression of the number of Gaussians.\n\n3. The paper provides extensive quantitative experiments that validate the effectiveness of the method."}, "weaknesses": {"value": "1. The qualitative experiments presented in the main text and appendix are limited, especially the qualitative comparison experiments under different iteration numbers, such as Figure 1. The limited cases are insufficient to demonstrate the effectiveness of this iterative refinement. Furthermore, qualitative ablation experiments for the different proposed components are missing, making it difficult to intuitively analyze what role these modules play.\n\n2. The core contribution of the paper lies in proposing a compressible initial feed-forward reconstruction and a weight-sharing recurrent network, where the latter is similar to SplatFormer and LIFe-GOM. Although the authors explain that the application scenarios differ, this makes me question whether the contribution of this work is limited. Furthermore, the experimental section lacks comparisons with these similar methods (e.g., Initialization + SplatFormer), which affects the evaluation of the proposed method's effectiveness.\n\n3. The working mechanism underlying the proposed iterative refinement module remains unclear. While its overall framework resembles the initialization stage, it achieves substantial performance improvements at inference time without introducing any additional auxiliary information or optimization. I suspect that this improvement may stem from stacking Attention blocks, similar to scaling laws. If this is the case, the contribution would be trivial.\n\n4. Although the authors discuss cross-dataset generalization in Figure 4, it lacks comparative experiments on cross-dataset scenarios, such as ACID, which has been mentioned in many existing works.\n\n5. Table 1 and Table 2 discuss comparisons with some optimization-based methods, but the methods mentioned are based on dense views, such as 3DGS and Mip-Splatting. Since the experimental setting is based on sparse views (8 or 16 views), such an experimental setup is unfair. It is recommended to introduce comparisons with some optimization-based sparse-view reconstruction works.\n\n6. Compared to existing methods like MVSplat and DepthSplat, ReSplat's efficiency is negatively affected, which may stem from the introduction of kNN attention."}, "questions": {"value": "1. In the recurrent reconstruction model, I observe that the impact of global attention is limited. Is this module necessary? Does its structure need to remain consistent with the initialization model?\n\n2. Compared to existing algorithms, what is ReSplat's inference computational cost?\n\n3. Why does ReSplat compress the number of Gaussians by 16×, yet only leads to 4× faster rendering speed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "odyfm09aRe", "forum": "iajaxDd9BO", "replyto": "iajaxDd9BO", "signatures": ["ICLR.cc/2026/Conference/Submission7229/Reviewer_ZHGA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7229/Reviewer_ZHGA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7229/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761367898739, "cdate": 1761367898739, "tmdate": 1762919371612, "mdate": 1762919371612, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method that recurrently refines Gaussians generated by feed-forward models using rendering error as a feedback signal. The initial Gaussians are produced in a 16× subsampled space to reduce computational cost during refinement. The proposed approach improves reconstruction quality on both in-domain and cross-domain datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This paper is well written, with clear motivation and a well-reasoned design.\n- The experiments are comprehensive, demonstrating not only the effectiveness of the proposed method but also its generalizability to unseen data and unseen resolution."}, "weaknesses": {"value": "- Although the experimental results show that reconstruction quality improves with more refinement iterations of the initial Gaussians, a similar effect could also be achieved with the original optimization-based refinement. Traditional optimization indeed converges slowly due to the sparse SfM initialization, but recent works such as Long-LRM have shown that initialization using dense Gaussian outputs from a feed-forward model can significantly reduce optimization steps. A comparison with such a scenario would make the proposed method’s advantage more convincing.\n- The two main contributions of the paper are the Gaussian initialization strategy and the recurrent network. However, the performance gain seems largely attributed to the point-level architecture and the use of rendering error for refinement, rather than to the recurrent nature itself. As shown in Table 1, the initial model improves over DepthSplat by more than 2 dB in PSNR, primarily due to these architectural enhancements, which is further supported by the ablation in Table 5. While the recurrent network provides additional gains (Tables 1, 2, and 5), the improvements saturate after two or three iterations, as noted in the limitations section. This raises the question of whether the recurrent design is essential. It would strengthen the paper to provide an explanation or intuition for why the improvement plateaus after a few iterations.\n- Conceptually, the proposed method appears to serve as an efficient refiner of Gaussians initialized by a feed-forward model—an alternative to lengthy gradient-based optimization. In this regard, it would be valuable if the method could be applied directly to existing feed-forward models without retraining. While I believe the proposed refining network can be integrated into the original-resolution feed-forward models, this could potentially increase memory usage and computational cost, which may affect the method’s praticaility."}, "questions": {"value": "- The recurrent network takes a hidden state as input. From my understanding, the Gaussian parameters themselves evolve over iterations and could naturally serve as the hidden state, since they are updated and reused. Could the authors clarify why a separate hidden state is necessary and how it is initialized?\n- The paper reports strong generalization to unseen resolutions. I understand that the recurrent naturally allow adaptation to unseen data distributions (e.g., RealEstate10K) by iteratively refining Gaussians using rendering error, but it is unclear how this mechanism supports resolution generalization. Could the authors elaborate on this aspect?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wI41Lua4VI", "forum": "iajaxDd9BO", "replyto": "iajaxDd9BO", "signatures": ["ICLR.cc/2026/Conference/Submission7229/Reviewer_45AN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7229/Reviewer_45AN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7229/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921080497, "cdate": 1761921080497, "tmdate": 1762919371286, "mdate": 1762919371286, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose ReSplat, a feed-forward recurrent Gaussian splatting model that iteratively refines 3D Gaussians without explicitly computing gradients. The authors find that rendering error in a *feature* space is an effective signal for learning Gaussian updates at every refinement iteration. The authors argue that the learned ReSplat model generalizes across different datasets and image resolutions via evaluations and ablations on the DL3DV and RealEstate10K datasets. To further speed up ReSplat, the authors find a quality-speed sweet-spot where, to initialize the recurrent process, the images are spatially downsampled by 16x, resulting in faster initialization and fewer Gaussians for the subsequent recurrent refinement step. This improves speed without a significant impact on image quality."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Predicting 3D Gaussians without explicit optimization offers a drastic speedup compared to optimization-based methods like 3D GS, Mip-Splatting, and Scaffold-GS. \n\nQuantitative results show superior speed and image quality on both same- and cross-dataset evaluation on DL3DV and RealEstate10K when compared to concurrent methods.\n\nPublic release is a big plus for an application-focused paper\n> (L308) We will release our code, pre-trained models, training and evaluation scripts to ease reproducibility."}, "weaknesses": {"value": "I believe only training and testing on two datasets, namely DL3DV and RealEstate10K, does not completely validate the method's generalizability across datasets.\n\nAdditionally, since this is a neural-network-based approach, there remains important questions about generalization that have yet to be answered. What is the break-even point in terms of the number of training images at which ReSplat becomes better than 3D GS? If given more training views per scene, such as 32 or 64, would ReSplat still generalize and have better performance than 3D GS? Can global attention exploit information from many views even when it was only trained on a few? I would be happy to raise my rating if provided with additional ablations."}, "questions": {"value": "It is possible to use feature spaces from newer, more modern vision models? E.g. DINOv2? I don't see a particular reason to stick with ResNets. \n\nDuring training, what is \"T\", the number of times for which the RNN is rolled out?\n\nCan you include GPU profiling for different parts of the model inference, such as a breakdown between the kNN attention and the global attention blocks? It would be insightful to see which parts uses the most wall-clock time and FLOPs, so perhaps a smarter trade-off between quality and compute can be found."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vWdbxRfJ1C", "forum": "iajaxDd9BO", "replyto": "iajaxDd9BO", "signatures": ["ICLR.cc/2026/Conference/Submission7229/Reviewer_N2FZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7229/Reviewer_N2FZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7229/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979955118, "cdate": 1761979955118, "tmdate": 1762919370416, "mdate": 1762919370416, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}