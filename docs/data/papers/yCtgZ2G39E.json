{"id": "yCtgZ2G39E", "number": 2107, "cdate": 1756990116367, "mdate": 1759898169254, "content": {"title": "Vertically Unified Agents for Graph Retrieval-Augmented Complex Reasoning", "abstract": "Graph retrieval-augmented generation (GraphRAG) has effectively enhanced large language models in complex reasoning by organizing fragmented knowledge into explicitly structured graphs. Prior efforts have been made to improve either graph construction or graph retrieval in isolation, yielding suboptimal performance, especially when domain shifts occur. In this paper, we propose a vertically unified agentic paradigm, $\\texttt{UniGraphRAG}$, to jointly connect the entire framework as an intricate integration. Specifically, $(i)$ a seed graph schema is introduced to bound the automatic extraction agent with targeted entity types, relations and attribute types, also continuously expanded for scalability over unseen domains; $(ii)$ To obtain higher-level knowledge upon the schema, we develop novel dually-perceived community detection, fusing structural topology with subgraph semantics for comprehensive knowledge organization. This naturally yields a hierarchical knowledge tree that supports both top-down filtering and bottom-up reasoning with community summaries; $(iii)$ An agentic retriever is designed to interpret the same graph schema to transform complex queries into tractable and parallel sub-queries. It iteratively performs reflection for more advanced reasoning; $(iv)$ To alleviate the knowledge leaking problem in pre-trained LLM, we propose a tailored anonymous dataset and a novel 'Anonymity Reversion' task that deeply measures the real performance of the GraphRAG frameworks. Extensive experiments across six challenging benchmarks demonstrate the robustness of $\\texttt{UniGraphRAG}$, remarkably moving the Pareto frontier of performance and efficiency with up to 33.6% cost saving and 16.62% higher accuracy over state-of-the-art baselines. The results indicate our adaptability, allowing seamless domain transfer with minimal intervention on the schema.", "tldr": "", "keywords": ["GraphRAG", "Schema", "Complex QA"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bfd1ded1e29b972f2566b912395ac64c48ab9302.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes UniGraphRAG, a vertically unified and agentic framework for graph-based retrieval-augmented generation (GraphRAG). The key idea is to connect the entire GraphRAG pipeline—graph construction, organization, and retrieval—under a single unified paradigm. Specifically, the authors first define a seed graph schema that constrains the automatic knowledge extraction process with specified entity and relation types, which can later be expanded by the LLM for scalability. Then, they introduce a dually-perceived community detection method that combines topological and semantic information to build a hierarchical knowledge tree supporting both top-down filtering and bottom-up reasoning. Finally, an agentic retriever interprets the same schema to decompose complex queries into sub-queries and iteratively reflect on retrieval results for more advanced reasoning. Experiments on six benchmarks demonstrate strong performance and efficiency gains, reportedly achieving up to 33.6% token savings and 16.6% higher accuracy over state-of-the-art baselines."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "Strengths\n\n**1.** Unified perspective: The paper takes one step toward connecting indexing, retrieval, and generation of Graph-based RAG.\n\n**2.** The proposed dually-perceived community detection that fuses structural and semantic signals is new in this context.\n\n**3.** The reported improvements in both accuracy and token efficiency across six benchmarks suggest the proposed framework is effective in practice."}, "weaknesses": {"value": "Weaknesses\n\n**1.** A major limitation is that the approach requires a manually designed seed schema for each knowledge domain. Constructing such schema demands expert knowledge and human involvement, which reduces generalizability and scalability, especially for open-domain or evolving corpora.\n\n**2.** The method relies on the LLM to iteratively expand the schema beyond its initial version. This process is computationally expensive and may require substantial hyperparameter tuning (e.g., expansion depth, stopping criteria), making it hard to reproduce and tune. Notably, the authors did not provide ablation or explanation on the confidence $\\mu=0.9$, why not using 0.95 or 0.99 ? Is this value scalable to any open world datasets?\n\n**3.** The framework introduces multiple tunable components—such as seed schema on different datasets, schema expansion confidence, knowledge tree depth, community detection intial cluster number, and community merging threshold—resulting in a large hyperparameter search space that may undermine its practicality and reproducibility.\n\n**4.** The agentic retriever and reasoning process is insufficiently detailed. The paper does not specify how many iterations of reflection are performed, how sub-queries are generated, how many sub-queires will be used, or how the agent’s reasoning quality is ensured. Without these details, the reproducibility and interpretability of the method are questionable.\n\n**5.** Limited ablation and analysis: While performance results are promising, the paper lacks **detailed** ablation studies isolating the contributions of each component and hyper-parameter sensitivity.\n\n**6.** This paper seems to violated the **Anonymous Protocol**. The **youtu-GraphRAG** in the experimental figures tells where the authors are from.\n\n**7. ** Typos: The symbol $S^{(t)}$ mentioned in the text near equation (3) does not appear in the equation."}, "questions": {"value": "Please refer to the weakness part"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YEJ7KJfbmY", "forum": "yCtgZ2G39E", "replyto": "yCtgZ2G39E", "signatures": ["ICLR.cc/2026/Conference/Submission2107/Reviewer_rQJp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2107/Reviewer_rQJp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2107/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761551841341, "cdate": 1761551841341, "tmdate": 1762916032582, "mdate": 1762916032582, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes **UniGraphRAG**, a vertically unified agentic paradigm for Graph Retrieval-Augmented Generation (GraphRAG) that jointly optimizes graph construction and retrieval through a shared graph schema. The framework introduces: (i) a schema-bounded extraction agent with automatic expansion capabilities; (ii) a novel dual-perception community detection algorithm that fuses structural topology with semantic similarity to build a four-level knowledge tree; (iii) an agentic retriever that decomposes complex queries into schema-aligned sub-queries with iterative reflection; and (iv) two anonymous datasets (AnonyRAG-CHS/ENG) with an \"Anonymity Reversion\" task to mitigate knowledge leakage. Experiments across six benchmarks demonstrate improvements of up to 16.62% in accuracy with 33.60% reduction in token costs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**S1.** The paper addresses a significant practical limitation in GraphRAG systems: the disconnection between graph construction and retrieval optimization. The vertically unified paradigm is a valuable engineering contribution that demonstrates measurable improvements across diverse benchmarks.\n\n**S2.** The schema-guided approach provides a principled framework for aligning extraction, organization, and retrieval. The automatic schema expansion mechanism (Equation 3) enables adaptability to new domains while maintaining quality control through confidence thresholds.\n\n**S3.** The dual-perception community detection algorithm (Section 3.2) combines structural connectivity (Jaccard similarity on relations) with semantic coherence (cosine similarity on embeddings), addressing limitations of purely topology-based or purely semantic clustering methods. The resulting four-level knowledge tree naturally supports multi-granularity reasoning.\n\n**S4.** The anonymous datasets (AnonyRAG-CHS/ENG) and Anonymity Reversion task represent a valuable contribution to fair GraphRAG evaluation. By breaking LLM memory shortcuts through entity anonymization while preserving discourse coherence, these datasets more accurately isolate retrieval effectiveness from parametric knowledge.\n\n**S5.** Comprehensive experimental evaluation across six benchmarks with two strong LLM backbones (DeepSeek-V3, Qwen3-32B). The consistent superiority in both open and reject modes, along with efficiency gains (up to 33.60% token reduction), demonstrates practical value. The dual-mode evaluation protocol properly separates retrieval quality from generation capability."}, "weaknesses": {"value": "W1. Except for the community detection module, most components largely adapt existing techniques: (i) the schema-guided extraction resembles ontology-based information extraction methods; (ii) the iterative agentic retrieval with reflection closely mirrors the Self-RAG architecture. The main contribution lies in orchestration rather than fundamental innovation. Furthermore, the paper emphasizes issues in unified graph construction and graph retrieval phases, but prior works have already designed retrieval schemes tailored to their our graph-structured databases. The claimed contribution of the schema-guided method is overstated—it functions more like a prompt-level enhancement that improves robustness and reduces noise rather than a genuine methodological innovation.\n\nW2. The authors claim that the proposed method consistently achieves optimal performance with minimal token consumption, yet fail to compare against cost-efficient agentic baselines such as RAPTOR and E2GraphRAG. \n\nW3. While UniGraphRAG is positioned as an agentic approach, most baselines—except for the iterative HippoRAG1/2—are single-turn retrieval models. The paper does not compare against existing agentic RAG methods such as Self-RAG or ReAct-RAG. Moreover, when evaluating “UniGraphRAG w/o Agent,” the model still benefits from a Query Decomposer, while other baselines do not. If the same query decomposition were applied before retrieval for all baselines, their performance—particularly on multi-hop reasoning tasks—might also improve. This experimental bias undermines the reliability of conclusions regarding the superiority of UniGraphRAG’s knowledge tree construction.\n\nW4. Although several datasets may have been seen during LLM pretraining, the zero-shot performance of LLMs remains relatively weak. Using the same base LLM while comparing the accuracy gap between Naive RAG and zero-shot LLM already provides a reasonable measure of retrieval effectiveness. \n\nW5. The provided code URL is inaccessible, and Figures 6 and 7 incorrectly label “UniGraphRAG” as “Youtu-GraphRAG,”."}, "questions": {"value": "Q1. The authors follow the design of HippoRAG1/2, where HippoRAG2 adopts Top-k = 5. What is the rationale for choosing Top-k = 10 and 20 in your experiments? \n\nQ2. As discussed in W3, please supplement comparisons with established agentic RAG baselines. Can you demonstrate that the unified paradigm outperforms applying existing agentic methods directly to GraphRAG? Moreover, can you provide a fair evaluation proving the effectiveness and reliability of UniGraphRAG’s knowledge tree construction under equivalent retrieval setups(without query decomposer or baseline with query decomposer)?\n\nQ3. Can you provide a correlation analysis between the degree of anonymization and the performance of zero-shot LLMs versus RAG models? For example, compare the performance difference of zero-shot LLMs on raw queries versus anonymized queries to quantify how anonymization impacts retrieval dependence.\n\nQ4. How are the hyperparameters λ in Equation 5 and ε in Equation 7 determined or tuned? Please clarify whether they are empirically selected, fixed across datasets, or adapted dynamically.\n\nQ5. How is the initial schema for each domain designed? Is it a general, domain-agnostic schema or a manually curated one per dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "z6CyRDonbm", "forum": "yCtgZ2G39E", "replyto": "yCtgZ2G39E", "signatures": ["ICLR.cc/2026/Conference/Submission2107/Reviewer_vYRA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2107/Reviewer_vYRA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2107/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761816717891, "cdate": 1761816717891, "tmdate": 1762916032408, "mdate": 1762916032408, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to address the suboptimal performance in existing Graph Retrieval-Augmented Generation (GraphRAG) frameworks, which stems from the disjointed and separately optimized \"graph construction\" and \"graph retrieval\" stages. The authors propose **UniGraphRAG**, a \"vertically unified agentic paradigm.\" The core of this framework is the introduction of a shared \"Graph Schema,\" which simultaneously guides (i) a \"construction agent\" to perform controlled, structured knowledge extraction, and (ii) a \"retrieval agent\" to decompose complex queries into schema-aligned sub-queries. Furthermore, the paper proposes a novel \"dually-perceived community detection\" algorithm (fusing topological structure and subgraph semantics) to build a four-level \"knowledge tree\" for hierarchical indexing. The retrieval agent leverages this knowledge tree for iterative reasoning and reflection. To address the \"knowledge leakage\" problem in LLM evaluation, the paper also introduces a new anonymous dataset (AnonyRAG). Experiments demonstrate that UniGraphRAG significantly improves accuracy (up to 16.62%) while substantially reducing token costs during the construction phase (up to 33.60%)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Novel \"Vertically Unified\" Framework:** The paper's central thesis—using a shared \"Graph Schema\" to simultaneously constrain and align graph construction and retrieval—is highly novel and pertinent. This directly addresses the critical pain point in existing GraphRAG methods, where the two stages suffer from misaligned objectives and informational mismatch. It provides a logically rigorous new paradigm for building more robust GraphRAG systems.\n2. **Advanced Hierarchical Indexing Mechanism:** The paper makes a significant contribution to graph organization. The proposed \"dually-perceived community detection\" (fusing topology and semantics) and the resultant four-level knowledge tree (Community, Keywords, Triples, Attributes) provide the retrieval agent with a powerful, multi-granularity index structure. This enables the agent to efficiently perform both \"top-down\" filtering and \"bottom-up\" fine-grained reasoning.\n3. **Rigorous and Innovative Evaluation Methodology:** The paper excels in its evaluation (Section 4). To address the pervasive \"knowledge leakage\" problem in RAG evaluation (where the LLM answers from memory rather than retrieval), the authors specifically constructed the `AnonyRAG` anonymous dataset and an \"Anonymity Reversion\" task. This approach, combined with the dual \"Reject Mode\" vs. \"Open Mode\" evaluation, substantially increases the reliability of the experimental conclusions and represents an important methodological contribution to RAG evaluation."}, "weaknesses": {"value": "**1. Strong and Brittle Dependency on Graph Schema:** The entire UniGraphRAG framework is strongly coupled to a shared \"Graph Schema,\" which is both its core strength and its most significant weakness. The framework's effectiveness is critically dependent on the initial quality of the \"seed schema,\" which requires substantial manual expert knowledge for cold-starting, posing a severe practical bottleneck. The paper's claims of \"automatic expansion\" and \"minimal-intervention transfer\" fail to quantify the necessary human-in-the-loop iteration and auditing costs. Furthermore, this \"vertically unified\" design can lead to error amplification: if the seed schema omits critical entity/relation types, the extraction agent will systematically \"miss\" facts, and the retrieval agent, following the same flawed schema, will be trapped in \"valid but ineffective\" sub-query loops. Finally, the schema-controlled extraction (Sec 3.1), while reducing noise, does so at the cost of recall, systematically omitting facts that fall outside the predefined schema.\n\n**2. Confused Contribution Attribution and Missing Key Ablations:** UniGraphRAG is a **strongly coupled** system composed of multiple innovations (Schema, novel community detection, agentic retrieval, reflection). The current ablation study (Table 3) is too coarse (removing only three large modules), making it impossible to attribute the performance gains to their true sources. For instance, the paper's key technical innovation—\"dually-perceived community detection\"—is not directly compared against standard graph clustering algorithms (e.g., Louvain, GMM), leaving its algorithmic value unproven. It is also impossible to discern whether the gains originate primarily from the \"Schema constraint,\" the \"knowledge tree indexing,\" or the \"agentic reflection\" (e.g., how much improvement does iterative reflection provide over single-shot decomposition?). This attribution confusion makes it difficult to pinpoint the marginal benefit of each component.\n\n**3. Heuristic-based Design and Robustness Concerns:** Many core components of the framework rely on brittle heuristic rules and hard-coded thresholds, casting doubt on its robustness. In the **indexing stage**, the \"dually-perceived community detection\" algorithm is itself a chain of heuristics: the k-value selection for K-means, the merging threshold $\\epsilon$, the use of Jaccard similarity for structural comparison (which can be fragile in sparse text graphs), etc. In the **retrieval stage**, the agent is constrained by hard thresholds, such as the maximum DFS depth ($d=5$) and a pre-defined sub-query limit, which may create a performance ceiling on tasks requiring longer reasoning chains. Furthermore, the framework suffers from a **toolchain risk** by using a small, frozen LM (e.g., `all-MiniLM-L6-v2`) to encode triple semantics, whose expressive power may be insufficient for complex domains, leading to poor quality in downstream clustering and matching."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UwSuvK6Aqq", "forum": "yCtgZ2G39E", "replyto": "yCtgZ2G39E", "signatures": ["ICLR.cc/2026/Conference/Submission2107/Reviewer_oGW9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2107/Reviewer_oGW9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2107/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761912474120, "cdate": 1761912474120, "tmdate": 1762916032231, "mdate": 1762916032231, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the problem of RAG on graphs. Specifically, it concerns the problem when a set of documents are converted into a KG prior to performing RAG. Previous methods typically operate in two stages: first they construct the KG and second they can perform RAG on it. The authors argue that the current construction methods are suboptimal for the task of RAG, as RAG may require a different construction process not captured by more traditional KG construction methods. To this point, the authors propose UniGraphRAG, which attempts to unify the construction and retrieval components of GraphRAG. To do this, the authors introduce a graph construction process that is guided by a specific \"seed schema\", allowing for a more targeted final graph. They further use an agent to expand on the graph, by choosing relevant schema elements that are sufficiently similar. They then summarize the knowledge into several communities in a tree structure. They consider 4 types of summaries: communties (i.e., structural), keywords, triples, and attributes (in that order from top to bottom). The communities themselves are created via structural and semantic similarity measures. Retrieval is then done on the final graph, where they further use reflection to refine results. The authors include results across a variety of benchmark datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. I like the motivation, they make a strong point that the construction and retrieval process should ideally be coupled. Because in reality, it's possible that current construction methods may actually harm retrieval.\n\n2. I like their idea for forming communities based on both structural (i.e., where in the graph) and semantic similarity. It's a subtle but good observation, as the structure is really just one piece of information that describes each node. For example, it's possible that two nodes share a high semantic similarity, but due to chance, are not near each other in the documents. As such, they don't appear in any triplets and may have low structural similarity. So this is a welcome idea. \n\n\n3. The overall results are quite good. They also include results on a variety of benchmarks which is good to see."}, "weaknesses": {"value": "1. It's unclear how the seed shemas were created. The authors only mention that they were made using queries from 2Wiki and MuSiQue (line 863). How was this done? Why is this a good strategy? My main concern is that there is no guidance for how to construct these seed schemas, in terms of their content, size, and other parameters. Furthermore, I imagine that the specific datasets may also play a big role. As such, much more information needs to be given here.\n\n2. A separate, but bigger, concern regarding the seed schemas is that they greatly constrain the resulting graph. This is because that schema guides how the graph is created. I know that the authors introduce an agent to expand on this knowledge, however from my understanding, it should still only really consider related information. However, I'd argue that this is suboptimal in real-world applications for two reasons: **(1)** It's unpredictable what kind of query a user may ask. As such, the constructed graph may have been optimized for queries that some user doesn't ask. In essence, the problem is capturing the long tail of user queries, which I'm unsure this method can handle. **(2)** For multi-hop questions, it is often necessary to take \"detours\" through pieces of information that may not seem relevant. However, by restricting the content in the graph, we are effectively closing off these paths, making it harder to solve these queries. This goes back to my last point, in that while this may be okay for many queries, it could very well hurt the long tail of user queries that are more complex or are on the margins of the seed schema.\n\n3. I don't see why having a more efficient graph construction process is very important, as this is a simply a pre-processing step and only needs to be done once. As such, the benefit is marginal at best.\n\n4. It's unclear to me how the retrieval and construction process are actually \"unified\". At the end of the day, they are still separate processes. Maybe the proposed construction process is better for retrieval, but it nonetheless is it's own thing. What I mean, is for them to really be unified, the construction process would have to be conditional on the retrieval which it isn't (and would be prohibitvely expensive). This is a minor weakness, but I think it would be better for the authors to be more process in their language."}, "questions": {"value": "1. I'd appreciate your perspective on my concerns in weakness 2, regarding the limitations of constructing the graph via a seed schema. In particular, I'm concerned that it may omit some information that is important for a subset of queries. [**Note**: This is my main concern and I'd be happy to raise my score depending on the answer] \n\n2.  Can you give more details about the seed schemas used (see weakness 1)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "C8gScRUgWC", "forum": "yCtgZ2G39E", "replyto": "yCtgZ2G39E", "signatures": ["ICLR.cc/2026/Conference/Submission2107/Reviewer_128g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2107/Reviewer_128g"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2107/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762067712062, "cdate": 1762067712062, "tmdate": 1762916031998, "mdate": 1762916031998, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}