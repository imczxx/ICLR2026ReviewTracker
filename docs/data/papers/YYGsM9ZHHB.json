{"id": "YYGsM9ZHHB", "number": 10450, "cdate": 1758171941525, "mdate": 1759897650182, "content": {"title": "ChainGeo: Enabling Effective Geometric Reasoning in Small VLMs through Interleaved Visual-Text Chains", "abstract": "Solving geometric problems requires linking visual perception with symbolic reasoning. However, small Vision-Language Models (VLMs) often fail to keep this connection. We introduce ChainGeo, a novel framework that enables small VLMs to perform complex geometric reasoning through interleaved visual-text chains. Our approach represents geometric elements as specialized tokens (e.g., [Point A], [Line AB]) that maintain explicit grounding in diagram regions, and act as bridges between visual features and symbolic reasoning. We further propose step-level consistency distillation to transfer complete reasoning processes from large teacher models, enforcing visual-textual coherence at each step. Experiments on GeoQA+ (72.1%), Geometry3K (64.7%), and We-Math (68.2%) show that our 2.7B model achieves performance comparable to GPT-4V while providing interpretable, grounded reasoning chains. In human evaluations, our model grounded visual references more accurately (75.3%) and reduced hallucinations by 36.6% compared with text-only baselines.", "tldr": "", "keywords": ["VLM", "Interleaved Reasoning", "Small-Scale Models", "Visual grounding"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d6d15667d154026f683440e6af0be5c146cff47d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper propose to solve geometric problems through symbolic reasoning in smale VLM, thus build ChainGeo framework that enables complex geometric reasoning. The central idea is the specialized geometric tokens to represent symbolic elements, and consistency distillation from large VLM. Extensive experiments were conducted on three datasets with improved performance."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The technical contributions are very limited and the experimental settings are seriously flawed."}, "weaknesses": {"value": "Presentation：\n\n--The writing is poor and difficult to follow.\n\nMethod：\n\n--Technical contribution is poor; \n\n--Limited novelty of representing geometric symbols as special tokens and distilling similarities.\n\nExperiment: \n\n--The compared large VLMs (e.g. GPT 4V, Gemini1.5) are all outdated, making the results unreliable. \n\n--The compared specialized geometric solvers are all from before 2022.\n\n--The authors only compare a limited number of early works, making it difficult to assess its contribution."}, "questions": {"value": "--If the large VLMs possesses a strong geometric reasoning ability, what are the motivations and application scenarios for distilling down to a smaller model?\n\n--Why not conduct experiments and comparisons based on methods from recent years?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "McoR7x2YDN", "forum": "YYGsM9ZHHB", "replyto": "YYGsM9ZHHB", "signatures": ["ICLR.cc/2026/Conference/Submission10450/Reviewer_a2DU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10450/Reviewer_a2DU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761734721970, "cdate": 1761734721970, "tmdate": 1762921749330, "mdate": 1762921749330, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ChainGeo, a framework designed to enhance complex geometric reasoning in small Vision-Language Models (1~3B parameters) by addressing the disconnect between visual perception and symbolic reasoning. It uses interleaved visual-text chains—specialized tokens grounded in diagram regions—to bridge visual features and logical reasoning, paired with step-level consistency distillation that transfers structured reasoning processes from large teacher models. ChainGeo enables small vision-language models to achieve geometric reasoning performance on par with large models such as GPT-4V, while being significantly more computationally efficient with inference speeds 15 times faster and producing reasoning chains that are more interpretable and verifiable. The approach is rigorously validated across multiple benchmarks, outperforming both general-purpose small VLMs and specialized geometry solvers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper innovatively introduces interleaved visual-text reasoning chains into small-scale vision-language models (1~3B parameters), explicitly anchoring symbolic reasoning to visual elements throughout the inference process. Unlike traditional text-only chain-of-thought (CoT) approaches, this representation systematically addresses— for the first time—the problem of \"visual amnesia\" in geometric reasoning with small models.\n2. The approach converts geometric elements (points, lines, angles, shapes) into explicit visual tokens and binds them to corresponding image regions, providing an interpretable interface for vision-symbol integration. This token-level grounding can be viewed as a novel multimodal intermediate representation, offering methodological innovation.\n3. ChainGeo provides a systematic implementation pathway that enables vision-language models to explicitly align visual elements with symbolic reasoning steps, laying a foundation for future research in areas such as 3D geometry and physical scene understanding."}, "weaknesses": {"value": "1. The distillation phase relies entirely on GPT-5 to generate reasoning chains, yet the paper does not disclose details about the teacher prompts, chain selection criteria, or quality control procedures. This component contributes significantly to the final results, but the lack of implementation details hinders reproducibility. It is encouraged to provide the teacher prompt templates and clear criteria for reasoning chain selection.\n2. Although the authors emphasize that ChainGeo is a general-purpose framework, all experiments are conducted using a single architecture (Phi-2 + CLIP ViT-L/14). The absence of validation across different base models makes it difficult to assess the method’s transferability across varying language model scales or architectures. Reproducing and comparing results on other lightweight architectures—such as Qwen-VL-2B, LLaVA-1.5, or MiniGPT-4—would provide stronger evidence supporting ChainGeo’s claim as a broadly applicable training methodology.\n3. The paper lacks sufficient training details: although it mentions losses such as \"logical consistency loss\" and \"coherence loss,\" it does not provide explicit equations and hyperparameter choices in the appendix or methodology section to enable readers to verify the feasibility and reproducibility of the approach."}, "questions": {"value": "1. Is the visual token generation process generalizable? The paper mentions that visual tokens are derived from a specially trained geometric element detector based on Faster R-CNN, but it is unclear whether this detector was tailored specifically to a particular dataset (e.g., GeoQA+). If applied to other types of geometric diagrams—such as hand-drawn textbook problems—would the detector maintain its performance?\n2. For the right subfigure in Figure 2, it is recommended to include a more intuitive visualization that clearly illustrates the positive correlation between \"attention retention\" and \"visual grounding accuracy,\" thereby strengthening the claim that ChainGeo effectively mitigates \"visual amnesia\" and ensures reliable visual grounding."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "myeQ7wD2X1", "forum": "YYGsM9ZHHB", "replyto": "YYGsM9ZHHB", "signatures": ["ICLR.cc/2026/Conference/Submission10450/Reviewer_USH7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10450/Reviewer_USH7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761790116702, "cdate": 1761790116702, "tmdate": 1762921748999, "mdate": 1762921748999, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ChainGeo, a framework designed to enable small Vision-Language Models (1–3B parameters) to perform geometric reasoning through interleaved visual–text chains. The core idea is to represent geometric primitives (e.g., points, lines) as specialized tokens that explicitly link symbolic reasoning steps with corresponding regions in the diagram."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The proposed token-level grounding approach offers a computationally efficient way to encode geometric primitives, suitable for smaller models.\n\nThey conducted experiments and evaluated their model on the public benchmarks, suggesting enhanced alignment between visual and symbolic reasoning."}, "weaknesses": {"value": "The contribution and novelty of this paper are limited. The observation that MLLMs fail to perceive diagrams correctly has been extensively explored in prior works such as MathVerse, MathVista, Primitive Vision, and MAVIS, which already provide detailed analyses of perception versus reasoning errors. Similarly, the discussion of visual information loss and attention misalignment is not a new insight—earlier studies (e.g., Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding) have investigated similar issues and proposed mitigation strategies. A more comprehensive literature review would help situate this work within the existing research landscape.\n\nRegarding the proposed solution, the use of a detector-based mechanism to localize geometric elements is not novel and closely resembles approaches in Primitive Vision (Shan Zhang et. al., Primitive Vision: Improving Diagram Understanding in MLLMs, ICML 2025 ). The authors of Primitive Vision explicitly acknowledged the uncertainty of detector outputs and therefore adopted selective feature maps as soft proxies for geometric regions, reducing error propagation from imperfect detections. But in this work, authors do not clearly explain how they ensure the reliability of detection results, especially since training on synthetic datasets often limits generalization to real-world diagrams. The paper also lacks a detailed description of the synthetic data generation process and its potential biases.\n\n\nThe proposed interleaved visual-text reasoning framework also explored by previous works, such as MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning, which addresses similar geometric reasoning challenges. Finally, the method appears restricted to planar geometric problems and does not generalize to other mathematical domains (e.g., graph-based or symbolic reasoning). The analysis of model responses remains shallow, with limited qualitative or interpretability discussion."}, "questions": {"value": "The proposed method appears tailored to 2D geometric problems. How would ChainGeo extend to other domains—such as graph-based reasoning, algebraic problem solving, or multi-step spatial reasoning—where visual grounding is less explicitly defined?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "u8Be4gw9dE", "forum": "YYGsM9ZHHB", "replyto": "YYGsM9ZHHB", "signatures": ["ICLR.cc/2026/Conference/Submission10450/Reviewer_v1Cr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10450/Reviewer_v1Cr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761804162725, "cdate": 1761804162725, "tmdate": 1762921748528, "mdate": 1762921748528, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ChainGeo, a framework that enables small Vision-Language Models (VLMs, 1–3B parameters) to perform complex geometric reasoning through interleaved visual-text chains. The core idea is to represent geometric elements (e.g., [Point A], [Line AB]) as specialized tokens that are explicitly grounded in regions of the input diagram, serving as bridges between visual perception and symbolic reasoning. The authors further introduce step-level consistency distillation, which transfers full reasoning processes from a large teacher model while enforcing visual-textual coherence at every step. Experiments on GeoQA+ (72.1%), Geometry3K (64.7%), and We-Math (68.2%) show that their 2.7B model achieves performance comparable to GPT-4V, while producing interpretable and grounded reasoning chains."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Precise problem framing: Clearly identifies “visual amnesia” as the key bottleneck in small VLMs for geometry.\n- Elegant mechanism: The interleaved visual-text chain with dynamic grounding tokens is simple yet highly effective.\n- High efficiency: 2.7B model runs ~15× faster than GPT-4V while achieving >90% of its accuracy—ideal for educational deployment."}, "weaknesses": {"value": "1. Limited generalization: The method depends on a pre-trained geometric detector, which may fail on hand-drawn sketches, 3D diagrams, or dynamic constructions (acknowledged in Appendix F).\n2. The core components are not fundamentally novel:\n   - Visual tokens with grounding appear in prior work (e.g., KOSMOS-2, DocLLM);\n   - Step-wise distillation for reasoning is conceptually similar to Hsieh et al. (2023)’s “Distilling Step-by-Step”;\n   - Geometric element detection builds on standard object detection frameworks.\nThus, the primary contribution lies in systematic engineering and domain-specific adaptation, rather than a breakthrough in representation learning or distillation theory."}, "questions": {"value": "1. Detector generalization: How robust is the geometric element detector on real-world diagrams with sketchy or noisy styles? Was cross-dataset generalization evaluated (e.g., training on GeoQA+ and testing detection on We-Math)?\n2. Token vocabulary extensibility: How does the system handle non-standard geometric elements (e.g., arcs, sectors, irregular polygons)? Could unsupervised token discovery (e.g., via clustering) reduce reliance on predefined categories?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KvsONUzHmy", "forum": "YYGsM9ZHHB", "replyto": "YYGsM9ZHHB", "signatures": ["ICLR.cc/2026/Conference/Submission10450/Reviewer_qvcE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10450/Reviewer_qvcE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10450/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761897331678, "cdate": 1761897331678, "tmdate": 1762921748062, "mdate": 1762921748062, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}