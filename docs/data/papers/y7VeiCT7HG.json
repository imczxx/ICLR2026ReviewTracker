{"id": "y7VeiCT7HG", "number": 21951, "cdate": 1758324015364, "mdate": 1759896894521, "content": {"title": "Probability of Matching for Pareto Coverage", "abstract": "In batch multi-objective Bayesian optimization (MOBO), it is often desirable to identify the whole Pareto optimal set, especially when considering the complicated interplay between different design criteria and constraints. This poses unique challenges in acquiring batches of both high quality and diversity to cover the Pareto front. We propose a novel acquisition strategy, Probability of Matching, which evaluates both batch candidate quality and diversity by explicitly capturing the likelihood that a batch matches the true Pareto set. This is achieved by factorizing the probability into two components: the likelihood that all batch points are Pareto optimal, and the probability that they collectively cover the full Pareto set. To estimate the coverage probability and promote diversity, we incorporate space-filling design principles, resulting in our space-filling qEHVI (qEHVI-SF), a new batch MOBO method. Across synthetic benchmarks and real-world tasks, qEHVI-SF consistently outperforms state-of-the-art baselines on standard MOBO metrics as well as a new design-space coverage metric, Expected Minimum Distance (EMD), with comparable computational efficiency.", "tldr": "", "keywords": ["Multi-objective Bayesian Optimization", "Pareto front", "Probability of Matching", "Hypervolume", "Space filling"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b8dd184135e14593e4162a36c9c7005096e918d8.pdf", "supplementary_material": "/attachment/48ed764127c46517212eccb9e557cab7da3d4ece.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a new acquisition strategy for expensive multi-objective Bayesian optimization (MOBO) that jointly promotes the quality and diversity of solutions in the Pareto set. The key idea is to estimate the probability of matching, which encompasses (i) the probability that batch points are Pareto-optimal, and (ii) the probability that they collectively cover the entire Pareto front. The authors approximate these terms using qEHVI for quality and a space-filling design for coverage, yielding an acquisition function that balances exploration and exploitation without additional hyperparameters."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Writing is good, easy to follow.\n- The paper clearly identifies the limitation of existing MOBO approaches that overemphasize quality while neglecting diversity. By modeling diversity in the design space rather than the objective space, the method avoids surrogate bias and is potentially more robust for problems with dispersed Pareto fronts.\n- The probability of matching $P(X = {X}^{\\star})$  is an intuitive and compelling way to frame the batch MOBO problem. Factorizing it into a quality term $P(X \\subseteq X^\\star)$ and coverage term $P({X}^\\star \\subseteq X \\mid X \\subseteq {X}^\\star)$ is a clean, logical decomposition.\n- The introduction of the Expected Minimum Distance (EMD) metric is a useful addition. Measuring coverage in the design space offers a stricter and more informative alternative to traditional objective-space metrics such as IGD."}, "weaknesses": {"value": "- The theoretical formulation defines the coverage probability $P({X}^\\star \\subseteq X | X \\subseteq {X}^\\star)$, yet the practical implementation replaces this with an approximation $P({X}^\\star \\subseteq A^r_X | X \\subseteq {X}^\\star)$, where $A^r_X$ is a union of balls. The final acquisition (Eq. 8) relies on a minimum-distance heuristic $\\min(\\Delta(X, {X}), \\Delta(X, X_n))$, but the paper does not provide a rigorous justification linking this heuristic to maximizing the coverage probability. Could the authors provide a more formal bridge between the theoretical coverage formulation and the adopted minimum-distance heuristic?\n- The coverage probability is approximated using minimax distance, which may not adequately capture complex or multimodal Pareto structures. Could alternatives like kernel-based diversity be explored? \n- This paper focuses on the MOBO problems that have many optimal solution regions, aiming to demonstrate the effectiveness of the proposed coverage term. However, the results do not significantly outperform the baselines; results on ZDT/DTLZ (Appendix) show smaller gains. The author should provide more diverse problems to strengthen claims.\n- The authors mentioned that a larger batch size leads to higher $P(X^\\star \\subseteq X)$ while it may reduce $P(X \\subseteq X^\\star)$. However, the result indicates that each batch size setting illustrates similar performance. There's no clear guidance on how to choose a batch size in practice for new problems.  Could you conduct more experiments for this phenomenon?\n\n**Minor issues:**\n- Some figures could better label axes or explain color scales for clarity.\n- The paper should be presented in the template of ICLR 2026, not ICLR 2025."}, "questions": {"value": "Kindly address weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ohdskecxr2", "forum": "y7VeiCT7HG", "replyto": "y7VeiCT7HG", "signatures": ["ICLR.cc/2026/Conference/Submission21951/Reviewer_kUdU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21951/Reviewer_kUdU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21951/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761327607272, "cdate": 1761327607272, "tmdate": 1762941993250, "mdate": 1762941993250, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new multi-objective acquisition function inspired by maximizing the probability that sampled batch points match the Pareto frontier. They use set theory identities to decompose this probability into two parts one representing the probability of sampled batch being Pareto optimal, and the other representing how well the batch X covers the entire Pareto set. Since these probabilities are intractable to compute directly, they approximate the first using qEHVI as a heuristic proxy for solution quality, and the second maximizes the minimum pairwise distance between batch points and previously sampled points, under the assumption that well-spaced points are more likely to cover dispersed Pareto optimal regions. The algorithm is benchmarked on synthetic problems including Gaussian mixture and RE4-7-1, standard MOBO benchmarks like DTLZ and ZDT families, and real world problems, demonstrating consistently better performance across hypervolume, inverted generational distance, and a new design-space coverage metric called expected minimum distance, while maintaining computational efficiency comparable to standard qEHVI."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The set-theoretic decomposition is conceptually elegant and refreshing, providing a principled justification for the hyperparameter-free multiplicative combination of quality and diversity terms.\n- The algorithm demonstrates competitive empirical performance across synthetic benchmarks and real-world materials discovery tasks."}, "weaknesses": {"value": "- I think the main issue is the heuristic foundation of this paper, there is no theoretical justifying thet $p(X \\subseteq X^*)$ can be approximate by qEHVI and in fact, I don't think this ever hold and one can justify by using exhaustive MC sampling as approximation.\n- Similar concerns apply to the coverage term: the connection between space-filling (minimum distance) and coverage probability is purely heuristic\n- (Minor) Tables would benefit from bold text to highlight best performance for easier comparison."}, "questions": {"value": "The acquisition function multiplies quality and coverage terms. As batch size $q$ increases, the quality term $P(X \\subseteq X^*)$ may decrease significantly since it requires all $q$ points to simultaneously be Pareto optimal. While the outputs are correlated under the GP prior, does this mean the quality term diminishes with $q$ while the coverage term grows with $q$? If so, how does their product balance these opposing trends, and does this create a systematic bias toward smaller or larger batch sizes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "59IDb9bV59", "forum": "y7VeiCT7HG", "replyto": "y7VeiCT7HG", "signatures": ["ICLR.cc/2026/Conference/Submission21951/Reviewer_EaKA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21951/Reviewer_EaKA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21951/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761698055967, "cdate": 1761698055967, "tmdate": 1762941993012, "mdate": 1762941993012, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new batch multi-objective Bayesian optimization acquisition strategy. It extends the popular qEHVI framework by incorporating the proposed Probability of Matching in order to trade-off convergence and diversity. An empirical comparison is performed on synthetic benchmarks and real-world tasks."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper proposes a novel acquisition strategy that jointly considers both convergence and diversity in batch multi-objective Bayesian optimization - a promising research topic in Bayesian optimization."}, "weaknesses": {"value": "1) Maximizing HV is actually also diversifying solutions as the true Pareto front always has the maximum HV value. It seems to me that this plays a similar role with maximising the coverage of solutions.  \n\n2) During HV-related search, the reference point may not be a big issue as it can be set adaptively based on the nondominated solutions found.\n\n3) The metric used for maximizing coverage is like the well-known uniformity metric in multi-objective evolutionary optimization, Spacing (SP), which measures the maximim distance between two nearest solutions. \n\n4) IGD is not first proposed in Ishibuchi et al 2025. Please cite the orignal paper. \n\n5) Not quite understand why you consider the \"IGD\" in the decision space. You didn't consider the diversity of solutions in the decision space since your method cares about the diversity in the objective space. There could be a situation that there is perfectly distributed solution set in the decision space, but poorly distributed mappings in the objective space - I think such a case can't verify your algorithm?\n\n6) Not quite understand why your algorithm obtains a better HV compared to qEHVI since the latter directly optimize HV, but you try to strike a balance between HV and SP. Did you use the same reference setting strategy? If yes, what is it?  \n\n7)  The proposed method is based on qEHVI and jointly estimates a batch of solutions, which may scale up poorly with the batch size [1] and perform worse than a sequential strategy [2,3]. When using a sequential acquisition strategy, qEHVI [2,3] can naturally produce a batch of solutions with good diversity and convergence through its iterative uncertainty updates. It would be useful to include a theoretical and empirical comparison between the proposed method and the sequential qEHVI. \n\n8) The related work section is not very comprehensive with respect to MOBO methods. The experimental evaluation lacks comparisons with several well-established MOBO baselines, such as Sobol sampling, ParEGO, and Joint Entropy Search (JES) [4]. \n\n\n[1] Daxberger, E. A.; and Low, B. K. H. 2017. Distributed batch Gaussian process optimization. In Proceedings of the 34th International Conference on Machine Learning, 951–960. PMLR.\n\n[2] Samuel Daulton, Maximilian Balandat, and Eytan Bakshy. Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization. In Advances in Neural Information Processing Systems, volume 33, pages 9851–9864. Curran Associates, Inc., 2020.\n\n[3] Samuel Daulton, Maximilian Balandat, and Eytan Bakshy. Parallel Bayesian optimization of multiple noisy objectives with expected hypervolume improvement. In Advances in Neural Information Processing Systems, volume 34. Curran Associates, Inc., 2021.\n\n[4] Ben Tu, Axel Gandy, Nikolas Kantas, and Behrang Shafei. Joint entropy search for multi-objective Bayesian optimization. Advances in Neural Information Processing Systems, 35:9922–9938, 2022."}, "questions": {"value": "Could you please respond to my comments 1, 3, 5, 6, 7 in the Weaknesses section?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gzKylhC9SG", "forum": "y7VeiCT7HG", "replyto": "y7VeiCT7HG", "signatures": ["ICLR.cc/2026/Conference/Submission21951/Reviewer_y2j9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21951/Reviewer_y2j9"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21951/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761865366226, "cdate": 1761865366226, "tmdate": 1762941992588, "mdate": 1762941992588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes qEHVI-SF, a novel batch multi-objective Bayesian optimization (MOBO) algorithm that introduces the Probability of Matching (PoM) — a probabilistic measure quantifying how likely a batch of candidate points matches the true Pareto optimal set. The approach factorizes this probability into two components: (i) the probability that all batch points are Pareto optimal, and (ii) the probability that they collectively cover the Pareto front. By combining qEHVI for quality estimation with a space-filling principle for diversity, yielding an integrated acquisition function that promotes both optimality and coverage. Extensive experiments on synthetic benchmarks and a real-world materials design case study show consistent improvements in hypervolume, IGD, EMD, and rediscovery ratio, while maintaining comparable computational efficiency to qEHVI. The paper is well-motivated, technically sound, and experimentally strong, though probabilistic factorization lacks rigorous justification."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Unified acquisition design: Integrates performance and diversity without manual hyperparameter tuning.\n2. Comprehensive experiments: Covers both synthetic and real-world alloy design tasks, showing consistent gains.\n3. Introduces a useful coverage metric (EMD) in design space, adding depth to MOBO evaluation.\n4. Maintains computational efficiency comparable to qEHVI, demonstrating practical scalability."}, "weaknesses": {"value": "1. The probabilistic factorization (Eq. 7–8) is intuitive but lacks formal theoretical proof.\n2. Ablation study for the space-filling component is missing, making it unclear how much it contributes individually.\n3. Some figures and equations are overly dense, affecting clarity.\n4. No discussion on extending the framework to constrained or preference-based MOBO.\n5. Theoretical limitations section (Section 5) could be expanded to strengthen formal grounding."}, "questions": {"value": "1. Can the authors provide a more formal justification for the decomposition of Eq. (7–8)?\n2. How sensitive is the method to batch size q? Could adaptive q be explored?\n3. How does qEHVI-SF behave when the Pareto front is discontinuous or highly non-convex?\n4. Could the approach be extended to constrained or preference-aware MOBO scenarios?\n5. Would the authors consider releasing implementation code to facilitate reproducibility?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bDIm5hD9lq", "forum": "y7VeiCT7HG", "replyto": "y7VeiCT7HG", "signatures": ["ICLR.cc/2026/Conference/Submission21951/Reviewer_jkQL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21951/Reviewer_jkQL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21951/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993631703, "cdate": 1761993631703, "tmdate": 1762941992178, "mdate": 1762941992178, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}