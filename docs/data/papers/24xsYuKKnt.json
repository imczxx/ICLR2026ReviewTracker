{"id": "24xsYuKKnt", "number": 21711, "cdate": 1758320755631, "mdate": 1762961506190, "content": {"title": "PaTSy-Neural-EM: Geometry-Aware Truth Discovery for Real-Time Multi-Agent Perception", "abstract": "We revisit truth discovery (TD) for multi-agent perception and present PaTSy-\nNeural-EM, a geometry-aware EM framework that learns state-conditioned reliability\nwhile preserving the interpretability of Dawid–Skene (DS) confusion\nmatrices. In dynamic V2X scenes, reliability varies with range, incidence angle,\nocclusion, latency, and agent identity. PaTSy injects this context via a log-linear\nreliability head whose outputs additively correct DS logits and are renormalized\nwith a softmax to yield valid context-dependent confusion columns. To stabilize\njoint learning, we introduce a gentle-Π schedule: (i) warm-start Π with DS, (ii)\nfreeze Π while training the head, and (iii) unfreeze with a KL trust-region tether.\nWe further add physics-inspired regularizers: range-monotonicity and angular\nsmoothness. The resulting model runs in real time, remains DS-compatible, and\nyields better calibration and hard-slice robustness at DS-level top-1 accuracy\non V2X-Real. On OPV2V under zero calibration, our best run improves over DS\nby +0.9% absolute on both validation and test.", "tldr": "PaTSy-Neural-EM combines EM with neural reliability prediction to assess agent trustworthiness via geometric context, achieving robust real-time multi-agent perception under occlusion and long-range conditions.", "keywords": ["Multi-agent Perception", "Truth discovery", "Sensor Fusion", "Expectation-maximization(EM)", "V2X", "OPV2V", "Confusion matrices", "Neural reliability head", "Scene geometry features", "Trust-region optimization"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/f1baab27261669a8d1b18ef09eb5aa031f02f0c5.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This submission presents PaTSyNeural-EM, a geometry-aware EM framework for multi-agent perception. It provides a new theoretical aspect to study Cooperative V2X systems. The results slightly improves the baselines."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. This submission proposes a new theoretical aspect to study multi-agent perception.\n2. The limited results show certain potential of the proposed method."}, "weaknesses": {"value": "1. The submission is not ready for any publication. It is a surprise for me to see such a submission at ICLR.\n2. The content is incomplete and very hard to follow. Notably, the related work section has only two lines.\n3. Many mathematical symbols are not defined and equations are not well explained at all."}, "questions": {"value": "The lack of clarity makes it challenging to formulate any constructive questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Fc6ZRGfRBJ", "forum": "24xsYuKKnt", "replyto": "24xsYuKKnt", "signatures": ["ICLR.cc/2026/Conference/Submission21711/Reviewer_pgL5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21711/Reviewer_pgL5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21711/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761615987336, "cdate": 1761615987336, "tmdate": 1762941899125, "mdate": 1762941899125, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "CjVKl5rRoB", "forum": "24xsYuKKnt", "replyto": "24xsYuKKnt", "signatures": ["ICLR.cc/2026/Conference/Submission21711/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21711/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762961505017, "cdate": 1762961505017, "tmdate": 1762961505017, "mdate": 1762961505017, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses truth discovery for cooperative perception in V2X scenarios, where multiple agents (vehicles and roadside units) submit labels about the same scene, and the system must infer the most likely ground truth. The key idea is to keep the familiar Dawid–Skene (DS) per‑agent confusion matrices but make them context‑aware: a small neural module adjusts an agent’s reliability on the fly using geometry and timing features such as range, bearing, line‑of‑sight/occlusion proxies, time offset, and agent identity. These adjusted reliabilities are re‑normalized so they remain valid probabilities and are used inside an EM (expectation–maximization) loop. To stabilize training and preserve the interpretability of the DS parameters, the authors use a three‑stage schedule—start from a DS solution, train only the neural head, then fine‑tune everything with a penalty that keeps the solution near the DS initialization—and add physics‑inspired regularizers that encourage reliability to decrease with distance and to vary smoothly with viewing angle. Experiments on V2X‑Real and OPV2V report DS‑level accuracy with better calibration on V2X‑Real and a small accuracy gain on OPV2V, alongside millisecond‑level inference on an NVIDIA T4"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Conceptual simplicity with DS‑compatibility. Casting context‑aware reliability as additive logit corrections to DS confusion columns is clean and keeps the DS interpretation at the core. This makes the approach easier to plug into EM‑style TD pipelines.\n2. Physics‑guided priors. Range‑monotonicity and angular‑smoothness regularizers encode domain knowledge and could help prevent pathological fits in sparse regimes"}, "weaknesses": {"value": "1. Headline results show no accuracy improvement on the main dataset; calibration evidence is incomplete.\nTable 1 (page 3) reports identical validation and test accuracies for DS, Graph+DS, and PaTSy (0.9766 / 0.9190), i.e., no improvement over DS. Meanwhile, Table 2 only reports PaTSy’s ECE (0.244 VAL / 0.299 TEST) without the DS ECE, so readers cannot verify the “improved calibration” claim. Figure 2 (page 4) is explicitly labeled “concept” rather than empirical. This makes the main claim—“better calibration while preserving DS‑level accuracy”—unsubstantiated on the primary benchmark. Please provide actual reliability diagrams and NLL/ECE for all methods.\n2. Missing baselines and incomplete related work for context‑aware annotator models.\nThe proposed idea—context‑ or item‑dependent annotator reliability—has close precedents (e.g., GLAD‑style difficulty modeling, Bayesian Classifier Combination variants, neural DS extensions). While Table 4 lists names like GLAD and BCC under an “alternate protocol,” these are not evaluated in the main setting and are not properly cited in the references section; key works (e.g., GLAD/Whitehill et al.) are missing. The paper should position PaTSy against instance‑dependent/noise‑adaptive TD methods with comparable training budgets on the same splits."}, "questions": {"value": "KL tether anchor. In Eq. (4), is the KL penalty anchored to the DS solution or to the previous iterate? If the former, why call it a trust‑region? Please provide ablations that (i) tether to DS, (ii) tether to previous Π, and (iii) no tether"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BTrtJZtkLK", "forum": "24xsYuKKnt", "replyto": "24xsYuKKnt", "signatures": ["ICLR.cc/2026/Conference/Submission21711/Reviewer_EDiF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21711/Reviewer_EDiF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21711/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761798833837, "cdate": 1761798833837, "tmdate": 1762941898839, "mdate": 1762941898839, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper should be desk rejected."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "This paper should be desk rejected."}, "weaknesses": {"value": "This paper should be desk rejected."}, "questions": {"value": "This paper should be desk rejected."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "v2lpSUnndG", "forum": "24xsYuKKnt", "replyto": "24xsYuKKnt", "signatures": ["ICLR.cc/2026/Conference/Submission21711/Reviewer_HVxs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21711/Reviewer_HVxs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21711/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945889547, "cdate": 1761945889547, "tmdate": 1762941898595, "mdate": 1762941898595, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper revisits truth discovery for cooperative V2X perception, arguing that classical Dawid–Skene is mis-specified because agent reliability depends on geometry and timing (range, bearing, occlusion, latency, agent identity). The authors propose PaTSy-Neural-EM, which preserves DS interpretability but makes reliability context-conditioned via a lightweight log-linear head and a per-column softmax inside EM; training is stabilized with a gentle-Π schedule (DS warm start → head-only → unfreeze with a KL tether) plus physics-inspired regularizers enforcing range-monotonicity and angular smoothness. On V2X-Real, the method matches DS in top-1 accuracy while improving calibration and robustness on hard slices; on OPV2V under zero calibration, it yields a +0.9% absolute gain, and the authors claim real-time performance."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Stability recipe that addresses Neural-EM pitfalls: The gentle-Π schedule (DS warm start → head-only → unfreeze with a KL tether) plus physics-inspired regularizers (range-monotonicity, angular smoothness) targets identifiability and training stability in a practical, reproducible manner. \n2. Practical signal: On V2X-Real, the method matches DS in top-1 while improving calibration and hard-slice robustness; it also reports real-time feasibility and a small positive transfer on OPV2V under zero calibration."}, "weaknesses": {"value": "1. Insufficient related work coverage. For a 2025 submission, surveying only seven papers (with the most recent around 2020) is inadequate. The literature on collaborative perception contains many more recent efforts that explicitly model confidence or spatial confidence maps and their impact on multi-agent fusion; these should be discussed and, where possible, compared. \n2. Ambiguous writing and notation. Several definitions and symbols are introduced with limited exposition, making the derivations and the exact semantics of variables difficult to follow; clearer notation tables and step-by-step derivations would improve readability.\n3. Lack of system/dataflow visualization. The paper would benefit from a concise schematic of the overall setting and per-item dataflow (agents, gating, features, EM steps). Current figures focus on accuracy/calibration/dynamics but do not convey the end-to-end pipeline. \n4. Underspecified experimental setting and limited datasets. Important protocol details are condensed, and the evaluation is restricted to V2X-Real and OPV2V, limiting external validity; broader datasets and fuller ablations/baselines are needed to substantiate generality."}, "questions": {"value": "1. EM details & stability. Specify the exact objective optimized per phase (DS-warm start / head-only / unfreeze with KL), the update rules, number of inner E-steps, stopping criteria, and evidence of monotonic improvement. Ablate the gentle-Π schedule and the KL tether to show their necessity.\n2. Baselines & related work coverage. Expand the survey and comparisons to include stronger TD/Neural-EM baselines (e.g., GLAD, MACE, Bayesian DS, recent neural variants) and recent collaborative-perception methods that model confidence (confidence maps, spatial gating, flow-based reuse). Justify any omissions.\n3. Datasets, protocol, and generalization. Clearly detail splits/protocols and broaden evaluation (e.g., DAIR-V2X, V2X-Sim). Define the “zero-calibration” setting precisely. Visualize conditional confusion columns across agents and report efficiency scaling with the number of agents/classes."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rDg5CTKYWU", "forum": "24xsYuKKnt", "replyto": "24xsYuKKnt", "signatures": ["ICLR.cc/2026/Conference/Submission21711/Reviewer_Bouw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21711/Reviewer_Bouw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21711/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762058602126, "cdate": 1762058602126, "tmdate": 1762941898355, "mdate": 1762941898355, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}