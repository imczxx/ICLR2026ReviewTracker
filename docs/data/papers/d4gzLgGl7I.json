{"id": "d4gzLgGl7I", "number": 18704, "cdate": 1758290294556, "mdate": 1759897086575, "content": {"title": "A Two-Phase Deep Learning Framework for Adaptive Time-Stepping in High-Speed Flow Modeling", "abstract": "We consider the problem of modeling high-speed flows using machine learning methods. While most prior studies focus on low-speed fluid flows in which uniform time-stepping is practical, flows approaching and exceeding the speed of sound exhibit sudden changes such as shock waves. In such cases, it is essential to use adaptive time-stepping methods to allow a temporal resolution sufficient to resolve these phenomena while simultaneously balancing computational costs. Here, we propose a two-phase machine learning method, known as ShockCast, to model high-speed flows with adaptive time-stepping. In the first phase, we propose to employ a machine learning model to predict the timestep size. In the second phase, the predicted timestep is used as an input along with the current fluid fields to advance the system state by the predicted timestep. We explore several physically-motivated components for timestep prediction and introduce timestep conditioning strategies inspired by neural ODE and Mixture of Experts. As ShockCast is the first framework for learning high-speed flows, we evaluate our methods by generating two supersonic flow datasets.", "tldr": "", "keywords": ["Partial Differential Equations", "PDEs", "CFD"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/93855ba24bbc887d77ed6f3b1a8a2d7da7002156.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes using an ML model to predict time steps for fluid simulations that use adaptive time steps.  It then uses those timesteps in an autoregressive fashion to solve compressible flow problems with a neural solver."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper makes an interesting observation that when using a neural PDE solver, you can't necessarily rely on the CFL number computed on the fine computational mesh used for the simulation, because the neural model will effectively downsample the mesh inside the network, and so the adaptive time step chosen should be on that coarser scale.\n- The numerical experiments seem convincing to me of the utility of the proposed method."}, "weaknesses": {"value": "- I think \"Our work represents the first steps towards developing machine learning models for high-speed flows\" is a bit of an inflated statement that could be toned down.\n- Although it's a fair point that a neural solver will have a different internal grid resolution than what is used for the PDE outside the network, presumably one knows what is the architecture they're dealing with and what that coarse grid resolution is.  Why not just compute an adaptive time step - classically - using that coarser scale (which should be known from looking at the network architecture you choose) and eschewing the proposed neural CFL predictor?\n- If the answer to the above is \"you could do either, but neural CFL predictor is faster while still just as accurate,\" can we see a study on that?"}, "questions": {"value": "- It's probably worth making the connection in the into that adaptive time stepping is not some CFD-specific thing - it is core to ML as well, e.g. \"adaptive learning rates\" with SGD/Adam/etc.\n- Probably also worth noting in the intro that the problem with adaptive time stepping is more extreme than what you describe - if you don't have good timesteps, not only will you miss fine-scale flow phenomena, but your simulation will just crash due to predicting negative pressures etc. - before the solution ever has a chance to diverge - see e.g. Patkar et al., \"Towards positivity preservation for monolithic two-way solid–fluid coupling\" (in particular the issue of positivity preservation that is highlighted - even for relatively low-Mach flows)\n- In 2.3, since you are interested in CFD/engineering, it may be worth noting that methods like PINNs are not convergent (they are, in their vanilla versions at least, one-shot predictors of the solution of a PDE, which can't be convergent).  Recent hybrid solver approaches like that of Kaneda et al., \"A deep conjugate direction method for iteratively solving linear systems\" use a neural network for preconditioning but use a classical solver loop to ensure convergence (that paper happens to be for incompressible flow, but same ideas for compressible flow systems)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QxEJdpR9AG", "forum": "d4gzLgGl7I", "replyto": "d4gzLgGl7I", "signatures": ["ICLR.cc/2026/Conference/Submission18704/Reviewer_b48r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18704/Reviewer_b48r"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761395731740, "cdate": 1761395731740, "tmdate": 1762928407215, "mdate": 1762928407215, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ShockCast, a two-phase deep learning framework for modeling high-speed flows with adaptive time-stepping.\n\n- Phase one uses a “Neural CFL” model to predict the timestep ∆t;\n\n- Phase two employs a timestep-conditioned neural solver to evolve the flow field.\n\nThe authors evaluate their framework on two internally generated supersonic datasets (circular blast and coal dust explosion), comparing multiple backbone architectures and conditioning strategies."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Clear motivation: aiming to addresses PDEs under varying time intervals.\n\n- Clear architecture modularity: Two phases modeling.\n\n- Inclusion of physically inspired features (∇u, wave speed, CFL terms) is a positive step toward physics-awareness.\n\n- Comprehensive validations across several backbones and conditioning methods.\n\n- Figures are clear and the manuscript is overall readable."}, "weaknesses": {"value": "- Conceptual shallowness: The so-called “Neural CFL” model merely regresses ∆t from local features; it does not derive from or guarantee compliance with the true CFL stability condition. There is no theoretical guarantee that predicted timesteps are stable or physically valid.\n\n- Lack of physical consistency: The paper never checks conservation of mass, momentum, or energy, which is essential for high-Mach or compressible flows.\n\n- Experimental validation is weak – Both datasets are self-generated 2D toy problems. Under the same physical conditions, which configuration for each benchmark is the most effective?\n\n- No efficiency or stability analysis – The core motivation of adaptive stepping (e.g., computational savings or others) is never quantified; no wall-clock or rollout stability plots of flow evolution.\n\n- Limited generalization – Only Mach < 3 cases are tested; unclear if the method scales to realistic hypersonic or turbulent regimes.\n\n- Over-claimed novelty – Prior works (e.g., continuous-time neural solvers, time-conditioned FNOs, and physics-aware operator networks) already include similar temporal adaptivity ideas; Also many works for supersonic/hypersonic flow modeling (not the first machine learning framework).\n\n- Method complexity vs. benefit – The two-phase design and multiple conditioning mechanisms add heavy machinery without showing clear improvement over a simpler time-conditioned baseline. Reporting a clear and full coparison (vs. graph-based methods, transformer-based methods, FNO-based methods, and etc. ) on one new table."}, "questions": {"value": "- If the ∆t distribution is known in training data, why we need the two-phases modeling?\n\n- If the two-phases modeling is usefull, the predicted ∆t from Phase one is inherently impossible for it to perfectly match the true ∆t  (based on a continuous value space) . In this case, what is the significance of designing the Phase one?\n\n- Can you demonstrate that ShockCast preserves key physical invariants or avoids divergence during long rollouts?\n\n- How much computational speedup or advantage (vs. one-phase modeling with time variable inputs) is achieved in practice?\n\n- Have you tested the model on higher Mach (>5) or 3D flow cases to assess scalability?\n\n- Have you tested the model on irregular domain cases to assess scalability?\n\nShould you be able to satisfactorily address the points I've raised above, I will accordingly provide a positive rating."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "vwZPJyNtGA", "forum": "d4gzLgGl7I", "replyto": "d4gzLgGl7I", "signatures": ["ICLR.cc/2026/Conference/Submission18704/Reviewer_WzPk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18704/Reviewer_WzPk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761469391424, "cdate": 1761469391424, "tmdate": 1762936208404, "mdate": 1762936208404, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper, ShockCast, proposes a novel two-phase deep learning framework for adaptive time-stepping in high-speed flow modeling (e.g., supersonic and hypersonic regimes). High-speed flows exhibit transient sharp gradients (shocks) requiring dynamic adjustment of the timestep size (Δt) using the Courant-Friedrichs-Lewy (CFL) condition, which is computationally expensive for classical solvers.\n\nShockCast addresses this by decomposing the task:\n\nNeural CFL Phase ($\\psi$): A ConvNeXt backbone predicts the optimal, large timestep $\\Delta t$ based on the current flow state. This module is trained to emulate the $\\Delta t$ choices from the classical solver used for data generation, circumventing issues caused by coarse computational meshes.\n\nNeural Solver Phase ($\\phi$): The flow state is evolved by the predicted $\\hat{\\Delta}t$. The authors introduce three novel timestep conditioning strategies for various neural solver backbones (F-FNO, U-Net, CNO, Transolver): Euler Residuals, Mixture of Experts (MoE), and Affine/Spatial-Spectral Conditioning.\n\nThe framework is evaluated on two new supersonic flow datasets—Coal Dust Explosion (multiphase) and Circular Blast (single-phase)—and achieves strong performance in accurately predicting both instantaneous fields and integrated physical quantities (TKE and Mean Flow)."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Improved Training Objective for Transient Dynamics: The core motivation is strong: adaptive time-stepping naturally balances the training objective by inversely scaling $\\Delta t$ according to the rate of change. This more evenly distributes the learning difficulty across states with smooth and sharp gradients (i.e., shocks), a highly pertinent consideration for high-speed flows.\n\n\nPhysically-Informed Neural CFL Model: The Neural CFL phase successfully emulates the true adaptive time mesh, as shown by the close match between predicted and true $\\Delta t$ during autoregressive rollout. Furthermore, incorporating physically-motivated inputs like spatial gradients ($\\nabla u$) and CFL features substantially improves the $\\Delta t$ prediction accuracy for the complex multiphase Coal Dust Explosion scenario\n\n\nNovel and Effective Conditioning Strategies: The introduction of Euler Residuals and Mixture of Experts (MoE) as timestep conditioning strategies is technically insightful. The results demonstrate that these methods are highly competitive, achieving the lowest TKE error for the Circular Blast (F-FNO backbone with MoE/Euler) and best Mean Flow/TKE performance for the Coal Dust Explosion (U-Net backbone with MoE/Euler)"}, "weaknesses": {"value": "1. Missing Quantification of Speedup: The paper's primary motivation is the immense computational cost of classical high-speed flow solvers. However, the results section fails to quantify the final speedup achieved by the full ShockCast pipeline (inference runtime) relative to the original classical solver. Without this figure, the practical utility of the entire framework remains unproven. (Only the classical solver runtime is given in Table 5, min: $\\sim 15$K seconds, mean: $\\sim 67$K seconds)\n\n2. Complexity of MoE Implementation: The MoE conditioning significantly increases peak training memory (e.g., F-FNO: $18.9$ GiB (Affine) vs. $37.2$ GiB (MoE); Transolver: $41.8$ GiB (Affine) vs. $62.4$ GiB (MoE))9. While the complexity is offset by reducing the latent dimension for some models, the substantial jump in memory requirement suggests that the MoE approach is challenging to implement and scale, requiring clarification on the trade-off."}, "questions": {"value": "Missing Speedup Quantification: The core justification is computational efficiency, yet the paper fails to state the final speedup factor (e.g., $1000\\times$) of ShockCast relative to the original classical solver runtime (which can take tens of thousands of seconds). This critical number must be explicitly provided\n\n\nrade-Off for MoE Complexity: The Mixture of Experts (MoE) component, while showing excellent results, dramatically increases memory consumption (e.g., up to $\\sim 62$ GiB)14. The efficiency/performance trade-off needs deeper analysis, as the simpler Euler Residuals or Affine methods often perform comparably"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GElBmFxqsd", "forum": "d4gzLgGl7I", "replyto": "d4gzLgGl7I", "signatures": ["ICLR.cc/2026/Conference/Submission18704/Reviewer_1474"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18704/Reviewer_1474"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761524711085, "cdate": 1761524711085, "tmdate": 1762928404298, "mdate": 1762928404298, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Update: ShockCast Response"}, "comment": {"value": "We thank the reviewers for their thoughtful feedback and for suggesting new experiments that explore several additional settings to improve our work. We are actively running these experiments, however, because they rely on computationally-intensive simulations with our classical solver, they require significant processing time. We are preparing our response as quickly as possible and appreciate the reviewers’ patience as we complete these experiments."}}, "id": "jeybwkXtpb", "forum": "d4gzLgGl7I", "replyto": "d4gzLgGl7I", "signatures": ["ICLR.cc/2026/Conference/Submission18704/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18704/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18704/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763770270569, "cdate": 1763770270569, "tmdate": 1763770270569, "mdate": 1763770270569, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ShockCast, a two-phase deep learning framework for adaptive time-stepping in high-speed flow modeling. The first phase employs a Neural CFL model to predict the time-step size ($\\Delta t$) based on the current flow state, while the second phase uses a time-conditioned neural solver to evolve the flow field by the predicted $\\Delta t$. The authors generate two new datasets (spherical blast and coal dust explosion) and demonstrate that ShockCast effectively handles the sharp gradients and varying time scales in supersonic/hypersonic flows."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "First work to address adaptive time-stepping in neural solvers for high-speed flows, filling a critical gap in ML-based CFD. Potential to accelerate simulations in aerodynamics, aerospace, and explosion modeling."}, "weaknesses": {"value": "1.Evaluated only on two synthetic datasets (spherical blast & coal dust explosion). Training neural CFL + solver may still be expensive compared to classical adaptive methods.\n\n2.Be overly dependent on data.\n\n3.The proposed component is not sufficiently validated."}, "questions": {"value": "1.How were the initial conditions (e.g., Mach numbers, pressure ratios) for the datasets chosen? Are they representative of real-world scenarios?\n\n2.Can you visualize/analyze which features (e.g., velocity gradients, sound speed) most influence the predicted $\\Delta t$?\n\n3.Small errors in $\\Delta t$ prediction may compound during autoregressive rollout. How does ShockCast handle stability over long simulations?\n\n4.Does ShockCast generalize to unstructured meshes or three-dimensional (3D) flows?\n\n5.The paper lacks an analysis of error accumulation beyond 100 autoregressive steps.\n\n6.The requirement for high-fidelity solver data for training may be prohibitive for certain users.\n\n7.Please specify the computational costs of the proposed methods and the actual speedup achieved compared to numerical simulations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "f97a8N0Qmb", "forum": "d4gzLgGl7I", "replyto": "d4gzLgGl7I", "signatures": ["ICLR.cc/2026/Conference/Submission18704/Reviewer_Ssu2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18704/Reviewer_Ssu2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18704/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761808118231, "cdate": 1761808118231, "tmdate": 1762928403661, "mdate": 1762928403661, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}