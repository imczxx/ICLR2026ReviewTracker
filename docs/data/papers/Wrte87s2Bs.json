{"id": "Wrte87s2Bs", "number": 21279, "cdate": 1758315739351, "mdate": 1759896931067, "content": {"title": "Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems", "abstract": "Scientists often infer abstract procedures from specific instances of problems and use the abstractions to generate new, related instances. For example, programs encoding the formal rules and properties of a system have been useful in fields ranging from reinforcement learning (procedural environments) to physics (simulation engines). These programs can be seen as functions which execute to different outputs based on their parameterizations (e.g., gridworld configuration or initial physical conditions). We introduce the term EFA (Executable Functional Abstraction) to denote such programs for math problems. EFA-like constructs have been shown to be useful for mathematical reasoning as problem generators for stress-testing models. However, prior work has been limited to automatically constructing abstractions for grade-school math (whose simple rules are easy to encode in programs), while generating EFAs for advanced math has thus far required human engineering. We explore the automatic construction of EFAs for advanced mathematics problems by developing EFAGen, which operationalizes the task of automatically inferring an EFA for a given seed problem and solution as a program synthesis task. We first formalize the properties of any valid EFA as executable unit tests. Using execution feedback from the unit tests, we search over candidate programs sampled from a large language model (LLM) to find EFA programs that are faithful to the generalized problem and solution class underlying the seed problem. We then apply the tests as a reward signal, training LLMs to become better writers of EFAs. We show that EFAs inferred by EFAGen are faithful to the seed problems, produce learnable problem variations, and that EFAGen can infer EFAs across diverse sources of competition-level math problems. Finally, we show uses of model-written EFAs, such as finding problem variations that are harder or easier for a learner to solve, as well as data generation.", "tldr": "", "keywords": ["math", "program synthesis", "abstraction learning", "program induction", "rule learning", "synthetic data"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cf1c51413066d8afc18e8e383b5df2e3ffbb7272.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a new form of synthetic data generation for mathematical reasoning based on EFA's (Executable Functional Abstractions). An EFA is a parameterized abstraction of a math problem that can generate new instances of a problem with the same structure but different input numbers and a different solution number. First, the authors propose a process for generating EFA's with an LLM. They find that conducting iterative fine-tuning on successfully generated EFA's improves a base model's ability to generate EFAs. They show that prompting a LLM to solve a problem given a solution to an EFA-derived example improves performance compared to solving the problem alone. They last show that fine tuning on EFA-derived problems improves performance on MATH-500 and FnEval, whether on its own or combined with other synthetic generation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- EFA's are a principled way to augment data for mathematical problems.\n- The authors conduct an extensive variety of experiments on generating EFA's and improving model performance using EFA's\n- Overall, the experiments are moderately well executed, although I have several questions about choices for fair comparison\n- Using an EFA for synthetic data generation is a general approach that could apply to a lot of domains\n- Given an existing solution, one can check EFA's for correctness with reasonable certainty, so it is a relatively safe form of data augmentation / synthetic data generation\n- In some sense, fine-tuning on EFA's can be thought of as one form of having the model \"self-train\" on new instances of the same problem, which is a significant and original idea."}, "weaknesses": {"value": "I would put the weaknesses of this paper in three main categories:\n\nW1. Limited novelty and impact of the approach and results\n    \n- Once you understand the definition of an EFA, their usefulness, implementation, and how to discover them is quite simple. However, the authors do a drawn-out presentation of the definition, desiderata, implementation, and verification of EFA's in section 2. To me, this is not much of a contribution, and the presentation is drawn out. For example, section 2.2 is entirely about how to implement EFA's in Python, which is too simple to be in the main text, and probably can be left out of the paper entirely.\n    \n- The authors originally present the task of inferring EFA's from a concrete problem as a challenge, but then use simple methods to do so: prompt a LLM to generate an EFA given a problem and its solution, then check for correctness. \n    \n- The authors show that showing a solution to an EFA-derived similar problem in context to a problem improves a model's performance, but this is not surprising to me, given how similar EFA-derived problems are.\n    \n- The main benefit of EFA's would be in a data augmentation scheme (sections 3.4 and 3.5). However, the performance improvement from EFA augmentation is quite small (~2-3% on average). Moreover, the increase in performance is only shown for a single 8B model, and it's unclear whether the method will help more capable models. \n\nW2. Some evaluations could be more fair\n    \n- For Table 1, the data generation process could bias the results in favor of EFA's. To start, only problems are used with pass rate < 50% and for which EFAGen can successfully infer an EFA. This is the type of problem that using an EFA would help the most. This is okay for saying an effect exists, but this overstates the overall average benefit of using EFA's, which the percent improvement numbers could be construed to mean.\n    \n- For section 3.4 and Table 2, a potential confounder of the benefit of EFA's is that the EFA-models are trained with more data. What if you control the number of total examples the model is fine-tuned on? For example, instead of 7500 teacher problems and 7500 EFA problems, you could compare 7500 teacher problems with 3750 teacher problems and 3750 EFA problems. This seems like a fair comparison to include.\n    \n- Similarly, for section 3.5 and Table 3, different methods (rows) might have a different number of total training examples. How does the number of examples for each of the data mixes vary, and what happens if you control the number of examples to be the same?\n\n\nW3. Writing quality and presentation\n    \n- The paper overelaborates on much of the material, making it long and fluff. For example, section 2.2 is entirely about how to implement EFA's in Python, which is too simple to be in the main text, and probably can be left out of the paper entirely. Other sections draw out what could be simple explanations, perhaps to make the contribution seem larger.\n    \n- The abstract is unusually long. The introduction is surprisingly long too, taking over 3 pages of the paper. This is more than the main experiments which take up less than 3 pages.\n    \n- There is a lack of precision in much of the writing, and many claims are overexaggerated. For example, in the introduction, the authors state, \"Our central research question is: How can we automatically transform static math problems into their corresponding executable functional abstractions (EFAs)?\" — but if this is the central research question of the paper, then the answer is simple: prompt a LLM to generate an EFA, and check for correctness. The value of the paper, I would argue, lies not in the ability to generate EFA's but in the evaluation of the potential of EFA's for data augmentation.\n    \n- Some parts are vague: line 139: \"We first show that EFAs have properties signaling their coherence.\" — Is this the EFA's created by the LLM, or EFA's in general?\n    \n- Overall, I think the paper could be shortened by 2-3 pages while still preserving the important main content."}, "questions": {"value": "Q1. For section 3.4 and Table 2, a potential confounder of the benefit of EFA's is that the EFA-models are trained with more data. What if you control the number of total examples the model is fine-tuned on? For example, instead of 7500 teacher problems and 7500 EFA problems, you could compare 7500 teacher problems with 3750 teacher problems and 3750 EFA problems.\nQ2. How does the number of examples for each of the data mixes vary, and what happens if you control the number of examples to be the same?\nQ3. For Table 1, what percent of tasks have pass@5 rate < 50% and EFAGen can infer an EFA? What do the numbers look like if you do it over all tasks that EFAGen can infer an EFA on?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qKgz0rcfCp", "forum": "Wrte87s2Bs", "replyto": "Wrte87s2Bs", "signatures": ["ICLR.cc/2026/Conference/Submission21279/Reviewer_eXQi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21279/Reviewer_eXQi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939826603, "cdate": 1761939826603, "tmdate": 1762941667529, "mdate": 1762941667529, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Executable Functional Abstractions (EFAs), programmatic representations that capture the underlying logic of math problems in parameterized form, and EFAGen, a method to automatically infer EFAs from static math problems using large language models (LLMs). An EFA is implemented as a Python class with three key methods: sample() (generates valid parameter sets), render() (produces natural language problem statements), and solve() (computes correct answers).\n\nThe authors operationalize EFA inference as a program synthesis task, using an overgenerate-and-filter approach where multiple candidate EFAs are sampled from an LLM and validated against automated unit tests. They demonstrate that: (1) LLMs can self-improve at EFA generation using execution feedback as rewards, (2) EFAs faithfully capture seed problem solutions, (3) EFA-generated variants are learnable, and (4) EFAs effectively augment existing math datasets. The work extends beyond grade-school arithmetic to competition-level mathematics (MATH, AMC, AIME, Olympiads)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Originality: This is the first automated method to infer functional abstractions for competition-level mathematics. Novel application of execution-based verification to constrain problem generation, and creative use of unit tests as reward signals for self-training.\n\n2. Quality: Rigorous experimental methodology with proper ablations (Table 8), comprehensive evaluation across diverse problem sources (Table 6, Figure 5), strong empirical results showing consistent improvements, and thorough appendix with implementation details and qualitative examples.\n\n3. Clarity: Well-structured paper with clear motivation. The figures effectively communicate key concepts. Concrete examples throughout (especially Appendix G) and good balance of technical depth and accessibility.\n\n4. Significance: This addresses a real limitation in math reasoning evaluation (reasoning gap). It enables practical applications for data augmentation and curriculum learning, and scalable generation of verified problem variants."}, "weaknesses": {"value": "Major:\n\n1. Limited analysis of what makes a \"good\" abstraction. The paper validates that EFAs pass unit tests and enable learning, but does not deeply analyze whether they capture the intended mathematical abstraction. Example: For the GCD/LCM problem (Fig 1), does the EFA capture \"problems about GCD/LCM relationships\" or just \"problems with those specific parameters\"?\nAlso missing: analysis of abstraction granularity, when are abstractions too specific or too general?\n\n2. Evaluation of faithfulness is circular. Section 3.2 measures faithfulness by whether EFA variants help solve the seed problem. Yet, this does not prove the EFA captured the correct generalization, it might just be generating similar problems. Suggestion: Include human evaluation of whether sampled variants test the same mathematical concepts.\n\n3. Incomplete failure analysis. What percentage of problems in MATH can be successfully abstracted? (Only partial data in Fig 4) What types of problems systematically fail? (Geometry? Proofs? Multi-step reasoning?) What happens when the seed solution is incorrect? Missing error analysis would help understand limitations.\n\n4. Computational cost not discussed. Generating 50 candidates per problem with filtering is expensive. No analysis of computational costs vs. benefits. Also, no comparison of cost vs. simply prompting an LLM for variants. This would be important for practical deployment.\n\nMinor:\n\n5. Statistical significance testing. Many comparisons lack significance tests (e.g., Table 2 improvements). With small absolute improvements (+1.8-3.7%), statistical testing is important.\n\n6. Limited scope of augmentation experiments. Only tested on Llama 3.1-8B Base. Would stronger base models benefit less from augmentation? How does this compare to other augmentation methods (paraphrasing, backtranslation)?\n\n7. Claims. Title says \"Advanced Math Problems\" but many examples are still relatively basic. \"Automatically infer\" glosses over the 50-candidate sampling requirement. \"Faithful\" is claimed but not rigorously validated beyond circular metrics.\n\n8. Writing issues. Dense presentation trying to cover too many applications. Some sections feel rushed (e.g., adversarial search in Appendix D). Repetitive phrasing in related work."}, "questions": {"value": "Main questions:\n\n1. How do you validate that an EFA captures the intended mathematical abstraction? Your tests verify executability and consistency, but not semantic correctness. Have you done any human evaluation of whether EFA variants test the same concepts?\n\n2. What is the distribution of EFA quality? You report success rates, but among successful EFAs, how many are \"good\" abstractions?\nCan you provide examples of EFAs that pass tests but are poor generalizations?\n\n3. How sensitive is the approach to the seed problem's solution quality? What happens if the seed solution is incorrect or uses a suboptimal method? Do bad seeds produce bad EFAs?\n\n4. What are the computational cost analysis? What is the wall-clock time and cost to generate EFAs for MATH train set?\nHow does this compare to alternative approaches (prompting GPT-4 for variants)?\n\nImportant questions:\n\n5. Why does EFA-generated data outperform real data (Table 5)? This is a surprising and important result. Is it because of diversity? Quality? Something about the generation process?\n\n6. Can you provide more analysis on the adversarial search results (Fig 7)? 40-80% success at finding harder variants is intriguing. What makes these variants harder? Can you characterize them?\n\n7. How does abstraction granularity affect results? Do coarse-grained abstractions (more general) vs. fine-grained (more specific) perform differently? Is there an optimal level of abstraction?\n\n8. Have you compared with few-shot prompting for variant generation? How does EFAGen compare to simply prompting \"Generate 10 variants of this problem\"? When is the added complexity of EFAs worth it?\n\n\nMinor questions:\n\n9. Why does performance plateau at 16 examples/EFA (Table 7)? Is this a diversity issue? Overfitting?\n\n10. Can EFAs be composed or hierarchically organized? Can you build meta-EFAs that sample from multiple EFA types?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "odxnq123UA", "forum": "Wrte87s2Bs", "replyto": "Wrte87s2Bs", "signatures": ["ICLR.cc/2026/Conference/Submission21279/Reviewer_RC2i"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21279/Reviewer_RC2i"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956217012, "cdate": 1761956217012, "tmdate": 1762941667266, "mdate": 1762941667266, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper describes a method to abstract mathematical problems and solutions into a programmatic representation, Executable Functional Abstraction (EFA), that can be used to systematically create variations of mathematical problems, with solutions. The paper proposes a pipeline to automatically extract EFAs from existing datasets, which includes both representing the solution as a Python program, as well as giving procedures for (a) sampling valid parameters for the problem, and (b) validating constraints on the parameters that might not be enforced by construction during sampling. Experiments with datasets derived from MATH (Original MATH, MATH(), MATH-Hard) and Llama 3.1-Instruct 8B show that the model can extract EFAs with reasonable baseline performance, which can be improved with iterative fine-tuning, that using solutions to problem variants generated with EFAs as in-context examples significantly improves performance (showing faithfulness), and that EFAs can serve to produce useful examples for data augmentation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles an important problem of how to improve model reasoning performance without collecting more human data. The idea to systematically extend and generalize existing datasets using a programmatic representation is sensible, and the paper proposes a simple pipeline to achieve that.\n\nThe paper is very clear and easy to follow. I have no major issues with the experimental design, and the results are clear."}, "weaknesses": {"value": "The idea of having a programmatic representation for mathematical problems and using that to sample variants is not entirely new, given both GSM-Symbolic and MATH() (here called FnEval). The paper goes beyond those in that it goes beyond grade-school problems (unlike GSM-Symbolic) and the extraction pipeline is automatic (unlike MATH() ). But, arguably the technical delta from those is small.\n\nI believe the main weakness of the paper is that the evaluation mostly shows \"internal validity\" of EFAs: the first two results argue that (1) models can extract (or improve at extracting) EFAs sucessfully from MATH-like problems, and that (2) the extraction is faithful, via the experiment of using EFA-generated variants as in-context examples. However, the main question the paper must answer is about \"external validity\": essentially, why are EFAs useful? The only result on this line is in using them as data augmentation for MATH (with and without Numina as a complement). While the paper shows positive results here, the improvement is generally small (< 5%), on a dataset and model that are already a bit behind. For instance, nowadays, Qwen-2.5-Math-Instruct 7B (so a similar scale to what was used here) already achieves 83% of pass@1 on MATH. Given this context, it's unclear whether this paper will indeed help push the field forward."}, "questions": {"value": "- Are the results in Figure 4 averaged over multiple runs, or was this a single run?\n- Is there a specific step in the pipeline to extract the parameters of the original problem in the EFA format? Otherwise, I don't see how you can implement \"matches_original\" in L249.\n- How does the \"is single valued\" check work (In 2.3)? Is it possible that the problem admits multiple solutions, but the EFA only captures one way to compute the answer? For instance, say the problem could be to find any prime factor of a given number N, but the EFA solution always finds the smallest, and thus the EFA would appear to be \"single valued\" even though the original problem was not.\n- Do the improvements from data augmentation carry over to AIME, which is currently a more relevant dataset to push performance on? There are many fewer available training problems at the AIME level, and I imagine EFAs could have a larger impact there compared to MATH."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ATnkYV8vkB", "forum": "Wrte87s2Bs", "replyto": "Wrte87s2Bs", "signatures": ["ICLR.cc/2026/Conference/Submission21279/Reviewer_hmuz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21279/Reviewer_hmuz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762117376330, "cdate": 1762117376330, "tmdate": 1762941666940, "mdate": 1762941666940, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper shows an approach to synthetic data generation. A common approach to improving LLM accuracy in a domain is by collecting more domain specific data and then using that data to finetune the LLM or providing that data for in-context learning examples in the prompt. If an initial human curated math question/solution training set is provided, this paper describes a system for analyzing the training set problems, creating a template for each training problem automatically using LLMs, and then using the templates to generate more similar problems to use as training data, and filtering that data for problems that an LLM can do reasoning steps and finds a correct solution, to provide more problem/solution pairs for finetuning, which can be much cheaper/faster than trying to collect more training problems/solutions from humans. The paper shows one such approach, Executable Functional Abstraction (EFA), a math abstraction that encapsulates the logic of a math problem in a parameterized form, enabling the automated sampling of variant problems and shows that it can be successfully applied to common math datasets like GSM8K."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The synthetic data generation task is important and relevant to LLM improvement.\nA specific method for synthetic data generation is shown, with code and models provided, which would be useful for other researchers trying to advance the state of the art.\nExperiments are done showing the method works for generating samples that improve the LLM accuracy when used for finetuning or as in context learning examples."}, "weaknesses": {"value": "Compared to other papers that have shown how to do synthetic data generation, it's not clear this is a significantly better approach than other synthetic data generation approaches, I don't feel like it was compared to other approaches in the literature for generating a synthetic dataset and getting better results. \n\nIt's not clear what types of problems this method has problems generating underlying problem generators for, not so much discussion of that."}, "questions": {"value": "Will the code for the project be released open source?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kiZb4cQCsS", "forum": "Wrte87s2Bs", "replyto": "Wrte87s2Bs", "signatures": ["ICLR.cc/2026/Conference/Submission21279/Reviewer_v6zH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21279/Reviewer_v6zH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762410135794, "cdate": 1762410135794, "tmdate": 1762941666722, "mdate": 1762941666722, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce the problem of synthesizing *executable functional abstractions* (EFAs), which are parameterized programs that generate math problems of diverse kinds. They define what it means for an EFA to be valid for a given concrete math problem, and introduce EFAGen, which generates valid EFAs by sampling and filtering from an LLM. They demonstrate self-training to improve EFAGen, and use experiments to show that EFAGen generates faithful and learnable EFAs. Finally, the authors show the utility of EFAs as a method for data augmentation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. *Originality:* The idea of using general programs to represent abstractions of concrete natural language math problems is novel.\n2. *Significance:* Executable functional abstractions are an effective method for data augmentation of natural language math problem datasets."}, "weaknesses": {"value": "1. The proposed method for generating EFAs is not novel; it simply reuses existing methods — LLM sampling + filtering + self-training with rejection sampling.\n2. I can see two possible interpretations of the purpose of Section 3.2. But Section 3.2 appears weak to me under both interpretations.\n  - The goal of Section 3.2 is to show how the solve rate on a problem can be improved by an in-context example of the solution to an EFA-generated variant problem. But EFAGen requires already knowing the solution to the original problem. So in fact Section 3.2 does not actually provide a method for improving the solve rate on a problem using an EFA-generated in-context example.\n  - The goal of Section 3.2 is to show that an in-context example showing how to solve a problem improves the LLM’s success rate of solving the same problem but with some parameters modified. But this is already a known fact.\n3. Similarly, Section 3.3 seems to just show that an in-context example showing how to solve a problem improves the LLM’s success rate of solving the same problem but with some parameters modified. This is already a known fact.\n\nOverall, I think the narrative of the paper can be strengthened. Currently, this is how I’m reading the paper:\n- EFAs are programs that generate variants of a concrete natural language problem with parameters modified — “That’s cool, but why would we want them?” I think the first paragraph of the introduction can do a better job of motivating the need for EFAs.\n- We generate EFAs using an LLM; we can also finetune LLMs using EFAs from rejection sampling — “But I already know that LLMs can generate code and rejection sampling can be used to finetune LLMs for generating code.”\n- EFA-generated problem variants can be used as in-context examples to improve performance — “But I already know this.”\n- EFA-generated problems can be used as data augmentation — “Ah, so this is why we wanted EFAs in the first place! EFAs are a data augmentation technique. Wait, this section is already over? I wanted to understand more about EFAs as a data augmentation technique!” (See Question 1 below.)\n\nI can see a much stronger version of the paper where the central message is “EFAs work well as a data augmentation technique” and the majority of the paper is devoted to conveying that message, as opposed to (essentially) reproducing known facts."}, "questions": {"value": "1. Sections 3.4 and 3.5 demonstrate how EFAs can be used as a data augmentation technique, but there is not much analysis regarding how they compare with existing data augmentation techniques. For example, I would like to understand what are the advantages and disadvantages of existing techniques vs. EFAs, and when I should use particular existing techniques, EFAs, or both."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Wc3QyJk4hF", "forum": "Wrte87s2Bs", "replyto": "Wrte87s2Bs", "signatures": ["ICLR.cc/2026/Conference/Submission21279/Reviewer_buZc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21279/Reviewer_buZc"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission21279/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762660922960, "cdate": 1762660922960, "tmdate": 1762941666484, "mdate": 1762941666484, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}