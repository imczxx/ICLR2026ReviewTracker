{"id": "RBIBMCdw7y", "number": 20963, "cdate": 1758312095196, "mdate": 1759896949658, "content": {"title": "The Intricate Dance of Prompt Complexity, Quality, Diversity and Consistency in T2I Models", "abstract": "Text-to-image (T2I) models offer great potential for creating virtually limitless synthetic data, a valuable resource compared to fixed and finite real datasets. Previous works evaluate the utility of synthetic data from T2I models on three key desiderata: quality, diversity, and consistency. While prompt engineering is the primary means of interacting with T2I models, the systematic impact of prompt complexity on these critical utility axes remains underexplored. In this paper, we first conduct synthetic experiments to motivate the difficulty of generalization w.r.t. prompt complexity and explain the observed difficulty with theoretical derivations. Then, we introduce a new evaluation framework that can compare the utility of real data and synthetic data, and present a comprehensive analysis of how prompt complexity influences the utility of synthetic data generated by commonly used T2I models. We conduct our study across diverse datasets, including CC12M, ImageNet-1k, and DCI, and evaluate different inference-time intervention methods. Our synthetic experiments show that generalizing to more general conditions is harder than the other way round, since the former needs an estimated likelihood that is not learned by diffusion models. Our large-scale empirical experiments reveal that increasing prompt complexity results in lower conditional diversity and prompt consistency, while reducing the synthetic-to-real distribution shift, which aligns with the synthetic experiments. Moreover, current inference-time interventions can augment the diversity of the generations at the expense of moving outside the support of real data. Among those interventions, prompt expansion, by deliberately using a pre-trained language model as a likelihood estimator, consistently achieves the highest performance in both image diversity and aesthetics, even higher than that of real data. Combining advanced guidance interventions with prompt expansion results in the most appealing utility trade-offs of synthetic data.", "tldr": "", "keywords": ["text-to-image models", "prompt complexity", "synthetic data"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ec912f0228b10ca5bd7348958728be734aa9aeb3.pdf", "supplementary_material": "/attachment/19f32551040643a1e2887ebe2e8ce7caa29f875a.zip"}, "replies": [{"content": {"summary": {"value": "This paper analyzes how prompt complexity affects the quality, diversity, and text-image alignment of text-to-image (T2I) generations. Through synthetic and large-scale experiments, the authors show that generalizing to simpler (more general) prompts is inherently harder for diffusion models. Increasing prompt complexity reduces diversity and consistency but narrows the gap to real data. Among inference-time methods, prompt expansion using large language models to enrich prompts consistently improves image quality and diversity, and combining it with advanced guidance yields the best trade-offs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- It is interesting to investigate the relationship between prompt complexity and the utility of generative models, including quality, diversity, and text-image alignment.\n\n- The paper provides several insightful observations, such as the generalization asymmetry between simple and complex prompts and the non-monotonic improvement of quality as complexity increases.\n\n- The authors propose an improved sampling strategy that combines prompt expansion with advanced diversity samplers (e.g., APG), based on the observation that moderately complex prompts can enhance generation quality."}, "weaknesses": {"value": "- **Lack of new messages.** Apart from the findings on generalization asymmetry and non-monotonic quality trends, most conclusions (e.g., that LLM-based prompt expansion increases diversity) are fairly predictable or already known.\n\n- **Weak application value.** Except for the combined sampler (e.g., prompt expansion + APG), the study remains largely descriptive and provides limited guidance for improving model performance.\n\n- **Clarity and focus.** The paper covers a large number of datasets, models, and metrics, which sometimes dilutes the main narrative and makes it harder to pinpoint the central contribution.\n\n- **Limited theoretical depth.** Although the paper provides a toy Gaussian experiment and a theoretical discussion, the analysis remains relatively shallow and does not fully explain why diffusion models exhibit the observed asymmetry beyond intuitive reasoning.\n\n- **Evaluation bias toward LDM family.** The study mainly focuses on LDM variants, leaving uncertainty about whether the conclusions generalize to non-diffusion architectures or transformer-based T2I models.\n\n- **No user evaluation.** The work focuses entirely on metric-based analyses without human validation to confirm the practical implications of prompt complexity."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cm5PAOqkzG", "forum": "RBIBMCdw7y", "replyto": "RBIBMCdw7y", "signatures": ["ICLR.cc/2026/Conference/Submission20963/Reviewer_CGJq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20963/Reviewer_CGJq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20963/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761743079989, "cdate": 1761743079989, "tmdate": 1762939057787, "mdate": 1762939057787, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a systematic analysis of how prompt complexity influences the quality, diversity, and consistency of synthetic data from text-to-image models. It establishes that increasing prompt complexity reduces diversity and consistency while improving the realism of generated images. The authors provide theoretical insight, showing that models struggle to generalize to general prompts, and introduce a comprehensive benchmarking framework for evaluation. Their large-scale empirical study identifies prompt expansion combined with advanced guidance like APG as the most effective approach for achieving optimal utility trade-offs in synthetic data generation."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1.Introduces the novel problem of systematically evaluating \"prompt complexity\" in T2I models, combining theoretical insight (\"OR\" vs. \"AND\" generalization) with practical interventions.\n\n2.Methodologically rigorous, featuring a well-designed benchmarking framework, compelling synthetic experiments, and a large-scale, comprehensive evaluation across models and datasets.\n\n3.Exceptionally well-structured and clearly written, with a logical narrative flow and effective figures that make the complex study accessible and reproducible.\n\n4.Provides crucial guidance for synthetic data generation and model evaluation, revealing fundamental trade-offs and setting an important agenda for future T2I model development."}, "weaknesses": {"value": "1.The paper relies on the DSG score for consistency evaluation but does not critically address its known limitations with very long, complex prompts (as in the DCI dataset). As prompt length increases, the VQA models underlying DSG may themselves fail, potentially conflating model inconsistency with VQA model error. A targeted analysis, such as a human evaluation on a subset of long prompts to verify DSG's correlation with human judgment in this regime, is needed to ensure the reported consistency drop is reliable.\n\n2.While prompt expansion is highlighted as a powerful intervention, the paper provides a limited discussion of its significant downside: it actively moves generations outside the support of the reference real data (as shown by reduced precision/density). This is a critical trade-off that is under-explored. The work would be improved by a deeper analysis of when this \"hallucination\" is beneficial (e.g., for data augmentation) versus detrimental (e.g., for faithful dataset replication), framing it not just as a boost in diversity but as a fundamental shift in the data distribution."}, "questions": {"value": "1.The authors rely on the DSG score for consistency evaluation. Could they clarify how they ensured this metric's validity for the very long, complex prompts from the DCI dataset? Providing a small-scale human evaluation to correlate with the DSG scores on these long prompts would help solidify the consistency findings.\n\n2.The authors note a drop in consistency for highly complex prompts. Could they comment on the semantic plausibility of these generations? Is the failure primarily in missing attributes, or also in generating globally incoherent scenes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QvEQfe8H6Y", "forum": "RBIBMCdw7y", "replyto": "RBIBMCdw7y", "signatures": ["ICLR.cc/2026/Conference/Submission20963/Reviewer_PuV8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20963/Reviewer_PuV8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20963/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892030532, "cdate": 1761892030532, "tmdate": 1762939057121, "mdate": 1762939057121, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies how prompt complexity (length/specificity) affects the quality, diversity, and prompt-consistency of images generated by text-to-image (T2I) models. It first uses a toy Gaussian setup with derivations to argue that generalizing from fine-grained training prompts to more general prompts is intrinsically harder (likelihood weighting is missing in standard diffusion), then introduces a benchmarking framework that builds multi-complexity prompts from CC12M, ImageNet-1k, and DCI and evaluates several open T2I models and inference-time interventions. Large-scale experiments show: increasing complexity reduces diversity and consistency, while aesthetics first rise then fall as prompts lengthen; prompt expansion improves diversity/aesthetics but may move generations off the real-data manifold; combining expansion with advanced guidance yields the best trade-offs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Writing & clarity. The paper is clearly written and easy to follow, with a logical flow (synthetic intuition → framework → large-scale evaluation), helpful figures, and explicit definitions of each utility axis and metric. Reproducibility details (datasets, hyperparameters, code note) are thorough.\n\n2. Comprehensive, reproducible evaluation framework. The authors propose a general framework (captioning → pairing → cross-complexity alignment → sampling → generation) that enables fair comparison between real and synthetic data across complexities, and they test multiple model families (LDM v1.5/v3.5, SDXL, etc.) and guidance strategies (CFG, CADS, Interval, APG) plus prompt expansion, with both reference-free (Vendi, aesthetics, DSG) and reference-based (FDD, precision/density/coverage) metrics—this breadth is valuable for practitioners."}, "weaknesses": {"value": "1. Findings mostly expected; limited novelty. Many conclusions—e.g., higher prompt complexity reduces diversity/consistency, prompt expansion increases diversity but can harm faithfulness—align with common practitioner intuitions and prior observations.\n\n2. No concrete method to handle complexity. The work is primarily evaluative. It surfaces that general prompts are hard because diffusion lacks likelihood weighting and that expansion/guidance can trade off axes—but it stops short of proposing a principled, train-time solution."}, "questions": {"value": "Your work studies semantic composition in prompts. A general question is, could LLM-derived semantics be used during training to improve robustness to complex or general prompts? \n\nAlso please see the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lDqsnYtQLd", "forum": "RBIBMCdw7y", "replyto": "RBIBMCdw7y", "signatures": ["ICLR.cc/2026/Conference/Submission20963/Reviewer_N9uF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20963/Reviewer_N9uF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20963/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982910341, "cdate": 1761982910341, "tmdate": 1762939056570, "mdate": 1762939056570, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how prompt complexity affects synthetic data utility from T2I models across quality, diversity, and consistency axes. The authors (1) conduct synthetic experiments on Gaussian mixtures with theoretical derivations, (2) introduce an evaluation framework comparing real vs. synthetic data, and (3) perform large-scale empirical analysis across CC12M, ImageNet-1k, and DCI datasets with multiple T2I models and inference-time interventions. Key findings: increasing prompt complexity reduces diversity and consistency but narrows the real-synthetic gap; prompt expansion consistently improves diversity and quality; combining advanced guidance with prompt expansion yields optimal trade-offs"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Important and underexplored research question.** This is the first systematic study of how prompt complexity affects T2I synthetic data utility. Given the widespread use of T2I models for data generation and the common practice of training on synthetic captions, understanding this relationship is timely and valuable.\n    \n- **Well-designed evaluation framework.** The 5-step pipeline (captioning, pairing, alignment, sampling, generation) enables fair comparisons between real and synthetic data across prompt complexities, a non-trivial methodological contribution that could benefit future work.\n    \n- **Comprehensive empirical evaluation.** The study covers multiple datasets (CC12M, ImageNet-1k, DCI), models (LDMv1.5/XL/v3.5M/v3.5L, Flux, Infinity), inference methods (CFG, CADS, Interval, APG, prompt expansion), and metrics (reference-free: Vendi, aesthetic, DSG; reference-based: FDD, precision, density, coverage), providing thorough coverage.\n    \n- **Human validation strengthens metric choice.** The human evaluation (Appendix E) shows Vendi score strongly correlates with human-perceived diversity, validating the automatic diversity metric.\n    \n- **Illustrative toy example provides intuition.** The synthetic Gaussian mixture experiments (Section 2) with mathematical derivations (Appendix A.2) offer clear intuition for why generalizing to general prompts is harder, nicely complementing the empirical findings."}, "weaknesses": {"value": "- **Independence assumptions in theoretical derivations may not hold for real text encoders.** The synthetic experiments (Section 2, Appendix A.2) derive score functions assuming conditional independence of text concepts. Specifically, Equations 5-7 assume that for fine-grained conditioning $c_f$ composed of general concepts ${c^i_g}$, we have $p(x_t, c^1_g, c^2_g, ..., c^K_g) = p(x_t) ∏_{i} p(c^i_g|x_t)$. However, real text encoders (CLIP, T5) do not treat concepts as independent: (1) they encode compositional phrases where \"white\" modifying \"dog\" produces entangled representations rather than separable \"white\" and \"dog\" signals, (2) they learn correlations from training data where certain concept combinations (e.g., \"white dog\") appear frequently, making $p(c^1_g|x_t, c^2_g) ≠ p(c^1_g|x_t)$, and (3) concept embeddings are context-dependent and non-orthogonal in the latent space. Similarly, the OR operator derivation (Equation 1) requires fine-grained categories to be exhaustive and mutually exclusive, which may not align with how models internally represent general concepts. The Gaussian mixture model provides valuable intuition, but the theoretical predictions should be interpreted cautiously when applied to real T2I models. The authors should discuss this gap and consider how it might affect the interpretation of their results. \n- **The alignment step lacks transparency and may introduce selection bias.** Algorithm 1 iteratively removes images not shared across complexities, but provides no analysis of what is discarded. Table 1 shows complexity-4 prompts cover only 46,066 images vs. 61,334 for complexity-1, a 25% reduction. What visual or semantic characteristics differentiate retained vs. discarded images? If alignment preferentially keeps images easier to describe with detailed prompts (e.g., clear objects vs. abstract scenes), this biases the evaluation set. Do discarded images have different mean aesthetic quality, diversity, or complexity than retained ones? Without this analysis, it is difficult to disentangle the genuine effects of prompt complexity from potential artifacts introduced by the evaluation pipeline itself."}, "questions": {"value": "- **Can you characterize discarded images in the alignment step?** Specifically, do they have different mean aesthetic quality, object count, scene complexity, or semantic diversity compared to retained images? This would help assess whether the observed trends are artifacts of selection bias.\n- **On Theoretical Assumptions:** Could you discuss the validity of the conditional independence assumption (Appendix A.2) in the context of compositional text encoders like CLIP? How might the violation of this assumption, where concepts like \"red\" and \"car\" are highly correlated and compositionally represented, affect the interpretation that generalizing to general prompts is inherently \"harder\" than generalizing to fine-grained ones? Could this theory-practice gap also explain some of the divergent behaviors observed between the CC12M and ImageNet experiments?\n- **Can you provide confidence intervals or significance tests for main trends?** With 5,000 prompts per complexity, bootstrapped confidence intervals for Vendi, aesthetic, and FDD would strengthen claims about trends and help assess how statistically significant differences between adjacent complexity levels are."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uMwGgF430R", "forum": "RBIBMCdw7y", "replyto": "RBIBMCdw7y", "signatures": ["ICLR.cc/2026/Conference/Submission20963/Reviewer_QZqM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20963/Reviewer_QZqM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20963/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762444442306, "cdate": 1762444442306, "tmdate": 1762939056004, "mdate": 1762939056004, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}