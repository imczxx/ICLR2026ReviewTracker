{"id": "2FiNJ20GQU", "number": 11007, "cdate": 1758186722517, "mdate": 1759897615004, "content": {"title": "In-Context Alignment: Resolving Representation Conflict for Parameter-Efficient Forgery Detection in Vision Models", "abstract": "Vision Foundation Models (VFMs) have shown remarkable potential in image forensics, yet their content-driven representations often suppress the subtle forensic cues essential for manipulation localization, thereby exhibiting an inherent representation conflict. Conventional full fine-tuning struggles to address this conflict, as it demands extensive parameter updates, risks overfitting, and erodes prior knowledge, leading to poor generalization in diverse forgery detection scenarios. We propose In-Context Alignment (ICA), a parameter-efficient framework that reframes forgery localization as a visual in-context learning task. ICA introduces two complementary prompting mechanisms within frozen VFMs: a Physical-Aware Prompter (PAP) that enhances suppressed low-level forensic signals such as noise and frequency artifacts via a Mixture-of-Experts for adaptive fusion, and a Semantic-Aware Prompter (SAP) that encourages the model to expose semantic inconsistencies in high-level features. \nWith only a small fraction of parameters updated, ICA achieves strong performance across diverse image forgery localization benchmarks and can even compete with fully fine-tuned models. Our results demonstrate that in-context alignment of semantic and forensic representations offers a scalable, robust, and efficient paradigm for advancing visual forensics.", "tldr": "", "keywords": ["representation conflict", "prompt learning", "visual forensics", "parameter-efficient learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/eee3a4318b8b278c153137c63d75ea746302c308.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a new transformer based architecture for image forgery localization and detection. They use an existing pretrained vision transformer and augment it using adapter layers termed PAP and SAP. The additional layers are aimed at transforming the intermediate token representations with noise and semantic features necessary for forgery detection.\n\nThe contributions of the paper include \n- A novel approach to incorporate noise level features to align the token representations to the goal without training or finetuning the base model.\n- A mixture of experts approach to combine multi-domain features to enhance token representation\n- Empirical evidence to support the claims"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The objective of reducing the distance between latent representation of content tokens and noise tokens is a good approach to tackling IFLD task. One of the major challenges of this domain is how to utilize existing pretrained models effectively without representation collapse.\n- The paper proposes a physical aware module that combines different noise and latent features of the input using mixture of experts fusion. They also handle the problem of expert balancing by tuning the loss function.\n- The authors focus on parameter efficiency and minimizing complexity which is clearly explained in the section on complexity.\n- The authors perform extensive experimental evaluation of various datasets and benchmarks, which show state of the art results\n- The paper is well written and clearly explains what steps were followed to achieve the results"}, "weaknesses": {"value": "- The paper does not include any analysis of how each feature / module effects the final performance. For example, how much do the noise feature, or frequency features, or the semantic features have an effect on the final prediction?\n- The paper does not have any new major contribution to the task of image forensics in general. Almost all works in this field use the same standard combination of noise filters, frequency filters, and combine them with image features for the final detection. Although it might be interesting to see how the feature fusion strategy might work in different domains or a different context, in terms of IFLD, this work does not propose any major new contribution."}, "questions": {"value": "- What is the motivation of using moe fusion? The goal of using mixture of experts is to reduce inference complexity by reducing the number of active parameters. To this end moe models only activate certain experts for some specific token. But the current framework focuses on all experts being equally weighted so that all the different noise features are used by the model. If this is the case why not just concatenate or combine the features in a different way? The usefulness of using moe needs more justification.\n- The model was trained only using CASIAv2 which  does not have any inpainting or neural forgery samples. However the model still shows high accuracy on datasets like Nist16 or DEF12k which have a large portion of inpainting samples. I request the authors to perform forgery specific evaluation to better understand the models capabilities.\n- The paper does not assess the limitations or failure cases of the model."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MiafKMU459", "forum": "2FiNJ20GQU", "replyto": "2FiNJ20GQU", "signatures": ["ICLR.cc/2026/Conference/Submission11007/Reviewer_cvu9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11007/Reviewer_cvu9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761749598346, "cdate": 1761749598346, "tmdate": 1762922188615, "mdate": 1762922188615, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes In-Context Alignment (ICA), a parameter-efficient framework for image forgery localization (IFL). ICA resolves the representation conflict in Vision Foundation Models (VFMs) by introducing two complementary prompting modules: the Physical-Aware Prompter (PAP), which amplifies low-level forensic cues, and the Semantic-Aware Prompter (SAP), which exposes high-level semantic inconsistencies. Built upon a frozen SegFormer backbone, ICA achieves robust localization with minimal trainable parameters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly identifies and analyzes the limitations of Vision Foundation Models (VFMs) in image forgery localization, and designs corresponding modules to address deficiencies in both physical and semantic perception. The motivation is well-grounded, the methodology is logically derived from the problem analysis, and the overall framework achieves effective adaptation of VFMs with high efficiency.\n2. The paper presents clear and well-structured descriptions, with precise mathematical formulations and theoretically sound derivations that enhance the overall rigor and credibility of the proposed framework.\n3. The paper conducts extensive experiments under various evaluation settings, verifying the effectiveness and robustness of the proposed method."}, "weaknesses": {"value": "1. The datasets used in the experiments are outdated. Given the rapid progress of diffusion-based image editing in recent years and the emergence of new datasets such as RealEdit, incorporating more up-to-date benchmarks to enhance the practical relevance of the proposed IFDL framework in real-world scenarios.\n2. The design of the Embedding Expert within the PAP module lacks sufficient clarification. From its structural perspective, it appears to model features at a semantic level rather than a physical level.\n3. The ablation study is insufficient. The paper does not provide experimental evidence demonstrating the effectiveness of the PAP and SAP modules or their subcomponents. Moreover, in the Optimization section, the choice of weighting parameters for different loss terms lacks ablation analysis to justify their settings.\n4. Since efficiency is a key advantage of the proposed method, it is recommended to include additional metrics such as trainable parameters in Table 1 to provide a more comprehensive and quantitative comparison of efficiency."}, "questions": {"value": "Please  see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rzQNytW56h", "forum": "2FiNJ20GQU", "replyto": "2FiNJ20GQU", "signatures": ["ICLR.cc/2026/Conference/Submission11007/Reviewer_F8mB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11007/Reviewer_F8mB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761804932835, "cdate": 1761804932835, "tmdate": 1762922188224, "mdate": 1762922188224, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes In-Context Alignment (ICA), a parameter-efficient framework for image forgery localization that adapts vision foundation models using two modules. The authors argue that vision foundation models have a representation conflict between content-oriented and forgery-sensitive features. To combat this the authors propose two modules: a Physical-Aware prompter for low-level inconsistencies using a MoE design and a Semantic-Aware prompter for high-level inconsistencies. The foundation model backbone remains frozen, allowing for parameter-efficient updates. ICA is evaluated across a wide range of baselines under multiple training regimes and robustness experiments."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The representation conflict is a meaningful concept to introduce.\n- The proposed method is parameter-efficient whilst attaining strong generalization. \n- The paper contains an extensive list of performance and robustness experiments."}, "weaknesses": {"value": "- The representation conflict is only explored in terms of ICA for forgery detection and localization, which is a very indirect approach. It could have been explored more thoroughly by using full-finetuning and LoRA/probing as baselines for foundation models. This would show the magnitude of the conflict. \n- The evaluation is performed on outdated baselines, while recently published IFL papers such as FakeShield [1] and SAFIRE [2] report higher F1 scores on many of the datasets, and focus on more recent datasets. \n- The evaluation is performed on outdated datasets that focus on legacy edit methods such as splicing and copy-move. The AIGC dataset, CoCoGLIDE, is outdated as diffusion models have advanced significantly.  Even then, the author’s CoCoGLIDE result substantially underperforms the state-of-the-art: 33.9 F1 vs 63.5 F1 of SAFIRE  and 52.3 F1 of TruFor, which are left out of the comparison. Therefore, we highly doubt the relevance of the proposed method in the context of modern edits such as those in SIDA [3].\n- In the ablation, the model without the shared MLP performs best; we are unsure whether this is the chosen model. \n- The robustness evaluation is done only on images from NIST16, limiting the generalizability of the results. Further, it is unclear to us why JPEG compression with a quality factor of 100 is a valid test of robustness.\n- We identified several inconsistencies in Table 1. Specifically, we highlight two inconsistencies. In general, however, the authors report lower scores in this paper than in others that implement the same baselines.\n  - TruFor reports pixel F1 scores for (NIST16, Columbia, CASIAv1, Coverage) are (39.9,85.9,73.7,60), respectively. In the author’s paper, the scores for TruFor on those datasets are (26.8, 82.9, 53.2, 28) . This possibly means TruFor outperforms ICA but is misreported. \n  - Similarly, quoting the scores from the CAT-Net paper, we see a pixel-level localization IoU on NIST16 and Columbia of 68.41, 83.05, whereas the authors report 10.2 and 20.6, respectively.\n\n\n[1] Xu, Z., Zhang, X., et al. (2025). FakeShield: Explainable image forgery detection and localization via multi-modal large language models. In Proceedings of the International Conference on Learning Representations (ICLR 2025).​\n\n[2] Kwon, M.-J., Lee, W., et al. (2025). SAFIRE: Segment any forged image region. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2025).​\n\n[3] Huang, Z., Hu, J., Li, X., He, Y., Zhao, X., Peng, B., Wu, B., Huang, X., & Cheng, G. (2025). SIDA: Social media image deepfake detection, localization and explanation with large multimodal model. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2025)."}, "questions": {"value": "- Why are recent image forgery detection and localization models not included as baselines?\n- Why is AIGC capability only evaluated on CoCoGLIDE (2023) and only to 5 baselines?\n- Is the model “w/o shared MLP” the chosen model in the ablation Table 4?\n- Why is robustness evaluated only on NIST16, and what is the rationale for using JPEG quality factor 100?\n- Why are the TruFor and CAT-Net scores significantly lower in the authors’ paper vs. other papers (TruFor paper, FakeShield [1], CAT-NET, SAFIRE [2])?\n\n[1] Xu, Z., Zhang, X., et al. (2025). FakeShield: Explainable image forgery detection and localization via multi-modal large language models. In Proceedings of the International Conference on Learning Representations (ICLR 2025).​\n\n[2] Kwon, M.-J., Lee, W., et al. (2025). SAFIRE: Segment any forged image region. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2025).​"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hx9f2WO14G", "forum": "2FiNJ20GQU", "replyto": "2FiNJ20GQU", "signatures": ["ICLR.cc/2026/Conference/Submission11007/Reviewer_DnqJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11007/Reviewer_DnqJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901576042, "cdate": 1761901576042, "tmdate": 1762922187826, "mdate": 1762922187826, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose In-Context Alignment, a parameter-efficient framework that reformulates forgery localization as a visual in-context learning task. ICA introduces two complementary prompting modules within frozen VFMs Physical-Aware Prompter and Semantic-Aware Prompter. The designed modules jointly enhance low-level forensic signals and encourage the model to highlight semantic inconsistencies in high-level features. The intra-domain, cross-domain, and ablation experiments well supported the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is well-organized, and the experimental results are comprehensive and convincingly support the proposed method."}, "weaknesses": {"value": "- Previous MLLM-based forensics models primarily focus on the textual explainability of model predictions. In contrast, this work only provides forgery mask predictions without any textual reasoning. Moreover, the cross-dataset generalization performance is inferior to previous methods on most unseen datasets.The motivation of using vision foundation model is unclear.\n\n- The manuscript claims that the feature representation  C can be decomposed as  C≈C_physical+C_semantic, and that the proposed method achieves a tighter bound. However, these claims lack rigorous theoretical analysis or formal derivation, which weakens the technical credibility of the argument.  \n\n- More comprehensive metrics such as F1 and IoU scores should be reported in the homologous-dataset evaluations to allow a more complete and interpretable assessment of model performance.  \n\n- The adopted data augmentation types overlap substantially with the perturbations used in robustness evaluation. This overlap may inflate the perceived robustness. In real-world applications, models often face more complex and unseen perturbations, which are not reflected in the current experimental setup.  \n\n- The claim that low-level artifact cues and high-level semantic cues are orthogonal components is not sufficiently justified or empirically validated. A deeper theoretical or statistical analysis would be needed to support this assumption.  \n\n- The role and quantitative contribution of the designated Embedding Expert module remain unclear. More justifications should be included to clarify its impact on the final performance.\n\nThe authors have overstated their method’s superiority and contributions in several parts of the manuscript.\n\n- In Tables 1 and 6, the captions claim that the best-performing results are highlighted in bold. However, the proposed method does not achieve the best performance on multiple datasets, such as NIST16, Columbia, IMD, COVER, DSO-1, In-the-Wild, and Korus. Despite this, these results are still shown in bold, which is highly misleading and potentially confusing to readers.\n\n- The authors repeatedly emphasize that their approach is efficient due to the use of PEFT. However, no complexity analysis or empirical evidence is provided to substantiate this claim. The paper must include quantitative evaluations of efficiency, such as FLOPs, training speed, GPU memory usage, and inference time.  \n\n- The claimed novelty and contributions are overstated. The use of PEFT has already been extensively explored in prior LVLM-based forensics studies, including So-Fake [a], SIDA [b], and FakeShield [c]. The concept of forensics-aware prompt learning for image forgery localization was introduced in ForgeryGPT [d]. The integration of low-level forensic and high-level semantic features within MLLMs has also been addressed in Propose and Rectify [e]. Additionally, the noise extractors adopted here (Bayar, Sobel, and SRM) are nearly identical to those used in [e]. The MoE mechanism has been extensively studied in prior forensics research and cannot be considered novel in this context.\n\n[a] So-Fake: Benchmarking and Explaining Social Media Image Forgery Detection\n\n[b] SIDA: Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model\n\n[c] FakeShield: Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models\n\n[d] ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization\n\n[e] Propose and Rectify: A Forensics-Driven MLLM Framework for Image Manipulation Localization"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "oZmOmJKp6P", "forum": "2FiNJ20GQU", "replyto": "2FiNJ20GQU", "signatures": ["ICLR.cc/2026/Conference/Submission11007/Reviewer_AaeU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11007/Reviewer_AaeU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916984469, "cdate": 1761916984469, "tmdate": 1762922187450, "mdate": 1762922187450, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}