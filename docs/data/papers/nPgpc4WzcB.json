{"id": "nPgpc4WzcB", "number": 8727, "cdate": 1758096241139, "mdate": 1759897767545, "content": {"title": "EDEL: Error-Driven Ensemble Learning for Imbalanced Data Classification", "abstract": "The class imbalance problem poses a critical challenge in high-stakes applications such as fraud detection, where the minority class often represents rare but consequential cases. In such settings, misclassifying minority instances can lead to substantial financial loss, underscoring the need for learning algorithms that remain reliable under severe imbalance. While deep learning methods have achieved remarkable success across various domains, their effectiveness often depends on large-scale datasets, and their black-box nature limits their interpretability, which is a critical requirement in high-stakes scenarios. To address this gap, we propose **E**rror-**D**riven **E**nsemble **L**earning (**EDEL**), an adaptive machine learning algorithm that dynamically introduces misclassified instances during training, thereby placing greater emphasis on hard-to-classify samples. Through theoretical analysis and extensive experiments on multiple real-world datasets, EDEL demonstrates strong effectiveness, particularly under challenging imbalanced conditions.", "tldr": "EDEL, which dynamically introduces misclassified instances to enhance model performance, particularly in extreme imbalance, as validated by extensive experiments on real-world datasets.", "keywords": ["Imbalanced Data Classification", "Machine Learning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4566fa5f4179c32883001e10154712b1889d72d8.pdf", "supplementary_material": "/attachment/3641817835f48e2f25179684f4808e1eb6ce88fb.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the class imbalance problem commonly encountered in high-stakes applications such as fraud detection, credit risk assessment, and medical diagnosis. The authors propose Error-Driven Ensemble Learning (EDEL), a new ensemble framework designed to emphasize hard-to-classify samples during training. EDEL reinjects misclassified instances into subsequent training rounds, refining decision boundaries and improving recognition of the minority class. Theoretical analysis using McDiarmid’s inequality and Bayes’ theorem is provided to justify the reduction in empirical error and the improvement in generalization. Extensive experiments on seven real-world datasets with varying imbalance ratios demonstrate that EDEL achieves superior performance in terms of AUC and F1-score compared to multiple baselines (SMOTE, RUS, CHRE, etc.) across four classifiers (DT, RF, XGB, and LGBM)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "(1) The paper introduces an error-driven ensemble learning framework (EDEL) that adaptively reinjects misclassified samples into the training process. This progressive emphasis on hard-to-classify instances offers a perspective on handling class imbalance beyond traditional resampling and cost-sensitive learning approaches. \n\n(2) The paper provides both theoretical justification and empirical validation across seven diverse real-world datasets with imbalance ratios ranging from mild to extreme. The reported performance improvements in AUC and F1-score across multiple classifiers (Decision Tree, Random Forest, XGBoost, and LightGBM) demonstrate the robustness and general applicability of EDEL. \n\n(3) The methodology is described in a stepwise and algorithmic manner (Algorithm 1), supported by mathematical definitions of “easy-to-classify” and “hard-to-classify” samples. The structure of the paper—problem definition, theoretical grounding, algorithmic description, and experiments—is logically coherent and easy to follow."}, "weaknesses": {"value": "(1) While the proposed “error-driven” mechanism is conceptually interesting, it largely resembles existing ensemble paradigms such as boosting, where misclassified samples are repeatedly emphasized during iterative training. The paper would benefit from a more explicit comparison and discussion of how EDEL fundamentally differs from or improves upon modern ensemble refinements. Without this clarification, the claimed novelty appears incremental.\n\n(2) The paper repeatedly claims that EDEL enhances interpretability, yet no concrete explanation mechanism (e.g., feature attribution, model introspection, or visualization) is presented, fixing hard samples does not equate to interpretability.\n\n(3) Key design choices such as the number of weak classifiers, subset partition strategy, and reinjection frequency are not systematically analyzed. An ablation or sensitivity analysis would clarify how these factors influence performance, stability etc."}, "questions": {"value": "The following are my concerns and questions:\n\n(1) In the introduction, the authors mention the general interpretability challenge in deep models but do not review or position existing interpretability tools (e.g., SHAP, LIME, or counterfactual explanation methods) relative to the imbalance problem. Without this, the motivation appears incomplete.\n\n(2) The statement that interpretability arises naturally from observing classifier errors is conceptually weak. Interpretability usually requires explicit mechanisms (e.g., feature importance, contribution maps). The authors should explain whether EDEL provides quantifiable interpretive outputs.\n\n(3) In the proposed method, the emphasis on misclassified samples resembles classical boosting techniques or ideas. The authors should clearly articulate how EDEL differs algorithmically or theoretically from these well-established methods.\n\n(4) Using unweighted parameter averaging may not be optimal, especially when subsets have varying difficulty or imbalance ratios. Why not adopt adaptive weighting or validation-based combination? And the average mechanism requires that these classifiers(e.g., deep models) have the same model architecture, limiting the diversity of these classifiers, them ultimately become homogeneous.\n\n(5) Furthermore, the definition of hard-to-classify samples does not distinguish between truly **ambiguous cases and mislabeled/noisy instances**. The reinjection of such noisy data might propagate errors instead of improving robustness. How the proposed methods solve this critical issue?\n\n(6) In the training process of EDEL, it seems the reinjection process only performs one iteration? I mean, what is the condition of ending \"while not done\"?  If the iteration is only 1, it is possible there are still many hard-classify samples for each classifier, then what's the point of the reinjection process? If not, what is the ending condition?\n\n(7) The algorithm description suggests reinjection of misclassified samples, yet the complexity derivation omits the number of such iterations. A multiplicative term  should be included to represent the number of update cycles (e.g., L rounds).\n\n(8) The paper claims that EDEL is interpretable but provides no model-level explanation, actually it is merely stating that “hard samples were fixed”, not proving that EDEL is “explainable”. For me, the introduction of \"interpretability\" concept in this paper is really weird. The introduction of “interpretability” appears conceptually inconsistent with the technical contributions of EDEL. The use of this term feels more rhetorical than substantive."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "A6Wb6U88df", "forum": "nPgpc4WzcB", "replyto": "nPgpc4WzcB", "signatures": ["ICLR.cc/2026/Conference/Submission8727/Reviewer_gXWh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8727/Reviewer_gXWh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8727/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761206877772, "cdate": 1761206877772, "tmdate": 1762920523760, "mdate": 1762920523760, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the task of imbalanced data classification, and proposes Error-Driven Ensemble Learning, an adaptive machine learning algorithm supported by theoretical analysis. The proposed method solves two challenges in this area, i.e., requirement of attention on hard-to-classify samples and requirement of attention to interpretability."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1: The studied problem is important.\nS2: The paper is easy to follow and well-written.\nS3: The paper has sufficient and detailed theoretical analysis."}, "weaknesses": {"value": "W1: Limited novelty for the first challenge. The first challenge, i.e., addressing hard-to-classify samples, seems to have been mentioned by a lot of existing methods. As noted in the manuscript (Line 1219), Focal Loss reduces the influence of easily classified samples, emphasizing hard-to-classify instances, while Class-Balanced Loss reweights losses based on class frequency to balance contributions.\nFurthermore, prior works like MESA [1] not only mentioned that there are existing methods assume instances with higher training errors are more informative for learning, but also extend their solution to other critical issues, such as generating synthetic samples for minority classes. Given this context, two key questions arise: 1 What is the unique advantage or fundamental difference of the proposed method compared to these specific, well-known techniques in handling the first challenge? 2 Why were comprehensive baselines like MESA not included in the comparisons?\n\n[1] MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler. NeurIPS 2020.\n\nW2: Apart from the above mentioned methods, a lot of methods have been mentioned in related work, why not compare with them? Are used baseline methods the SOTA methods? If not, SOTA techniques should be compared. Or authors need to give reasons why they did not compare with them.\n\nW3: Lack of clear explanation about technical details. Why divide the dataset into sub groups? And how to ensure that the algorithm could converge (Line 165)?\n\nW4: Some typos. For example, STD belongs to algorithm-level according to line 348, but it belongs to data-level according to related works in Line 1196. \n\nW5: Since the second challenge is the requirement of interpretability, is there any quantitative analysis or intuitive qualitative analysis for explanation, apart from theoretical analysis?"}, "questions": {"value": "Please see weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yMUu3qihnA", "forum": "nPgpc4WzcB", "replyto": "nPgpc4WzcB", "signatures": ["ICLR.cc/2026/Conference/Submission8727/Reviewer_kgFh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8727/Reviewer_kgFh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8727/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761302041420, "cdate": 1761302041420, "tmdate": 1762920523380, "mdate": 1762920523380, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes EDEL (Error-Driven Ensemble Learning), a novel algorithm to address class imbalanced data classification. EDEL works by partitioning the data and having parallel weak classifiers dynamically identify and re-train on misclassified, \"hard-to-classify\" samples from other subsets. The authors provide theoretical proof that this process enriches minority class representation and demonstrate through experiments on 7 datasets that EDEL significantly outperforms baselines in F1-measure and AUC, especially under extreme imbalance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1.The authors provide strong theoretical support for EDEL. The paper uses Bayes' theorem to prove the enrichment phenomenon of minority class instances within the misclassified sample set and employs McDiarmid's inequality to demonstrate the algorithm's convergence, presenting a rigorous line of reasoning.\n\n2.The method was validated on 7 real-world datasets with varying imbalance ratios (IR), including an extreme case with an IR as high as 577.88. In terms of AUC and F1-measure, EDEL consistently outperforms baseline methods, showing particularly strong performance on highly imbalanced datasets."}, "weaknesses": {"value": "1. In the table3，Some datasets (e.g., GMSC, CDH) exhibit large standard deviations (±0.2987，±0.2778 etc), raising questions about the method’s stability across folds.\n\n2. The experimental evidence supporting the interpretability claim is relatively limited. Although Tables 4 and 5 provide some descriptive analysis, the evaluation remains fairly simple. The paper would benefit from richer interpretability experiments.for instance, t-SNE or feature embedding visualizations showing how hard-to-classify samples evolve before and after EDEL’s error-driven enhancement."}, "questions": {"value": "1. What is the training time or computational cost compared to SMOTE ，S-T-D or CHRE? A runtime table would be helpful.\n\n2. Could the authors consider adding some visualization components to better illustrate the interpretability aspect of EDEL? For example, visual analyses such as t-SNE projections or feature-space evolution plots could provide more intuitive evidence of how the model improves the representation of hard-to-classify samples.\n\n3. EDEL reinjects all misclassified samples during training. Would this potentially lead to overfitting on noisy or outlier instances from the majority class? Have the authors considered applying a filtering mechanism to $\\mathcal{D}_{i}^{h}$, for example, by reinjecting only the misclassified minority-class samples?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LmRpEKowkB", "forum": "nPgpc4WzcB", "replyto": "nPgpc4WzcB", "signatures": ["ICLR.cc/2026/Conference/Submission8727/Reviewer_44n3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8727/Reviewer_44n3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8727/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987530589, "cdate": 1761987530589, "tmdate": 1762920522782, "mdate": 1762920522782, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}