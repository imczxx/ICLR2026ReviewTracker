{"id": "2qS5fes4RL", "number": 24923, "cdate": 1758361973764, "mdate": 1759896742305, "content": {"title": "EchoRAG: A Cognitive Memory-Inspired Framework for RAG with Semantic Gist", "abstract": "Retrieval-Augmented Generation (RAG), a pivotal technology connecting external knowledge with large language models, has been widely applied in various knowledge-intensive tasks. However, due to the inherent discrete representation of textual information and retrieval paradigms in current mainstream RAG systems, there is a prevalent issue of lack of semantic integrity, which leads to deviations in semantic retrieval. Therefore, we propose the concept of semantic gist and design EchoRAG, a novel RAG framework that simulates human cognitive memory. Specifically, inspired by the human episodic memory mechanism, this framework first achieves an understanding of semantic gist through reasoning and uses this to construct a multi-dimensional knowledge graph. During retrieval, it relies on a thought diffusion module to conduct global thinking on the knowledge graph, building a more comprehensive semantic landscape. Additionally, we propose the CogniRank algorithm, which incorporates the structural relevance of entity nodes and entity frequency metrics to measure node importance, thereby completing efficient ranking of candidate knowledge. To verify the effectiveness of EchoRAG, experiments were conducted on 5 public datasets for Question Answering (QA) tasks and multi-hop reasoning tasks. The results show that compared with current mainstream RAG methods, EchoRAG significantly improves answer accuracy and recall metrics while enhancing speed.", "tldr": "", "keywords": ["Retrieval-augmented generation", "Large language models"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4e8f209159adc29afb710e418e26221cf7b92b33.pdf", "supplementary_material": "/attachment/1fd57277eddfbef2220db500445f8fd7ec046af3.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes EchoRAG, a Retrieval-Augmented Generation (RAG) framework. The method first constructs a multi-dimensional knowledge graph from source documents by identifying what the authors term \"semantic gist.\" During retrieval, it employs a \"thought diffusion\" module to traverse this graph and a \"CogniRank\" algorithm to rank candidate nodes based on structural relevance and frequency. The framework is evaluated on Question Answering and multi-hop reasoning tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "S1. The experimental comparisons are comprehensive and cover multiple latest datasets. The results are highly credible."}, "weaknesses": {"value": "W1. The performance advantage is marginal. With the exception of the 2Wiki dataset, the proposed method achieves only a slight improvement over HippoRAG2. This suggests that the limitations of existing RAG methods, as identified by the authors, may not be the primary bottleneck hindering performance.\n\nW2. The motivation is not clearly articulated. The introduction presents a vague description, making it difficult for the reader to discern the primary problem being addressed. For instance, it is unclear whether the core issue is the potential information loss from structuring text into a graph, or the inherent difficulty that existing retrieval processes face in locating relevant information.\nI strongly advise the authors to revise and clarify the motivation section. Incorporating a concrete example or a case study would significantly help to illustrate the problem. Furthermore, if technical terms are necessary, they should be explained directly within the text rather than being introduced with only a citation. The responsibility of justifying the motivation for the present work should not be offloaded to external references, as this hinders the paper's clarity and self-containedness."}, "questions": {"value": "Q1. I don't understand the meaning of this sentence: “During the retrieval stage, these deficiencies are further magnified. Even with the introduction of advanced iterative (Wang et al., 2025) or agentic (Maragheh et al., 2025; Ravuru et al., 2024) reasoning frameworks, while these systems can comprehend the associations between entities, they fail to understand how these associations collectively constitute a meaningful semantic scene, thereby becoming trapped in localized reasoning (Fountas et al., 2024; Gutiérrez et al., 2025).”"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZS5osemSS9", "forum": "2qS5fes4RL", "replyto": "2qS5fes4RL", "signatures": ["ICLR.cc/2026/Conference/Submission24923/Reviewer_6Kcf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24923/Reviewer_6Kcf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24923/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761811294053, "cdate": 1761811294053, "tmdate": 1762943247371, "mdate": 1762943247371, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "EchoRAG targets a core weakness of RAG—fragmented, locally-biased retrieval—by first distilling each passage into a semantic gist and building a multi-faceted graph that links gists, entities/relations/triples, and the original passages. At query time, the system maps the query to seed triples and runs a Cognitive Diffusion Module (CDF) to spread relevance over the whole graph, incorporating structure and simple priors (e.g., entity frequency) to estimate global importance. A CogniRank stage then fuses this global importance with standard query–passage semantic similarity to rerank evidence and answer. The authors position this as a cognitively inspired “recall” process that captures broader context than nearest-neighbor retrieval, and they report improvements over vector and graph-RAG baselines on multi-hop QA benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths\n\n- Global view: CDF (full-graph semantic diffusion) adds global importance beyond local vector similarity, reducing near-neighbor mistakes.\n\n- Gist-first indexing: Semantic gist abstracts core facts before graphing, improving robustness to paraphrase and preserving passage context.\n\n- Consistent gains: Shows improvements over several Graph-RAG and vector baselines across multiple QA datasets; ablations support each module."}, "weaknesses": {"value": "Weakness\n\n- The paper does not clearly explain why CDF is useful. Please include targeted experiments and case studies to demonstrate its effectiveness, beyond ablation studies.\n\n- Popularity bias: Frequency priors can favor common entities and hurt long-tail or rare but crucial evidence.\n\n- Weaker path explainability: Produces global weights and rankings rather than explicit multi-hop paths, making audits harder."}, "questions": {"value": "same as weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "V83Q6buAIo", "forum": "2qS5fes4RL", "replyto": "2qS5fes4RL", "signatures": ["ICLR.cc/2026/Conference/Submission24923/Reviewer_eJYa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24923/Reviewer_eJYa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24923/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761858291970, "cdate": 1761858291970, "tmdate": 1762943247170, "mdate": 1762943247170, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes EchoRAG, a graph RAG approach inspired by human episodic memory. The proposed approach consists of an offline indexing stage and an online retrieval stage. In the indexing stage, documents are segmented into multiple passages, each of which is processed by an LLM to generate a one-sentence summary, referred to as a semantic gist. From each semantic gist, the system further extracts entities and relations to construct a knowledge graph. In the retrieval stage, EchoRAG first computes entity score using both fact-based similarity and entity-frequency reward.  These entity scores are then aggregated to produce an entity-based relevance score for each passage. Finally, this score is combined with the query–passage similarity to generate the final passage ranking used for retrieval."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes a cognitively inspired RAG framework that constructs multi-dimensional KGs from documents and perfrom passage retrieval from the resulting graph. \n2. Experimental results on five QA datasets show that the proposed approach can achieve better performance than baselines."}, "weaknesses": {"value": "1. The writing of the paper requires improvements in terms of clarity and precision. \n2. The proposed approach is not well explained, particularly in the methodology section. For example, it remains unclear how the knowledge graph is constructed from the semantic gists. Specifically, the process by which entities and relations are extracted is not described in sufficient detail. Furthermore, in the final multi-dimensional graph used for retrieval, the definitions of nodes and edges are vague, making it difficult to understand the structure and semantics of the graph. \n3. The motivation behind the proposed CogniRank retrieval mechanism is not clearly explained. The paper does not provide sufficient justification for why this particular ranking strategy is needed or how it might improve over existing retrieval methods. \n4. The main contribution of the paper is the construction of semantic gist. However, the analysis of this component remains superficial. The paper lacks an in-depth examination of how and why semantic gists contribute to improved retrieval or reasoning performance. \n5. The proposed method introduces a large number of hyperparameters (e.g., $\\alpha$, $\\beta$, $\\lambda_1$, $\\lambda_2$, $\\gamma$, $\\lambda_3$, $\\lambda_4$), but the paper does not clearly specify their values or provide guidance on how they are chosen. Moreover, there is no analysis or discussion regarding their sensitivity or impact on performance, which raises concerns about reproducibility and the robustness of the method.\n6. In Equation (16), the final ranking score for a passage is computed as a weighted combination of the entity-based score and the passage–query similarity. However, since the paper does not report the specific values of the weights $\\lambda_3$ and $\\lambda_4$, it is difficult to assess the relative contribution of the entity-based score. \n7. The paper lacks efficiency analysis compared with baselines."}, "questions": {"value": "Please see the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9ddfd0fxU5", "forum": "2qS5fes4RL", "replyto": "2qS5fes4RL", "signatures": ["ICLR.cc/2026/Conference/Submission24923/Reviewer_Ay2G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24923/Reviewer_Ay2G"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24923/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959133990, "cdate": 1761959133990, "tmdate": 1762943246956, "mdate": 1762943246956, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes EchoRAG, which stems from the human cognitive memory processes. The paper introduces semantic gist, the distilled semantic essences extracted from passages that preserve meaning while reducing noise. EchoRAG constructs a multi-dimensional knowledge graph incorporating entities, relations, facts, and passages, then uses a cognitive diffusion module during retrieval that simulates episodic memory and importance judgment. The proposed CogniRank algorithm combines semantic similarity with graph-topological importance to rank passages. Experiments on various QA benchmarks demonstrate improvements over existing RAG methods in accuracy, recall, and efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The framework applies cognitive science principles to computational mechanisms. The multi-dimensional knowledge graph that preserves structured facts and grounding passages is well-motivated.\n\n- The experimental results show improvements across five datasets, especially on multi-hop reasoning tasks. The comprehensive ablation studies demonstrate the mechanism of the model components."}, "weaknesses": {"value": "- The foundation of the proposed framework relies heavily on prompted LLM gist extraction, which the authors acknowledge may occasionally produce summaries that are imprecise but is not discussed in the paper. There is no evaluation of gist extraction quality or its impact on downstream performance.\n\n- The evaluation focuses exclusively on QA datasets with relatively standard retrieval scenarios. The approach hasn't been tested on other knowledge-intensive tasks or more complex reasoning scenarios. Additionally, the comparison with LightRAG shows surprisingly poor performance."}, "questions": {"value": "- How robust is EchoRAG to errors in gist extraction? What happens when the initial gist extraction fails to capture crucial semantic nuances or introduces misleading information?\n\n- The experiments are conducted on relatively small datasets. How does the computational complexity of the Cognitive Diffusion Module scale with graph size?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YNAM7CxA3C", "forum": "2qS5fes4RL", "replyto": "2qS5fes4RL", "signatures": ["ICLR.cc/2026/Conference/Submission24923/Reviewer_ZwaJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24923/Reviewer_ZwaJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24923/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972326442, "cdate": 1761972326442, "tmdate": 1762943245741, "mdate": 1762943245741, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}