{"id": "xpE2UhIILB", "number": 8828, "cdate": 1758099462506, "mdate": 1763015680127, "content": {"title": "PaTTA-ID : Practical Test-Time Adaptation for Person Re-Identification", "abstract": "Existing test-time adaptation (TTA) methods for person re-identification (re-ID) assume unrealistic scenarios: a large target gallery is available in advance, ignores temporal correlations in streaming input, and all identities are guaranteed to exist in the gallery set. Furthermore, they rely on server-side settings where data from multiple cameras are aggregated in advance, which is unrealistic for edge\ndevice applications on a single-camera. Therefore, they experience performance degradation in practical real-world deployments due to domain gaps between the training (source) data and the unseen (target) gallery streams. In this work, we introduce a practical scenario of test-time adaptation for person re-ID tailored for online streaming environment on resource-constrained edge devices, where a\nsmall predefined query set is registered in advance and unlabeled large gallery data continuously arrive from a single camera stream. We propose a novel framework to address this practical problem, called PaTTA-ID, that enables effective adaptation from two complementary perspectives. First we devise Input Distribution Compensation, which employs query-guided sampling and contrastive adaptation\nto compensate the bias of streaming inputs and promote cross-camera discriminability. Moreover, we investigate Model Drift Compensation, which prevents the bias toward the current camera stream via camera invariant learning and query\nfeature compensation. Experimental results evaluated on four benchmark datasets compared with nine baselines demonstrate that the proposed PaTTA-ID achieves state-of-the-art performance surpassing existing TTA methods.", "tldr": "", "keywords": ["person re-identification", "test-time adaptation", "image retrieval", "computer vision"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/69cdb8c924d0f9db3cfb052df4df3c966c02546d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The topic of this paper is person re-identification for video surveillance. In this paper a new task of the broader ReID problem is introduced. A new practical scenario for re-ID, targeted for edge devices, where a small predefined query set is registered in advance, and model is adapted to specific camera. For this scenario a new framework is proposed. The experimental evaluation is organized as following. The model is trained on one dataset, and then applied to another dataset with adaptation. This is similar in nature to testing of the generalizable person re-ID methods, but with adaptation to the target dataset. Experimental evaluation demonstrates that the proposed method allows significant improvement in accuracy compared to other test-time adaptation re-ID methods and generalizable re-ID methods without adaptation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) New practical scenario of person re-ID with adaptation to target camera, which can be potentially applied in industrial systems with good results\n2) Extensive evaluation on most of modern benchmarks (some of the results are in supplementary)\n3) Extensive description of all model parameters and meta-parameters, which will allow re-implementation even if source-codes are not released"}, "weaknesses": {"value": "1) The are a number of details missing in the description and discussion of the proposed scenario. The overal goal is on-line adaptation to the targeted camera on edge device. However, all experiments have been performed using 3090 gpu, which is definetely not an edge device. What are the computational and memory requirements of the proposed model for inference and adaptation? How long the adaptation is taking time? What are the memory requirements for features, gallery images, etc? All this information is required to thoroughly assess whether the proposed method is suitable for the proposed scenario.\n\n2) One important weakness is identified by the authors themselfs. Method requires a pre-defined query set with multiple instances captures from diverse cameras. In practice only 1 query image is provided per person and new queries are provided."}, "questions": {"value": "1) How the method will perform if pre-defined query set has only 1 image per person, which is how it is in practice?\n2) How the method will perform if new query images are provided?\n3) Please, address the computational and memory requirements for the method inference and adaptation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cN7zxwFWzP", "forum": "xpE2UhIILB", "replyto": "xpE2UhIILB", "signatures": ["ICLR.cc/2026/Conference/Submission8828/Reviewer_7Hr9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8828/Reviewer_7Hr9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824498635, "cdate": 1761824498635, "tmdate": 1762920599448, "mdate": 1762920599448, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "mImDnEBVkK", "forum": "xpE2UhIILB", "replyto": "xpE2UhIILB", "signatures": ["ICLR.cc/2026/Conference/Submission8828/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8828/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763015679469, "cdate": 1763015679469, "tmdate": 1763015679469, "mdate": 1763015679469, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a realistic test-time adaptation setting for person re-ID tailored for online streaming environments and proposes a PaTTA-ID framework that enables effective adaptation through two complementary strategies that compensate for the input distribution and the model drift. The experimental results with multiple person re-ID benchmarks demonstrate that PaTTA-ID outperforms existing methods under the practical TTA setting."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a new test-time adaptation setting for person re-ID tailored for online streaming environments.\n\n- The experimental results show the effectiveness of the proposed method."}, "weaknesses": {"value": "Please refer to Questions. Some parts of the proposed method are not clearly introduced."}, "questions": {"value": "•\tThe memory Q stores only two representative queries. Given this limited size, Is the positive sample for each anchor uniquely determined, and how is the hardest positive sample selected? A clearer explanation of the sampling strategy is needed.\n\n•\tThe test-time adaptation (TTA) setting in the prior work TEMP employs a fixed gallery and processes streaming query, whereas the proposed method uses a fixed query set and processes streaming gallery. The two settings share conceptual similarities—with some minor differences such as sampling 20% of the query set—it would be insightful to explore whether TEMP's setting can be adapted by using streaming query data from a single camera. A discussion on the interchangeability of these two settings would strengthen the analysis.\n\n•\tThe design of Input Distribution Compensation bears a strong resemblance to the approach in TEMP, which also computes cosine similarity between the query feature and each gallery feature and selects the top-k most similar samples for further processing. Is the primary distinction merely that TEMP optimizes based on entropy minimization, while the proposed method employs a contrastive loss? If so, a more explicit comparison of the two objectives and their respective effects would be valuable.\n\n•\tIn Figure 4, the performance degrades as the query set size increases, which is counterintuitive. One would expect that a larger query set provides more diverse and informative data, potentially improving model adaptation and performance. The authors should provide a justification for this unexpected trend.\n\n•\tThe “No adapt” baseline results should be included in Tables 6 and 7 for completeness. This would allow for a more comprehensive comparison and better illustrate the actual gain brought by the proposed adaptation strategy across different settings."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zKPBPRVCgo", "forum": "xpE2UhIILB", "replyto": "xpE2UhIILB", "signatures": ["ICLR.cc/2026/Conference/Submission8828/Reviewer_efJe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8828/Reviewer_efJe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761834624816, "cdate": 1761834624816, "tmdate": 1762920598732, "mdate": 1762920598732, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Existing test-time adaptation (TTA) methods for person re-identification (re-ID) rely on unrealistic assumptions (e.g., pre-available full target gallery, ignoring temporal correlation in streams), leading to poor performance on resource-constrained edge devices with single-camera streams; to address this, the paper proposes PaTTA-ID, a framework that combines Input Distribution Compensation (query-guided sampling + contrastive adaptation) and Model Drift Compensation (camera-invariant learning + query feature compensation) to tackle biased stream inputs and model drift. Experiments on 4 benchmarks (Market1501, CUHK03, MSMT17, LPW) show PaTTA-ID outperforms 9 baselines—e.g., 50.1% Rank-1 on CUHK03, 22.7% higher than the best baseline. Its contributions include: a practical streaming TTA setting for re-ID, the dual-compensation PaTTA-ID framework, and the new NQ-ROC metric for non-query rejection evaluation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed \"edge-device single-camera streaming re-ID TTA\" setting breaks the unrealistic \"pre-available full gallery\" assumption of existing methods, creating a new direction for deployment-oriented re-ID research. The NQ-ROC metric, the first to evaluate non-query rejection ability, complements the re-ID TTA evaluation system.\n2. Experiments are systematic—covering 4 mainstream benchmarks, comparing 9 baselines (general TTA + re-ID-specific TTA), and using multi-metrics (mAP, Rank-1, NQ-ROC). Ablation studies validate the necessity of core modules (QCA, QRL, QFC), ensuring high result credibility.\n3. The paper follows top-conference structure. It clearly identifies flaws in existing methods (background), elaborates on the dual-compensation strategy (methods), and presents complete experimental data (tables), making it easy for readers to grasp the core of the work.\n4. It addresses key bottlenecks in re-ID deployment (streaming inputs, edge deployment, non-query interference). PaTTA-ID provides a practical solution for adaptive re-ID in real scenarios, advancing re-ID from lab research to engineering applications."}, "weaknesses": {"value": "1. Insufficient Technical Novelty: The core strategies are combinations of existing techniques—Input Distribution Compensation uses \"query-guided sampling + contrastive learning,\" and Model Drift Compensation uses \"camera-invariant learning + feature update.\" No breakthrough TTA paradigms are proposed; innovations are limited to scenario adaptation rather than core principles.\n2. Incomplete Experiments: It fails to test performance on edge hardware (e.g., NVIDIA Jetson, mobile devices) (e.g., inference speed, memory usage), conflicting with its \"edge deployment\" positioning. It also lacks validation on complex datasets (e.g., Occluded-DukeMTMC for occlusion) and ablation of key parameters (e.g., τₛ), making it hard to prove the optimality of sampling logic.\n3. Inadequate Analysis & Visualization: There is no quantitative analysis of model drift (e.g., embedding space changes over update steps) to visually justify the need for drift compensation. Critical visualizations (e.g., sample distribution before/after Input Distribution Compensation, t-SNE of cross-camera features) are missing. Streaming performance curves (performance vs. gallery accumulation steps) are also absent, inconsistent with the \"streaming scenario\" focus.\n4. Presentation Flaws: Core module principles are vague—e.g., \"adaptive adjustment of τₛ\" and \"sample age calculation logic\" in query-guided sampling are unexplained. The number of reference format inconsistencies (e.g., missing conference/journal sources for some papers) reduces professionalism."}, "questions": {"value": "The paper claims \"edge-device deployment\" but provides no performance data (inference speed, memory usage) on edge hardware (e.g., NVIDIA Jetson, mobile phones). Can you supplement edge-device performance tests to prove engineering practicality?\nThe threshold τₛ in query-guided sampling directly affects sample selection. The paper does not explain its value basis (e.g., why a fixed value instead of adaptive adjustment). Can you add ablation experiments on τₛ (e.g., 0.3, 0.5, 0.7) to verify parameter sensitivity?\nIn Model Drift Compensation, drift vectors are estimated from query feature differences between consecutive updates. How does the number of query samples (for drift vector calculation) affect estimation accuracy? Can you supplement performance comparisons under different sample sizes to clarify the basis for optimal sample size selection?\nCurrent experiments do not test complex datasets (e.g., Occluded-DukeMTMC for occlusion, NightMarket for low light). How does the method generalize to such real-world scenarios? Can you add relevant experiments to prove robustness?\nThe paper claims \"the dual-compensation strategy must be combined\" but does not analyze the limitations of using Input Distribution Compensation or Model Drift Compensation alone. Can you add single-strategy experiments to justify the necessity of combining both? Additionally, can you provide t-SNE visualizations of cross-camera feature embeddings to intuitively show the effect of camera-invariant learning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zRMivWxLwF", "forum": "xpE2UhIILB", "replyto": "xpE2UhIILB", "signatures": ["ICLR.cc/2026/Conference/Submission8828/Reviewer_5NWu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8828/Reviewer_5NWu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921644586, "cdate": 1761921644586, "tmdate": 1762920598115, "mdate": 1762920598115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new test-time adaptation setting for person re-identification, where gallery images arrive sequentially. The method achieves strong performance and is clearly presented, but its practicality is limited by the need for predefined query sets with cross-camera annotations. Overall, the idea is interesting but needs clearer assumptions and stronger validation for real-world use."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tCompared with previous test-time adaptation settings that assume access to all gallery images, this work introduces a new setting where gallery images arrive sequentially. This assumption reflects more realistic scenarios in certain applications.\n\n2.\tThe proposed method demonstrates a significant performance improvement over existing Re-ID and TTA approaches.\n\n3.\tOverall, the paper is clearly written and easy to follow."}, "weaknesses": {"value": "1.\tAlthough this work relaxes the assumption of full access to gallery images, it introduces a stronger requirement for query image annotations. Specifically, the method assumes access to a predefined query set, which requires multiple images of each person across different cameras. This assumption is not very practical for test-time adaptation, as it necessitates additional identity annotations, which are costly and time-consuming to obtain. Moreover, based on Table 4, the performance heavily depends on such data in camera-invariant learning, which limits the practical applicability of the proposed method.\n\n2.\tWhile the paper claims that prior works ignore the assumption that “all identities are guaranteed to exist in the gallery set,” this work still implicitly makes the same assumption. Although the gallery images are assumed to arrive sequentially, the method ultimately uses all of them and still presumes that all identities exist in the gallery. The paper would benefit from an analysis of scenarios where certain identities do not appear in the gallery.\n\n3.\tThe concept of “temporal correlation” in person appearances across sequential streams is not clearly defined. Does it refer to the same person appearing at different times within the stream? \n\n4.\tGeneralization to unselected queries: The model requires a predefined set of query samples, but it is unclear how well the model generalizes to unselected queries. An experimental comparison between the selected and unselected query sets would clarify this point.\n\n5.\tNumber of selected queries: The model uses 20% of the total query IDs, but it is not explained how this ratio is determined. Would performance continue to improve as this ratio increases? Using a fixed number of queries instead of a dataset-dependent ratio might make the setting more generalizable across datasets and independent of data scale.\n\nAdditionally, in Figure 4, are the results evaluated only on the selected query IDs? If the evaluation includes all query IDs, the “non-adapt” results should remain consistent across settings, which does not appear to be the case.\n\n6.\tThe paper does not explain how the pseudo-label mentioned in Line 216 is obtained, which causes confusion for the reader.\n\n7.\tThe paper lacks an analysis of the required adaptation time, which is important for understanding the method’s efficiency and real-time applicability."}, "questions": {"value": "1. How are the batches temporally organized? For example, are all images within a batch sampled from the same camera? This seems unlikely, as the model requires images of a person from multiple cameras. However, the paper also states that unlabeled gallery data continuously arrive from a single camera stream, which creates confusion. \n\n2. Are adjacent batches sampled from the same or from different cameras?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KOWixJolKL", "forum": "xpE2UhIILB", "replyto": "xpE2UhIILB", "signatures": ["ICLR.cc/2026/Conference/Submission8828/Reviewer_vJzK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8828/Reviewer_vJzK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947083919, "cdate": 1761947083919, "tmdate": 1762920597662, "mdate": 1762920597662, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}