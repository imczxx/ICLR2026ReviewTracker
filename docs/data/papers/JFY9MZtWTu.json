{"id": "JFY9MZtWTu", "number": 1166, "cdate": 1756856221792, "mdate": 1759898224367, "content": {"title": "T-TAMER: Provably Taming Trade-offs in ML Serving", "abstract": "As machine learning models continue to grow in size and complexity, efficient serving faces increasingly broad trade-offs spanning accuracy, latency, resource usage, and other objectives. Multi-model serving further complicates these trade-offs; for example, in cascaded models, each early-exit decision balances latency reduction against potential accuracy loss. Despite the pervasiveness and importance of such trade-offs, current strategies remain largely heuristic and case-specific, limiting both their theoretical guarantees and general applicability.\n\nWe present a general framework, T-Tamer, which formalizes this setting as a multi-stage decision process, where the objective is to determine both when to exit and which model to consult. Our main result shows that recall (i.e., the ability to revisit earlier models) is both necessary and sufficient for achieving provable performance guarantees. In particular, we prove that strategies without recall cannot obtain any constant-factor approximation to the optimal trade-off, whereas recall-based strategies provably attain the optimal trade-off in polynomial time.\n\nWe validate our analysis through experiments on synthetic datasets and early-exit workloads for vision and NLP benchmarks. The results show that recall-based strategies consistently yield efficient accuracy‚Äìlatency trade-offs. We hope this work provides a principled foundation for bridging heuristic practice with theoretical guarantees in the design of early-exit and cascaded models.", "tldr": "T-Tamer optimally balances accuracy‚Äìlatency trade-offs in cascaded inference using recall-based dynamic indexing.", "keywords": ["Cascaded Inference", "Early-Exit Models", "Multi-Model Serving", "Provable Optimality"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5d523701f2cc514d906b3df9b4f9b6a57e50b664.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a theoretical framework to tackle trade-offs in ML serving when there are two objectives. One of the main claims is that it is impossible to achieve offline optimal performance without recall. Then the authors introduce a dynamic indexing strategy to tackle this challenge."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The writing is clear. The authors abstract out the problem as a Markovian Costly Exploration and offered a principled solution to tackle this tradeoff.\n\n2. The proposed solution also contains optimality guarantees."}, "weaknesses": {"value": "1. It's not clear how one would attain such a loss distribution for complex data in practice in the proposed Markovian setting, the cost associated with it, and whether there is a cheap surrogate that can estimate this loss distribution.\n\n2. This concern remains when the authors attempt to solve this via the dynamic indexing strategy. It is not clear whether discretization/quantization effort would be practical.\n\n3. No recall is a weak baseline. What about heuristics-based approaches that don't have the theoretical optimality guarantees and does the proposed method achieve a significant improvement over them?\n\nMinor issues:\nLine 80: There is an extra precedence in the sentence."}, "questions": {"value": "Please see my points above.\n\nIn addition, would it be possible to adapt the current framework to account for hard SLO constraints (such as serving latency / throughput) that are pervasive in real-world deployments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Sz6T70bF0A", "forum": "JFY9MZtWTu", "replyto": "JFY9MZtWTu", "signatures": ["ICLR.cc/2026/Conference/Submission1166/Reviewer_kRkc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1166/Reviewer_kRkc"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1166/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760904823250, "cdate": 1760904823250, "tmdate": 1762915695426, "mdate": 1762915695426, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies accuracy, latency (more generally, bi-objective) trade-offs in cascaded / early-exit ML serving. It models routing + stopping over a DAG and shows a clean result: policies without recall cannot achieve any constant-factor approximation, while recall-based policies can achieve the optimal trade-off in polynomial time. The framework is instantiated as T-TAMER and applied to three common DAGs (line, transitive closure of a line, and directed tree), and experiments on synthetic data plus vision/NLP early-exit workloads show the expected accuracy‚Äìlatency frontiers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear formalization of cascaded inference as costly exploration over DAGs (line, transitive closure, tree).\n- Strong, easy-to-communicate message: no-recall is information-theoretically too weak; recall fixes it.\n- Algorithm has polynomial-time preprocessing and ùëÇ(ùëõ) per-query inference, so it‚Äôs not just theory."}, "weaknesses": {"value": "- Experiments are synthetic + standard EE workloads; no real production-style serving stack.\n- Some assumptions (Markovian losses, known dists) could be made more operational for systems people."}, "questions": {"value": "1. Can you show one setting where recall is not implementable and quantify the loss?\n2. How robust is the policy to mild mis-specification of the loss distributions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fhhtYPFc5X", "forum": "JFY9MZtWTu", "replyto": "JFY9MZtWTu", "signatures": ["ICLR.cc/2026/Conference/Submission1166/Reviewer_m2Vw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1166/Reviewer_m2Vw"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1166/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958408090, "cdate": 1761958408090, "tmdate": 1762915695252, "mdate": 1762915695252, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a theoretical framework designed to optimize bi-objective trade-offs in cascaded inference. The work includes a powerful information-theoretic proof demonstrating that common no-recall confidence-thresholding heuristics are fundamentally suboptimal. The central solution is the Dynamic Indexing Strategy, which the authors prove is both polynomial-time computable and provably optimal for making adaptive inference decisions across various DAG structures."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper provides theoretical foundations, particularly through its information-theoretic impossibility result for no-recall strategies. \n2.\tBy abstracting cascaded inferences as costly explorations over DAGs, the framework naturally captures diverse topologies (from linear cascades to tree structures).\n3.\tThe work delivers strong theoretical guarantees through its dynamic indexing strategy, proving polynomial-time optimality for multiple DAG structures."}, "weaknesses": {"value": "1. The experimental evaluation is insufficient. It lacks comparison against critical baselines (e.g., standard thresholding, other learned routers) on the same Pareto frontier plots. Furthermore, the practical implementation and advantage of the core DAG-based routing mechanism remain unclear.\n2. The theoretical guarantees presented in the paper appear to rely on strong assumptions, most notably the Markov property of the loss sequences. Could you please discuss how these assumptions might influence the experimental results and their generalizability?\n3. Although inference is fast, the preprocessing time for the dynamic indexing policy can be computationally expensive. Could you explain how to solve the system with numerous sub-models (large $n$) requiring fine-grained discretization (large $|V|$).\n4. There are some instances of missing punctuation. For example, the first paragraph and entry with \"metrics\" in Section 6 lacks necessary punctuation marks."}, "questions": {"value": "I would appreciate the authors‚Äô responses to the four weaknesses outlined above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "mY8zD8iHcV", "forum": "JFY9MZtWTu", "replyto": "JFY9MZtWTu", "signatures": ["ICLR.cc/2026/Conference/Submission1166/Reviewer_nk36"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1166/Reviewer_nk36"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1166/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761983821054, "cdate": 1761983821054, "tmdate": 1762915695081, "mdate": 1762915695081, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores balancing accuracy, latency, and cost in serving large ML models. Traditional cascaded inference runs models from simple to complex, exiting early for easy queries. The authors point out a flaw: once a complex model is used, systems must accept its output (‚Äúno-recall‚Äù). They propose T-Tamer, a framework viewing inference as a multi-stage decision process. Its key insight: allowing a ‚Äúwith-recall‚Äù strategy‚Äîchoosing the best output at any stage‚Äîachieves an optimal trade-off."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. Original Problem Formulation:\nThis paper's most original contribution is the critical distinction between \"no-recall\" and \"with-recall\" strategies, which re-frames how efficiency trade-offs are understood and optimized.\n\nS2. Theoretical Contributions:\nThe work provides strong theoretical guarantees, including an information-theoretic proof that \"no-recall\" policies are inherently suboptimal (cannot achieve any constant‚Äëfactor approximation to the offline optimal), and the development of a provably optimal dynamic indexing strategy for \"with-recall\" settings, which extends efficiently to complex DAG structures.\n\nS3. Generality and Empirical Validation:\nThe T-TAMER framework is a general, model-agnostic \"plug-in\" solution, and its practical effectiveness is thoroughly validated through empirical experiments on CV/NLP benchmarks, demonstrating significant latency reductions with minimal accuracy loss."}, "weaknesses": {"value": "W1. Theory‚ÄìReality Gap:\nThe paper's central claim of \"provable optimality\" rests on strong assumptions that may not hold in practice. The most critical is the Markov property, which assumes a model's loss at one stage only depends on the loss of the immediately preceding stage. In deep neural networks, dependencies are far more complex and long-range, mediated by high-dimensional hidden states.\n\nW2. Limited Experiments and Baselines:\nAlthough results show better accuracy‚Äìlatency trade-offs, comparisons are mostly against weak ‚Äúno-recall‚Äù baselines. The paper omits tests against state-of-the-art heuristics like confidence- or entropy-based early exits and evaluates only simple linear cascades, leaving complex DAG performance unverified."}, "questions": {"value": "Q1. From what I gather, deploying T‚ÄëTamer requires estimating the loss distributions D·µ¢ and transition matrices P·µ¢  from a limited dataset, as well as discretizing the continuous loss space. These implementation steps appear essential for the policy‚Äôs effectiveness in practical settings, yet the paper doesn‚Äôt seem to discuss them in depth. What are your thoughts on this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KYjXT6iElH", "forum": "JFY9MZtWTu", "replyto": "JFY9MZtWTu", "signatures": ["ICLR.cc/2026/Conference/Submission1166/Reviewer_nhrK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1166/Reviewer_nhrK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1166/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994832865, "cdate": 1761994832865, "tmdate": 1762915694772, "mdate": 1762915694772, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}