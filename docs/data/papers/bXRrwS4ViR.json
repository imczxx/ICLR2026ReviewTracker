{"id": "bXRrwS4ViR", "number": 14718, "cdate": 1758242397398, "mdate": 1759897353085, "content": {"title": "RealEngine: Simulating Autonomous Driving in Realistic Context", "abstract": "Driving simulation plays a crucial role in developing reliable driving agents by providing controlled, evaluative environments. To enable meaningful assessments, a high-quality driving simulator must satisfy several key requirements: multi-modal sensing capabilities (e.g., camera and LiDAR) with realistic scene rendering to minimize observational discrepancies; closed-loop evaluation to support free-form trajectory behaviors; highly diverse traffic scenarios for thorough evaluation; multi-agent cooperation to capture interaction dynamics; and high computational efficiency to ensure affordability and scalability. However, existing simulators and benchmarks fail to comprehensively meet these fundamental criteria. To bridge this gap, this paper introduces RealEngine, a novel driving simulation framework that holistically integrates 3D scene reconstruction and novel view synthesis techniques to achieve realistic and flexible closed-loop simulation in the driving context. By leveraging real-world multi-modal sensor data, RealEngine reconstructs background scenes and foreground traffic participants separately, allowing for highly diverse and realistic traffic scenarios through flexible scene composition. This synergistic fusion of scene reconstruction and view synthesis enables photorealistic rendering across multiple sensor modalities, ensuring both perceptual fidelity and geometric accuracy. Building upon this environment, RealEngine supports three essential driving simulation categories: non-reactive simulation, safety testing, and multi-agent interaction, collectively forming a reliable and comprehensive benchmark for evaluating the real-world performance of driving agents.", "tldr": "", "keywords": ["LiDAR-Camera Synthesis", "Closed-Loop Autonomous Driving Simulation"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2470cc341df87d46a050b0ccd8659d3e8a0800ea.pdf", "supplementary_material": "/attachment/4a3c2cce306166fe509aa6c17cf5208d29b0e85d.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a simulation framework for closed-loop benchmarking of autonomous driving agents. It leverages real-world driving data to reconstruct the background and combine it with 3D meshes of foreground traffic participants to composite a realistic and reactive driving scenario. It shows the application of such a framework in non-reactive simulation, safety testing, and multi-agent interaction."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. Closed-loop simulation is important for benchmarking end-to-end driving models, and simulating using real-world data helps address the sim2real gap.\n2. The composition of the reconstructed static background and foreground objects with 3D meshes is flexible and could help with closed-loop simulation."}, "weaknesses": {"value": "1. The paper is hard to follow, with the contribution not clearly stated. Especially in the method section, why specifically compare to DriveArena and mention its drawbacks? The proposed method is not comparable to DriveArena with fundamental differences. The proposed method is based on reconstructing real-world data, while DriveArena uses a generative model to synthesize observations. The main difference from the previous approaches should be the separate construction of foreground objects and the background from my understanding.\n2. The main component of the simulation framework is the scene reconstruction and composition module, but it mainly relies on existing approaches without much technical novelty.\n3. The space and time horizon of the simulation shown in the supplementary video is very limited, and I doubt whether such a short duration is really useful for closed-loop testing, especially for the multi-agent interaction scenario.\n4. From the qualitative video, it seems the framework only simulates vehicles, but other essential traffic participants, like pedestrians, are not simulated. The traffic light is also not simulated, which is common at the intersections.\n5. The proposed evaluation benchmark consists of only 14 sequences from Navsim, which lacks diversity. Therefore, the results from such a benchmark may not be general and comprehensive for the driving agent's performance."}, "questions": {"value": "1. How does the proposed method help to better acquire occluded regions within a scene as mentioned in the introduction?\n2. How does the chamfer distance loss help to align the point cloud? Point clouds from different timesteps could capture different parts of the scene, and aligning them only with the chamfer distance may be suboptimal?\n3. Can the proposed framework include pedestrian simulation as well?\n4. Is the ego-agent used in simulation the same one for data capture? Can we put an additional ego-vehicle in the reconstructed scene?\n5. Can the proposed framework be easily extended to other datasets besides NuPlan? Will the reconstruction quality be degraded given different sensor configurations?\n6. Can the authors elaborate more on optimizing the shadow and lightning of the inserted assets with the SDS loss from diffusion models? The current blending of foreground objects still looks very unnatural."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "0OCVU86HQl", "forum": "bXRrwS4ViR", "replyto": "bXRrwS4ViR", "signatures": ["ICLR.cc/2026/Conference/Submission14718/Reviewer_sAct"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14718/Reviewer_sAct"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760733118207, "cdate": 1760733118207, "tmdate": 1762925081134, "mdate": 1762925081134, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents RealEngine, a Gaussian-splatting–based simulator for autonomous driving. RealEngine reconstructs static 3D scenes via 3D Gaussian splatting and pairs them with photorealistically rendered, controllable foreground traffic to generate high-fidelity scenarios. The pipeline enables end-to-end, non-iterative closed-loop evaluation on the nuPlan dataset and reports comparative results across popular end-to-end driving methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- `Addresses a key evaluation gap:` As end-to-end autonomous driving becomes more prevalent, rigorous evaluation remains challenging because intermediate perception outputs are not exposed. The proposed system enables non-iterative closed-loop evaluation without relying on intermediate signals, which is a substantive technical contribution.\n\n- `Cohesive and well-engineered pipeline:` The overall system design appears sound, and the implementation effort is substantial and appreciated.\n\n- `Benchmarking value:` The experimental results on the simulator are informative and position the framework as a promising benchmark for standardized comparison of end-to-end driving methods."}, "weaknesses": {"value": "- `Foreground–background domain gap and realism (Fig. 2):`\nThe participant model in Fig. 2 appears visually inconsistent with the reconstructed background even after relighting, creating a noticeable distribution gap. Models may exploit these artifacts to “spot” foreground objects, potentially inflating performance relative to real images. I wish to see the idea behind this concern from the authors.\n\n- `Novel-trajectory rendering and temporal consistency:`\nIt’s unclear how well 3DGS rendering holds when the ego vehicle follows trajectories not present in nuPlan logs. Novel-view extrapolation can suffer from floaters, holes, or “texture swimming.”\nPlease include visualizations along genuinely novel paths (lateral offsets, new turns).\n\n- `Safety-critical scenario support and policy impact: `\nThe paper focuses on evaluation, but it is important to know whether RealEngine can author and leverage rare/hazardous events for training end-to-end policies."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1W9hbodgOY", "forum": "bXRrwS4ViR", "replyto": "bXRrwS4ViR", "signatures": ["ICLR.cc/2026/Conference/Submission14718/Reviewer_VuT4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14718/Reviewer_VuT4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761570497222, "cdate": 1761570497222, "tmdate": 1762925079205, "mdate": 1762925079205, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents RealEngine, a system-level framework for realistic and interactive autonomous driving simulation.\nRealEngine integrates multiple existing techniques — Gaussian-splatting for static background reconstruction, LiDAR-based pose correction, mesh-based dynamic objects, and diffusion-guided relighting — into a unified multi-modal simulation engine that supports both camera and LiDAR rendering and closed-loop evaluation.\nExperiments on nuPlan sequences demonstrate higher image reconstruction quality (PSNR/SSIM/LPIPS) than previous methods such as PVG and StreetGaussians, and a small PDMS gap (~1%) between real-world and simulated trajectories, indicating strong behavioral consistency. The paper positions RealEngine as a potential benchmark for closed-loop evaluation.\n\n\nWhile RealEngine is a promising engineering contribution with solid implementation and clear motivation, it lacks sufficient methodological novelty and theoretical insight expected for ICLR. The paper would be better suited for a systems-oriented venue  rather than a core machine learning conference."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "●System Integration: A well-engineered pipeline that combines multiple state-of-the-art components (3DGS, GS-LiDAR, PBR rendering, diffusion relighting) into a coherent simulator.\n●Practical Value: Addresses a clear gap between open-loop datasets and realistic, interactive simulation for autonomous driving.\n●Quantitative Rigor: Provides detailed ablation studies, pose-correction evaluation, and multi-agent PDMS comparisons.\n●High-quality Visual Results: Demonstrates strong image reconstruction metrics and visually appealing renderings."}, "weaknesses": {"value": "●Limited Novelty: The paper mainly integrates existing techniques rather than introducing a novel algorithmic contribution. The background reconstruction uses StreetGaussians and GS-LiDAR, the foreground uses off-the-shelf meshes, and the composition uses a PBR pipeline with a diffusion prior. The proposed \"innovations,\" such as LiDAR-based pose correction and exposure compensation, feel more like necessary engineering adjustments for the nuPlan dataset rather than fundamental research contributions. The paper reads more like a well-executed system engineering project than a research paper introducing a novel algorithmic insight.\n●Insufficient Technical Depth: Key modules—such as diffusion-guided relighting and GS-LiDAR integration—are described only at a high level without clear mathematical formulation or ablation. The relighting pipeline lacks details on optimization objectives and diffusion loss design, while the multi-modal fusion is treated as a black-box step, offering little technical insight or reproducibility.\n●Incomplete Evaluation:\n○No scalability analysis for multi-agent or long-sequence simulation.\n○Limited exploration of edge cases (e.g., nighttime, adverse weather).\n○Behavioral metric (PDMS) is domain-specific and lacks comparison to broader RL/AD simulation benchmarks.\n●Dependence on External Assets: The quality of foreground meshes relies heavily on existing datasets (CO3D, 3DRealCar). This dependence limits scalability and generalization, as the paper provides no details on asset adaptation or automated mesh generation."}, "questions": {"value": "see the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nIGVfmSY03", "forum": "bXRrwS4ViR", "replyto": "bXRrwS4ViR", "signatures": ["ICLR.cc/2026/Conference/Submission14718/Reviewer_GUJq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14718/Reviewer_GUJq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762000890337, "cdate": 1762000890337, "tmdate": 1762925078693, "mdate": 1762925078693, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces RealEngine, a comprehensive simulation framework for autonomous driving that aims to bridge the critical gap between the high flexibility of traditional simulators and the high-fidelity realism of real-world datasets. The authors identify key limitations in existing tools: datasets are non-reactive (open-loop), while simulators like CARLA suffer from a significant sim-to-real gap.\n\nBuilding on this powerful foundation, the authors establish a benchmark with three essential evaluation modes: (1) non-reactive simulation with static background traffic, (2) safety testing with injected critical scenarios, and (3) multi-agent interaction where multiple planners operate simultaneously. The paper demonstrates the platform's capabilities by evaluating several state-of-the-art driving models, providing a detailed analysis of their performance in these challenging, realistic, and interactive scenarios."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Strength\n1.\tThe paper addresses a fundamental and highly significant problem in autonomous driving research. The lack of a simulator that is simultaneously realistic, interactive, and controllable is a major bottleneck for developing and validating robust driving agents. RealEngine represents a substantial step forward in addressing this need, and its contribution is very timely given the recent advances in neural rendering.\n2.\tA standout strength of this work is its comprehensiveness. The authors do not just propose a renderer; they deliver a complete simulation platform and benchmark. The three proposed simulation modes—non-reactive, safety test, and multi-agent—cover the most critical use cases for evaluating modern driving planners. The extensive experiments, testing four different driving models and providing both quantitative (Tables 2 & 3) and qualitative (Figures 4, 5, 6) results, convincingly demonstrate the utility and power of the RealEngine framework.\n3.\tThe paper provides strong evidence of the simulator's realism. The visual results in Figure 3 show a clear improvement in reconstruction quality over prior work. More importantly, the quantitative analysis in Section A.2 (Table 8), which shows a mere ~1% gap in planner performance between the real world and the simulation, is a powerful testament to the low sim-to-real gap achieved by the system."}, "weaknesses": {"value": "Weaknesses:\n1.\tThe paper accurately identifies a critical need for a realistic, closed-loop simulator. However, the solution can be characterized as a sophisticated systems integration effort rather than a work of fundamental algorithmic novelty. It combines SOTA rendering techniques effectively but does not propose new rendering methods or a more insightful data generation paradigm. More critically, while 'multi-agent interaction' is highlighted as a key capability, this contribution feels significantly underdeveloped. The paper provides a high-level demonstration but omits crucial details about the implementation. The most valuable contribution for the community would be the methodology for defining and controlling these interactions—for instance, the framework for modeling cooperative, adversarial, or game-theoretic behaviors between agents. Without these details, it is unclear how researchers can use RealEngine to conduct a principled study of agent-agent dynamics, which arguably is one of the most challenging frontiers in autonomous driving. This lack of detail leaves one of the paper's most exciting claims without sufficient scientific backing.\n2.\tThe framework relies on a library of 3D meshes for traffic participants. The paper mentions these are sourced from manual creation and reconstruction from datasets like CO3D. This asset creation process is a known bottleneck. The paper would be strengthened by a more detailed discussion on the scalability of this pipeline. How sensitive is the realism and the downstream planner performance to the diversity and quality of this mesh library? A limited library could inadvertently become a source of domain bias\n3.\tRealEngine provides powerful control over agent trajectories, making it an excellent testbed for specific scenarios and multi-agent interactions. However, the problem of populating a scene with diverse, realistic, and reactive background traffic is not fully addressed. The \"non-reactive\" mode uses pre-recorded trajectories, which is a standard but limited approach. Simulating the long tail of complex human driving behaviors at scale remains an open challenge that is outside the scope of this work but is worth acknowledging as a limitation."}, "questions": {"value": "na"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hvlDUKMWvK", "forum": "bXRrwS4ViR", "replyto": "bXRrwS4ViR", "signatures": ["ICLR.cc/2026/Conference/Submission14718/Reviewer_EJhm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14718/Reviewer_EJhm"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission14718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762003953508, "cdate": 1762003953508, "tmdate": 1762925078232, "mdate": 1762925078232, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}