{"id": "wZ9KCmV6a4", "number": 12851, "cdate": 1758210931152, "mdate": 1759897481522, "content": {"title": "Do Brains and LLMs Process Alike? Exploring Neural and Model Trajectories Similarity", "abstract": "Understanding the similarity between large language models (LLMs) and human brain activity is crucial for advancing both AI and cognitive neuroscience. In this study, we provide a multilinguistic, large-scale assessment of this similarity by systematically comparing 16 publicly available pretrained LLMs with human brain responses during natural language processing tasks in both English and Chinese. Specifically, we use ridge regression to assess the representational similarity between LLM embeddings and electroencephalography (EEG) signals, and analyze the similarity between the \"neural trajectory\" and the \"LLM latent trajectory.\" This method captures key dynamic patterns, such as magnitude, angle, uncertainty, and confidence. Our findings highlight both similarities and crucial differences in processing strategies: (1) We show that middle-to-high layers of LLMs are central to semantic integration and correspond to the N400 component observed in EEG; (2) The brain exhibits continuous and iterative processing during reading, whereas LLMs often show discrete, stage–end bursts of activity, which suggests a stark contrast in their real-time semantic processing dynamics. This study could offer new insights into LLMs and neural processing, and also establish a critical framework for future investigations into the alignment between artificial intelligence and biological intelligence. The code is available at https://anonymous.4open.science/r/57DF.", "tldr": "This paper compares the \"neural trajectory\" and \"LLM latent space trajectory,\" revealing key similarities and differences in semantic processing between the brain and LLMs.", "keywords": ["EEG", "Large Language Models", "Brain-Model Alignment", "Trajectory", "Cognitive Neuroscience"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/eb6247ed6834f86f5d13179fdd38bd8ea3647dc4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper evaluates the similarity between electroencephalography (EEG) signals and layer representations of LLMs from the static and dynamic perspective. Specifically, they adopt linear regression and RSA to quantify the representational similarity between EEG and internal representations of LLMs for the same sentence. On the dynamic perspective, they measure some metrics like magnitude and angle dynamics of EEG and LLMs' representations during the trajectory. Experimental results on English and Chinese EEG datasets show that middle-to-high layers of LLMs are better aligned with the N400 component in EEG."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- It is interesting to quantify the similarity between cognitive signals of human brain and the internal representations of LLMs from the dynamic perspective.\n- The structure of this paper is clear, and the content is easy to follow."}, "weaknesses": {"value": "- The analysis is only conducted on one EEG dataset for each language. It is better to investigate more datasets, e.g., ZuCo 2.0 and DERCo, or languages to support the soundness of your findings. \n- The settings to obtain the results of Figure 4 are unclear. Are they averaged across all subjects and sentences? Does it pass a statistical test?\n- Typo in Figure 2(c): D($x_k$, $x_{k+1}$) --> A($x_k$, $x_{k+1}$)"}, "questions": {"value": "- In addition to the trajectory to process the whole sentence, how about the result during the trajectory of the each word? The definition of $h_l$ represents the l-th word in the sentence under this setting.\n- How to reach the results of Figure 4? Are they averaged across all subjects and sentences? Does it pass a statistical test?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "H9wITv2sp0", "forum": "wZ9KCmV6a4", "replyto": "wZ9KCmV6a4", "signatures": ["ICLR.cc/2026/Conference/Submission12851/Reviewer_bfSx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12851/Reviewer_bfSx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12851/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760777905480, "cdate": 1760777905480, "tmdate": 1762923646533, "mdate": 1762923646533, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Previous works have examined similarities between brain activations and LLM internal representations. The novelty of the work presented in this paper is to compare the temporal dynamics of LLMs representations and neural activations. The neural data consist of two EEG datasets, one from 12 English participants and the other from 10 Chinese participants, who read sentences in their native language. Using 16 LLMs, the authors replicate previous works showing that the LLMs' internal representations correlates with the EEG states. The authors then characterize the \"neural trajectories\" and the \"LLM latent trajectories\" with various indicators: magnitude and angle of changes of states, uncertainty, mutual information, etc. They find that the trajectories of neural states and LLM states are quite dissimilar (Fig. 5)."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Comparing human neural dynamics in natural language processing with successive computations through the different layers of a language model is a potentially novel and interesting idea."}, "weaknesses": {"value": "- The Method section is extremely unclear, making it impossible to assess the results.\n\n    I did not find the definition of the time window over which the EEG states are computed (line 225). What do the \"steps\" on the $x$-axis of the graphics in Fig. 5 refer to concerning the EEG signals?\n\n    line 159: I suppose $d$ is the number of EEG channels. What is $N$, the number of samples? Is it a sample every ms? Then the duration varies across sentences.\n\n    line 194: Equation (2). The index $i$ refers to a time sample, I suppose. $W$ depends on $l$, but then $\\hat{M}$ should depend on $l$ given Eq. (2), but it does not appear like that. How is $\\hat{M}_{i, \\text{test}}$ computed? \n\n    line 196 and Fig. 3a: RDMs are usually computed from responses to sets of stimuli. How are the RDMs computed here? From the sentences, I would guess, but this should be clearly indicated. How did you the handle the differences in durations?\n\n    In the Results section, Fig. 5, how are these curves obtained? Why are there no error bars? Can you explain the $x$-axis? Is it not odd that Confidence Dynamics and Mutual Information Dynamics are clamped to zero (for LLM on Fig. 5d, for EEG on Fig. 5e) for several datapoints?\n\n- The LLM temporal dynamics is defined across layers, rather than across time.\nWhile the trajectories are defined over time steps for EEG, they are defined over successive layers for the LLMs (lines 220--226). But Fig. 2b suggests that the LLM internal state is sampled at each token onset. This is extremely confusing.\n\n- The neurocognitive content is very weak.\n\n    The review on \"neuroscientific foundations of language comprehension\" (line  107-120.) is too vague to be informative. For example, the \"N400 = semantic and P600 = syntax\" dichotomy has been falsified with the discoveries the Semantic-P600 effect (see, e.g., Kim & Osterhout, 2005; Sanford et al., 2011; Kos et al. 2010).\n\n    On lines 214--216, the authors wrote that \"Human cognition involves both fast, intuitive processes and slower, deliberative ones, similar to how LLMs process surface features in lower layers and semantics in higher layers\": this is an odd analogy. The time scale of deliberative processes in humans ($\\sim$ tens of seconds) is much longer than that of sentence comprehension ($\\sim$1s).\n\n- Some conclusions are not supported.\nline 86, and lines 316-317: The comparison between English and Chinese is confounded by the dataset (different texts, different subjects), so one cannot conclude that the differences observed are necessarily due to the fact that the LLMs are mainly trained on English.\n\n- The scientific aim is not very clear. There are two dynamics going on during sentence processing: across layers and across tokens (or in the brain, across brain regions and across time). It is not clear in the current paper, how the two are disentangled."}, "questions": {"value": "- Can you explain exactly how the RDMs in Fig. 3a were obtained?\n- Can you explain precisely how the curves on Fig. 5 were computed?\n\nSee also questions in Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RLOAJ497qC", "forum": "wZ9KCmV6a4", "replyto": "wZ9KCmV6a4", "signatures": ["ICLR.cc/2026/Conference/Submission12851/Reviewer_Mud6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12851/Reviewer_Mud6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12851/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837805810, "cdate": 1761837805810, "tmdate": 1762923645824, "mdate": 1762923645824, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors analyze EEG recordings from one English and one Chinese reading experiment and compare them to internal representations from 16 pretrained LLMs using ridge regression (predicting EEG features from LLM embeddings) and representational similarity metrics (RSA, CKA). Beyond static alignment, they propose a Latent Trajectory Comparison (LTC) framework that captures dynamic processing features —magnitude, angle, entropy, mutual information, and confidence — across LLM layers and EEG time windows. The study finds that (1) middle-to-high LLM layers align most strongly with the N400 EEG component (semantic integration), and (2) brains show continuous, iterative processing while LLMs exhibit discrete, stage-end bursts of activation."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "The paper’s contribution lies in extending representational similarity analysis toward temporal dynamics—a direction that has received limited attention. The introduction of LTC and Dynamic Representational Alignment (DRA) metrics adds methodological novelty, and the bilingual EEG–LLM comparison broadens linguistic scope. The results, while incremental in some respects, provide empirical evidence that middle LLM layers correspond to human semantic integration signals. This contributes to the ongoing dialogue about neural interpretability and AI–brain alignment, though the conceptual leap to “shared processing strategies” remains speculative."}, "weaknesses": {"value": "1. Missing implementation information: It is unclear how EEG and LLM time scales were aligned. For example, were EEG windows synchronized to token boundaries, or aggregated over words or sentences? The alignment procedure (temporal resolution, interpolation, or averaging) should be described in more detail. It would also be helpful to specify precisely how the representational dissimilarity matrices (RDMs) were computed. For RSA, are you using D = 1 − ρSpearman, S = ρSpearman as the dissimilarity and similarity metrics, respectively? Please clarify whether Spearman’s ρ is applied both when *constructing* RDMs and when *comparing* them. In many RSA implementations, the RDMs can alternatively be constructed using distance metrics such as cosine or Euclidean distance, while correlations (e.g., Pearson or Spearman) are reserved for comparing RDMs at the second level (For reference, Table 2 in [Do Large Language Models Mirror Cognitive Language Processing?](https://aclanthology.org/2025.coling-main.201/) (Ren et al., COLING 2025) provides a clear comparison of these alternative RSA similarity computation methods. It would also be useful to explain the rationale for mixing Pearson and Spearman correlations in different parts of the analysis; what guided these choices, and how sensitive are the results to this decision? Some references also appear misleading or insufficiently informative for readers seeking implementation details. For example, Du et al., 2025 do not describe how RDMs are computed, and Cortes et al., 2012 do not explain how to compute CKA. See my questions below for specific guidance on replacing these citations. Lastly, the description of ridge regression could be more complete: while the regularization parameter (α) is said to be selected via nested cross-validation, the search range and evaluation criterion (e.g., MSE, correlation) are not specified. Clarifying these details would improve reproducibility.\n2. Overclaims and causal overreach: The writing occasionally uses deterministic phrasing (e.g., \"LLMs simulate the brain’s semantic network\"), which could be toned down. The conclusion implies deep process similarity between LLMs and brains, though the results show only correlational alignment. I would recommend carefully rephrasing the claims in this study. Please see further information in the questions that need to be addressed to improve the clarity and reproducibility of the work.\n3. Missing baselines[minor]: Comparing to simpler embeddings (e.g., GloVe, BERT-base) could contextualize whether LLM size or architecture drives the observed effects."}, "questions": {"value": "**General Comments:**\n\n- Could the authors elaborate on their decision to predict EEG features from LLM embeddings (encoding) rather than the reverse (decoding)? It would be helpful to clarify why this direction was chosen and whether the inverse mapping was considered.\n- The choice of EEG as the primary modality deserves further justification. While the authors emphasize temporal resolution, related fMRI studies have achieved word-level temporal modeling through smoothing techniques (e.g., [Li et al., 2024](https://proceedings.mlr.press/v228/li24a.html)). The paper should better contextualize this choice and acknowledge complementary approaches. The following recent work seems directly relevant and missing from the discussion: [Structural Similarities Between Language Models and Neural Response Measurements](https://proceedings.mlr.press/v228/li24a.html) (Li, et al., 2024) \n- How sensitive are LTC and DRA metrics to the choice of embedding normalization or EEG preprocessing? Could these metrics detect spurious alignment from random embeddings?\n- Did you control for sentence length or lexical frequency when computing EEG–LLM correlations?\n\n**Line-Specific Comments:** \n- Lines 077-078 and lines 196-197. Why do the authors prefer to cite Freund et al., 2021 and Du et al., 2025 for RSA and RDMs instead of acknowledging their original conceptual sources ([Kriegeskorte et al., 2008](https://www.frontiersin.org/journals/systems-neuroscience/articles/10.3389/neuro.06.004.2008/full); [Kriegeskorte & Kievit, 2013](https://pubmed.ncbi.nlm.nih.gov/23876494/) and [Jörn Diedrichsen & Nikolaus Kriegeskorte, 2017](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005508))? It is also not clear how the RDMs are computed. Is it by measuring Spearman correlation? Or are you using a distance metric? Du et al., 2025 do not mention anything about calculating RDMs in their paper. \n- It would strengthen the interpretability of Table 1 if the authors could report or estimate random performance for the presented metrics (e.g., MSE, Pearson r, RSA, CKA). What would be expected under a random or uncorrelated mapping—for instance, after permuting EEG–text pairs or using shuffled LLM embeddings? Providing such a baseline would help quantify how much the observed alignment exceeds chance levels.\n- Lines 132-135: The sentence uses the wrong citation format (no need for parentheses since those works are given as examples), and it also appears to conflate steps. Is Pearson correlation used both in constructing and comparing RDMs (1 – r)? Are you following Kriegeskorte et al., 2008)? Please rephrase for precision.\n- Lines 135-137: The paper would benefit from a careful review of citation formatting for consistency. At present, both \\citet and \\citep styles appear to be used inconsistently, and in some cases citations are misplaced within or outside parentheses (e.g., \"...via ridge regression McDonald (2009)\" instead of \"...via ridge regression (McDonald, 2009)\" and  \"Additionally, (Tuckute et al., 2024) trained...\" instead of  \"Additionally, Tuckute et al., 2024, trained...\").\n- Line 200: The CKA citation should be corrected. The method originates from Kornblith et al., 2019 (“Similarity of Neural Network Representations Revisited”), building on kernel alignment (Cortes et al., 2012) and related kernel-target alignment work (Cristianini et al., 2001).\n- Figure 2 lacks visual consistency (varying font sizes and labeling styles for panels a–d). Aligning figure formatting (e.g. by removing the bullet points) and ensuring correspondence between panels and textual references would improve clarity (e.g. correspondence between Figure panels and paragraphs in subsection 3.2 LATENT TRAJECTORY COMPARISON).\n- Lines 147-151: The methodology description could be more precise: rather than saying \"metrics such as\" or \"including\", please explicitly list the exact similarity measures used for both representation and trajectory analysis. Similarly, in lines 218-219 and 462-463, avoid \"like..\" and \"and others\" when enumerating metrics (e.g., entropy, magnitude, skewness, kurtosis). It would be better to specify all the applied metrics used for clarity, consistency, and completeness.\n- Regarding the conclusion, I would be very careful with the claims made, ensuring that the findings are consistent between English and Chinese to avoid over-generalizing. For example, the paper refers to the study as “multilingual,” though only English and Chinese are included. It would be clearer to describe the work as bilingual or cross-linguistic to avoid overstatement. How could we ensure the results are language-specific and not dataset-specific? I think it would be important to acknowledge such a limitation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8bpn0xSJL5", "forum": "wZ9KCmV6a4", "replyto": "wZ9KCmV6a4", "signatures": ["ICLR.cc/2026/Conference/Submission12851/Reviewer_HuCo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12851/Reviewer_HuCo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12851/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876948838, "cdate": 1761876948838, "tmdate": 1762923644348, "mdate": 1762923644348, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a multilingual comparison between internal states of LLMs and human EEG signals on tasks in English and Chinese. The authors employ two approaches. First, they use ridge regression to assess the static representational similarity between LLM embeddings and EEG signals. Second, they introduce latent trajectory comparison to analyze the dynamics of information processing. \n\nThe study's findings shows similarities and crucial differences. The authors show that middle to high layers of LLMs are central to semantic integration and correspond to the N400 component observed in EEG. This suggests LLMs capture a temporal landmark of human semantic processing. However, the processing dynamics diverges. Human brains exhibits continuous and iterative processing during reading. In contrast, LLMs often show \"silent analysis\" followed by discrete, stage end bursts of activity, where processing metrics spike only near the final layers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This paper's main strength is its shift from static representational alignment to a dynamic comparison of processing trajectories. I found the comparison of the evolution of neural states across time windows with the layer by layer transformations of internal LLM states to be interesting. The proposed latent trajectory comparison is also thought-provoking, as it employs a suite of metrics including magnitude, angle, and entropy to characterize the processing pathways. The authors find that human brains exhibit continuous, iterative processing, while LLMs demonstrate a very different pattern of delayed, stage end bursts of activity. The scale of the experiments, which cover 16 LLMs, and its multilingual analysis of English and Chinese, are also useful."}, "weaknesses": {"value": "The paper's main methodological contribution, the latent trajectory comparison, relies on a significant and largely undefended assumption, the direct equivalence of a temporal EEG trajectory and a hierarchical LLM layer trajectory. This \"time to layer\" mapping is a strong conceptual leap. Human brain processing is recurrent, with all areas processing concurrently over time. A feedforward LLM processes sequentially through layers for a single token's computation. This discrepancy is not really addressed. \n\nThis paper also makes a strong neuroscientific claim about aligning with the N400 component, which appears overstated. The analysis shows a correlation with general brain activity around 400 milliseconds. This is not the same as aligning with the N400 effect, which is a specific, differential signal (an event-related potential) that peaks in response to semantic incongruity. \n\nFinally, the paper's mathematical approach is somewhat uneven. It relies on a simple linear ridge regression model for static comparisons, which seems insufficient in capturing nonlinear relationships. It then introduces a new, overly complex metric, dynamic representational alignment, to capture dynamic similarity. The justification for this specific formulation is quite thin, and its mathematical properties are not fully convincing. The authors might instead explore standard nonlinear mapping techniques, which are common in this field, before proposing a new composite metric."}, "questions": {"value": "1. Could you provide a justification for the \"time-to-layer\" mapping? Given the fundamental difference between recurrent temporal processing in the brain and sequential hierarchical processing in a feedforward LLM, how do you validate this as a meaningful comparison?\n\n2. What alternative mappings were considered? For instance, did you consider comparing the EEG trajectory to the recurrent states of an RNN or to the LLM's processing trajectory as it generates tokens over time?\n\n3. Can you clarify the claim of aligning with the N400 component? This component is typically an event-related potential (ERP) defined by a differential response to semantic anomalies. How does your finding of a general correlation at 400ms during natural reading map to this specific, differential effect, especially in an experiment that does not use a semantic anomaly paradigm?\n\n4. Was the choice of linear ridge regression for the static representational similarity analysis sufficient? Given the high likelihood of complex, nonlinear relationships between neural signals and LLM embeddings, were any nonlinear mapping techniques explored, and if so, how did they perform in comparison?\n\n5. Regarding the new Dynamic Representational Alignment (DRA) metric, could you provide a justification for its specific formulation? What advantage does this composite metric offer over more established methods for comparing time series, and would it be possible to provide an ablation study that reports its individual components separately to make the results more interpretable?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fUjbJ9KsNN", "forum": "wZ9KCmV6a4", "replyto": "wZ9KCmV6a4", "signatures": ["ICLR.cc/2026/Conference/Submission12851/Reviewer_59Rz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12851/Reviewer_59Rz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12851/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762243893297, "cdate": 1762243893297, "tmdate": 1762923644009, "mdate": 1762923644009, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}