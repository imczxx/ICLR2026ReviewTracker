{"id": "0cKUfYFeaf", "number": 5232, "cdate": 1757870923288, "mdate": 1759897986609, "content": {"title": "Pre-Generating Multi-Difficulty PDE Data For Few-Shot Neural PDE Solvers", "abstract": "A key aspect of learned partial differential equation (PDE) solvers is that the main cost often comes from generating training data with classical solvers rather than learning the model itself. Another is that there are clear axes of difficulty—e.g., more complex geometries and higher Reynolds numbers—along which problems become (1) harder for classical solvers and thus (2) more likely to benefit from neural speedups. Towards addressing this chicken-and-egg challenge, we study difficulty transfer on 2D incompressible Navier-Stokes, systematically varying task complexity along geometry (number and placement of obstacles), physics (Reynolds number), and their combination. Similar to how it is possible to spend compute to pre-train foundation models and improve their performance on downstream\ntasks, we find that by classically solving (analogously pre-generating) many low and medium difficulty examples and including them in the training set, it is possible to learn high-difficulty physics from far fewer samples. Furthermore, we show that by combining low and high-difficulty data, we can spend 8.9× less compute on pre-generating a dataset to achieve the same error as using only high-difficulty examples. Our results highlight that how we allocate classical-solver compute across difficulty levels is as important as how much we allocate overall and suggest substantial gains from principled curation of pre-generated PDE data for neural solvers.", "tldr": "Pre-generating lower difficulty data improves the few-shot performance of neural PDE solvers.", "keywords": ["Artificial Intelligence", "ML for Science", "Machine Learning", "Deep Learning", "Partial Differential Equations"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/72c864d6c798906658ef136a46c05783a982329b.pdf", "supplementary_material": "/attachment/5a012f6aa5d9023b0fc308000278229ff6bdcca1.zip"}, "replies": [{"content": {"summary": {"value": "This manuscript investigates how the difficulty composition of training data affects the performance and cost efficiency of neural PDE solvers. The experiments and analysis take the example of 2D incompressible N.-S. equation along two axes: geometry (number and complexity of obstacles) and physics (Reynolds number). The authors test their results using OpenFOAM on three datasets with varying difficulties. The experimental results are meaningful, e.g., mixing in low-to-medium difficulty data with 10% hard data might be a general-purpose tradeoff, and the results generalize across supervised NOs and Poseidon families. This manuscript opens a new avenue for designing “foundation datasets” that balance simulation cost and problem difficulty for scalable PDE model training. Although there are some technical weaknesses (mainly due to a lack of theoretical grounding), this manuscript still lies above the acceptance threshold and thus I'm recommending a weak accept."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Research aspect**: Data difficulty allocation in PDE learning is an important topic in scientific ML, but has not been extensively explored before. The analogy of \"pre-generating PDE data\" and \"pretraining foundation models in NLP and vision\" is well-motivated. The results offer insights into how simulation resources should be distributed during the data generation phase (e.g., favoring low-to-medium difficulty cases with 10% hard cases).\n- **Comprehensive experiments**: The experiments use multiple axes of difficulty, several neural architectures NO/Poseidon, and multiple PDE setups. The quantitative results show a consistent pattern across datasets and models. Cost-error curves and ablation studies are also included. \n- **Reproducibility**: The appendices document simulation setups, boundary conditions, scheduling, and solver parameters, with a promise to release data and code."}, "weaknesses": {"value": "- **Limited theoretical grounding**: The results are all based on experience, but no analytical or statistical reasoning. It remains unclear why difficulty transfer works.\n- **Scope limited to 2D N.-S.**: The generality to other PDE families (e.g., hyperbolic, nonlinear diffusion-reaction) remains unknown.\n- **Few discussions on convergence**: It's not clearly mentioned whether all models reached stable convergence, or whether the medium-difficulty pretraining data leads to different convergence curves/patterns. \n- **Readability concerns**: Figures 4-9 are really dense, but the captions repeat observations rather than providing new insight. This makes the manuscript a little difficult to read. The terminology could also be made clearer: The use of “hard,” “medium,” and “easy” terms refers to both physics and geometry without a consistent notation."}, "questions": {"value": "- How will the results adapt to different grid resolutions and temporal sampling? Would coarser data alter the observed scaling?\n- How do the authors ensure that medium-difficulty examples do not merely dominate by data quantity rather than content diversity?\n- How would the authors discuss the convergence dynamics under varying dataset difficulties/configurations? Are there significant differences?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xtZcitUET3", "forum": "0cKUfYFeaf", "replyto": "0cKUfYFeaf", "signatures": ["ICLR.cc/2026/Conference/Submission5232/Reviewer_31vP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5232/Reviewer_31vP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5232/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760717978271, "cdate": 1760717978271, "tmdate": 1762917963431, "mdate": 1762917963431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates an interesting idea of the trade-off between simulation difficulty and the performance of neural surrogates. By studying the 2D incompressible Navier-Stokes equations, the authors show that training on low and medium difficulty examples benefits few-shot learning on high-difficulty examples. The results highlight the importance of strategically allocating numerical solver resources across simulations of varying complexity."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is overall well written, with clear motivation and reasonable structure.\n- The problem studied is important for efficiently building practical neural PDE solvers.\n- The experiments clearly shows the increased computational cost with increased difficulty settings."}, "weaknesses": {"value": "My major concerns about this paper are regarding its contributions.\n\n- From my perspective, it is intuitively accurate and well known that mixing data with different levels of difficulty facilitates modeling training. Some existing papers have already analyzed the transfer learning bahaviour of scientific machine learning foundation models, which show that model trained with a specific set of PDE coefficients can be more data-efficient than models trained from scratch. [1] I think this conclusion can be adapted to the experimental setting in this paper.\n- Therefore, the experimental results in this paper do not suprise me. The 2D incompressible Navier-Stokes equation is a relatively simple case in the scientific machine learning community, and all the conclusions in this paper are based on experiments on this single dataset. More datasets should be considered, especially those with industrial level difficulty, such as driavernet++ [2] or the Well [3].\n- For more general PDEs, it might become hard to define \"easy\" \"medium\" and \"difficult\" cases. Therefore, the conclusion \"medium (across any axis) data can be much more effective as a mixing dataset than easy (across any axis) data for multi-obstacle performance\" may not be useful for building more powerful PDE foundation models, as all collected training cases can be \"hard\".\n- Overall, I think the best way to justify the contribution of this paper is to really train a PDE foundation model using the idea of this paper. It will make this paper more impressive and important.\n\n[1] Subramanian, Shashank, et al. \"Towards foundation models for scientific machine learning: Characterizing scaling and transfer behavior.\" *Advances in Neural Information Processing Systems* 36 (2023): 71242-71262.\n\n[2] Elrefaie, Mohamed, et al. \"Drivaernet++: A large-scale multimodal car dataset with computational fluid dynamics simulations and deep learning benchmarks.\" *Advances in Neural Information Processing Systems* 37 (2024): 499-536.\n\n[3] Ohana, Ruben, et al. \"The well: a large-scale collection of diverse physics simulations for machine learning.\" *Advances in Neural Information Processing Systems* 37 (2024): 44989-45037."}, "questions": {"value": "Please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xWTlnOkkSG", "forum": "0cKUfYFeaf", "replyto": "0cKUfYFeaf", "signatures": ["ICLR.cc/2026/Conference/Submission5232/Reviewer_WQ84"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5232/Reviewer_WQ84"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5232/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761054829038, "cdate": 1761054829038, "tmdate": 1762917963171, "mdate": 1762917963171, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how the difficulty composition of training data affects the efficiency and performance of neural PDE solvers. Using 2D incompressible Navier–Stokes equations, the paper defines three axes of difficulty and systematically analyzes how mixing low-, medium-, and high-difficulty data influences model accuracy on hard target distributions. Experiments demonstrate that training with mostly easy or medium data plus only 10–25% hard examples recovers nearly all of the performance of fully hard-data training, while requiring up to 8.9× less simulation compute. Moreover, generating medium-difficulty data is shown to be more cost-effective than generating large volumes of easy data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles an important and underexplored problem: how to allocate data-generation effort across different difficulty levels in neural PDE solver training.\n\n2. The study is thorough and methodologically sound, with carefully controlled experiments along geometry, physics, and combined difficulty axes.\n\n3. Results are consistent across multiple model families (CNO, FFNO, Poseidon), reinforcing the robustness of the findings.\n\n4. The proposed idea of difficulty transfer and the notion of “foundation datasets” for PDE solvers are original and practically meaningful.\n\n5. The paper is very well written, clearly structured, and includes detailed reproducibility documentation with OpenFOAM setups and metrics."}, "weaknesses": {"value": "1. The work is entirely empirical and lacks a theoretical explanation or analytical framework for the observed difficulty transfer phenomenon. It does not explain why medium-difficulty data generalize better than easy data toward harder regimes.\n\n2. The experimental scope is somewhat limited. All results are based on 2D incompressible Navier–Stokes simulations. It remains unclear whether the conclusions hold for other PDE families or multi-physics problems.\n\n3. The evaluation focuses mainly on normalized MAE; additional physics-aware metrics (e.g., conservation or stability) could provide a more complete assessment."}, "questions": {"value": "1. Can you provide intuition or theoretical reasoning behind why medium-difficulty data yield stronger transfer than easy data?\n\n2. Would similar trends be expected for other PDE types or 3D cases?\n\n3. How sensitive are the results to the particular definition of “difficulty” (e.g., obstacle count vs. Reynolds number)?\n\n4. Could difficulty transfer be linked to similarities in the solution manifolds or frequency spectra across datasets?\n\n5. When scaling to large “foundation datasets,” how might storage or simulation parallelization affect the practical cost trade-offs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "87g6CBtBZQ", "forum": "0cKUfYFeaf", "replyto": "0cKUfYFeaf", "signatures": ["ICLR.cc/2026/Conference/Submission5232/Reviewer_k82h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5232/Reviewer_k82h"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5232/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761271050044, "cdate": 1761271050044, "tmdate": 1762917962880, "mdate": 1762917962880, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the impact of adding simple fluid datasets on the training difficulty and results when learning hard fluid datasets, from the perspectives of Reynolds number and obstacles. The paper conducts experiments in FPO and LDC scenarios , exploring the relationship between data generation time and performance on hard datasets. It draws three main conclusions:\n\n(1) By mixing in a large number of easy or medium samples, it is possible to recover most of the performance of training on 100% hard data using only a small fraction  of hard samples. \n\n(2) In most cases, spending the computational budget to generate medium difficulty samples yields a lower error than generating a larger number of easier samples.\n\n (3) Pre-generated easy or medium difficulty data can improve few-shot performance on more complex downstream tasks like FlowBench, demonstrating the potential for \"foundation datasets\" ."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper uses multiple SOTA Neural Operators (CNO, FFNO, and Poseidon variants) to verify the training effectiveness of different data difficulty distributions within the dataset.\n\n- The paper conducts extensive experiments across various scenarios, including fixed total sample size, fixed hard sample size, and few-shot downstream tasks to validate its conclusions."}, "weaknesses": {"value": "See Questions"}, "questions": {"value": "- There is an issue with the experimental setup in this paper, namely the distributional shift between the training and test sets. The varying proportions of hard difficulty data lead to significant differences between the training and test distributions, which would cause notable differences in test set performance. The authors did not perform further fine-tuning on the purely hard dataset, which may have affected the results.\n\n- Could the authors consider further validation on real-world datasets? Given that the flow-past-object dataset in 3.3 (FlowBench) is relatively close in terms of scenario to the easy or medium datasets, the authors are encouraged to conduct additional experiments in real-world settings to verify the transferability of simulation data to real-world data."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ivIbGWGGv1", "forum": "0cKUfYFeaf", "replyto": "0cKUfYFeaf", "signatures": ["ICLR.cc/2026/Conference/Submission5232/Reviewer_zUe1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5232/Reviewer_zUe1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5232/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761921864091, "cdate": 1761921864091, "tmdate": 1762917962682, "mdate": 1762917962682, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}