{"id": "vSbYEwVFqM", "number": 16360, "cdate": 1758263718112, "mdate": 1759897245808, "content": {"title": "F-PvE: Fairness-Aware Structured Neural Network Pruning via Evolution", "abstract": "Model compression plays a crucial role in deployment, as it can significantly reduce computational costs with minimal loss in accuracy. However, recent studies have shown that model compression may involve additional bias, posing fairness risks that can potentially lead to social impact. As a result, mitigating bias during model compression has emerged as an important topic. In this work, we focus on structured neural network pruning, a widely adopted model compression technique that remains rarely explored in the context of fairness. Specifically, we introduce evolutionary algorithms as a general yet powerful approach to achieve fairness-aware structured pruning. That is, we formulate structured pruning as a subset selection problem and use evolutionary search to identify an optimal set of structural components to retain, balancing both accuracy and fairness objectives. Given the multi-objective nature and the large combinatorial search space of structural components, we further incorporate multi-objective evolution and cooperative coevolution to effectively address them. To verify the effectiveness of our method, we conduct experiments that cover three typical fairness scenarios: class-wise and group-wise fairness in classification models, and toxicity in language models. Compared with classic structured pruning methods and state-of-the-art competitors on fairness-aware structured pruning, our method can preserve better fairness while keeping competitive accuracy, demonstrating the superiority of evolutionary optimization for fairness-aware structured pruning in practice.", "tldr": "This paper introduces F-PvE, a general framework for fairness-aware structured neural network pruning via evolution, where multi-objective evolution and cooperative evolution techniques are further adopted to address the inherent challenges.", "keywords": ["Structured neural network pruning", "fairness", "evolutionary optimization"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/45b860015ba796035ac1d80b3722c0419e1cd8d6.pdf", "supplementary_material": "/attachment/f054e50031fdeb3fd3cdcbf9a4cf04f8b984e59f.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the problem of fairness degradation in model compression, particularly within the context of structured neural network pruning. The authors propose F-PvE, a unified evolutionary optimization framework designed to achieve fairness-aware structured pruning. The method formulates pruning as a subset selection problem and optimizes both accuracy and fairness simultaneously. Two variants are introduced: multi-objective evolution and cooperative coevolution. Experiments are conducted on three types of fairness-related tasks: (1) class-wise fairness on CIFAR-100 and CUB-200, (2) group-wise fairness on CelebA, and (3) social bias mitigation in language models using GPT-2 and DistilGPT-2."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly identifies fairness degradation as a critical issue in model compression and effectively formulates structured pruning as a multi-objective problem involving both accuracy and fairness.\n2. The experiments cover multiple architectures and fairness settings, including CNNs and Transformers, demonstrating the generality and adaptability of the proposed framework."}, "weaknesses": {"value": "1. While the paper introduces an evolutionary approach to fairness-aware structured pruning, the core optimization framework relies heavily on well-established methods such as NSGA-II and cooperative coevolution. The work mainly adapts these existing algorithms to the fairness context without providing new algorithmic insights or innovations. As a result, the contribution may appear incremental rather than conceptually novel.\n\n2. The method relies heavily on hyperparameter tuning, particularly the weight Œª in the fitness function. Different tasks and models may require different Œª values to balance accuracy and fairness, which introduces additional effort and uncertainty in practical applications.\n\n3. The computational cost of F-PvE is significantly higher than that of criteria-based pruning methods. This is because evolutionary algorithms require iterative evaluation of multiple candidate models throughout the search process, which is computationally intensive. Although the paper acknowledges the high computational cost of evolutionary search and proposes cooperative coevolution to improve efficiency, it provides only a qualitative discussion."}, "questions": {"value": "- Could the authors clarify what aspects of F-PvE are fundamentally novel beyond adapting these standard approaches to a fairness-aware pruning setting? It would be helpful to elaborate on whether any new search operators, objective formulations, or convergence criteria are specifically designed for fairness optimization.\n- Could the authors elaborate on how Œª is selected for different experiments and whether its value significantly affects performance stability?\n- While the paper mentions that cooperative coevolution improves scalability, the evaluation mainly remains qualitative. Could the authors provide concrete runtime comparisons with baseline pruning methods or ablation studies showing how cooperative coevolution reduces the search cost?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fApW0tHd0F", "forum": "vSbYEwVFqM", "replyto": "vSbYEwVFqM", "signatures": ["ICLR.cc/2026/Conference/Submission16360/Reviewer_5ihw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16360/Reviewer_5ihw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16360/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761551190461, "cdate": 1761551190461, "tmdate": 1762926485925, "mdate": 1762926485925, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies fairness-aware structured pruning and proposes F-PvE, a general evolutionary-optimization framework that treats structured pruning as a subset-selection problem over architectural units (e.g., CNN filters, Transformer heads). Each candidate solution encodes which units to keep/prune in a binary vector; evolution (mutation + environmental selection) then optimizes an evaluation functional ùëÄ(‚ãÖ) that combines accuracy and fairness on a validation set. For models with few components (e.g., heads), F-PvE uses multi-objective evolution (NSGA-II) to balance accuracy/fairness; for models with many components (e.g., CNN filters), it uses cooperative co-evolution to scale search. Experiments span three ‚Äúfairness scenarios‚Äù: class-wise degradation in multi-class classification, group-wise degradation with sensitive attributes, and toxicity/social bias for LMs; the paper reports superior trade-offs versus standard structured pruning and the one prior head-pruning fairness method. The paper positions itself as the first general approach to fairness-aware structured pruning (prior work handled only Transformer head toxicity via a greedy method) and motivates the need by citing fairness harms introduced by compression."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1- The paper directly addresses an emerging pain point: compression can skew error across classes/groups or amplify toxicity; structured pruning is especially relevant because it maps well to real hardware speedups. \n\n2- Casting fairness-aware structured pruning as evolution over subsets with an explicit multi-objective is clean and implementable; the binary encoding and controllable pruning-ratio step are practical touches. \n\n3- Using NSGA-II when the unit count is small and co-evolution for large unit counts is a sensible, documented design that aids scalability. \n\n4- The paper claims coverage of class-wise, group-wise, and LM toxicity scenarios across CNNs and Transformers, which (if fleshed out) would be a strong empirical contribution."}, "weaknesses": {"value": "1- The core idea (evolutionary search optimizing a fairness-aware objective) is a predictable extension of existing structured-pruning via evolution; the paper needs stronger contrasts vs. (i) greedy head-pruning for toxicity and (ii) fairness-aware training/regularization and constrained ERM (e.g., Fairlearn/FairReg/FairRet/SA methods) to demonstrate added value beyond ‚Äúsearch with a different objective.‚Äù \n\n2- It‚Äôs unclear which fairness metrics are optimized/measured in each scenario (e.g., class-balance error, worst-group accuracy, demographic parity, equalized odds, toxicity rate). Provide metric definitions, calibration of thresholds, and statistical significance across multiple seeds. Without this, ‚Äúconsistently outperforms‚Äù is hard to verify. \n\n3- Evolutionary search can be compute-intensive (population √ó generations √ó fine-tuning). The paper should fix a wall-clock or FLOP budget and compare to (a) non-evolutionary structured pruning with fairness-aware fine-tuning, (b) joint training with fairness constraints (e.g., group-loss constraints), and (c) lottery-ticket style selection with fairness-guided saliency at matched cost.\n\n4- Add ablations for (i) NSGA-II vs. weighted-sum scalarization, (ii) with/without co-evolution, (iii) mutation rate, population size, generation count, (iv) influence of fine-tuning schedule per candidate. This will show where the gains come from rather than attributing them to the umbrella ‚ÄúF-PvE.‚Äù\n\n5- Evaluate sensitivity to dataset shift and class/group imbalance, and report worst-group performance with confidence intervals. In the LM toxicity setting, consider prompt distribution shifts and disentangle fairness from perplexity degradation to rule out ‚Äúfairness by uniformly worse language modeling.‚Äù"}, "questions": {"value": "1- How exactly is ùëÄ(‚ãÖ) defined per scenario? Do you optimize a vector (accuracy,‚àífairness_gap) with NSGA-II in ‚Äúfew-unit‚Äù settings and a scalarized version with co-evolution? Please provide formulas and normalization details so accuracy/fairness are weighed comparably. \n\n2- Which group-fairness metrics do you optimize/measure (DP, equalized odds, worst-group acc., class-balance error)? For LM toxicity, is the toxicity classifier fixed and calibrated? If so, which model/threshold?\n\n3- At matched compute, how do you compare against (a) constrained ERM with group constraints and (b) fairness regularizers during fine-tuning? (These are natural baselines many practitioners would attempt before evolutionary search.)\n\n4- Please add NSGA-II vs. scalarization, co-evolution on/off, population √ó generations sweeps, and fine-tuning budget sweeps to isolate which ingredients matter.\n\n5- What is the variance across random seeds (initial population, mutation randomness, data splits)? Show error bars on fairness and accuracy for the reported Pareto fronts.\n\n6- For CNNs with thousands of components, what are the population sizes, generations, and wall-clock? How does F-PvE scale to larger ViT/LLM backbones where pruning units are numerous? Co-evolution partition strategy details would help."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WVM5Jls8SA", "forum": "vSbYEwVFqM", "replyto": "vSbYEwVFqM", "signatures": ["ICLR.cc/2026/Conference/Submission16360/Reviewer_yWHp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16360/Reviewer_yWHp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16360/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761682405013, "cdate": 1761682405013, "tmdate": 1762926485557, "mdate": 1762926485557, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper propose F-PvE (Fairness-aware Pruning via Evolution) ‚Äî a general evolutionary-optimization-based framework that jointly optimizes accuracy and fairness during structured pruning. F-PvE formulates pruning as a subset-selection problem and employs multi-objective evolution (NSGA-II) and cooperative co-evolution to handle both multi-objective optimization and the combinatorial search space. The authors evaluate F-PvE on three fairness scenarios: (1) class-wise degradation (CIFAR-100, CUB-200), (2) group-wise degradation (CelebA), and (3) social bias in language models (GPT-2 / DistilGPT-2). Results show that F-PvE improves fairness metrics (EDI, DEO, DT) with minimal loss in accuracy compared to baselines and a prior fairness-aware method (FASP)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. F-PvE creatively formulates fairness-aware structured pruning as a multi-objective subset-selection problem solved with evolutionary search. This is a unified design, which is applicable to CNN and Transformer\n\n2. The evaluation metric is diverse, which makes the results and conclusion convincing.\n\n3. The experiments use model that in both vision and language domain. The whole evaluation is thorough."}, "weaknesses": {"value": "1. The major concern about this paper is the novelty. While the paper claims to propose the first general fairness-aware structured pruning framework, but the components in the method is a combination of well-established works. There are many references in the proposed method such as Zhou et al., 2021 and Shang et al., 2022 for subset-selection, and Deb et al., 2002 for multi-objective trade-offs, etc. Therefore, I have to ask the originality of the proposed method, because right now it seems that the method is incremental.\n\n2. Current experiments are focusing on relatively small model and dataset. How would F-PvE scale to very large models (e.g., BERT-Large, ViT-Huge), or large dataset like ImageNet? Cooperative co-evolution may face exponential growth in search space, could gradient-based or hybrid heuristics reduce the cost? \n\n3. F-PvE is search-based, and although the paper acknowledges higher computation costs, there‚Äôs no quantitative breakdown such as GPU-hours results."}, "questions": {"value": "Please refer to weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fPreZyn9B9", "forum": "vSbYEwVFqM", "replyto": "vSbYEwVFqM", "signatures": ["ICLR.cc/2026/Conference/Submission16360/Reviewer_CPRZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16360/Reviewer_CPRZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16360/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761867952107, "cdate": 1761867952107, "tmdate": 1762926485145, "mdate": 1762926485145, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes F-PvE, a general framework for fairness-aware structured pruning. It formulates pruning as subset selection over structural units (e.g., CNN filters, Transformer heads) and uses evolutionary optimization to search for pruned subnetworks that jointly optimize accuracy and fairness. To cope with competing objectives and large combinatorial spaces, the method multi-objective evolutionary algorithms and cooperative coevolution to enhance the performance. Experiments on various datasets indicate that F-PvE achieves better or comparable accuracy while improving fairness compared to criteria-based pruning and a recent fairness-aware structured pruning baseline."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem formulation and proposed method is general to both CNN and transformers.\n2. The adoption of NSGA-II for pareto-front optimization is well-motivated.\n3. This paper tackles multiple fairness settings, including EDI, DED, and DT."}, "weaknesses": {"value": "1. The core optimization machinery, multi-objective evolutionary search and cooperative coevolution, are well-established. The paper‚Äôs contribution primarily lies in instantiating these tools for fairness-aware structured pruning rather than introducing fundamentally new optimization principles.\n2. Evolutionary algorithms typically require many model evaluations and fine-tuning cycles. This paper does not provide a computing comparison. This paper just say acceptable and finished within 12 hours.\n3. The paper offers no theoretical analysis of when/why fairness should improve under the proposed search, nor any convergence guarantees for the fairness~accuracy Pareto optimization."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Fzb16C756v", "forum": "vSbYEwVFqM", "replyto": "vSbYEwVFqM", "signatures": ["ICLR.cc/2026/Conference/Submission16360/Reviewer_Xpds"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16360/Reviewer_Xpds"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16360/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762060237887, "cdate": 1762060237887, "tmdate": 1762926484551, "mdate": 1762926484551, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}