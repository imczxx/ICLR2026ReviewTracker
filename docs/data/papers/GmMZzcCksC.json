{"id": "GmMZzcCksC", "number": 3886, "cdate": 1757560842526, "mdate": 1763551226877, "content": {"title": "Learning from Adversity: Semantic-Aware Mask Refinement through Adversarial Perturbation", "abstract": "Despite significant advances in image segmentation, even state-of-the-art models produce masks with imperfect boundaries, semantic inconsistencies, and structural errors. Mask refinement addresses these limitations, yet current approaches rely on simplistic synthetic noise that fails to capture the complex error patterns of real segmentation models. We introduce Phoenix, a novel framework that leverages adversarial learning to generate semantically meaningful noise patterns and contrastive learning to model refinement relationships. Our approach consists of two key innovations: (1) Adversarial Mask Perturbation, which employs embedding attacks to create semantic-aware noise that mimics real segmentation errors, and (2) Contrastive Mask Refinement Learning, which establishes a tri-directional framework that ensures feature consistency within semantic regions while maintaining separation between classes. Experiments demonstrate that Phoenix significantly outperforms existing methods across diverse tasks, while consistently enhancing state-of-the-art segmentation models with substantial improvements.", "tldr": "", "keywords": ["Image Segmentation; Mask Refinement; Adversarial Perturbation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f1cf95ce6803b83c1b5f5672465ef9710a1e884c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Although recent advances have greatly improved image segmentation, even state-of-the-art models still produce masks with inaccurate boundaries, semantic inconsistencies, and structural artifacts. While mask refinement techniques aim to address these limitations, existing approaches typically rely on simplistic synthetic noise that fails to represent the complex error patterns found in real segmentation outputs. \nThe authors present Phoenix, a novel framework that combines adversarial and contrastive learning for realistic mask refinement. Phoenix introduces two core components: (1) Adversarial Mask Perturbation, which employs embedding-level attacks to generate semantically meaningful noise resembling real segmentation errors, and (2) Contrastive Mask Refinement Learning, a tri-directional contrastive formulation that enforces feature consistency within semantic regions while maintaining clear separation across classes."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The authors address an interesting and important topic.\n- I appreciate that the authors go into more detail about the limitations of other papers in section 3.\n- The method is well described and motivated - everything is easy to follow. \n- The approach of adaptive, threshold-controlled noise generation is useful.\n- The datasets, evaluation metrics, and models were appropriately selected.\n- The results (Tables 2 and 3) are very good compared to SOTA.\n- The authors have conducted a large number of ablation studies and made good comparisons. The ablations address each component of the presented method.\n- In the appendix, more complex datasets and zero-shot approaches were tested - so great additional results.\n- Implementation details are presented, and the authors intend to make code available at a later date.\n- The limitations are reflected in failure cases, and based on these and their findings, the authors outline the next possible steps."}, "weaknesses": {"value": "- The related work section seems superficial to me, as if the authors are only focusing on the works they use as baselines.\n\n\nRemarks: \n- The theoretical analysis of semantic distribution is a good idea, but I find the section insufficiently explained and would therefore perhaps only explain it in the appendix. \n- I think details for the point annotations are worth adding.\n- A brief explanation of the challenging DIS task would be helpful.\n- The order of the figures in comparison to when they are referenced in the text is somewhat confusing."}, "questions": {"value": "- Regarding the novelty, are you the first to use adversarial perturbation for mask refinement?\n- Why were the NB and PointWSSIS methods chosen as baseline models for (weakly) semi-supervised?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cZsOMGeZ1z", "forum": "GmMZzcCksC", "replyto": "GmMZzcCksC", "signatures": ["ICLR.cc/2026/Conference/Submission3886/Reviewer_bEY1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3886/Reviewer_bEY1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3886/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760705677370, "cdate": 1760705677370, "tmdate": 1762917083921, "mdate": 1762917083921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Common Response"}, "comment": {"value": "We sincerely appreciate all reviewers for their thoughtful and constructive feedback on our work. We are grateful for the time and effort invested in providing detailed evaluations, which have been invaluable in strengthening our paper. The insightful suggestions and critical observations have helped us clarify our contributions and address important concerns.\n\n---\n**Summary of Our Contributions.** Phoenix introduces a novel framework for mask refinement that addresses the fundamental limitation of existing approaches, $i.e.,$ their reliance on simplistic morphological noise that fails to capture real segmentation errors. Our two key innovations are: (1) **Adversarial Mask Perturbation (AMP)**, which generates semantically meaningful, contextually aware noise patterns through adversarial embedding attacks, providing controllable yet realistic training data, and (2) **Contrastive Mask Refinement Learning (CMRL)**, a tri-directional contrastive framework that explicitly models relationships between ground truth, noisy input, and refined predictions to learn better refinement patterns. Our extensive experiments demonstrate significant improvements across diverse segmentation tasks. \nMoreover, Phoenix offers significant practical impact and broad applicability: it serves as a **plug-and-play module** that enhances diverse segmentation models without architectural changes (Tables 1-3, 6a), enables dataset annotation refinement for quality improvement (Table 6b), and demonstrates zero-shot generalization to medical imaging and urban scenes (Tables 7a-b).\n\n---\n**Strengths Acknowledged by Reviewers.** We are encouraged that reviewers recognized several strengths of our work:\n- Innovation in noise modeling and AMP methodology (Reviewers Nrbx, 38XS, ADPo, bEY1): The adversarial approach to noise generation was acknowledged as an interesting and technically sound contribution that provides more challenging and semantically aligned training data.\n- Powerful contrastive learning framework (Reviewer Nrbx): The tri-directional CMRL design was recognized as mathematically well-motivated and moving beyond basic pixel-level objectives.\n- Comprehensive and strong empirical results (Reviewers Nrbx, bEY1): Our systematic evaluation across multiple settings, including semi-supervised, weakly-supervised, fine-grained segmentation, and zero-shot generalization, demonstrates consistent improvements over state-of-the-art methods.\n- Thorough experimental analysis (Reviewers ADPo, bEY1): The extensive ablation studies, efficiency analyses, and additional applications in the appendix were appreciated for providing thoughtful experimentation.\n- Clear presentation and well-motivated method (Reviewer bEY1): The method description, implementation details, and code availability commitment were valued.\n\n---\n**Addressing Reviewer Concerns.** We have carefully considered all concerns raised by the reviewers and provide detailed responses to each reviewer individually below. Based on the valuable feedback, we have **updated the paper accordingly (indicated in blue text in the revised manuscript)**.\n\n---\nWe remain open to further discussion and feedback during the rebuttal period. We believe the additional experiments and clarifications significantly strengthen the paper and address the core concerns raised by all reviewers."}}, "id": "Y2osA7iwI7", "forum": "GmMZzcCksC", "replyto": "GmMZzcCksC", "signatures": ["ICLR.cc/2026/Conference/Submission3886/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3886/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3886/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763551384733, "cdate": 1763551384733, "tmdate": 1763551384733, "mdate": 1763551384733, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Phoenix, a semantic-aware mask refinement framework that leverages adversarial perturbations and contrastive learning. The method consists of two main modules: (1) AMP, which generates semantically meaningful noise to simulate realistic segmentation errors; and (2) CMRL, a tri-directional contrastive framework aligning ground-truth, noisy, and refined masks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The idea of using adversarial embedding perturbations for generating realistic segmentation noise is interesting and technically sound.\n- The framework is systematically evaluated across multiple segmentation settings, with comprehensive ablations and efficiency analyses showing thoughtful experimentation."}, "weaknesses": {"value": "1. Is the proposed adversarial mask perturbation conceptually similar to augmentation strategies that add positive (or forward) perturbations to enhance robustness? If so, how does Phoenix differ in motivation or mechanism—does it essentially act as a form of task-specific adversarial regularization?\n2. Are there cases where adversarial perturbations introduce unrealistic distortions that negatively affect training stability? If so, how are such cases identified or mitigated during training?"}, "questions": {"value": "1. Is the proposed **adversarial mask perturbation** similar to these augmentation strategies that add positive perturbations to improve robustness? Is Phoenix effectively a form of task-specific adversarial regularization?  \n2. Are there cases where adversarial perturbations may introduce unrealistic distortions that harm training stability? If so, how are such cases handled or filtered?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "90IqW9WZ6q", "forum": "GmMZzcCksC", "replyto": "GmMZzcCksC", "signatures": ["ICLR.cc/2026/Conference/Submission3886/Reviewer_ADPo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3886/Reviewer_ADPo"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3886/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930923942, "cdate": 1761930923942, "tmdate": 1762917083412, "mdate": 1762917083412, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new framework for segmentation mask refinement. The method proposes two primary contributions to generate semantic-aware noisy masks for training and optimize the refiner. The paper's narrative is framed around the AMP component, hypothesizing that this \"adversarial noise\" better mimics real segmentation errors than the morphological noise used by prior work."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The core premise of using adversarial attacks not as a test-time failure mode but as a training data generation mechanism is an interesting methodological direction for this problem.\n2. The method is benchmarked against SAMRefiner, which also uses the SAM backbone."}, "weaknesses": {"value": "1.  The paper attributes the performance gains to \"Learning from Adversity\" (AMP), as implied by the title, abstract, and introduction. However, it simultaneously introduces a second, complex, and independent contribution: the CMRL loss. It fails to experimentally disentangle the effects of these two new components, making it impossible to verify the central hypothesis.\n2.  The ablation studies are inadequate and confusing. They fail to provide a clear analysis that isolates the individual contributions of AMP and CMRL.\n3.  The large performance gap between all SAM-based methods and non-SAM methods suggests the ViT-H backbone itself is a dominant factor. The paper's narrative under-emphasizes this, attributing the improvement primarily to the noise generation strategy."}, "questions": {"value": "1.  To evaluate the paper's central hypothesis, could the authors provide an ablation study that isolates the individual contributions of AMP and CMRL? \n2.  Could the authors please clarify the exact settings for the baselines in Tables 4c and 4d? Does the \"Morp\" setting (Table 4d) use the full CMRL loss?\n3.  Could the authors comment on why the paper's narrative (title, abstract) is framed exclusively around the AMP (\"Adversity\") component?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A."}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wnSjS1AtG0", "forum": "GmMZzcCksC", "replyto": "GmMZzcCksC", "signatures": ["ICLR.cc/2026/Conference/Submission3886/Reviewer_38XS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3886/Reviewer_38XS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3886/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932354063, "cdate": 1761932354063, "tmdate": 1762917082991, "mdate": 1762917082991, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Phoenix, a framework for mask refinement in image segmentation, aiming to address persistent issues in mask boundaries, semantic consistency, and structural integrity. Phoenix augments the current state-of-the-art by leveraging adversarial perturbation in the embedding space (Adversarial Mask Perturbation, AMP) to generate semantically-plausible noise, and a tri-directional Contrastive Mask Refinement Learning (CMRL) loss to refine noisy masks. The approach is built atop the Segment Anything Model (SAM) and is extensively evaluated—outperforming strong baselines in semi-supervised, weakly-supervised, fine-grained, and zero-shot transfer settings across multiple datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**Innovation in Noise Modeling:** The introduction of AMP, which generates mask perturbations via adversarial embedding-level attacks rather than naive morphological operations, provides a more challenging and semantically aligned training regime. As shown in Figure 2, adversarial noise patterns demonstrate a higher semantic correlation with segmentation errors compared to morphological noise.\n\n**Powerful Tri-Directional Contrastive Loss:** The CMRL loss explicitly models relationships between ground-truth, noisy, and refined masks, encouraging foreground–background separation, intra-class consistency, and self-improvement. The design is mathematically well-motivated—Section 3.4 details feature-space losses that move beyond basic pixel-level objectives.\n\n**Comprehensive Empirical Evidence:** The paper presents broad quantitative comparisons (see Tables 1, 2, and 3), consistently demonstrating strong improvements over state-of-the-art refinement strategies, especially SAMRefiner and SegRefiner. The results generalize across full-supervision, semi-/weak-supervision, and domain transfer tasks."}, "weaknesses": {"value": "**Theoretical Clarity of AMP Mechanism:** While the AMP methodology is generally well-explained (see Algorithm 1), the theoretical analysis connecting adversarial perturbation in embedding space to task-specific semantic error diversity is somewhat hand-wavy. The justification for why embedding-level attacks yield realistic error patterns is primarily based on empirical distributions (see Figure 2c), and the claimed proportionality between gradient norm and local uncertainty relies heavily on assumed model properties. No ablation examines weaknesses of AMP, e.g., failure modes if embedding space is not predictive of real error patterns.\n\n**Contrastive Loss Formulation Details:** The mathematical construction of the tri-directional loss in Section 3.4 (multiple feature regions derived from mask overlaps) is intricate but under-explained for readers unfamiliar with the domain. The paper would benefit from explicit algorithmic pseudo-code or stepwise explanation of how region masks and projection features are computed and batched in a practical setting. Furthermore, the mapping from features to projected space (projector $g$) is presented as an afterthought, with no architectural or optimization ablation provided.\n\n**Ambiguities and Reproducibility Gaps:** Key implementation choices for both guiding mask selection and the adversarial update process are reported as “randomly chosen” or based on heuristics (Section 3.3 and Appendix B). For instance, Table 4d (mask perturbation method) and Table 8d (guidance mask ablation) demonstrate sensitivity to mask type, but practical selection protocols are not systematically explored. Minor but notable: several equations (especially for the loss in Section 3.4) lack definitive bounds for summations, and some index notations could be clarified for reproducibility."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ipg9l7cvh5", "forum": "GmMZzcCksC", "replyto": "GmMZzcCksC", "signatures": ["ICLR.cc/2026/Conference/Submission3886/Reviewer_Nrbx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3886/Reviewer_Nrbx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3886/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762135910043, "cdate": 1762135910043, "tmdate": 1762917082695, "mdate": 1762917082695, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Phoenix, a framework for mask refinement in image segmentation, aiming to address persistent issues in mask boundaries, semantic consistency, and structural integrity. Phoenix augments the current state-of-the-art by leveraging adversarial perturbation in the embedding space (Adversarial Mask Perturbation, AMP) to generate semantically-plausible noise, and a tri-directional Contrastive Mask Refinement Learning (CMRL) loss to refine noisy masks. The approach is built atop the Segment Anything Model (SAM) and is extensively evaluated—outperforming strong baselines in semi-supervised, weakly-supervised, fine-grained, and zero-shot transfer settings across multiple datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**Innovation in Noise Modeling:** The introduction of AMP, which generates mask perturbations via adversarial embedding-level attacks rather than naive morphological operations, provides a more challenging and semantically aligned training regime. As shown in Figure 2, adversarial noise patterns demonstrate a higher semantic correlation with segmentation errors compared to morphological noise.\n\n**Powerful Tri-Directional Contrastive Loss:** The CMRL loss explicitly models relationships between ground-truth, noisy, and refined masks, encouraging foreground–background separation, intra-class consistency, and self-improvement. The design is mathematically well-motivated—Section 3.4 details feature-space losses that move beyond basic pixel-level objectives.\n\n**Comprehensive Empirical Evidence:** The paper presents broad quantitative comparisons (see Tables 1, 2, and 3), consistently demonstrating strong improvements over state-of-the-art refinement strategies, especially SAMRefiner and SegRefiner. The results generalize across full-supervision, semi-/weak-supervision, and domain transfer tasks."}, "weaknesses": {"value": "**Theoretical Clarity of AMP Mechanism:** While the AMP methodology is generally well-explained (see Algorithm 1), the theoretical analysis connecting adversarial perturbation in embedding space to task-specific semantic error diversity is somewhat hand-wavy. The justification for why embedding-level attacks yield realistic error patterns is primarily based on empirical distributions (see Figure 2c), and the claimed proportionality between gradient norm and local uncertainty relies heavily on assumed model properties. No ablation examines weaknesses of AMP, e.g., failure modes if embedding space is not predictive of real error patterns.\n\n**Contrastive Loss Formulation Details:** The mathematical construction of the tri-directional loss in Section 3.4 (multiple feature regions derived from mask overlaps) is intricate but under-explained for readers unfamiliar with the domain. The paper would benefit from explicit algorithmic pseudo-code or stepwise explanation of how region masks and projection features are computed and batched in a practical setting. Furthermore, the mapping from features to projected space (projector $g$) is presented as an afterthought, with no architectural or optimization ablation provided.\n\n**Ambiguities and Reproducibility Gaps:** Key implementation choices for both guiding mask selection and the adversarial update process are reported as “randomly chosen” or based on heuristics (Section 3.3 and Appendix B). For instance, Table 4d (mask perturbation method) and Table 8d (guidance mask ablation) demonstrate sensitivity to mask type, but practical selection protocols are not systematically explored. Minor but notable: several equations (especially for the loss in Section 3.4) lack definitive bounds for summations, and some index notations could be clarified for reproducibility."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ipg9l7cvh5", "forum": "GmMZzcCksC", "replyto": "GmMZzcCksC", "signatures": ["ICLR.cc/2026/Conference/Submission3886/Reviewer_Nrbx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3886/Reviewer_Nrbx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3886/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762135910043, "cdate": 1762135910043, "tmdate": 1763566009648, "mdate": 1763566009648, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}