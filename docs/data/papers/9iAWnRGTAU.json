{"id": "9iAWnRGTAU", "number": 6375, "cdate": 1757975344779, "mdate": 1763069480625, "content": {"title": "RareFlow: Physics-Aware Flow-Matching for Cross-Sensor Super-Resolution of Rare-Earth Features", "abstract": "Super-resolution (SR) for remote sensing imagery often fails under out-of-distribution (OOD) conditions, such as rare geomorphic features captured by diverse sensors, producing visually plausible but physically inaccurate results.We present RareFlow, a physics-aware SR framework designed for OOD robustness. RareFlow's core is a dual-conditioning architecture. A Gated ControlNet preserves fine-grained geometric fidelity from the low-resolution input, while textual prompts provide semantic guidance for synthesizing complex features. To ensure physically sound outputs, we introduce a multifaceted loss function that enforces both spectral and radiometric consistency with sensor properties. Furthermore, the framework quantifies its own predictive uncertainty by employing a stochastic forward pass approach; the resulting output variance directly identifies unfamiliar inputs, mitigating feature hallucination.We validate RareFlow on a new, curated benchmark of multi-sensor satellite imagery. In blind evaluations, geophysical experts rated our model's outputs as approaching the fidelity of ground truth imagery, significantly outperforming state-of-the-art baselines. This qualitative superiority is corroborated by quantitative gains in perceptual metrics, including a nearly 40\\% reduction in FID. RareFlow provides a robust framework for high-fidelity synthesis in data-scarce scientific domains and offers a new paradigm for controlled generation under severe domain shift.", "tldr": "We present RareFlow, a physics-aware SR framework designed for OOD robustness.", "keywords": ["satellite images", "remote sensing", "diffusion models"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/8109a4af23fac37fb408d7f598f88ffd279e1e02.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a new single image super resolution approach tailored for a scientific context with low available data (less than one thousand images).\nIt is based on a ControlNet approach that attempts to propose a good balance the perception-distortion trade-off by using additional prompt information.\nThe prompts are obtained from GPT5."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper proposes a pipeline for training a ContolNet for super resolution. \nOne contribution is to modulate the control adapters using uncertainty. \nThe uncertainty is computed using Monte Carlo Dropout.\nThe remaining of the training pipeline is rather classical with a combined loss that assemble various desired properties (spectral faithfulness, color consistency, LPIPS, see Eq. (12)).\n\nThe reported experimental results are very good.\nThe method coined RareFlow achieves best performances on fidelity metrics, perceptual similarity and realism metrics (Table 1) for a difficult SISR task with intrument shift.\nIt is also very efficient in a more academic SISR problem with simulated LR images (no instrument shift).\nA comprehensive ablation study is also performed."}, "weaknesses": {"value": "The main weakness of this paper is the lack of novelty in its methodology for adapting a computer vision tool for a scientific application.\nThe use of GPT5 for the data expertise is also debatable as a scientific expertise.\nAll in all, even though this is an interesting problem, this may be of limited interest for the ICLR community.\n\nAnother main limitation is that reproducibility is not discussed.\n\nPerformance in terms of computation times are not discussed.\nThe computation of the uncertainty requires $T$ image evaluations at each step, which certainly burdens the computation time.\n\nSplitting in training and testing set is not discussed.\n\nIf I understand correctly the GPT5 caption is performed on the HR reference image to perform SR on the LR image.\nThis is a form of ground truth leakage to provide this text to the network. \n\nThe paper suffers from several presentation issues: \n* Some figures are not referenced in the text (Fig 2, Fig 5).\n* ControlNet presentation: $f_\\theta$ is presented as a frozen diffusion transformer, but then it appears as trained in Eq. (8). It would be good to highlight the dependency with respect to trainable parameters.\n* It is not clear what are the latents $u_\\theta$ and $u^\\star$ from Eq. (9). There seem to be a conflict of notation with the uncertainty $u$ of Eq. (9). \n* Caption of Fig. 2 discusses features $F_i$, a notation not present in the main text.\n* What is the meaning of physics-aware? Prompt-informed?\n\n\nOther minor issues:\n* Appendix numbering, \n* l. 048: RS used before definition line 054\n* Figures referenced as Fig. and Figure\n* 249: Eq. equation\n* 246: equivalently: Does not sound equivalent\n* Two references for ControlNet: Is it really needed to cite the v1 of the preprint in addition to the ICCV 2023 paper?"}, "questions": {"value": "1) About Eq. (9): Frequency regularization in latent space requires that the encoder $\\mathcal{E}$ respects the low-mid-high frequency separation, but is has been shown that this is not generally the case in\nImproving the Diffusability of Autoencoders, Skorokhodov et al., ICML 2025.\nIs this ensured here ? \n\n2) Figure 4: On the third line, can you ensure that snow is indeed present in the sentinel 2 LR or is it hallucination from training set?\n\n3) Is the caption used for testing obtained from the groundtruth HR image ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zd1iV3IRlU", "forum": "9iAWnRGTAU", "replyto": "9iAWnRGTAU", "signatures": ["ICLR.cc/2026/Conference/Submission6375/Reviewer_W1wK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6375/Reviewer_W1wK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6375/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760975848370, "cdate": 1760975848370, "tmdate": 1762918665019, "mdate": 1762918665019, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "QCD6NNpnQx", "forum": "9iAWnRGTAU", "replyto": "9iAWnRGTAU", "signatures": ["ICLR.cc/2026/Conference/Submission6375/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6375/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763069479644, "cdate": 1763069479644, "tmdate": 1763069479644, "mdate": 1763069479644, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new super-resolution framework for satellite images called RareFlow. It introduces three main challenges in realistic use-cases of super-resolution with satellite images: domain shift between sensors of which the data is combined, the need for preserving the original sensor properties in the images (which can be lost in super-resolving), and the presence of rare features that can be distorted during super-resolution. The authors additionally propose a new dataset to train and evaluate models for this problem. They present three evaluations: one real-world super-resolution evaluation with domain shift, using two different sensors (Sentinel-2 and Maxar); one with synthetic training pairs created by down-sampling Maxar data, and a qualitative evaluation by a human panel. The authors report improved performance over baseline super-resolution methods in both supervised and unsupervised metrics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper establishes a clear knowledge gap and highlights issues that are important to make super-resolution approaches usable in real-life satellite-image applications. Class imbalance/ lack of examples of rare phenomena are a pervasive problem that is important to address. \n- The contributions are relevant, as the issues highlighted in the paper are specific to satellite images and are not necessarily a problem in the natural image domain (specifically the importance of preserving the ‘style’ of a sensor)"}, "weaknesses": {"value": "- Motivation/clarity can be improved: key methodological concepts (uncertainty quantification, physics-aware components, prompts, dual-conditioning, ControlNet) are introduced too late or not sufficiently motivated. \n‘Uncertainty quantification’ is mentioned in the abstract, then the next occurrence is in section 3.2. It would be good to explain it also in the introduction and start of methods section. \nThe title mentions ‘physics-aware’, but this also does not appear in the introduction. \nPrompts: Figure 1 shows that prompts are being used in RareFlow but it is not really clear from the introduction or the methods section how this fits into the methodology \n‘dual-conditioning mechanism’ (line 085) – not yet clear what this is, can the authors elaborate? \nControlNet (line 086) can the authors elaborate why this architecture specifically is being used?  \n\n- Positioning/scoope: The paper positions the methods as a general method for satellite image datasets with rare features, yet the method is evaluated on a single small dataset with a single type of rare feature (retrogressive thaw slumps) and one combination of sensors, yet there is an enormous variety of possible rare features and sensor combinations. Therefore, the current evaluation does not support positioning this as a general method. Either the authors should narrow the scope of the paper, or present additional experiments on different datasets with other sensors and rare features.  \n- Experimental details: Critical experimental details are missing from the main text or relegated to appendices: training procedures (optimiser, epochs, random seed variations), evaluation metrics, and their justification. This limits the interpretation of the results and reproducibility. Furthermore, the dataset description lacks some details: the authors should clarify why the images are so small, why there are so few images in the dataset, and the issue of the bit depth (this issue is not unique to this dataset as satellite images tend to have higher bit-depth). This explanation should clarify why these issues have to be addressed algorithmically/with models rather than in pre-processing/dataset composition. \n- Not all claims supported by evidence: The human expert validation (Section 4.3 and corresponding appendix lacks methodological rigour: number of panelists, number of images reviewed in total, panel demographics, inter-rater agreement, or quantitative results are reported. I suggest the authors provide more evaluation details as well as numerical results, or leave the analysis entirely out of the papers, as any conclusions should be supported by results.   \n- Conclusions: The conclusions should scope the contribution to remote sensing applications and acknowledge the single-dataset evaluation. The current text does not mention remote sensing data and is scoped too broadly.   \n- The image samples are too small to interpret. I suggest the authors update the figures to make the images larger (e.g. by removing some less relevant rows or columns to make space for larger images).  \n- Line 048: acronym RS not expanded \n- Small formatting note: It seems like citations are placed after periods, which is slightly confusing (e.g. line 040, “European Space Agency (ESA) (a;b)”). Suggestion to add citations before periods and clearly distinguish them from the rest of the sentence."}, "questions": {"value": "- ControlNet seems to be cited twice, in two different formats. Is this correct? (lines 738-743) \n- Regarding the contributions: Contribution 2 mentions ‘we ensure the SR process preserves the large-scale radiometric information’ (lines 105-106), contribution 3 mentions ‘end-to-end model that jointly performs SR and radiometric harmonization’ (line 107). What is the difference between contributions 2 and 3, if they both refer to radiometric harmonisation?  \n- Lines 180-184: What domain-specific knowledge is necessary to reconstruct the RTS? What is the unique morphology of the RTS? These aspects should be made more concrete to explain why generic photo domain methods wouldn’t work.  \n- How representative are RTS of rare features in satellite images? What are examples of other features?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gDRdIyTQkJ", "forum": "9iAWnRGTAU", "replyto": "9iAWnRGTAU", "signatures": ["ICLR.cc/2026/Conference/Submission6375/Reviewer_F295"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6375/Reviewer_F295"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6375/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761602082744, "cdate": 1761602082744, "tmdate": 1762918664445, "mdate": 1762918664445, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes RareFlow, a physics-aware dual-conditioning super-resolution framework designed for cross-sensor and out-of-distribution remote sensing imagery. The method integrates a dual-conditioning architecture combining Gated ControlNet and text-guided semantic conditioning, an uncertainty-gated control mechanism using Monte Carlo dropout and a physics-aware loss. Experiments demonstrate that RareFlow significantly improves perceptual realism and physical consistency over SOTA baselines such as SeeSR, AdcSR, and ZoomLDM."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper presents a well-motivated and technically innovative framework that effectively addresses the issue of generating physically inconsistent details in out-of-distribution scientific imagery. RareFlow’s dual-conditioning architecture successfully balances structural fidelity and semantic guidance, while its uncertainty-gated control mechanism adaptively suppresses hallucinated features under high uncertainty. The introduction of a physics-aware loss formulation, which integrates spectral alignment, radiometric consistency, and perceptual quality, provides a principled bridge between visual realism and physical correctness."}, "weaknesses": {"value": "1.While the paper repeatedly emphasizes its “physics-aware”, the methodology relies primarily on heuristic loss formulations rather than an explicit physical modeling framework. No clear theoretical connection is established between the proposed losses and physics. As a result, the term “physics-aware” feels more empirical than principled, potentially overstating the scientific rigor of the approach.\n2.Although most backbone components are frozen, the overall training pipeline still feels fragmented and under-specified, relying on several pretrained modules (VAE, SD3, ControlNet) whose interconnections are not fully transparent.\n3.Key hyperparameters (e.g., λ-weights for each loss) are not justified or tuned systematically."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dwkfdHjAS2", "forum": "9iAWnRGTAU", "replyto": "9iAWnRGTAU", "signatures": ["ICLR.cc/2026/Conference/Submission6375/Reviewer_jpJK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6375/Reviewer_jpJK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6375/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762085751070, "cdate": 1762085751070, "tmdate": 1762918663850, "mdate": 1762918663850, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes RareFlow which is designed OOD-robust super-resolution in remote sensing, especially rare geomorphic features across heterogeneous sensors. The method combines flow-matching with dual conditioning: a Gated ControlNet to preserve fine-grained geometry from the LR input and text prompts to steer complex feature synthesis. Training uses physics-aware losses to enforce spectral/radiometric consistency with sensor properties, and a stochastic forward-pass uncertainty estimates unfamiliar inputs to mitigate hallucinations. A curated cross-sensor benchmark shows large qualitative gains and almost 40% FID reduction over SOTA baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1) They designed losses tied to sensor spectra which helps keeping outputs physically plausible, not just visually sharp. This also ensure that the large-scale radiometric information are preserved and the hallucination is prevented.\n\n2) A gated ControlNet (for structure) plus text prompts (for semantics) jointly handle appearance and geometry under distribution shift.\n\n3) They got a strong performance on benchmark compared to SOTA methods."}, "weaknesses": {"value": "1) How sensitive are the results to prompt wordings? Can you do some ablation on this? \n\n2) Do the physics losses transfer to unseen sensors and bands without retraining? Can you provide any zero-shot evaluation?\n\n3) Do the authors have any intuition why PSNR is low comparatively compared to other metrics in Table 3?\n\n4)  Do the author have some ablations on different parts of the losses. Which components (spectral vs. radiometric) drive more gains? Provide loss term ablations."}, "questions": {"value": "Check the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "GQupSLyQax", "forum": "9iAWnRGTAU", "replyto": "9iAWnRGTAU", "signatures": ["ICLR.cc/2026/Conference/Submission6375/Reviewer_U7Ez"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6375/Reviewer_U7Ez"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6375/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762125346326, "cdate": 1762125346326, "tmdate": 1762918663369, "mdate": 1762918663369, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}