{"id": "zTLMPYaF6F", "number": 14154, "cdate": 1758229338956, "mdate": 1759897387192, "content": {"title": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory", "abstract": "While inference-time scaling enables LLMs to carry out increasingly long and capable reasoning traces, the patterns and insights uncovered during these traces are immediately discarded once the context window is reset for a new query. External memory is a natural way to persist these discoveries, and recent work has shown clear benefits for reasoning-intensive tasks.  We see an opportunity to make such memories more broadly reusable and scalable by moving beyond instance-based memory entries (e.g. exact query/response pairs, or summaries tightly coupled with the original problem context) toward *concept-level memory*: reusable, modular abstractions distilled from solution traces and stored in natural language. For future queries, relevant concepts are selectively retrieved and integrated into the prompt, enabling test-time continual learning without weight updates.  Our design introduces new strategies for abstracting takeaways from rollouts and retrieving entries for new queries, promoting reuse and allowing memory to expand with additional experiences. We evaluate on ARC-AGI, a benchmark that stresses compositional generalization and abstract reasoning, making it a natural fit for concept memory. Our method yields a 7.5% relative gain over a strong no-memory baseline with performance continuing to scale with inference compute. We find abstract concepts to be the most consistent memory design, outscoring the baseline at all tested inference compute scales. Moreover, dynamically updating memory during test-time outperforms fixed settings, supporting the hypothesis that accumulating and abstracting patterns enables further solutions in a form of self-improvement", "tldr": "We introduce a text-based memory system for LLMs emphasizing abstraction and modularity to improve compositional reasoning and enable lifelong learning and demonstrate on ARC-AGI.", "keywords": ["memory", "llm memory", "lifelong learning", "test time adaptation", "ARC-AGI", "compositional reasoning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/be003d06a128c6a3996b9b9def0c6f50d92bc482.pdf", "supplementary_material": "/attachment/9a1443ab31b5b1922e02f38af66bca8b61e8ec60.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces ArcMemo, a framework that augments LLMs with an external memory to retain and reuse insights from past reasoning traces. The central idea is to distill abstract, modular \"concepts\" from solutions rather than storing raw, instance-specific memories. The authors propose two memory formats: an unstructured Open-Ended (OE) format and a more complex Program Synthesis (PS) format that frames concepts as parameterized routines. The system includes components for abstracting new concepts (Memory Write) and retrieving relevant ones for new problems (Memory Read). The method is evaluated on the ARC-AGI benchmark, where it shows improved performance over a no-memory baseline. The paper also presents experiments on test-time continual learning, where the memory is updated during the evaluation process."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "**Novel Conceptual Framework:** The core idea of moving from instance-level storage to abstract, modular concepts is a key strength. It thoughtfully addresses how an LLM might generalize from past experience rather than just retrieving it.\n\n**Strong Empirical Results on a Hard Benchmark:** The paper demonstrates a clear and consistent performance improvement on ARC-AGI, a benchmark known to be very challenging for modern LLMs. The ArcMemo-PS variant outperforms the baseline at all tested inference compute scales.\n\n**Well-Designed Memory Formats:** The paper proposes and analyzes two different memory formats, OE and PS. The PS format, inspired by functional programming, is particularly novel for its encouragement of higher-order functions and compositional reuse .\n\n**Demonstration of Continual Learning:** The experiments showing that a dynamically updated memory improves performance over a fixed one provide strong evidence for the \"lifelong learning\" potential of this approach, at least within the tested domain ."}, "weaknesses": {"value": "**Limited Generalizability of Evaluation:** The entire empirical validation rests on the ARC-AGI benchmark. While challenging, ARC-AGI is a clean, synthetic, and self-contained domain. It is not clear that the proposed methods, especially the highly structured PS format, would be effective in messier, real-world domains like scientific reasoning or complex code generation, where concepts are often ambiguous or less neatly parameterized.\n\n**Incomplete Contextualization Against Intra-Problem Reasoning Methods:** While the related work section is strong, it could be improved by discussing and differentiating ArcMemo from methods designed to handle long-range dependencies within a single task. For instance, works like \"PRISM: Efficient Long-Range Reasoning With Short-Context LLMs\" tackle the context length issue for processing a single long input (e.g., a book).\n\n**Unaddressed Problem of Memory Scalability and Maintenance:** The paper introduces mechanisms for adding concepts to memory but largely ignores the critical long-term challenges of maintaining it. As the memory grows, how does the system handle concept redundancy, contradiction, or obsolescence? The memory-aware abstraction process could become a computational bottleneck with thousands of entries.\n\n**Heavy Reliance on External Feedback:** The Memory Write operation fundamentally depends on having access to a correct solution trace to extract useful concepts. This assumption severely limits the practical applicability of the method, as many important, open-ended reasoning tasks lack such immediate and reliable feedback."}, "questions": {"value": "The reasoning-based selection mechanism is core to the PS method but seems computationally expensive. Can you quantify its cost relative to the baseline inference and discuss how this cost scales with the size of the memory? Do you foresee this \"System 2\" selection becoming a practical bottleneck for a truly lifelong agent with a massive memory store?\n\n1. Your work rightly points out that standard embedding retrieval performed poorly . However, the proposed PS format is quite complex. Did you consider or experiment with intermediate structured formats (e.g., simple typed function signatures, key-value properties) that might offer a better balance between abstraction and retrieval simplicity? This would help justify the necessity of the full complexity of the PS format.\n\n2. The framework requires correct solutions to generate new memories. How would the system perform in a more realistic setting where feedback is sparse or occasionally incorrect? Would the memory quality degrade over time as flawed concepts are inevitably introduced, and are there any mechanisms in place to guard against this?\n\n3. Regarding the selection ablation: you show that selection is generally helpful. However, could you discuss the failure modes of the selection process? When does it retrieve irrelevant or distracting concepts, and what is the impact on downstream performance in those cases? Is it possible for poor selection to make the agent perform worse than the no-memory baseline on certain problems?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "T60x6DjMv2", "forum": "zTLMPYaF6F", "replyto": "zTLMPYaF6F", "signatures": ["ICLR.cc/2026/Conference/Submission14154/Reviewer_qa1C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14154/Reviewer_qa1C"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760548899567, "cdate": 1760548899567, "tmdate": 1762924617336, "mdate": 1762924617336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ArcMemo, a framework that moves from instance-based memory entries to concept-level, reusable, and modular abstractions distilled from natural-language solution traces. The paper presents two implementations, Open-Ended and Program-Synthesis. Through experiments and ablation studies on the ARC-AGI 1 benchmark, the paper demonstrates the effectiveness of abstract reasoning and compositional generalization. The author argues that this is a potential pathway to enable lifelong, test-time learning in reasoning-oriented LLM."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. At the conceptual level, lifelong memory has broad implications for test-time adaptation and reasoning scalability. Although the evaluation is limited to ARC-AGI 1, the proposed idea could potentially generalize to long-horizon reasoning models and even inform the development of self-evolving systems.\n\n2. The methodology is clearly articulated, and the experiments compare against reasonable baselines such as Dynamic Cheatsheet. The inclusion of standard deviation in the reported metrics is commendable, which is a standard yet important measure of reliability that recent reasoning literature often overlooks, typically assuming that pass@1 scores averaged over large rollouts have negligible variance."}, "weaknesses": {"value": "1. The idea of reusing abstract reasoning “concepts” distilled from solution traces has already been introduced and explored in several closely related prior and concurrent works. For example, RLAD [1] formalizes reasoning abstractions as compact, reusable summaries generated by aggregating multiple solution traces for a single problem or across problems. Metacognitive Reuse [2] independently develops a nearly parallel mechanism that transforms recurring reasoning fragments into reusable behaviors. More recently, NuRL [3] (a post-submission work) adopts a similar abstraction definition and generation process, while further integrating abstraction formation directly into the RL training loop.\n\n2. The evaluation remains narrow—limited to ARC-AGI 1—and does not include ARC-AGI 2, ARC-AGI 3, or any math or textual reasoning benchmarks where other abstraction-based methods have been validated (e.g., AIME 2025, HMMT 2025, IMO 2025). Without cross-domain experiments, it is unclear whether ArcMemo’s abstraction mechanism truly captures compositional reasoning or merely memorizes task-specific heuristics.\n\n3. The evaluation and ablation is sounded, but this paper provides little analysis of why or when its memory abstractions help. Without measuring abstraction diversity, redundancy, or transferability, it is difficult to assess whether the improvement arises from genuine conceptual reuse or from simple example recall."}, "questions": {"value": "1. Although the paper claims to move beyond task-specific guidance, the “memory write” operation still generates one abstraction per problem–solution pair, same as NuRL. It is not clear to me how this avoid problem-local rather than cross-problem abstraction learning. To show an example, [1] and [2] explicitly synthesizes abstractions across multiple solutions or problems, allowing the model to generalize higher-order reasoning motifs. A discussion on this could help understand the design choice here. \n\n2. The implementation section mentions seeding ArcMemo’s memory using prior work’s “python solutions”. It is unclear how the method would perform if such initialization were unavailable or needed to bootstrap from scratch. \n\n3. Most of the experimental results are reported in terms of Oracle@k. How does this metric differ from the community-standard pass@k or maj@k evaluation?\n\n4. In Table 1, for ArcMemo-PS, why adding retry also leads standard deviation blows up?\n\n4. In Section 5.3, why does the continual memory update appear to provide little benefit, or even degrade performance when retry = 0 or 1?\n\n[1] Y. Qu, A. Singh, Y. Lee, A. Setlur, R. Salakhutdinov, C. Finn, and A. Kumar, “Learning to Discover Abstractions for LLM Reasoning,” in Workshop on Programmatic Representations for Agent Learning, International Conference on Machine Learning, 2025\n\n[2] Chih-Yao Chen, Justin, et al. \"Nudging the Boundaries of LLM Reasoning.\" arXiv e-prints (2025): arXiv-2509.\n\n[3] Didolkar, Aniket, et al. \"Metacognitive reuse: Turning recurring llm reasoning into concise behaviors.\" arXiv preprint arXiv:2509.13237 (2025)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "xF7eXDy29X", "forum": "zTLMPYaF6F", "replyto": "zTLMPYaF6F", "signatures": ["ICLR.cc/2026/Conference/Submission14154/Reviewer_j2wS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14154/Reviewer_j2wS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761509736674, "cdate": 1761509736674, "tmdate": 1762924616732, "mdate": 1762924616732, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ArcMemo, which implements a memory augmented reasoning system that uses abstraction/concept memories that describe how to solve problems. The authors implement several variants of such a system, defining different characteristics of memories are, how they are retrieved and written. Evaluation on ARC-AGI-1 demonstrates the effectiveness. of the method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "I think this is a very interesting and original paper:\n* **Retrieval for Reasoning** - The methodological approach seems to be effective for expanding the reasoning capabilities of models. It is an interesting approach, which is likely to inspire future work in this direction. \n* **Abstractions** - The definition of abstractions is general and interesting. The OE & PS distinctions are quite interesting also. \n* **Empirical Successes** - The proposed method seems to be quite effective empirically, albeit in the singular setting."}, "weaknesses": {"value": "- **Presentation** - The paper is written very generally (at least for the most part), but there is a single instantiation of the method. Of course, a more general method usually carries more weight. That said, I am not asking the authors to give a second. But perhaps story-telling more about ARC in the introduction could be good. \n- **Presentation** - It would be important to provide all prompts & details of implementation in the appendix. \n- **Model specificity** - Do I understand correctly that the results only use o4 as base model ? How much do you think this system requires o4 or would work directly for other models?"}, "questions": {"value": "1. How would ArcMemo fair with a base model other than o4-mini? (can be your intuition rather than running experiments)\n2. Given Table 3's results is there a reason not to consider retry>=3?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0bJ4aGw00m", "forum": "zTLMPYaF6F", "replyto": "zTLMPYaF6F", "signatures": ["ICLR.cc/2026/Conference/Submission14154/Reviewer_GA2r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14154/Reviewer_GA2r"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762148940715, "cdate": 1762148940715, "tmdate": 1762924616199, "mdate": 1762924616199, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ArcMemo, a memory-augmented framework for LLMs that stores distilled concepts from solution traces in natural language. The system implements three core operations: memory format design, memory write from solution traces, and memory read for new problems. Evaluated on ARC-AGI-1, ArcMemo-PS achieves an over 4% improvement using o4-mini. The method scales with inference compute through retries."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper operationalizes a compelling idea--storing abstractions in conceptual form and using them during inference. I think it's a creative application of programming principles."}, "weaknesses": {"value": "- The evaluation scale is quite limited; experiments are only done on 100 puzzles from ARC-AGI-1. Perhaps due to this, the standard deviations between methods quite frequently overlap.\n- The proposed method has quite a bit of complexity, which I'm not sure is sufficiently justified by the empirical gains.\n- Could you try the method with other models, for example Sonnet 4 or DeepSeek R1? Generally, do you have a sense for how strong the model has to be to benefit from your method? Does it have to be a reasoning model?\n- The method simultaneously introduces many components, including parameterization, typed interfaces, pseudocode preprocessing, and reasoning-based selection. The paper only does ablation on selection, and most of the results there have overlapping standard deviations.\n- For the PS format in particular, how much prompt engineering was required to make this work? Also, I think the appendix should include the prompts as they are likely critical for the method working."}, "questions": {"value": "Please see weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1igYtIlXTq", "forum": "zTLMPYaF6F", "replyto": "zTLMPYaF6F", "signatures": ["ICLR.cc/2026/Conference/Submission14154/Reviewer_rFxx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14154/Reviewer_rFxx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14154/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762230850068, "cdate": 1762230850068, "tmdate": 1762924615426, "mdate": 1762924615426, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}