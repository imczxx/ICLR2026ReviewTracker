{"id": "W2UHin1T0R", "number": 16463, "cdate": 1758264847831, "mdate": 1759897239228, "content": {"title": "Learning to Describe Urban Change: Graph-Guided Detection and spatio-Temporal State Space Model with Uncertainty Estimation", "abstract": "Automated change detection (CD) and captioning from satellite imagery plays a crucial role in urban development monitoring, infrastructure assessment, and land-use analysis. However, existing change captioning systems lack uncertainty quantification, making it challenging to assess prediction reliability when analysing critical infrastructure changes, building construction, or environmental modifications where inaccurate interpretations could impact urban planning decisions or infrastructure management. We address this limitation through a comprehensive pipeline combining SemanticGraphCD module for enhanced change detection with a State Space Model(SSM)-based captioning module for scalable description generation. SemanticGraphCD integrates graph neural networks with task-agnostic semantic learning, employing an adaptive processing mechanism that dynamically switches between GNN-based feature propagation and convolutional operations. This architecture learns semantic representations through bi-temporal consistency constraints, better discriminating meaningful infrastructure and land-use changes from temporal variations in very high-resolution imagery. The State Space Model based captioning module contains a Spatial Difference-aware SSM (SD-SSM) which improves upon previous CNN and Transformer-based models in receptive field. Moreover a Temporal Traversing SSM (TT-SSM) is used which scans bi-temporal features in a temporal cross-wise manner enhancing the model's temporal understanding and information interaction. This SSM is guided by SemanticGraphCD's change masks using a convolutional focusing module which aggregates change information from the masks with the bitemporal images. This guides the model in representing the changes between the bi-temporal images within the state space model hidden states, enabling linear computational scaling while maintaining competitive performance. Instead of treating all caption tokens equally in the context of change detection, we introduce Semantic-Weighted Sentence Entropy (SWSE) for principled uncertainty quantification. SWSE emphasizes domain-relevant vocabulary over function words, providing interpretable confidence measures that correlate with caption quality. Experimental results demonstrate that our approach achieves improvement in captioning performance compared to existing state space models, while SWSE provides reliable uncertainty estimates for informed decision-making in urban monitoring applications.", "tldr": "We propose  SemanticGraphCD for robust change detection with an SSM-based captioning model, enhanced by Semantic-Weighted Sentence Entropy (SWSE), which estimates uncertainty in satellite image change captioning for urban monitoring.", "keywords": ["Change Detection", "Change Captioning", "State Space Model", "Uncertainity Estimation", "Urban development monitoring", "Deep Learning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b36a0fb3886848c2af9758ddcccd18af3c84f0c7.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a unified pipeline for change detection and captioning from bi-temporal remote sensing images. The key contributions include a novel change detection backbone (SemanticGraphCD) that combines GNNs and CNNs, a State Space Model (SSM)-based captioning module with Spatial Difference-aware SSM (SD-SSM) and Temporal Traversing SSM (TT-SSM) for efficient spatio-temporal modeling, and a new uncertainty metric, Semantic-Weighted Sentence Entropy (SWSE). Evaluated on LEVIR-CC and LEVIR-MCI datasets, the method claims state-of-the-art performance and provides interpretable confidence scores for decision-support systems."}, "soundness": {"value": 1}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The hybrid GNN-SSM architecture and the semantically-weighted uncertainty metric (SWSE) are innovative contributions tailored to the challenges of remote sensing change captioning. The work bridges vision-language modeling and reliability estimation, a crucial step towards trustworthy decision-support systems in safety-critical applications like urban planning and disaster response."}, "weaknesses": {"value": "1.\tThe paper fails to provide essential implementation details for its core innovations. Specifically: the graph structure and \"task-agnostic learning\" objective in SemanticGraphCD; the specific parameterization and operational mechanisms of \"spatial difference awareness\" in SD-SSM and \"cross-wise scanning\" in TT-SSM. This severely hampers reproducibility and accurate assessment of their novelty.\n2.\tComputational efficiency claims are not backed by hardware-agnostic metrics (FLOPs, memory) or runtime comparisons.\n3.\tThe ablation study lacks depth, failing to quantify the individual contribution of each proposed module.\n4.\tGeneralization is only tested on two related datasets, lacking cross-dataset evaluation.\n5.\tThe semantic weight values in SWSE appear to be set heuristically without validation (e.g., sensitivity analysis).\n6.\tThere is no mention of code release, which is critical for a work with multiple complex, custom components."}, "questions": {"value": "1.\tCould the abstract be revised to be more concise, focusing on the core problem, high-level approach, key results, and impact, while moving detailed module descriptions into the main body?\n2.\tImplementation of Core Modules: Could you provide:\n3.\tDetailed architecture diagrams or pseudocode for SemanticGraphCD, specifically explaining the graph construction and the \"task-agnostic learning\" mechanism?\n4.\tThe precise mathematical formulation or algorithmic description of how \"spatial difference awareness\" is integrated into the SSM (for SD-SSM) and the exact \"cross-scanning\" path (for TT-SSM)?\n5.\tPlease report computational metrics (e.g., FLOPs, inference time) comparing your SSM-based captioner with a standard transformer-based baseline.\n6.\tCould you provide a more comprehensive ablation study that clearly isolates the performance gain from SD-SSM, TT-SSM, and the convolutional focusing module individually?\n7.\tHave you evaluated the model's performance on other public change detection/captioning datasets to demonstrate broader generalization?\n8.\tHow were the specific semantic weight values in SWSE determined? Please provide an ablation study or theoretical justification for this weighting scheme.\n9.\tWill the source code and trained models be made publicly available to ensure the reproducibility of these results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2TtGmMJ6hK", "forum": "W2UHin1T0R", "replyto": "W2UHin1T0R", "signatures": ["ICLR.cc/2026/Conference/Submission16463/Reviewer_pwYV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16463/Reviewer_pwYV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761016374302, "cdate": 1761016374302, "tmdate": 1762926573399, "mdate": 1762926573399, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors proposes a novel method to generate change detection captions of remote sensing images.\nThe model takes as input two remote sensing images to produces a change mask. That mask is then used to extract the relevant parts in the original image (Image Enhancement), and passed through a CLIP backbone, State Space Model and finally passed through a Language decoder to generate the change caption.\nIn addition, the authors introduce \"semantic weighted sentence entropy\" (SWSE), which ads weights to the words in the generated caption, depending on their importance: (in order of increasing importance) function words, descriptors, natural features, land use, and infrastructure categories respectively."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The proposed method seems to be on par or slightly improving over other state of the art methods. The proposed metric of weighting the words in the captions differently is an interesting approach that could potentially lead to more accurate captioning."}, "weaknesses": {"value": "The paper is a little hard to follow, I have a hard time understanding some of the aspects. For example,  the way SemanticGraphCD is introduced makes it seem like it is a well known method, but lacks references. Later, it appears that SemanticGraphCD is new and introduced in the paper. But this is not explicitly stated in the paper.\nOverall, the methods are a bit hard to follow, there are a lot of moving parts. Figure 1 helps, but the figure isn't very clear. Each step could be illustrated more and explain what the inputs are, and how they are combined.\n\nI am not sure the paper is actually doing uncertainty quantification. SWSE is introduced as a new metric, which can make sense - although introducing a new metric to evaluate the proposed methods is heavily biased towards the new method. But it doesn't seem like the model is doing uncertainty quantification. Furthermore, how are the weights of SWSE chosen? Again, this could be engineered towards making the model seem more performing than it is.\n\nThe proposed method, although sound, has a lot of complicated parts. It is unclear to me how some of these parts help in the performance of the model. As no ablation study has been performed, it is hard to say with certainty that the steps are actually necessary. In addition, SemanticGraphCD seems very complicated just for change detection. How does it compare to simpler methods?\n\nLastly, the proposed model doesn't actually perform that well when compared to other methods. In table 2, other models perform better in 3 of the six metrics (PSNet performs better than the proposed model for BLEU-2, the bolding is wrong). It doesn't seem like the proposed methods advances the field significantly.\n\nI would also welcome a qualitative assessment with more examples where the model fails.\n\nMinor issues: \n- in a lot of places, citations wrongly use the inline style (citet) instead of in parentheses (citep)\n- Heading 3.2 is wrong, should read \"Quantitative\" and not \"Qualitative\".\n- PSNet performs better than the proposed model for BLEU-2, the bolding is wrong\n- line 20: missing space \"Model(SSM\"\n- line 245: missing parenthesis around \"equation 1\"\n- Line 385: \"The\" is not needed at sentence start"}, "questions": {"value": "What is the source of the remote sensing images?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "x1DkIwNia0", "forum": "W2UHin1T0R", "replyto": "W2UHin1T0R", "signatures": ["ICLR.cc/2026/Conference/Submission16463/Reviewer_m4dD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16463/Reviewer_m4dD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761602466596, "cdate": 1761602466596, "tmdate": 1762926572853, "mdate": 1762926572853, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a framework for urban change detection and captioning from satellite imagery that integrates a graph-based detection module and a state-space model (SSM)–based captioning system with uncertainty estimation. The method combines: (1) SemanticGraphCD, a graph neural network with adaptive processing between GNN propagation and convolutional operations; (2) Spatial Difference-aware SSM (SD-SSM) and Temporal Traversing SSM (TT-SSM) for enhanced spatio-temporal modeling; and (3) Semantic-Weighted Sentence Entropy (SWSE) for uncertainty quantification, emphasizing domain-relevant vocabulary. The paper claims improved captioning accuracy and interpretable uncertainty estimates compared to previous SSM-based approaches."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The integration of change detection and captioning is a meaningful goal for urban monitoring.\n\n- The idea of incorporating uncertainty quantification through SWSE is potentially useful."}, "weaknesses": {"value": "- The abstract is overly long and fails to clearly state the motivation and core problem, giving an impression of poor focus. The abstract includes too much architectural detail (e.g., descriptions of SemanticGraphCD, SD-SSM, TT-SSM, and SWSE) without first clarifying why these components are needed. It spends nearly the entire length listing modules and mechanisms, but only briefly mentions the underlying problem that current change captioning systems lack uncertainty quantification. As a result, the reader does not immediately understand the main research gap or the practical significance of the work. A clearer abstract should first motivate why uncertainty in change captioning is critical, then summarize the method and findings.\n\n- The citation format is incorrect and unpolished. For example, the paper writes \"With the increasing availability of high-resolution satellite data from missions like Landsat Wulder et al. (2019), Sentinel Drusch et al. (2012), and commercial providers Li et al. (2022b) …\", where the citations are appended without proper integration into the sentence. This gives the paper an unpolished feel and makes it harder to read.\n\n- Related work on change detection is outdated, missing more recent literature: \"Deep learning revolutionized the field\nwith convolutional neural networks (CNNs) Zhang & Li (2017); Daudt et al. (2018) that could automatically learn hierarchical features, followed by more advanced architectures like U-Net variants Peng et al. (2019) and attention mechanisms Chen & Shi (2020).\" There are definitely works about change detection after 2020, such as [1] Chen, Hongruixuan, et al. \"ChangeMamba: Remote sensing change detection with spatiotemporal state space model.\" IEEE Transactions on Geoscience and Remote Sensing 62 (2024): 1-20. [2] Fang, Sheng, Kaiyu Li, and Zhe Li. \"Changer: Feature interaction is what you need for change detection.\" IEEE Transactions on Geoscience and Remote Sensing 61 (2023): 1-11.\n\n- Table 1 lists manually set weights, but no rationale or sensitivity analysis is provided to show how these values affect results.\n\n- Section 3.2's title should be \"quantitative results\" rather than \"qualitative results\".\n\n- While the paper lists many baselines (e.g., MCCFormer, PSNet), it does not explain why these particular models were chosen or how they were adapted for the current task.\n\n- No ablation study is provided to isolate contributions of individual modules (SemanticGraphCD, SD-SSM, TT-SSM, SWSE). That would be particularly useful to verify whether each module (SemanticGraphCD, SD-SSM, TT-SSM, SWSE) contributes meaningfully to the overall performance.\n\n- The inclusion of an unfinished Acknowledgements section violates ICLR’s anonymity policy.\n\n- Overall, the writing is hard to follow, and the technical presentation lacks clarity and rigor."}, "questions": {"value": "Please refer to Weaknesses.\n\nWhile the topic of combining change detection, captioning, and uncertainty estimation is interesting, the paper suffers from serious presentation issues, unclear motivation, lack of experimental rigor, and incomplete justification of design choices. It does not meet ICLR’s standard of clarity or scientific soundness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tN6NvAu7o0", "forum": "W2UHin1T0R", "replyto": "W2UHin1T0R", "signatures": ["ICLR.cc/2026/Conference/Submission16463/Reviewer_Tqbn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16463/Reviewer_Tqbn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998120593, "cdate": 1761998120593, "tmdate": 1762926572392, "mdate": 1762926572392, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript aims to present a comprehensive pipeline for automated change captioning from remote sensing imagery. The pipeline integrates SemanticGraphCD, state space models, Semantic Weighted Sentence Entropy."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The paper identifies a critical and underexplored challenge: the absence of uncertainty quantification in existing change captioning systems for remote sensing. This is a well-motivated problem. It is a small contribution to use Semantic Weighted Sentence Entropy for principled uncertainty quantification."}, "weaknesses": {"value": "1、The overall writing and structural logic of the paper are disorganized. The authors present a series of loosely connected motivations and then stack multiple pre-existing components without clear theoretical integration. As a result, the contribution appears engineering-driven rather than scientifically innovative.\n\n2、The paper highlights the SD-SSM and TT-SSM as key innovations for spatial-temporal reasoning. However, these modules have already been introduced in RSCaMa (2024). Simply reusing or reconfiguring such components without conceptual advancement does not constitute a novel contribution.\n\n3、The overall text annotations in the LEVIR-CC and LEVIR-MCI datasets are actually the same. It is recommended to experiment on other datasets, such as the WHU-CDC dataset.\n\n4、While the method section explains why each module (SemanticGraphCD, SD-SSM, TT-SSM, SWSE) is introduced, it lacks details on how they are technically implemented. The paper omits critical aspects such as the mathematical formulation of the SSM components, the adaptive mechanism of SemanticGraphCD, and how SWSE is integrated into the training pipeline. Without these details, the reproducibility and scientific rigor of the method remain questionable.\n\n5、The introduction overlooks several recent advances (2024–2025) in remote sensing change detection and captioning—especially works leveraging state space models (e.g., Mamba variants) and uncertainty-aware captioning frameworks. This omission makes it difficult to assess the originality and relevance of the proposed work within the current research landscape.\n\n6、The paper does not present sufficient ablation studies to quantify the individual contributions of each proposed component (SemanticGraphCD, SD-SSM, TT-SSM, SWSE).\n\n7、The evaluation compares the proposed method mainly with models from 2020–2023 (e.g., PSNet, RSICCFormer), but omits more recent and competitive 2024–2025 methods. Without these, it is difficult to determine whether the method truly achieves state-of-the-art performance.\n\n8、Although Semantic Weighted Sentence Entropy (SWSE) is an interesting idea, it lacks a solid theoretical basis. The weighting scheme appears to be heuristically assigned rather than learned or validated. The paper does not provide empirical evidence showing that SWSE correlates with actual uncertainty or reliability in generated captions.\n\n9、Many of the references in the paper are incorrect, such as the authors and journals listed. Please check carefully."}, "questions": {"value": "1.Can the authors clarify the exact architectural differences between their SD-SSM/TT-SSM and those used in RSCaMa (2024)? If they are reused or modified, please specify the improvements quantitatively or structurally\n\n2.Regarding SWSE, how were the token importance weights determined (e.g., manual heuristics or learned via optimization)? \n\n3.Could the authors provide ablation results isolating the contributions of SemanticGraphCD, SD-SSM, TT-SSM, and SWSE individually? This would clarify which component contributes most to the observed performance gains."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "wZsMzYk5mP", "forum": "W2UHin1T0R", "replyto": "W2UHin1T0R", "signatures": ["ICLR.cc/2026/Conference/Submission16463/Reviewer_4f7S"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16463/Reviewer_4f7S"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16463/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762088011165, "cdate": 1762088011165, "tmdate": 1762926571988, "mdate": 1762926571988, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}