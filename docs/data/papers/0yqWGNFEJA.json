{"id": "0yqWGNFEJA", "number": 22504, "cdate": 1758331999885, "mdate": 1759896862355, "content": {"title": "DMIL-Net: A Multi-View Fusion and Region Decoupling Network For Diffusion-Based Generative Image Forgery Localization", "abstract": "With the increasing application of image generation technology in artistic creation and image editing, its potential for misuse in image forgery has also become increasingly prominent, posing new challenges to verifying image authenticity. In response to this issue, we propose the DMIL-Net. Specifically, we first design a multi-view feature learning strategy combining RGB views, noise views, and high-frequency information to fully capture clues from forgery regions. Secondly, we introduce multi-level contrastive learning to capture long-term dependencies across different modalities, leading to better fusion of multi-view features. Finally, we propose a forgery region decoupling and integration strategy, which iteratively decouples and integrates the body region and detail region to generate complete and detail-accurate localization results. In addition, we construct the DMI dataset, which contains 50,000 generative forgery images created via five prevalent diffusion-based generative image forgery methods, to support model training and testing. Experimental results show that DMIL-Net outperforms five mainstream methods on localization performance, generalization, extensibility, and robustness.", "tldr": "We introduce DMIL-Net to ​​effectively​​ localize generative forgeries produced by diffusion-based image inpainting through multi-view feature fusion and hierarchical region decoupling.", "keywords": ["Generative Image Forgery Localization; Image Manipulation Detection; Forgery Image Dataset;  Diffusion Model"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/995002769eeb56d07e5d51d22515fd2499cc32be.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces DMIL-Net, a new framework for diffusion-based generative image forgery localization (DMIL). The model leverages three key strategies:\n\n- Multi-view feature learning, integrating RGB, noise, and high-frequency information to capture tampering cues.\n\n- Multi-level contrastive learning, enhancing long-range dependencies across modalities and improving feature fusion.\n\n- Region decoupling and integration, which separately models body and detail regions for more accurate localization.\n\nIn addition, the authors introduce a new dataset, DMI, comprising 50,000 forged images generated by five diffusion-based inpainting methods with various post-processing operations. Experimental results show that DMIL-Net surpasses existing SOTA methods in localization accuracy, generalization, extensibility, and robustness."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Comprehensive architecture: The proposed combination of multi-view learning and multi-level contrastive fusion is well-motivated and carefully designed.\n\n- Thorough experiments: Extensive evaluations are provided, including ablation, cross-dataset generalization, extensibility to classical datasets, and robustness tests under noise and compression attacks."}, "weaknesses": {"value": "- The Method section is somewhat complex, with numerous formulas and detailed information, making it difficult to read. The lack of detailed descriptions of each module's functionality (including the problems it addresses and how they are solved) makes it difficult to understand the innovations of DMIL-Net.\n\n- The extraction and learning of multi-view and multi-level features have been covered in other papers (e.g., MVSS-Net[1], MMFusion[2]). However, it seems that the authors do not show how to better utilize these features to localize tampering in diffusion-based generation images, which also weakens the innovation of the article.\n\n- The DMI Dataset, one of the article's innovations, doesn't quite fit the description in the Experiment section. Secondly, DMI simply aggregates existing image editing models to construct it, making it seem like an engineering exercise rather than an innovation.\n\n- In ablation experiments, the improvement in localization performance across various modules is unclear. For example, the effect of NRE can only be seen by comparing Scheme 2 and Scheme 3, but it's unclear whether this improvement is related to the presence of HFE. It would be better to add NRE directly to Scheme 1 and conduct a comparison. Similar experimental verification may also be required for other modules.\n\nOverall: The main problem with the article is that the Method section is overly complex, lacking the necessary motivations and key design details for each module. The excessive detail obscures the core innovations. Furthermore, the overall structure of the article is somewhat unbalanced. For example, the DMI Dataset, one of the innovations, is only briefly described in the Experiment section.\n\nMinor Issues:\n\n- Line 174, $r_i,n_i,n_i$ should be corrected to $r_i,h_i,n_i$.\n\n[1] MVSS-Net: Multi-View Multi-Scale Supervised Networks for Image Manipulation Detection\n\n[2] Exploring Multi-Modal Fusion for Image Manipulation Detection and Localization"}, "questions": {"value": "Please refer to the Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gRavgw1iNn", "forum": "0yqWGNFEJA", "replyto": "0yqWGNFEJA", "signatures": ["ICLR.cc/2026/Conference/Submission22504/Reviewer_8n7g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22504/Reviewer_8n7g"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760930892399, "cdate": 1760930892399, "tmdate": 1762942246375, "mdate": 1762942246375, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the challenge of detecting and localizing tampered regions in images generated by diffusion-based models, which are increasingly difficult to distinguish due to their high fidelity. The authors propose DMIL-Net, a novel framework that integrates multi-view feature learning (combining RGB, noise, and high-frequency domains), multi-level contrastive learning for cross-modal dependency modeling, and a region decoupling strategy that separates tampered areas into body and edge components for iterative refinement. A key contribution is the construction of the DMI dataset, containing 50,000 synthetic forgery images generated via five prevalent diffusion methods, annotated with diverse tampering patterns including object removal, text-guided editing, and shape-aware manipulation. Extensive experiments demonstrate superior performance over existing methods in localization accuracy, robustness to distribution shifts, and generalization across different tampering scenarios, with ablation studies validating the effectiveness of each architectural component."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Originality\nThe paper demonstrates strong originality through both methodological innovation and dataset contribution. The proposed DMIL-Net framework creatively combines multi-view feature learning (RGB, noise, and high-frequency domains) with multi-level contrastive learning to model cross-modal dependencies, which is a novel approach for diffusion-based forgery detection. The region decoupling strategy—iteratively refining tampered areas by separating body and edge components—is a new perspective that addresses the inherent challenges of diffusion-generated forgeries. Additionally, the construction of the DMI dataset (50,000 synthetic images generated via five diffusion methods, annotated with diverse tampering patterns) is an original contribution, as existing datasets focus on traditional forgeries (e.g., copy-paste, splicing) but lack coverage of diffusion-specific manipulations. \n\nQuality:\nThe experimental validation is thorough and methodologically sound. The authors compare DMIL-Net against state-of-the-art methods across multiple metrics (e.g., localization accuracy, robustness to distribution shifts) and demonstrate consistent improvements. Ablation studies meticulously disentangle the contributions of individual components (e.g., multi-view features, contrastive learning, region decoupling), providing strong empirical support for their design choices. The evaluation includes diverse tampering scenarios (object removal, text-guided editing, shape-aware manipulation) and tests generalization across unseen diffusion models, which strengthens the credibility of the claims. The technical depth and reproducibility are further enhanced by detailed implementation details and public dataset availability.\n\nClarity:\nThe problem formulation is clearly articulated in the introduction, with a concise overview of limitations in prior work. The methodology section logically unfolds the design of DMIL-Net, using intuitive diagrams and pseudocode to explain complex components like the multi-level contrastive module and region decoupling. The experiments are presented in a structured manner, with comparisons to baselines and qualitative results that effectively highlight the method’s strengths. Technical terms are well-defined, and the language is precise without being overly verbose, making the paper accessible to both domain experts and broader machine learning audiences.\n\nSignificance:\nThe work addresses a highly relevant and timely problem: detecting forgeries generated by diffusion models, which are rapidly becoming the dominant paradigm in image synthesis. As diffusion-based manipulations grow in sophistication and prevalence, the ability to detect and localize tampered regions is critical for applications in security, forensics, and media integrity. The proposed framework not only advances the technical capabilities of forgery detection but also provides the community with a benchmark dataset that will catalyze future research."}, "weaknesses": {"value": "1. Limited Evaluation on Real-World Data and Generalization to Unseen Manipulation Types\nWhile the DMI dataset is comprehensive for diffusion-based forgeries, it is entirely synthetic. The experiments focus exclusively on this synthetic data, leaving open critical questions about the method’s performance on real-world tampered images (e.g., from social media or forensic casework). Additionally, the synthetic forgeries in DMI are generated via only five diffusion methods and three tampering patterns (object removal, text-guided editing, shape-aware manipulation). Real-world scenarios may involve hybrid manipulations (e.g., combining object removal with style transfer) or novel diffusion variants not included in the training set. The paper does not address how DMIL-Net might generalize to such cases, nor does it provide results on existing real-world forensic datasets (e.g., Columbia or MICC datasets adapted for diffusion forgeries). \n\n2. Over-Reliance on Multi-View Features Without Ablation on Computational Cost\nThe multi-view feature learning (RGB, noise, high-frequency domains) is a key strength, but the paper does not analyze the computational trade-off between accuracy and inference speed. For instance, the high-frequency domain extraction (e.g., Laplacian filtering) adds preprocessing steps that may be computationally expensive in deployment. Furthermore, the ablation study focuses only on feature contribution, not on whether the added complexity is justified for real-time applications. \n\n3. Lack of Theoretical Justification for Region Decoupling Strategy\nThe region decoupling strategy (separating tampered areas into body and edge components for iterative refinement) is empirically effective but lacks a theoretical foundation. The paper does not explain why separating these components improves performance—does the decoupling reduce intra-class variability in tampered regions? Does it mitigate boundary ambiguity in diffusion-generated forgeries? Without a principled explanation, the approach risks being seen as an ad hoc heuristic rather than a generalizable framework. \n\n4. Incomplete Comparison to Non-Diffusion-Based Forgery Detection Methods\nWhile the paper compares DMIL-Net to state-of-the-art diffusion-specific methods, it does not benchmark against traditional forgery detection approaches (e.g., image splicing detection or GAN-based forgery localization). This omission is significant because some traditional methods (e.g., detecting noise inconsistencies or illumination artifacts) might still perform reasonably well on diffusion forgeries, especially for simpler tampering types like object removal. \n\n5. Ambiguity in \"Tampered Edge\" Definition and Annotation Consistency\nThe DMI dataset annotations define \"tampered edges\" as boundaries between forged and authentic regions, but the paper does not specify how these edges were annotated (e.g., manually by experts, automated post-processing of diffusion outputs). If annotations are noisy or inconsistent (e.g., blurry edges or misaligned masks), this could bias the evaluation of the region decoupling strategy. \n\n6. Limited Discussion on Adversarial Robustness\nThe paper emphasizes robustness to distribution shifts but does not test whether DMIL-Net is vulnerable to adversarial attacks (e.g., small perturbations designed to fool forgery detectors). Given the adversarial nature of diffusion-based forgeries (e.g., attackers may optimize for stealthiness), this is a critical gap. Improvement: Evaluate the model under adversarial conditions (e.g., FGSM or PGD attacks) and propose mitigation strategies (e.g., adversarial training or input purification)."}, "questions": {"value": "1. Real-World Generalization and Unseen Tampering Types\nThe experiments focus entirely on synthetic data from five diffusion methods and three tampering patterns. How does DMIL-Net perform on real-world tampered images (e.g., social media or forensic datasets) or hybrid/unknown manipulation types (e.g., diffusion-based forgeries combined with traditional splicing)?\n\n2. Computational Cost of Multi-View Features\nThe multi-view feature learning (RGB, noise, high-frequency domains) improves accuracy but adds preprocessing steps (e.g., Laplacian filtering). What is the trade-off between accuracy gains and inference speed/memory usage compared to simpler baselines (e.g., using only RGB features)?\n\n3. Theoretical Justification for Region Decoupling\nThe region decoupling strategy (body-edge separation) is empirically effective, but the paper lacks a theoretical explanation for why this approach improves localization. Is there a principled connection between diffusion model properties and the decoupling mechanism?\n\n4. Comparison to Traditional Forgery Detection Methods\nThe paper compares DMIL-Net to diffusion-specific methods but omits traditional forgery detection techniques (e.g., noise inconsistency or illumination-based methods). Are these methods competitive on diffusion forgeries, and if not, why?\n\n5. Annotation Consistency in the DMI Dataset\nThe DMI dataset defines \"tampered edges\" but does not clarify how annotations were created (e.g., manual vs. automated). How consistent are the edge annotations across annotators or diffusion methods?\n\n6. Adversarial Robustness of DMIL-Net\nThe paper claims robustness to distribution shifts but does not test adversarial attacks (e.g., FGSM or PGD). Could diffusion-based forgeries be optimized to evade DMIL-Net?\n\n7. Interpretability of Multi-Level Contrastive Learning\nThe multi-level contrastive learning module models cross-modal dependencies but does not explain how these dependencies correlate with tampering artifacts. Can the authors provide visualizations or feature maps to interpret what the module learns?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "FxgowJzfZx", "forum": "0yqWGNFEJA", "replyto": "0yqWGNFEJA", "signatures": ["ICLR.cc/2026/Conference/Submission22504/Reviewer_qXSa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22504/Reviewer_qXSa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761620038815, "cdate": 1761620038815, "tmdate": 1762942246113, "mdate": 1762942246113, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript focuses on diffusion-based generative image forgery localization and introduces a framework called DMIL-Net. The proposed model integrates multi-view feature learning, multi-level contrastive learning, and a region decoupling–integration strategy to achieve accurate and detailed forgery localization. In addition, the authors construct a DMI dataset to support model training and evaluation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The task of diffusion-based generative image forgery localization is novel and meaningful, and the constructed DMI dataset provides support and benchmarking resources for future research."}, "weaknesses": {"value": "**Limited methodological innovation.** The core designs of the DMIL-Net framework, i.e., multi-view feature learning, multi-level contrastive learning, and region decoupling and integration, are relatively common design choices in existing image forgery detection and localization (IFDL) research. While the combination is reasonable in diffusion-based generative image forgery localization, the methodological novelty is moderate.\n\n**The description of DMI dataset is insufficient.** Although the DMI dataset is presented as an important contribution, this manuscript provides limited detail and lacks qualitative examples or analyses, which makes it difficult to fully understand its characteristics and significance.\n\n**The experimental evaluation needs to be more comprehensive.** Only the F1 score is reported, while key metrics such as AUC and IoU, commonly used in IFDL tasks, are missing. This makes the evaluation less comprehensive."}, "questions": {"value": "How does DMIL-Net perform at the image level? Does it tend to produce a high false positive rate?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3YU374Fz7v", "forum": "0yqWGNFEJA", "replyto": "0yqWGNFEJA", "signatures": ["ICLR.cc/2026/Conference/Submission22504/Reviewer_KvHj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22504/Reviewer_KvHj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761848632197, "cdate": 1761848632197, "tmdate": 1762942245856, "mdate": 1762942245856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces DMIL-Net, a multi-view fusion and region decoupling network designed for diffusion-based generative image forgery localization (DMIL).\nThe approach first captures tampering traces through three complementary views: RGB, noise residual, and high-frequency streams. Then, a multi-level contrastive learning (MCL) strategy is employed to align these feature spaces. Finally, a region decoupling and integration framework separates tampered regions into “body” and “detail” components via multiple decoder branches.\nTo support this task, the authors also propose a new DMI dataset with 50,000 forged images generated by five diffusion-based inpainting and editing models (BrushNet, Paint-by-Example, Inpaint Anything, PowerPaint, and Repaint).\nExtensive experiments on DMI and other benchmark datasets are presented, showing improvements over several existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The work focuses on the detection of diffusion-based forgeries, an emerging challenge in multimedia forensics.\n2. The proposed DMI dataset is large-scale and diverse, covering multiple diffusion models and manipulation types. If publicly released, it could serve as a useful benchmark for the community.\n3. The paper incorporates RGB, noise, and frequency information, which is intuitively reasonable and might improve the model’s ability to detect subtle generative inconsistencies.\n4. The paper presents ablation studies, cross-dataset testing, and robustness experiments, suggesting careful empirical evaluation."}, "weaknesses": {"value": "1. The proposed framework has limited novelty and conceptual contribution, which mainly integrates existing components, such as multi-view fusion, contrastive learning, and multi-branch decoders, that are well-known in image forensics, without introducing a brand new insight or distinctive mechanism.\n2. In Section 3, the Capturing Tamper Traces module follows standard noise/frequency extraction strategies widely used in prior work (e.g., MVSS-Net, EMF-Net, Mesorch, IML-ViT).\n3. The Multi-Level Contrastive Learning resembles existing pixel-level contrastive schemes from CFL-Net (WACV 2023) and MPC[1], which makes me believe that there's limited contribution, from my point of view.\n4. The Region Decoupling and Integration mechanism is highly similar to hierarchical decoders in MVSS-Net or coarse-to-fine refinement modules in TruFor.\n5. It's a heavy problem that the framework is an overly complicated and poorly motivated architecture. For example, the paper includes a large number of modules (NRE, HFE, BAB, DAB, IFB, CPD, EPM, REB, EEB), resulting in a very heavy and difficult-to-understand design. More importantly, the motivation for each level of modular granularity is unclear, and the paper lacks discussion on why each component is necessary or how they interact synergistically. \n6. Figure 2 references modules such as the Region Enhancement Block (REB) that are never described in the main text. Moreover, the paper states that BAB is structurally identical to DAB, but then uses different names without explaining their distinction or specific functionality.\n7. At line 199, the paper mentions a semi-hard example sampling strategy (SHES) and even shows it in Figure 4, but no textual explanation or citation is provided. \n8. At line 202, a fixed configuration of 512 negative samples + 10 positive samples per class is adopted for constructing the memory bank. However, no motivation or sensitivity analysis is offered. Considering that forgery regions vary greatly in size, a fixed sampling ratio may bias the representation. Without justification, these design choices appear arbitrary and may limit reproducibility.\n9. At line 289, there is an invalid or unresolved reference [28], which should be corrected. Besides, several formulae are overloaded and lack intermediate explanations, making it difficult to follow the data flow.\n10. There is no analysis of computational efficiency, parameter count, or inference time, making the method difficult to reproduce or compare fairly.\n11. The paper presents an incomplete comparison with recent state-of-the-art methods. The comparison excludes several relevant and competitive models that directly address AI-based or diffusion forgeries, such as CAT-Net, TruFor (CVPR 2023), IML-ViT (AAAI 2024), Mesorch [2] (AAAI 2025), and SparseViT[3](AAAI 2025). Without these, it isn't easy to assess the real advancement of DMIL-Net relative to the current state of the art. The claim of superiority is therefore not fully convincing.\n12. In experiments, Table 1 and Table 2 show extremely small gains between configurations. Such marginal improvements do not convincingly demonstrate the necessity or effectiveness of each proposed block.\n13. The DMI dataset creation process is not well-documented. The specific prompts, diffusion model versions (e.g., Stable Diffusion 1.5 vs SDXL), and hyperparameters are not stated and not included in the supplementary, thus I believe the dataset description lacks transparency and reproducibility.\n\nOverall, I believe its technical novelty is limited, and the architecture is over-complicated and poorly justified. Several submodules (e.g., REB, SHES) are mentioned but never explained, and the ablation improvements are too minor to substantiate the effectiveness of the design. The experimental comparison lacks major recent related baselines, and the dataset description is insufficient for reproducibility.\nOverall, the work represents an incremental combination of existing ideas rather than a new advance, falling short of the standards required for acceptance at a top-tier venue.\n\n[1] Lou, Zijie, et al. \"Exploring multi-view pixel contrast for general and robust image forgery localization.\" IEEE Transactions on Information Forensics and Security (2025).\n[2] Zhu, Xuekang, et al. \"Mesoscopic insights: orchestrating multi-scale & hybrid architecture for image manipulation localization.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 39. No. 10. 2025.\n[3] Su, Lei, et al. \"Can we get rid of handcrafted feature extractors? sparsevit: Nonsemantics-centered, parameter-efficient image manipulation localization through spare-coding transformer.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 39. No. 7. 2025."}, "questions": {"value": "1. Why are some submodules like REB not described, while BAB and DAB are said to be identical? What is their functional distinction?\n2. Could you explain the rationale for using a fixed 512/10 sampling in the memory bank? Did you test variable ratios depending on the forgery size?\n3. What exactly is the “semi-hard example sampling strategy” (SHES) in Figure 4? Please describe it explicitly.\n4. Please correct the missing citation [28] at line 289 and verify all other references.\n5. How do the small performance increments in Tables 1 and 2 support the claimed effectiveness of each module? I'm not sure such a heavy design is helpful. Can you report confidence intervals or variance?\n6. Why are key SOTA methods (CAT-Net, TruFor, IML-ViT, SparseViT) omitted from comparison?\n7. Will the DMI dataset, including prompt texts and model versions, be released for public use?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ly4KWq2xnK", "forum": "0yqWGNFEJA", "replyto": "0yqWGNFEJA", "signatures": ["ICLR.cc/2026/Conference/Submission22504/Reviewer_7GmT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22504/Reviewer_7GmT"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22504/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923088987, "cdate": 1761923088987, "tmdate": 1762942245628, "mdate": 1762942245628, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}