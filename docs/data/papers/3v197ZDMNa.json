{"id": "3v197ZDMNa", "number": 6330, "cdate": 1757968952272, "mdate": 1762924015193, "content": {"title": "Learning Causal Structures from Mixed Dynamics via Polynomial Chaos Expansion", "abstract": "Real-world systems are rarely purely linear or nonlinear, but are instead a complex mixture of both. This heterogeneity makes them exceedingly difficult for standard causal discovery algorithms, which are typically designed for one regime and are brittle when applied to the other. Linear models miss critical nonlinear effects, while general nonlinear methods are computationally expensive and notoriously prone to discovering spurious relationships. We propose a new framework that robustly learns causal structures from such mixed-dynamics systems by learning from a spectral representation of model residuals. Our approach first identifies a sparse linear backbone and then systematically evaluates candidate nonlinear additions through a novel multi-criteria decision process. This validation mechanism, which requires convergent evidence from multiple independent tests, is powered by a new application of Polynomial Chaos Expansion (PCE) to detect latent structure in model residuals with high sensitivity. On a complex industrial process dataset, our method achieves a state-of-the-art 88.9% F1-score, correctly identifying the mixed-type causal graph while drastically reducing the false discoveries that plague other nonlinear methods.", "tldr": "", "keywords": ["Causal Discovery", "Nonlinear Systems", "Polynomial Chaos Expansion", "Residual Analysis", "Uncertainty Quantification"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/d39ed25ad2466dc8f5c755cf1ea6b331ff2ba307.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors consider causal inference in settings where we have both linear and nonlinear relationships. They propose an algorithm that leverages polynomial chaos expansion, among others, to find a linear core structure and remaining nonlinear relationships, which are assumed to be sparse. The proposed algorithm performs well on an industrial dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1) The problem itself seems relevant and indeed not very well researched.\n\n2) The usage of polynomial chaos expansion is innovative.\n\n3) Evaluation and comparison seem convincing."}, "weaknesses": {"value": "1) I think the claim that $\\epsilon_j$ can follow arbitrary distributions is a bit bold, given that Assumption 2 states that it can actually not be all that arbitrary. The noise distribution needs to be such that it allows for identifiability. \n\n2) The paper goes over some details that would be important to fully understand the algorithm. For instance, what exactly are the compressed sensing techniques that you use? Where does $f$ in (11) come from? If things are explained in the appendix, this should be mentioned. This also holds for the proofs of theorems, which are indeed in the appendix.\n\n3) The score (10) is not very well motivated. Overall, it is not that clear to me how exactly the algorithm now supports causal inference in systems with linear and nonlinear dependencies.\n\n4) Bootstrap methods are in the introduction criticised for not being well-understood, but in the end, used for getting edge probabilities. This seems inconsistent and is not explained.\n\n5) The dataset used for the evaluation is only briefly introduced without much detail."}, "questions": {"value": "1) The random variables $Y$ for PCE need to have finite second moment. Does the same hold then also for the variables considered here? This would mean another assumption on the noise distribution.\n\n2) What is a \"standard random variable?\" Should it be a standard normal random variable? ($\\xi$, introduced after (3)).\n\n3) What are the compressed sensing techniques that you use?\n\n4) Can you motivate how your algorithm, and especially the score function (10), supports making causal inference in the considered mixed dynamics setting?\n\n5) Where does $f$ in (11) and (12) come from? What is its structure, and how did we find it?\n\n6) Can you provide more details on the dataset? Will it be made public? What about the code?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "koeHQRj5S8", "forum": "3v197ZDMNa", "replyto": "3v197ZDMNa", "signatures": ["ICLR.cc/2026/Conference/Submission6330/Reviewer_22Y9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6330/Reviewer_22Y9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761737808837, "cdate": 1761737808837, "tmdate": 1762918625223, "mdate": 1762918625223, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "APhGZetAcv", "forum": "3v197ZDMNa", "replyto": "3v197ZDMNa", "signatures": ["ICLR.cc/2026/Conference/Submission6330/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6330/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762924013973, "cdate": 1762924013973, "tmdate": 1762924013973, "mdate": 1762924013973, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "CausalPCE tackles causal discovery with mixed linear–nonlinear relations. It first learns a sparse\nlinear scaffold via a GES-style search scored by a PCE-augmented BIC, then probes candidate\nnonlinear edges using a simple “two-of-three” test (polynomial LRT, conditional MI, and a\nPCE residual index), and finally reports bootstrap edge probabilities and Sobol indices. Claims\ninclude asymptotic consistency under identifiability and sparsity assumptions and polynomial\ncomplexity with fixed PCE order."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "• Using Polynomial Chaos Expansion on residuals produces a measurable and testable “nonlinearity\nindex” for model misspecification.\n\n• The two-of-three screening (polynomial LRT, kNN-CMI, PCE reduction) may be easy to\nimplement.\n\n• The ablation table shows the method degrades in sensible ways when components are removed\nand that performance depends predictably on PCE order, which is at least informative\nabout the design’s levers."}, "weaknesses": {"value": "• No Related Work section. The literature is folded into a short introduction, which does\nnot meet ICLR expectations and makes novelty hard to judge. Recent ML work on causal\ndiscovery is largely missing, including differentiable DAG search, nonlinear SEMs, kernel\nbased tests, and uncertainty methods.\n\n• The paper assumes a DAG model but does not explain why this is appropriate. It does not\ndiscuss feedback or cycles. Faithfulness is mentioned but not defined. Basic graph properties\nare also unstated.\n\n• Assumption 1 limits the nonlinear part to order O(d) but does not restrict the total number\nof edges in the graph. Without a bound on the total number of edges, sparsity is undefined,\nand complexity or consistency statements later in the paper have no clear basis.\n\n• For Assumption 2, proper references for the “established identifiability theory” are needed.\n\n• In Assumption 3, the paper mentions “confounders” but never defines what is meant or\nhow they are handled. It is unclear whether confounders refer to latent common causes,\ncorrelated noise terms, or observed control variables.\n\n• The paper does not justify the index or define it precisely. There is no calibrated test under\na linear null and no explanation of what the index measures or how it grows with signal\nstrength. Robustness to non Gaussian and heteroskedastic noise is not addressed.\n\n• Many symbols are used without definition, which makes the paper hard to read and verify.\nExamples include, e.g., c, log n, L, NPCE, ˆI, MEC(G).\n\n• The experiments rely on an unnamed “real-world industrial process” with known ground\ntruth, but the paper provides no dataset name, citation, variable descriptions, or access\ndetails. Figures and tables use generic X1–X6 labels, and no provenance is given for the\nclaimed ground truth, which makes the results non-verifiable and indistinguishable from a\nsynthetic toy example."}, "questions": {"value": "1. Add a proper Related Work section that situates PCE-on-residuals against modern methods,\nstates what is new beyond a GES-style scaffold plus residual tests, and justifies the\ncomparison set.\n\n2. Please say whether the graph can be disconnected, whether there is a bound on in degree,\nand whether a topological order is used in the search.\n\n3. Define every symbol on first use and keep names consistent across text, equations, and\nalgorithms.\n\n4. Please identify and cite the dataset (or release it), describe variables and preprocessing,\nand justify the ground-truth graph.\n\n5. Please add standard public benchmarks and at least one named industrial benchmark.\nFor public data, for example, consider Sachs (Causal discovery with interventional data)\nand ALARM (A Logical Alarm Reduction Mechanism). For an industrial setting, consider\nthe Tennessee Eastman process with metrics against strong baselines."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HD3C3y819v", "forum": "3v197ZDMNa", "replyto": "3v197ZDMNa", "signatures": ["ICLR.cc/2026/Conference/Submission6330/Reviewer_JyuS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6330/Reviewer_JyuS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761838698925, "cdate": 1761838698925, "tmdate": 1762918624565, "mdate": 1762918624565, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a multi-step algorithm for causal structure learning when structural equations are a mix of linear and nonlinear functions. Methods rely heavily on the polynomial chaos expansion (PCE), which helps quantify nonlinearities in residuals via a \"nonlinearity index.\" The proposed algorithm proceeds in three steps: (i) a modified GES search, (ii) a multi-criterion decision rule to add new edges, and (iii) uncertainty quantification. Consistency is shown, and experimental results on a real-world industrial process show promising results."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Mixed linear/nonlinear relationships pose an interesting and realistic problem that's seldom addressed directly in the literature.\n\n- Efficient uncertainty quantification over edges is an important problem, with somewhat lacking state-of-the-art.\n\n- The paper is generally well-written. Motivations and background materials are quite clear, and the methodology of the proposed algorithm is easy to follow.\n\n- Results on a real-world industrial process are promising, achieving the best SHD and F1 score over all baselines."}, "weaknesses": {"value": "- I'm not so sure what is meant exactly in Assumption 1, where the number of nonlinear relationships is O(d). This is perplexing since standard Big-O notation is asymptotic. If this is to mean that there are at most d nonlinear relationships, then Assumptions 1 and 2 concurrently holding with Gaussian noise is quite difficult, as the standard identifiability assumes all functions are strictly nonlinear.\n\n- There are lots of moving parts in the proposed algorithm, with limited ablation. This is not necessarily bad, but leaves lots of spaces where there is potential room for improvement (e.g., why use the k-nearest neighbor MI estimate? Why stop with three tests? Why are the three tests chosen particularly good? What happens if we use more modern alternatives to GES? Why require 2 tests to pass instead of 1 or 3? etc.).\n\n- The use of GES inherits some rough scalability issues. It would be nice to identify other \"step 1\" algorithms that could scale more readily with the number of nodes.\n\n- Some modern baselines are missing. For example, Dagma [1] is a quite popular alternative to NOTEARS, and is typically faster and more accurate.\n\n- The breadth of experiments is quite lacking for an ICLR submission, in my opinion. I would expect results on other various popular benchmark datasets. I would also expect to see results, e.g., in purely linear or purely nonlinear scenarios, and how results break down as assumption 1 is pushed.\n\n- As a minor point, (1) is taken to be a \"general nonlinear structural equation model\" but assumes additive noise.\n\n- As another minor point, there is a missing reference in line 633.\n\n[1] Bello, K., Aragam, B., & Ravikumar, P. (2022). Dagma: Learning dags via m-matrices and a log-determinant acyclicity characterization. Advances in Neural Information Processing Systems, 35, 8226-8239."}, "questions": {"value": "1. What is performance like on a more general set of datasets? What about some more modern alternative CD algorithms? This is the most important question to me.\n\n2. How can acyclicity be strictly enforced? Notice that in the presented results (Figure 2), CausalPCE returns a cyclic graph (I suppose due to step 3). \n\n3. Can cubic complexity in $d$ be avoided with an alternative step 1 algorithm? \n\n4. What exactly is meant in Assumption 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "q1Uy3VWfpO", "forum": "3v197ZDMNa", "replyto": "3v197ZDMNa", "signatures": ["ICLR.cc/2026/Conference/Submission6330/Reviewer_ShKR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6330/Reviewer_ShKR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6330/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987129529, "cdate": 1761987129529, "tmdate": 1762918624028, "mdate": 1762918624028, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}