{"id": "lPQOPD1tcm", "number": 12969, "cdate": 1758212277396, "mdate": 1759897473571, "content": {"title": "Calibration Is Grouping: VR-SAG with Intra-Group Variance Control and Logit-Cluster Evaluation", "abstract": "Accurate click-through and conversion-rate estimates are pivotal for bid optimization in large-scale advertising, yet modern deep CTR/CVR models are often miscalibrated. Classical global calibrators (Platt scaling, isotonic regression) and feature-based binning struggle to capture latent user–item heterogeneity. We approach calibration through the lens of \\emph{learned semantic groupings} and propose \\textbf{Variance-Reduced Semantic-Aware Grouping (VR-SAG)}—a lightweight post-hoc layer over a frozen backbone that (i) forms semantically coherent partitions in embedding space, (ii) fits per-group temperature+bias calibrators, and (iii) explicitly penalizes intra-group variance to tighten probability spreads.\nOur design is grounded in a group-wise decomposition of proper scoring rules (e.g., Brier), which isolates intra-group variance as a key driver of residual miscalibration and motivates variance control for genuine loss reduction. To decouple evaluation from training, we introduce \\textbf{Logit-Cluster Calibration Error (LCCE)}, an unsupervised fixed-partition metric obtained via $K$-means in logit space; LCCE aligns with the reliability term of proper scores while avoiding pitfalls of trainable grouping heads used as metrics.\nAcross large-scale offline logs and \\textbf{AuctionSys}—a realistic ad-auction simulator with oracle CTR—VR-SAG consistently improves calibration (ECE/LCCE and Brier variants) over strong baselines, with negligible latency and memory overhead. Together, VR-SAG and LCCE provide a principled, production-friendly toolkit for group-aware calibration in recommender systems.", "tldr": "", "keywords": ["recommender systems", "calibration"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fc6d3b32e9dbed6668131ab902d8d5f63fb08137.pdf", "supplementary_material": "/attachment/62f636d93b5085d4797b7a2e917f7579110dea4f.zip"}, "replies": [{"content": {"summary": {"value": "This paper tackles CTR/CVR probability calibration in advertising recommendation by proposing VR-SAG. On top of a frozen backbone, a semantic grouping head performs soft partitioning in embedding space and learns per-group temperature and bias. The core innovation is to explicitly identify the intra-group variance and covariance term Δ in the group-wise decomposition of proper scores (e.g., Brier), and introduce an intra-group variance penalty to contract prediction spread and improve calibration. \n\nTo avoid coupling evaluation with a trainable grouping head, the authors propose Logit-Cluster Calibration Error (LCCE), a fixed-partition metric that applies K-means in logit space and computes a group-level reliability term. Experiments on AliCCP, AliExpress, and the AuctionSys simulator (with oracle CTR) show VR-SAG outperforms strong baselines on ECE/LCCE and Brier variants, with improved NLL and largely preserved AUC."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Strong theoretical motivation: Provides error decompositions under semantic grouping, clarifying how intra-group variance σ² and covariance γ affect proper scores, which justifies the variance penalty.\n\n- Engineering-friendly method: Frozen backbone with small parameter overhead and a single m×K multiply-add at inference; post-hoc and production-ready."}, "weaknesses": {"value": "- (main weakness) Selection bias/non-IID risk for CVR and serving distribution mismatch: In industrial recommender systems, CVR is trained/evaluated on clicked/exposed samples (about 5 ads per request) but served over the candidate set (about 1000 per request), whose logits are substantially lower and differently distributed (many non-winners). Since LCCE clusters in logit space and VR-SAG learns per-group calibrators from a validation split, there is a strong risk that clustering and calibration are fit to the high-logit clicked regime, amplifying IID assumptions and failing on the serving distribution. Offline evaluation on clicks will not expose this issue, which can lead to poor online calibration or ranking stability.\n\n- Insufficient boundary/risk analysis for Δ’s sign: The paper mentions that \"the extra term ∆ is often positive in practice and increases the Brier loss.\" When γ dominates and Δ becomes negative, and whether the proposed approach still works? There are few negative-case studies or safeguards.\n\n- Statistical and implementation details need clarity: Why penalize variance of uncalibrated p̂ rather than calibrated p̃? Differences in stability and effect are under-discussed."}, "questions": {"value": "1) Under what data conditions can Δ be negative? Can you show results for such “covariance-dominant” negative cases?\n2) Why define the variance penalty on uncalibrated probabilities p̂ rather than calibrated probabilities p̃? What are the stability/effect differences? Any comparative experiments or theoretical support?\n3) Please evaluate under selection bias/non-IID. Concretely:\n- Train/validate the calibrator on exposure/candidate logs, and report metrics on the serving distribution (not only clicks).\n- Compare LCCE/VR-SAG when clusters are formed from clicked vs exposure/candidate logits; show distribution shift diagnostics (logit histograms, cluster assignments, per-cluster support).\n- It's better to add an online A/B to validate that calibration gains translate when deployed; include per-stratum calibration (clicked vs non-clicked exposures) and drift stability over time."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "X1un467IjN", "forum": "lPQOPD1tcm", "replyto": "lPQOPD1tcm", "signatures": ["ICLR.cc/2026/Conference/Submission12969/Reviewer_U2VD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12969/Reviewer_U2VD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12969/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761790684310, "cdate": 1761790684310, "tmdate": 1762923724128, "mdate": 1762923724128, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new method for improving the calibration of click-through and conversion-rate predictors in large-scale advertising systems. It introduces Variance-Reduced Semantic-Aware Grouping (VR-SAG)—a lightweight post-hoc calibration layer that partitions embedding space into semantically coherent groups, fits per-group temperature and bias parameters, and penalizes intra-group variance to tighten predicted probability spreads. A key theoretical contribution is a group-wise decomposition of the Brier score. For evaluation, the authors design the Logit-Cluster Calibration Error (LCCE). Experiments on public datasets (AliCCP, AliExpress) and a proposed simulator (AuctionSys) show that VR-SAG consistently outperforms strong baselines (temperature scaling, isotonic regression, SAG) on ECE, Brier, and NLL metrics."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "I believe the paper provides a novel perspective on calibration through the theoretical variance decomposition of the Brier loss in Section 2.3. Building on these theoretical insights, the authors propose an effective and easy-to-implement calibration method. The paper also presents extensive numerical experiments to demonstrate the performance of the proposed method."}, "weaknesses": {"value": "1. My main concern is that the proposed method is only loosely connected to the theoretical development based on the variance decomposition. The additional penalty term does not exactly correspond to the $\\Delta$ term in the decomposition, as the $\\gamma$ component is ignored. Furthermore, the REL and RES terms should not be neglected, since the groups are formed in a data-adaptive manner, as the authors themselves note in the derivation of LCCE. Consequently, minimizing over $W$ may alter the group structure, which in turn affects both REL and RES.\n\n2. Since the theoretical insights are derived from the Brier loss, why not directly minimize the GCE or Brier loss to estimate $\\phi$, $\\tau$, and $\\beta$?\n\n3. The writing could be improved. For example, $g_\\phi$ is first mentioned on line 145 without a prior definition, and in fact, $g_\\phi$ is never formally defined throughout the paper. \n\n4. The estimators (9) should be written with \\hat. And it is unclear whether those estimators are consistent. \n\n5. I checked the supplementary materials, and it appears that the AdAuction dataset is not open-sourced. Moreover, the AdAuction dataset provided does not contain any feature information."}, "questions": {"value": "Could the authors explain the following sentence:  \n*Probabilistic models should be judged with proper scoring rules(Gneiting & Raftery, 2007)—losses minimized, in expectation, only by the true data-generating distribution.*"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BG1neXsfJd", "forum": "lPQOPD1tcm", "replyto": "lPQOPD1tcm", "signatures": ["ICLR.cc/2026/Conference/Submission12969/Reviewer_SeQh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12969/Reviewer_SeQh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12969/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761799336962, "cdate": 1761799336962, "tmdate": 1762923723601, "mdate": 1762923723601, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper, “Calibration Is Grouping: VR-SAG with Intra-Group Variance Control and Logit-Cluster Evaluation,” addresses the problem of probability miscalibration in large-scale CTR/CVR prediction models used in advertising systems. The authors propose a post-hoc calibration framework called Variance-Reduced Semantic-Aware Grouping (VR-SAG) and a new evaluation metric named Logit-Cluster Calibration Error (LCCE)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Principled connection between grouping and calibration. The paper offers an insightful theoretical perspective by reformulating calibration as a grouping problem and deriving a group-wise decomposition of the Brier score. This connection provides a clear explanation of how intra-group variance contributes to residual miscalibration and motivates the proposed variance-reduction strategy.\n\n2. Lightweight and production-friendly design. VR-SAG operates as a post-hoc layer over a frozen backbone, requiring only a small number of additional parameters and negligible latency. This makes it well-suited for large-scale CTR/CVR systems where model retraining and serving efficiency are critical.\n\n3. Comprehensive empirical evaluation and metric innovation. The paper evaluates the method on multiple real-world and simulated datasets (AliCCP, AliExpress, AuctionSys) and introduces the LCCE metric, which provides a more stable and model-aware assessment of calibration quality. The experimental results consistently show that VR-SAG improves over strong baselines under multiple calibration metrics."}, "weaknesses": {"value": "1. The proposed evaluation metric LCCE relies on K-means clustering in the logit space, making it sensitive to random initialisations. As a result, even when the model’s predicted probability distribution remains identical, different random seeds may lead to varying cluster assignments and cause slight fluctuations in the computed LCCE values.\n\n2. The novelty of the paper requires further clarification. In essence, VR-SAG is an incremental extension of SAG, achieved by adding a variance regularisation term. Although the core idea that “variance reduction improves calibration” is theoretically motivated, the methodological contribution appears modest.\n\n3. The assumption that “Group = Semantic region” may not always hold in CTR/CVR embedding spaces, where similar embeddings do not necessarily correspond to semantically coherent entities (due to the mixture of user and ad features). Consequently, the softmax-based grouping softmax(W^T* z) might capture noisy directions rather than meaningful semantic partitions."}, "questions": {"value": "1. About LCCE stability: Since LCCE depends on K-means clustering in the logit space, how stable is the metric across different random seeds or clustering initialisations? Have the authors evaluated the variance of LCCE when the same model is evaluated multiple times under different seeds?\n\n2. Choice of number of clusters (K): How is the number of clusters K selected in LCCE? Does performance or ranking consistency significantly vary with K? Could the authors provide a sensitivity analysis or a heuristic for selecting this parameter?\n\n3. Interpretability of semantic grouping: The authors assume that groups correspond to latent “semantic regions” in the embedding space.\nCould the authors provide qualitative or quantitative evidence that these learned groups are indeed semantically meaningful (e.g., user–item patterns, ad types, or contextual factors)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4Z3YNV8Eix", "forum": "lPQOPD1tcm", "replyto": "lPQOPD1tcm", "signatures": ["ICLR.cc/2026/Conference/Submission12969/Reviewer_tBJs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12969/Reviewer_tBJs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12969/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761900638535, "cdate": 1761900638535, "tmdate": 1762923723067, "mdate": 1762923723067, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new calibration method for CTR/CVR models based on  Semantic-Aware Grouping (SAG). Experiments show the proposed method can achieve better calibration."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper improves upon SAM by regularizing intra-group variance and reveals in theory how intra-group variance is connected to calibration error.\n2. The paper also open-sourced an ad-auction simulator, which could help reproduction and benchmarking for future works in the field."}, "weaknesses": {"value": "1. The main weakness lies in position of the proposed approach. It uses automatically identified groups for calibration, which lacks interpretability and it is hard to inject explicit control if manual adjustment of calibration is needed."}, "questions": {"value": "The calibration potentially can affect model performance since it changes order of predicted scores across different region, could authors comment more on if there is any trade-offs here and how does the proposed method compare with traditional methods calibrating using meta data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "XWtVISR47C", "forum": "lPQOPD1tcm", "replyto": "lPQOPD1tcm", "signatures": ["ICLR.cc/2026/Conference/Submission12969/Reviewer_my5g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12969/Reviewer_my5g"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12969/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762117113902, "cdate": 1762117113902, "tmdate": 1762923722616, "mdate": 1762923722616, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}