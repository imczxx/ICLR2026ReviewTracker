{"id": "qj1EL0oT1n", "number": 15209, "cdate": 1758248995899, "mdate": 1759897321257, "content": {"title": "Inference-Time Search using Side Information for Diffusion-based Image Reconstruction", "abstract": "Diffusion models have emerged as powerful priors for solving inverse problems.\nHowever, existing approaches typically overlook side information that could significantly improve reconstruction quality, especially in severely ill-posed settings.\nIn this work, we propose a novel inference-time search algorithm that guides the\nsampling process using the side information in a manner that balances exploration\nand exploitation. This enables more accurate and reliable reconstructions, providing an alternative to the gradient-based guidance that is prone to reward-hacking\nartifacts. Our approach can be seamlessly integrated into a wide range of existing\ndiffusion-based image reconstruction pipelines. Through extensive experiments on\na number of inverse problems, such as box inpainting, super-resolution, and various deblurring tasks including motion, Gaussian, nonlinear, and blind deblurring,\nwe show that our approach consistently improves the qualitative and quantitative\nperformance of diffusion-based image reconstruction algorithms. We also show\nthe superior performance of our approach with respect to other baselines, including\nreward gradient-based guidance algorithms.", "tldr": "This work introduces an inference-time search framework that leverages side information to guide diffusion models for solving inverse problems, enabling more accurate and robust reconstructions than existing gradient-based approaches.", "keywords": ["Diffusion Models", "Inverse Problems", "Inference-Time Search", "Side Information", "Exploration–Exploitation", "Gradient-Free Guidance", "Ill-Posed Problems", "Generative Priors"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2f18e276175c687b21394ea2f5edc71963cd4226.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposed a method to take advantage of side information in solving ill-posed inverse problems with diffusion prior. Side information is incorporated by a reward function and is integrated in a plug-and-play manner into any inverse problem solvers using pre-trained diffusion model, such as DPS and DAPS. Instead of using reward gradient guidance, the paper adopts inference-time search techniques to accommodate general reward functions. Extensive experiments show superior performance comparing to baselines across various inverse problems on a number of base models."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Novelty: The paper is the first to incorporate side information for diffusion inverse problems.\n2. Flexibility: The proposed method integrates smoothly into a wide range of diffusion inverse problem solvers, and is compatible with general reward functions.\n3. Effectiveness: Experimental results suggest that the method outperforms baselines under various scenarios."}, "weaknesses": {"value": "1. Although experiments show that the proposed method significantly outperforms baseline methods without side information, it is not clear how side information quality could affect the reconstruction.\n2. Since highly informative side information is provided, the authors should consider testing on \"difficult\" scenarios such as high measurement noise and severe ill-posedness. \n3. The method involves various approximations such that theoretical insights are intractable."}, "questions": {"value": "1. Is it possible to compare reconstruction quality with side information with different quality? For example, in a fixed inverse problem, it could be interesting to see the difference between text \"golden retriever sitting on a snowy frozen lake, facing forward\", \"golden retriever sitting on a snowy frozen lake\", \"golden retriever sitting\", and \"dog\". It could be also interesting to see how a blurry image (or a side view when the ground truth is a front view) side information could affect the reconstruction.\n2. Can the authors apply the algorithm on more challenging inverse problems as mentioned in the second point of Weaknesses?\n3. Why does DPS fail completely in the results of Figure 4?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MYEdNzYPbU", "forum": "qj1EL0oT1n", "replyto": "qj1EL0oT1n", "signatures": ["ICLR.cc/2026/Conference/Submission15209/Reviewer_kQJ7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15209/Reviewer_kQJ7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761881817896, "cdate": 1761881817896, "tmdate": 1762925511867, "mdate": 1762925511867, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a training-free inference-time search framework that leverages side information to guide diffusion-based image reconstruction. By modeling side information as a reward-tilted prior and applying greedy or recursive fork-join search, the method balances exploration and exploitation without gradient guidance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper introduces inference-time search to diffusion-based inverse problems with side information, a setting largely unexplored in prior work.\n- The proposed reward-tilting formulation allows the use of arbitrary side information (image, text, MRI contrast) without retraining or model modification."}, "weaknesses": {"value": "- The proposed search algorithms lack formal theoretical guarantees for exploration–exploitation optimality or convergence.\n- The method relies on heuristic scheduling and requires manual tuning across tasks.\n- The computational trade-offs between particle count, reward evaluation cost, and performance are not systematically discussed.\n- The experimental comparisons are not fully consistent across baselines. Different methods are evaluated on different task settings or degradation levels, which weakens the fairness and interpretability of the reported improvements."}, "questions": {"value": "- How robust is the search procedure when the side information is noisy, partially mismatched, or misleading?\n- The reported DPS baseline results appear significantly weaker than those in prior literature. Could the authors clarify whether this is due to different degradation settings, implementation details, or the influence of side-information conditioning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8Zde15SbGu", "forum": "qj1EL0oT1n", "replyto": "qj1EL0oT1n", "signatures": ["ICLR.cc/2026/Conference/Submission15209/Reviewer_1jpL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15209/Reviewer_1jpL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937696174, "cdate": 1761937696174, "tmdate": 1762925511283, "mdate": 1762925511283, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose to solve inverse problems by using side information in diffusion model based inverse problem samplers. This could be useful for cases where the observed degradation signal itself might not provide useful information for generating high quality reconstructions and thus using side information could help in these scenarios. In addition to the reward gradient guidance, the authors also propose search methods for non-differentiable rewards. Empirical results are illustrated on the FFHQ dataset for different inverse problems like Super-resoution, non-linear deblur etc."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The flow of the paper is straightforward to understand although some claims in the main text need more clarification (see weaknesses below)\n\n2. The problem setup seems relevant in the context of diffusion inverse problem solvers and could be useful for a lot of other applications."}, "weaknesses": {"value": "**Re. Theoretical assumptions:**\n\n1. The authors propose to use the reward model r(x_0, s). However, the right distribution to sample from would be the following tilted distribution p(x_0|s,y) \\propto p(y|x_0)p(s|x_0)p(x_0). Do the authors assume that p(x_0|s, y) \\approx p(x_0|s) which would imply that the side information completely explains the ground truth observation. This is a very strong assumption and might not hold in practice. Can the authors clarify more on this aspect?\n\n2. What is the intuition behind setting \\eta=0 in Eq. 6. This implies that the authors assume E[x_0|x_t, y] \\approx E[x_0|x_t] which is again a strong assumption? Is this primarily for computational convenience? I see that the authors have some theoretical results which validate these assumptions to some extent for a small t but the claims are still seem dubious here. I would request the authors to clarify this aspect in more details in the main text.\n\n**Re. Missing related work**:  The authors highlight some work under Reward-gradient guidance in Section 2 and highlight that recent works are typically used for semantic generation tasks rather than inverse problems (line 126). However this claim is incorrect and I think some related work is missing. For instance the idea of using reward maximization with KL regularization for test time inference is not new and has been explored in [1] from the perspective of optimal control and in [2] from the perspective of variational inference. Both works explore these ideas in the context of inverse problems.\n\n[1] Variational Control for Guidance in Diffusion Models - Pandey et al.\n\n[2] Divide-and-conquer posterior sampling for denoising diffusion priors - Janatai et al.\n\n**Re Empirical Comparisons:**\n\n1. Given the large body of work on solving inverse problems, the paper lacks empirical comparisons with state of the art methods which do not require any side information. For instance comparisons are made against DPS which is outdated. This is important since if the method cant outperform solvers which dont require any side information for the same input degradation, its practical utility is very limited.\n\n2. While the reconstructions in Fig. 3 look decent and the differences between the proposed method and baseline DPS look noticeable, I wonder how cherry picked these samples are? This is because in terms of quantitative results, the reconstruction gains (in terms of PSNR and SSIM) and perceptual gains (LPIPS) are marginally better than the baselines. I can see that the main differences are in terms of the FaceSimilarity metric but Im curious why the other metrics are only marginally better.\n\n3. Can the authors report runtime estimates in Table 1 too? This would help in a holistic comparison between different baselines and the proposed method in terms of the improvement in different metrics vs the additional compute required."}, "questions": {"value": "See weaknesses above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3zF2fAFJd2", "forum": "qj1EL0oT1n", "replyto": "qj1EL0oT1n", "signatures": ["ICLR.cc/2026/Conference/Submission15209/Reviewer_8H1q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15209/Reviewer_8H1q"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979581695, "cdate": 1761979581695, "tmdate": 1762925510572, "mdate": 1762925510572, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This author proposes a reward-model based method to aid the inverse problem solving with side information with diffusion models such as reference image, text and so on."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This reward function to utilize side information is a novel contribution.\n2. The injection of side information seems to improve performance"}, "weaknesses": {"value": "1. The side information is explored in prior works such as [1], [2], [3]. Authors should extensively discuss with those methods\n2. Even though reward function may not be differentiable, why not using DPO to fine tune the model. How is the fine-tuned performance compared with inference-time search? Is the inference-time searching adding more computational cost.\n3. The experiments do not show the advantage of this method significantly. Inverse problem solvers already achieve quite good performance in most common cases. I expect this method should be more effective in challenging scenarios, for example 32x super-resolution, inpainting with heavy noise, or heavy blur etc. I also expect your method largely outperform DPS if implemented correctly. \n4. The code is not available and I cannot validate without the code. \n\n\n[1] CLAY: A Controllable Large-scale Generative Model for Creating High-quality 3D Assets\n\n[2] Generative Diffusion Prior for Unified Image Restoration and Enhancement\n\n[3] Prompt-tuning Latent Diffusion Models for Inverse Problems"}, "questions": {"value": "Please show the experimental results on hard inverse problems, compare with [1],[2],[3], and at least provide some pseudo-code, and then I will consider improving my rating."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "M3NaQuAd2m", "forum": "qj1EL0oT1n", "replyto": "qj1EL0oT1n", "signatures": ["ICLR.cc/2026/Conference/Submission15209/Reviewer_nJoA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15209/Reviewer_nJoA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15209/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994251623, "cdate": 1761994251623, "tmdate": 1762925509348, "mdate": 1762925509348, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}