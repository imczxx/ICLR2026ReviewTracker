{"id": "qW0hWsQOxD", "number": 136, "cdate": 1756729422265, "mdate": 1759898274581, "content": {"title": "Lightweight Image-to-3D Shape Generation via Vitality-Aware Pruning and Quantization", "abstract": "We propose a novel compression framework for image-to-3D generative models that substantially reduces model size while preserving synthesis fidelity. Current Diffusion Transformer (DiT) architectures achieve impressive quality but remain excessively expensive due to large parameter counts and memory demands. Unlike prior work that focuses only on inference acceleration, our approach directly reduces model capacity by leveraging layer vitality—quantifying each layer’s contribution to generation quality. Guided by this analysis, we combine structured pruning, vitality-aware adaptive quantization, and lightweight finetuning to maintain fidelity under compression. Experiments on state-of-the-art 3D models, including Step1X-3D, Hunyuan3D 2.0, and Hunyuan3D 2mini, demonstrate reductions of up to 66% in model size while preserving synthesis performance. Our framework offers the potential for a plug-and-play solution to make high-quality 3D synthesis broadly accessible in resource-constrained environments.", "tldr": "We propose a compression framework that reduces 3D generative model size while preserving quality. By leveraging Transformer layer vitality, we combine pruning, adaptive quantization, and finetuning, enabling efficient 3D generation.", "keywords": ["3D generative models", "diffusion models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ae723058cb98db143cae225c1c1f3422b7fb918b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a compression framework for image-to-3D DiT models using layer vitality analysis, structured pruning, adaptive quantization, and targeted finetuning. Experiments on Step1X-3D, Hunyuan3D 2.0, and 2mini achieve 44-66% size reduction while maintaining synthesis quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This work addresses a practical problem with good results - 44-66% compression enables deployment in resource-constrained environments.\n2. The evaluations are systematic and comprehensive, with results on different backbone models showing its generalization ability.\n3. The idea of vitality analysis from T2I (Avrahami et al. 2025) to 3D generation using EMD on point clouds is a reasonable domain adaptation."}, "weaknesses": {"value": "1. The technical novelty is relatively limited, as the core techniques (layer pruning, quantization, and distillation) are mostly from existing ones. The main contribution is applying vitality analysis (from Avrahami et al. 2025) to 3D with EMD. This is essentially applying a 2D technique to 3D generation with minimal domain-specific innovation. It would be better if there are some novel insights about 3D geometry or generation processes. \n2. Different thresholds per architecture undermine \"plug-and-play\" claims. How sensitive are results? Can this be automated?\n3. Why does selective finetuning of only the \"Min-vital\" layer work? There is no ablation study about this strategy."}, "questions": {"value": "Refer to weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "16xqLTkSXy", "forum": "qW0hWsQOxD", "replyto": "qW0hWsQOxD", "signatures": ["ICLR.cc/2026/Conference/Submission136/Reviewer_i2aw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission136/Reviewer_i2aw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761829554008, "cdate": 1761829554008, "tmdate": 1762915456956, "mdate": 1762915456956, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper has introduced the first study of prunning and quantization of I23D models. Specifically, by leveraging the structured pruning, vitality-aware adaptive quantization, and lightweight finetuning, fidelity can be well maintained under compression. Extensive experiments on several 3D base models and benchmarks have demonstrated the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. With the rapid progress of 3D AIGC, the prunning and quantization of these models is indeed necessary.\n2. The analysis and experiments of this paper is comprehensive."}, "weaknesses": {"value": "1. I appreciate the The main concern is whether the proposed method is unique on 3D, or can be directly applied to any DiT/transformer architecture. Considering 3D generation all follow the same design, just applying existing prunning and quantization tricks on 3D DiTs can only be a weak contribution.\n2. Some discussions of 3D generative models are missing, like 3DTopia-XL (CVPR 25), GaussianAnything (ICLR 25), EG3D / pi-GAN (GAN-based 3D generative models), and OpenAI's Shape-E (the first 3D diffusion model)."}, "questions": {"value": "1. I did not fully understand why the single-layer and double-layer block needs separate threshold and processing. Any insight behind?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zMaK07lVon", "forum": "qW0hWsQOxD", "replyto": "qW0hWsQOxD", "signatures": ["ICLR.cc/2026/Conference/Submission136/Reviewer_UAxA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission136/Reviewer_UAxA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837353455, "cdate": 1761837353455, "tmdate": 1762915456829, "mdate": 1762915456829, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a compression framework for image-to-3D generative models based on Diffusion Transformers (DiT). The core contribution is introducing \"layer vitality\" analysis to quantify each layer's contribution to generation quality using Earth Mover's Distance (EMD) between outputs of the full model and layer-ablated models. Based on this analysis, the method combines: Structured pruning of low-vitality layers, Vitality-aware adaptive quantization (8-bit for vital layers, 4-bit for others) and Selective finetuning targeting minimally-vital layers. Experiments on Step1X-3D, Hunyuan3D 2.0, and Hunyuan3D 2mini demonstrate effective model size reductions while maintaining synthesis quality comparable to full models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "1. Have analysis of layer importance in image-to-3D DiT models and first work to achieve actual model size reduction in this domain.\n2. Achieves substantial compression (up to 66%) with minimal quality degradation, making high-quality 3D generation more accessible for resource-constrained environments."}, "weaknesses": {"value": "1. Limited Novelty\nThis is essentially a straightforward application of existing compression techniques to 3D models, not a novel method:\n\n\"Layer vitality\" via ablation+distance is directly borrowed from 2D image/video work (Avrahami 2025, Kim 2025)\nAdaptive quantization based on importance scores is standard practice\nThe paper doesn't explain what makes 3D generation uniquely challenging for compression\n\n2. No Theoretical Analysis\nThe paper is purely empirical without explaining why compression works:\n\nWhy do certain layers have low vitality? Is it due to training data, architecture design, or something else?\nWhy do different models (Step1X-3D vs. Hunyuan3D) show different vitality patterns?\nWithout understanding the underlying causes, it's unclear when this approach will succeed or fail\n\n3. Missing Critical Experiments\nFailure cases: No analysis of when/why compression degrades quality. What types of objects fail? At what compression ratio does quality collapse?\nComputational cost: No reported training time, memory usage, or actual inference speedup. How expensive is the vitality analysis (requires N forward passes)? How long does finetuning take?\nBaseline comparisons: No comparison with standard compression methods: Teacher-student distillation(e.g.,DMD) from scratch and other structured pruning approaches\n\n4. Generalization Concerns\n\nDifferent models need different hyperparameters (learning rates: 10⁻⁸ vs 10⁻⁴, different thresholds, different finetuning iterations)\nOnly 210 images used for vitality calculation—how stable are these scores?\nOnly tested on DiT models—unclear if it works for other 3D architectures such as AR-based models.\n\n5. Insufficient Ablations\n\nHow does each component (pruning, quantization, finetuning) contribute individually?\nHow sensitive is performance to threshold selection"}, "questions": {"value": "Why not try sparse-voxel-based methods such as Trellis? What are the challenges?\nHow sensitive is the method to the number of samples used for vitality calculation?\nSince 3D generation models are not particularly large, speedup seems less critical to me. Why not focus on general model compression task or video generation instead, which is more crucial?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "a3FpJLBvsc", "forum": "qW0hWsQOxD", "replyto": "qW0hWsQOxD", "signatures": ["ICLR.cc/2026/Conference/Submission136/Reviewer_Rc1K"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission136/Reviewer_Rc1K"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980249184, "cdate": 1761980249184, "tmdate": 1762915456455, "mdate": 1762915456455, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a compression pipeline for large image-to-3D DiT models. The central idea is to estimate each layer’s *vitality* by measuring the 3D output degradation via Earth Mover’s Distance between point clouds after temporarily removing that layer. Layers with low vitality are pruned, while remaining ones are quantized with adaptive bit widths proportional to vitality. A small distillation fine-tuning step attempts to recover performance. Experiments on Step1X-3D, Hunyuan3D 2.0, and Hunyuan3D 2-mini report parameter reduction with minimal drop in embedding-based metrics (Uni3D-I, OpenShape-I)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Clear motivation.**\n3D DiT models are large, so compression is valuable.\n\n**Practical meanings.**\nThe parameter reduction without catastrophic quality loss is practical.\n\n**Good writing.**\nThe core idea of this paper is clearly written and explained in the method section. The ablation study cleanly separates pruning, quantization, and finetuning effects, and main comparison experiments are clearly demonstrated."}, "weaknesses": {"value": "**Marginal novelty.**\nThe approach reuses well-known pruning and quantization frameworks from 2D diffusion literature, adding no new theoretical formulation, and its contribution mainly lies in empirical replication on 3D models. It only substitutes the 2D similarity metric with a 3D EMD and apply the same concept to 3D DiTs. The quantization and finetuning steps are standard, and the final pipeline is an incremental adaptation rather than a new principle.\n\n**Computational cost and scalability not addressed.**\nThe vitality analysis itself appears computationally heavy. The paper does not disclose GPU hours, runtime, or scaling properties. Without these, claims of *lightweight* or *efficient* are debatable and the significance of this approach would suffer.\n\n**Insufficient evaluation.**\nAll quantitative metrics are embedding-based and no direct 3D geometry comparisons are provided, which leaves uncertainty about how much detail or structural accuracy is lost during pruning. The reported metrics are calculated from only 200 test samples, which is too small to support broad claims and hinders credibility."}, "questions": {"value": "1. What is the actual computational cost of vitality analysis?\n\n2. Is there a particular reason why the reported metrics can only be evaluated with 200 pairs?\n\n3. Can you report Chamfer Distance or other geometry-level metrics on a small benchmark?\n\n4. What are the real inference-time savings (latency and memory) after compression?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7dq08cpWZo", "forum": "qW0hWsQOxD", "replyto": "qW0hWsQOxD", "signatures": ["ICLR.cc/2026/Conference/Submission136/Reviewer_ts7t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission136/Reviewer_ts7t"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission136/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995633942, "cdate": 1761995633942, "tmdate": 1762915456338, "mdate": 1762915456338, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}