{"id": "T29Oa85nzw", "number": 18028, "cdate": 1758283040777, "mdate": 1759897138512, "content": {"title": "CausalProfiler: Generating Synthetic Benchmarks for Rigorous and Transparent Evaluation of Causal Machine Learning", "abstract": "Causal machine learning (Causal ML) aims to answer \"what if\" questions using machine learning algorithms, making it a promising tool for high-stakes decision-making. Yet, empirical evaluation practices in Causal ML remain limited. Existing benchmarks often rely on a handful of hand-crafted or semi-synthetic datasets, leading to brittle, non-generalizable conclusions. To bridge this gap, we introduce CausalProfiler, a synthetic benchmark generator for Causal ML methods. Based on a set of explicit design choices about the class of causal models, queries, and data considered, the CausalProfiler randomly samples sets of data, assumptions, and ground truths constituting the synthetic causal benchmarks. In this way, Causal ML methods can be rigorously and transparently evaluated under a variety of conditions. This work offers the first random generator of synthetic causal benchmarks with coverage guarantees and transparent assumptions operating on the three levels of causal reasoning: observation, intervention, and counterfactual. We demonstrate its utility by evaluating several state-of-the-art methods under diverse conditions and assumptions, both in and out of the identification regime, illustrating the types of analyses and insights the CausalProfiler enables.", "tldr": "", "keywords": ["Synthetic Benchmarks", "Causal Reasoning", "Causal Machine Learning", "Empirical Evaluation"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d7d53a41dd36380823ebbbaaa05d7f0aaa728e64.pdf", "supplementary_material": "/attachment/4893557b3f6c1d111cfb7d164039586af8f63a93.zip"}, "replies": [{"content": {"summary": {"value": "Evaluation is causal modeling is challenging due to the inability to observe both factual and counterfactual outcomes at the same time.  This has resulted in evaluation being very fragmented in the field, consisting of a mix of a small number of empirical dataset, a range of semi-synthetic options, and, most commonly, ad hoc synthetic data created by the person doing the evaluation.  To aid in standardization, mitigate implicit biases, and promote better exploration of the problem space, the authors propose CausalProfiler, a tool that enables users to generate a wide range of synthetic causal model datasets, complete with intervention and counterfactual queries to evaluate.  CauaslProfiler has a large number of configurable settings that can take on a range of values, allowing a user to create many types of synthetic datasets for evaluation, all using the same generation tool.  By modifying these parameters, a user can explore a method's robustness to a wide range of data types, variable distributions, network layouts, and causal assumptions.  The authors demonstrate how such an evaluation can provide value insights by comparing a few popular causal modeling algorithms under a wide range of SCMs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The authors' focus on evaluation and description of the challenges in evaluation are compelling and motivating.  With an increase in focus on finding new ways to produce more realistic datasets for evaluation, the authors' choice to focus on more rigorous synthetic evaluation is a smart one.  Any evaluation with empirical data is going to be inherently limited due to the reasons the authors discuss, so synthetic data will continue to be used to explore the range of an algorithm's performance.  Improving how we generate synthetic data and allowing for greater standardization across papers will both make any given paper's evaluation stronger and enable easier comparison across papers.\n\nThe experiments presented in Sections 6.4 and 6.5 are well designed and compelling.  I appreciate how cleanly Table 1 shows that a practitioner evaluating using linear SCMs may draw significantly different conclusions than if they had instead used a neural SCM, highlighting the value of exploring a wide range of SCMs when evaluating."}, "weaknesses": {"value": "A lot of the rhetoric in the first half of the paper is overly broad and grandiose.  This ends up over-selling CausalProfiler so that, when we actually see how it's used in the Experiments section, it seems to fall short of the promises the paper seemed to make.  Really, CausalProfiler seems like a flexible and useful tool, but my expectations were set unrealistically high which, rather than making it seem like a powerful tool, only results in a sort of \"this is it?\" feeling by the end of the paper.\n\nA couple of specific examples:\n\n- in the abstract, you state that \"CausalProfiler randomly samples sets of data, assumptions, and ground truths\".  However, at least from reading the Experiments, it seems like any assumptions you want to test need to be manually specified as part of the SoI (e.g., CausalNF, which assumes continuous data, was evaluated with discrete data by manually specifying that in the SoI; a causal sufficiency assumption can be violated by increasing the value of \"Proportion of hidden variables\" above the default value of 0).  Section 5.3, when discussing assumptions, points to Appendix G, stating that the analysis module can compute a bunch of statistics that relate to assumptions.  But that is a much more manual process than is implied by the statement that CausalProfiler \"randomly samples sets of data, assumptions, and ground truths\".\n\n- On line 66, you state that \"an evaluation with CausalProfiler […] uncovers failure modes, generalization limits, and assumption sensitivities that remain hidden in conventional evaluations.\"  During my initial read of the paper, this line reads as if CausalProfiler is testing these bounds in an automated way, providing something that would not be possible in a conventional evaluation without a lot of additional effort.  After reading the rest of the paper, though, it's clear that this statement just means that CausalProfiler provides a lot of knobs to turn, and that a user could turn those knobs to test the limits of an algorithm.  So it's not really providing a completely novel capability (synthetic data evaluations will often vary different parameters), but rather lowering the complexity of running systematic evaluations with different parameter values, thus making it easier to test a wider range than people are likely to do if they have to define all of the synthetic models themselves.\n\nSetting more realistic expectations early on would help with this framing issue.\n\nAlso, because the manual nature of setting the SoI parameters isn't addressed much throughout the paper, there is little guidance provided on how to set the large number of parameters.  Table 3 in the appendix should really be included in the main body of the paper.  In addition, the appendix could benefit from a description of what each parameter value means and what values it can take on. (unless I'm just missing it somewhere) I understand that some of these aren't clearly bounded (e.g., \"Number of endogenous variables\") while others could be easily extended to include additional options (e.g., adding a new kernel type).  But only listing a couple of examples for some and then providing limited defaults means that anyone looking to use CausalProfiler for evaluation in practice is likely to just stick with the default settings, defeating a lot of the value that CausalProfiler provides.\n\n---\n\nOn line 69, you state \"Although synthetic evaluation cannot replace real data, it provides the only reliable access to ground-truth causal queries\", which seems like an overly-broad statement.  I guess maybe \"reliable\" is the key word here, but it still seems like there are other alternatives (as you discussed in the second paragraph of the intro) where ground truth causal effects can be obtained.\n\nOn line 146, you state that \"counterfactual questions reason about what would have happened under a different intervention, given an observed outcome\".  First, \"different intervention\" compared to what?  Second, counterfactual questions aren't really about what would happen under an intervention - rather, it's about what would happen in a hypothetical world where a variable took on a value that is counter to what we observe.\n\nIn line 152, you bring up types of causal queries, distinguishing between intervention queries and counterfactual queries.  ATE is standard and makes sense for interventions, so that part's fine.  However, Ctf-TE isn't a term I've seen before and I don't think is standard.  If this is something from the literature, add a citation.  If it's something you are custom defining, include a definition. (You have a definition in Appendix B, but at the very least, you should describe it and point to the appendix here)\n\nIn Appendix B.2, you give an example of a counterfactual query $P(Y_{do(T=t)}|V_F = v_F)$.  However, it seems strange to have the query contain an intervention. Generally, counterfactuals are written like $P(Y_{T=t}|V_F = v_F)$, denoting the probability of Y in a world where T takes on the value t.  This is different from a world where we intervened to set $T = t$, which is what your notation seems to suggest.\n\nIn Definition 2, the definition of D could be clearer.  It states that there are \"I interventional (or observational) settings\".  However, looking at how I is used (to set which variables are being intervened on), it looks like all settings determined by I are, in fact, interventional and not observational.  If that's correct, then \"(or observational)\" should be removed, and you could add a note that the observational setting can be achieved by setting I = {}.\n\nThe sentence immediately after Definition 2 is unclear.  I'm not sure what \"the assumed causal graph\" means - is it G*?  Is it a graph assumed by whatever algorithm is being tested (or, in the case of causal discovery, the learned graph)?  I'm also not sure what assumptions are being compared between \"the assumed causal graph and assumptions\" and \"ground truth and controlled assumption violations\".  This whole paragraph should be reworked to be a bit more explicit.\n\nMore information about how assumptions can be extracted from a causal dataset would be helpful.  From Definition 2, it looks like the output of CausalProfiler is a causal dataset, with one of its components being H*, \"a set of assumptions satisfied by M*\".  However, Section 5.3's description of H* now makes it seem like a user has to examine the metrics output by the analysis module, decide which assumptions they're interested in testing for, and compute any violations from the analysis module output.  If my understanding is correct, then, while this isn't necessarily a problem, it IS significantly different from simply getting \"a set of assumptions satisfied by M*\".  In that case, you should provide more detail about how H* can be extracted from a causal dataset.  If my understanding of that is incorrect and you do get a direct set of assumptions from running CausalProfiler, then it would be great to provide an example of that output for avoid confusion.\n\nUnder Benchmark Design in Section 5.3, can you say more about \"bias awareness\"?  The description given (\"supported by the coverage guarantee and the empirical distribution analysis module\") is a bit vague.\n\nThe experiments in Section 6.1 and 6.2, while useful validity tests and proofs-of-concept, don't feel like they are interesting enough to take up an entire page in the paper, especially given how much information had to be relegated to the appendix.  6.1 is a fine validity test, but should just be in the appendix, and 6.2 and Figure 1 feel largely unnecessary and uninformative.  Figure 1a is at least comparing two sets of SCMs.  Figure 1b, on the other hand, is comparing a large set of SCMs to two static SCMs, so obviously the large set is going to cover a wider space than the set of 2.  If you're going to compare to bnlearn, at least compare to more than 2 of the 24 discrete networks provided by bnlearn.  The current version of Figure 1b just feels incredibly disingenuous and clearly like an unfair comparison.  A more fair comparison would be something like comparing against datasets generated from the ACIC challenge.\n\n---\nA few minor notes that don't affect my score:\nOn line 57, that should be a comma, not a semi-colon.\nOn lines 73-75, your comma structure is messed up.  I think both commas should be removed, unless you want to restructure the sentence.\nIn the paragraph starting on line 127, you use the term \"levels\" to refer to the levels of Pearl's causal hierarchy, but in the final sentence, refer to answering \"higher-layer questions\" - I assume this should be \"higher-level\" to keep the terms consistent\nOn line 142, you use the \"on the one hand\" vs \"on the other hand\" structure to compare how intervention and counterfactual questions are represented, which feels very clunky - they're not really in clear contrast to each other, so I don't think this linguistic structure works here.\nOn line 175, \"following the Definition 4.1\" should be \"following Definition 4.1\"\n\n---\n\nUltimately, I do like what this paper is trying to do.  I just think there are some significant organizational (wrt what is in the main paper vs appendix) and presentation (wrt how the usability of CausalProfiler and presentation of assumptions are discussed) issues that hold the paper back in its current form.  If these are adequately addressed, I would be happy to raise my score."}, "questions": {"value": "In Definition 4.1, you define H*, the assumptions satisfied by M*, as part of a causal dataset produced by CausalProfiler.  What assumptions are detected and presented to the user as part of a causal dataset?  The only concrete examples of assumptions you consider that I can find are causal sufficiency (mentioned on the bottom of page 3 as an example assumption in H) and discrete vs continuous data (mentioned on the bottom of page 8 when discussing CausalNF), both of which would be determined by the parameters the user sets in the SoI.  Are there additional assumptions beyond those manually specified in the SoI that CausalProfiler can detect are satisfied in a produced causal dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "W07zGnSXjK", "forum": "T29Oa85nzw", "replyto": "T29Oa85nzw", "signatures": ["ICLR.cc/2026/Conference/Submission18028/Reviewer_Rs5Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18028/Reviewer_Rs5Q"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875050087, "cdate": 1761875050087, "tmdate": 1762927818057, "mdate": 1762927818057, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes CausalProfiler, a synthetic benchmark generator for systematically assessing causal machine learning. The proposed generator allows for generation of synthestic causal datasets under different assuptions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Causal inference is an extremely important problem, and developing comprehensive benchmarks to evaluate the performance of related methods under controlled conditions is essential."}, "weaknesses": {"value": "My main concern with this paper is its lack of novelty. Synthetic datasets have long been used to assess causal inference performance. The paper appears to unify existing methods to create a synthetic data generator. However, it still focuses mainly on synthetic data generation, rather than addressing the major benchmarking issue in causal inference: ensuring the realism of the data and assessing performance on real-world datasets. I also highly suggest that the paper be submitted to a benchmark track.\n\nIn addition, the use of the term causal machine learning is misleading. Causal machine learning is a broad term that often refers to machine learning methods built upon causal principles. This paper, however, focuses on machine learning frameworks specifically designed for causal inference. This distinction needs to be made clear in the paper. The paper should also include more benchmarking results for a wider range of machine learning methods for causal inference, to better demonstrate the quality and comprehensiveness of the benchmark.\n\nFinally, many important details, including the algorithms, have been deferred to the appendix."}, "questions": {"value": "Please refer to the weakness section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "eTu7HyNMe3", "forum": "T29Oa85nzw", "replyto": "T29Oa85nzw", "signatures": ["ICLR.cc/2026/Conference/Submission18028/Reviewer_wEg1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18028/Reviewer_wEg1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762007674598, "cdate": 1762007674598, "tmdate": 1762927817643, "mdate": 1762927817643, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CausalProfiler, a framework for generating synthetic benchmark datasets to enable more rigorous evaluation of causal machine learning algorithms.\n\nCausalProfiler randomly samples diverse causal scenarios (models, queries, and data) based on user specifications, producing a wide range of evaluation tasks with known ground truth. It is the first benchmark generator to cover all three levels of Pearl’s causal hierarchy—association, intervention, and counterfactual—under transparent assumptions. The authors demonstrate its utility by evaluating several state-of-the-art methods, showing the framework can rigorously analyze algorithm performance and failure modes, even in cases where the causal effect is not identifiable."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- CausalProfiler offers a novel, randomized generator for causal ML evaluation. Unlike static, hand-crafted datasets, it can instantiate diverse causal models and queries. Crucially, it is the first framework to cover all three levels of Pearl’s causal hierarchy (observational, interventional, and counterfactual), allowing for broad algorithm testing against known ground truth.\n\n- The framework operates by sampling from a user-defined \"Space of Interest\" (e.g., graph types, data distributions). This ensures that all benchmark conditions and assumptions are fully transparent. By systematically exploring a space of models rather than a few examples, it provides rigorous stress-testing and avoids the risk of cherry-picked scenarios.\n\n- The paper demonstrates CausalProfiler's value through extensive experiments on state-of-the-art methods. The tests vary functional forms (linear vs. non-linear), graph sizes, and sample sizes. Notably, the evaluation includes scenarios where the causal effect is not theoretically identifiable, allowing the framework to effectively reveal the failure modes and assumption sensitivities of different algorithms."}, "weaknesses": {"value": "- The evaluation relies entirely on synthetic data. While this provides ground truth, it fails to demonstrate how insights from CausalProfiler generalize to the complexity and \"messiness\" of real-world applications. The lack of real or semi-synthetic case studies makes it unclear if the framework's conclusions hold in practice.\n\n- The framework's utility is constrained by its initial design assumptions (e.g., graph types, functional forms). It is unclear if the current \"space of interest\" adequately covers challenging, realistic scenarios like high-dimensional or complex temporal data. Evaluations might remain optimistic if they omit hard-to-model cases.\n\n- The paper does not directly compare evaluations from CausalProfiler against existing, \"hand-crafted\" benchmarks (like IHDP). Without this comparison, it is difficult to quantify the practical advantage of the new framework or judge how much more informative its results are than those from standard datasets."}, "questions": {"value": "- How do the authors envision bridging the gap between synthetic benchmarks and real-world data challenges? In particular, can CausalProfiler incorporate patterns or constraints derived from real datasets (for example, using a real data covariance structure or causal graph as a template) to improve its real-world applications. Additionally, have the authors considered validating whether performance trends observed in these synthetic experiments hold true on real or semi-synthetic datasets? Such validation would strengthen confidence that the synthetic benchmarks are representative of practical scenarios.\n\n- What are the current limits of CausalProfiler in terms of problem size and complexity, and how might it scale moving forward? For instance, if one wanted to generate benchmarks with significantly larger causal graphs (hundreds of nodes) or incorporate more complex data modalities (like time-series or image data in a causal context), what challenges would arise? Understanding the computational and design hurdles for scaling up (or extending to new data types) would clarify how widely applicable the framework is, and what developments are needed to broaden its usage for the community."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gi5zsg99po", "forum": "T29Oa85nzw", "replyto": "T29Oa85nzw", "signatures": ["ICLR.cc/2026/Conference/Submission18028/Reviewer_afzW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18028/Reviewer_afzW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18028/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762070434431, "cdate": 1762070434431, "tmdate": 1762927816919, "mdate": 1762927816919, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}