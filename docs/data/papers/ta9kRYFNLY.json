{"id": "ta9kRYFNLY", "number": 9207, "cdate": 1758115258938, "mdate": 1763245128117, "content": {"title": "Ensuring Physicochemical Fidelity of Generated Polymers with PoGE", "abstract": "Recent advances in machine learning have accelerated progress in chemistry, enabling new capabilities in molecular design, property prediction, and materials discovery. A critical challenge in materials science is designing polymers with targeted macroscopic properties. However, prior generative models often fail to produce chemically valid polymer structures, hindering progress toward this goal. We introduce PoGE (Polymer Generation and Evaluation), a framework comprising two complementary components: a physics-informed evaluation suite for polymer generative models, and an unconditional transformer-based generative model adapted to polymer representations. Building upon and extending established molecule-centric benchmarks, our evaluation quantifies the alignment between the generated and experimental property distributions using the Wasserstein distance. The generative model is trained on a hybrid corpus of synthetic and experimental polymer representations and enforces polymer-specific validity constraints (“p-validity”) beyond the standard small-molecule validity. PoGE achieves high p-validity and significantly improved agreement with experimental property distributions compared to prior methods, even without explicit property conditioning during generation. By releasing a comprehensive benchmark, a high-quality pre-training corpus, and the trained model, PoGE establishes a foundation for conditional polymer generation tasks (e.g., on-demand reverse design), enabling targeted property optimization and accelerating reproducible, domain-aware polymer discovery.", "tldr": "PoGE is a transformer-based polymer generative model with a physics-informed evaluation that produces chemically valid polymers closely matching experimental structures, advancing polymer design and discovery.", "keywords": ["Polymer Informatics", "Generative models", "Materials discovery", "Domain-specific evaluation", "SMILES-based modeling", "Transformers"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1941f34edc10c572248aaf019a8cb21226945625.pdf", "supplementary_material": "/attachment/42522efcc0f2ac6f21af9b23f9a3439e2aadb555.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents PoGE, a framework that integrates an unconditional transformer-based generative model with a physics-informed evaluation suite.\n\nFor the unconditional generative model, this paper adopts a scaled-down variant of GPT-2, pretrained on a large volume of typically lower-quality p-SMILES and subsequently fine-tuned on a smaller set of high-quality p-SMILES examples.\n\nFor the evaluation suite, this paper proposes a set of metrics specifically designed for polymers, thereby overcoming the limitations of directly applying evaluation criteria developed for drug-like molecules.\n\nThrough establishing such a foundational platform, this paper paves the way for more effective AI-driven materials design in the polymer domain."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper proposes a physics-driven evaluation framework specifically designed for polymers, thereby overcoming the limitations of directly applying evaluation criteria developed for drug-like molecules.\n\n2. This paper proposes an unconditional generative model, which achieves high p-validity and significantly improved agreement with experimental data compared to prior methods."}, "weaknesses": {"value": "1. Fundamentally, the unconditional generative model proposed in this paper is little more than a straightforward application of GPT-2 through pretraining and fine‑tuning on p-SMILES, offering limited methodological novelty.\n\n2. Moreover, since both the PI1M dataset and PolyTAO corpora have already been used as part of the proposed model’s pretraining corpus, and the proposed model is further fine‑tuned on the higher‑quality PolyInfo dataset, comparisons against PI1M and PolyTAO are inherently unfair.\n\n3. For the evaluation metrics, some aspects are inaccurate or not entirely appropriate:\n    * The p‑valid metric requires that each bond at the endpoints of the polymer repeat unit be of the same type. However, this is chemically unreasonable since repeat units can be asymmetric, branched, or linked in non‑head‑to‑tail patterns. Therefore, this rule introduces bias and may misjudge structurally valid polymers as invalid.\n    * The novelty metric considers only PolyInfo data as the reference dataset. However,  this is not appropriate since the PI1M dataset and PolyTAO corpora are also used as training data. This rule lead to an overestimation of novelty, as the model’s generated samples might overlap with training data not accounted for in the evaluation.\n\n4. More datasets and methods should be discussed and compared in this work, such as the PolyOne dataset introduced in [1] and the SMiPoly generator proposed in [2].\n\n[1] Kuenneth, Christopher, and Rampi Ramprasad. \"polyBERT: a chemical language model to enable fully machine-driven ultrafast polymer informatics.\" Nature Communications 14.1 (2023): 4099.\n\n[2] Ohno, Mitsuru, et al. \"SMiPoly: generation of a synthesizable polymer virtual library using rule-based polymerization reactions.\" Journal of Chemical Information and Modeling 63.17 (2023): 5539-5548."}, "questions": {"value": "1. Except for the novelty metric, I would like to know what reference datasets are used for the other evaluation metrics, such as SNN and various descriptor‑based metrics. Are these metrics also computed using only PolyInfo data as the reference?\n\n2. In Table 1, why don't you report the p-valid, Unique, and Novel metrics on the PI1M dataset?\n\n3. In Tables 1 and 2, does the “PolyTAO” dataset correspond to the same PolyTAO corpus used for pretraining?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7cLRmDHfBI", "forum": "ta9kRYFNLY", "replyto": "ta9kRYFNLY", "signatures": ["ICLR.cc/2026/Conference/Submission9207/Reviewer_WM68"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9207/Reviewer_WM68"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9207/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761240245533, "cdate": 1761240245533, "tmdate": 1762920959255, "mdate": 1762920959255, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents PoGE, a polymer generation framework based on a small GPT-2 model trained on polymer SMILES (p-SMILES) representations.It introduces a p-validity definition specific to polymers and uses Wasserstein distance between distributions of molecular descriptors (molar mass, TPSA, rotatable bond fraction, aromatic fraction, etc.) for generated versus experimental polymers.\nThe goal is to ensure that generated polymers are not only syntactically valid but also physically plausible."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The work focuses on polymers, an important but underexplored domain.\n\n2. The work highlights the lack of polymer-specific validity metrics in current molecular generation benchmarks.\n\n3. The work is well written and easy to follow."}, "weaknesses": {"value": "## Limited Novelty: \n\n1. The only methodological novelty of evaluating distributions via Wasserstein distance is very straightforward statistical measure and not new.\n\n## Overstated claims\n\n2. The paper uses terms like “physics-driven” and “physically grounded” evaluation, yet all evidence comes from simple 1D descriptor distributions. The evaluation does not extend to polymer ensembles with experimentally verified properties or synthesis constraints.\n\n3. The p-valid is interesting but not comprehensive. But a valid polymer may have more than 2 (e.g., 4) indicators (*) for the polymerization positions.\n\n## Generation\n\n4. PoGE performs unconditional sampling only, without showing how its learned distributions could guide goal-oriented polymer design."}, "questions": {"value": "1. Why does the work focus on unconditional generation instead of conditional generation, which is more useful for polymers?\n\n2. Have the authors tested their generated polymers in simulations or lab experiments? What makes the dataset different from previous ones in terms of usefulness and properties?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "biIa8Ja0Ob", "forum": "ta9kRYFNLY", "replyto": "ta9kRYFNLY", "signatures": ["ICLR.cc/2026/Conference/Submission9207/Reviewer_Zzzu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9207/Reviewer_Zzzu"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9207/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761420596938, "cdate": 1761420596938, "tmdate": 1762920873275, "mdate": 1762920873275, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work introduces PoGE (Polymer Generation and Evaluation, a unified framework designed to improve the physicochemical fidelity of machine learning-generated polymer structures. PoGE presents two innovations: 1) a GPT-2-based generative model for unconditional polymer design, and 2) a physics-informed evaluation suite for evaluating polymers according to domain-specific property distribution metrics. The authors additionally present an unconditional dataset of polymers curated via PolyTAO, taking advantage of conditional generation with broad property coverage to curate a dataset of 1 million generated polymers. Empirical results show that PoGE achieves superior chemical validity, uniqueness, and alignment with experimental descriptor distributions relative to prior frameworks. The work establishes the first reproducible, domain-aware platform for conditional and inverse design tasks in polymer informatics."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. PoGE compares favorably to baseline models on most metrics, including validity and lower Wasserstein distances to the true data with respect to various physicochemical properties. \n2. PoGE introduces a new, expanded dataset and benchmark by combining the PI1M dataset, the PolyInfo dataset, approximately 1 million structures generated by PolyTAO. The work is able to harness PolyTAO for unconditional generation by marginalizing the conditional model over the empirical PolyInfo distributions of 15 property types.\n3. The authors supplement the work with property density comparison across different components of the complete dataset."}, "weaknesses": {"value": "1. Although it is mentioned as a potential application of the work, PoGE does not seem to showcase experiments in property-conditioned polymer design. \n2. The machine-learning novelty of the work is rather limited. The authors appear to directly use GPT-2 with little to no architectural modifications.\n3. The selection of hyperparameters to optimize with Optuna (top_p, top_k, and temperature) is never explicitly motivated in the paper. \n4. In section 3.4, the authors argue that chosen properties avoid redundancy and multicollinearity. In addition, as described in section A.2.1, descriptor values for conditional input to PolyTAO are sampled independently. This is a strong assumption and insufficiently justified, with no correlation analyses performed between individual properties. \n\nMinor:\n1. In table 1, it may be best to indicate for each metric whether lower is better or higher is better.\n2. The paper omits some details on experimental results; for instance, the number of generated samples per run."}, "questions": {"value": "As a sanity check, was the PolyInfo dataset ever screened for p-validity? That is, is the entire PolyInfo dataset p-valid?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wbUhx94Fl9", "forum": "ta9kRYFNLY", "replyto": "ta9kRYFNLY", "signatures": ["ICLR.cc/2026/Conference/Submission9207/Reviewer_LwqX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9207/Reviewer_LwqX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9207/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761953131444, "cdate": 1761953131444, "tmdate": 1762920872897, "mdate": 1762920872897, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors trained GPT-2 to generate polymers. They then evaluate the distribution of the generated polymers, and show that there is a good match with existing datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The paper is relatively clear. The resulting dataset could be useful."}, "weaknesses": {"value": "I think the primary weakness of this work is that its main contributions seem to be incremental, and somewhat speculative. Inverse design is clearly important, and they authors claim that this will facilitate incremental design, it seems reasonable to think that it might, but there should be stronger evidence or at least plausible or cited ways to get to inverse design from an unconditional generator or dataset.\n\nThe paper takes a number of datasets, themselves generated, such as PI1M (RNN) and also one real-world dataset (PolyInfo). It then trains/fine-tunes on those to create what is claimed to be a better generator. The results in Table 1 are suggestive, but the ones that I believe are most important, Uniqueness, Novelty, and IntDiv, show mixed results. Validity and p-valid are useful to know as a performance standpoint, but modest differences do not seem crucial to me. The reason is: Suppose there is Method A that can generate 100 million polymers in 50 minutes, and Method B that can generate 50 million an hour. Raw outputs of Method A are only 75% p-valid, but raw outputs of Method B are 100% p-valid. But suppose the outputs of Method A can be filtered for p-validity in 10 minutes. Method A can now effectively generate 75 million, 100% p-valid polymers an hour, while Method B can only generate 50 million p-valid polymers an hour. Of course, it may be the case that the polymers generated by Method B may be higher quality, but that is a different metric.\n\nThere is a claim that the authors used BPE because it reduces the number of tokens, and mention that RNN struggle over 5-7 tokens. PoGE, however, is a transformer architecture.\n\nComparing the unconditional distributions as a metric seems weak. Why is this a good metric to use, if our ultimate goal is inverse design? Distributions of the conditional generation would be more convincing."}, "questions": {"value": "Why are there any invalid SMILES in PI1M?\n\nBPE has no awareness of p-SMILES/SMILES syntax, so might find byte pairs that are not very semantically meaningful. Would a custom tokenizer that was aware of p-SMILES syntax do better?\n\nNovelty for PoGE was only tested against PolyInfo data? What about the PI1M data? That was also in the training set for PoGE.\n\nWas Uniqueness measured using canonicalized SMILES?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lJYZBpDxh1", "forum": "ta9kRYFNLY", "replyto": "ta9kRYFNLY", "signatures": ["ICLR.cc/2026/Conference/Submission9207/Reviewer_acNN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9207/Reviewer_acNN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9207/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761964086993, "cdate": 1761964086993, "tmdate": 1762920872474, "mdate": 1762920872474, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}