{"id": "1mQT8PXIy8", "number": 4846, "cdate": 1757775923300, "mdate": 1763723645392, "content": {"title": "Boosting for Predictive Sufficiency", "abstract": "Out-of-distribution (OOD) generalization is a defining hallmark of truly robust and reliable machine learning systems. Recently, it has been empirically observed that existing OOD generalization methods often underperform on real-world tabular data, where hidden confounding shifts drive distribution changes that boosting models handle more effectively. Part of boosting’s success is attributed to variance reduction, handling missing variables, feature selection, and connections to multicalibration. This paper uncovers a crucial reason behind its success in OOD generalization: boosting’s ability to infer stable environments robust to hidden confounding shifts and maximize predictive performance within those environments. This paper introduces an information-theoretic notion called $\\alpha$-predictive sufficiency and formalizes its link to OOD generalization under hidden confounding. We show that boosting implicitly identifies suitable environments and produces an $\\alpha$-predictive sufficient predictor. We validate our theoretical results through synthetic and real-world experiments and show that boosting achieves robust performance by identifying these environments and maximizing the association between predictions and true outcomes.", "tldr": "We explain how boosting can improve OOD generalization under hidden confounding shifts by connecting boosting and predictive sufficiency", "keywords": ["OOD Generalization", "Boosting", "Predictive sufficiency", "Reference Class"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0eb0f948302a58d9069fefbe3392b6d9a38efb1c.pdf", "supplementary_material": "/attachment/e56bc5b1681cefe74fa72bf41646f68bd8a48b35.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces an information theoretic notion called $\\alpha$-predictive sufficiency to measure the generalizatiability of predictive models under hiding confounding shifts. It shows that boosting algorithms gives a predictor that is $\\alpha$-predictive sufficient and they implicitly identifies environments corresponding to hidden confounding shifts."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is mostly well-written. The introduction gives a very clear picture what problems it is trying to solve and sufficient background information, including the relevant work.\n\n- The observation on achieving $\\alpha$-predictive sufficiency by maximizing the predictive information is insightful. Using $\\alpha$-predictive sufficiency to evaluate the invariance of the predictors is logically sound given that equation 1 holds.  \n\n- Proposition 4.1 seems correct. \n\n- The paper provides codes to reproduce the experimental results."}, "weaknesses": {"value": "- The paper acknowledges that the idea of $\\alpha$-predictive sufficiency is inspired by by $\\alpha$-approximate multi-calibration. It would be better to include some high-level descriptions about $\\alpha$-approximate multi-calibration in the background. Otherwise, the flow of the paper in lines 282-285 becomes a bit disconnected for someone who does not know anything about $\\alpha$-approximate multi-calibration. \n\n- Definition 5.1 is not quite clear.  For example, it is not clear why definition 5.1 says ‘then, there exists…’ and it also seems to use $c_{E}$ and $c_{G}$ interchangeably. The subscript $G$ does not seem to carry any meaning.  \n\n-  The main claim in Theorem 5.1 is built on the assumptions 5.1-5.3, but the description of the assumptions 5.1 is not clear enough for readers to assess the significance of Theorem 5.1.\n\n- The derivation of the predictive information (Eq. 1) based on a non-peer-reviewed paper seems very questionable. It is built on assumptions that are not described in the submitted manuscript about the information flow between variables. \n\n- The main theorem 5.1 is heavily built on equation 1 in the paper, but equation 1 is derived by Gowtham Reddy et al. 2025. The contribution of the paper seems limited by simply adding assumptions 5.1-5.3 for showing boosting algorithms to be $\\alpha$-predictive sufficient. \n\n- Some steps in the proof of Theorem 5.1 are not clear.\n\n- The instructions in the code says to reproduce Figure 2 by running ‘CatBoost_Cluster_wrt_U.py’, but it doesn’t use 100 estimators as shown in the paper.  It only shows up to 40 estimators with max_depth =5. \n\n- In the synthetic experiment 2, the paper does not explain why the boosting algorithm will need $S$ to improve its performance. \n\n- The real-world data seems synthetic by simulating an artificial hidden confounding shift."}, "questions": {"value": "- Why does the mutual information of the residual and the environment variable given the prediction need to be upper bounded by 1 for $\\alpha$-predictive sufficiency in Definition 4.2?\n- What is $c_{E}$ in definition 5.1? Is $c_{G}$ supposed to be written as $c_{E}$?\n- What the set of covariates $\\mathbf{X}$ is defined as the elements of environment $E$ in definition 5.1? How should one interpret it as they are separate nodes in the causal graph in Figure 1?\n- Is $p$ positive in Assumption 5.1? \n- Can the authors explain why assumption 5.1 is realistic?\n- For the derivation of equation 1, it relies on the two equations (eq 2 and eq 3) in Gowtham Reddy et al. 2025. The derivation of those inequalities claims that by conditioning on Y, the mutual information between $\\phi(X)$ and $E$ will increase, and it will be greater than or equal to $I(\\phi(X); E)$, but there is no theoretical support for this claim. A similar issue occurs for other inequalities in eq 2 and eq 3. Can the authors justify these claims to demonstrate the correctness of eq 1 in the submitted manuscript?\n- How is line 747 implied by Equation 4 in the proof in Theorem 5.1?\n- Why did the experiment choose to shift the mean by 0.2 only in the synthetic experiment 1 as indicated by the code? Can the experiment show the effect of the $\\mu_{e}$ for a wider range of values to see how robust the boosting algorithms are?\n- How is the shift implemented in the synthetic experiment 2? What is the role of $S$ in this experiment? Why would XGboost fail even when it is only trained by $X$? Isn’t that the opposite of what the paper claims when the hidden confounder shifts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cgogBrx48L", "forum": "1mQT8PXIy8", "replyto": "1mQT8PXIy8", "signatures": ["ICLR.cc/2026/Conference/Submission4846/Reviewer_75bL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4846/Reviewer_75bL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761037011749, "cdate": 1761037011749, "tmdate": 1762917607822, "mdate": 1762917607822, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduce  $\\alpha$-predictive sufficiency and argues that boosting algorithms implicitly identify stable “reference classes” lead to predictors with better OOD behavior under hidden confounding shifts. The authors provide theoretical connections between boosting and predictive sufficiency and validate these claims with synthetic and real-world tabular experiments showing boosting’s robustness in such settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The introduction of $\\alpha$-predictive sufficiency is interesting\n\n2. Robust OOD performance under hidden confounding is a pressing problem for real-world tabular data, where many popular OOD methods underperform; the paper directly targets this gap."}, "weaknesses": {"value": "1. The authors focus on tabular datasets. It would be helpful to briefly comment on whether the predictive-sufficiency perspective extends to other modalities like Image\n\n2. Comparisons to other OOD approaches.\n\n3. The author can summarize the contribution of this article in detail and the difference from existing methods to make it easier for readers to understand."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "DaCBfygYe2", "forum": "1mQT8PXIy8", "replyto": "1mQT8PXIy8", "signatures": ["ICLR.cc/2026/Conference/Submission4846/Reviewer_Pav5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4846/Reviewer_Pav5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761627942123, "cdate": 1761627942123, "tmdate": 1762917607532, "mdate": 1762917607532, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper asks why boosting methods often outperform specialized OOD techniques on real‑world tabular data, especially under hidden confounding shift. It reframes OOD as a reference‑class inference problem and argues that boosting succeeds because it implicitly infers “environments” aligned with latent confounder values. It introduces an information‑theoretic target, α‑predictive sufficiency, measuring whether the residual depends on the (latent) environment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Authors recast OOD under hidden confounding as reference‑class inference and formalizes when a predictor “uses the right class” via α‑predictive sufficiency (Def. 4.2). This helps bridge invariance, multicalibration, and MI‑based viewpoints. \nThe analysis offers a compelling narrative: boosting’s reweighting plus diverse weak learners implicitly induce environment‑like partitions aligned with confounder strata—consistent with clustering observed in leaf embeddings. \nAcross synthetic setups and two datasets, increased predictive information and lower sufficiency residuals correlate with better OOD metrics (Table 1), strengthening the paper’s thesis even if not conclusive."}, "weaknesses": {"value": "1. Alg. 1 chooses weak learners by maximizing (I(Y;h(X))) under reweighting and assumes an oracle. CatBoost/XGBoost instead optimize gradient‑based surrogates on losses; no result shows that those procedures approximate the MI‑oracle selection or that their reweighting schedules satisfy Assumption 5.1. The main theorem therefore does not directly cover the widely used algorithms studied empirically. \n\n2. The definition of predictive sufficiency uses a numeric residual; for categorical (Y), this is ill‑posed without an embedding of labels. The paper empirically studies both regression and classification tasks but does not specify how the residual is defined for the latter (e.g., one‑hot, logits, or 0/1 error event)."}, "questions": {"value": "1. Can you formalize conditions under which gradient‑boosted tree splitting criteria (e.g., squared‑error or logloss gain) are monotone surrogates for the MI objective in Alg. 1 step 3? Even a lemma relating gain to a lower bound on (I(Y;h(X))) would narrow the theory–practice gap. \n\n2. How exactly is $Y-\\hat{Y}$ instantiated when (Y) is categorical (e.g., indicator of misclassification, one‑hot minus probability vector, or log‑odds residual)? Please specify and justify for the MI/KSG estimators."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pCsR8gl6yz", "forum": "1mQT8PXIy8", "replyto": "1mQT8PXIy8", "signatures": ["ICLR.cc/2026/Conference/Submission4846/Reviewer_ZKii"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4846/Reviewer_ZKii"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971896113, "cdate": 1761971896113, "tmdate": 1762917607183, "mdate": 1762917607183, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an information-theoretic framework linking boosting-type algorithms to out-of-distribution generalization. It defines the notion of $\\alpha$-predictive sufficiency, based on conditional mutual information, and presents an iterative “information-boosting” procedure that aims to build predictors satisfying this condition. Theoretical guarantees and empirical results on synthetic and real datasets illustrate the proposed connection between boosting and predictive sufficiency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes an original theoretical connection between boosting and out-of-distribution generalization through an information-theoretic framework. In particular, the introduction of the α-predictive sufficiency concept provides a novel way to formalize robustness to hidden confounding shifts.\n\n- Empirical studies on both synthetic and real datasets offer some qualitative support to the proposed theory.\n\n- The paper is clearly written, with good motivation and intuitive explanations connecting information theory, causality, and ensemble learning. Sometimes the mathematical notation is ambiguous tough."}, "weaknesses": {"value": "- The use of the term *boosting* is largely metaphorical: Algorithm 1 assumes access to an oracle that exactly maximizes a mutual-information objective, rather than invoking a weak learner trained under a reweighted data distribution. As a result, the procedure cannot be interpreted as a genuine boosting algorithm or as a weak-to-strong reduction.\n\n- The main theoretical result (Theorem~5.1) is deterministic and depends on the assumption that the learner performs an exact maximization step. This removes the probabilistic weak-learning premise that underlies classical boosting theory.\n\n- The notation and treatment of the environment variable $E$ are inconsistent: sometimes $E$ is treated as a random variable, elsewhere as a subset or conditioning event, making several definitions (e.g., Def. 5.1) mathematically ambiguous.\n\n- The quantity $I(Y-\\hat{Y};E\\mid\\hat{Y})$ is introduced without a rigorous definition of the residual term $Y-\\hat{Y}$, which limits the formal interpretability of the proposed $\\alpha$-predictive sufficiency condition."}, "questions": {"value": "Refer to the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IBEBN1RfYk", "forum": "1mQT8PXIy8", "replyto": "1mQT8PXIy8", "signatures": ["ICLR.cc/2026/Conference/Submission4846/Reviewer_91R9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4846/Reviewer_91R9"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762099661612, "cdate": 1762099661612, "tmdate": 1762917606741, "mdate": 1762917606741, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}