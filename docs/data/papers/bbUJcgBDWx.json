{"id": "bbUJcgBDWx", "number": 7827, "cdate": 1758037816035, "mdate": 1759897829565, "content": {"title": "Harmonizing Multi-Site Multi-Sequence Brain MRI via Semantic-Guided Conditional Diffusion", "abstract": "Training robust AI models for brain MRI analysis typically requires large datasets, prompting many studies to aggregate multi-site data. However, this introduces unwanted variations due to differences in scanners and/or acquisition protocols. These non-biological variations (known as site effects) can significantly compromise the performance and generalizability of downstream deep learning models. While image-level harmonization has emerged as a promising solution, existing methods frequently demand paired data (e.g., scans of the same subject at different sites) or costly encoder-decoder networks to disentangle anatomical content from predefined imaging style (e.g., intensity and contrast), which struggle to comprehensively capture diverse image styles. Moreover, existing methods cannot readily adapt across different MRI sequences, limiting their scalability. This paper proposes a semantic-guided conditional diffusion (SGCD) framework for unpaired 3D multi-sequence MRI harmonization. SGCD first trains a conditional diffusion model (CDM) to align multi-site, multi-sequence MRIs into a unified, sequence-specific domain, reducing global site-related variations. It then fine-tunes the CDM for target-specific harmonization using a style loss derived from BiomedCLIP, trained on medical imaging data. By capturing differences in disentangled semantic image style between the harmonized and target MRIs, this loss enables effective harmonization that preserves anatomical structure and does not require paired training data. We evaluate SGCD on 4,163 T1-/T2-weighted MRIs from three multi-site datasets, with results suggesting its superiority over several state-of-the-art methods across voxel-level comparison, downstream classification, and brain tissue segmentation tasks.", "tldr": "We propose a semantic-guided conditional diffusion model for unpaired multi-sequence MRI harmonization that preserves anatomy, handles diverse imaging styles, and outperforms existing methods.", "keywords": ["Brain MRI Harmonization", "Style Translation", "Diffusion"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/deb77702b1e81f29a5d7f2197b0d83e87ac83540.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a diffusion-based method to remove non-biological differences in MRI images due to differences in scanners, and to adapt the images to match the style for a particular scanner site. The method does not require paired data (one individual scanned in multiple scanners), which is difficult to obtain. The paper compares to other methods and shows that they (a) better preserve anatomical detail according to tests on paired data,  while also (b) better removing site variation as measured by voxel intensity histograms and downstream site classifiers. The method incorporates several interesting features including spatial gradient map conditioning in the diffusion model, voxel histogram alignment loss, and a semantic loss incorporating BioMedCLIP embeddings to better preserve anatomical details while harmonizing images. An ablation study confirms the utility of each component.\n\nWhile the paper is focused on neuroimaging and therefore may not appeal to the wider ICLR community, the authors describe the general problem of disentangling spurious and meaningful differences in brain images well and give some interesting and generalizable methods to solve the problem."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Multi-site harmonization is an important challenge in neuroimaging. The authors describe the problem well. Diffusion based methods are increasingly being used here to improve image quality. \n\n- While I've seen several works using the DDIM inversion trick for neuroimaging, there were some interesting methodological innovations here, including the use of spatial gradient maps for anatomical conditioning, histogram matching loss, and fine-tuning with a semantic loss. \n\n- Comparisons include reasonable 2d and 3d baselines, as far as I'm aware. \n\n- The paired subject evaluation, voxel histograms, and downstream classification checks were a nice way to verify that anatomical features are preserved while scanner differences are removed. The results look quite strong."}, "weaknesses": {"value": "- DDIM inversion presentation. I think there are some issues. Either I've misunderstood something or there are mistakes in the equations. My main issue is that the current notation suggests T (the target domain) is never used in the DDIM reversal. See specific questions below. (The notation T (target domain) vs. T_f, T_r (timestep indices) is also confusing.)\n\n\n-  The ablation discussion was useful, but I didn't think the single result in Fig. 5a was enough to support all the comments. For instance, \"SGDCw/oT... fails to capture local style features such as tissue contrast and texture\", how are we supposed to see something like this?"}, "questions": {"value": "1. I believe that the CLIP style guidance is only used for fine-tuning the model to preserve semantic detail during alignment. If so, is the backprop done through multiple layers of DDIM inversion, or just one (I hat)? \n2. In Equations 10–11, should the sign before the predicted noise term be negative (as in standard DDIM) to represent noise removal?\n3. Is the target domain T ever explicitly used in the sampling process, or is it only involved in the CLIP-based style loss?\n4. I believe Eq. 10 and 11, and Alg. 2, line 16 and 17 are not correct. I would have thought that we get the \"noise\" or \"latent space representation\" using T, then we generate using the noise T but the gradient maps from X. Is this correct? If not please clarify as I have misunderstood how the domain target is meant to be incorporated. (And if I'm correct, please check and fix the notation.)  \n5.\tCould you add references or discussion of prior uses of gradient consistency or gradient-difference losses for preserving anatomical detail? This is an interesting feature, but I hadn't come across the idea that it removes spurious site specific artifacts (though that seems reasonable, if we believe those are just random biases at each voxel.) \n6. Out of curiosity, is it correct that the method cannot perform unconditional generation (since gradient conditioning requires an existing input anatomy)? \n7. Is the L_R loss really necessary? It seems like it just measures the error in the DDIM ODE discretization. With more steps I'd expect this to go to zero. Still, I guess it can't hurt, and maybe it's useful to have fewer steps. Actually, you talk about tuning these parameters, but shouldn't results always improve with more steps? \n8. Other work \nOne paper that may be relevant (though I didn't study it, so perhaps not) \nhttps://arxiv.org/pdf/2409.00807v1.  Also, I feel that I've seen the \"DDIM inversion\" trick used on brain images in other contexts, like this one (https://ieeexplore.ieee.org/abstract/document/10782737/), for example. If there are one or two relevant examples they may be nice to mention or to contrast with your approach."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UAcmuB0jfY", "forum": "bbUJcgBDWx", "replyto": "bbUJcgBDWx", "signatures": ["ICLR.cc/2026/Conference/Submission7827/Reviewer_bDEP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7827/Reviewer_bDEP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7827/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761262084725, "cdate": 1761262084725, "tmdate": 1762919871610, "mdate": 1762919871610, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The presented work researches the use of diffusion models to harmonize MR images acquired with different MR scanners. In the first stage, the proposed method translates images to a sequence-specific, site-invariant representation. This is achieved by processing the images via a diffusion model, which is conditioned on edge maps from the original image as well as a learnable soft intensity histogram. In the second stage, the obtained unified representations are translated to the target style using yet another conditional diffusion model. The conditioning for the site-specific image appearance is generated by obtaining embeddings from the target image and its unified representation via a pre-trained CLIP encoder and calculating their difference. In experiments using three MR image datasets, the proposed method is shown to successfully translate images to diverse target styles, which is quantified via image similarity metrics, comparison of tissue segmentation maps, and measuring the utility of harmonized MR images to train age prediction models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- MR scanner harmonization is a topic of emerging scientific interest, with only a limited number of related works researching the use of deep learning for this purpose. Moreover, any successful method would have clear practical benefit for scientists and clinicians handling MR images acquired with different scanners.\n\n- The proposed method is intuitively understandable, with the use of a pre-trained CLIP encoder to disentangle content and style as well as a learnable soft-histogram to guide the site-invariant representation learning being interesting and potentially novel.\n\n- The manuscript is clearly structured, illustrated and well written, making it easy to understand and follow.\n\n- The proposed method is extensively evaluated by comparing it to five relevant baselines using three datasets. Moreover, the generated images are assessed through the lens of image similarity metrics, anatomical realism, and their utility as training data for neural networks for brain age prediction."}, "weaknesses": {"value": "- There is considerable overlap with previously published work, which is most likely by the same authors (Wu, Mengqi, et al. \"Unpaired Multi-site Brain MRI Harmonization with Image Style-Guided Latent Diffusion.\" International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham: Springer Nature Switzerland, 2025). In particular, the entire second stage – called Target-Specific Fine Harmonization in the submitted work and CLIP-Style Fine Harmonizer in the published work – are essentially the same. Moreover, the use of gradient maps to guide the harmonization in the first stage is copied from the first work. As a result, the methodological novelty of the presented work is substantially diminished.\n\n- While the ICLR’s call for papers explicitly mentions work exploring applications in healthcare, I feel that the presented study only makes limited contributions towards the general advancement of representation learning. I believe that the presented work with its highly specialized topic of MR scanner harmonization and tailored solution is mostly relevant for scientists working in the domains of medical image analysis or magnetic resonance imaging.\n\n- The proposed method barely outperforms several baselines with regard to image similarly metrics, tissue structure, and downstream utility. These concerns are further amplified by ambiguities related to the tuning of the method’s hyperparameters (see further questions below).\n\n- Circling back to the aforementioned similarities to previously published work, it is noteworthy, that the paper by Wu et al. reports markedly better performance of both the proposed method and baselines in apparently similar evaluation settings."}, "questions": {"value": "In addition to above’s major concerns I have a couple of minor questions:\n\n- The authors call the gradient maps “style-free”. However, I am unsure if these are truly style-free as a range of scanner-specific image characteristics, such as contrast, sharpness and grid homogeneity, will directly impact these gradient maps. I was wondering whether the authors have any quantitative results that back their claim that the gradient maps are unaffected by site effects?\n\n- The authors introduce the variable $m_i$, which encodes sequence type as a set of discrete numbers. I was wondering whether this is truly being used in practice instead of encoding the sequence type as a one-hot encoding?\n\n- It is unclear how several of the method’s hyperparameters were tuned. While the authors have compared different numbers of forward and reverse diffusion steps in an ablation study, they should also describe how the weighting of the many loss terms was determined.\n\n- Additionally, the statement “we ensured consistent training hyperparameters across all methods for fair comparisons” is ambiguous. Does this mean that the same hyperparameters were used across all methods (leading to a potential disadvantage for baselines that may benefit from additional hyperparameter tuning) or that the same hyperparameters as in the original publication were used (leading to a potential benefit for baseline that may have originally been tuned for different data domains) or something entirely different?"}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "details_of_ethics_concerns": {"value": "As outlined in my comments to the authors, there is considerable overlap with previous work (Wu, Mengqi, et al. \"Unpaired Multi-site Brain MRI Harmonization with Image Style-Guided Latent Diffusion.\" International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham: Springer Nature Switzerland, 2025). Considering the highly similar method, experimental setup, and manuscript style, I suspect that both studies were conducted by the same group of authors.\n\nIn particular, the entire second stage – called Target-Specific Fine Harmonization in the submitted work and CLIP-Style Fine Harmonizer in the published work – is essentially the same. Moreover, the use of gradient maps to guide the harmonization in the first stage is copied from the first work. As a result, the methodological novelty of the presented work is substantially diminished. Crucially the previous work is not referenced or mentioned at all in the submitted paper.\n\nConversely, there are a few novel contributions in the submitted work, specifically the introduction of a soft intensity histogram to guide extraction of site-invariant MR image representations."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PUj8ARbWHJ", "forum": "bbUJcgBDWx", "replyto": "bbUJcgBDWx", "signatures": ["ICLR.cc/2026/Conference/Submission7827/Reviewer_qmeS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7827/Reviewer_qmeS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7827/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761498787132, "cdate": 1761498787132, "tmdate": 1762919870667, "mdate": 1762919870667, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The content of this work appears to echo that of a paper titled, \"Unpaired Multi-Site Brain MRI Harmonization with Image Style-Guided Latent Diffusion\" accepted to MICCAI 2025. The paper cites another work by the author of the MICCAI paper, but not the MICCAI paper itself, though the figures, datasets, writing, baselines, and evaluation methods are almost identical. I believe that the only novel contribution from this work is section 3.1.2, the EMA-based record update in this particular context."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "N/a."}, "weaknesses": {"value": "The figures seem to be slight modifications of the MICCAI paper that bear obvious resemblance, including the same order. The numerical values in the tables are shown in a different format with similar values and the same metrics in the same order (age and site classification scores for all baselines are identical except for rounding variation to the other paper except for the proposed method). Both studies used exactly 3,984 subjects across 58 sites and the same competing methods. I can provide additional examples if necessary."}, "questions": {"value": "I do not have any questions regarding this work at this time."}, "flag_for_ethics_review": {"value": ["Yes, Research integrity issues (e.g., plagiarism, dual submission)"]}, "details_of_ethics_concerns": {"value": "Substantial mirroring of a paper available online from MICCAI 2025 (see paper weaknesses)."}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gvtZUXaZTa", "forum": "bbUJcgBDWx", "replyto": "bbUJcgBDWx", "signatures": ["ICLR.cc/2026/Conference/Submission7827/Reviewer_copw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7827/Reviewer_copw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7827/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762800984379, "cdate": 1762800984379, "tmdate": 1762919869710, "mdate": 1762919869710, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}