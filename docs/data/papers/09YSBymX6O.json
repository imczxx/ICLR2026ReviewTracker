{"id": "09YSBymX6O", "number": 11483, "cdate": 1758200193649, "mdate": 1763738467895, "content": {"title": "Spatially Informed Autoencoders for Interpretable Visual Representation Learning", "abstract": "We introduce spatially informed variational autoencoders (SI-VAE) as self-supervised deep-learning models that use stochastic point processes to predict spatial organization patterns from images.  Existing approaches to learning visual representations based on variational autoencoders (VAE) struggle to capture spatial correlations between objects or events, focusing instead on pixel intensities. We address this limitation by incorporating a point-process likelihood, derived from the Papangelou conditional intensity, as a self-supervision target. This results in a hybrid model that learns statistically interpretable representations of spatial localization patterns and enables zero-shot conditional simulation directly from images. Experiments with synthetic images show that SI-VAE improve the classification accuracy of attractive, repulsive, and uncorrelated point patterns from 48% (VAE) to over 80% in the worst case and 90% in the best case, while generalizing to unseen data. We apply SI-VAE to a real-world microscopy data set, demonstrating its use for studying the spatial organization of proteins in human cells and for using the representations in downstream statistical analysis.", "tldr": "We present spatially informed variational autoencoders that use stochastic point processes to learn interpretable spatial patterns from images.", "keywords": ["autoencoder", "visual representation", "point process", "conditional simulation", "interpretable machine learning", "self supervision", "spatial statistics"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/19dfe759456f5c45ce81010d1580d43e5c3d1558.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose using spatial point processes as a self-supervision prior that explicitly models spatial distributions of objects to address the gap in previous un- and self-supervised methods that miss the spatial correlations.  Thus, the paper proposes spatially informed variational autoencoders (SI-VAE) to predict spatial organization patterns from images. The authors apply SI-VAE to a real world microscopy dataset, OpenCell, and correctly identify the protein localization classes."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Improving VAEs by fusing them with spatial point processes, thus learning statistically interpretable representations of spatial distributions of objects in images can improve biological data analysis.\n\n- Furthermore, the decomposition into interpretable potentials is also a non-trivial contribution that is based on well-established statistical frameworks.\n\n- The paper introduces a principled way of interpreting the learnt representations within spatial statistics. The results on the biological dataset are promising."}, "weaknesses": {"value": "- The real world applications were limited in the paper. Given the novelty of the proposed method, I would have wanted to see more results on biological data and also interpretations. While the results are promising, it is unclear to me whether SI-VAE generalizes to more complex localization patterns or proteins with overlapping spatial distributions.\n\n- SI-VAE assumes that given z, the image and point pattern would be independent.\nBut since X is deterministically obtained from x, wouldn't this assumption be false? Could the authors clarify this?"}, "questions": {"value": "- Biological tissues can have direction dependent spatial structure (e.g.  muscle fibers, neuronal axons) which would lead to directionally correlated spatial patterns. Since SI-VAE assumes pairwise interaction potential to be symmetric, isotropic, from an implementation standpoint, how difficult would it be to extend SI-VAE to include anisotropic or direction aware interactions?\n\n- How sensitive are the SI-VAE representations to errors in spot detection, and could the model be extended to be fully end-to-end (e.g. learning jointly the point locations and spatial interactions)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Kx7KXvnROr", "forum": "09YSBymX6O", "replyto": "09YSBymX6O", "signatures": ["ICLR.cc/2026/Conference/Submission11483/Reviewer_vPwX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11483/Reviewer_vPwX"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11483/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761701736349, "cdate": 1761701736349, "tmdate": 1762922588754, "mdate": 1762922588754, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to Reviews"}, "comment": {"value": "We thank the Reviewers for the careful reading of our manuscript and for the constructive comments. We have accounted for them in the revised manuscript, which we upload herewith. We provisionally upload a redlined revision of the manuscript to more easily spot the changes. This will be replaced with a clean version by Dec. 3 latest.\n\nIn addition, we provide point-by-point responses to all reviews below, explaining the revisions made. We invite the Reviewers to post answers or additional comments, if any, which we will gladly try to address by Dec. 3 to the extent possible."}}, "id": "onBDoPRGHq", "forum": "09YSBymX6O", "replyto": "09YSBymX6O", "signatures": ["ICLR.cc/2026/Conference/Submission11483/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11483/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11483/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763738875699, "cdate": 1763738875699, "tmdate": 1763738875699, "mdate": 1763738875699, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a spatially informed variational autoencoder - SI-VAE, which consists of a VAE augmented with a spatial point process.  The latent representation z from the VAE is used as input to a neural network that then predicts the Gibbs potentials that define the point process.  Experiments are performed with synthetic data, showing a comparison to standard VAE, generalization to unseen processes, and zero-shot conditional simulation.  Lastly, an application to protein localization patterns is given, where it is demonstrated that the learned potentials agree with domain knowledge (eg proteins in vesicles being homogeneously distributed versus nucleus proteins being inhomogeneously distributed within the nuclei)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Interesting proposed model, sufficient technical contribution/novelty.  Validation on synthetic data."}, "weaknesses": {"value": "Although the proposed model is interesting, majority of the validation is on synthetic data in some sense tuned to the specifics of the model.  Demonstration of applicability to a real problem is somewhat limited - consisting of only one specific test application where the final evaluation is a check that the learned model potentials agree at a high level with what is expected from domain knowledge.  Within this particular task, there is also no notion of a baseline for comparison.  This is an area where the impact could be much improved, by showing broader applicability to other domains, or giving a more qualitative analysis against baseline methods, or showing some unexpected/novel finding instead of confirming existing domain knowledge."}, "questions": {"value": "see weaknesses above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iaaD2UHH3v", "forum": "09YSBymX6O", "replyto": "09YSBymX6O", "signatures": ["ICLR.cc/2026/Conference/Submission11483/Reviewer_B6yH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11483/Reviewer_B6yH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11483/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946309119, "cdate": 1761946309119, "tmdate": 1762922588336, "mdate": 1762922588336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper developed a self-supervised deep-learning model  that use stochastic point processes to predict spatial organization patterns from images, coined as Spatially Informed Variational Autoencoders (SI-VAE). The self-supervision mechanism is modeled by the Papangelou conditional intensity. Extensive experiments were presented to illustrate the effectiveness of the SI-VAE model."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper provided a comprehensive illustration of the idea of Spatially Informed Variational Autoencoders (SI-VAE), which leverages the Papangelou conditional intensity as the self-supervision target for measuring the spatial information of images. Extensive experiments provided convincing results to showcase the effectiveness of the SI-VAE model in capturing spatial interactions and its generalization to unseen data in terms of zero-shot learning. The impact of the SI-VAE was also demonstrated on a challenging real-world application of protein localization in human cells."}, "weaknesses": {"value": "Despite the strength as mentioned above, the paper only compares the proposed SI-VAE to the original VAE, while ignoring the existence of similar techniques, such as \n\n1) Semenova, et al., PriorVAE: encoding spatial priors with variational autoencoders for small-area estimation, J R Soc Interface, 2022\n2) Jazbec, et al., Scalable gaussian process variational autoencoders, AISTATS 2021.\n\nSuch an incompleteness of refereeing and comparisons weakens the overall quality of the paper."}, "questions": {"value": "What are the connections between the present work with existing Gaussian process variational autoencoders? What is new in the SI-VAE? Does the current model promote easy implementations?\n\nIf Gaussian process variational autoencoders can also be used to capture spatial information in the images, can the SI-VAE model still outperform its Guassian process counterparts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "aah6oDvMks", "forum": "09YSBymX6O", "replyto": "09YSBymX6O", "signatures": ["ICLR.cc/2026/Conference/Submission11483/Reviewer_zSUz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11483/Reviewer_zSUz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11483/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761949045196, "cdate": 1761949045196, "tmdate": 1762922587909, "mdate": 1762922587909, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}