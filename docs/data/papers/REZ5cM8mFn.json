{"id": "REZ5cM8mFn", "number": 10045, "cdate": 1758158000112, "mdate": 1759897678545, "content": {"title": "Robust onion: Peeling Open Vocab Object Detectors Under Noise", "abstract": "The impact of real-world noise on Open Vocabulary Object Detectors (OV-ODs) is constrained by their architectural complexity and the scarcity of noise-annotated datasets. Our empirical analysis, Robust Onion, uses controlled synthetic visual degradations to mirror feature collapse of real-world noises and systematically peel apart OV-OD components to assess their robustness. Our findings include: Similar vision backbones show comparable robustness, driven by identical feature collapse at similar layers. Pretraining, architectural nuances, and captions contribute little to robustness. Robustness relies strongly on the image domain rather than on annotations, explaining the similar impact of COCO and LVIS on robustness (same images, different annotations), and how datasets like ODinW-13, with large, isolated objects, can give a misleading impression of high robustness. These insights point to potential research on cross-layer feature exchange and continual learning strategies to improve robustness efficiently. Our findings highlight critical directions for designing robust OV-ODs under challenging visual degradations", "tldr": "Removing bells and whistles of Open Vocab Object Detectors to narrow down the factors affecting robustness against noises.", "keywords": ["object detection", "vlm", "robustness", "noise", "open vocab", "zero-shot"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/01093456f677faf3face8b3e110483826311ed04.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the robustness of Open-Vocabulary Object Detectors (OVODs) under real-world noise and visual degradation.\nThe authors introduce Robust Onion, a systematic framework that “peels apart” different OVOD components to analyze their resilience to noise using controlled synthetic distortions. Through empirical analysis across multiple architectures and datasets, the paper finds that:\n\n1. robustness is driven mainly by the image domain rather than annotations.\n\n2. similar backbones exhibit comparable robustness due to shared feature collapse patterns.\n\n3. pretraining details and captions contribute little to noise robustness.\n\n4. common benchmarks such as ODinW-13 may give a misleading impression of robustness.\n\nThese insights highlight the need for new strategies such as cross-layer feature exchange or continual learning for building noise-tolerant OVODs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Comprehensive evaluation across multiple models and datasets under diverse visual distortions.\n\n- Clear empirical dissection of factors (architecture, pretraining, annotations) affecting robustness.\n\n- Rich analysis with quantitative and qualitative visualization results.\n\n- Identifies key limitations of current benchmarks (e.g., ODinW-13) and provides valuable diagnostic insights."}, "weaknesses": {"value": "- Lacks quantitative comparison against recent SOTA robust or noise-aware OVD methods.\n\n- The motivation for studying robustness under visual noise could be better connected to real-world deployment scenarios.\n\n- Analysis-heavy paper without a concrete methodological contribution or design proposal.\n\n- No clear theoretical or mathematical formulation for the proposed “robust design direction.”\n\n- Missing comparison with input-level denoising or data augmentation baselines."}, "questions": {"value": "- How does Robust Onion compare quantitatively to recent noise-aware or robust OVD baselines beyond ODinW-13?\n\n- What are the key real-world deployment scenarios where robustness under visual noise is most critical?\n\n- Can the insights from this analysis lead to a concrete training or architectural strategy for improving OVD robustness?\n\n- How does the proposed analysis differ in impact from simpler input-level methods such as denoising or augmentation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "D6B0jaVty5", "forum": "REZ5cM8mFn", "replyto": "REZ5cM8mFn", "signatures": ["ICLR.cc/2026/Conference/Submission10045/Reviewer_cRjy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10045/Reviewer_cRjy"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761672403476, "cdate": 1761672403476, "tmdate": 1762921446474, "mdate": 1762921446474, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents robustness analysis of open-vocabulary object detectors (OV-ODs) under common visual corruptions like pixelation, motion blur, and turbulence. The authors propose the Robust Onion framework, which isolates how different model components contribute to robustness. Evaluating six models (e.g., GLIP, MM-GDINO, GLEE) across COCO, LVIS, ODinW-13, and Wider Face, the study finds that backbone depth, not fine-tuning or caption supervision, dominates robustness behavior. It also introduces two lightweight continual learning strategies (LR-TK0+ and LR-TK0++) to improve robustness in zero-shot settings."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "S1. The paper introduces a clear analytical framework to “peel” away layers of complexity and pinpoint which components of OV-OD models contribute to or detract from robustness. By systematically turning off or swapping certain components (e.g. using a frozen vs. fine-tuned backbone, or evaluating with vs. without caption-based training), the authors can attribute robustness (or lack thereof) to specific factors. This level of analysis moves beyond treating the model as a black box – it provides insightful breakdowns of how different stages (backbone, detector head, multimodal fusion, etc.) behave under noise. \n\nS2. The study delivers some important insights. One of them, the discovery that backbone depth/capacity is the primary driver of robustness (more so than fine-tuning or the richness of text supervision) is a interesting fact for further work.\n\nS3. The paper makes a practical contribution by proposing simple fine-tuning strategies (LR-TK0+ and LR-TK0++) that yield noticeable robustness gains. These strategies are lightweight (avoiding full model retraining) and thus would be attractive for practitioners looking to harden existing OV detectors against noise. The fact that a gradual fine-tuning on noisy data (LR-TK0++) outperforms a naive augmentation approach is a useful takeaway for the field.\n\nS4. Writing and structuring of the paper is easy to follow."}, "weaknesses": {"value": "W1. Contribution - While the analysis is detailed, the paper’s contributions are primarily empirical. The lack of a strong algorithmic or theoretical innovation prevent the exact take home knowledge to advance the field of OVOD. The proposed robustness fixes (LR-TK0+/TK0++) are relatively simple fine-tuning heuristics rather than fundamentally new methods which means, the contributions in applied and theoretical research are limited. \n\nW2.  Comparisons with Prior Work: The paper does not explicitly situate itself against closely related robustness studies. For instance, Chhipa et al. (2024) [1] evaluates open-vocabulary detectors (OWL-ViT, YOLO-CLIP, Grounding DINO) under distribution shifts and corruptions finding significant performance drops as well. Similarly, in the broader object detection literature, there have been benchmarks for robustness to corruptions (e.g. COCO-C and BDD100K-C) introduced by Liu et al. (2024) [2]. These works revealed, for example, that even high-mAP detectors can be very brittle and that transformer-based detectors may handle corruptions better than older architecture. It is suggested to have combined reasonable analysis with such studies and provide clear insights your findings.\n\n[1]  Chhipa, Prakash Chandra, et al. \"Open-Vocabulary Object Detectors: Robustness Challenges Under Distribution Shifts.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024\n\n[2] Liu, Jiawei, et al. \"Benchmarking object detection robustness against real-world corruptions.\" International Journal of Computer Vision 132.10 (2024): 4398-4416.\n\nW3. This paper propose fine-tuning strategies (LR-TK0 series) but do not compare them to alternative robustness interventions like standard data augmentation training or adversarial training. It’s mentioned that LR-TK0++ beats “random augmentation” (presumably LR-TK0+), but a stronger baseline could be full data augmentation during initial training (for instance, training the detector on corrupted images from scratch or heavy augmentation schedules). Evaluating such a baseline would show how far the proposed lightweight approach is from what one could achieve with more extensive retraining.\n\nW4. The claim that backbone depth alone drives robustness might be somewhat oversimplified. There is a correlation in their results, but correlation does not guarantee causation. Deeper models often also differ in other aspects: e.g. architecture family (CNN vs Transformer), pre-training dataset size, or training strategies. It’s possible that the robustness comes from some of these factors (for example, transformer-based detectors might inherently be more robust to certain perturbation. I suggest to provide convincing argument for that.\n\nW5. Scope of Noise Types: The study covers three synthetic noise types (pixelation, gaussian blur, turbulence). These mainly represent low-level distortions blurring or obscuring the image. While these are important, the robustness problem has other dimensions that the paper does not address – for example, illumination changes, weather effects (rain, fog)."}, "questions": {"value": "Please refer weakness section. I can change the score based on rebuttal's response."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FJdaptco9I", "forum": "REZ5cM8mFn", "replyto": "REZ5cM8mFn", "signatures": ["ICLR.cc/2026/Conference/Submission10045/Reviewer_gY5W"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10045/Reviewer_gY5W"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833202865, "cdate": 1761833202865, "tmdate": 1762921446177, "mdate": 1762921446177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Robust Onion, an extensive empirical analysis of Open-Vocabulary Object Detectors (OV-ODs) under visual noise and distortions. The work introduces a systematic framework to “peel apart” different components of OV-ODs (backbones, fusion modules, pretraining datasets, fine-tuning strategies, etc.) using controlled synthetic degradations that approximate real-world noise such as turbulence, motion blur, and pixelation. The authors evaluate six prominent models (GLIP, FIBER, MM-GDINO, GLEE, YOLO-World, and RegionCLIP) across multiple datasets (COCO, LVIS, ODinW-13). Key findings suggest that robustness is primarily driven by the vision backbone, particularly its depth and scale, while language features, annotations, and pretraining data contribute little. The analysis also highlights that robustness correlates with object size and domain rather than annotation type, and that prompt engineering or caption expressiveness has minimal effect. Finally, the authors propose LR-TK0+ and LR-TK0++, lightweight continual learning extensions designed to enhance robustness in zero-shot settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Provides a comprehensive empirical dissection of robustness factors in open-vocabulary object detection, covering multiple architectures, datasets, and controlled noise settings.\n\nThe experimental setup is methodologically clear and systematic, using synthetic degradations to emulate real-world noise with qualitative and quantitative alignment (as shown in Figures 1–3).\n\nOffers important and actionable insights, such as the dominance of backbone features in determining robustness, limited effect of pretraining size or language inputs, and the misleading robustness impression given by ODinW-13 due to large-object bias.\n\nIntroduces lightweight continual learning strategies (LR-TK0+, LR-TK0++) that show measurable improvement on COCO and WiderFace without retraining full models, demonstrating practical applicability."}, "weaknesses": {"value": "The paper does not clearly position itself in relation to previous robustness studies. For instance, Chhipa et al. (2024) [1] evaluated open-vocabulary detectors including OWL-ViT, YOLO-CLIP, and Grounding DINO under distribution shifts and common corruptions, reporting significant performance drops across models. Similarly, Liu et al. (2024) [2] introduced robustness benchmarks such as COCO-C and BDD100K-C in the broader object detection literature, showing that even high-mAP detectors can be fragile, while transformer-based architectures generally perform better under corruptions. It would strengthen the paper to connect its analysis with these prior works and clarify how its findings extend or differ from them.\n\nEvaluation noise types are somewhat narrow, focusing primarily on pixelation, turbulence, and motion blur, with little exploration of other real-world distortions (e.g., rain, snow, fog).\n\n[1] Chhipa, Prakash Chandra, et al. (2024) \"Open-Vocabulary Object Detectors: Robustness Challenges Under Distribution Shifts.\" European Conference on Computer Vision.\n\n[2] Liu, Jiawei, et al. \"Benchmarking object detection robustness against real-world corruptions.\" International Journal of Computer Vision, 132 (10), 4398-4416. (2024)"}, "questions": {"value": "Please follow the strengths and weaknesses. \nI am open to adjusting scores."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "AGgkjQaSgt", "forum": "REZ5cM8mFn", "replyto": "REZ5cM8mFn", "signatures": ["ICLR.cc/2026/Conference/Submission10045/Reviewer_x5K3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10045/Reviewer_x5K3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911086283, "cdate": 1761911086283, "tmdate": 1762921445667, "mdate": 1762921445667, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work evaluates the effect of noise on open-vocabulary object detectors, similar to ImageNet-C and CIFAR-C for classification. The authors analayze numerous detectors across many axes. Interesting findings include robustness being correlated to backbone, and that robustness is more correlated to images than corresponding annotations; while pre-traiining  and captions matter little. They propose a solution, training spatial tokens, on corrupted inputs to improve robustness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The analysis is thorough and interesting. I reallt enjoyed reading all of Section 4, and I found the key findings, such as sensitivity to backbone, to be very interesting. \n* The presentation is mostly very good. \n* There was a need for a such a study in the literature; object detectors are related to yet different from classifiers, and so one might see different behaviour."}, "weaknesses": {"value": "* Although the paper is mostly well written, Section 5 became difficult to parse. For example in line 450 \"an existing approach for low-resolution clas- sification (preserves zero-shot)\"; what does preserves zero-shot mean here?\n* It seems like the solution in Section 5 trains on corrputions. This seems to be  training on the test domain, in which case this ceases to properly test generalization. \n* Some findings are not suprising; like larger objects being more robust. It's more difficult to corrupt the structure!"}, "questions": {"value": "* When visual backbones are shared, couldn't they have the same visual pre-training? So maybe it's not suprrising that they would be correlated in robustness.\n* Will a benchmark be released?\n* For classifiers there is a concept of expected calbiration error for measuring decreased confidence in ood examples. Is there a similar metric that could be shown here? It seems like this could be an good measure of 'graceful degradation'."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HqQyZKB0TN", "forum": "REZ5cM8mFn", "replyto": "REZ5cM8mFn", "signatures": ["ICLR.cc/2026/Conference/Submission10045/Reviewer_oUsL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10045/Reviewer_oUsL"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10045/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761958023034, "cdate": 1761958023034, "tmdate": 1762921445156, "mdate": 1762921445156, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}