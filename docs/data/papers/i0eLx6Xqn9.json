{"id": "i0eLx6Xqn9", "number": 15848, "cdate": 1758256061819, "mdate": 1759897277872, "content": {"title": "Not All Imbalance Is Random: Cluster-Balanced Ensembling for Missing-Not-At-Random Class Imbalance", "abstract": "Class imbalance methods inherently assume that observed minority instances are representative of their class and Missing At Random (MAR). However, in many real-world settings, minority instances are Missing Not At Random (MNAR), with observability shaped by both class and feature values. This leads to structurally biased samples, introducing a deeper challenge that goes beyond class-count imbalance. We show that when MNAR affects high-impact features, popular imbalance methods overfit the observed minority and fail to generalize. To address this, we propose a simple yet effective cluster-balanced ensemble approach that constructs diverse, near-balanced training sets by pairing all minority instances with different clusters of the majority class. Extensive experiments identify MNAR conditions under which our approach improves F1 scores over existing methods, and when it does not. We also introduce an evaluation protocol using representative balanced test sets, demonstrating that standard hold-out testing on MNAR data can mislead performance assessments. Our findings underscore that the cause of imbalance is as critical as the correction method.", "tldr": "This paper shows that the nature of class imbalance is as critical as the correction method, and introduces a cluser-balanced ensembling approach to address Missing-Not-At-Random imbalance.", "keywords": ["Class Imbalance", "Missing-Not-At-Random", "Ensemble Methods", "Cluster-Based Undersampling"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3bbfa59951250913de1d3ddd5d13e7364c7b1574.pdf", "supplementary_material": "/attachment/960ef6ff4fd4db7e848646ba6a2ae4dfdd627f91.zip"}, "replies": [{"content": {"summary": {"value": "In this paper, the authors study the problem of class imbalance. To be specific, the authors argue that the test distribution is often imbalanced not in a random way: Data is missing-not-at-random (MNAR), which is not taken into account in the class imbalance literature so far. The authors provide an analysis and introduce a method borrowed from the MNAR literature. The introduced ensembling based method provides strong results on two tabular benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "+ MNAR appears to be an important issue overlooked in the class imbalance literature.\n+ The provided analysis is helpful.\n+ The introduced method borrowed from the MNAR literature appears to be effective."}, "weaknesses": {"value": "Weaknesses:\n\n1. The paper makes many claims without providing justifying references. The whole Introduction section is written without any references at all. \n\n2. They generate MAR and MNAR from a balanced dataset. Although this is understandable for an analysis, it is not clear what the scale of the problem is for naturally-collected long-tailed datasets. Therefore, it is not clear whether this is a real concern in natural datasets. I strongly suggest the authors to perform experiment with LT datasets such as ImageNet-LT, Places-LT, iNaturalist.\n\n2.1. The authors argue that \"sampling test sets from imbalanced dataset that are potentially MNAR, can bias true model performance.\" => This potential should not prevent one from performing experiments with such datasets. \n\n3. The figures in the paper have major issues.\n\n3.1. Figure 1 is not referred to in the text. As the figure doesn't explain how the samples are generated or what kind of dataset these are, the figure fails to support the paper.\n\n3.2. Fig 2: Text too small to read.\n\n3.3. Figure 3 is very critical for the main motivations of the paper. However, (i) many variables (measures, SHAP values, feature values) are drawn in a complex manner without sufficient guidance in the figure or the caption, and (ii) the figure is not sufficiently explained in the text. \n\n4. I find the experimental evaluation weak.\n\n4.1. For starters, the datasets are not used in the imbalance literature and therefore, the experimental evaluation fails to be convincing. Even for a balanced starting dataset, the paper could have preferred datasets commonly used: E.g., CIFAR10 and CIFAR100, which are converted into their balanced settings in a controlled manner. \n\n4.2. \"These metrics were aggregated across datasets (to enable a data-set agnostic analysis) to predict which features induce MNAR that leads to poor performance by existing methods and benefit most by cluster-balanced ensembling.\" => Is the impact of the missingness of a feature not dataset-dependent? Aggregation over datasets makes it difficult to perform a problem-dependent deductions.\n\n\n\nMinor comments:\n\n- \"follows well-known hybrid methods of undersampling the majority class\" => Please cite.\n- \"euclidean distance\" => \"Euclidean distance\".\n- \"This is to capture local structure defined by original regions of the feature space, rather than the normalized subspace that may compress important structure. In particular, normalizing before clustering often results in less diverse majority subgroups.\" => It would be nice to visualize this.\n- \"sever MNA\" => \"severe MNA\".\n- \"Implementation and details of each algorithm is given\" => \"Implementation and details of each algorithm are given\"."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qRn1j1kmHw", "forum": "i0eLx6Xqn9", "replyto": "i0eLx6Xqn9", "signatures": ["ICLR.cc/2026/Conference/Submission15848/Reviewer_jUqk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15848/Reviewer_jUqk"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15848/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761476267030, "cdate": 1761476267030, "tmdate": 1762926071175, "mdate": 1762926071175, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the overlooked Missing Not At Random (MNAR) class imbalance, where minority samples’ observability depends on both class and features—unlike traditional methods’ assumption of Missing At Random (MAR), which causes overfitting to biased observed minorities and misleading evaluations (testing on MNAR-damaged data). The Cluster-Balanced Ensemble (CBE) method proposed by the authors significantly improves multiple metrics when samples are MNAR by clustering majority class samples and then combining each cluster with minority class samples separately to train multiple classifiers. This paper identifies MNAR’s limitations on traditional methods; introduces CBE to mitigate MNAR bias; characterizes critical MNAR-triggering features; and provides a protocol to avoid evaluation distortion."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper novelly introduces class imbalance in the form of MNAR, and the proposed method achieves better performance than traditional methods focused on MAR.\n2. The experiments compare multiple metrics, test various types of classifiers, and expose biased MNAR evaluation.\n3. The paper is well organized and motivated, making it easy to follow."}, "weaknesses": {"value": "1. Gold-standard protocol relies on rare originally balanced datasets, and crucially, no comparisons are done on imbalanced test sets (e.g., from KEEL’s imbalanced dataset repository, where balanced test sets do not exist). This leaves uncertainty about whether CBE still outperforms others on real-world imbalanced test beds.\n\n2. CBE only uses K-means for majority clustering. This paper would be better if it showed how CBE can adapt methods like DBSCAN (for irregular clusters) or hierarchical clustering (for nested structures), and how such adaptations affect performance.\n\n3. It uses \"top-5 high-impact features\" for MNAR simulation without justifying the number (3 vs. 5 vs. 7) and ignores feature interactions. This undermines MNAR realism—testing varying feature counts and including interactions is needed.\n\n4. Scalability oversight: No complexity analysis for CBE’s K-means + multi-classifier training is provided. For large datasets, Mini-Batch K-means or distributed training is unmentioned, and scalability benchmarks (e.g., runtime vs. data size) are missing.\n\n5. **Potentially Biased MNAR simulation**: MNAR is simulated using mechanisms that maximize CBE’s advantages (e.g., features where other methods struggle most). MNAR construction targets (via XGBoost) the weaknesses of traditional methods (overreliance on observed minority structure) while exploiting CBE’s strengths (majority cluster-based structural coverage). This creates a scenario in which CBE’s advantages are artificially amplified, rather than a fair test of its robustness across diverse MNAR mechanisms. Simulating diverse MNAR mechanisms would better validate CBE’s robustness.\n\n6. On balanced test sets (where overall accuracy is more relevant), the paper overemphasizes F1. It lacks F1 comparisons on imbalanced test sets, where F1 is more appropriate, leaving gaps in understanding CBE’s performance in target real scenarios.\n\n7. This method (CBE) is limited to imbalanced binary tabular data, which narrows its practical scope. Specifically, CBE cannot be extended to non-tabular data (e.g., images) nor to multi-classification tasks such as long-tailed learning.\n\n8. Lack of theoretical analysis on how MNAR harms more than MAR and how CBE improves it."}, "questions": {"value": "Same to weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "iJh0liFL2H", "forum": "i0eLx6Xqn9", "replyto": "i0eLx6Xqn9", "signatures": ["ICLR.cc/2026/Conference/Submission15848/Reviewer_7YCq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15848/Reviewer_7YCq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15848/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761665242731, "cdate": 1761665242731, "tmdate": 1762926070350, "mdate": 1762926070350, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies Missing-Not-at-Random (MNAR) class imbalance and proposes a cluster-balanced ensembling (CBE) scheme: k-means partitions the majority into ≈|majority|/|minority| clusters; each cluster is paired with all minority points to train base learners; predictions are PR-AUC–weighted. Using small, near-balanced tabular datasets (PMLB + one finance dataset), MNAR is simulated by deleting minority instances by feature value; evaluation is done on the original balanced test folds. CBE reports higher F1 than many baselines (SMOTE, ADASYN, Tomek, EasyEnsemble, etc.). While the MNAR emphasis and simple CBE are interesting, the heavy reliance on outdated baselines, limited novelty over prior cluster-ensemble ideas, and narrow evaluation setting put this below ICLR’s threshold for novelty and soundness in its current form."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "+ The gold-standard evaluation idea (train on damaged MNAR data, test on the original balanced folds) is thoughtfully motivated and reveals pitfalls of conventional hold-out on biased test sets.\n+ CBE is simple, reproducible, and competitively strong on the authors’ tabular MNAR simulations; tables/figures show consistent F1 gains over several baselines and classifiers.\n+ The paper probes feature conditions that exacerbate MNAR (via SHAP over meta-features), which I find informative."}, "weaknesses": {"value": "+ Baseline set is heavily outdated relative to ICLR expectations. Most “state-of-the-art” comparisons are classic reweighting, SMOTE variants, Tomek Links, Cluster Centroids, Easy Ensemble, and basic cost-sensitive losses—largely pre-deep-long-tail era and often with default imbalanced-learn/sklearn settings. There is no comparison to modern methods: margin-aware re-balancing (e.g., logit-adjustment with tuned τ), distributionally robust optimization, meta-reweighting, deferred reweighting, AUCPR-direct objectives, calibrated thresholding with risk control, or recent long-tail generalization techniques. This makes the claimed “consistent state-of-the-art” gains hard to accept for ICLR.\n+ Method novelty is limited. CBE is essentially clustering-guided undersampling + ensembling. Similar ideas (e.g., EKR; clustering-centroid undersampling; balanced bagging) exist, with the main tweak here being that k is set by the imbalance ratio and all minority points are reused. The conceptual leap beyond known cluster-based ensembles is modest.\n+ All evidence is on small tabular datasets with binary labels and simulated MNAR; there are no results on image/text/representation-learning regimes where feature geometry is non-Euclidean and k-means on raw features is questionable. The approach also fixes Euclidean k-means “on original unscaled features,” which can be brittle and scale-dependent.\n+ he base classifiers are LR/SVM/RF/MLP/XGBoost with minimal tuning; no modern tabular SOTA (e.g., strong GBDT variants with tuned class weighting, TabTransformer, FT-Transformer) or representation learning is attempted. Reported superiority over such a baseline pool does not clear ICLR’s bar.\n+ The paper centers F1; while PR-AUC appears in plots and for voting, there is no calibration or operating-point analysis under MNAR (sensitivity@specificity per subgroup), which is central to the motivation. F1 also has been criticized for usage in imbalanced datasets."}, "questions": {"value": "+ Can you include modern baselines (e.g., DRO, meta-reweighting, AUCPR-direct losses, recent long-tail re-balancing with tuned priors/margins) and strong tabular SOTA (well-tuned LightGBM/CatBoost with class weights) to substantiate the “SOTA” claim? \n+ How sensitive is CBE to feature scaling and the choice of distance/representation for clustering? Have you tried clustering in a learned metric space (e.g., supervised embedding) rather than raw Euclidean space “on the original unscaled dataset”? \n+ Could you report calibration and thresholded metrics under MNAR (e.g., precision/recall at fixed costs) and include cost-weighted utilities to justify F1-centric conclusions?\n+ Beyond simulated MNAR, can you provide semi-synthetic or cross-site evaluations, or at least stress tests where train/test MNAR mechanisms differ, to probe robustness of CBE?\n+ What happens when k deviates from the imbalance ratio or when minority is extremely small (e.g., 100+:1)? Please include compute/time and memory costs vs. stronger baselines."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "pyH1I9jBCX", "forum": "i0eLx6Xqn9", "replyto": "i0eLx6Xqn9", "signatures": ["ICLR.cc/2026/Conference/Submission15848/Reviewer_pnHJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15848/Reviewer_pnHJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15848/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761773649296, "cdate": 1761773649296, "tmdate": 1762926069181, "mdate": 1762926069181, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates data imbalance under the Missing Not At Random (MNAR) setting. The authors observe that commonly used imbalance-handling methods may fail when MNAR affects high-impact features. To address this issue, they propose a cluster-balanced ensemble approach that constructs diverse, near-balanced training sets by pairing each minority instance with different clusters of the majority class. The effectiveness of the proposed method is demonstrated through extensive experiments."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Methods that effectively handle data imbalance are important in practice.\n2. The proposed approach is intuitive and easy to implement.\n3. The method demonstrates improved performance in the experimental results."}, "weaknesses": {"value": "1. The paper is not well written. The description of the methods is mostly textual and lacks a clear, organized structure. In addition, the discussion of the underlying intuition, advantages and limitations, and potential extensions of the proposed approach is quite limited.\n2. The paper does not include any theoretical analysis or discussion to support the proposed method.\n3. The novelty of the proposed approach is unclear."}, "questions": {"value": "1. Is there any theoretical justification or analysis supporting the proposed method?\n2. The number of clusters k is set as round($\\frac{n^-}{n^+}$). Is this choice always optimal, or how sensitive is the performance to this parameter?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yWgg7TzqdI", "forum": "i0eLx6Xqn9", "replyto": "i0eLx6Xqn9", "signatures": ["ICLR.cc/2026/Conference/Submission15848/Reviewer_SaQc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15848/Reviewer_SaQc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15848/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761794308682, "cdate": 1761794308682, "tmdate": 1762926068815, "mdate": 1762926068815, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}