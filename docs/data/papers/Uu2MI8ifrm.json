{"id": "Uu2MI8ifrm", "number": 13055, "cdate": 1758213141536, "mdate": 1759897468567, "content": {"title": "Adversarial Robustness of Continuous Time Dynamic Graphs", "abstract": "Real-world relations are dynamic and often modeled as temporal graphs, making Temporal Graph Neural Networks (TGNNs) crucial for applications like fraud detection, cybersecurity, and social network analysis. However, our study reveals critical vulnerabilities in these models through three types of adversarial attacks: structural, contextual, and temporal perturbations. We introduce Temporally-aware Randomized Block Coordinate Descent (TR-BCD), a novel gradient-based evasion attack framework for continuous-time dynamic graphs. Unlike previous approaches that rely on heuristics or require training data access, TR-BCD optimizes adversarial edge selection through continuous relaxation while maintaining realistic temporal patterns. Through extensive experiments on six temporal networks, we demonstrate that TGNNs are highly vulnerable to TR-BCD attacks, reducing Mean Reciprocal Rank (MRR) by up to 53% while perturbing only 5% of edges. Our attacks are highly effective against state-of-the-art models, including TGN and TNCN, highlighting the importance of studying adversarial robustness for temporal graph learning methods.", "tldr": "We introduce Temporally-aware Randomized Block Coordinate Descent (TR-BCD), a novel gradient-based evasion attack framework for continuous-time dynamic graphs to test TGNN vulnerabilities.", "keywords": ["Adversarial Attacks", "Temporal Graph Learning", "Graph Neural Network"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5f3ec82d2a8b2c4fb88693b8c8148e5bc03b698e.pdf", "supplementary_material": "/attachment/6e72d8198847be447b885719fb81bcedd4bc30fc.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates the adversarial robustness of Temporal Graph Neural Networks (TGNNs) in the continuous-time dynamic graph (CTDG) setting. The authors introduce TR-BCD (Temporally-aware Randomized Block Coordinate Descent), a novel gradient-based evasion attack that perturbs structural, contextual, and temporal dimensions of a temporal graph during inference without modifying training data. TR-BCD greedily injects adversarial edges over time using randomized block coordinate descent to keep the optimization scalable. Experiments on six real-world temporal graph benchmarks demonstrate that the proposed attack can reduce Mean Reciprocal Rank (MRR) by up to 53% while perturbing only 5% of edges. The paper further analyzes the attack’s stealthiness using anomaly detection (SPOTLIGHT) and finds TR-BCD to be both effective and evasive."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n* Novel and timely topic: This is one of the first works systematically studying adversarial evasion attacks on continuous-time dynamic graphs, a problem of growing relevance for fraud detection, cybersecurity, and temporal recommendation systems.\n* Methodological soundness: The TR-BCD algorithm is clearly formulated, combining continuous relaxation, randomized block coordinate descent, and temporal consistency constraints.\n* Strong empirical results: Extensive experiments on six datasets and two state-of-the-art TGNNs (TGN, TNCN) convincingly demonstrate the vulnerability of temporal graph models.\n* Practical considerations: The discussion on memory efficiency, time complexity, and unnoticeability constraints makes the work well-grounded.\n* Evasion realism: The use of anomaly detection evaluation adds credibility by showing that TR-BCD attacks can remain stealthy."}, "weaknesses": {"value": "Weaknesses:\n\n* Limited defense discussion: The paper focuses entirely on the attack side; exploring or even briefly analyzing potential defenses (e.g., adversarial training, temporal regularization) would make the study more complete.\n\n* Comparative baselines: Although MemStranding and heuristic attacks are included, more recent or stronger gradient-based baselines (e.g., temporal variants of PGD or PR-BCD) could strengthen the evaluation.\n\n* Sensitivity analysis: The paper could analyze how performance varies with hyperparameters like block size, time perturbation variance, or contextual budget."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "UiTB5nPZwd", "forum": "Uu2MI8ifrm", "replyto": "Uu2MI8ifrm", "signatures": ["ICLR.cc/2026/Conference/Submission13055/Reviewer_kzqx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13055/Reviewer_kzqx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13055/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791497115, "cdate": 1761791497115, "tmdate": 1762923786793, "mdate": 1762923786793, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work presents Temporally-aware Randomized Block Coordinate Descent (TR-BCD), a novel gradient-based evasion attack tailored for continuous-time dynamic graphs. TR-BCD formulates adversarial edge selection via a continuous relaxation and optimizes it with temporally aware block coordinate updates that preserve realistic timing patterns. Experiments show that TR-BCD substantially degrades the performance of temporal graph neural networks (TGNNs), demonstrating its effectiveness as a targeted evasion strategy on dynamic graphs."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper discusses real-world scenarios where continuous-time dynamic graphs commonly occur, underscoring the practical relevance and significance of the proposed framework.\n\n2. It focuses on adversarial attacks against Temporal Graph Neural Networks (TGNNs), aiming to assess and enhance their robustness for real-world applications.\n\n3. The proposed TR-BCD framework optimizes adversarial edge selection through continuous relaxation and directly optimizes the adversarial objective during inference."}, "weaknesses": {"value": "1. The proposed method relies on a relatively standard Randomized Block Coordinate Descent framework without introducing a sufficiently innovative or compelling design.\n2. The paper lacks a comprehensive discussion of the method’s limitations, particularly regarding performance variations across different TGNN architectures and graph data characteristics."}, "questions": {"value": "1. The authors do not provide a comprehensive comparison of TR-BCD with other existing adversarial attacks on TGNNs. It is recommended to include comparisons with more recent baseline methods. \n\n2. The experimental evaluation is limited to small datasets. The authors should consider testing TR-BCD on larger-scale datasets to demonstrate its generalizability and effectiveness in real-world applications.\n\n3. The study evaluates TR-BCD using only a limited set of TGNN models. Recent advances have introduced more powerful TGNNs, such as ROLAND [1]; including these models in the evaluation would strengthen the paper.\n\n4. The experiments only assess TR-BCD against raw TGNNs without incorporating existing GNN defense mechanisms. It would be valuable to test TR-BCD against TGNNs equipped with defense strategies to evaluate its robustness under defended settings.\n\n5. How do the authors ensure the unnoticeability of perturbations in continuous-time dynamic graphs (CTDGs), given that up to 5% of edges are added? Please clarify how such perturbations remain realistic and imperceptible.\n\n6. Please report the runtime or computational cost of TR-BCD to better understand its efficiency compared to other attack methods.\n\n7. The results show that TR-BCD causes more than 50% performance degradation on some datasets but less than 10% on some datasets. Could the authors explain the factors contributing to this large performance variation?\n\n8. In the TGNNs victim model, combining all types of perturbations leads to lower attack effectiveness than using only structural perturbations (see Table 5 in the Appendix). This suggests that integrating temporal and contextual perturbations may reduce TR-BCD’s performance. Could the authors elaborate on the reason for this behavior?\n\n9. Table 6 indicates that edge deletion has a stronger impact than edge addition, which contrasts with typical adversarial attack findings where edge addition tends to be more influential. Could the authors explain why TR-BCD exhibits this reverse effect?\n\n\n[1] You, Jiaxuan, Tianyu Du, and Jure Leskovec. \"ROLAND: graph learning framework for dynamic graphs.\" Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2022."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "d5fhuMn7n7", "forum": "Uu2MI8ifrm", "replyto": "Uu2MI8ifrm", "signatures": ["ICLR.cc/2026/Conference/Submission13055/Reviewer_VZ6t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13055/Reviewer_VZ6t"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13055/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761875530394, "cdate": 1761875530394, "tmdate": 1762923786507, "mdate": 1762923786507, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the adversarial robustness of Temporal Graph Neural Networks (TGNNs) on Continuous-Time Dynamic Graphs (CTDGs). The authors propose Temporally-aware Randomized Block Coordinate Descent (TR-BCD), an evasion (test-time) attack that optimizes adversarial edge insertions through gradient-based continuous relaxation. Additionally, TR-BCD introduces temporal consistency by modeling timestamps with Gaussian noise, enabling it to craft realistic, temporally coherent perturbations. The attack considers three perturbation types—structural, contextual, and temporal—and is evaluated across six datasets (Wikipedia, Reddit, MOOC, Enron, etc.) and two TGNNs (TGN, TNCN). Results show that TR-BCD significantly reduces performance (up to 53% MRR drop with 5% perturbation budget), outperforming heuristic baselines and prior TGNN-specific attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper has the following strengths:\n- Robustness of TGNNs under adversarial conditions remains a pressing and underexplored area.\n- The attack’s optimization objective, constraints, and procedures are clearly presented.\n- Evaluations span multiple datasets and perturbation types (structural, contextual, temporal), and provide decent experimental support."}, "weaknesses": {"value": "The paper has the following weaknesses:\n- The attack model is not explicitly stated, making it difficult to gauge the attack’s practicality or compare it with prior white-box or black-box works.\n- Only two TGNNs (TGN and TNCN) are evaluated. Broader coverage would better support the general claims of effectiveness.\n- The paper compares the proposed method with limited state-of-the-art GNN attacks.\n- The method is an adaptation of existing coordinate-descent GNN attacks, with the primary novelty being timestamp regularization. While meaningful, it sounds incremental."}, "questions": {"value": "This paper investigates the adversarial robustness of Temporal Graph Neural Networks (TGNNs) in continuous-time dynamic graphs (CTDGs). The authors propose Temporally-aware Randomized Block Coordinate Descent (TR-BCD), an evasion attack that extends gradient-based GNN perturbations to the temporal domain. TR-BCD jointly optimizes structural, contextual, and temporal perturbations while maintaining time consistency via Gaussian timestamp modeling. Experiments on six datasets (Wikipedia, Reddit, MOOC, Enron, etc.) and two TGNN architectures (TGN, TNCN) demonstrate significant performance degradation compared to prior TGNN attacks.\n\nHowever, a few questions may help clarify the generalizability and novelty of the proposed approach:\n\n1. Could you explicitly describe the attacker’s knowledge assumptions? For example, does TR-BCD assume access to model parameters, gradients, or node embeddings (i.e., a white-box setting), or does it operate under a limited or black-box setting? If the attack assumes a white-box setup, could you discuss how it might transfer or adapt to a more restricted setting (e.g., black-box or limited-feedback environments)\n\n2. The evaluation includes TGN and TNCN, which share similar memory-update structures. Have you considered testing TR-BCD on other representative TGNNs, such as DyRep, JODIE, or ROLAND, as discussed in prior work [1]?\n\n3. Many of these static graph attacks, such as TDGIA[2], could be temporally adapted with minor modifications. Have you attempted such adaptations, or can you discuss why they may not be directly applicable to the CTDG setting?\n\n4. Beyond introducing timestamp regularization, how does TR-BCD fundamentally differ from prior coordinate-descent-based GNN attacks? In what way does temporal smoothness change the optimization landscape or attack transferability compared to static or snapshot-based graph settings?\n\n5. The paper demonstrates strong attack performance in standard settings, but it is unclear how TR-BCD behaves when common defenses are applied. Could the authors discuss whether they evaluated TR-BCD under known GNN or TGNN defense strategies? If not, do they expect the attack to remain effective, or would temporal regularization make it more vulnerable to such countermeasures?\n\n[1] Dai, Yue, et al. \"MemFreezing: A Novel Adversarial Attack on Temporal Graph Neural Networks under Limited Future Knowledge.\" Forty-second International Conference on Machine Learning.\n\n[2] Zou, Xu, et al. \"Tdgia: Effective injection attacks on graph neural networks.\" Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 2021."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "t6VyINTNfR", "forum": "Uu2MI8ifrm", "replyto": "Uu2MI8ifrm", "signatures": ["ICLR.cc/2026/Conference/Submission13055/Reviewer_vwMw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13055/Reviewer_vwMw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13055/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962451949, "cdate": 1761962451949, "tmdate": 1762923786256, "mdate": 1762923786256, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper propose a Randomized Block Coordinate Descent method to attack white-box TGNNs. The attacker applies gradient decent based method to increase the target model loss and pick components with higher gradients greedily. To reduce the memory cost of such optimization on whole edges, the method is further adapted by choosing a small randomized fraction of edges as candidates to cut down the range. To better obtain the candidates the author further greedily incorporate historical negative edges. Experiments across several datasets and victim models validates the performance of the method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**S1.** The paper study the vulnerabilities of TGNN models against adversarial attack, which is a not well explored topic but has many potential impact since TGNN relates to many practical applications.\n\n**S2.** Abundant experiments are done to show the effectiveness and practicability. The method is not only evaluated decreased performance of the method compared with several baselines, but also show deceiving ability on mitigating anomaly detection method and ablation study on different components and different budget. There is also code provided to support its reliability. \n\n**S3.** The randomized entry samples cut down the memory complexity , which makes the method more friendly to device requirement."}, "weaknesses": {"value": "**W1.** The practicability of the proposed method is doubtful. The proposed attack is a gradient based attack with knowledge of both the white-box victim model and all historical temporary graphs, both of which seems not accessible in real world application. \n\n**W2.** The technique contribution is somewhat limited. The proposed Randomized Block Coordinate Descent is also a simple adaptation of typical gradient descent optimization over edges with so called randomized samples, mainly relying on a greedy idea of highly picking historical negative edges. There's no deduction nor theoretical guarantees on the proposed method with only considerable optimization efficiency due to the small size of random sampled edge candidates.  \n\n**W3.** The presentation of the paper should be improved.\n\n3.1. The methodology of the  proposed method are fully expressed in textual description throughout section 4 without formulations for illustrate. Considering there's actually large space remaining in the paper, simply copying expression from the algorithm flow would solve. \n\n3.2. The memory mechanism is lacked of illustration. There is a introduced mechanism of model memory that help the TGN to encode temporal graph. Since this is a mechanism that not held widely by general GNN or other ML models, its definition and formally illustration at problem statement is needed since it tightly relates to the designed algorithm. An only reference in the related works would make the reader ignore and feel confused when encountering it in latter section 4.\n\n3.3. In the technique design a lot of mechanisms are proposed to tackle the memory problem of the attack process, while this is not clearly stated in motivation and contribution aspect in introduction session. Such technique challenge and solution should be briefly mentioned in the section 1 so reader could expect content related."}, "questions": {"value": "Please see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Myr6lRYiFG", "forum": "Uu2MI8ifrm", "replyto": "Uu2MI8ifrm", "signatures": ["ICLR.cc/2026/Conference/Submission13055/Reviewer_SWaR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13055/Reviewer_SWaR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13055/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762000979271, "cdate": 1762000979271, "tmdate": 1762923785942, "mdate": 1762923785942, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}