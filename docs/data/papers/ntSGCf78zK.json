{"id": "ntSGCf78zK", "number": 9002, "cdate": 1758106755092, "mdate": 1759897748762, "content": {"title": "COOL: Chain-Oriented Objective Logic with Neural Networks Feedback Control for Multi-DSL Regulation", "abstract": "Multi-DSL regulation requires dynamic coordination of modular domain logic, yet existing frameworks lack mechanisms for cross-DSL state management. We address these challenges with \\textbf{COOL (Chain-Oriented Objective Logic)}, a neural-symbolic framework that introduces: (1) \\textbf{Chain-of-Logic (CoL)}: Structures the reasoning process into hierarchical, expert-guided multiple sub-DSLs with heuristic vectors and runtime keywords; and (2)~\\textbf{Neural Network Feedback Control (NNFC)}: A self-correcting mechanism that isolates neural components into reusable libraries, filtering erroneous predictions via sequential network coupling. Through rigorous theoretical analysis, we formally establish the efficacy of CoL and NNFC components. Ablation studies on relational and symbolic tasks validate that: CoL achieves \\textbf{70\\% higher accuracy} than non-CoL DSLs while reducing computational overhead by \\textbf{91\\% fewer tree operations} and \\textbf{95\\% faster reasoning}. Under adversarial conditions—insufficient training data, increased complexity, and multi-library requirements—NNFC further improves accuracy by \\textbf{6\\%} and reduces tree operations by \\textbf{64\\%} compared to the CoL-only variant. Both theoretical analysis and experimental validation confirm COOL as a highly efficient and reliable framework for multi-DSL regulation.", "tldr": "A groundbreaking multi-DSL regulation framework combining control theory and neural networks, with theoretical and experimental proofs.", "keywords": ["Chain-of-Logic", "Neural Network Feedback Control", "Multi-DSL Regulation"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4185a890520f6609c6b3df6215f01a0d4a5e7fca.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies 'multi-domain-specific languages regulation' using a new neurosymbolic method."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- I am not aware of earlier research in this topic\n- Ablation studies show clear improvements"}, "weaknesses": {"value": "- The problem of Multi-DSL regulation is not introduced, and the writing is very hard to follow: Method description is high level and not reproducible.\n- Theoretical claims are unclear and do not come with obvious assumptions. Proofs are often very informal\n- The paper does not use baselines\n- No code is available"}, "questions": {"value": "- Except for the appendix, this paper does not cite any other literature. The problem and approach is therefore not grounded in existing work. \n    - For example, how could this paper be tackled using much simpler methods, eg involving LLMs?\n    - The citations in the appendix are also suspicious. Eg, [1] is used as a reference for GNNs, but [1] does not use GNNs at all, and, I quote, \"Sagar Imambi, Kolla Bhanu Prakash, and GR Kanagachidambaresan. Pytorch. Programming with TensorFlow: solution for edge computing applications, pp. 87–104, 2021\" is used as a reference for Pytorch (?). The most similar hit on Google for that reference is a book about Tensorflow.\n- The problem ('regulation of multiple modular DSLs') is not introduced and is not clear to me. \n- Table 2: What does \"Group DSL\" mean? Is that a baseline? \n- The abstract ends with \"(need revision)\", and there are many invalid references\n- The figures are very hard to parse and do not provide useful insight into the method\n- Line 054 claims that 'neural adaptive control (...) is confined to continuous states spaces (...) [and] inapplicable to the discrete symbolic reasoning required'. Neural control can certainly be used for discrete state spaces, in fact this is very common. This claim also comes without support. \n\n\nFurthermore, I don't like saying this, and I hope I'm wrong, but the writing sounds very LLMy to me. No LLM usage is declared in the paper (which is a requirement by ICLR standards).\n\n[1] Drori, Iddo, et al. \"A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level.\" Proceedings of the National Academy of Sciences 119.32 (2022): e2123433119."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Wh7j7p9pDI", "forum": "ntSGCf78zK", "replyto": "ntSGCf78zK", "signatures": ["ICLR.cc/2026/Conference/Submission9002/Reviewer_JQLx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9002/Reviewer_JQLx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9002/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761038006479, "cdate": 1761038006479, "tmdate": 1762920728976, "mdate": 1762920728976, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes COOL, a neural-symbolic framework to coordinate reasoning across multiple Domain Specific Languages (DSLs). The framework involves two components: \n1. Chain-of-Logic (CoL): a symbolic control mechanism that introduces heuristic vectors and runtime keywords (return, logicjump(n), abort) to manage rule application and cross-DSL transitions.\n2. Neural Network Feedback Control (NNFC) – a neural module that employs small neural agents to monitor symbolic derivations, filter errors, and adjust heuristic parameters adaptively.\n\nThe authors provide theoretical analyses claiming CoL retains expressiveness of the most powerful DSL, proves complexity reductions, and uses a Lyapunov-based argument to claim stability for NNFC.\n\nExperiments are conducted on synthetic “relational” and “symbolic” benchmarks collected by the paper, showing large performance gains (up to 100% accuracy, 95% faster reasoning, 91% fewer tree operations)."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The paper contains many technical details, proofs, and analysis. While I cannot fully understand the work, I acknowledge the effort from the authors. \n- The accuracy improvement of the proposed COOL seems to be significant."}, "weaknesses": {"value": "1. **Lack of clarity:** The paper is very difficult to follow. The writing is also hard to understand, and many explanations are very high-level and read like LLM-generated. The explanations on each proposed components are also very high level and lack of implementation details. Here are some questions:\n    - How are heuristic vectors constructed? \n    - How are the CoL keywords determined?\n    - Regarding the neural components, how do you handle non-differentiable operations? Or do you somehow gather ground-truths for each intermediate steps (so you do not back propagate gradients through symbolic/non-differentiable ops)? How large is the training set? How well does it generalize to OOD tasks?\n    - The paper uses \"agents\" a lot. Is it just referring to the NN as in Figure 6? Or does it have anything to do with LLM-based agents?\n2. **Poor grounding in existing literature:** The paper is poorly grounded in existing literature. There is no existing works, and no comparison of the proposed approach with existing works. There are a few references in the bibliography, but they are not really cited or referred in the text. \n3. **Empirical validity:** \n   - Benchmarks are not compared with any existing works.\n   - Results show 100% accuracy and 95% speed-ups. I somewhat doubt about the validity of the test data and baseline.\n\nOverall I find the paper very difficult to comprehend, which affects my judgements. I highly recommend the authors to refer to other published papers in similar domains (e.g. [1]) to rework the paper to be more readable.\n\n[1] Latent execution for neural program synthesis beyond domain-specific languages"}, "questions": {"value": "1. Could the authors provide more details about the related work and better compare the proposed COOL with existing works? \n2. Could the authors provide more implementation details? For instance, how CoL/heuristic vectors are constructed, how keywords are determined, and how are the neural components trained?\n3. Could the authors provide evaluation on benchmarks used in existing literature and compare with existing works? For instance, for math problems you can consider e.g. GSM8K, and for logic reasoning please consider various Knowledge Graph Completion tasks (e.g. FB15k, WN18RR etc.)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "y8JXjd6fYJ", "forum": "ntSGCf78zK", "replyto": "ntSGCf78zK", "signatures": ["ICLR.cc/2026/Conference/Submission9002/Reviewer_7Whn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9002/Reviewer_7Whn"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9002/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761531266018, "cdate": 1761531266018, "tmdate": 1762920728524, "mdate": 1762920728524, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The work contributes to the management of multi domain specific language (DSL) regulation. It introduces 1) Chain of Logic (CoL) and a neural network feedback control (NNFC). Chain of Logic uses heuristic vectors and runtime keywords as syntax to specify what DSL is suitable for that part of a text (or program?). The neural network feedback control introduces \"neural agents\", which may adaptively redefine the scope of what a DSL is responsible for."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "The work claims positive results. (Although the experimental section does not explain exactly what task exactly is being tested on)."}, "weaknesses": {"value": "The presentation is unsuitable for a broader audience. The exact task that is being solved is not explained, neither what task is performed in the experiments. As a consequence, the contribution itself is also not clear. The main paper is not self-contained.\n\nThe main paper contains no references. The few references that are included originate from the appendix. For example, there are no citations to prior work (i.e., line 051 states intersections with several research areas are fundamentally distinct. No citations appear).\n\nThe work is not well motivated, by not having a clear description of the problem and a description of its importance with references to prior work."}, "questions": {"value": "Regarding more specific suggestions:\n\n* Figure 1 is not self contained, and from the text it is unclear what it is showing exactly.\n\n* Line 237 has a broken Appendix reference"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uhycQkP7hd", "forum": "ntSGCf78zK", "replyto": "ntSGCf78zK", "signatures": ["ICLR.cc/2026/Conference/Submission9002/Reviewer_sutB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9002/Reviewer_sutB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9002/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959384180, "cdate": 1761959384180, "tmdate": 1762920728199, "mdate": 1762920728199, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Chain-Oriented Objective Logic (COOL) as a neuro-symbolic framework for Multi-DSL regulation. To achieve this, the authors introduce Chain-of-Logic (CoL) and Neural Network Feedback Control (NNFC) to create a hierarchical reasoning process with self-correcting mechanisms."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Due to the manuscript's lack of clarity and the absence of a discussion on related work, I am unable to confidently identify the strengths of this work."}, "weaknesses": {"value": "- Although the authors claim \"Our approach to multi-DSL regulation, COOL (Chain-Oriented Objective Logic), intersects with several research areas\" (line 50), the paper does not contain a related work section. \n- All 12 references to related work the paper contains are contained in the appendix, i.e., the main text does not contain a single reference as far as I can tell.\n- The paper contains erroneous LaTeX commands (e.g., line 237 \"Apendix ??\") and unfinished text fragments (e.g., \"(need reversion)\" comment in line 28).\n- Neither the text nor the figures enabled me to understand the proposed approach, and rather left me with more questions than answers."}, "questions": {"value": "I have no questions to the authors."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CrbHTI0H50", "forum": "ntSGCf78zK", "replyto": "ntSGCf78zK", "signatures": ["ICLR.cc/2026/Conference/Submission9002/Reviewer_RwiZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9002/Reviewer_RwiZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9002/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993664715, "cdate": 1761993664715, "tmdate": 1762920727703, "mdate": 1762920727703, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}