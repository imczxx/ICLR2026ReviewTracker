{"id": "ixYvy0wOTr", "number": 6996, "cdate": 1758004360601, "mdate": 1762921059228, "content": {"title": "Incremental Learning of Vision-Language Models via Task Subspace Projection and Dynamic LoRA", "abstract": "Recent pre-trained vision-language models usually face a Multi-Domain Task-Incremental Learning (MTIL) benchmark in practice, where a set of classes of multi-modal tasks arrive incrementally. Due to privacy concerns and memory constraints, MTIL with pre-trained models encounters forgetting of knowledge from old tasks, degradation of zero-shot transfer capability, and underfitting of new-task knowledge. To overcome these challenges, previous MTIL methods attempt to learn a discriminative cross-task identification (CTI) module and an effective new-task adaptation (NTA) module. However, current CTI modules suffer from severe task confusion between seen and unseen tasks, and NTA modules cannot adaptively balance the performance and parameter cost while incorporating task-specific knowledge. To alleviate the above dilemmas, we propose an effective and efficient TSP-DLoRA method for MTIL, which consists of Task Subspace Projection (TSP) and Dynamic Low Rank Adapter (DLoRA) modules. Specifically, our TSP module includes a task identifier classifier based on task-specific subspaces and a feature projection strategy that can determine the identifier associated with samples from both seen and unseen tasks. Our DLoRA improves the knowledge adaptation from new tasks by dynamically assigning Low Rank Adapter (LoRA) across transformer layers based on the task distributions. Experimental evaluations across 11 datasets, using three performance metrics, demonstrate the effectiveness of our proposed method.", "tldr": "", "keywords": ["Multimodal learning", "incremental learning", "continual learning", "vision-language model"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/bcd988095af79628d12143d8a09db7bb367b176e.pdf", "supplementary_material": "/attachment/466fb3521ba7238c1a6db08db3a54b8091e46f28.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel and efficient TSP-DLoRA framework for Multi-Domain Task-Incremental Learning (MTIL). It combines a training-free task identification module (TSP) with a dynamic parameter-efficient fine-tuning module (DLoRA), striking a balance between retaining old knowledge, learning new tasks, and maintaining generalization capabilities. It achieves good performance with low parameter costs. The method's effectiveness is validated on a standard MTIL benchmark composed of 11 diverse datasets, offering a significant solution for the continual learning of large vision-language models in resource-constrained environments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The gating mechanism in the DLoRA module allows the model to dynamically and adaptively decide whether to activate the LoRA adapters based on the features of each input sample. This is more flexible and intelligent than previous static fine-tuning methods and performs exceptionally well when dealing with multi-domain tasks that have significant distributional disparities."}, "weaknesses": {"value": "1.\tThe performance of the TSP module is highly dependent on fixed energy and similarity thresholds. These values may not be optimal for all task sequences or data distributions, potentially requiring tedious manual tuning in new application scenarios.\n2.\tThe core assumption of the TSP module is that tasks are separable in the sub feature space. For highly similar tasks with overlapping feature spaces, the TSP may struggle to create clear subspace boundaries, leading to a decrease in task identification accuracy.\n3.\tAlthough the core diagram of the paper (Figure 2) illustrates the overall architecture, the coloring of major modules is unclear. For instance, at the bottom of the training flowchart, the colored feature blocks representing different tasks (e.g., aircraft, food, flowers) lack clear labels or explanations. This makes it difficult for readers to fully understand their specific roles in the 'task subspace' construction process, hindering detailed comprehension and reproducibility."}, "questions": {"value": "see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "H7rqPK9U8n", "forum": "ixYvy0wOTr", "replyto": "ixYvy0wOTr", "signatures": ["ICLR.cc/2026/Conference/Submission6996/Reviewer_v6CH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6996/Reviewer_v6CH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6996/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761636309769, "cdate": 1761636309769, "tmdate": 1762919212675, "mdate": 1762919212675, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "BPdCNlP3v0", "forum": "ixYvy0wOTr", "replyto": "ixYvy0wOTr", "signatures": ["ICLR.cc/2026/Conference/Submission6996/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6996/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762921057814, "cdate": 1762921057814, "tmdate": 1762921057814, "mdate": 1762921057814, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel approach for multi-domain task-incremental learning (MTIL) in vision-language models, termed TSP-DLoRA.\nThe method integrates two main components, Task Subspace Projection (TSP) and Dynamic Low-Rank Adapter (DLoRA). TSA is a training-free discriminative module that identifies task boundaries by projecting sample features into task-specific subspaces. It distinguishes seen versus unseen tasks via cosine similarity and an adaptive threshold, thereby mitigating task confusion and catastrophic forgetting. DLoRA is an adaptive parameter-efficient fine-tuning module that dynamically determines where to apply LoRA based on task complexity, guided by a Gumbel-based gating mechanism.\nExperiments are conducted on 11 datasets from the MTIL benchmark (e.g., CIFAR100, EuroSAT, Flowers, Food, SUN397), showing state-of-the-art performance across “Transfer”, “Average”, and “Last” metrics, while training only 0.86% of parameters. The method also reduces GPU cost and inference time compared with MoE-Adapter and DIKI."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.Achieves SOTA results while training <1% of parameters. It’s a remarkable trade-off between performance and efficiency.\n\n2.The combination of SVD-based task subspace analysis with adaptive LoRA gating is novel and creative.\n\n3.The experiment is complete, which covers 11 datasets, strong baselines, and ablation studies that isolate both modules’ effects."}, "weaknesses": {"value": "1.While the modular ablations are solid, there’s limited discussion of failure cases\n\n2.The paper could better justify why cosine similarity with a fixed threshold generalizes across domains.\n\n3.Would fine-tuning the CLIP backbone further improve unseen-task performance?\n\n4.Have you considered extending TSP-DLoRA to cross-modal task transfer (e.g., from image-text to video-text)?"}, "questions": {"value": "see weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "hNYsKbTOoC", "forum": "ixYvy0wOTr", "replyto": "ixYvy0wOTr", "signatures": ["ICLR.cc/2026/Conference/Submission6996/Reviewer_nNiC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6996/Reviewer_nNiC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6996/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761709320336, "cdate": 1761709320336, "tmdate": 1762919212334, "mdate": 1762919212334, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a Cross-Task Identification (CTI) module that predicts the task/dataset identity of an input image and routes it to a corresponding dataset-specific LoRA (DLoRA) adapter on top of a CLIP-style image encoder. The goal is to improve adaptation to new domains while retaining zero-shot generalization. Experiments are conducted under the MTIL benchmark."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The CTI→DLoRA routing pipeline is a clean, extensible design for multi-domain adaptation.\n\n2. Routing prior to specialized adapters is a reasonable way to reduce negative transfer when tasks are heterogeneous."}, "weaknesses": {"value": "1. **The paper’s CTI-centric design conflicts with the MTIL evaluation protocol**: under MTIL, each dataset is evaluated in isolation using only its own label set, which assumes the test sample’s dataset/task is known a priori. In this setting, a task-identification module adds no value—one can directly route to the corresponding dataset-specific DLoRA.\n\n2. **Limited contribution.** The architecture is nearly isomorphic to MoE-adapter , i.e., a task identifier plus task-specific LoRA. Even Figure 2 appears very similar to MoE-adapter schematics, making the contribution look incremental.\n\n3. **Marginal performance gains.** On MTIL, the reported Transfer (Avg Last) improvements over MOE-ADAPTER are small, calling into question the practical benefit relative to added complexity.\n\n\n4. **Insufficient baselines.** For example:\nConDU: Enhanced Continual Learning of Vision-Language Models with Model Fusion\nRAIL: Advancing Cross-domain Discriminability in Continual Learning of Vision-Language Models\nDuPLe: Mitigating the Evolving Semantic Entanglement in Continual Learning of Vision-Language Models"}, "questions": {"value": "**Transfer > Zero-shot on unseen tasks?**\n\nYou state that for unseen tasks the system falls back to the original CLIP (even assuming a perfectly accurate task identifier offers no specialized adapter). How do you obtain transfer scores higher than zero-shot on some datasets (e.g., 93.5 vs. 88.4 on Caltech101)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "RsqwjigHLm", "forum": "ixYvy0wOTr", "replyto": "ixYvy0wOTr", "signatures": ["ICLR.cc/2026/Conference/Submission6996/Reviewer_5Get"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6996/Reviewer_5Get"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6996/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972780395, "cdate": 1761972780395, "tmdate": 1762919211893, "mdate": 1762919211893, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a Cross-Task Identification (CTI) module that predicts the task or dataset identity of an input image and routes it to a corresponding dataset-specific LoRA (DLoRA) adapter built on top of a CLIP-style image encoder. The goal is to enhance adaptation to new domains while preserving zero-shot generalization capability. Experiments are conducted on the MTIL benchmark to evaluate the effectiveness of the proposed approach."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The CTI→DLoRA routing pipeline presents a clean and extensible design for multi-domain adaptation.\nPerforming routing prior to specialized adapters is a reasonable and effective strategy to mitigate negative transfer across heterogeneous tasks."}, "weaknesses": {"value": "[Major]1-Novelty is incremental: The proposed architecture is largely isomorphic to MoE-Adapter, comprising a task identifier coupled with task-specific LoRA modules. Even Figure 2 closely resembles the schematic of MoE-Adapter, making the overall contribution appear incremental.\n\n[Major]2-Limited performance gains: On MTIL, the reported Transfer (Avg Last) improvements over MoE-Adapter are marginal, raising questions about the practical benefits relative to the added architectural complexity.\n\n[Major]3-Unfair comparison: Miss several methods, for example:\nConDU: ENHANCED CONTINUAL LEARNING OF VISION-LANGUAGE MODELS WITH MODEL FUSION\nRAIL: Advancing Cross-domain Discriminability in Continual Learning of Vision-Language Models\nDuPLe: Mitigating the Evolving Semantic Entanglement in Continual Learning of Vision-Language Models"}, "questions": {"value": "Please see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5IeJWFiomG", "forum": "ixYvy0wOTr", "replyto": "ixYvy0wOTr", "signatures": ["ICLR.cc/2026/Conference/Submission6996/Reviewer_bK4Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6996/Reviewer_bK4Y"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6996/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982297782, "cdate": 1761982297782, "tmdate": 1762919211429, "mdate": 1762919211429, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}