{"id": "DDuF4lpcTl", "number": 10257, "cdate": 1758165215923, "mdate": 1759897662648, "content": {"title": "HarmoMoE: Unifying Domain-Specialized Experts into a Mixture-of-Experts Model under Privacy Constraints", "abstract": "Mixture-of-Experts (MoE) models offer a powerful way to scale capacity, but existing designs typically assume centralized access to all training data. In many real-world scenarios, however, data is distributed across clients from different domains and cannot be shared due to privacy constraints, making it challenging to build a unified and generalizable MoE. We propose HarmoMoE, a framework that unifies domain-specialized experts into a single MoE without sharing private data. HarmoMoE combines relevance-weighted DPP proxy selection with a context-aware router, ensuring that experts trained on both private and proxy data remain compatible and effectively coordinated. Experiments on CV and NLP show that HarmoMoE consistently outperforms recent methods such as BTX and FlexOlmo.", "tldr": "", "keywords": ["Mixture of Experts", "Privacy-Preserving Learning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2ccb3a90f4c5d771c2a361ab86ae32ec36a060e6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a framework for enabling data-distributed training without sacrificing data owners’ privacy. Their approach is to train diverse experts using local data for each client, and then construct proxy samples for fine-tuning private models and router learning. The method has shown superior performance over SOTA baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This paper provides a novel method to merge domain-specific experts into a versatile expert, with a special focus on data privacy. The method is promising. \n\n- The authors introduce several key elements, compared to the existing baselines: DPP proxy data sampling, context-aware router, and proxy-aligned expert training. Each component is ablated rigorously and is proven empirically to have contributed to the performance improvement."}, "weaknesses": {"value": "- An immediate dropback is that what if there are no similar data to $D_p$ in the public dataset to construct $\\hat{D}_p$? Does the procedure still work?\n\n- There is no documentation of the computational cost in addition to BTM. Is the enhanced performance coming at a greater cost?"}, "questions": {"value": "- In Table 3, it seems the domain-specific experts are not performing the best in the corresponding domains?\n\n- There are several other works with similar purposes. How does your method compare to [1][2]?\n\n- To get a complete understanding of the method, could you please replicate the experiment from Section 4.4 on the vision tasks and the experiment from Section 4.5 on the NLP tasks?\n\n\n[1] On-Device Collaborative Language Modeling via a Mixture of Generalists and Specialists\n\n[2] Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "WDCvYez4n6", "forum": "DDuF4lpcTl", "replyto": "DDuF4lpcTl", "signatures": ["ICLR.cc/2026/Conference/Submission10257/Reviewer_VQAo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10257/Reviewer_VQAo"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10257/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761768400144, "cdate": 1761768400144, "tmdate": 1762921613151, "mdate": 1762921613151, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript proposes HarmoMoE, a framework designed to unify expert models trained on private data without requiring coordinated retraining. HarmoMoE uses a relevance-based determinantal point process to select diversified and domain-representative proxy samples, allowing the router to be trained in a harmonized manner using abundant approximate data. A context-aware router further refines the overall design."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The baseline selection is up to date.\n2. The motivation for unifying expert models is well explained."}, "weaknesses": {"value": "1. The main concern lies in the privacy-preserving claim. HarmoMoE uses relevance-weighted DPP to select proxy data that represent private data. However, if the proxy data are highly similar to the private data, wouldn’t this constitute a form of data exposure? If not, how does this differ from a vanilla DPP? I suggest adding more discussion about the privacy–utility trade-off involved in using such public proxy data.\n2. HarmoMoE focuses on unifying full-rank experts, but extending the approach to low-rank adapters seems both more feasible and practical in many real-world settings."}, "questions": {"value": "1. Given the assumption that D_0 contains sufficient public data that are representative of private client data, why not simply allow the cloud to train directly on the entire D_0? This baseline should be included to highlight the unique effectiveness of HarmoMoE.\n2. Please discuss the relationship between HarmoMoE and low-rank adaptation unification methods (e.g., LoRASuite, NeurIPS 2025). While additional experiments are not mandatory, even a small-scale or illustrative experiment could strengthen the empirical validation.\n3. What is the proportion of public versus private data used in the experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HWT6nVr7EB", "forum": "DDuF4lpcTl", "replyto": "DDuF4lpcTl", "signatures": ["ICLR.cc/2026/Conference/Submission10257/Reviewer_ZFYq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10257/Reviewer_ZFYq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10257/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761812417727, "cdate": 1761812417727, "tmdate": 1762921612775, "mdate": 1762921612775, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a privacy-preserving training method for sparse Mixture-of-Experts models. To unify multiple expert models, each trained on separate private data, into a single MoE model, the paper proposes a proxy-data selection strategy (weighted DPP) and a context-aware router-training strategy to train the router within the unified model. The empirical results presented in the paper demonstrate that the proposed method outperforms previous baselines in privacy-preserving unification to MoE models."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed method is logically designed\n\n2. The empirical results outperform previous baselines\n\n3. The paper is well-structured and easy to follow"}, "weaknesses": {"value": "1. **Underperformance**: The proposed method outperforms previous privacy-preserving unification baselines. But it still underperforms compared to separately finetuned models on private data. My concern is that, if the proposed unification method does not improve results after unification, what is the advantage of unification? In that case, each client can use their respective finetuned model and enjoy better performance.\n\n2. **Potential suboptimal design**: The paper incorporated the context-aware router training, where the input tokens contain a component average over all the tokens of the input sequence, to capture the input context. Although the design choice improves performance over router training without the context-aware component, the design choice may be suboptimal."}, "questions": {"value": "1. Can the authors explain why the proposed technique is advantageous despite having lower performance than the individually trained models on private data?\n\n2. Can the authors discuss why the proposed context-aware design is optimal?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dRRu8JBnIp", "forum": "DDuF4lpcTl", "replyto": "DDuF4lpcTl", "signatures": ["ICLR.cc/2026/Conference/Submission10257/Reviewer_gTvc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10257/Reviewer_gTvc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10257/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928705746, "cdate": 1761928705746, "tmdate": 1762921612356, "mdate": 1762921612356, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors present HarmoMoE, an approach to training a unified MoE model leveraging local client expertise while respecting data residency constraints. The approach addresses common challenges in training across heterogeneous data sources by introducing a proxy dataset that ensures commonality between local experts during training, enabling more effective model unification when the model is assembled and the router is trained. The approach differs from conventional federated learning in that it trains each local expert fully without coordinated optimization.  The work is similar to FlexOlmo with the main innovation being a proxy data selection method that enforces diversity, yielding better representativeness across the clients and their local training sets."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "* Well-motivated and situated against prior work in this area.\n* Good experimental setup and empirical validation.\n* Strong clarity of presentation and results."}, "weaknesses": {"value": "* The proxy selection approach is perhaps a marginal improvement over FlexOlmo. \n* Privacy benefits are limited or illusory - see my comments below."}, "questions": {"value": "1. It is a bit of a stretch to claim privacy with this setup. It is true that you enforce data residency constraints, but by training and transmitting a local expert on the private data you are essentially communicating a compressed version of the private data that is highly vulnerable to attack. Many papers play fast and loose with this idea of privacy, but it would not meet criteria for privacy compliance in settings where this matters.\n\n2. What is the relative computational cost of DPP vs the similarity-based method in FlexOlmo?\n\n3. What assumptions are necessary about the proxy data?  What is the impact of having a client with strictly OOD data relative to the proxy set?\n\n4. What client signals are needed for training the router? Is it just a question of minimizing the loss on the proxy data assuming frozen client experts?\n\n5. Discuss the absence of an FL-based baseline evaluation.\n\n6. As an additional nice-to-have baseline it might be interesting to train solely on the proxy data. \n\n7. Do you have an ablation where you don't perform final fine-tuning? How important is that step?\n\n8. Are there any concerns about catastrophic forgetting in the final fine-tuning phase? How do you protect against this?  \n\n9. Briefly clarify the difference between the two CLIP models tested.\n\n10. You could get away with moving the large table of CLIP /32 results to the appendix as it doesn't add a lot to the discussion. Likewise for Llama-3b\n\n11. In the experiment comparing with DPP- what is the baseline? Is it random sampling of proxy examples? I get the impression a slightly different set of experiments are depicted in Table 5 vs Fig 2- eg Table 5 has a row for FlexOlmo + DPP but Fig 2 has a figure for FlexOlmo with similarity-based sampling."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UEuThbBmrD", "forum": "DDuF4lpcTl", "replyto": "DDuF4lpcTl", "signatures": ["ICLR.cc/2026/Conference/Submission10257/Reviewer_pz7X"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10257/Reviewer_pz7X"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10257/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946658649, "cdate": 1761946658649, "tmdate": 1762921611764, "mdate": 1762921611764, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}