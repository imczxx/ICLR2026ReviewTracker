{"id": "bisWxwcK8D", "number": 19856, "cdate": 1758300039053, "mdate": 1759897015626, "content": {"title": "Using reinforcement learning to solve vehicle routing problems with dynamic customers", "abstract": "Deep Machine Learning methods have been proven to be effective in solving the travelling salesman problem and general vehicle routing problems. In this paper, we use reinforcement learning to learn effective and fast constructive heuristics for solving a problem with dynamic customer requests, the partially dynamic travelling repairman problem, and variants with customer demands and time windows. We perform an ablation study on the policy network that map between state and action spaces of arbitrary size to investigate which features from previous literature translate well to this new domain and introduce a recurrent neural network component to the decoder that tracks arrivals of dynamic customers improving performance on problems with time windows. The encoder-decoder network can map between state and action spaces of arbitrary dimension, so we investigate how it generalizes to problems of different sizes. The performance of the construction heuristic is compared with several baselines on real world examples and different spatio-temporal customer request distributions of different sizes.", "tldr": "In this paper, we apply reinforcement learning based constructive heuristics to dynamic vehicle routing problems with dynamic customers.", "keywords": ["Reinforcement Learning", "Dynamic Vehicle Routing Problems", "Graph Neural Networks", "Vehicle Routing Problems"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a0ea808df826ad43cd7b0b8bf11a0e2ee99a6b05.pdf", "supplementary_material": "/attachment/c009e66ac970062685ec147ec4730dd85adf8f7b.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents a reinforcement learning framework for solving VRPs with dynamic customer requests. It considers the partially dynamic travelling repairman problem (PDTRP) and its variants with customer demands and time windows. The authors use a graph neural network (GNN) encoder-decoder architecture combined with a recurrent neural network in the decoder to handle dynamic customer arrivals and incorporate variable-sized state and action spaces. Their RL policy is trained to construct routes step-by-step and quickly adapt to new incoming requests in real-time, making the method suitable for dynamic, practical scenarios such as emergency dispatch, courier services, and industrial logistics.​\n\nThe paper includes an ablation study to test which network features and training methods improve performance, and demonstrates that their trained policies generalize from small to large problem instances. The framework is benchmarked against classical heuristics and state-of-the-art solvers (OR-Tools, previous RL and heuristic approaches), showing competitive and sometimes superior results on simulated and real-world dynamic datasets across multiple VRP variants.​\n\nThe contributions include: 1) Development of an RL-based constructive heuristic for dynamic VRPs, generalizing to arbitrary size and handling real-time dynamism. 2) Integration of GNNs and RNNs for state encoding and tracking dynamic arrivals, along with a transformer-based decoder for node selection. 3) Detailed ablation studies investigating model components and training strategies for dynamic routing. 4) Empirical demonstration of fast solution times and robust performance across uniform, skewed, and real-world instance distributions, making the method practical for time-sensitive routing applications."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper combines reinforcement learning with graph neural networks and recurrent neural architectures to solve vehicle routing problems with dynamic customer requests. It is a significant extension beyond prior work focused on static or semi-static VRPs. By tackling the partially dynamic travelling repairman problem and practical variants with time windows and customer demands, it broadens the scope of RL for online combinatorial optimization. The integration of a GNN encoder with RNN-based context tracking is a creative and technically meaningful development.​\n\nThe proposed method is benchmarked on both simulated and real-world datasets (including instances adapted from major routing competitions), compared against strong baselines like OR-Tools and recent RL/heuristic approaches, and supported by detailed ablation studies. The RL policy demonstrates competitive or superior performance, with solution times that are orders of magnitude faster than resolving static snapshots via conventional solvers. Generalization ability across problem sizes is clearly reported and validated.​\n\nThe paper is well written, with clear explanations of the problem setup and all architectural choices. Figures and tables report results and ablation findings, facilitating understanding of why certain modeling decisions matter. Key challenges of dynamic and uncertain routing are contextualized with practical motivation throughout.​\n\nThe significance is high. The proposed RL method brings strong real-time optimization capability to dynamic VRPs, potentially improving routing in domains such as courier logistics, vehicle dispatch, and time-sensitive delivery. The robust generalization and adaptability make it valuable for practice, not just theory."}, "weaknesses": {"value": "1. Although the RL policy generalizes from small to large problem instances within the tested range, there is limited evaluation on very large-scale problems (e.g., thousands of dynamic customers), heterogeneous fleets, or highly complex real-world scenarios with richer, evolving features. Performance is not assessed outside of stylized or competition-like settings, which raises questions about robustness in diverse and practical deployments.​\n\n2. The comparison set relies mainly on classical heuristics, and OR-Tools with snapshot re-solving. More advanced or recent RL, ADP, or local search methods are not comprehensively benchmarked, especially for the most demanding dynamic and constrained scenarios. Thus, conclusions about superior or state-of-the-art performance may not be fully substantiated for the broader DVRP literature.​\n\n3. Results show that the model’s performance can quickly degrade when tested on problem distributions or instance sizes that are mismatched with the training set. This suggests a lack of universal adaptability, and may imply a need for frequent retraining or fine-tuning as operational conditions or customer demand profiles change.​\n\n4. The design and behavior of the RL policy, especially why specific architectural choices (like the transformer decoder components) yield benefits, and how routing decisions evolve over time, are not deeply analyzed or visualized. Real-world users may find the policy’s underlying logic opaque, making trust and debugging difficult.​\n\n5. While the method is fast in simulation, there is no demonstration of robust integration or deployment in real-time vehicle dispatch or distributed logistics systems, where networking, synchronization, and actuator delays can present new failure modes not captured in the static or batched testing protocol.​\n\n6. On the most constrained or time-sensitive problem variants (e.g., with tight time windows and capacities), the RL approach sometimes underperforms or is only on par with adapted classical solvers. This weakness is acknowledged but not deeply investigated; further ablations and failure case exploration would clarify root causes and improvement strategies."}, "questions": {"value": "1. How does the policy handle catastrophic distribution shifts or customer arrival processes significantly different from training time, and what theoretical guarantees can you offer for real-world robustness?​\n\n2. Can the authors explain the learning dynamics or provide ablation evidence on how the recurrent decoder and GNN encoder specifically contribute to generalization for much larger or more dynamic instances?​\n\n3. What are the core scaling bottlenecks (computation, memory, or policy degradation) when moving to real-time, distributed fleet management with thousands of dynamic requests?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Bfc0TOT1bA", "forum": "bisWxwcK8D", "replyto": "bisWxwcK8D", "signatures": ["ICLR.cc/2026/Conference/Submission19856/Reviewer_Q2AM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19856/Reviewer_Q2AM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761650912854, "cdate": 1761650912854, "tmdate": 1762932028228, "mdate": 1762932028228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors apply reinforcement learning to the \"partially dynamic travelling repairman problem\" (PDTRP). They use a graph neural network (GNNs) encoder-decoder framework to model state spaces of arbitrary size and include the hidden state of a Long-Short-Term-Memory (LSTM) layer, adding its output to the decoder's context vector. \nFor evaluation, they run OR Tools on static variants of the instances (i.e., with perfect information) as a benchmark, and include additional heuristic baselines for the dynamic instances."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The routing problem tackled is an interesting one, as it includes uncertainty and is closer to real-world problems than most of the problems studied in the neural combinatorial optimization (NCO) literature.\n- The arguing for using GNNs to model state spaces of arbitrary size is nice, again promising flexibility that could be valuable in routing problems closer to reality."}, "weaknesses": {"value": "- Results\n\t- It is hard to objectively judge the method's performance, considering that the benchmark mentioned in the text (OR Tools on a \"static counterpart of each dynamic instance\", run for 10s) is (1) not actually included in the result table and (2) only run for 10 seconds, raising doubts about the suitability of the values obtained as a benchmark. Gaps of -59% are reported in the result table, raising the questions whether maybe better baselines could have been found, considering this \"static counterpart\" has perfect information and zero uncertainty.\n\t- Results for the Skewed spatial-temporal (S.T.) instances are not mentioned at all in the text.\n- Structure \n\t- Some passages of the introduction are essentially listings of previous works. By restructuring the introduction, the motivation for this work could be presented to the reader with greater clarity.\n\t- The authors could state more clearly, e.g., at the end of the introduction as bullet points, what their main contributions in the paper are. \n\t- The structure of the paper would have benefited of a \"related works\" section, ideally with one subsection on the RL part and one on DVRPs (incl. the PDTRP). As it is, related works are scattered across the introduction and problem description sections, making for a somewhat chaotic read. \n\t- Concepts like LSTM and multi-head attention should briefly be introduced if they are to be used.\n- Problem definition\n\t- For someone not familiar with the PDTRP, the problem description in section 2 should be more detailed. For example, it is never explained what the time horizon $T$ actually is, and when speaking of arrival times, often the time of arrival at a customer is meant, but here it seems to be the time at which a new customer is added to the system. \n\t- It could also be stated more clearly already in the problem definition on p. 3 that while customer nodes have service times, they do not per default have time windows (first explicitly mentioned at the bottom of p. 6).\n- Form\n\t- Tables and Figures need to be referenced in the text!\n\t- From the main text, the reader has no idea how training was performed. Not even how many instances were used (except for the 100 test instances per problem configuration that served for the result table).\n\t- Figure 1 could be improved: Considering it's supposed to show the encoder-decoder architecture, it would be helpful to the reader if it would be marked which parts actually belong to the encoder, etc. It could also help the understanding of section 3.\n\t- Math formulas could have used more care:\n\t\t- p. 3: In the definition of $t'$ there are two issues, (1) $t$ i not included, but the current time should always be updated based on the last current time, and (2) $u$ is never introduced and it is not clear what $u$ is (probably for scaling the distances to the unit square?) \n\t\t- p. 4: Index $i$ in the calculation of $L$ should have run from $0$ to $N-1$ (there are $N-1$ customer nodes, starting the count at 1, not 0). Alternatively, $i$ could run from $1$ to $N$, but as it is, $v_{\\tau(i+1)}$ would result in an invalid index.\n\t\t- p. 5: $T$ is not introduced in section 3, I assume it is not the time horizon\n\t\t- p. 6: $\\tau$ was introduced as a concatenation of nodes, it has no direct information on actions and states\n\t- From reading section 3, there are several things that are unclear in the formulas, where the authors should have provided more extensive explanations (e.g., regarding network parameters for the GNNs). If explanations were kept overly short due to space limitations, maybe some parts should have been put in the appendix instead."}, "questions": {"value": "- In the conclusion you write your \"key innovations are the use of reinforcement learning alongside GNN's to encode the node features in the network, aggregation to achieve summarise in the network state, and use of a transformer to value each node in the context of the other nodes in the system\". Considering that there have been papers combining GNNs and RLs at least since 2023, how are your contributions new or differ from existing neural combinatorial optimization research?\n- What was the basic experiment setup? E.g., instances, hardware, learning rate, etc.\n- p. 6, l. 318-321: How does this qualify as generalizing if problems of the same size were already seen during training (e.g., instances with 50 nodes in the 20-50 case)?\n- p. 6, l. 322 ff.: What about the model trained on 20-100, why not include these as well for the S.T. and R.W. test instances, like they were for the U.U. test instances?\n- Why are the benchmark values for OR Toolson the \"static counterpart\" not reported in the table?\n- Why were Nearest Neighbour (NN) and First Come First Served (FCFS) heuristics combined into one line \"Heur.\" in the table instead of simply reporting them in two separate rows in the table?\n- p. 7. l. 343 ff.: This is not about the static OR Tools benchmark, is it? Make it clearer for the reader.\n- How do you explain that 20-100 consistently performs better for PDCTRPTW on the U.U. N=50 case even though 20-50 could be considered more \"in-distribution\"?\n- How do you explain that the gaps for PDTRPTW and PDCTRPTW behave inconsistently for S.T. N=50 instances, i.e., gaps going down for dod 0.5 (compared to dod 0.2), but then going drastically up again for dod 0.8?\n- Figure 2, Training Method (top left, PDTRP): Why does (100, 0.8) have lower gaps on average (for 20-100, 20-50, and POMO) than (50, 0.8), even though the dod is the same between these two scenarios? Intuitively, one would expect longer routes for larger problems."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OPPw2R52tv", "forum": "bisWxwcK8D", "replyto": "bisWxwcK8D", "signatures": ["ICLR.cc/2026/Conference/Submission19856/Reviewer_gjnc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19856/Reviewer_gjnc"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761898520021, "cdate": 1761898520021, "tmdate": 1762932027766, "mdate": 1762932027766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the dynamic traveling salesman problem (TSP) where customers\nappear during route execution, such that the route has to be revised dynamically.\nThe authors propose to add the new nodes to the state graph and then use the \ngraph convolutional network (GCN) based model from Joshi et al. 2019 to predict the \nnext customer to visit, but to train this model via reinforcement learning. They\nalso add an additional encoder component for the sequence of customers arrived \nso far. In experiments on different variations of the problem (time windows, capacities) \nthey show that their model outperforms heuristics from the literature, rerouting\nvia OR tools and the vanilla GCN model."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- s1. The paper addresses an interesting, (compared to the static variants) not so frequently \n  researched combinatorial optimization problem (COP): dynamic TSPs. \n- s2. The paper is clearly written."}, "weaknesses": {"value": "- w1. it is not clear why the heuristics perform so badly for variations with time windows.\n- w2. it is not clear if the OR solvers have been seeded with a repaired instance, or have to\n  solve the remaining problem from scratch.\n- w3. a local search based neural solver starting from a heuristically repaired solution \n  is a trivial baseline, but not compared.\n- w4. better baseline OR solvers have been missed.\n- w5. the methodological contribution is limited, the exact delineation to existing models not \n  very explicit.\n- w6. it is not clear why the ablation study for the RNN encoder of past arrivals shows an \n  effect in the uniform scenario.\n\nmore details:\nw1. it is not clear why the heuristics perform so badly for variations with time windows.\n- Can you clarify: does this happen because both, nearest neighbor and first come first served\n  do not respect time windows and thus incur very high penalties?\n- Is the most basic insertion heuristic, to check all insertion points and choose the\n  one with lowest cost, evaluated?\n\nw2. it is not clear if the OR solvers have been seeded with a repaired instance, or have to\nsolve the remaining problem from scratch.\n- Starting from a repaired solution and then just refining this a little bit seems so much\n  less effort than construcing them from scratch again.\n\nw3. a local search based neural solver starting from a heuristically repaired solution \nis a trivial baseline, but not compared.\n- same rational as w2. And there are many local-based neural solvers available\n  who could address the problem without modification.\n\nw4. better baseline OR solvers have been missed.\n- Why do you compare against OR tools? \n- LKH and HGS in most papers are found to provide way better results.\n\nw5. the methodological contribution is limited, the exact delineation to existing models not \nvery explicit.\n- Combining GCN encoders with RL is very close to POMO. You just say that the specific\n  idea of POMO, to start from different points, did not help.\n\nw6. it is not clear why the ablation study for the RNN encoder of past arrivals shows an \neffect in the uniform scenario.\n- In the ablation study in fig. 2 you look at the problem where new customers are \n  distributed uniformly over time. To me it is not clear, what can the sequence of\n  past customer arrivals tell the model in this case?\n- I would understand the effect for the time-variant arrival distributions (called \n  \"skewed spatial-temporal\" in your paper)."}, "questions": {"value": "- q1. Why do the repair heuristics perform so badly for problems with time windows?\n- q2. Do OR solvers refine a repaired solution or try to solve problems from scratch?\n- q3. Can you compare against a local search based neural solver that tries to \n  improve the heuristically repaired solution?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1kyjQq6yrr", "forum": "bisWxwcK8D", "replyto": "bisWxwcK8D", "signatures": ["ICLR.cc/2026/Conference/Submission19856/Reviewer_rdoa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19856/Reviewer_rdoa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904445183, "cdate": 1761904445183, "tmdate": 1762932027116, "mdate": 1762932027116, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper applies reinforcement learning (RL) to the partially dynamic traveling repairman problem (PDTRP) and related variants with customer demands and time windows. The authors propose an encoder–decoder network that maps variable-sized state and action spaces, with a recurrent decoder component that tracks dynamic customer arrivals. The goal is to learn fast constructive heuristics that generalize across instance sizes. Empirical evaluation compares the learned heuristic to baselines, including OR-Tools in a rolling-horizon setting, on several real-world–inspired datasets."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The topic—learning constructive heuristics for dynamic routing—is relevant to both operations research and reinforcement learning communities.\n\n2. The problem choice (partially dynamic traveling repairman) has practical interest, and the integration of recurrent decoding for dynamic requests is conceptually reasonable.\n\n3. The paper attempts to conduct ablation studies to understand design choices, which shows some experimental care."}, "weaknesses": {"value": "1. Lack of methodological novelty: The proposed encoder–decoder architecture closely follows prior works on neural combinatorial optimization and RL-based routing. No clear algorithmic or architectural innovation is introduced. The RNN-based decoder extension is minor and does not constitute a substantial methodological advance.\n\n2. Weak experimental design and baselines: The choice and configuration of baselines are inappropriate for the studied problem.\n• OR-Tools is a general-purpose solver not tailored to dynamic routing, and its use in a rolling-horizon fashion is a weak benchmark.\n• Restricting OR-Tools to 3-second or 10-second runtime windows heavily biases results in favor of the proposed approach.\n• A much stronger baseline would be a stochastic or sample-average approximation (SAA) method or other optimization-based dynamic repairman heuristics, which can easily be computed for the proposed problem.\nConsequently, the empirical conclusions are unreliable.\n\n3. Unclear problem framing: The relationship between the studied variant (PDTRP) and prior definitions in the literature is not well explained. It is unclear which benchmark instances are used or why those from previous foundational works are omitted. Without a well-defined benchmark setting, comparisons lose validity.\n\n4. Inconsistent and incomplete reporting: The paper does not define some abbreviations or baseline methods (e.g., “Heur.” in Table 1). Figures and tables lack clear descriptions, and runtime constraints for different methods are inconsistently justified.\n\n5. Limited generalization and insight: The paper neither provides theoretical insights nor demonstrates meaningful generalization. It remains a straightforward application of existing neural routing architectures to a modified problem setting.\n\n6. Overall contribution below ICLR standards: Both in terms of technical innovation and experimental rigor, the work falls short of what is expected for a top-tier ML conference. The study could be better suited for a specialized application venue if reformulated and empirically strengthened."}, "questions": {"value": "1. What concrete architectural innovations distinguish your encoder–decoder from prior works?\n\n2. Why was OR-Tools chosen as the main baseline, and why were time limits set so restrictively?\n\n3. Which specific benchmark instances from the literature were used or modified, and why are original PDTRP instances not employed?\n\n4. Could the authors clarify what “Heur.” in Table 1 refers to?\n\n5. How sensitive are the results to the choice of rolling-horizon interval and computational cutoff?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "NjY5TjUu4N", "forum": "bisWxwcK8D", "replyto": "bisWxwcK8D", "signatures": ["ICLR.cc/2026/Conference/Submission19856/Reviewer_WgWg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19856/Reviewer_WgWg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19856/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947190174, "cdate": 1761947190174, "tmdate": 1762932026231, "mdate": 1762932026231, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}