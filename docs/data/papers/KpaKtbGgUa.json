{"id": "KpaKtbGgUa", "number": 17763, "cdate": 1758280304131, "mdate": 1763709674650, "content": {"title": "MemoryField: Exploiting Gravitational Field for Long-term Memory Management", "abstract": "Despite the rapid progress of large language models (LLMs) enabling agents to perform complex decision-making and interaction, their limited long-term memory capacity hinders effective retention and organization of historical interactions. This often leads to instability and semantic fragmentation in multi-turn dialogues and long-range reasoning tasks. Existing memory mechanisms struggle with structural reorganization, dynamic semantic retrieval, and the modeling of cognitive phenomena such as memory consolidation and forgetting. To address these challenges, we propose MemoryField, a novel dynamic spatial cognitive memory architecture driven by an attention-based gravitational field model. MemoryField represents memory items as nodes in a high-dimensional semantic space, where semantic attraction, repulsion, attention-driven forces, and decay mechanisms enable self-organized evolution and adaptive restructuring. By integrating node dynamics with fusion and forgetting processes, our approach ensures semantic coherence and cognitive stability. We validate the effectiveness of our approach on multi-turn dialogue and multi-type reasoning tasks. In dialogue tasks, MemoryField outperforms baseline models, achieving improvements of up to 4.9 points in Mauve and 3.3 points in ROUGE-L. In long-context reasoning tasks, the F1 score is improved by up to 14.7 points on adversarial and temporal reasoning benchmarks. These results demonstrate that the proposed method offers significant advantages in memory modeling and can serve as a general solution for long-term memory management in LLM agents.", "tldr": "", "keywords": ["Large Language Models", "Long-term Memory", "Cognitive Memory Architecture"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/535a0d68c81260da8f3d30a0bf735785fe8f311d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces MemoryField, an innovative memory architecture for large language models (LLMs) based on an attention-driven gravitational field model. MemoryField addresses challenges in long-term memory management, including structural reorganization, semantic retrieval, and cognitive phenomena like memory consolidation and forgetting. It models memory as nodes in a high-dimensional semantic space, enabling adaptive restructuring through forces like attraction, repulsion, and decay. Extensive experiments demonstrate superior performance in dialogue coherence, reasoning stability, and real-world benchmarks compared to existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The MemoryField framework effectively integrates semantic dynamics, memory consolidation, and forgetting mechanisms, providing a scalable and novel approach to long-term memory management.\n\n2. Experimental results highlight significant improvements in dialogue coherence and reasoning stability over state-of-the-art baselines across diverse benchmarks.\n\n3. The paper presents a well-grounded theoretical foundation, with clear descriptions of the gravitational field model and its impact on memory reorganization."}, "weaknesses": {"value": "1. As a study addressing the challenge of long-term memory in large language models, it is concerning that the authors did not evaluate their approach on well-established memory benchmarks such as LongMemEval [1] or LoCoMo [2], raising doubts about the model's memory capabilities.\n\n2. Is the memory forgetting module necessary? For humans, forgetting is essential due to limited brain capacity. However, in scenarios where storage space is sufficient, forgetting may become redundant or even detrimental, especially if critical information is forgotten, potentially impacting performance negatively. Additionally, even if certain information is not queried immediately, there is no guarantee it will not be required in future contexts.\n\n3. The proposed method involves multiple components, including attraction, repulsion, forgetting, and fusion modules. However, the paper lacks the necessary ablation studies to demonstrate the effectiveness of these individual components.\n\n4. The title of Table 1 appears to be inconsistent with the table's content. Furthermore, it is recommended to include evaluation metrics similar to GPT4Judge in the results for a more comprehensive assessment.\n\n[1] Wu, Di, et al. \"LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory.\" The Thirteenth International Conference on Learning Representations.\n\n[2] Maharana, Adyasha, et al. \"Evaluating Very Long-Term Conversational Memory of LLM Agents.\" Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2024."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4qwk47l7PF", "forum": "KpaKtbGgUa", "replyto": "KpaKtbGgUa", "signatures": ["ICLR.cc/2026/Conference/Submission17763/Reviewer_FVEg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17763/Reviewer_FVEg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761105772924, "cdate": 1761105772924, "tmdate": 1762927606127, "mdate": 1762927606127, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes¬†MemoryField, a dynamic spatial cognitive memory architecture.¬†This architecture is driven by an attention-based gravitational field model.¬†This model allows the memory structure to self-organize and adaptively restructure.¬†The system also explicitly integrates node fusion, which serves as a form of conceptual abstraction to reduce redundancy, and a forgetting mechanism to prune long-term, low-activity memory nodes, ensuring semantic coherence and cognitive stability. Extensive experiments were conducted across diverse benchmarks, including multi-turn dialogue long-context reasoning, and real-world agent tasks.¬†The results shows that MemoryField consistently outperforms existing memory mechanisms."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper introduces a gravitational-field concept from physics into the memory module of LLMs, enabling self-evolution and natural forgetting. This is a interesting idea.\n\n2. This framework provides a unified and intuitive simulation of advanced cognitive functions. Specifically, the mechanism of ‚ÄúFusion‚Äù aligns with memory consolidation, whereas ‚ÄúActivity Decay‚Äù and ‚ÄúSource Repulsion‚Äù reflect the dynamics of natural forgetting.\n\n3. The experimental design is comprehensive, covering three major scenarios‚Äîdialogue, reasoning, and agent-based tasks. It compares multiple baselines and further validates the framework‚Äôs generalization ability across several state-of-the-art models."}, "weaknesses": {"value": "1. There are too many new hyperparameters. It is difficult to reproduce the results. Moreover, it raises concerns about the robustness and generalization ability of the proposed method, as the performance might be highly sensitive to specific hyperparameter settings.\n\n2. The framework appears to be quite complex, yet the authors do not provide any analysis or discussion of its computational cost. A detailed examination of the time and space complexity would help readers better understand the practicality of the method. In addition, the authors should report the inference latency and compare it quantitatively with other baseline methods to demonstrate the efficiency and scalability of their approach."}, "questions": {"value": "1. Which embedding model is used to obtain the semantic content vector?\n2. How is the spatial position vector obtained? \n3. Why can‚Äôt the semantic vector replace the position vector?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bmAfn6FRC1", "forum": "KpaKtbGgUa", "replyto": "KpaKtbGgUa", "signatures": ["ICLR.cc/2026/Conference/Submission17763/Reviewer_2Fqr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17763/Reviewer_2Fqr"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761306546185, "cdate": 1761306546185, "tmdate": 1762927605538, "mdate": 1762927605538, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MemoryField, a long-term memory module that models stored memories as particles in a high-dimensional ‚Äúgravitational field,‚Äù with four forces (attraction/repulsion/attention pull/peripheral pushback), plus fusion and forgetting. It reports gains on dialogue quality (e.g., +4.9 MAUVE, +3.3 ROUGE-L) and reasoning F1, and claims cross-model generalization (abstract & Sec. 4)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The introduction of a field-based memory representation is quite novel and creative, providing a new physical metaphor for modeling interactions among memories.\n\n2. The paper conducts extensive experiments across multiple datasets and tasks (dialogue, reasoning, and real-world benchmarks), demonstrating consistent improvements over strong baselines.\n\n3. The approach shows broad applicability across different model backbones, suggesting good generalization potential."}, "weaknesses": {"value": "- The paper could be strengthened by connecting to Trace Theory ‚Äî where each perceived sentence or event is mapped into a sequence of nodes (a trace) rather than a single node in the field. Such a design would better capture the temporal and structural continuity of cognition, and make the framework fundamentally different from standard RAG systems. The current formulation, which stores each paragraph or text chunk as an independent node, remains conceptually close to conventional retrieval-based architectures.\n\n- If the goal is to show superiority in text organization and retrieval, the comparisons should include RAG baselines such as BM25, Dense Passage Indexing (DPI)[2], HippoRAG[1], or HippoRAG-v2[3]. At present, the baselines are mostly non-RAG methods (e.g., ReAct), making it unclear whether the proposed method truly outperforms simpler yet competitive retrieval pipelines.\n\n- Despite being named MemoryField, the system primarily operates as a structured RAG rather than a true memory system. It lacks properties associated with long-term memory, such as global understanding, skill accumulation, or adaptive reuse of prior knowledge (as discussed in MemoryAgentBench[4]). In its current form, the work feels closer to an ‚Äúadvanced RAG‚Äù rather than a genuine ‚Äúmemory‚Äù architecture.\n\n[1] HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models.  \n[2] Dense Passage Retrieval for Open-Domain Question Answering.  \n[3] From RAG to Memory: Non-Parametric Continual Learning for Large Language Models.   \n[4] Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions."}, "questions": {"value": "When merging multiple nodes, how do you merge the texts in these nodes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "q8mtUpVRCO", "forum": "KpaKtbGgUa", "replyto": "KpaKtbGgUa", "signatures": ["ICLR.cc/2026/Conference/Submission17763/Reviewer_pTa2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17763/Reviewer_pTa2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761819512674, "cdate": 1761819512674, "tmdate": 1762927604904, "mdate": 1762927604904, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose MemoryField, a dynamic architecture for long-term memory in LLM agents. Each ‚Äúmemory node‚Äù is treated as a particle in a high-dimensional semantic space with a content vector $ùê∂_ùëñ$, position $ùëÉ_ùëñ$, velocity $ùëâ_ùëñ$, and activation $ùê¥_ùëñ$. Nodes are subject to four forces: inter-node attraction/repulsion and attraction to/repulsion from the origin, with periodic merge and forgetting rules. The system answers a query, updates links, and relaxes the configuration until the energy converges. Experiments are reported for dialogue (MSC, CC), long-context settings (five task types), and ‚Äúreal-world tasks‚Äù (AlfWorld, ScienceWorld, HotPotQA, FEVER)."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The idea of dynamic, physics-inspired memory control (four forces plus merge/forgetting) is fresh and potentially useful for mitigating long-context noise. The formalization of the forces and update rules is sufficiently clear.\n\n* An appealing intuition: store the answer and its context as a new memory node; reinforce frequently used knowledge and weaken the ‚Äúperiphery.‚Äù\n\n* A broad set of setups (dialogue, reasoning categories, and environment/interaction tasks) is intended to test the approach‚Äôs generality. The work also features clear, informative visualizations that aid understanding."}, "weaknesses": {"value": "1. In Section 4.1 (‚ÄúExperimental Setup‚Äù), the ‚ÄòDatasets‚Äô paragraph lists categories (single-hop, multi-hop, temporal, open-domain, adversarial) and mentions only illustrative datasets in Appendix A.5 (e.g., NQ, MuSiQue, HotPotQA, 2WikiHop), but there is no clear mapping between these datasets and the listed categories. Table 2 summarizes results by the five reasoning categories rather than listing the exact datasets, and for the Single-hop Reasoning, Temporal Reasoning, and Adversarial Reasoning categories no concrete benchmarks are specified. For HotPotQA/FEVER, the SR (success rate) metric is reported, but SR is not clearly defined (is it EM? EM@1? the fraction of successful agent episodes?), and the evaluation protocol is not described (e.g., whether HotPotQA distractor passages were used, how hops were constructed, number of steps, etc.).\n\n2. What exactly is stored in a memory node, and how memory is initialized and grows, is described too generally.\nIn particular, it is unclear what precise textual payload constitutes the semantic content vector $ùê∂_ùëñ$. Is it the raw answer, the question+answer pair, retrieved passages, an extractive span set, a summary, or a prompt-formatted bundle (with instructions/system text)? The paper states that retrieved nodes plus the current question are fed to the LLM, after which ‚Äúthe answer and its context‚Äù are saved as a new node, but there is no benchmark-specific recipe: no concrete templates or examples, no accumulation depth, allowable top-k sizes, update frequency, merge triggers, or forgetting thresholds in the evaluation setup.\n\n3. $ùê∂_ùëñ$ is defined as a ‚Äúsemantic content vector,‚Äù but the specific embedding model is not specified, nor is it clear how it was chosen or fine-tuned, or whether it is the same across tasks and LLMs. For $ùëÉ_ùëñ$, the dimensionality ùëõ is not fixed in the method. In the training ‚Äúexample log,‚Äù a position matrix with shape (1,128) (and later (2,128), (3,128)) appears, which suggests that the implementation likely uses $n=128$, but this is not stated in the main text. The ablation visualizations (Figure 4) appear two-dimensional, yet the projection or reduction method (t-SNE, UMAP, PCA, or force-directed) is not described.\n\n4. Ablations are shown only visually, without metrics. Section 4.3 presents visual configurations with ‚Äúforces turned off,‚Äù but there is no table quantifying the impact of each force on key metrics (Mauve, ROUGE-L, F1, SR). This weakens the evidence for the necessity of all components.\n\n5. Unclear/inconsistent descriptions and captions in the tables.\nTable 1 is titled ‚ÄúF1‚Ä¶ across context lengths,‚Äù but the table itself reports BLEU-4/ROUGE-L/Mauve/BERTScore for MSC/CC, with no context lengths and no F1. This is a clear mismatch between caption and content. Table 3 uses ‚Äúautomatic scoring, higher is better,‚Äù but the metric is neither named nor defined (no scale, source, or validity).  In Table 2, there is an ‚ÄúOverall‚Äù column, but it is not explained how it is computed; judging by the numbers, it is not the simple average of the five categories (and this needs to be clarified)."}, "questions": {"value": "1. In your Table 4, you include the Reflexion baseline. Please clarify whether you reproduced these results under your own protocol, or adopted them from the source. If taken from the source, provide an exact citation and justify protocol comparability, since in Shinn et al. the metrics are computed over trials and are notably sensitive to agent configuration. In the original Reflexion paper, Figs. 3‚Äì4 show stronger curves on AlfWorld/HotPotQA and explicitly test the ReAct + Reflexion configuration. Please explain why the ReAct + Reflexion variant is not reported in your Table 4.\n2. Please refer to Weaknesses ¬ß1‚Äì¬ß3"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UjluP8sNL5", "forum": "KpaKtbGgUa", "replyto": "KpaKtbGgUa", "signatures": ["ICLR.cc/2026/Conference/Submission17763/Reviewer_YpTb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17763/Reviewer_YpTb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17763/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761949869139, "cdate": 1761949869139, "tmdate": 1762927604029, "mdate": 1762927604029, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}