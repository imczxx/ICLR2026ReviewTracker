{"id": "9NDmVHQ6sx", "number": 4037, "cdate": 1757588778505, "mdate": 1759898056534, "content": {"title": "MTGS: Multi-Traversal Gaussian Splatting", "abstract": "Multi-traversal data, commonly collected through daily commutes or by self-driving fleets, provides multiple viewpoints for scene reconstruction within a road block. This data offers significant potential for high-quality novel view synthesis, which is crucial for applications such as autonomous vehicle simulators. However, inherent challenges in multi-traversal data often result in suboptimal reconstruction quality, including variations in appearance and the presence of dynamic objects. To address these issues, we propose Multi-Traversal Gaussian Splatting (MTGS), a novel approach that reconstructs high-quality driving scenes from arbitrarily collected multi-traversal data by modeling a shared static geometry while separately handling dynamic elements and appearance variations. Our method employs a multi-traversal scene graph with a shared static node and traversal-specific dynamic nodes, complemented by color correction nodes with learnable spherical harmonics coefficient residuals. This approach enables high-fidelity novel view synthesis and provides flexibility to navigate any viewpoint. We conduct extensive experiments on a large-scale driving dataset, nuPlan, with multi-traversal data. Our results demonstrate that MTGS improves LPIPS by 23.5% and geometry accuracy by 46.3% compared to single-traversal baselines. Code will be publicly available.", "tldr": "", "keywords": ["Dynamic scene reconstruction", "Multi-traversal reconstruction", "Autonomous driving"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c8170e704a1ab31a6d385e61cc73fad67f93b584.pdf", "supplementary_material": "/attachment/c26556aeb4c126c9d4330140485784f356300542.zip"}, "replies": [{"content": {"summary": {"value": "Multi-traversal data enables multi-view road scene reconstruction and high-quality novel view synthesis (vital for autonomous vehicle simulators). However, it faces challenges like appearance variations and dynamic objects, leading to suboptimal reconstruction. We propose Multi-Traversal Gaussian Splatting (MTGS), which models shared static geometry while handling dynamic elements and appearance variations separately for high-fidelity novel view synthesis. Experiments on nuPlan show MTGS improves LPIPS by 23.5% and geometry accuracy by 46.3% over single-traversal baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Interesting questions and clear definitions of the questions.\n2. Clear expression of methods and presentation of algorithms. \n3. Reasonable ablation experiments."}, "weaknesses": {"value": "The paper has several areas that need improvement:\n- **Lack of comparison with the latest methods**: The paper fails to compare with the latest novel view synthesis methods such as ReconDreamer, FreeVS, and Dist - 4D. By comparing with these methods, the performance, advantages, and disadvantages of the proposed method can be more comprehensively evaluated, providing more valuable reference for readers.\n- **Absence of novel view synthesis visualization**: The paper does not provide novel view synthesis visualization. It is recommended to visualize translations of 1m, 2m, and 4m. This kind of visualization can more intuitively show the effect of the method in novel view synthesis, helping readers better understand the performance of the method.\n- **Poor - quality images**: The image quality in the paper is poor and cannot be used in real - world scenarios, and there is a large gap compared with the novel view synthesis of ReconDreamer. High - quality images are crucial for demonstrating the effectiveness of the method, and poor - quality images may affect readers' understanding and evaluation of the method.\n- **Poor - quality reconstruction results in the demo**: The reconstruction results in the demo seem to be of poor quality, and there is still a large gap compared with the demo of OmniRe. The demo is an important means to show the practical effect of the method. Poor - quality reconstruction results may make readers question the practical value of the method."}, "questions": {"value": "The main problem lies in the above aspects. Additionally, the innovation of the thesis is limited."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "npyFEOpP84", "forum": "9NDmVHQ6sx", "replyto": "9NDmVHQ6sx", "signatures": ["ICLR.cc/2026/Conference/Submission4037/Reviewer_Nsvs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4037/Reviewer_Nsvs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761223356693, "cdate": 1761223356693, "tmdate": 1762917144907, "mdate": 1762917144907, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors propose a novel approach MTGS that reconstructs high-quality driving scenes from multi-traversal data. Specifically, MTGS employs a multi-traversal scene graph consisting of a static node and dynamic nodes. To address appearance variations across different traversals, the scene graph is further complemented by appearance nodes with learnable spherical\nharmonics coefficient residuals. Experiments demonstrate that MTGS achieves state-of-the-art performance in both driving scene reconstruction and novel view synthesis."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper focuses on high-fidelity driving scene reconstruction using multi-traversal data, which is valuable for cross-lane simulations of AV. However, appearance variations in multi-traversal data disrupt scene consistency and introduce geometric errors, making the reconstruction process more challenging.\n2. The authors decompose the entire driving scene using a multi-traversal scene graph with three core nodes: shared static nodes, appearance nodes, and transient nodes, which significantly improves the fidelity and geometric consistency of scene reconstruction.\n3. Extensive experiments on the nuPlan dataset demonstrate that MTGS achieves superior performance."}, "weaknesses": {"value": "1. One of the core innovations of MTGS—the \"Scene Graph Node Decomposition\"—has similarities to prior 3D Gaussian Splatting-related methods (such as StreetGS, DrivingGaussian) and lacks breakthrough ideas.\n2. MTGS’s performance advantages are highly dependent on multi-traversal data, which poses significant drawbacks in real-world autonomous driving scenarios and hinders its practical deployment due to high data collection costs and inefficiencies."}, "questions": {"value": "Please check the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "cSVkhsBkw1", "forum": "9NDmVHQ6sx", "replyto": "9NDmVHQ6sx", "signatures": ["ICLR.cc/2026/Conference/Submission4037/Reviewer_buEE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4037/Reviewer_buEE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761727864980, "cdate": 1761727864980, "tmdate": 1762917144708, "mdate": 1762917144708, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes MTGS, a method for reconstructing driving scenes using multi-traversal data, where multiple recordings of the same road are available. The goal is to achieve high-quality view extrapolation and photorealistic driving scene reconstruction. To do so, the authors propose a multi-traversal scene graph with shared static nodes and traversal-specific appearance and transient nodes as welll as some tricks for better quality.  The authors conduct comprehensive experiments using the large-scale nuPlan dataset, which contains multi-traversal data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is technically solid, well-organized, and supported by comprehensive ablation studies.\n- The proposed framework effectively aligns appearances and reconstructs static environments with high visual fidelity in drivable areas.\n- Leveraging multi-traversal data for reconstruction is an important and underexplored direction for autonomous driving and digital twin simulation."}, "weaknesses": {"value": "- The handling of transient and dynamic objects remains problematic. Since these objects vary across traversals, the current model cannot establish consistent geometry or appearance. While the approach has potential as a strong background reconstruction technique, it is still incomplete as a holistic driving-scene solution.\n\n- The method’s technical novelty is moderate. While the multi-traversal setting is valuable, the main modules (scene graph design, affine correction, normal/depth regularization) extend prior work rather than introducing fundamentally new formulations. The problem formulation is also very similar to reconstruction methods using in the wild images.\n\n- As can be seen from the videos in the supplementary materials,  roadside vehicles are almost broken (in traversal_test).\n\n- In Table 1, for ST setting, StreetSG and OmniRe are even worse than the original 3DGS in terms of PSNR, which needs better explanations."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yxW8PGwWVo", "forum": "9NDmVHQ6sx", "replyto": "9NDmVHQ6sx", "signatures": ["ICLR.cc/2026/Conference/Submission4037/Reviewer_9PmS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4037/Reviewer_9PmS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761838485511, "cdate": 1761838485511, "tmdate": 1762917144475, "mdate": 1762917144475, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a method for reconstructing realistic driving scenes from multiple trips along the same route. It separates static geometry from dynamic elements and adjusts for lighting or appearance changes, leading to cleaner, more consistent results. Experiments show that MTGS achieves noticeably better image quality and geometry accuracy compared to single-traversal methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well written and easy to follow.\n2. The paper contributes to an interesting and important problem of reconstructing a scene across multi-traversals. Multi-traversal data often involve significant temporal and appearance variations such as changes in illumination, weather, and dynamic objects, which make achieving consistent, high-fidelity reconstruction difficult. This paper shows that their solution achieves strong results in multi-traversal reconstructions."}, "weaknesses": {"value": "1. While I think this paper tackles an interesting topic. However, I think the most important challenge in the multi-traversal reconstruction is not enough handled. The decomposition of static and dynamic objects is common in self-driving gaussian splatting. While it is a natural solution in the multi-traversal scenarios, I believe it is not a significant contributions here. I feel the solutions to handle the illumination, weathers, etc. need to be strengthened in this paper. \\\n2. This paper seems lacking of visual comparisons, can the author provide more results comparisons on novel-view synthesis?"}, "questions": {"value": "1.I understand that the traversal-specific residual coefficients are meant to capture appearance differences such as lighting and reflections. However, since these residuals are learned independently for each traversal, wouldn’t that make it difficult for the model to generalize or interpolate lighting changes between traversals? In particular, because higher-order SHs (which normally encode directional illumination) are now traversal-specific, isn’t there a risk that the model just memorizes traversal-specific lighting instead of learning a shared representation of how lighting varies? From table 2, it seems without the Appr.Node, the novel-view psnr/ssim shows better results. \\\n2. You mentioned that sharing Y_0,0 forces the Gaussian to learn albedo. But since this is enforced only implicitly by sharing, without explicit supervision or intrinsic decomposition, how can you be sure that Y_0,0 doesn’t still capture some average lighting components?\\\n3. For the LiDAR-guided exposure alignment, view-dependent lighting effects such as shadows or specular highlights might be mistaken for exposure differences. Could this cause the method to over-correct and distort the true scene appearance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VYINAO2glH", "forum": "9NDmVHQ6sx", "replyto": "9NDmVHQ6sx", "signatures": ["ICLR.cc/2026/Conference/Submission4037/Reviewer_aCbS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4037/Reviewer_aCbS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4037/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762007694525, "cdate": 1762007694525, "tmdate": 1762917144218, "mdate": 1762917144218, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}