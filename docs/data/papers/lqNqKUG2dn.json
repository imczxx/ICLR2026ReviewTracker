{"id": "lqNqKUG2dn", "number": 22051, "cdate": 1758325359733, "mdate": 1759896888764, "content": {"title": "Which LLM Multi-Agent Protocol to Choose?", "abstract": "As large-scale multi-agent systems evolve, the communication protocol layer has become a critical, yet understudied, component affecting system performance and reliability. Despite a range of protocols, such as JSON-RPC, A2A, ANP, and ACP, protocol selection remains ad hoc. To address this, we introduce ProtocolBench, a benchmark designed to evaluate agent communication protocols across task utility, communication overhead, system performance, and resilience under failure. ProtocolBench uses a three-layer architecture with protocol adapters for fair com- parison, diverse scenarios (e.g., document aggregation, collaborative coding), and detailed telemetry. Our results show protocol choice can impact task completion time by up to 36%, communication overhead by 3.5 seconds, and resilience with statistically observable differences. We also propose ProtocolRouter, a learnable protocol routing system that dynamically selects protocols based on runtime con- ditions, improving performance by up to 18% compared to individual protocols. Our findings highlight that hybrid protocol deployments outperform homogeneous ones by approximately 6.6%, with negligible protocol translation overhead. We release ProtocolBench as an open-source framework to standardize protocol eval- uation and improve multi-agent system reliability at scale.", "tldr": "", "keywords": ["LLM", "Multiagent System", "LLM Agent", "Agent Protocol", "Benchmark"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/69a333bc7563ad96f0c2c1cdd6fd07ba8d4c11ac.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper investigates multi-agent communication protocols in terms of their performance and reliability, including A2A, ACP, ANP, Agora, MCP. The authors believe that these protocols' comparative behavior and trade-offs remain poorly understood. To address this, the authors design a benchmark (i.e., ProtocolBench) that systematically evaluates these protocols across multiple realistic scenarios and performance metrics. They further introduce a dynamic, learnable routing system (i.e., ProtocolRouter) that automatically selects or combines protocols depending on the situation, rather than relying on a single fixed protocol."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper includes the most popular multi-agent communication protocols, providing a good coverage for protocol selection.\n2. The authors tailor four different datasets with tasks to measure different dimensions of the communication protocols.\n3. A flexible routing mechanism is proposed as an additional performance booster for the multi-agent applications."}, "weaknesses": {"value": "1. The focus of the paper is on the multi-agent communication protocols without providing sufficient insights. For example, the proposed benchmark reveals that there are differences in task utility in terms of the GAIA document QA tasks, but there is no analysis or explanation about how those protocols will introduce such differences.\n2. It is unclear whether the implementation of the single agents in tasks can introduce unexpected factors to the benchmark. For example, the authors use their own implementations in terms of the planner module, tool design and execution, etc. It is possible that some implementations work better with a specific communication protocol than others.\n3. From a higher-level perspective, such comparisons of different multi-agent communication protocols can provide limited insight for the LLM agent research. However, since those protocols are still in rapid development phases, the key observations in this paper may become outdated shortly. \n4. Some metrics (e.g., end-to-end latency)on the communication protocol may not be important, especially when the (single) agent mechanism, or multi-agent topology optimization, or LLM inference engine, deserves more attention, which can bring larger end-to-end benefit.\n5. The algorithm design of ProtocolRouter is unclear to the reader."}, "questions": {"value": "1) How does the ProtocolRouter eliminate the manual configuration?\n2) What does the \"module\" concept refer to in this paper?\n3) How is fairness across protocols truly ensured, considering different protocols inherently implemented with different serialization, encryption, and transport stacks?\n4) How does the Protocol Adapter Layer work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LbNgUb1IMr", "forum": "lqNqKUG2dn", "replyto": "lqNqKUG2dn", "signatures": ["ICLR.cc/2026/Conference/Submission22051/Reviewer_xJMG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22051/Reviewer_xJMG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22051/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761368646880, "cdate": 1761368646880, "tmdate": 1762942037053, "mdate": 1762942037053, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces ProtocolBench, a benchmark to compare agent communication protocols (A2A, ACP, ANP, Agora) across task utility, communication overhead/latency, system resilience, and security, and proposes ProtocolRouter to pick protocols per scenario/module. Results show protocol choice matters; no single protocol dominates, and a learned router can sometimes match or beat the best single protocol."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is clearly written and tackles a very important problem, given the recent surge of Agent Communication Protocols. The 4 tasks/metrics being covered are also central to the evaluations of these protocols, I liked how the benchmark tackles each of the specific metrics and generates queries/scenarios specific to them. The experimental analysis also provides good insights into the limitations of existing protocols."}, "weaknesses": {"value": "I have two central concerns: the contribution of ProtocolRouter and the lack of actionable insights for future work. While the paper carefully reports where different protocols vary in performance, it does not sufficiently diagnose why these differences arise or how they could guide the design of better protocols. The analysis ends at identifying which protocol performs best under specific scenarios, rather than translating those observations into concrete recommendations for improving protocol mechanisms themselves. As a result, a reader can learn which protocol to use for a given setup but not what features or communication principles future protocols should incorporate to achieve more consistent, generalizable gains. This limitation is reinforced by ProtocolRouter, which largely serves as a selector over existing methods and, as shown in Table 9, often performs worse than or only marginally better than the best single protocol. This suggests that simple routing on top of current designs offers limited benefit. Given these points, I strongly believe that adding deeper, more actionable insights into why existing protocols fail and how they can be improved would make this work significantly more valuable for the community.\n\nAdditionally, the benchmark itself omits several key metrics that would better capture real-world performance—particularly scalability with the number of agents and task complexity. Including these dimensions would provide a more comprehensive understanding of how each protocol scales under load and handles increasingly difficult coordination challenges, thereby making the benchmark a stronger foundation for evaluating future multi-agent systems."}, "questions": {"value": "1. How can ProtocolRouter be adapted to rapidly changing task contexts, given that the paper mentions it assumes slowly changing workload distributions?\n\n2. What kinds of data or diagnostics would be most useful for future work to derive more generalizable design principles for multi-agent communication?\n\n3. How can we incorporate the metrics like Number of Agents and Task complexity into ProtocolBench?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "dQPH1NwbZr", "forum": "lqNqKUG2dn", "replyto": "lqNqKUG2dn", "signatures": ["ICLR.cc/2026/Conference/Submission22051/Reviewer_erSJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22051/Reviewer_erSJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22051/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761769205289, "cdate": 1761769205289, "tmdate": 1762942036827, "mdate": 1762942036827, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces ProtocolBench, a benchmark for evaluating communication protocols in LLM-based multi-agent systems. It also proposes ProtocolRouter, a dynamic protocol selection system. ProtocolBench systematically compares protocols (A2A, ACP, ANP, Agora) across diverse scenarios and metrics, while ProtocolRouter dynamically selects and composes protocols to optimize system performance. The authors claim that protocol choice significantly affects system reliability, efficiency, and security, and that hybrid deployments outperform single-protocol baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper addresses an important and timely problem in multi-agent LLM systems by introducing ProtocolBench and ProtocolRouter. The systematic evaluation of multiple protocols across diverse scenarios is a valuable contribution, as it highlights the practical impact of protocol choice on system performance and reliability. The experimental design is OK, with clear metrics and reproducible setups, which strengthens the credibility of the results. I appreciate the open-source release of ProtocolBench. Overall, the paper demonstrates strong engineering effort and provides useful insights for practitioners.\n\nIn summary, these are the strong points of the paper:\n* The paper tackles the understudied problem of protocol selection in LLM-based multi-agent systems, which is increasingly relevant as such systems move to production.\n* ProtocolBench provides a comprehensive, reproducible framework for evaluating protocols across multiple dimensions (task utility, communication overhead, resilience, security), filling a gap left by prior benchmarks like MultiAgentBench and AgentBench.\n* The evaluation covers realistic scenarios (document QA, streaming, fault recovery, medical privacy), uses controlled setups, and reports detailed metrics (success rates, latency, recovery times, security matrices).\n* ProtocolRouter introduces dynamic, scenario-aware protocol selection, demonstrating that hybrid protocol deployments can outperform any single protocol in success rate and performance"}, "weaknesses": {"value": "**Summary:**\n* ProtocolRouter’s learning approach assumes stationary or slowly-changing workloads, which may not generalize to highly dynamic or adversarial environments.\n* Maintaining multiple protocol states and adapters could introduce computational overhead at very large scales, which is not fully addressed or quantified.\n* Comparing protocols head-to-head may not always be fair because each protocol is designed with different optimization goals and assumptions.\n* Technical contribution is limited.\n\n**Details:**\nThe technical novelty of the paper is somewhat limited because the main contributions—benchmarking protocols and dynamically selecting among them—are engineering extensions rather than fundamentally new algorithmic ideas. While the authors correctly point out that prior benchmarks such as MultiAgentBench and AgentBench evaluate agents under a fixed protocol and do not compare protocols directly, the proposed solution builds on similar evaluation and orchestration principles already established in those frameworks. The novelty lies primarily in expanding the scope from agent-level to protocol-level, rather than introducing new theoretical constructs or protocol designs. To strengthen the contribution, the authors could complement the empirical benchmark with formal analysis or propose new protocol mechanisms beyond selection and composition.\n\nWhile the benchmarking effort is valuable, comparing protocols head-to-head may not always be fair because each protocol is designed with different optimization goals and assumptions. For example, some prioritize low latency while others emphasize robustness or security. Evaluating them under a single metric or uniform scenario can obscure these design trade-offs and lead to misleading conclusions. A more nuanced approach would be to frame comparisons in terms of goal alignment—e.g., assessing protocols within categories that share similar objectives or reporting performance relative to their intended design targets. This would provide a clearer picture of strengths and limitations without penalizing protocols for objectives they were never meant to optimize.\n\nThe scenarios included in ProtocolBench, though diverse, do not fully capture the complexity of real-world deployments. Critical edge cases such as adversarial agents, byzantine failures, and integration with non-LLM components are missing, which limits the generalizability of the findings. For instance, security evaluation focuses on privacy leakage but does not consider malicious protocol manipulation or denial-of-service attacks. Expanding the benchmark to include these challenging conditions would make the evaluation more comprehensive and relevant for production environments. Additionally, incorporating heterogeneous agent roles and mixed-modality tasks could better reflect practical use cases.\n\nThe paper does not adequately address scalability concerns when deploying ProtocolRouter in large-scale systems with hundreds or thousands of agents. Maintaining multiple protocol states and adapters could introduce significant computational overhead, yet the experiments are limited to relatively small agent groups. Without quantitative analysis of resource consumption and latency under high concurrency, it is difficult to assess the feasibility of the proposed approach for enterprise-scale applications. Including experiments on larger deployments or providing complexity bounds for protocol switching would strengthen the paper’s claims about practical applicability.\n\nProtocolRouter’s decision-making process appears largely deterministic and assumes stable workloads, which may not hold in dynamic or adversarial environments. The paper does not explore adaptive routing strategies that can respond to sudden changes in task characteristics or agent behavior. For example, online learning or multi-armed bandit algorithms could enable the router to continuously optimize protocol selection under uncertainty. Incorporating such adaptive mechanisms would improve robustness and make the system more suitable for real-world conditions where workloads and failure patterns are unpredictable.\n\nThe paper lacks formal analysis of protocol complexity, optimality, or impossibility results, which limits its theoretical depth. While empirical results are useful, they do not provide guarantees about performance under unseen conditions or adversarial settings. Related work in distributed systems often includes proofs of convergence, fault tolerance bounds, or communication complexity, which are absent here. Adding theoretical insights—such as conditions under which hybrid routing is provably better than single-protocol strategies—would significantly enhance the paper’s rigor and make it more compelling"}, "questions": {"value": "* How does ProtocolRouter handle highly dynamic or adversarial workloads where task characteristics change rapidly?\n* What is the computational and memory overhead of maintaining multiple protocol states and adapters in large-scale deployments (e.g., hundreds or thousands of agents)?\n* Have you measured latency or throughput degradation when scaling up the number of agents? If so, please share quantitative results.\n* Why were adversarial scenarios (e.g., malicious agents, byzantine failures) excluded from ProtocolBench?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hEcBQ7QtbF", "forum": "lqNqKUG2dn", "replyto": "lqNqKUG2dn", "signatures": ["ICLR.cc/2026/Conference/Submission22051/Reviewer_jgZC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22051/Reviewer_jgZC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22051/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761860202227, "cdate": 1761860202227, "tmdate": 1762942036490, "mdate": 1762942036490, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors address the critical and underexplored challenge of protocol selection in LLM-based multi-agent systems. They introduce ProtocolBench, the first systematic benchmark designed to evaluate and compare communication protocols across diverse dimensions, including task utility, latency, resilience, and security. Building on the insights from this benchmark, they further propose ProtocolRouter, a learnable, dynamic routing system that leverages an LLM to select the optimal protocol or combination of protocols for a given task. The proposed methods enable a principled, data-driven approach to optimizing multi-agent communication, moving beyond the current ad-hoc selection practices."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. Novelty and Significance: The paper tackles a highly relevant and important problem. The lack of a systematic framework for evaluating communication protocols is a major bottleneck in the field. \n\n\n2. Comprehensive and Rigorous Evaluation: The experimental design is a major strength. The authors conduct experiments across four well-chosen, diverse scenarios that stress different aspects of protocol performance. The evaluation is multi-faceted, using a comprehensive set of metrics that capture the complex trade-offs involved. The effort to control for confounding variables (e.g., by fixing the model, hardware, and setting temperature to 0) is commendable and strengthens the validity of the results.\n\n\n3. ProtocolRouter is a novel systems level component. The paper does not stop at benchmarking. ProtocolRouter is an automated planner that assigns different protocols to different modules, outputs a machine executable plan in JSON, and uses protocol bridges to enable cross protocol communication at runtime. The authors show that this heterogeneous per module composition can outperform any single protocol globally, improving combined metrics by about 6.6 percent on average and in some cases up to around 18 percent."}, "weaknesses": {"value": "1. Statistical Reporting could be Clearer: While the authors mention using statistical procedures (e.g., bootstrap CIs, Holm-Bonferroni correction) in the appendix, the main results in the tables are often presented as point estimates (e.g., averages) without confidence intervals or p-values. Directly including measures of statistical uncertainty in the main tables would make the claims of performance differences (e.g., \"statistically observable differences\") more immediately transparent and compelling to the reader.\n\n2. Lack of Deeper Qualitative Analysis: This paper could benefit from a deeper qualitative analysis of why these differences occur. For example, a more detailed, illustrative walkthrough of how A2A's hierarchical aggregation mechanism concretely leads to better performance in the GAIA task, or how ACP's design minimizes latency in the Streaming task, would provide richer insights beyond the quantitative results.\n\n3. Clarity on ProtocolRouter's Decision Process: The paper states that ProtocolRouter uses an LLM to parse scenario descriptions and select protocols. While the high-level approach is clear, more detail on the prompting strategy and the features the LLM is guided to focus on would be beneficial. For instance, how does the router handle scenarios with conflicting requirements (e.g., needing both high security and low latency)? An example of the router's “reasoning” process would be very instructive.\n\n4. Limited Scope of Models: The study, while thorough, is limited to four specific protocols (A2A, ACP, ANP, Agora) and a single LLM (Qwen2.5-VL-72B-Instruct). While these are reasonable choices, the generalizability of the findings to other foundational models (e.g., GPT-4, Claude 3) remains an open question. It would strengthen the paper to include a discussion on the potential model-dependency of protocol performance."}, "questions": {"value": "see weakness 1,2,3,4"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RXRUUbL3th", "forum": "lqNqKUG2dn", "replyto": "lqNqKUG2dn", "signatures": ["ICLR.cc/2026/Conference/Submission22051/Reviewer_A3Eq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22051/Reviewer_A3Eq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22051/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762165956314, "cdate": 1762165956314, "tmdate": 1762942036179, "mdate": 1762942036179, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}