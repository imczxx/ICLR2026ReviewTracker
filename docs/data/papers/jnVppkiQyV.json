{"id": "jnVppkiQyV", "number": 19112, "cdate": 1758293658619, "mdate": 1759897059039, "content": {"title": "Proof of Forgeability: Universal Repudiation against Membership Inference Attacks", "abstract": "Membership inference attacks (MIAs) aim to infer whether a data point was used to train a target model and are widely used to audit the privacy of machine learning (ML) models.\nIn this work, we present a new approach to asserting repudiation evidence against MIA-supported claims.\nExisting strategies require computationally intensive, case-by-case proofs. We introduce Proof of Forgeability (PoF), which denies all membership claims with an universal repudiation.\nThe key idea is to generate forged examples that are non-members yet are misclassified as members by MIAs.\nWe construct forged examples by adding carefully designed perturbations to non-members so that the attack signal distribution derived from model outputs for the forged examples matches that of members.\nTo achieve this, we use quantile matching to derive a member-like signal estimator (MLSE) that maps each non-member’s signal to its target member-like signal. We prove the optimality of this MLSE and derive closed-form expressions when the attack signal is the logit-scaled true-label confidence.\nWe then apply a first-order Taylor expansion of the signal with respect to the input to bridge the input and signal space. This relation converts the target signal change into an input perturbation and yields the designed perturbation in closed form.\nEmpirical results demonstrate that the forged examples indeed confuse the MIAs in comparison with the genuine members; meanwhile, the forged examples differ imperceptibly from the original non-members in input content while fully preserving data utility.", "tldr": "Proof-of-Forgeability  uses  member-like signal estimator to imperceptibly perturb non-members so that SOTA membership inference attacks be fooled across datasets and settings.", "keywords": ["Privacy Protection", "AI safety"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/03a8d6457d91bee6bfb0afd2015fb41225dbbc8e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper studies the problem of refuting membership inference claims, where the goal is: given a trained model, how can one craft a data record, on which a specific membership inference attack's membership inference claim is wrong.  They proposes a method that adds minimal imperceptible perturbations to non-member samples so as to produce member-like signals. To solve this problem, they perform quantile matching to identify the member score value that matches the rank of the non-member score in non-member distribution, and then prove that quantile matching is one-dimensional optimal transport in score space. Finally, they use a Taylor expansion based technique to compute the approximate direction and magnitude of input perturbation needed to move non-member signal to its corresponding member signal. Experiments show the proposed method successful forge examples that are non-member, yet state-of-the-art MIA methods fail to correctly infer as non-member."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The problem of refuting membership inference has significant implication for data usage inference and copyright, and would boost the understanding of precise meaning and limitations of membership inference attack."}, "weaknesses": {"value": "1.  The paper deem forged examples as non-member simply by input similarity to a ground-truth non-member. But this definition is flawed as membership inference targets member/non-member defined by strict game formulation and fresh randomness, **prior to releasing the trained model**. In this paper, the data records are forged after observing the trained model, making it arguable to deem them as non-member. A more convincing refutation, is to perturb data a priori to training, and then train model including/excluding the perturbed record, and show that the MIA accuracy drops to near random guess.\n2. The authors only study one direction of refuting membership inference, i.e., perturbing non-member data to make it member-like. This is arguably the less interesting case, compared to perturbing a member to make it more non-member like. Indeed, in most copyright or data usage inference problems, membership inference is used for detecting usage, rather than for arguing one did not use certain data. The authors should at least clarify why they focus on this particular direction, and how the insights could generalize to the other direction."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gnkTAgaKv7", "forum": "jnVppkiQyV", "replyto": "jnVppkiQyV", "signatures": ["ICLR.cc/2026/Conference/Submission19112/Reviewer_2uSD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19112/Reviewer_2uSD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19112/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761862712178, "cdate": 1761862712178, "tmdate": 1762931133925, "mdate": 1762931133925, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Proof of Forgeability (PoF), a defense mechanism against Membership Inference Attacks. Instead of refuting individual membership claims through computationally heavy Proof-of-Repudiation (PoR) logs, PoF proposes a universal repudiation approach: generating forged non-member examples that are misclassified by MIAs as members.\nThe key idea is to construct imperceptible perturbations on non-member samples using a Member-Like Signal Estimator (MLSE) derived via quantile matching and Taylor expansion, aligning their attack-signal distributions with members. Empirical results show that forged examples fool LiRA and RMIA attacks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The idea of leveraging adversarial perturbations as a means of repudiating membership inference is interesting. \n\n- The theoretical framework that integrates quantile matching, optimal transport, and first-order Taylor expansion is well-formulated and mathematically solid to me."}, "weaknesses": {"value": "- The evaluation focuses solely on MIAs that depend on distribution differences of output signals (e.g., LiRA, RMIA). It neglects other major categories of attacks, for example, reference-calibration-based methods (e.g., [R1]) and label-only MIAs (e.g., [R2]), which do not rely on confidence scores or logit access. Since PoF’s construction explicitly assumes access to continuous attack signals, its applicability to label-only or black-box MIAs is unclear.\n\n- The empirical section lacks crucial implementation details needed for reproducibility, such as: (1) How many non-member samples are used to generate forged examples per dataset and model; (2) The sensitivity of results to the perturbation bound \\epsilon.\n\n- The main idea—perturbing non-member inputs until they appear as members—is ethically questionable, especially since the paper explicitly uses a courtroom analogy (Figure 1).\nSuch a mechanism effectively creates falsified evidence rather than verifiable proof, which undermines the integrity of the proposed legal scenario.\n\n[R1] Watson, Lauren, et al. \"On the Importance of Difficulty Calibration in Membership Inference Attacks.\" International Conference on Learning Representations. 2022.\n\n[R2] Peng, Yuefeng, et al. \"Oslo: one-shot label-only membership inference attacks.\" Advances in Neural Information Processing Systems 37 (2024): 62310-62333."}, "questions": {"value": "- How would PoF perform against other major types of membership inference attacks, such as reference-calibration-based methods (e.g., [R1]) or label-only MIAs (e.g., [R2]), which do not rely on confidence scores or logit access?\n\n- How many non-member samples are used to generate forged examples for each dataset and model?\n\n- Does the approach risk producing falsified or misleading evidence rather than verifiable proof, thereby undermining the integrity of the intended legal scenario?"}, "flag_for_ethics_review": {"value": ["Yes, Potentially harmful insights, methodologies and applications"]}, "details_of_ethics_concerns": {"value": "- The main idea—perturbing non-member inputs until they appear as members—is ethically questionable, especially since the paper explicitly uses a courtroom analogy (Figure 1).\nSuch a mechanism effectively creates falsified evidence rather than verifiable proof, which undermines the integrity of the proposed legal scenario."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YguO8QK4Yu", "forum": "jnVppkiQyV", "replyto": "jnVppkiQyV", "signatures": ["ICLR.cc/2026/Conference/Submission19112/Reviewer_dZ9A"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19112/Reviewer_dZ9A"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19112/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761892363230, "cdate": 1761892363230, "tmdate": 1762931133170, "mdate": 1762931133170, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new approach to repudiate membership claims using membership inference, by showing membership inference attacks would falsely predict perturbed non-members as members. While it is interesting to see a paper dedicated to adversarial samples for MIAs, it falls short as a justified tool for membership repudiation."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Although known in the community, this is one of the first papers that actually presents a complete pipeline that generates adversarial data for membership inference attacks.\n2. The experiments cover all popular and the state-of-the-art MIAs."}, "weaknesses": {"value": "1. The motivation and the argument are incorrect. Showing that MIA would make mistakes on crafted adversarial data does not mean all of their other membership predictions are wrong. It is not enough to repudiate membership claims by showing MIAs make mistakes on a crafted adversarial data point that is not related to the target query. After all, all (automated) systems make mistakes, especially when used out of the designed data domains. And all MIAs have a designed false positive rate when setting their decision thresholds.\n2. The authors argued that forged data is also from the same data distribution, but this claim is not corroborated by citations and does not stand. Adversarial data distribution is known to be different from natural data distribution even it is perceptually identical for humans. This results in the proposed framework testing on OOD data, and thus much less useful as repudiation proof.\n3. Some important details of the experiments are missing. For example, the size of the $\\ell$-infinity ball is not specified in the membership inference experiment. The authors also did not explain how online attacks are done on forged data. Online models for forged data need to be trained with forged data as part of the training set. The authors did not mention training these models. If the authors used the online models for the unperturbed data, they are actually offline, not online.\n4. The main algorithm is basically an existing adversarial data generation algorithm with another objective that is based on membership inference signals. This significantly limits the novelty of the approach.\n5. The writing is unscientific in several parts of the paper, especially in the introduction. A few words and sentences are written in an unnecessarily convoluted way. For example, ”mistakes the secondary for the primary\" and \"We answer in the affirmative\"."}, "questions": {"value": "1. As mentioned in the weakness, the membership repudiation framework is not valid. To repudiate that model $f$ did not train on $x$, you need to show evidence that $f$, which is the observation, can be obtained without using $x$. This is the method used in the prior works (e.g. Kong et al. 2022). Your proposed framework argues MIAs on $f$ will make mistakes on specifically crafted data $z$ that is unrelated to $x$. This does not directly lead to the conclusion that $f$ is not trained on $x$. Hence, the proposed framework needs a redesign. I would suggest going along the false positive rate of MIAs.\n2. What is the threat model? It seems that you need white-box access to the target model, training and test datasets, and the MIA used in membership claims to obtain IN and OUT signals for every data and to perform adversarial perturbation. If so, you can directly check the membership of your data query without using any MIA. \n3. Given that adversarial data distribution is not identical to natural data distribution, forged data are essentially OOD data and it is not surprising for MIAs to misclassify them. What is your justification of using misclassified forged data as repudiation?\n4. How do you launch online LiRA and RMIA on forged data as there are no reference models trained on forged data?\n5. RMIA's signal is the percentage of population data points dominated by $x$, which is not Gaussian. How does your method, which assumes Gaussian, apply to RMIA?\n6. “logit-scaled TLC\" -> do you mean rescaled logits?\n7. In the problem formulation, why is the model's output domain K-1 dimensional when there are K output classes?\n\n**Minor comment**:\n\n1. Besides images, how does the forging mechanism work on tabular data where the data is mostly categorical or binary values?\n2. The citation for RMIA should be the ICML version instead of the arxiv version.\n3. Kong et al. 2023 should be Kong et al. 2022\n4. L465 da ta -> data"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PzIo8AWLpb", "forum": "jnVppkiQyV", "replyto": "jnVppkiQyV", "signatures": ["ICLR.cc/2026/Conference/Submission19112/Reviewer_6hLQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19112/Reviewer_6hLQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19112/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954860769, "cdate": 1761954860769, "tmdate": 1762931132797, "mdate": 1762931132797, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of repudiation in membership inference, showing that non-member samples can be transformed into forged members that are misclassified as members, thereby undermining the reliability of membership inference conclusions. The proposed method adds adversarial perturbations to non-member samples so that their membership signals resemble those of true members. Experiments demonstrate the effectiveness of the approach in achieving successful repudiation and reducing the credibility of membership inference results."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written, clearly structured, and easy to follow.  \n2. The proposed method is simple yet effective and intuitive. By constructing non-member samples that are misclassified as members, the work introduces a novel and practically meaningful way to repudiate membership inference results.  \n3. The paper provides both theoretical analysis and empirical evidence. Experiments are conducted using state-of-the-art MIA methods and demonstrate strong effectiveness, with attack performance (e.g., AUC) approaching random guessing after applying the proposed method."}, "weaknesses": {"value": "1. The proposed method appears to be optimized primarily for RMIA and LiRA. Although these are state-of-the-art MIAs, it is unclear how well the approach generalizes to other classes of attacks, such as simple loss-based methods that do not rely on a reference model.  \n\n2. The paper does not discuss label-only MIAs [1][2][3][4], which also achieve strong performance and rely on label-based signals rather than loss or confidence. Since both label-only MIAs and the proposed repudiation approach introduce adversarial perturbations to the original samples, it is unclear whether these perturbations may interfere with each other and whether the proposed technique would remain effective under such conditions.  \n\nOverall, the paper is well-written and technically sound, with few major weaknesses. To further strengthen it, the authors might consider:  \n- Adding visual examples comparing non-member and forged samples to better illustrate the imperceptibility of the perturbations.  \n- Including a brief case study or qualitative example showing how the method alters the MIA signal and affects the final inference conclusions.  \n\n[1] *Label-Only Membership Inference Attacks*, ICML 2021  \n[2] *Membership Leakage in Label-Only Exposures*, CCS 2021  \n[3] *You Only Query Once: An Efficient Label-Only Membership Inference Attack*, ICLR 2024  \n[4] *OSLO: One-Shot Label-Only Membership Inference Attacks*, NeurIPS 2024"}, "questions": {"value": "1. Would adversarial purification methods, such as DiffuPure [1], affect the effectiveness of the proposed repudiation approach?  \n\n[1] *Diffusion Models for Adversarial Purification*, ICML 2022"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R3BC3gvad7", "forum": "jnVppkiQyV", "replyto": "jnVppkiQyV", "signatures": ["ICLR.cc/2026/Conference/Submission19112/Reviewer_r3Y6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19112/Reviewer_r3Y6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19112/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982377769, "cdate": 1761982377769, "tmdate": 1762931132356, "mdate": 1762931132356, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}