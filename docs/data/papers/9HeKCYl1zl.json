{"id": "9HeKCYl1zl", "number": 12546, "cdate": 1758208487986, "mdate": 1759897502535, "content": {"title": "Auto-Regressive Surface Cutting", "abstract": "Surface cutting is a fundamental task in computer graphics, with applications in UV parameterization, texture mapping, and mesh decomposition. However, existing methods often produce technically valid but overly fragmented atlases that lack semantic coherence. We introduce SeamGPT, an auto-regressive model that generates cutting seams by mimicking professional workflows. Our key technical innovation lies in formulating surface cutting as a next token prediction task: sample point clouds on mesh vertices and edges, encode them as shape conditions, and employ a GPT-style transformer to sequentially predict seam segments with quantized 3D coordinates. Our approach achieves exceptional performance on UV unwrapping benchmarks containing both manifold and non-manifold meshes, including artist-created, and 3D-scanned models. In addition, it enhances existing 3D segmentation tools by providing clean boundaries for part decomposition.", "tldr": "An auto-regressive approach that generate seams for surface cutting,  with applications in uv parametrization and 3d part decomposition.", "keywords": ["surface cutting", "Mesh UV unfolding", "3D part segmentation", "auto-regressive generative model"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d87b1e80941da51be1de34768e5f39a76d6bc175.pdf", "supplementary_material": "/attachment/7575895ebc157bc08b4c88192c6cfc2409646e6d.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes SeamGPT, an auto-regressive transformer model for generating surface-cutting seams on 3D meshes.\nThe authors reformulate surface cutting — a classic problem in UV parameterization and mesh segmentation — as a sequence generation task, treating each 3D coordinate of a seam segment as a discrete token predicted autoregressively.\nA point-cloud encoder encodes sampled vertices and edges into a latent shape embedding, which conditions a GPT-style hourglass transformer decoder to sequentially predict seam coordinates.\nThe method is trained on a large dataset (≈560K artist-annotated meshes filtered from Objaverse/3D-Future) and evaluated on UV unwrapping and part segmentation benchmarks.\n\nWhile the paper presents a polished system and thorough experiments, the core technical novelty is minimal. Most components (point-cloud encoder, quantization, autoregressive transformer, hourglass hierarchy) are directly adopted from existing works such as MeshGPT (Siddiqui et al. 2023) and Meshtron (Hao et al. 2024) with only superficial adaptation to a new task.\nAs a result, the overall contribution feels incremental and more of an application of existing sequence modeling methods than a fundamental advance in 3D geometry understanding."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper’s strength lies mainly in its problem framing rather than architectural innovation. It takes an established operation in computer graphics—surface cutting and UV unwrapping—and recasts it as an auto-regressive generation task. This conceptual reformulation is novel from a modeling perspective and has some intuitive appeal, as it parallels how artists progressively define seams in practice. The proposed workflow is well structured and technically sound: it integrates a point-cloud encoder to extract shape features and a transformer decoder for coordinate generation, both of which are established and well-tested components. The experimental section is extensive, evaluating across multiple benchmarks (FAM, Toys4K, AI-generated meshes), with both quantitative metrics and qualitative visualizations. The results consistently show that SeamGPT can produce fewer fragmented UV charts with comparable or slightly lower distortion compared to baseline methods. The inclusion of user studies with professional artists is also commendable, as it adds a perceptual validation dimension to the otherwise geometric evaluations. The paper is generally well written and easy to follow, and the authors provide sufficient implementation details for reproduction."}, "weaknesses": {"value": "Despite a polished presentation, the paper’s technical novelty and empirical contributions are quite limited. The proposed framework is almost entirely composed of pre-existing components: the point-cloud encoder is borrowed from standard 3D transformer models, and the auto-regressive decoder closely follows prior work such as PolyGen, MeshGPT, and related sequence models for 3D geometry. The only distinct aspect—the reformulation of cutting seams as quantized coordinate sequences—feels incremental rather than conceptually new.\n\nMore concerning, the experimental results do not convincingly support the claimed superiority. In Tables 2 and 3, SeamGPT’s distortion metrics are often worse than or comparable to XAtlas, which is a purely geometric non-learning baseline. For example, on several FAM models (e.g., Bimba, Dragon, Happy Buddha) and most Toys4K categories, XAtlas yields lower distortion. The authors highlight fragment reduction, but this is a side effect of predicting fewer seams rather than genuine geometric improvement. The evaluation lacks a rigorous statistical analysis or significance testing, and the results fluctuate widely across categories."}, "questions": {"value": "- Why does SeamGPT perform worse than Xatalas in distortion metrics on many test cases if its purpose is to improve UV quality?\n- How sensitive are the results to the quantization resolution and seam-length control parameter?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eB3P6rtxeN", "forum": "9HeKCYl1zl", "replyto": "9HeKCYl1zl", "signatures": ["ICLR.cc/2026/Conference/Submission12546/Reviewer_4sRE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12546/Reviewer_4sRE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761549117389, "cdate": 1761549117389, "tmdate": 1762923408062, "mdate": 1762923408062, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a GPT-based auto-regressive model to infer and generate cutting seams derived from data. The surface cutting problem is turned into a next token prediction task and a language-like learning is conducted to infer seams. The experiments on several meshes demonstrate the seams inferred this way can better align artists' preferences."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Overall, it's a good idea and a low hanging fruit to approach seam cutting through a GPT-like architecture. \n- I believe that the results are accurate and good quality can be achieved this way. \n- The paper clearly describes the approach and except some doubts on implementation (see below) the work seems to be reproducible."}, "weaknesses": {"value": "- Abstract claims exceptional performance. This is not validated by the experiments. Please tone down.\n- Missing baselines (See Q1). \n- UV texturing can introduce bad seams. There are some new works that discuss and alleviate this problem. See: \nFoti, S., Zafeiriou, S., & Birdal, T. Uv-free texture generation with denoising and geodesic heat diffusion. NeurIPS 2024. More on this in Q3 below. \n- Ordering (for example yzx) is rotation dependent and there seems to be no treatment of this. See Q4.\n- Large triangles seem to be problematic for this work. Point cloud networks that operate on mesh vertices will fail if the surface is not resampled. Large triangles will also cause more errors in the seams which are directly defined over edges / vertices. See Q6. \n- In principle, edges have infinite number of points whereas vertices are finite. Even sampling on both does not seem justified. This must be studied in a controlled manner. See Q7.\n- I'm not sure if qualitative examples in Fig. 3 are conclusive enough to justify the 'artistic' quality superiority.\n- Appendix seem to report that SeamGPT is faster in runtime, whereas table 1 shows that it's slower. There seems to be some inconsistency or not consistent benchmarking of runtime.\n- Paper uses graph convolutions as baselines for mesh processing. This is not okay. I suggest comparing to any mesh convolution based network. \n- Before making conclusive statements, I would like to see the results before Blender's minimum stretch algorithm is applied. One needs to gauge how much of the actual contribution is coming from this. In fact, this should be applied to other methods as well, for a fair comparison. \n- Social impact: This work is not theoretical. It has immediate practical application and can be used by artists. As such, I invite the authors to think a little about the implications of their work rather than dismissing this mandatory section. We owe this much to our community. \n\nMinor weaknesses:\n- Ln. 41: flatten -> flattening\n- Ln. 64: init -> initialize\n- Ln. 203: S has to be ordered, not a set. This is true for all in Eq. 1. In fact I'm not sure if Eq. 1 is actually needed. It is covered in preceding paragraph. \n- Ln. 267: Isn't H20 96GB? (text says 98)\n- Ln. 367: S was reserved for sequence, now used for depicting a 3D shape\n- \"Does pointer networks work?\" section is not an ablation study. Please use the term correctly."}, "questions": {"value": "1. What about a non auto-regressive method based on for example diffusions? Can we make a simple baseline and compare?\n2. Will the authors make the filtered dataset public? (Maybe indices of the models?)\n3. UV-parameterization naturally suffers from introducing arbtirary seams that are not meant to be in the original shape. So what about these seams that had to be there not because of semantics but because of the drawbacks of UV? \n4. How are rotations of the meshes handled? An equivariant network? It feels like data augmentation would just cause additional problems here. \n5. How is the quantization in Ln. 219 precisely done? \n6. What about large triangles? How are those handled? Are there different resampling strategies? Any of these ablated? \n7. Why are the points on vertices and edges evenly split? What about other ratios?\n8. Does the paper compare to MeshGPT encoder? \n9. How about using a test set that is split from the training set in the experiments? Did the authors try this? \n10. In experiments, why is distortion an indicator of semantic superiority?  \n11. How is the seam lines are used to partition the shape into P_i as in Ln. 374?\n12. I don't see any reason why seams should align with semantic 3D parts of the objects. Could this be justified?\n13. Can we have quantitative results corresponding to Fig. 5 and maybe compare with some other sampling methods? \n14. How is R chosen in practice? I mean the actual value."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RPKa9jal8n", "forum": "9HeKCYl1zl", "replyto": "9HeKCYl1zl", "signatures": ["ICLR.cc/2026/Conference/Submission12546/Reviewer_5xei"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12546/Reviewer_5xei"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761847900414, "cdate": 1761847900414, "tmdate": 1762923407702, "mdate": 1762923407702, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper formulates surface cutting as a next token prediction task, and designs a novel auto-regressive architecture that predicts seam coordinate sequences from a given mesh."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper proposes a new paradigm for surface cutting, which formulates surface cutting as a next token prediction task. The idea is novel, and the results are pretty good.\n2. Surface cutting is a very important task in 3D understanding. It essentially finds the best way to geometrically segment a 3D surface into parts (with different criteria). With the part information, it potentially boosts a variety of downstream tasks, such as semantic segmentation (as demonstrated), texture editing, rendering, generation, animation, articulated objects, etc. Hence, the contribution of this paper to the community is significant in my opinion."}, "weaknesses": {"value": "1. As the method is trained purely supervised by ground truth cuttings, the quality of the ground truth cuttings matters a lot, and the model might be sensitive to the poor samples. As the authors mentioned, a rigorous filtering process was applied to clean the data. Thus, scaling up the dataset may be laborious. \n2. Some details about the paper are not clearly described, which I will mention in the question section."}, "questions": {"value": "1. How does the number of sampled points affect the performance?\n2. How to choose K at line 244?\n3. In the data augmentation, how large a portion will the masked region be? Is the method able to predict seams for a part of the object (instead of feeding in the whole point cloud, feed in a point cloud sampled from a part of the object)? \n4. The topologies of the objects shown in the paper are fairly simple. How are the generated cuttings for objects with complex topologies? Is this limited by the number of mesh faces?\n5. Instead of controlling the segment count by the seam length, is it possible to do this hierarchically? For example, predict basic seams that cut the surface into a small number of segments, and then cut each of the large segments into smaller segments hierarchically.\n6. Will the dataset and code be open-sourced?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "VtQs7lbSk1", "forum": "9HeKCYl1zl", "replyto": "9HeKCYl1zl", "signatures": ["ICLR.cc/2026/Conference/Submission12546/Reviewer_nRhE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12546/Reviewer_nRhE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761891207081, "cdate": 1761891207081, "tmdate": 1762923407250, "mdate": 1762923407250, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SeamGPT, an auto-regressive model for 3D surface cutting and UV unwrapping. The method reformulates surface cutting as a sequence generation problem, where cutting seams are predicted token by token within a quantized 3D space. SeamGPT achieves strong results on both UV parameterization and part segmentation benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The idea of framing surface cutting as an auto-regressive sequence prediction task is novel and well-motivated. The integration with PartField yields particularly clean and semantically coherent part boundaries, leading to visually impressive segmentation outcomes. The approach also demonstrates solid generalization across datasets and diverse mesh types."}, "weaknesses": {"value": "The method section would benefit from additional toy visualizations to clarify the intuition behind the sequence representation and the quantization/tokenization strategy. Some architectural details (such as hierarchy levels and quantization schemes) could be illustrated more intuitively to help readers grasp the overall process."}, "questions": {"value": "Could the authors add simple illustrative examples (e.g., 2D surfaces or flat cubes) to show how the auto-regressive process operates geometrically and how seams are tokenized?\n\nSince vertex coordinates are quantized and generated sequentially, could BPT-style point compression or token sparsification be integrated into SeamGPT’s decoder to improve efficiency?\n\nDuring data preparation, did the authors consider incorporating feature-line extraction or curvature-sensitive priors beyond UV seams to better capture subtle geometric cues?\n\nThe fandisk example shows missing curved boundaries, would integrating differential geometric features (such as curvature flow) help improve seam placement in such cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qBHyxtpD4j", "forum": "9HeKCYl1zl", "replyto": "9HeKCYl1zl", "signatures": ["ICLR.cc/2026/Conference/Submission12546/Reviewer_fdf2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12546/Reviewer_fdf2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12546/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762329569263, "cdate": 1762329569263, "tmdate": 1762923406916, "mdate": 1762923406916, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}