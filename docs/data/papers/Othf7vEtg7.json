{"id": "Othf7vEtg7", "number": 8609, "cdate": 1758092518393, "mdate": 1759897773521, "content": {"title": "MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation", "abstract": "Compositionality is critical for 3D object and scene generation, but existing part-aware 3D generation methods suffer from poor scalability due to quadratic global attention costs when increasing the number of components. In this work, we present MoCA, a compositional 3D generative model with two key designs: 1) importance-based component routing that selects top-k relevant components for sparse global attention, and 2) unimportant components compression that preserve contextual priors of unselected components while reducing computational complexity of global attention. With these designs, MoCA enables efficient, fine-grained compositional 3D asset creation with scalable number of components. Extensive experiments show MoCA outperforms baselines on both compositional object and scene generation tasks.", "tldr": "A scalable compositional 3D generation framework for fine-grained part-composed object or instance-composed scene generation.", "keywords": ["Compositional 3D Generation", "Latent Diffusion Models", "Sparse Attention"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bdb4b590dde210d054abc58d39649c1164d8cb50.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a new method for compositional 3D generation. The authors identity that part-aware 3D generation suffers from poor scalability due to the quadratic complexity of attention-based models. The authors therefore proposed to use mixture-of-experts to route the most important components and compress distant components to achieve linear complexity. The authors evaluated their method on both object-level and scene-level 3D generation tasks to demonstrate the effectiveness of their methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-motivated and technically sound.\n- The use of MoE in 3D generation is interesting and effective."}, "weaknesses": {"value": "- The generated results in Figure 3 are less detailed compared to baselines like PartCrafter. The surface is much smoother.\n- The comparison is relatively limited compared to papers like PartCrafter, which compared on different datasets like Objaverse, ABO etc.\n- Visual results and 3D results are fairly limited. Would love to see more 3D rendering results."}, "questions": {"value": "I would love to see the authors provide more comparison and video results. I would also like to see the explanations of loss of details in reconstruction."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TbYA8GZqV2", "forum": "Othf7vEtg7", "replyto": "Othf7vEtg7", "signatures": ["ICLR.cc/2026/Conference/Submission8609/Reviewer_ELxf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8609/Reviewer_ELxf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8609/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761679586820, "cdate": 1761679586820, "tmdate": 1762920449987, "mdate": 1762920449987, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates part-composed 3D object and scene generation, an important and timely problem in 3D vision. The approach leverages the availability of high-quality modern 3D datasets. The authors propose a transformer-based model (arguably over-complicated) trained with flow matching to learn the distribution of shape latents. Each part is encoded and decoded in SDF representation, while image and text conditions can be incorporated into the diffusion transformer. Only a few examples are shown, also demonstrating synthetic image to compositional 3D generation."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- Although the method itself is standard, the results appear strong, largely due to the high quality of current datasets rather than novel modeling contributions.\n- The focus on structured, compositional 3D generation is a meaningful and valuable research direction that deserves further attention."}, "weaknesses": {"value": "- The transformer design lacks novelty and is quite widely used and studied in the literature of scene generation and part-based 3D object generation. Given the small latent space (fewer than 100 parts), any sufficiently large transformer could model the distribution; the architectural choices do not seem critical. I would believe this is a \"fake\" contribution.\n- The reported results are not diverse, raising concerns about overfitting to the dataset.\n- The paper only evaluates on synthetic data and generated images no real image experiments are provided."}, "questions": {"value": "- Main question: What is the real contribution of this paper to the community?\n- Secondary: How does the method ensure diversity and handle real data?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gWAecK2n7W", "forum": "Othf7vEtg7", "replyto": "Othf7vEtg7", "signatures": ["ICLR.cc/2026/Conference/Submission8609/Reviewer_oLgj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8609/Reviewer_oLgj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8609/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761873866449, "cdate": 1761873866449, "tmdate": 1762920449531, "mdate": 1762920449531, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MoCA, a compositional 3D generative model for efficient, scalable, and accurate compositional modeling of 3D objects and scenes."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed Mixture-of-Components Attention is well motivated for addressing the quadratic global attention cost.\n\n2. Complete ablations: All design choices (compression, gating, activation, multi-head routing) are completely ablated.\n\n3. Strong performance: better experimental results have been observed against baselines like PartPacker, PartCrafter, MIDI"}, "weaknesses": {"value": "1. No apperance: It seems that all methods, including baselines, only generate meshes without textures, which might limit the real-world applications. Can the authors provide more details about this?"}, "questions": {"value": "Runtime analysis: It would be better to include a breakdown of runtime about different procedures of the proposed pipeline and compare against other baselines to demonstrate the efficiency."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mgo7MwFMNK", "forum": "Othf7vEtg7", "replyto": "Othf7vEtg7", "signatures": ["ICLR.cc/2026/Conference/Submission8609/Reviewer_Dfrs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8609/Reviewer_Dfrs"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8609/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893619435, "cdate": 1761893619435, "tmdate": 1762920448978, "mdate": 1762920448978, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "TLDR: using routers to select top relevant tokens between parts to avoid full attention, enables larger number of parts generation.\n\nThis paper proposes a new approach to the image to 3D parts problem. It tries to generate more parts than previous work by using routers to select top relevant tokens between parts to avoid full attention, which is inspired by the router mechanism in the Mixture-of-Experts (MoE) methods.\n\nThis can effectively reduce the memory requirement and hence support up to 30 components generation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Good motivation: The most challenging aspect of part generation is having a large number of parts. This works tries to improve performance on such important task.\n- Good results. The method can generate more parts than previous work.\n- Sound technical approach. The general design of the method is sound. And the idea of using routers is interesting."}, "weaknesses": {"value": "- Complicated system. The system seems to be very complicated, and the technical details are hard to read. Method pipeline figure is challenging to understand - Maybe a better way is to decompose the figure into multiple figures so it is easier to understand part by part.\n- Limited insight. Although the Routing mechanism seems valid, it is a general method and the author does not further utilize properties that are unique to 3D part structures."}, "questions": {"value": "- Why the part geometry quality degrade significantly when the number of parts are increased? In figure 6, shapes start to be scattered and broken for part number to be 30.\n- Also in figure 6, we show the parts clearly get disconnected from each other (the feet and the legs), please provide more analysis on this limitation and give potential ideas to solve\n- What if you don't use routing scheme at all? How do you compare your model removed the routing mechanism. The results should be better since it will use full attention, but what will be the difference, and how do you compare the results when you have same number of parts, like 30, but with smaller number of tokens per part so the parts can fit in the memory, will it have similar results as the scattered ones you have shown in figure 6?\n\nIf the author can better understand how routing contributes to the existing approach, I would consider to raise my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CiffhKRTvh", "forum": "Othf7vEtg7", "replyto": "Othf7vEtg7", "signatures": ["ICLR.cc/2026/Conference/Submission8609/Reviewer_sfEm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8609/Reviewer_sfEm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8609/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943196584, "cdate": 1761943196584, "tmdate": 1762920448505, "mdate": 1762920448505, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}