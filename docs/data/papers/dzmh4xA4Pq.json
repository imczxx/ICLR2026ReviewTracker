{"id": "dzmh4xA4Pq", "number": 9388, "cdate": 1758120822230, "mdate": 1763467426816, "content": {"title": "Entropy-informed Decoding: Adaptive Information-Driven Branching", "abstract": "Large language models (LLMs) achieve remarkable generative performance, yet their output quality is dependent on the decoding strategy. While sampling-based methods (e.g., top-$k$, nucleus) and search-based methods (e.g., beam search) can improve upon greedy decoding, both approaches suffer from limitations: sampling commits to a single path, while search often expends excessive computation regardless of task complexity. We introduce Entropy-informed DEcodiNg (EDEN), a plug-and-play, model-agnostic decoding framework that adaptively allocates computation based on the model’s own uncertainty. At each generation step, EDEN estimates the entropy of the output token distribution and adjusts the branching factor monotonically with the entropy, expanding more candidates in high-entropy regions and following a greedier path in low-entropy regions. This dynamic allocation improves search efficiency without requiring additional training, external rewards, or architecture changes. For closed-source models, we provide theoretical bounds on the number of samples needed to estimate entropy within a target error, ensuring robust branching under limited API access. Experiments across complex tasks, including mathematical reasoning, code generation, and scientific questions, demonstrate that EDEN consistently improves output quality over both fixed-parameter sampling and fixed-width search, achieving better trade-offs between accuracy and computational cost. By treating next token selection as a noisy maximisation problem, we prove that branching factors monotone in entropy are guaranteed to find better (i.e. more probable) continuations than any fixed branching factor within the same total computation budget.", "tldr": "", "keywords": ["decoding", "search", "branching", "beam search", "adaptive"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0ce8b2b717313c98041bca43d7556c81f8d47cbf.pdf", "supplementary_material": "/attachment/61b78ec33f226d1b7461d113710b50aec03450a3.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose an adaptive beam search strategy which adjust the amount of branching based on the entropy of the next-token distribution. They provide a theoretical analysis that justifies their design and gives guarantees about the optimality of their method. Finally, they show that in the restricted API setting, the method continues to work because top-k probabilities allow for robust estimation of next-token distribution entropy even for modest k."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The subject matter is interesting, the method makes sense, the theoretical analysis seems reasonable. I like that the method requires minimal hyperparameter tuning (basically, just need to set the maximum budget)."}, "weaknesses": {"value": "I am concerned about the novelty of the method. A cursory search by ChatGPT surfaced Lin et al. (2018) who propose a method that adapts the beam search width based on the model's probability assigned to the search paths. Their method appears to be less theoretically justified and does not explicitly use entropy, but the kernel of the idea is there: search less when the model is confident, search more when it is unsure. I noticed that the related work section cites no papers prior to 2024, which is a red flag to me, since beam search and other decoding methods predate this by a wide margin. What other methods exist that adjust beam width based on entropy (or proxies of entropy)?\n\nThe Lipschitz assumption strikes me as something that can be empirically supported. Is there a reason that you do not? It would make your choice much more justified if you could show that the assumption holds generally for some specific language models.\n\nAs far as I can tell, you do not seem to address one of the major shortcomings of MAP decoding approximations like beam search, namely that the most likely sequence is not necessarily natural (Stahlberg et al. 2018). While this is not specific to your method, (it afflicts beam search as well) it might be misleading to claim that your method trumps sampling methods like top-k/p. In the specific task of factual question answering, math, and coding tasks, MAP is known to do well, but in more open-ended tasks and creative tasks, sampling methods often win. \n\nUpon further consideration, your results showing that your method beats sampling methods (like top-p/k) are nothing new, these same results would manifest themselves were you to just use beam search. The advantage of your method over existing methods, as I understand it, is that it allows for a more *efficient* beam search, with the same expected outcome of beam search with a correspondingly large width budget. Therefore, I would recommend that you frame your work solely around an efficiency comparison with beam search. I think the comparisons with sampling methods are out of scope, perhaps irrelevant, unless you have something new to add to conversation about MAP vs. sampling.\n\n[1] Lin, Yu-Hsiang et al. “Adaptive Beam Search in Sequence-to-Sequence Models.” (2018).\n\n[2] Stahlberg, Felix and Bill Byrne. “On NMT Search Errors and Model Errors: Cat Got Your Tongue?” ArXiv abs/1908.10090 (2019): n. pag."}, "questions": {"value": "Questions embedded in weakness section. As it stands, I would be willing to raise my score if my above concerns are addressed. Despite my criticisms, I actually do like this paper. The main problem is that the presentation may be misleading and mischaracterize the state of the field and its contributions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rtoUgfQT0Y", "forum": "dzmh4xA4Pq", "replyto": "dzmh4xA4Pq", "signatures": ["ICLR.cc/2026/Conference/Submission9388/Reviewer_s9ME"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9388/Reviewer_s9ME"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9388/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761943308827, "cdate": 1761943308827, "tmdate": 1762920999112, "mdate": 1762920999112, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a simple variant of beam search in which the beam size grows monotonically at each node with the entropy of the model. The paper provides theoretical analyses using a model of risk of missing the argmax, as well as some analysis of using their method when one has only sampling ability from an API. The paper provides compute-matched comparisons with beam search, and non-compute-matched comparisons with sampling algorithms like top-p. Evaluations are run on humaneval, gsm8k, and math500. The authors also run experiments in a simulated API setting and run a synthetic noise-dependence study."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "This paper provides a really nice simple algorithm for adaptively spending more compute while generating from language models. I think it’s well-motivated, clearly described, and while I don’t draw too much insight from the theory because it rests on premises I don’t think really hold, I still found the theoretical discussion thought-provoking, so I consider the theory a win overall. If this method is a better use of compute than sampling multiple times from a model with top-p, this would be a great contribution. Unfortunately, we just don’t know if this is the case (see below.)"}, "weaknesses": {"value": "The summary here is that I really want to like this paper but in order to draw conclusions from it, I need the core experiments to be stronger, in particular by comparing EDEN not just to beam search but to methods in which we use a large p in top-p and sample multiple times from a model and take the best or most likely under the model (which is a standard way to spend more compute on finding good generations under a model.) I also don’t feel like I can conclude too much from the theory (details below,) but I consider this not a huge issue.\n\nI was really hoping that the experiments would include compute-matching between not just EDEN and beam search, but also between EDEN and sampling methods like top-p. Calling methods like top-p (or min-p, or even top-k) “not entropy-adaptive” seems just wrong. Indeed, if one considers sampling multiple times from each model, then they’re all adaptive on entropy. Indeed, by computing multiple full sequence-level samples from each model under each sampling method and then taking the highest-likelihood under that set, all of these methods adaptively explore “more” in expectation from prefixes for which the model being sampled from has high conditional entropy. Computing these most-likely-of-n metrics for sampling is standard, and one can compute-match by matching the expected number of conditional distributions one must compute for each (e.g., num_samples*seq_len for the sampling methods.) On this note, using temperature=0.6 with top-p=0.9 is really really close to greedy decoding in many circumstances, so if you compare in this setting, you should make sure to sample from a wider distribution (e.g., top-p 0.95, temperature=1)\n\nOn that note, just a few more models – especially stronger models! – evaluated in Table 1 would be a great use of space to make the experiments stronger. Testing just a single model is not preferable.\n\nThe entropy as a proxy for hardness doesn’t make a lot of sense in distributions with desirable – aleatoric – uncertainty, e.g., building a good model of text means generating many things for the prefix “My name is” but this has nothing to do with the computational hardness of the problem. The analysis and lemmas provided in section 3 have the assumption that there’s a single correct candidate, which is not true. Overall I found the analysis nice and thought-provoking, but the setting just doesn’t reflect LM use. The method — “use a larger beam when there’s more uncertainty, independent of the source of that uncertainty” is nice! But the theory provided doesn’t make it better-motivated.\n\nRarely in modern APIs can we just sample a single token continuation (as opposed to a whole rollout) – rolling out full sequences to estimate each prefix’s entropy would be very expensive – so I’m not sure of the relevance of the closed-model parts of this paper.\n\nThe noise model (in embedding space) used for the sensitivity analysis doesn’t make a lot of sense – robustness to embedding noise isn’t necessarily related to real noise distributions – and claims about the connections between paraphrase noise and this don’t make a lot of sense to me because we certainly don’t know what the lipschitz constants of deep networks are (especially with layer norm), and even then small changes in the tokens provided can lead to hard-to-characterize changes in the output distribution."}, "questions": {"value": "Notes\n- Around 170, it’s odd to have the notion of the entropy of the conditional distribution for a prefix y_{1:t} have the next word y_{t+1} – the entropy (as in the definition you give) does not depend on the real next word y_{t+1}.\n- It’s not the case that the highest-probability sequences under a model are the highest-quality – e.g., they assign very high probability to repetitive strings. It would be nice to briefly discuss the conditions under which we do want to maximize probability. The heuristics in top-p seem useful in part because they seem to avoid issues that come up when we try to find the argmax in a high-entropy setting with LLMs (I realize finding the argmax is an intuitive thing to want to do, but indeed it seems like not what we want to do even if we could in mondern times.)\n- How is temperature=0.6 default? Where is the default set? I guess I'm saying I don't think most papers use temp=0.6.\n- Not required, but it would be nice to cite and briefly discuss Optimal Beam Search for Machine Translation (Rush et al., 2013) in your discussion of your beam pruning strategy.\n- I think the delta-greedy row in Table 1 is odd – why are you showing the difference to the cheap greedy method, not the compute-matched Beam search baseline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "1cvcRt4QCS", "forum": "dzmh4xA4Pq", "replyto": "dzmh4xA4Pq", "signatures": ["ICLR.cc/2026/Conference/Submission9388/Reviewer_rgbd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9388/Reviewer_rgbd"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9388/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761948250868, "cdate": 1761948250868, "tmdate": 1762920998612, "mdate": 1762920998612, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a new decoding strategy, EDEN, which is an adaptive form of mode-seeking search. At each decoding step, the number of expansions for each candidate is determined by the entropy of the logits distribution (and a fixed maximum width), with higher entropy completions being expanded to more candidates and lower entropy completions being expanded to less candidates. EDEN outperforms beam search in 1B-3B models with substantially less candidates expanded."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. I think this is a really nice idea-- it's intuitive and thoroughly justified in the text, and clearly reduces the number of expansions dramatically with improved output quality (e.g. in Figure 3).\n\nS2. The paper has some thoughtful treatment of settings where the entropy distribution is modified by some other decoding strategy, justifying its claim that it can be used in conjunction with temperature or truncation based decoding strategies.\n\nS3. The paper makes an intriguing claim that the method could still work on a model where the logit distribution is not available, such as for closed-source models. I like the framing of presenting Llama results with and without this closed source assumption to compare the performance degradation, although I also have feedback on this section in W3 below."}, "weaknesses": {"value": "W1. Some statistical testing should be performed on all results, especially since many of the values in Table 1 are quite close between beam search and EDEN. Bootstrapped confidence intervals would be helpful here. \n\nW2. I am not convinced by the argument about efficiency starting on line 351. The paper acknowledges in the limitations that there's an additional time penalty for looking at entropy, and heterogenous branching may be harder to balance. The time is the real concern to me-- can you graph wall clock time of beam search vs EDEN vs sampling? It's okay if EDEN isn't the fastest, but this is the real tradeoff, not the number of expanded paths. \n\nW3. While I'm sympathetic to the expense of using large or API-based models, I think if you are proposing a decoding strategy, you must provide some evidence of its behavior at a more typical scale. This doesn't have to be massive models, and this doesn't need to be every experiment, but we know that decoding methods behave differently when the base model has different capabilities (e.g. beam search outperforming sampling by this much is a bit of an artifact of only evaluating on small models). I'd really like to see two things:\n* Some experiments comparing sampling to beam search to EDEN on a 7-8B model; for inference at half precision, this should likely fit on a 16GB GPU. \n* Lower priority than the above, but I think the closed source LLMs argument is really interesting and would be *far* more compelling if you could also demonstrate on a small scale on a closed source model. OpenAI's current cheapest model (gpt-4.1-nano) is $0.10 per 1M input/\\$0.40 per 1M output tokens. The simulation of the black-box model in Figure 7 is using 100 random examples from GSM-8k; if you use 1000 tokens per example (600 input + up to 400 output), that would cost ~\\$0.03 to run per decoding method! That can be halved if you run batch requests.\n\nW4. More diverse benchmarks would be nice, but that's the most minor of my critiques by far."}, "questions": {"value": "In general I'm actually quite positive about this idea, although there are a number of clarifications or additional pieces of evidence I'd really like to see. I'm happy to revise my score after discussion if these concerns are addressed. \n\nQ1. While I'm generally convinced by your continuity assumption argument, I don't follow the argument in lines 836-837. Why is normalized log-likelihood bounded (other than being trivially bounded above by 0)? Why mention temperature scaling as an example here, especially since most experiments in the paper are run without it?\n\nQ2. Can you provide benchmarking of the efficiency of the method in some metrics other than number of paths expanded? Wall clock time is the one I'd most like to see, though maximum VRAM allocation would also be interesting. \n\nQ3. How does EDEN scale to 7B models?\n\nQ4. Does the closed source performance translate to improvements on these tasks for an actual closed-source model? \n\nQ5. Can you discuss how the intuition of EDEN relates to methods like locally typical decoding, which use entropy at each step as well but instead treat it as a measure of information content? \n\nOther comments/typo feedback (not contributors to the score):\n- There are already plenty of entropy-informed decoding methods, so the name is quite vague (and the acronym is pretty contrived). Why not something a bit more descriptive, maybe \"Entropy-Dependent ExpansioN\"? \n- in Table 1 it would be nice to have up/down arrows next to each column name (i.e. to indicate that higher is better for the four datasets and lower is better for rank)\n- on line 432, you mention using Llama for the closed-source simulation; which Llama? I'm assuming it's the same Llama 3.2-3B used earlier, but it's never explicitly said\n- Llama is styled \"Llama\" for Llama 3 (the LLaMA capitalization was retired in the Llama 2 release)\n- line 854: \"preffered\" -> \"preferred\" \n- [HARP](https://aclanthology.org/2025.naacl-long.612/) is a quite relevant prior work\n- Not sure why, in line 112, you quote another paper instead of stating the part of the claim that's relevant to the argument you're making in your own words and citing back, as is done everywhere else in the paper"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "B02AwnYxqd", "forum": "dzmh4xA4Pq", "replyto": "dzmh4xA4Pq", "signatures": ["ICLR.cc/2026/Conference/Submission9388/Reviewer_xL45"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9388/Reviewer_xL45"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9388/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957374595, "cdate": 1761957374595, "tmdate": 1762920998291, "mdate": 1762920998291, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work proposes a novel search algorithm called EDEN. The core idea is to perform argmax decoding by estimating and branching factor at each search step using the entropy of the token level distribution. Authors described all the math behind proving the correctness of their algorithm that aligns with a clear logic: higher entropy needs wider search / larger branching. Then authors show how one can use API models as well to approximate EDEN decoding even without having the access to token-level sampling control.\nAuthors perform experiments over a wide range of tasks using public benchmarks, and compared their method with other search and sampling algorithms. They showed how their approach outperform baselines they chose to report using a few different underlying models for generation."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* the method sounds clear and contribute with a novel technique. I will focus more on the discussion of why I believe it could be presented better in the next section."}, "weaknesses": {"value": "I like the proposed idea of branching, while i believe it might have been applied / tested under a much more convincing experimental design and baselines.\nFirst is the choice of baseline generation methods. We have to compare this to aggregation based decoding such as majority voting and related methods, since they can be seen as performing argmax decoding too (see the original self-consistency decoding paper). \nSecond, lots of prior work suggest that model log score is not the best choice for choosing / ranking answers with LLMs. This is where the best test-time scaling methods use external scoring models to choose the final answer. Looks like eden might be combined with step-level score models etc., but it was not discussed much in the paper.\nThird, stronger and newer LLMs have to be tested here. There are much stronger and smaller LLMs than llama3.2 3b out there that can generate multiple thousands tokens of reasoning. This is where branching can be so helpful! Current numbers with 400 generated tokens are way too limited to be convincing."}, "questions": {"value": "* when we use EDEN decoding, did you apply topp topk, temp etc you mention in the experiments before computing the entropy and anywhere else?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hrfeHmquuS", "forum": "dzmh4xA4Pq", "replyto": "dzmh4xA4Pq", "signatures": ["ICLR.cc/2026/Conference/Submission9388/Reviewer_friN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9388/Reviewer_friN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9388/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762226283918, "cdate": 1762226283918, "tmdate": 1762920997947, "mdate": 1762920997947, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}