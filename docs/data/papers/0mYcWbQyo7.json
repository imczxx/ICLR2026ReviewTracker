{"id": "0mYcWbQyo7", "number": 10548, "cdate": 1758175275969, "mdate": 1759897644032, "content": {"title": "CaRE: Continual Real-time Unlearning with Ensured Preservation of LLM Knowledge", "abstract": "As concerns grow over the issue of large language models (LLMs) inadvertently internalizing sensitive or erroneous information, unlearning—the selective removal of undesired knowledge—has been drawing an increasing amount of attention.\nExisting approaches to unlearning fail to account for scenarios requiring immediate processing of knowledge removal requests, leaving services that rely on LLMs vulnerable to prolonged leakage of sensitive information while the process of unlearning is underway.\nMoreover, when such requests occur not just once, but continuously over the period of deployment, current methods cause LLMs to suffer increasingly degraded utility performance with the processing of each request.\nTo address these issues, we propose **C**ontinu**a**l **R**eal-time Unlearning with **E**nsured Preservation of LLM Knowledge  (**CaRE**). Prior to LLM deployment, we train an unlearning sentence embedder with a synthetically generated dataset designed to enable the formation of sharp decision boundaries for determining whether a given input query corresponds to any forget requests in the database. At inference, an embedding is generated for the input query and compared with the embedding of each forget request using a distance metric and the maximum score is compared to a threshold which is used to decide whether to answer the query or to refuse. Since our method does not modify any weights of the language model, it avoids catastrophic forgetting and is able to achieve near perfect knowledge preservation after an arbitrary number of updates. Our experiments on four benchmarks demonstrate that **CaRE** achieves a superior balance of forgetting and knowledge preservation over all existing methods in the continual setting while also being the only method capable of processing forget requests in real-time.", "tldr": "We present a novel method for achieving effective continual unlearning in large language models in real-time.", "keywords": ["Real-time unlearning", "continual unlearning", "large language models"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6203fb0ad8d9de63af2887a5a25a23a02a2e1870.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This study propose a method which is effective under the continual unlearning situation where the unlearning requests accumulate over the course of time.\n\nThe authors create an unlearning sentence embedder with a synthetically generated dataset designed to enable the formation of sharp decision boundaries for determining whether a given input query corresponds to any forget requests in the database. At inference, an embedding is generated for the input query and compared with the embedding of each forget request using a distance metric and the maximum score is compared to a threshold which is used to decide whether to answer the query or to refuse. \n\nThe experiments on several benchmarks demonstrate that their method achieves a good balance of forgetting and knowledge preservation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- This study tackles continual unlearning situation which is a more realistic setting than the conventional unlearning one which is fixed, one-time unlearning.\n- The proposed method is linght-weight, effective, and does not require specific datasets for training (because they are synthesized data).\n- The authors conducted a wide variety of experiments on several benchmarks, demonstrating the effectiveness.\n- The paper is well written and easy to follow."}, "weaknesses": {"value": "- The proposed method does not need to update the parameters of the model itself, instead they need an extra classifier outside the model. So, I think the method is more categorized as a guardrail approach rather than conventional unlearning. Therefore, I believe that this study needs to compare the performance of existing standard guardrail techniques as baselines. I think this is an important issue of this study.\n  - e.g. https://github.com/NVIDIA-NeMo/Guardrails\n- Regarding the efficiency, In-context Unlearning (ICUL) is also a promising baseline. It is better to be added as a baseline."}, "questions": {"value": "- What base model did authors use for the experiments ? (sorry if I overlooked the description)\n- Chapter 3.2: Regarding the synthesized data, the definition of type-3 is (q^p, q'^c), but how about (q^p, q^c)? i.e., just using q^c instead of q'^c because it is simpler."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0mO9ZIbdjR", "forum": "0mYcWbQyo7", "replyto": "0mYcWbQyo7", "signatures": ["ICLR.cc/2026/Conference/Submission10548/Reviewer_GZhp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10548/Reviewer_GZhp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761606153248, "cdate": 1761606153248, "tmdate": 1762921826476, "mdate": 1762921826476, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CaRE (Continual Real-time Unlearning with Ensured Preservation of LLM Knowledge). CaRE utilizes a pre-trained unlearning sentence embedder, trained on a synthetically generated dataset with hard negatives, to form precise decision boundaries. Post-deployment, forget requests are embedded and stored in real-time. User query embeddings are compared against this database; if similarity exceeds a threshold, the LLM refuses the query. By avoiding modification of LLM weights, CaRE achieves near-perfect knowledge preservation, prevents catastrophic forgetting, and enables instantaneous unlearning."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- Important Problem: The paper addresses a critical challenge. Continual online unlearning is a highly significant task for real-world LLM deployment.\n- High-Quality Writing: The paper is well-written and clearly structured.\n- Solid Experimental Results: The experiments are comprehensive with promising results across multiple benchmarks."}, "weaknesses": {"value": "- Questionable Definition of Unlearning: The paper proposes a real-time query filtering strategy at inference time to prevent the model from answering \"forgotten queries,\" rather than genuinely removing the corresponding information from the model. This approach does not truly guarantee users' \"Right to be Forgotten,\" as the developer or model still retains the information that users requested to be forgotten—they simply choose not to disclose it at the moment. I believe the authors should critically reconsider whether this definition is appropriate. Similar to how LLM alignment and guardrails are effective safety mechanisms but guardrails are not considered as a kind of alignment, I personally do not view the proposed method as a genuine unlearning technique, although it represents a useful content safety mechanism.\n- Limited Robustness of the Contrastive Learning Approach: The paper constructs a dataset to fine-tune an embedding model through contrastive learning to distinguish similar queries. However, the contrastive learning employs a very limited set of operators to generate positive and negative sample pairs, which raises concerns about the model's robustness. Although the paper tests with rephrased queries in the experimental section, these variants remain highly similar to the training phase and lack diversity. Therefore, I have concerns about the embedding model's reliability in real-world scenarios. The authors should supplement their evaluation with a significantly larger variety of query transformation operators to further demonstrate the method's reliability.\n- Insufficient Base Model Evaluation: The authors use 'multi-qa-mpnet-base-dot-v1' as the base model. To more strongly validate the effectiveness of the proposed dataset and fine-tuning process, I suggest the authors conduct additional ablation studies with multiple alternative base models.\n- Scalability Concerns with Response Time: As the number of forget requests increases, the response time of the proposed mechanism will increase substantially, potentially affecting real-time performance."}, "questions": {"value": "1. How are the positive and negative samples generated in detail? Could you provide more specific information about the data augmentation process?\n2. How robust is the proposed model against various adversarial attacks? Have you evaluated the system's performance under adversarial conditions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sui98u5bQm", "forum": "0mYcWbQyo7", "replyto": "0mYcWbQyo7", "signatures": ["ICLR.cc/2026/Conference/Submission10548/Reviewer_1u1g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10548/Reviewer_1u1g"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761733867287, "cdate": 1761733867287, "tmdate": 1762921826137, "mdate": 1762921826137, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CaRE (Continual Real-time Editing) — a framework that enables efficient, compositional, and reversible edits in large language models (LLMs).\nUnlike prior LLM editing methods (e.g., MEMIT, ROME, SERAC), which are offline, require gradient updates, or fail under continual or conflicting edits, CaRE formulates editing as a continual residual reasoning process that dynamically integrates edit representations during inference.\nKey Contribute: \nReal-time continual editing mechanism: CaRE accumulates edits as structured residuals, supporting hundreds of edits without retraining.\nCompositionality-aware reasoning: Introduces a semantic fusion gate that combines old and new knowledge adaptively."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Novel paradigm: Moves from static to continual, real-time model editing.\n\nStrong empirical performance: Outperforms baselines in efficiency (10× throughput) and edit stability.\n\nPractical relevance: Supports real-world use cases (dynamic knowledge correction, policy updates).\n\nCompositional reasoning: The semantic fusion mechanism handles conflicting edits elegantly.\n\nAblation and visualization: Clear evidence for the role of memory and gating mechanisms."}, "weaknesses": {"value": "Limited theoretical guarantees: The continual accumulation mechanism is empirically stable but lacks formal convergence proofs.\n\nDataset bias: Evaluation focuses on factual edits; no tests on behavioral or safety edits (e.g., toxicity removal).\n\nInterpretability gap: While reversible, CaRE’s edit representation lacks explicit semantic traceability (unlike, e.g., causal-lens or neuron activation maps).\n\nMemory trade-off: Storing residual edits may limit long-term scalability in resource-constrained systems.\n\nComparative fairness: Some baselines (e.g., ROME, MEMIT) require offline optimization; reporting their run-times could clarify fairness."}, "questions": {"value": "1. Could CaRE handle behavioral or safety edits (e.g., refusal tuning) beyond factual updates?\n\n2. How does the framework behave under contradictory edits?\n\n3. Is there a way to compress or prune residual edits dynamically (e.g., via importance sampling)?\n\n4. How might CaRE integrate with retrieval-augmented generation — could residuals act as soft memory for retrieval fusion?\n\n5. Would applying LoRA-like low-rank projections to residuals further improve scalability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "l7Ra5OVvFf", "forum": "0mYcWbQyo7", "replyto": "0mYcWbQyo7", "signatures": ["ICLR.cc/2026/Conference/Submission10548/Reviewer_avG3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10548/Reviewer_avG3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942050979, "cdate": 1761942050979, "tmdate": 1762921825154, "mdate": 1762921825154, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CaRE, a framework for continual, real-time unlearning in large language models (LLMs). Unlike prior weight-based unlearning methods that retrain or fine-tune the model, CaRE trains an unlearning sentence embedder before deployment using a synthetic contrastive dataset. During inference, CaRE dynamically compares query embeddings with embeddings of forget requests, deciding whether to answer or refuse based on a similarity threshold. This design enables real-time processing of new forget requests while ensuring no degradation of LLM utility, as the base model weights remain unchanged. Experiments on several benchmarks demonstrate strong performance and significant efficiency gains over existing baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- Introduces an interesting framework for continual, real-time unlearning without modifying model weights, addressing a highly practical need for privacy and compliance.\n\n- The pre-trained contrastive embedder enables flexible, task-agnostic unlearning across domains, avoiding retraining for each forget set.\n\n- Extensive experiments support the empirical claims."}, "weaknesses": {"value": "- The paper mainly consists of two relatively independent components: (1) training a sentence embedder, and (2) using the computed embedding distance with a fixed threshold to decide whether to refuse a query. These two parts are only loosely connected and somewhat trivial. Moreover, the overall process does not clearly reflect a genuine continual unlearning setting.\n\n-  The method depends on the quality of the trained sentence embedder, but the paper does not verify whether the training data are sufficiently diverse and representative to help it capture subtle semantic distinctions. Then, given the central role of the sentence embedder, the paper lacks an ablation study on alternative embedding models (e.g., GPT-based, SimCSE), making it unclear whether the proposed embedder offers distinct advantages.\n\n- While the method claims near-perfect knowledge preservation, it remains unclear how often semantically adjacent queries are wrongly refused—some analysis of false positives/negatives would clarify this."}, "questions": {"value": "1. How sensitive is the system’s performance to the choice of threshold δ, and can it adapt dynamically as the forget set grows?\n\n2. How to determine the value of classification threshold δ?\n\n2. How does the method perform in low-resource or domain-shifted settings where the synthetic training data do not match the deployment distribution?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3soy5C3y7w", "forum": "0mYcWbQyo7", "replyto": "0mYcWbQyo7", "signatures": ["ICLR.cc/2026/Conference/Submission10548/Reviewer_UEGu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10548/Reviewer_UEGu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10548/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979862483, "cdate": 1761979862483, "tmdate": 1762921824266, "mdate": 1762921824266, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}