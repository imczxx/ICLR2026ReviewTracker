{"id": "jbJGhHpwmJ", "number": 14558, "cdate": 1758238913939, "mdate": 1759897362558, "content": {"title": "BIRD: Behavior Induction via Representation-structure Distillation", "abstract": "Human-aligned deep learning models exhibit behaviors consistent with human values, such as robustness, safety, and fairness.  Transferring these behavioral properties to models trained on different tasks or data distributions remains challenging: aligned behavior is easily forgotten during fine-tuning, and collecting task-specific data that preserves this behavior can be prohibitively costly.  We introduce BIRD, a flexible framework for transferring aligned behavior by matching the internal representation structure of a student model to that of a teacher.  Applied to out-of-distribution robustness in image classification, BIRD outperforms fine-tuning, transfer learning, and continual learning methods, improving robust accuracy by up to 18\\% over the next strongest baseline. It remains effective even when the teacher is trained on a much simpler dataset and is $25\\times$ smaller in parameter count than the student.  In a large-scale study of over 400 teacher-student pairs, we show that three interpretable and computable properties of the teacher's representations explain up to 85\\% of the variance in transfer success, offering practical guidance for teacher selection and design.  We further show that BIRD generalizes beyond applications in vision by enhancing safety alignment in language models when paired with Direct Preference Optimization and improving weak-to-strong generalization when combined with soft-label distillation.  BIRD turns small, well-aligned models into scalable alignment seeds, mitigating challenges from key bottlenecks in deploying safe AI systems.", "tldr": "", "keywords": ["Knowledge Distillation", "AI Alignment", "Weak-to-strong generalization"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4eac725b35e88d755294e7db78a22717c4b1f2f6.pdf", "supplementary_material": "/attachment/7c00bbabfa21c28cf21c9192eee615d52a8f63ea.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes BIRD that aligns student model to teacher model by using a similarity loss between the representations of the teacher and student models. This alignment works even without access to the teacher data, or even if the dimensions of the teacher and student models do not match. CKA is used here as a similarity metric, which performs matrix multiplication of features of student and teacher models across the batch dimension. Experimental results are provided comparing the work with existing works of distillation and alignment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper provides an algorithm to align student model with teacher models by increasing the similarity between student and teacher models using CKA ensuring that the dimensions of the student and teacher models need not align\n- Experimental results are provided to show the benefits of the method."}, "weaknesses": {"value": "- The novelty of this method as well as the application scope and results are very limited. The main selling point of models of different dimensions getting aligned, but finetuning using labels from teacher model also works in such cases. Moreover, the results shown in Table.1 has very little improvement compared to prior works\n- The experiments limited to robustness is very limited. What properties from the teacher is getting transferred in this case? Moreover, finetuning/alignment usually provides control over the reward or utility to align on (robustness in this case), but how is BIRD is used to align in general."}, "questions": {"value": "In addition to addressing the weaknesses, how do we choose the batchsize used in CKA, the similarity here seems to be dependent on the batchsize."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "me8BRmxP17", "forum": "jbJGhHpwmJ", "replyto": "jbJGhHpwmJ", "signatures": ["ICLR.cc/2026/Conference/Submission14558/Reviewer_W2qD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14558/Reviewer_W2qD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761800106113, "cdate": 1761800106113, "tmdate": 1762924947513, "mdate": 1762924947513, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents BIRD (Behavior Induction via Representation-Structure Distillation), a framework for transferring desirable behavioral properties (e.g., robustness, safety, fairness) from a teacher model to a student model by aligning the geometric structure of their internal representations (using Gram matrices) rather than matching outputs or activations. Inspired by NeuroAI insights, BIRD enables weak-to-strong generalization across differing architectures, tasks, datasets, and domains without requiring shared inputs or labels. guidance for teacher design."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Flexibility and Scalability: Unlike traditional knowledge distillation or continual learning, BIRD doesn't require shared tasks, data, or output spaces, allowing transfer from small/simple teachers (e.g., CIFAR-10-trained MobileNetV2) to 25× larger students on complex datasets like TinyImageNet.\n\nPrincipled Teacher Selection: The identification of three interpretable, computable properties (quantifying task and behavioral relevance in representations) makes the method actionable and predictable, advancing beyond ad-hoc approaches.\n\nBroad Applicability: Demonstrates versatility beyond vision (e.g., OOD robustness) to language models, improving DPO for safety on PKU-SafeRLHF and soft-label distillation for generalization, positioning it as a general alignment tool."}, "weaknesses": {"value": "Computational Overhead: Computing Gram matrices over batches adds overhead during training, potentially scaling poorly for very large models or high-dimensional representations.\n\nLayer Selection Sensitivity: Relies on choosing specific \"guiding\" and \"guided\" layers; while properties help, this introduces hyperparameters and may not generalize across all model families.\n\nLimited to Encoded Behaviors: Assumes behaviors are fully captured in representation structure (e.g., geometry via Gram matrices); subtler or output-specific alignments might not transfer well."}, "questions": {"value": "In the language model experiments, how does BIRD integrate with DPO—does it modify the loss function, act as a regularizer, or run in a separate phase? What ablation studies support this combination?\n\nWhat are the typical runtime and memory costs of BIRD compared to standard fine-tuning or logit-based KD, especially for large models like those in your 400+ pair study?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PaakhaDByp", "forum": "jbJGhHpwmJ", "replyto": "jbJGhHpwmJ", "signatures": ["ICLR.cc/2026/Conference/Submission14558/Reviewer_X3w8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14558/Reviewer_X3w8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830472186, "cdate": 1761830472186, "tmdate": 1762924947139, "mdate": 1762924947139, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces BIRD (Behavior Induction via Representation-structure Distillation), a new framework for transferring \"aligned behaviors\" (such as robustness or safety) from a teacher model to a student model. The core problem it addresses is that aligned behaviors are costly to instill and are often lost when a model is fine-tuned on a new task (a phenomenon known as \"catastrophic forgetting\"). Traditional transfer learning and distillation methods often fail because they require the teacher and student to share tasks, data, or output spaces. The key method of this work is to distill the internal representation structure of the teacher, rather than its outputs or raw activation values. It does this by minimizing the dissimilarity between the pairwise similarity of inputs in the teacher's and student's representation spaces, using Centered Kernel Alignment (CKA) as its loss function."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. BIRD does not require the teacher and student to share an input space, output space, task, or architecture.\n2. The paper successfully shows BIRD is not just a vision technique. Its application to DPO (safety) and soft-label distillation demonstrates its potential as a general tool."}, "weaknesses": {"value": "1. The method relies on selecting a single \"guiding\" and \"guided\" layer. This selection was based on a heuristic, and the authors acknowledge that exploring multi-layer extensions is a direction for future work.\n2. The experimental setup is not representative of modern, real-world applications. The use of CIFAR-10, CIFAR-100, and TinyImageNet, with all images downsampled to $32 \\times 32$ pixels, deemed a \"toy problem\" by 2026 standards. It is highly uncertain whether robustness features learned on $32 \\times 32$ images, and the CKA-based structural alignment that transfers them, are in any way representative of the features and alignment challenges in high-resolution, large-scale vision foundation models.\n3. The language experiments use models that are orders of magnitude smaller than the popular models (e.g. SmolLM2-135M/360M and GPT2-Large v.s. Qwen3-8B). The paper itself admits these are \"relatively small\". The gains on these tiny models provide very little evidence of practical utility because scaling up to multi-billion parameter models introduces alignment challenges and it's a significant leap to assume this method would be effective."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "SHGHa4qS6W", "forum": "jbJGhHpwmJ", "replyto": "jbJGhHpwmJ", "signatures": ["ICLR.cc/2026/Conference/Submission14558/Reviewer_rkTA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14558/Reviewer_rkTA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864322961, "cdate": 1761864322961, "tmdate": 1762924946684, "mdate": 1762924946684, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces BIRD, a method to transfer behavioral properties like robustness by matching the representation structure (via CKA) between a teacher and a student model. The central claim is that this enables transfer across different tasks, datasets, and architectures. The authors provide comprehensive experiments, primarily in robust image classification, showing BIRD outperforms strong transfer learning baselines. A large-scale analysis identifies interpretable properties of teacher representations that predict transfer success. The paper is complemented with LLM experiments, showcasing the method's generalizability. The idea is novel and can indeed be a practical tool for achieving desirable representation structures within various models."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. I believe the main idea is quite solid, using the geometry of the representation is justified, and the authors show that it also yields practical utility, beyond the intuitive justification. The overall hypothesis has high potential impact.\n2. Identifying predictive factors is a valuable contribution. The high explained variance (up to 85%) provides practitioners with a principled way to select teachers.\n3. The paper is well written and clearly explained, which helps with reproducibility.\n4. The robust image classification experiments are extensive, covering many model architectures and dataset pairs. Hinting at solid results.\n\nOverall, I believe the idea is quite solid and has high potential impact. I would like to see this paper accepted; However, I have a few concerns, which I will list below. I believe addressing these can indeed increase its potential."}, "weaknesses": {"value": "There is a lack of ablation studies on some key aspects, or at least some important metrics are not reported.\n\nMajor:\n1. The batch size B is a fundamental hyperparameter for CKA. This is not reported anywhere. The performance could be highly sensitive to this parameter.\nMinor:\n2. The choice of kernel (e.g., linear vs. RBF) can drastically change the geometry being compared. No ablation or discussion is provided on why this specific similarity measure was chosen over others.\n3. The paper does not explore multi-layer distillation, which is a natural extension.\n4. The values for $\\alpha$ and $\\beta$ should be reported.\n\nAnother problem would be with some claims, which are not justified by current experiments.\n\nMajor:\n4. The paper repeatedly emphasizes that BIRD works \"even when the teacher and student differ in architecture, task, and training data\" and \"does not require a shared input space.\" However, all experiments use the same input modality and resolution (images resized to 32x32). The teacher and student process the same input batches. The method has not been demonstrated to work across truly different input spaces (e.g., teacher on text, student on images; teacher on high-res images, student on low-res images). This is a significant overstatement of the current evidence."}, "questions": {"value": "1. Could you provide more experimental details, especially the batch size used, and how it affects the performance?\n2. Were other design choices, e.g., different kernels, multi-layer distillation, explored? If not, are there any reasons why we should not look into those, or is it just not that beneficial to do so?\n3. What would happen if we use some pretrained teacher models? e.g., foundation encoders like CLIP would indeed be good examples of models with aligned representations, which could also be good for assessing the claim that \"BIRD does not require a shared input space.\"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "PJDACVeSPx", "forum": "jbJGhHpwmJ", "replyto": "jbJGhHpwmJ", "signatures": ["ICLR.cc/2026/Conference/Submission14558/Reviewer_1C7Y"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14558/Reviewer_1C7Y"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14558/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761872613124, "cdate": 1761872613124, "tmdate": 1762924946144, "mdate": 1762924946144, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}