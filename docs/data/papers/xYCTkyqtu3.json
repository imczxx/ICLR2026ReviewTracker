{"id": "xYCTkyqtu3", "number": 14979, "cdate": 1758246446486, "mdate": 1759897337884, "content": {"title": "Automatic Moderator Discovery via SHAP Interaction Values", "abstract": "Machine Learning (ML) is increasingly applied across the sciences, accelerating simulations, automating data preparation, and improving predictive accuracy. Yet most efforts emphasize efficiency and performance, with limited attention to interpretability, thereby leaving unexplored how ML can drive discovery—uncovering novel patterns in data and advancing scientific theory. Moderation effects—where the influence of one variable depends on the level of another—are central to disciplines such as social science and human behavior. However, they are typically studied through a theory-driven process based on regression models with manually specified interactions. While insightful, this approach is limited because it scales poorly and may miss unexpected moderators.\nWe introduce an automated, interpretable framework for moderator discovery based on SHAP interaction values. Our method computes global interaction contributions from a predictive model, quantifies their dependence on constituent features, and identifies statistically significant moderators. In experiments on real-world datasets, the framework not only recovers known, theory-consistent moderating effects but also uncovers novel moderator candidates. These results illustrate how explainable ML can move beyond prediction toward systematic discovery, offering scientists a scalable tool to reveal conditional relationships that inform theory development.", "tldr": "We propose a SHAP interaction–based framework to automatically discover moderators in data, enabling interpretable, systematic detection of conditional effects.", "keywords": ["Interpretable Machine Learning", "moderating effect", "science"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6f1c2142a5932a362c2eea1c4a97fc4adf843aea.pdf", "supplementary_material": "/attachment/03abd9c58c89fba8eca27c96194176a2b1f1e8bb.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes an automated framework for data-driven moderator discovery using SHAP interaction values derived from gradient-boosted decision trees (LightGBM). The framework aims to bridge predictive ML and theory-driven science, allowing researchers to systematically uncover moderating effects (conditional relationships) without prespecifying candidate moderators."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "### **Clear Motivation**\n* The work addresses an underexplored gap between predictive modeling and interpretable, theory-oriented discovery, particularly relevant in social sciences and behavioral domains.\n\n### **Methodology**\n* Leveraging TreeSHAP for interaction attribution is clever: it enables scalable, model-faithful extraction of interaction information with polynomial-time complexity.\n\n### **Empirical Validation**\n* Experiments include both synthetic (ground-truth known) and real-world (social science) datasets."}, "weaknesses": {"value": "### **Technical Limitations / Mathematical Depth**\n* The paper does not provide theoretical justification or bounds on when SHAP interaction values can be reliably interpreted as moderation effects. SHAP interaction measures contribution, not necessarily conditional effect in a causal or statistical moderation sense.\n* The $\\beta_3$ estimation step treats SHAP values as regression targets without addressing their statistical dependence structure or the implications of SHAP value non-orthogonality. This may lead to inflated significance or misinterpretation.\n* No identifiability or robustness analysis is provided: for instance, how stable the discovered moderators are to model perturbations, feature scaling, or correlated covariates.\n\n### **Novelty**\n* The method is essentially a combination of existing components: TreeSHAP, classical moderation regression, and significance testing\n* Attribution-based moderation inference has conceptual similarity to existing feature interaction explanation methods\n\n### **Conceptual Ambiguity**\n* The paper equates SHAP interaction values with moderating effects, but this is not strictly justified: SHAP interactions are symmetrical, whereas moderation is directional (one variable moderates another). Although regression on SHAP attributions introduces directionality, the interpretation remains heuristic, not theoretically guaranteed."}, "questions": {"value": "Please see the above weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OoVOC9KTmB", "forum": "xYCTkyqtu3", "replyto": "xYCTkyqtu3", "signatures": ["ICLR.cc/2026/Conference/Submission14979/Reviewer_wtgj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14979/Reviewer_wtgj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14979/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760687415577, "cdate": 1760687415577, "tmdate": 1762925310736, "mdate": 1762925310736, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a three-step interpretable framework for the automatic discovery of moderator effects from data. The method aims to bridge predictive machine learning with theory-driven scientific discovery. The framework first trains a high-capacity GBDT model to capture complex relationships. Second, it computes pairwise SHAP interaction values to quantify the joint contribution of feature pairs. Third, it regresses these attribution scores onto the original feature values (fitting $\\phi_{i,j}^{tot} \\approx \\dots + \\beta_3 x_i x_j$) and uses the resulting $\\beta_3$ coefficient and its p-value to identify and rank significant moderators. The method is validated on synthetic data and two real-world datasets demonstrating it can recover theoretically-consistent moderators and outperform baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses a highly important and practical goal: moving ML from a purely predictive tool to one that can aid in systemic, data-driven scientific discovery. \n2. The paper is exceptionally well-written. The problem is clearly defined, the method is presented in a logical, three-step algorithm, and the experimental setup is easy to follow.\n3. While the individual components (GBDT, SHAP, OLS) are standard, their composition is novel. The core original idea is to re-purpose SHAP values as an intermediate data source for a second-stage statistical analysis. This is a clever approach that reframes the vague problem of \"interaction detection\" into the more specific, interpretable problem of \"moderator assessment.\""}, "weaknesses": {"value": "1. The designed framework can only detect 2-way interactions. It is blind to higher-order interactions, which are common and critical in many scientific domains. This makes the contribution feel more like a proof-of-concept than a complete discovery system.\n2. The contribution is a clever pipeline of existing tools rather than a new algorithm or fundamental theory. This limits the technical originality of the work.\n3. The claim of a general, systematic framework is supported by only one synthetic and two real-world datasets. This is not extensive enough to prove its general applicability across different scientific domains.\n4. The validation metric (a linear test) seems mismatched with the non-linear GBDT model.\n5. The paper does not analyze how sensitive the discovered moderators are to the GBDT's hyperparameters, which is critical for a discovery tool's reliability."}, "questions": {"value": "1. What are the primary conceptual or computational barriers to extending this framework to 3-way (or higher-order) interactions? Would this involve computing 3rd-order SHAP values and regressing them onto a term like $\\beta x_i x_j x_k$?\n2. Why use a linear test to validate a non-linear model? Doesn't this risk penalizing true non-linear discoveries? Relatedly, how sensitive is the final list of moderators to the GBDT's hyperparameters? We need to be sure the discoveries are robust and not artifacts of tuning.\n3. The claim of a general framework is supported by only two real-world datasets. Could the authors comment on the expected generalizability to other scientific domains and data types? What challenges in applying this method to much higher-dimensional data (e.g., M > 10,000)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "YeTLgLn1dB", "forum": "xYCTkyqtu3", "replyto": "xYCTkyqtu3", "signatures": ["ICLR.cc/2026/Conference/Submission14979/Reviewer_yJu9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14979/Reviewer_yJu9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14979/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761806810733, "cdate": 1761806810733, "tmdate": 1762925309946, "mdate": 1762925309946, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a scalable and interpretable framework for automatic moderator discovery in machine learning models. It uses SHAP interaction values to screen for and quantify moderating effects, where the influence of one variable depends on the level of another, across all feature pairs in high-dimensional data. Evaluation on synthetic and real-world datasets (COMPAS, Medicare vaccination) demonstrates the method’s ability to recover known moderators and reveal new candidates not previously highlighted by domain-driven analyses."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper tackles an interesting but underexplored facet of interpretable machine learning.\n- The methodology is well-motivated and clearly described. The use of SHAP interaction values for model-wide screening, combined with a regression-based moderation assessment, is a compelling merge of machine learning and statistical theory"}, "weaknesses": {"value": "1. While the paper evaluates the statistical significance of discovered moderators via inclusion in a linear regression, this does not fully control for potential confounding or capture non-linear relationships. The approach essentially reduces the problem to significance of pairwise terms, which may inflate discovery of spurious moderators, especially in complex or collinear datasets. Further, no detailed ablation/sensitivity studies are reported regarding how methodological or hyperparameter changes (e.g., choice of model class, depth of GBDT, or normalization scheme) affect results or stability of discovered moderators.\n2.  The method is only tested using GBDT (LightGBM). While it is stated that other tree ensembles (XGBoost, CatBoost) or potentially other model classes could be used, no empirical evidence or discussion is provided for non-tree models, or for cases where SHAP values are approximated rather than computed exactly.\n3. While the technique is positioned as “interpretable” and “scalable,” the practical interpretability of discovered moderators is not rigorously evaluated beyond recovering known scientific patterns. For instance, how do domain experts interpret SHAP-ranked moderators in highly collinear data, or when moderators do not have a causal interpretation?\n4. The quality of Figure 2 could be improved. The legend/axes titles are too small, and there are no error bars/bands."}, "questions": {"value": "1. Could the authors clarify the exact normalization approach for predictors used prior to the regression-based moderation test (Section 3.3)? For continuous vs. categorical features, is normalization performed identically?\n2. How does the method perform if the predictive model is replaced with a neural network backbone, or if SHAP values must be estimated empirically rather than via TreeSHAP? Is the approach robust to approximate SHAP implementations?\n3. How scalable is the method in practice as the number of features increases into the hundreds/thousands? Actual running time benchmarks or empirical scaling curves would be valuable for practitioners."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "P4BWOoG9PB", "forum": "xYCTkyqtu3", "replyto": "xYCTkyqtu3", "signatures": ["ICLR.cc/2026/Conference/Submission14979/Reviewer_bQgQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14979/Reviewer_bQgQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14979/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992504876, "cdate": 1761992504876, "tmdate": 1762925309462, "mdate": 1762925309462, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a heurstic framework for automated, data-driven discovery of moderation effects (conditional dependence bet two variables given a context) using SHAP interaction values derived from gradient-boosted decision trees. The idea is well motivated and the empirical experiment is supported with domain insights, yet the methodology sound limited, please see comments below. Overall, I believe the scope and implementation of this work are of limited interest to ICLR community."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Proposes a systematic approach for uncovering moderating effects. The approach is hypothesis-agnostic, scalable to high-dimensional datasets, and preserves model interpretability. Empirical results on synthetic and real data show that some known moderators and even novel candidates can be recovered."}, "weaknesses": {"value": "- The use of GBDTs for moderator discovery indeed captures nonlinear interactions; but also results in discontinuous, piecewise-constant outputs. This discretization may not be able to capture smooth moderation patterns, limiting method generalization. \n\n- The method computes SHAP interaction values via TreeSHAP (as indicators of moderation). TreeSHAP relies on sampling features from their product-marginal (i.e., assuming independence bet features) when estimating the contributions. Thus, it may ignore or misrepresent the true joint dependence structure among features, which can lead to artificial conditional relationships or spurious moderators being detected.\n\n- ShapMod-1st outperforms ShapMod (based in Eq. 6) in three of four datasets, raising a question about the need for SHAP interaction terms in Eq (6)?\n\n- Both the SHAP method and trained model introduce potential errors through estimation and initialization. Evaluation relies on small datasets, including a synthetic example with only 3,000 samples but many features (40), raising various questions about generalizability and sample-size sensitivity."}, "questions": {"value": "See weaknesses section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Rtw5X8EJbX", "forum": "xYCTkyqtu3", "replyto": "xYCTkyqtu3", "signatures": ["ICLR.cc/2026/Conference/Submission14979/Reviewer_3ihw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14979/Reviewer_3ihw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14979/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997270305, "cdate": 1761997270305, "tmdate": 1762925309017, "mdate": 1762925309017, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the problem of automatically identifying moderator variables. The authors propose a three-step approach that utilizes SHAP interaction values to train a predictive model, evaluate moderation effects, and identify significant moderators. The effectiveness of the proposed framework is validated on both synthetic datasets and real-world dataset."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written and clearly organized.\n\n2. The authors provide a good review of related work.\n\n3. The experimental results on the Medicare vaccination dataset reveal an interesting and potentially novel pattern, which could bring useful insights to this community."}, "weaknesses": {"value": "1.  The baseline methods (e.g., Lasso and ANOVA) seem a bit outdated. I am not an expert in this particular subarea, but if there are newer or more advanced baselines available, including them could make the evaluation more convincing.\n\n2. The proposed framework currently lacks a theoretical guarantee. It would be helpful to discuss under what conditions the identified moderator can be regarded as the most important one. Adding some theoretical insights or sensitivity analysis could further strengthen the contribution."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "XZS5OT91jf", "forum": "xYCTkyqtu3", "replyto": "xYCTkyqtu3", "signatures": ["ICLR.cc/2026/Conference/Submission14979/Reviewer_jHLQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14979/Reviewer_jHLQ"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission14979/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762050198186, "cdate": 1762050198186, "tmdate": 1762925308666, "mdate": 1762925308666, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}