{"id": "YtOAjOsL4N", "number": 9758, "cdate": 1758138760690, "mdate": 1759897700166, "content": {"title": "MemLens: Uncovering Memorization in LLMs with Activation Trajectories", "abstract": "Large language models (LLMs) are commonly evaluated on challenging benchmarks such as AIME and Math500, which are susceptible to contamination and risk at being memorized. Contamination can be explicit, where samples appear verbatim, or implicit, where samples are rephrased, perturbed, or translated but still memorized. Existing detecting baselines focuses on surface-level lexcial overlap and perplexity, performing well for explicit contamination but degrading significantly under implicit cases. We propose MemLens (An Activation Lens for Memorization Detection) to detect memorization by analyzing the probability trajectories of numeric tokens during generation. We observe that contaminated and clean samples exhibit distinct and well-separated reasoning trajectories. To further validate the observation, we inject carefully designed samples into the model through LoRA fine-tuning and observe the same trajectory patterns as in naturally contaminated data. These results provide strong evidence that MemLens captures genuine signals of memorization rather than spurious correlations.", "tldr": "", "keywords": ["LLM", "Interpretability", "Memorization"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ea3df2790265756b4f9309f42237da5a1be88d24.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper tackles the problem of uncovering dataset contamination on benchmark datasets, in a way that is robust to rephrasing or perturbations. They first identify that existing approaches which are based upon completion based recall or output distribution can be easily   fooled when rephrasings or language translations are introduced. Moreover, these approaches can often have high false positive rates on clean (non-contaminated) samples. This motivates their approach of studying the internal activations of the model to more accurately identify memorized examples. Using restricted logit lens prediction distributions, they generate a trajectory of predictive features and train a predictive model to classify between contaminated and uncontaminated samples. They demonstrate (a) MemLens remains more stable to rephrasings/translations and avoids false positives compared to existing techniques. Additionally, they demonstrate that provide a controlled study with LoRA knowledge injectction to demonstrate that MemLens does not rely on superficial correlations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "In general, this is an exciting, well motivated, and interesting paper. The problem is clearly one that is under-addressed by existing techniques (as authors mention). It is also a problem of significant interest as we work towards accurate and representative evaluations of LLM capabilities. I find the mechanistic approach employed by this paper to be both novel, yet also highly suited to the problem at hand. I was especially inspired by the author's usage of the activation dynamics, clearly going beyond prior \"representation engineering\"-like approches to interpretability. I believe that this \"activation dynamics\" based approach holds significant promise for other related problem statements (such as chain-of-though faithfulness/monitoring). I also think that the authors devised a very clever way to probe the success of their approach, using the LORA injection experiments. For this reason, I believe this paper is sound and can be very inspirational for future approaches across a range of problems statements."}, "weaknesses": {"value": "I have some concerns about the practicality of this approach. It remains unclear from my reading of this paper whether this contamination detecting model that they train is shared for detecting inference across multiple models and or types of contamination. For example, is it that a single model is trained for each (model, contamination type) pair in the table 1? If it is indeed the case that the results presented in Table 1 require retraining across perturbation or model types, that raises the question of how can this approach be used effectively in the real world? Do I have to \"train\" a discriminator everytime a new model comes in? If so, what data should I train the MemLens discriminator on? I think that the authors should either establish the generalization of their approach or concretely explain under what circumstances it generalizes. This would be valuable guidance for efforts to incorporate MemLens as a practical tool for eliminating contamination in models.\n\nWhile I found the Section 4.4 evaluation on MMLU to be interesting, I feel that the authors could strengthen this result significantly. For example, is it possible for the authors to locate the contaminated examples and show that they arise in some training datasets? I understand that the accuracy is a proxy for this. However, it seems like it could be conflated with how straightforward the questions are (for example). I am not sure if its feasible for authors to find that some of the \"contaminated likely\" samples existing in the training dataset, but this would significantly improve the MMLU result in my opinion.\n\nFrom a presentation standpoint, I found that Section 2 (Preliminaries) was a bit confusing due to the \"definitions of Memorization\". A significant amount of time is spent conveying the formal definitions of memorization and then they wrap up the section by mentioning that these definitions are not robust. Additionally, it seemed that the formal definitions introduced didn't contribute to my understanding of the remainder of the paper. So, I would encourage the authors to consider moving all this detail to the Appendix. This space can perhaps be reclaimed to offer a more in-depth exploration of the motivation behind dataset contamination research (i.e. more discussion on the points summarized as \"However, recent findings show that such signals are fragile: rephrased or translated benchmark items can still induce contamination effects even without verbatim overlap (Yang et al., 2023; Deng et al., 2024). This motivates alternative strategies that capture subtler memorization dynamics.\" I personally found that I had to read the prior work Yang et al., 2023 and Deng et al., 2024 before I got a solid understanding of the motivations for this paper."}, "questions": {"value": "(1)  is it that a single model is trained for each (model, contamination type) pair in the table 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZyytJnwRwf", "forum": "YtOAjOsL4N", "replyto": "YtOAjOsL4N", "signatures": ["ICLR.cc/2026/Conference/Submission9758/Reviewer_Vm4u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9758/Reviewer_Vm4u"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9758/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761511586422, "cdate": 1761511586422, "tmdate": 1762921252255, "mdate": 1762921252255, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MemLens, a novel method for detecting data contamination in Large Language Models (LLMs) by analyzing the activation trajectories of numeric tokens. The authors posit that existing methods, which rely on lexical overlap or perplexity, are brittle and fail when benchmark data is implicitly contaminated (e.g., rephrased or translated). MemLens operates on the hypothesis that memorized (contaminated) samples induce \"shortcut\" reasoning paths, causing the model to \"lock onto\" an answer with high confidence in its early layers. In contrast, clean samples show more gradual evidence accumulation across the model's depth.\n\nThe method extracts layer-wise probabilities for digit tokens, along with metrics like entropy and maximum confidence. These trajectories are fed into a 1D CNN discriminator to classify samples as \"contaminated\" or \"clean\". The authors validate this approach across four LLMs , showing that MemLens is significantly more robust to rephrasing, perturbation, and translation than baseline methods. Crucially, they provide strong causal evidence using LoRA injection: fine-tuning a model on clean data causes MemLens to identify those samples as contaminated, demonstrating it captures a genuine signal of memorization. Finally, the method is applied to the MMLU-Math benchmark, suggesting that 94.9% of the dataset is \"seen-like\" and that model performance is significantly inflated on this subset."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "** 1. Novelty **\n\nThe paper core contribution is moving detection from surface-level statistics (overlap, perplexity) to internal activation dynamics. The \"shortcut hypothesis\" provides a clear intuition for why memorization should manifest differently in activation space. The strong empirical evidence shows there is reliable signal for memorization in activations space. The performance is maintained across rephrased, translated, and perturbed inputs.\n\n** 2. Strong Causal Validation **\n\nThe LoRA injection experiments (Section 4.3, Table 2) provide compelling causal evidence. The monotonic increase in detection rates with increasing LoRA rank (2.2% → 45.1%) and the controlled single-sample case study (Figure 4) strongly suggest the method captures genuine memorization signals rather than spurious correlations.\n\n** 3. Implications **\n\nThe ability to detect data contamination is a powerful tool for robust model evaluation and selection, benefiting both developers and end-users. Furthermore, identifying memorization is critical for mitigating legal and ethical risks, such as the potential for models to reproduce copyrighted or private data, which compromises claims of generalization and trustworthiness."}, "weaknesses": {"value": "**1. Limited Scope**\n\nThe method explicitly focuses on digit tokens (Eq. 7), severely limiting applicability. The generalizability claim is undermined by this narrow scope.\n\n*Recommendation:* show, even a small demonstration of success on non-numeric tasks to encourage further research along those lines.\n\n**2. Limited Mechanistic Insight**\n\nWhile the paper compellingly demonstrates that a reliable memorization signal exists in the activation space, it falls short of explaining the underlying mechanism. The \"shortcut hypothesis\"  is presented as intuition but isn't proven or deeply investigated. Instead, the method relies on training a black-box discriminator (a 1D CNN ) on a set of engineered features. This approach successfully detects the signal but does not explain the precise relationship between the activations and the memorization.\n\n*Recommendation:* A feature ablation study, as suggested, would be a valuable starting point to understand the relative importance of different trajectory features. A deeper, more localized analysis could also examine which specific model components (e.g., MLPs vs. attention layers, or even individual neurons or attention heads) are the primary carriers of this signal, moving toward finding a minimal, interpretable pattern.\n\n**3. Supervised Approach:**\n\nThe method requires training a supervised discriminator with an already existing set of seen and unseen examples. The paper's setup is excellent for evaluating MemLens, but it doesn't address the practical challenge of how a developer would bootstrap this detector for a new model without already knowing which samples are contaminated."}, "questions": {"value": "1. Would you hypothesize the current approach generalizes to non-numeric tasks?\n2. Do you have a guess for what is it, about the internal activation trajectory, that shed light on memorization?\n3. How would one practically deploy MemLens for a new model without an existing, labeled dataset of clean/contaminated samples?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "j3AWXCn4PN", "forum": "YtOAjOsL4N", "replyto": "YtOAjOsL4N", "signatures": ["ICLR.cc/2026/Conference/Submission9758/Reviewer_VAtL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9758/Reviewer_VAtL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9758/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761726257593, "cdate": 1761726257593, "tmdate": 1762921251923, "mdate": 1762921251923, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The author proposes a new method called MemLens to detect the test data leakage for mathematical benchmarks even when the test data is rephrased and merged into the training data. More specifically, it proposed a feature set based on the trajectories of numeric tokens for the target LLM and trained a CNN-based discriminator to predict whether the test samples are exposed in the training of the target LLMs. Experimental results show that MemLens can effectively detect the test data leakage in two mathematical benchmarks with multiple LLMs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The strengths of the paper are listed as follows.\n1. The paper is well-motivated. Figure 1 clearly shows how the test data leakage can affect the objective evaluation of the mathematical reasoning capability of the target LLMs and highlights the importance of addressing this concern.\n2. The paper is well-written and easy to follow. The authors provide enough preliminaries and descriptions to help the reader catch the key ideas of the proposed method.\n3. The representation-space analysis provides deep insights into understanding the pattern of memorized samples, which is inspiring for future research in this area."}, "weaknesses": {"value": "The weaknesses of the paper are listed as follows.\n1. The proposed method only works for mathematical benchmarks, which limit its impact significantly.\n2. Some important technical details are not clear, which are listed in the Questions section of the review.\n3. The demonstration of the main results is not clear enough. In Table 1, the proposed method does not dominate all the metrics and settings. It seems that it achieves a better trade-off in identifying the contaminated samples and clean samples. However, it would be better if there were a quantitative metric to show it clearly. Since it is a binary classification task, metrics like AUC, F1 score may be used.\n4. Table 2 does not provide the PCR of the other baselines to show the advantage of MemLens.\n5. Figure 3 does not clearly show the difference between the patterns of clean samples and contaminated samples. The left and right figures look quite similar.\n6. It would be better if the authors could clearly point out which existing methods mentioned in the related work are not compared in the experiments and why not compared with them.\n7. The detection algorithm is training-based, which may be a little bit costly."}, "questions": {"value": "The questions are listed as follows.\n1. What is the difference between the extractable memorization and discoverable memorization? They look quite similar according to the provided definition.\n2. What is the intuition to use the first-order temporal differences as the features? How to define this kind of feature for the first layer?\n3. Why do the authors choose a CNN-based discriminator instead of a transformer-based model?\n4. When building the training datasets for the CNN detector, which data are used? What is the class distribution of the training data? Are the training data class-balanced? Does the training data have any overlap with the test data to evaluate the trained CNN detector?\n5. When you build the training datasets for the CNN detector, how do you decide the ground truth label for each sample? Is it the same as the completion-based detection method? Do you incorporate any rephrased data samples into the training datasets?\n6. For evaluation, why not use the clean samples from AIME 1983-2024 but use AIME 2025 instead?\n7. For the LoRA injection evaluation, do you need to retrain a new detector based on the generations from the LoRA-tuned model?   \n8. In Table 1, for the completion-based method, why is the metric of clean samples in the original settings not 0?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RhSIFEYHOz", "forum": "YtOAjOsL4N", "replyto": "YtOAjOsL4N", "signatures": ["ICLR.cc/2026/Conference/Submission9758/Reviewer_1VoQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9758/Reviewer_1VoQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9758/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966591918, "cdate": 1761966591918, "tmdate": 1762921251235, "mdate": 1762921251235, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MemLens, a representation-level detector for benchmark contamination/memorization in LLMs. Rather than relying on lexical overlap or perplexity, MemLens probes hidden states with a logit-lens, projects per-layer distributions over digit tokens, and builds layerwise trajectories (probabilities, entropy, max-prob, and first-differences) for the first answer position. A compact 1D-CNN discriminator classifies a sample as contaminated vs. clean from these trajectories. The authors report robustness to rephrased/translated/perturbed inputs, and provide causal evidence via LoRA injection: after fine-tuning on clean items, both task accuracy and predicted contamination rates rise together. They also show early-layer salience and run a zero-shot analysis on MMLU-Math, where “seen-like” items (per the detector) correlate with much higher accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality: Shifts contamination detection from surface/output statistics to representation trajectories, a neat operationalization of “shortcut” reasoning.\nQuality: Multi-model evaluation (Qwen2.5-7B/Math-7B, Qwen3-8B, Llama-3.1-8B) and four text distributions; MemLens often keeps low false-positive rates on clean sets while maintaining higher detection on contaminated sets vs. baselines (Table 1).\nCausality: LoRA rank sweep shows monotonic rise in contamination score with performance (Table 2; Fig. 4), strengthening the interpretation that trajectories capture memorization rather than incidental cues.\nMechanistic insight: Early-layer importance and Grad-CAM patterns support the shortcut story; ablations indicate much of the signal lives in shallower layers.\nReproducibility: Implementation and data handling details are spelled out (feature channels, z-scoring, CNN architecture, class weights, LoRA config)."}, "weaknesses": {"value": "Digit-only scope. The method narrows to numeric tokens; while well-motivated for AIME/Math, it risks missing non-numeric memorization (e.g., multi-choice letters, symbolic names, proof sketches). At minimum, an ablation adding letters/operators or subword buckets would test generality.\n\nDetector training labels. Clean/contaminated labels are constructed heuristically (e.g., “contaminated” from legacy AIME/Math500 where model exactly matches gold; “clean” from newer sets). This is reasonable but imperfect—some “clean” may be indirectly seen; some “contaminated” may be solvable. A sensitivity study to label noise or semi-supervised training would help.\nThresholding/metrics. The paper uses Youden J / chosen thresholds and reports many percentages without CIs (except for the MMLU analysis). A more uniform AUROC/PR-AUC reporting and bootstrap CIs for Table 1/2 would strengthen claims.\nExternal validity beyond math. Results and features are math-centric; it remains unclear how MemLens fares on code or commonsense QA where the “numeric-answer” anchor is absent.\nPotential confound: answer-positioning. Extracting trajectories at the “first answer token” assumes prompt formatting and answer position are comparable across variants; explicit controls (e.g., randomized prompt wrappers) would reduce positional artifacts."}, "questions": {"value": "Beyond digits: Can MemLens operate on a token subset S that includes letters, punctuation, or task-specific tokens? Any preliminary results with operator tokens or a learned S?\nGeneralization: How does the detector transfer to non-math benchmarks (e.g., trivia QA, code)? What channel set would you recommend there?\nLabel noise robustness: Did you simulate noisy labels for the discriminator to estimate performance degradation?\nCalibration/thresholding: Please report AUROC/PR-AUC (and CIs) alongside thresholded rates in Tables 1–2.\nPositional control: If the answer position is shifted by instruction wrappers, does the trajectory signature persist?\nDetector leakage: When the same backbone provides both features and outputs, could there be overfitting to model-specific idiosyncrasies? Any cross-model train/test where the detector trained on one model diagnoses another (beyond what’s shown)?\nMMLU analysis: The detector labels ~95% of MMLU-Math as “seen-like”. Could this be a difficulty proxy rather than contamination? Any stratification by item metadata or adversarially rephrased MMLU to check invariance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MF8lnKlrQl", "forum": "YtOAjOsL4N", "replyto": "YtOAjOsL4N", "signatures": ["ICLR.cc/2026/Conference/Submission9758/Reviewer_CSuY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9758/Reviewer_CSuY"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9758/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762125208391, "cdate": 1762125208391, "tmdate": 1762921250768, "mdate": 1762921250768, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}