{"id": "RnNqSYqEcm", "number": 2016, "cdate": 1756977044244, "mdate": 1759898173868, "content": {"title": "Online Multi-objective Convex Optimization: A Unified Framework and Joint Gradient Descent", "abstract": "Online Convex Optimization (OCO) usually addresses the learning task with a single objective; however, in real-world applications, multiple conflicting objectives often need to be optimized simultaneously. In this paper, we present an Online Multi-objective Convex Optimization (OMCO) framework with a novel multi-objective regret. We prove that, when the number of objectives in OMCO decreases to one, the regret is equal to the regret in OCO, thus unifying the OCO and OMCO frameworks. To facilitate the analysis of the proposed novel regret, we derive its equivalent form using the strong duality theory of convex optimization. Moreover, we propose an Online Joint Gradient Descent algorithm and prove that it achieves a sublinear multi-objective regret according to the equivalent regret form. Experimental results on several real-world datasets validate the effectiveness of our proposed algorithm.", "tldr": "", "keywords": ["online multi-objective convex optimization", "Pareto front", "primal-dual method"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/aadcb63dbc7ae071d61749654984cc48254bfa56.pdf", "supplementary_material": "/attachment/23743ffc99772fadc92ef5c8ebf728ce9e2b3ad3.zip"}, "replies": [{"content": {"summary": {"value": "This paper investigates online multi-objective convex optimization (OMCO), where a multi-objective optimization problem has no unique optimal solution, but a set of efficient solutions that do not dominate each other. The authors first show that the regret of OMCO is equal to that in classical OCO when the number of objectives decreases to one. Furthermore, they propose an Online Joint Gradient Descent algorithm, which achieves a sublinear multi-objective regret by the upper bound of regret. Finally, they also conduct experiments to validate the effectiveness of their proposed algorithm."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Overall, this paper is clearly written. The authors propose a novel multi-objective metric that improves upon previous work (Jiang et al., 2023). Moreover, the multi-objective regret can be reduced to the classical online setting regret. Finally, the experimental evaluation is thorough and convincing."}, "weaknesses": {"value": "This paper is primarily theoretical. However, the theoretical support is not entirely convincing. Regarding Theorem 1, I believe its theoretical contribution may not fully justify the designation of a theorem, and it might be more appropriate to present it as a proposition. In addition, my main concern lies in the significance of the proposed multi-objective regret and the corresponding OJGD algorithm. More specific issues are listed in the **Questions** section."}, "questions": {"value": "**Q1:** In Theorem 2, the authors present an equivalent form of the multi-objective regret. However, minimizing this metric is essentially equivalent to optimizing a weighted regret with arbitrarily chosen weights, due to $\\min_{\\lambda}$. Therefore, the proposed multi-objective regret may lack intrinsic significance. \n\n**Q2:** In the algorithmic development, the authors only consider minimizing the upper bound of the multi-objective regret in Eq. (9) rather than the original metric. It is evident that Eq. (8) represents a worst-case multi-objective target. Hence, it is unclear whether the proposed OJGD algorithm, which aims to optimize this worst-case formulation, provides substantial value."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0wM5uGcjtd", "forum": "RnNqSYqEcm", "replyto": "RnNqSYqEcm", "signatures": ["ICLR.cc/2026/Conference/Submission2016/Reviewer_mgg6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2016/Reviewer_mgg6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2016/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761386730775, "cdate": 1761386730775, "tmdate": 1762915990011, "mdate": 1762915990011, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies online multi-objective convex optimization (OMCO). A regret definition is proposed, derived from Translative scalarization. The authors show that this regret recovers the classical regret in online convex optimization (OCO) when the number of objectives is one. They further propose an algorithm that optimizes both action and the objective weights, and show that this algorithm achieves sub-linear regret under some assumptions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper is clearly structured. The core proofs are clear and appear technically correct on a first pass. The dynamic regret is provided in the appendix."}, "weaknesses": {"value": "Limited novelty compared to [Jiang et al, 2023]. I found the theoretical contribution of this paper to be weak. The proposed regret is essentially the same as [Jiang 2023], see Proposition 1, under convex conditions where we can intechange min and max. Besides, the algorithm seems to be a specialization of mirror-descent–style methods with Euclidean geometry (happy to be corrected if the authors think otherwise). The paper should make the precise relationship explicit and clarify what is genuinely new.\n\nUnconvincing discussion of “non-negative regret”. This paper claims in line 128-131 that [Jiang 2023] restrict the regret to be non-negative and positions this work as removing that restriction. In my opinion, this argument is weak since regret is almost non-negative. If negative values are possible under the authors' definition, the paper should provide an example demonstrating why this is meaningful. \n\nTheorem 1 shows that multi-objective regret is equal to the regret in OCO framework when p=1. This is very simple, expected, and does not advance understanding of the multi-objective case.\n\nThe experiments need more details. For example, in Fig 1 (a), how is the average regret computed at each round? How to compute the optimal \\lambda^* at each round?"}, "questions": {"value": "How to compute the average regret in Fig 1(a)?\n\nWhat is the technical novelty compared to [Jiang 2023]?\n\nIn Assumption 2, is it the loss to be convex instead of its gradient?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "PdnjQbacN5", "forum": "RnNqSYqEcm", "replyto": "RnNqSYqEcm", "signatures": ["ICLR.cc/2026/Conference/Submission2016/Reviewer_6Pcp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2016/Reviewer_6Pcp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2016/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761838043233, "cdate": 1761838043233, "tmdate": 1762915989840, "mdate": 1762915989840, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a unified framework for Online Multi-objective Convex Optimization (OMCO), generalizing the standard Online Convex Optimization (OCO) setting to multiple objectives. The authors introduce a new definition of multi-objective regret based on translative scalarization, show that it reduces to classical regret when the number of objectives is one, and derive an equivalent dual form via convex duality. They further propose an algorithm named Online Joint Gradient Descent (OJGD) that updates both the primal decision and the objective weights jointly in an online manner. The paper provides sublinear regret bounds under standard assumptions and some empirical validation on convex regression tasks and multi-task learning benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem itself (OMCO) is important and relevant to the ICLR community, especially with the clear connections to multi-task learning.\n\n2. The unification of OCO and OMCO within a single regret framework is interesting and conceptually sound.\n\n3.  The proposed OJGD algorithm is simple and computationally efficient (avoiding the QP of min-norm methods)."}, "weaknesses": {"value": "1. The paper spends a lot of time building up the new regret from Definition 4, based on translative scalarization. However, Theorem 2 immediately shows that this is equivalent to min-max problem.  This equivalent form in Eq. (6) looks very much like a standard minimax regret, i.e., finding the set of weights $\\lambda$ that defines the best scalarized regret against a learner. The idea of finding the best post-hoc scalarization is not new. The unification part (Theorem 1) also feels like an expected outcome. So, the contribution in Definition 4 feels more like a (slightly complex) re-formulation of a known concept rather than a fundamentally new performance metric.\n\n2. The algorithm is designed to solve the problem in Eq. (9), which is a classic online minimax (or saddle-point) problem. The update rules in Eq. (10) and (11) are a standard application of Online Gradient Descent-Ascent applied to the instantaneous loss $\\lambda^T {F}_t(x)$. The addition of the $\\alpha_t \\Delta(\\lambda_t)$ term is a minor modification (a regularization) to pull the weights back towards the initial $\\lambda_1$. This is a well-known algorithmic template."}, "questions": {"value": "1. Could you please clarify the novelty of the regret definition compared to the standard concept of a minimax regret (i.e., finding the optimal $\\lambda^*$ on the simplex that minimizes the weighted-sum regret)? The \"unification\" in Theorem 1 seems to follow directly from this, so the core contribution isn't entirely clear to me.\n\n2. How does the proposed OJGD algorithm (Eq. 10/11) fundamentally differ from a standard Online Gradient Descent-Ascent (OGDA) applied to the instantaneous game $\\mathcal{L}_t(x_t, \\lambda_t) = \\lambda_t^T F_t(x_t)$? It looks very similar to existing primal-dual methods for online saddle-point problems."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TuhEG5zPqd", "forum": "RnNqSYqEcm", "replyto": "RnNqSYqEcm", "signatures": ["ICLR.cc/2026/Conference/Submission2016/Reviewer_XQ86"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2016/Reviewer_XQ86"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2016/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942026488, "cdate": 1761942026488, "tmdate": 1762915989670, "mdate": 1762915989670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies Online multi-objective convex optimization by introducing multi-objective regret. The paper proposes a new multi-objective regret in OMCO based on translative scalarization that unifies the single and multi-objective frameworks. After an initial characterization of the problem, the paper proceeds to give algorithms based on the primal-dual framework. The paper is concluded by a set of experimental evaluations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper tackles an important extension of online convex optimization to the multi-objective setting, proposing a unified regret definition and algorithmic framework."}, "weaknesses": {"value": "I already reviewed this paper at NeurIPS 2025. I had included numerous points that concerned me, as well as several minor mistakes and typos. Unfortunately, none of these issues have been addressed in the updated version.\n\nThe central conceptual objection I had remains unresolved:\nThe paper still does not address the trivial algorithmic baseline: maintaining a separate regret minimizer for each objective and a meta-level regret minimizer that chooses which objectives to follow.\n\nThe lack of this discussion raises doubts about the necessity and novelty of the proposed method.\n\nAlso, the first half of the proof of Theorem 3 is just the standard calculations for OGD."}, "questions": {"value": "see weknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EMfLr82i5c", "forum": "RnNqSYqEcm", "replyto": "RnNqSYqEcm", "signatures": ["ICLR.cc/2026/Conference/Submission2016/Reviewer_Ggst"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2016/Reviewer_Ggst"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2016/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994023074, "cdate": 1761994023074, "tmdate": 1762915989333, "mdate": 1762915989333, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}