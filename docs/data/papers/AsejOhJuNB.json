{"id": "AsejOhJuNB", "number": 19137, "cdate": 1758293788909, "mdate": 1763118612346, "content": {"title": "Learning and Evaluating Visual Similarity Discovery under Incomplete Labeling", "abstract": "Visual Similarity Discovery (VSD) focuses on retrieving positives: images of distinct objects that exhibit perceptual similarity to a given query. This is a core need in applications like e-commerce and visual search. This work advances VSD research through several key contributions. First, we introduce a new VSD dataset in the furniture domain with over 63K labeled image pairs, providing a valuable resource for VSD learning and evaluation. Second, we propose two evaluation metrics that enable more reliable and consistent VSD performance assessment under incomplete labeling. Third, we show that supervised finetuning of multiple pretrained models on VSD labels significantly improves VSD performance. Moreover, we present Soft Positive Augmentation, a method that leverages existing VSD labels to infer soft positive relations among unlabeled pairs via weighted graph transitivity. Augmenting the VSD labels with these inferred soft positives during finetuning yields additional performance gains. Our code and dataset will be made publicly available.", "tldr": "", "keywords": ["visual similarity discovery"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/5a8595ab15152ef36ec068e37ad866b3604c9ad5.pdf", "supplementary_material": "/attachment/6f29c53524b81ab4fb73b1c023673e68415f1b92.pdf"}, "replies": [{"content": {"summary": {"value": "This paper addresses the challenge of Visual Similarity Discovery (VSD) under incomplete labeling, where many visually similar image pairs remain unlabeled due to generator-based retrieval bias. This limitation affects both evaluation reliability and model training.\n\nThe paper makes three main contributions:\n\n- VSD-Furniture Dataset:\nA new human-annotated dataset of over 63K image pairs in the furniture domain, extending prior VSD benchmarks beyond fashion using the Efficient Discovery of Similarities (EDS) paradigm.\n\n- Evaluation Metrics for Incomplete Labeling:\nThe authors propose two new metrics to improve robustness under sparse annotations:\nDiscounted Credit Score (DCS) emphasizes top-ranked retrievals and mitigates AUC’s limitations, while Estimated Hit-Ratio at K (EHR@K) normalizes for unlabeled results to ensure consistent evaluation.\n\n- Supervised Fine-tuning with Soft Positive Augmentation (SPA):\nFine-tuning pretrained models such as CLIP, DINOv2, and BEiT on VSD labels significantly improves performance. The proposed SPA method further enhances results by inferring soft positive relationships among unlabeled pairs via weighted graph transitivity.\n\nOverall, the paper presents a unified and practical framework for learning and evaluating VSD models in realistic, partially labeled settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Clearly explains the necessity and significance of the Visual Similarity Discovery (VSD) task and its differences from traditional retrieval or recognition settings\n\n- Provides comprehensive experiments with multiple pretrained models (CLIP, DINO, BEiT, etc.) and proposes quantitative evaluation using diverse metrics (AUC, BPREF, DCS, EHR@K).\n\n- Introduces practical methods (DCS, EHR@K, SPA) that effectively address the issue of incomplete labeling and improve fine-tuning results."}, "weaknesses": {"value": "- The main contribution is unclear. It combines dataset extension, metric design, and fine-tuning without a single coherent focus. The motivation for creating a new furniture-domain dataset using the same EDS pipeline is not fully convincing, as it seems an incremental domain extension.\n\n- The logical flow around DCS is confusing. The paper links generator bias (EDS limitation) with AUC’s triplet limitation but does not clearly explain how DCS specifically resolves these issues.\n\n- Presentation clarity is limited. The paper lacks a figure illustrating the full motivation and pipeline, and supervised fine-tuning is not novel—SPA should be emphasized more as the true methodological contribution."}, "questions": {"value": "- Could the authors include a figure or diagram illustrating the overall motivation and pipeline, showing how dataset construction, metric design, and SPA are connected?\n\n- Beyond supervised fine-tuning, have the authors considered alternative learning approaches more suited for VSD, such as semi-supervised, contrastive, or retrieval-specific adaptation methods?\n\n- The paper mentions using multiple generator models to aggregate top-K retrievals—could the authors clarify how this aggregation is performed (e.g., union, weighted ranking, or score fusion)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ISngkWoSb5", "forum": "AsejOhJuNB", "replyto": "AsejOhJuNB", "signatures": ["ICLR.cc/2026/Conference/Submission19137/Reviewer_fBez"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19137/Reviewer_fBez"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907249772, "cdate": 1761907249772, "tmdate": 1762931154642, "mdate": 1762931154642, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "comment": {"value": "We thank all reviewers for the time and effort invested in evaluating our paper, as well as for their comments and suggestions. While we addressed all concerns raised in our detailed responses, we nonetheless feel that the contribution and overall value of our work have been significantly underrated, particularly given its multiple substantive contributions to VSD research and its substantially more comprehensive, rich, and advanced treatment of VSD (on multiple fronts) compared to prior studies.\n\nFor these reasons, we have decided to withdraw the manuscript and submit it to another venue. We sincerely thank the reviewers again for their feedback."}}, "id": "ONePQjzLws", "forum": "AsejOhJuNB", "replyto": "AsejOhJuNB", "signatures": ["ICLR.cc/2026/Conference/Submission19137/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19137/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763118611221, "cdate": 1763118611221, "tmdate": 1763118611221, "mdate": 1763118611221, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a dataset created by experts on the topic of VSD. VSD (Visual Similarity Discovery) is the task of finding objects that are similar to the query object, but preferably not the exact same object. This is very relevant for the task of product suggestions, which we find in all commerce sites. They highlight the problem of incomplete labeling when training models for these tasks. In addition to the dataset, propose two evaluation metrics designed for VSD in the case of missing labels, and lastly empirical evidence showing that fine-tuning on VSD datasets significantly improves performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The authors address a very real and important problem in the VSD literature, namely incomplete labels in a VSD dataset. Furthermore, the authors have performed rigorous testing of the proposed metrics and show that they are \"better\" when using them on VSD with incomplete labeling."}, "weaknesses": {"value": "\"Using cosine similarity alone to generate candidate pairs systematically biases the dataset toward the geometry of the pretrained embedding space, which may not reflect perceptual or semantic similarity. The Circle-loss paper explicitly shows why cosine similarity is an incomplete measure of true pair similarity. Suggestions on what else to do could be to fine-tune the embedding models using the circle-loss, or similar. Other approaches might be to combine or use an ensemble of similarity metrics. Also, a minor formatting error: overlapping text in figure and paragraph on line 206-207.\n\n\\cite{https://arxiv.org/abs/2002.10857}"}, "questions": {"value": "I would like to see a test of the use of the similarity metrics, or at least a discussion as to why you think solely using cosine-similarity is enough."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2O7igVvTCO", "forum": "AsejOhJuNB", "replyto": "AsejOhJuNB", "signatures": ["ICLR.cc/2026/Conference/Submission19137/Reviewer_DEhh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19137/Reviewer_DEhh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942800317, "cdate": 1761942800317, "tmdate": 1762931154054, "mdate": 1762931154054, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a study on Visual Similarity Discovery (VSD)—retrieving visually similar but non-identical items—through a new dataset (VSD-Furniture), two evaluation metrics for handling incomplete labeling (Discounted Credit Score and Estimated Hit-Ratio@K), and a fine-tuning strategy called Soft Positive Augmentation (SPA). The authors position VSD as distinct from visual search or duplicate detection, focusing on perceptual similarity beyond exact matches. Experiments on the proposed dataset and fashion benchmarks show consistent gains from supervised fine-tuning and SPA."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well-written. It identifies a gap between standard visual search and perceptual similarity discovery. The newly proposed metrics try to mitigate some limitations of existing metrics—how incomplete labeling can bias retrieval evaluation—and the empirical validation may be technically right."}, "weaknesses": {"value": "The main conceptual concern lies in the unclear distinction between visual similarity discovery and conventional visual search. From a technical standpoint, the two tasks share almost identical pipelines, and a standard visual search system can naturally serve as a discovery engine by filtering out identical products. They share a similar goal, i.e., to rank the most visually similar objects higher based on retrievals. \n\nThis weakens the motivation for defining VSD as a separate problem space. The necessity of introducing a new dataset becomes questionable, considering strong benchmarks such as Stanford Online Products and In-Shop Clothes Retrieval–among others–already exist for evaluating visual similarity and retrieval models. The proposed VSD-Furniture dataset is limited to a single product category and modest in scale, which restricts its generalizability and practical impact. \n\nFurthermore, while the proposed metrics and fine-tuning strategies yield some improvements, the gains appear limited. Standard metrics such as Recall@K can already provide reasonable ranking–use different K values–estimates even under partial labeling, reducing the necessity of introducing new ones. Moreover, the reported benefits from fine-tuning are modest and do not seem to be significant observations."}, "questions": {"value": "Claiming MAP is “less effective” or should be excluded entirely seems to be a stretch. It could be better if the authors provided stronger evidence, rather than relying on a single reference to justify this decision."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "uRupsHZI5h", "forum": "AsejOhJuNB", "replyto": "AsejOhJuNB", "signatures": ["ICLR.cc/2026/Conference/Submission19137/Reviewer_XbZo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19137/Reviewer_XbZo"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961794071, "cdate": 1761961794071, "tmdate": 1762931153422, "mdate": 1762931153422, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on Visual Similarity Discovery under scenarios with incomplete labeling and presents four core contributions: (1) constructing the VSD-Furniture dataset, a VSD dataset in the furniture domain; (2) designing two evaluation metrics—Discounted Credit Score (DCS) and Estimated Hit-Ratio at K to adapt to incomplete labeling; (3) verifying that supervised finetuning using VSD labels can improve model performance; and (4) proposing the Soft Positive Augmentation (SPA) method, which mines potential similarity relationships in unlabeled samples via weighted graph transitivity to further enhance finetuning effects. Experiments on the VSD-Furniture and Fashion datasets validated the consistency of the proposed metrics and the effectiveness of the finetuning methods."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Visual Similarity Discovery is a scientifically significant problem. It addresses a core demand in practical applications such as e-commerce and visual search."}, "weaknesses": {"value": "1. **Notation and Formatting Issues:** The manuscript appears to be very hastily written, with numerous formatting and notation flaws. For instance, in the Abstract, there is ambiguity about an extra quotation mark after the phrase \"retrieving positives\". Additionally, the title of Figure 1 overlaps with the body text, making it difficult to read. These issues hinder the clarity of the manuscript and suggest a lack of careful proofreading. The authors should carefully polish and revise the manuscript to fix these formatting and notation problems.\n2. **Outdated Experimental Comparisons:** The methods used in the experiments are relatively outdated, and the paper lacks comparisons with more recent VSD-related methods developed in recent years. \n3. **Weak Theoretical Basis for Metrics:** The proposed metrics are only validated experimentally, with no proof of key mathematical properties. This lack of theoretical guarantees casts doubt on the metrics’ generalizability to other domains."}, "questions": {"value": "Please refer to the \"Weaknesses\" section for relevant questions and suggestions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "L4BLhT46Mm", "forum": "AsejOhJuNB", "replyto": "AsejOhJuNB", "signatures": ["ICLR.cc/2026/Conference/Submission19137/Reviewer_S4Wq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19137/Reviewer_S4Wq"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19137/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762006502066, "cdate": 1762006502066, "tmdate": 1762931152815, "mdate": 1762931152815, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}