{"id": "IrVGdVSJU1", "number": 4073, "cdate": 1757596026892, "mdate": 1759898054498, "content": {"title": "TL;DR: Too Long, Do Re-weighting for Efficient LLM Reasoning Compression", "abstract": "Large Language Models (LLMs) have recently achieved remarkable progress by leveraging Reinforcement Learning and extended Chain-of-Thought (CoT) techniques. However, the challenge of performing efficient language reasoning--especially during inference with extremely long outputs--has drawn increasing attention from the research community. In this work, we propose a dynamic ratio-based training pipeline that does not rely on sophisticated data annotations or interpolation between multiple models. We continuously balance the weights between the model's System-1 and System-2 data to eliminate redundant reasoning processes while preserving the model's reasoning capability. We validate our approach across models on DeepSeek-R1-Distill-7B and DeepSeek-R1-Distill-14B and on a diverse set of benchmarks with varying difficulty levels. Our method significantly reduces the number of output tokens by nearly 40% while maintaining the accuracy of the reasoning. Our code and data are at link: \\url{https://anonymous.4open.science/r/TLDR_Review-BBE5/}.", "tldr": "An Efficient Post-Training Method For Reasoning LLM.", "keywords": ["LLM", "Reasoning", "Compression"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/d050023dc14a10652e043fc68d4a3d9f39dcafbc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the issue of \"over-deliberation\" in Large Language Models (LLMs), where extensive System-2 (slow, deliberate) reasoning leads to excessive output token lengths and high inference costs, even on simple problems. The authors propose a novel training method called TLDR (Thinking Length Data Re-Weighting). Instead of relying on complex reinforcement learning or model merging, TLDR uses a dynamic SFT approach. It defines two data categories: System-1 (short CoT on easy problems) to encourage efficiency and System-2 (long CoT on difficult problems) to maintain reasoning accuracy. During training, the method dynamically adjusts the mixing ratio of these two data sources, guided by the model's performance on a validation set (monitoring both accuracy and output length). Experiments on 7B and 14B models show that TLDR can reduce output tokens by nearly 40% while maintaining accuracy comparable to the original, lengthy model, and is significantly more training-efficient than RL-based baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Clear Motivation & Strong Rationale: The paper is well-motivated by a practical problem (inference efficiency). The analysis in Section 2, which shows that naively mixing data fails, provides a strong and clear justification for the necessity of the proposed dynamic re-weighting approach.\n\nMethod Simplicity and Novelty: The TLDR method is elegant. By reformulating the compression problem as a dynamic data-weighting task solved with SFT, it avoids the high complexity and instability of reward-based (RL) methods or the architectural issues of model merging.\n\nExcellent Empirical Results: The method demonstrates significant, practical gains. It achieves a high token compression ratio (~40-45%) across multiple math benchmarks (Table 1) while suffering minimal to no accuracy degradation.\n\nTraining Efficiency: A key practical strength is the method's training speed. Table 3 shows TLDR is 8-10x faster than comparable RL-based methods like ThinkPrune or L1, making it a much more viable solution for model compression."}, "weaknesses": {"value": "Limited Evaluation Domain: The experiments are conducted exclusively on mathematical reasoning datasets (GSM8K, MATH, AIME, etc.). It is unclear if this \"System-1/System-2\" data paradigm and the TLDR method will generalize to other reasoning domains, such as commonsense reasoning (e.g., HellaSwag), code generation, or long-form creative/factual writing.\n\nDependency on Curated \"Hard\" Data: The method's success seems to rely on the availability of a high-quality \"difficult\" dataset (like S1) to source the System-2 data. The sensitivity to the choice and quality of this dataset is not fully explored, and it may be a bottleneck for applying the method to new domains where such data is not readily available."}, "questions": {"value": "Generalization to Other Tasks: How do you anticipate TLDR would perform on non-mathematical tasks? For example, in a domain like code generation, what would constitute \"System-1\" (easy) and \"System-2\" (hard) data, and would you expect a similar trade-off between efficiency and accuracy?\n\nSensitivity to Data Source: The ablation study (Table 4) shows that \"hard\" data is best for System-2. How sensitive is the method to this? For instance, what happens if the System-2 data is sourced from a \"medium\" difficulty dataset (like MATH500) instead of the \"hard\" S1 dataset? Does performance just degrade, or does the re-weighting algorithm fail to stabilize?\n\nBaseline Comparison (L1): In Table 5, TLDR is compared to the L1 baseline under a \"same\" token budget. How was this budget determined? Is it the average token length of the final TLDR model, and was the L1 model trained specifically to target this exact budget?\n\nI would like to improve my scores if authors can solve some questions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3h2PRa7ldo", "forum": "IrVGdVSJU1", "replyto": "IrVGdVSJU1", "signatures": ["ICLR.cc/2026/Conference/Submission4073/Reviewer_oLZs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4073/Reviewer_oLZs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4073/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910777171, "cdate": 1761910777171, "tmdate": 1762917164487, "mdate": 1762917164487, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the inefficiency of long Chain-of-Thought (CoT) reasoning in LLMs, which leads to excessive token usage during inference. It introduces **TL;DR**, a dynamic fine-tuning framework that adaptively balances short, intuitive (System-1) and long, deliberate (System-2) reasoning data using an exponentiated-gradient reweighting mechanism. This approach optimizes both efficiency and accuracy without requiring reinforcement learning or manual data curation. Experiments on multiple reasoning benchmarks show that TL;DR reduces output length while maintaining accuracy and training faster than prior RL-based compression methods."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "* How to tune the length of reasoning is a well-known issue related to LLM performance. The paper addresses a key challenge in the area by proposing a new method.\n* Empirically, the proposed method strikes a sweet balance between accuracy, inference reasoning length (or inference efficiency), and training efficiency (compared to RL).\n* Concrete experiments include extensive ablation studies revealing multiple insights."}, "weaknesses": {"value": "* The presentation is not clear, lacking citations. Many terms are not well defined. \n  - In Line 40-41, the argument is not citing any prior work. It is not clear which work is the mainstream model merging that represents training-free methods.\n  - In the paragraph starting from Line 73, the meaning of long CoT compression is not well defined. It is not clear if the proposed research is on training-based or training-free methods. \n  - In Line 86-87, there is no citation for clarifying which GSM8k and s1 datasets are. \n* Novelty is unclear, probably due to poor presentations. After reading the introduction, I am still confused about what is the techincal novelty of the method. Is this a data mixture method? What is the meaning of \"re-weighting\" in finetuning? What is the meaning of ratio learning? Why do we need a dynamic ratio? Since the reasoning length is associated with the difficulty of problems and the difficulties have been well defined in the datasets (GSM8k vs S1), a simple data pre-processing is enough to assign different length of reasoning to different problems of different difficulty.\n* Missing related literature on the key finding. The trade-off between the short and long thinking was studied but not well reviewed in the paper. For example,  short thinking degrades performance due to unnecessary reasoning detours [A], and longer thinking can cause LLM to be trapped in redundant verification loops [B]. Admittedly, the effect of using short or long reasoning data in fine-tuning is worth studying, but the results are expected. When LLMs are trained on short reasoning, the LLMs will reason shorter and therefore based on [A], the LLM performance will be degraded. \n* Because of the lack of related literature as aforementioned, the first contribution, the relation between reasoning length and accuracy, sounds trivial and its novelty is not well justified.\n* Doubtable efficacy. In the main results, the comparison to training-based methos is not well discussed. In hard tasks like AIME, AMC, Minerva, the performance of the proposed method is consistently worse than ThinkPrune, even if it reduce more tokens. The gap in accuracy is not ignorable. For example, 50 -> 43 on AIME by DS model. Such gaps are not noted in the discussion, and it may undermine the claimed efficacy of the proposed method.  \n\n[A] Wang, Y., Liu, Q., Xu, J., Liang, T., Chen, X., He, Z., ... & Yu, D. (2025). Thoughts are all over the place: On the underthinking of o1-like llms. arXiv preprint arXiv:2501.18585.\n\n[B] Chen, X., Xu, J., Liang, T., He, Z., Pang, J., Yu, D., ... & Yu, D. (2025). Do not think that much for 2+ 3=? on the overthinking of o1-like llms. ICML."}, "questions": {"value": "Why are TOPS and other data synthesis work not included as a baseline in the experiments? Specifically, the authors mentioned that \" Somework (Maetal.,2025;Jiangetal.,2025;Yuetal., 2025) synthesizes diverse-length CoT data, while TOPS (Yang et al., 2025) samples budget-sensitive versions using data model\", showing that these works are closely related."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EoJ4VvMRtl", "forum": "IrVGdVSJU1", "replyto": "IrVGdVSJU1", "signatures": ["ICLR.cc/2026/Conference/Submission4073/Reviewer_R9kL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4073/Reviewer_R9kL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4073/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932273879, "cdate": 1761932273879, "tmdate": 1762917164262, "mdate": 1762917164262, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents TL;DR (Thinking-Length Data Re-weighting), a method for compressing the reasoning length of Large Language Models (LLMs) without degrading accuracy. The approach dynamically adjusts the ratio between System-1 (short CoT) and System-2 (long CoT) data, using feedback from token length and accuracy metrics. Experiments on DeepSeek-R1-Distilled Qwen models (7B/14B) across GSM8K, MATH-500, AIME, AMC, and Minerva show around 40% token reduction with negligible accuracy loss compared to baseline reasoning compression methods such as CoT-Valve, ThinkPrune, and L1."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Compressing reasoning length for improved efficiency is an important and timely research direction, and the proposed method demonstrates strong empirical effectiveness.\n- The paper includes extensive ablation studies, providing thorough and convincing evaluations.\n- The proposed approach is clearly presented, easy to follow, and supported by released code, enhancing reproducibility."}, "weaknesses": {"value": "- I am somewhat unconvinced about the necessity of the dynamic re-weighting strategy in Algorithm 1. An ablation study comparing different re-weighting strategies would help clarify its contribution. For example, including simple baselines such as fixed curriculum ratios (large-to-small, small-to-large, or random re-weighting) could provide a clearer understanding of the proposed methodâ€™s effectiveness.\n\n- It would be helpful to clarify the inference settings in the experimental setup. For instance, the DeepSeek report uses a maximum sequence length of 32k and a temperature of 0.6 for AIME. From my own experience, AIME responses can easily exceed 10k tokens, which may not align with the results reported in Table 1."}, "questions": {"value": "- How about the generalizaton of this method, current evlaution tasks are all math tasks, if we'd like to go beyond to other tasks like code or common-sense, will it be important to collect mixed data from different domain for training."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3ZhvpIABsQ", "forum": "IrVGdVSJU1", "replyto": "IrVGdVSJU1", "signatures": ["ICLR.cc/2026/Conference/Submission4073/Reviewer_TPrS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4073/Reviewer_TPrS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4073/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960786667, "cdate": 1761960786667, "tmdate": 1762917164035, "mdate": 1762917164035, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes, TLDR: a mixed data construction and re-weighting of short and long CoT data for reasoning model's supervised finetuning. This helps the finetuned model generated precise yet accurate reasoning responses. The authors compared with prompt based, model merging based and RL based methods as baselines to demonstrate the efficacy of TLDR. The authors further categorize the sources\nof questions in the thinking compression data into three difficulty levels: easy, medium, and hard, to perform short and long CoT performance generalization analysis."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The data mixing idea to make models generate concise yet correct reasoning traces is new to me.\n2. The experiments were done on multiple datasets and models\n3. The model performance is consistently similar or better."}, "weaknesses": {"value": "1. The paper needs to be proof-read by a native english speaker, as there are certain grammar issues. Example: \"on reasoning LLMs, enabling the model to learn to generate more concise $\\textbf{yet still}$ correct reasoning paths.\"-- use \"yet\".\n\n2. The authors did not compare with training free reasoning compression methods ([1-2]).\n\n3. The overhead of manual selection easy to hard data as well as system-1, 2 categorization has additional labeling overhead in their SFT process.\n\n[1] SEAL: Steerable Reasoning Calibration of Large Language Models for Free, COLM 2025.\n\n[2] Activation Steering for Chain-of-Thought Compression, Arxiv 2025."}, "questions": {"value": "1. Is there any training compute or latency overhead of the process?\n\n2. Please compare with training free steering method for reasoning trace control."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Gw20mcl2fx", "forum": "IrVGdVSJU1", "replyto": "IrVGdVSJU1", "signatures": ["ICLR.cc/2026/Conference/Submission4073/Reviewer_FBQD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4073/Reviewer_FBQD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4073/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968126268, "cdate": 1761968126268, "tmdate": 1762917163831, "mdate": 1762917163831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}