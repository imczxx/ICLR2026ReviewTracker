{"id": "5LhpD6O5Sk", "number": 11889, "cdate": 1758204502064, "mdate": 1759897548601, "content": {"title": "TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers", "abstract": "Agentic systems often implement routing, shortlisting, gating, and verification with repeated frontier-LLM calls, which accumulates token/latency costs over a run. We introduce TabAgent, a framework that reframes such closed-set decision heads as textual–tabular classification trained on signals extracted from execution traces. TabAgent comprises (i) TabSchema, which distills schema, state, and dependency features from trajectories; (ii) TabSynth, which adds schema-aligned synthetic supervision to improve coverage of rare but decision-critical patterns; and (iii) TabHead, a compact classifier that outputs calibrated probabilities for each candidate in a single forward pass. Evaluated as a drop-in replacement for the GPT-based shortlister in IBM CUGA on AppWorld, TabAgent maintains shortlist quality—e.g., Recall@7 ≥ 0.88 and Recall@9 ≥ 0.92 across five applications—and, with TabSynth, improves macro P@R by +0.14 on average. Critically, TabAgent eliminates shortlist-time LLM calls, achieving a ~95% latency reduction and an 85–91% cost reduction relative to CUGA’s GPT-4.1 shortlister in our setup, while also generalizing to other heads such as application selection and task-complexity gating. These results suggest execution traces expose sufficiently rich, tabular-representable signals to replace generative components with efficient discriminative heads in production agentic architectures.", "tldr": "Single-pass textual–tabular head (TabAgent) replaces generative decision modules in agents, preserving tool shortlisting task quality while cutting latency by ~95% and cost by 85–91%.", "keywords": ["agentic systems", "tool shortlisting", "tabular models", "textual–tabular classifier", "execution traces", "schema/state/dependency features", "synthetic supervision", "routing/gating", "efficiency"], "primary_area": "applications to robotics, autonomy, planning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/740bc66abc1edb714c992c44dbd5e511b82f846f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes TabAgent, a framework that replaces expensive generative components in agent systems (like tool selection) with efficient tabular-textual classifiers trained from execution traces. By extracting structured features and using synthetic data to boost coverage, TabAgent achieves similar decision quality to LLM-based shortlisters while reducing inference cost by up to 90% and latency by 95%, making it a practical solution for scalable, low-cost agent deployment."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. **Practical Focus on Reducing Inference Cost in Agent Systems**  \n   The paper tackles a real bottleneck in deploying LLM-based agents at scale—high latency and cost from repeated generation. By proposing a discriminative alternative, it offers a concrete path toward more efficient agent execution.\n\n2. **Modular and Reusable Framework Design**  \n   The TabAgent architecture is presented in a modular manner (TabSchema, TabSynth, TabHead), making it relatively straightforward to apply the same approach to other agent components beyond tool selection.\n\n3. **Significant Efficiency Gains Demonstrated in Experiments**  \n   Results show that the framework can reduce inference cost by over 85% and latency by 95% while maintaining comparable performance, giving strong empirical support for the idea of replacing generation with classification in suitable cases."}, "weaknesses": {"value": "See questions."}, "questions": {"value": "1. **Limited Scope of Application**  \n   The proposed framework is only evaluated on a single tool-selection scenario. How can TabAgent be generalized to more complex agentic components (e.g., planning, dialogue control) where structured tabular data may be insufficient?\n\n2. **Dependence on Execution Traces**  \n   TabAgent relies heavily on historical agent execution traces for feature extraction and training. How does the method handle cold-start settings, or domains where such trajectories are unavailable or incomplete?\n\n3. **Synthetic Data Justification**  \n   The TabSynth module generates synthetic samples to augment training data, but the methodology seems heuristic. Are there any theoretical guarantees or empirical analyses showing that these synthetic examples preserve distributional fidelity and do not induce bias?\n\n4. **Limited Evaluation Metrics**  \n   The metrics focus mainly on latency and cost. Can the authors provide more comprehensive evaluations, such as error analysis on misclassified tools, or effects on downstream task success under diverse environments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6OxvaKqcvL", "forum": "5LhpD6O5Sk", "replyto": "5LhpD6O5Sk", "signatures": ["ICLR.cc/2026/Conference/Submission11889/Reviewer_YS7o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11889/Reviewer_YS7o"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11889/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959014403, "cdate": 1761959014403, "tmdate": 1762922903327, "mdate": 1762922903327, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work propose a new framework to reduce the overhead for agentic systems by replacing the long context to tabular and reformulate this problem to a classification problem. The results show the proposed framework TabAgent can reduce 95% latency but maintatin similar performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation is very clear to me.\n2. The evaluation are comprehensive and the results are convincing.\n\nThis work tries to solve an important problem and they find an interesting perspective, no matter the results or the rationale, I think the novelty is already there.\nThere are various results provided in the evaluation section and in the appedix, I appreciate these efforts."}, "weaknesses": {"value": "1. The organization and clarity can be improved.\n2.  More insights are required to make it better to understand.\n\nMy major concern about this work is the organization and clarity, but I believe these can be improved before submitting the camera-ready version. My detailed comments can be found below:\n1. The description of TabSynth is very limited, there is no visulization for it and I'm not sure whether I understand this part, either. I wonder howw do you validate the quality of the data generated by TabSynth? Maybe it is better clarify it and also include a subfigure of TabSynth in Fig 1.\n2. The TabSchema seems to be the core of this work. However, it is unclear to me why it works. I think this is one of the key difference between an empirical report and a scientific paper. Maybe it is better to include more insights in Section 3 and explain which part is TbSchema is original, and which part is inspried by previous works. Also, please include rationales behind the choices and show it in evaluations."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "rq3Fg1N8ZZ", "forum": "5LhpD6O5Sk", "replyto": "5LhpD6O5Sk", "signatures": ["ICLR.cc/2026/Conference/Submission11889/Reviewer_mSH6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11889/Reviewer_mSH6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11889/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968848434, "cdate": 1761968848434, "tmdate": 1762922902831, "mdate": 1762922902831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes the TabAgent framework, which aims to replace the LLM-based generative decision modules with a lightweight discriminative classifier. This avoids the slow rollout of the LLM models when repetitively generating tokens to decide the final action, rather, the classifier can make the decision in one forward pass.\n\nTabAgent first converts agent execution traces into a structured form named TabSchema using a LLM. Specifically, the key details about the task’s schema, current state, and dependencies are converted into a structural format. This converts the raw trajectory data into a features that describes each decision point and the available candidate options. Then, TabSynth synthesizes extra training data by generating synthetic examples that follow the same schema.\n\nThe TabHead is trained on both real and synthesized data, and achieve better performance than DSR and LLM-based methods on AppWorld task with IBM CUGA agent framework."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Strong motivation -- attempting the tackle the slowness problem in the current agent framework due to the LLM autoregressive token generation.\n- Clear design of the TabAgent framework, which is consist of constructing TabSchema from traces, synthesizing more training data with TabSynth, and training the TabHead classifier to replace expensive generative decision components.\n- Strong improvement in the efficiency of the agent framework, which achieves good performance while reducing the inference cost and time."}, "weaknesses": {"value": "- What is the generalizability of to other tasks than AppWorld under the IBM CUGA agentic framework?\n- How flexible can TabAgent framework be adapted to another agent framework compared to the baselines?\n- What is the performance comparisons LLMs designed specifically for agentic usage?\n- What would be the benefit of TabAgent over fine-tuning small language models regarding to cost-effectiveness (https://arxiv.org/abs/2506.02153)?\n- To what extend the TabAgent is reliant on GPT-4.1 for TabSchema extraction? What would the performance impacts be if weaker or stronger models are adopted?"}, "questions": {"value": "The main questions are already reflected in the weakness listed above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vGh3zHukc3", "forum": "5LhpD6O5Sk", "replyto": "5LhpD6O5Sk", "signatures": ["ICLR.cc/2026/Conference/Submission11889/Reviewer_BrTr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11889/Reviewer_BrTr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11889/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762424501429, "cdate": 1762424501429, "tmdate": 1762922902164, "mdate": 1762922902164, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}