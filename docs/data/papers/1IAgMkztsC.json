{"id": "1IAgMkztsC", "number": 8920, "cdate": 1758102563374, "mdate": 1759897754128, "content": {"title": "EVADE-Bench: Multimodal Benchmark for Evasive Content Detection in E-Commerce Applications", "abstract": "E-commerce platforms increasingly rely on Large Language Models (LLMs) and Vision–Language Models (VLMs) to detect illicit or misleading product content. However, these models remain vulnerable to evasive content: inputs (text or images) that superficially comply with platform policies while covertly conveying prohibited claims. Unlike traditional adversarial attacks that induce overt failures, evasive content exploits ambiguity and context, making it far harder to detect. Existing robustness benchmarks provide little guidance for this high-stakes, real-world challenge. We introduce EVADE-Bench, the first expert-curated, Chinese, multimodal benchmark specifically designed to evaluate foundation models on evasive content detection in e-commerce. The dataset contains 2,833 annotated text samples and 13,961 annotated images spanning six categories, including body shaping, height growth, health supplements, and others. Two complementary tasks assess distinct capabilities: Single-Violation, which probes fine-grained reasoning under short prompts, and All-in-One, which tests long-context reasoning by merging overlapping policy rules into unified instructions. Our benchmarking of 26 mainstream LLMs and VLMs reveals that even state-of-the-art models frequently misclassify evasive samples. By releasing EVADE-Bench, we provide the first rigorous standard for evaluating evasive-content detection, expose fundamental limitations in current multimodal reasoning, and lay the groundwork for safer and more transparent content moderation systems in e-commerce.", "tldr": "Our paper introduces EVADE-Bench, a benchmark for evaluating how LLMs and VLMs handle evasive content in e-commerce, focusing on detecting misleading ads and comparing the performance of open-source and closed-source models.", "keywords": ["E-commerce", "Evasive Content Detection", "Benchmark", "Large Language Models", "Vision Language Models", "Chinese"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5866342d6d0dcd5effa14b7988b6d4d472a6175c.pdf", "supplementary_material": "/attachment/524fa4345f74806a19c01e43fd25c881cb7254b0.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents EVADE-Bench, a Chinese multimodal benchmark for detecting evasive content in e-commerce advertisements, where sellers deliberately obscure prohibited claims.\nThe dataset contains 2.8K text and 13.9K image samples annotated by domain experts under six product categories.\nTwo evaluation settings are designed: Single-Violation and All-in-One.\nThe authors benchmark 26 LLMs and VLMs, analyze their accuracy under Partial/Full match metrics, and further explore RAG/SFT enhancements."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "(1) EVADE-Bench tackles a practically important and underexplored safety problem (e-commerce content moderation) and provides the first large-scale Chinese multimodal dataset aligned with legal advertising rules.\n\n(2) The split between Single-Violation and All-in-One tasks provides interesting insights into how rule clarity and context length affect model reasoning.\n\n(3) The discussion on hallucination, omission, OCR distortion, and rule-matching bias provides useful diagnostics for practitioners."}, "weaknesses": {"value": "1. The work primarily repackages an individual content-moderation pipeline. It lacks a methodological or conceptual contribution to multimodal reasoning or safety. The dataset is heavily tied to Chinese e-commerce advertising and cannot generalize to other safety or reasoning contexts. Thus, it does not qualify as a \"foundation benchmark\", but rather a domain-specific dataset.\n\n2. The results are broad but shallow, no causal or ablation analysis of why model fail, or what architecture factors matter. The paper's Section 5.5 presents a discussion of adopting a two stage VLM --> LLM pipeline inspired by Prism. However, no corresponding experiments or quantitative results are reported. The discussion remains conceptual, which weakens the empirical rigor of the paper's analytical claims.\n\n3. The paper does not disclose the exact data source (which platforms, how samples were licensed, whether commercial content was reproduced), raising reproducibility and ethical concerns."}, "questions": {"value": "1. Could the authors clarify the data collection sources and the legal/ethical permissions involved?\n\n2. Have the authors tried multimodal decomposition (VLM→LLM reasoning) empirically, or is this purely conceptual?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "c2HzavdyOD", "forum": "1IAgMkztsC", "replyto": "1IAgMkztsC", "signatures": ["ICLR.cc/2026/Conference/Submission8920/Reviewer_9eFs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8920/Reviewer_9eFs"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8920/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761297985668, "cdate": 1761297985668, "tmdate": 1762920671375, "mdate": 1762920671375, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces EVADE-Bench, the first expert-curated Chinese multimodal benchmark designed to evaluate the performance of Large Language Models (LLMs) and Vision-Language Models (VLMs) in detecting evasive content in e-commerce scenarios. The benchmark comprises 2,833 text samples and 13,961 annotated images across six product categories (e.g., body shaping, height growth, health supplements) and includes two core tasks: Single-Violation (assessing fine-grained reasoning with short prompts) and All-in-One (testing long-context reasoning with unified, rule-intensive instructions). Through evaluating 26 mainstream LLMs and VLMs, the paper finds that state-of-the-art models frequently misclassify evasive content, and highlights the effectiveness of rule categorization, Retriever-Augmented Generation (RAG), and Supervised Fine-Tuning (SFT) in improving model performance. The work aims to lay the groundwork for safer e-commerce content moderation systems."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Working on a real-world application challenge by focusing on evasive content detection.\n2. Constructs a large-scale, expert-annotated multimodal dataset (covering text and image inputs) with rigorous annotation pipelines, ensuring high-quality and regulation-aligned ground truth.\n3. Conducts extensive experiments on 26 LLMs/VLMs (both open-source and closed-source), offering systematic baselines and detailed error analysis that sheds light on model limitations in multimodal reasoning.\n4. Validates practical improvement strategies (RAG, SFT, rule merging) that can be directly applied to enhance real-world content moderation systems."}, "weaknesses": {"value": "1. Unclear definition of Evasive Content Detection (ECD): The paper fails to provide a rigorous, cited definition of ECD, leaving ambiguity about its scope and distinguishing features. It also does not adequately justify why ECD is a unique and critical task for LLMs/VLMs, nor does it clarify how ECD differs from existing QA or adversarial detection tasks.\n2. Narrow focus on domain-specific scenarios without generalizable capability assessment: The benchmark is limited to six e-commerce product categories, and the paper does not attempt to decouple domain-specific knowledge from core reasoning abilities (e.g., semantic understanding, logical inference). This limits the generalizability of the results to other evasive content detection scenarios.\n3. Lack of novelty in research contributions: The work primarily reports experimental results using existing techniques (benchmark construction, RAG, SFT) without introducing innovative methods, frameworks, or theoretical insights. It functions more as a benchmark report than a novel research contribution.\n4. Insufficient analysis of cross-category and cross-modality consistency: The paper does not deeply explore why model performance varies drastically across product categories (e.g., health supplements vs. body shaping) or modalities (text vs. image), missing opportunities to identify modality-specific or category-specific bottlenecks.\n5. Limited discussion of benchmark generalizability and external validity: There is no analysis of whether EVADE-Bench’s samples are representative of real-world evasive content at scale, nor is there evidence that model performance on this benchmark correlates with real-world content moderation effectiveness.\n6. Please fix grammer issue: english -> English, chinese -> Chinese"}, "questions": {"value": "1. How do the evasive content strategies in EVADE-Bench compare to those observed in non-e-commerce domains (e.g., social media, healthcare), and would the benchmark’s evaluation framework be adaptable to these domains?\n2. Did the authors consider cross-lingual generalizability? Given that EVADE-Bench is Chinese-focused, would the observed model limitations and improvement strategies transfer to other languages?\n3. How do the expert annotations account for evolving e-commerce regulations? Is there a plan to update the benchmark as policies change over time?\n4. This paper mentioned adversarial attacks. What is the relationship between ECD and adversarial attacks? How can this benchmark help to defend against adversarial attacks?"}, "flag_for_ethics_review": {"value": ["Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)"]}, "details_of_ethics_concerns": {"value": "The benchmark involves e-commercial content crawled from the web."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SU1LoGdMA7", "forum": "1IAgMkztsC", "replyto": "1IAgMkztsC", "signatures": ["ICLR.cc/2026/Conference/Submission8920/Reviewer_kXw3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8920/Reviewer_kXw3"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8920/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761400658844, "cdate": 1761400658844, "tmdate": 1762920670814, "mdate": 1762920670814, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents EVADE-Bench, a new Chinese multimodal benchmark designed to evaluate large language models (LLMs) and vision–language models (VLMs) on evasive content detection in e-commerce. The dataset contains 2,833 expert-annotated text samples and 13,961 annotated images across six high-risk product categories. The authors benchmark 26 open- and closed-source LLMs/VLMs, revealing substantial performance gaps and common reasoning failures. Additional experiments using retrieval-augmented generation (RAG) and supervised fine-tuning (SFT) demonstrate measurable improvements in detection accuracy. The paper further provides a detailed analysis of common error types and discusses a potential multi-agent or decomposed multimodal reasoning paradigm for future development. Overall, this work establishes the first rigorous benchmark standard for evaluating evasive content detection, offering a valuable foundation for developing safer and more transparent content moderation systems in e-commerce, and exploring effective strategies such as RAG and SFT to enhance large models’ compliance detection capabilities."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. According to the authors, this work presents the first Chinese multimodal benchmark for evasive content detection in e-commerce scenarios. The study holds strong practical significance in detecting potentially deceptive or policy-violating advertisements and demonstrates both social value and pioneering potential in improving content safety and regulation in online commerce.  \n\n2. The authors employ a data construction pipeline that integrates human experts and large language models (LLMs), ensuring both the difficulty and quality of the dataset’s questions.  \n\n3. The paper conducts extensive experiments on the proposed benchmark, covering both open-source and closed-source models, as well as LLMs and VLMs, thoroughly validating the dataset’s effectiveness and quality.  \n\n4. In addition to the construction and evaluation of the dataset, this paper also examines the performance of RAG and SFT in optimizing the effectiveness of content avoidance detection, providing valuable insights and clear directions for further utilization of LLMs and VLMs in this field.  \n\n5. The authors provide comprehensive supplementary materials, including dataset construction methods, examples, and detailed definitions, which is commendable and enhances the transparency and reproducibility of the work."}, "weaknesses": {"value": "1. The differences between the two task paradigms, Single-Violation and All-in-One, are not sufficiently explained.  \n\n2. The paper lacks an evaluation of annotation quality. Given that the task is a complex multi-class classification problem, inter-annotator agreement among experts is essential to ensure data reliability.  \n\n3. In the All-in-One task, the authors introduce two subtasks, “simplified description” and “detailed description,” but the motivation behind this design and the performance analysis across these subtasks are not adequately discussed.  \n\n4. The study does not include accuracy baselines from traditional methods (e.g., rule-based systems or human review), making it difficult to assess the true performance level of LLMs and VLMs on this task."}, "questions": {"value": "1. Could the authors more clearly explain the conceptual and functional differences between the “single-violation” setting and the “all-in-one” setting? If possible, including detailed case examples in the supplementary material would better illustrate the differences and motivations behind these two settings.  \n\n2. The rationale for the partial-accuracy metric needs further explanation and analysis, especially in practical application scenarios. If a model tends to predict many violation categories, its partial accuracy could be very high — but this circumstance may be risky in real-world use.\n\n3. Have the authors considered including human performance (from laypeople or experts) or traditional detection methods on the dataset? Given that evading content detection is a difficult task with many classes and hidden content, adding human accuracy would provide a better benchmark for model performance.\n\n4. Regarding the particularly poor model performances in Table 2, did the authors verify that model inference was executed correctly? The authors suggest differences in model architecture and training strategies as an explanation — is this a reasonable account? Please provide detailed descriptions of how Deepseek-VL2 differs in architecture and training strategy from the other VLMs listed in the table. \n\n5. The setups in Table 2 and Table 4 are confusing: Table 2 lists 23 models while Table 4 lists only 22. It appears that Deepseek-VL2, which performs poorly in Table 2, was omitted from Table 4 — this further raises doubts about whether Deepseek-VL2 was properly evaluated. The formats of Table 2 and Table 4 also need to be made consistent so readers can better compare model performance across tasks; consider uniformly distinguishing open-source and closed-source models.  \n\n6. From the tables, the authors only include the “simplified description” and “detailed description” sub-tasks under the All-in-One task — what motivated this choice? Also, please provide example cases in the supplementary material to demonstrate the specific differences between simplified and detailed descriptions. \n\n7. In the error analysis section, the authors mention that stronger models are more likely to misinterpret prompt rules. One hypothesis is that stronger models possess more powerful reasoning capabilities and thus amplify deviations from human understanding — what is the detailed causal relationship here? Please supplement with a thorough explanation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vt21qFWU7d", "forum": "1IAgMkztsC", "replyto": "1IAgMkztsC", "signatures": ["ICLR.cc/2026/Conference/Submission8920/Reviewer_XC9t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8920/Reviewer_XC9t"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8920/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982302532, "cdate": 1761982302532, "tmdate": 1762920670333, "mdate": 1762920670333, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors present a Chinese multimodal benchmark for evasive content detection for E-Commerce scenarios. The benchmark can support two kinds of evalution tasks: single violation and all-in-one, which help discriminate the reasoning ability under different fine-grained levels. The authors further perform evaluation for 26 open- and closed-source LLMs and VLMs under zero-shot, few-shot, RAG and SFT settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well written and easy to follow.\n2. The task of evasive content detection is meaningful for many real-world scenarios. The proposed benchmark bears significant value towards the enhancement of the relevant techniques.\n3. The authors perform a series of evaluation with the existing LLMs and VLMs. The results and error analysis shed a light on the further development."}, "weaknesses": {"value": "1. The human annotation quality is not uncovered by the authors. It is unknown how hard this task is even for a human being. Also, fine-grained breakdown of the category distribution of the dataset should be reported."}, "questions": {"value": "See the above 'Weaknesses'."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2fQg1acRtH", "forum": "1IAgMkztsC", "replyto": "1IAgMkztsC", "signatures": ["ICLR.cc/2026/Conference/Submission8920/Reviewer_YKj2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8920/Reviewer_YKj2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8920/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762079979268, "cdate": 1762079979268, "tmdate": 1762920669807, "mdate": 1762920669807, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}