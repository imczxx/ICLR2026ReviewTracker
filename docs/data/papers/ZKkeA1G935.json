{"id": "ZKkeA1G935", "number": 1449, "cdate": 1756883497560, "mdate": 1759898208587, "content": {"title": "Can LLMs Alleviate Catastrophic Forgetting in Graph Continual Learning? A Systematic Study", "abstract": "Nowadays, real-world data, including graph-structure data, often arrives in a streaming manner, which means that learning systems need to continuously acquire new knowledge without forgetting previously learned information. Although substantial existing works attempt to address catastrophic forgetting in graph machine learning, they are all based on training from scratch with streaming data. With the rise of pretrained models, an increasing number of studies have leveraged their strong generalization ability for continual learning. Therefore, in this work, we attempt to answer whether large language models (LLMs) can mitigate catastrophic forgetting in graph continual learning}. We first evaluate the performance of LLMs and graph foundation models in graph continual learning scenarios, and found that with minimal modifications, they can easily achieve state-of-the-art results. Moreover, we found that certain current settings for graph continual learning tasks have significant flaws; it is possible to achieve zero forgetting with simple manipulations. Finally, based on extensive experiments, we propose a simple-yet-effective method, Simple Grpah Continual Learning (SimGCL), that surpasses the previous state-of-the-art baselines by around 20% under the rehearsal-free constraint.", "tldr": "Benchmarking LLMs and graph foundation models in continual learning on graph-structured data.", "keywords": ["graph continual learning;graph neural networks;large language models"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/47fa5b9634c3950d7e778950f4693e5137f93dd2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates whether large language models (LLMs) can help overcome catastrophic forgetting in Graph Continual Learning (GCL) tasks. \n\n- They have identified a serious flaw, task ID leakage, in common GCL evaluations, where models inadvertently access task identifiers during testing.\n\n- They introduce LLM4GCL, the first systematic benchmark for LLMs in GCL.\n\n- Proposed a method, SimGCL, that consistently achieves state-of-the-art results and mitigates forgetting effectively."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "### 1. Theoretical Soundness\n- The work is well motivated as the authors have identified that all prior GCL methods train from scratch and do not exploit pretrained models’ generalization.\n\n- Uses Parameter-Efficient Fine-Tuning (PEFT) via LoRA, a proven method for adapting large models efficiently.\n\n- Employs prototype-based classification, which is widely accepted as a way to mitigate forgetting in continual learning.\n\n- The graph prompt design is conceptually consistent with instruction tuning paradigms in multimodal LLMs.\n\n### 2. Experimental Soundness\n- The paper introduces LLM4GCL, with 9 LLM/GLM methods and 7 datasets. This is a substantial empirical foundation for a GCL.\n\n- The identification of task ID leakage in existing setups is a major contribution.\n\n- They release code, datasets, and standardized evaluation. This is a strong signal of methodological transparency."}, "weaknesses": {"value": "### 1. Theoretical Limitations\n- They assume graph structure can be effectively encoded as text prompts. While innovative, this verbalization step might oversimplify structural relationships, potentially losing fine-grained topology information.\n\n- Use of LoRA only in the first session assumes that continual adaptation can be achieved purely through frozen embeddings and prototype updates — a strong assumption that may not generalize across highly dynamic graph evolutions.\n\n- Missing formal theoretical analysis of why the prototype mechanism preserves generalization in LLM-embedded graph representations (e.g., no bounds on forgetting or feature drift).\n\n### 1. Experimental Limitations\n- The authors do not deeply dissect which component of SimGCL contributes most (LoRA, prototype, or prompt design). Without that, causal claims (“graph prompts mitigate forgetting”) remain partially speculative.\n\n- In small-scale datasets like Cora and Citeseer, very large LLMs might overfit to textual node attributes, inflating reported improvements."}, "questions": {"value": "Please refer to the weakness section. I would urge the authors to pay special attention to the following concerns first.\n\n- The work is conceptually sound and empirically motivated but not theoretically grounded. The rationale aligns with existing literature, but lacks formal guarantees. Can the authors provide some theoretical justifications to their method?\n\n- Empirical claims are mostly well-supported, though some causal explanations (e.g., why GLMs fail) remain conjectural. Therefore, I request the authors to substantiate such claims.\n\n- Address limited ablation analyses and potential structural oversimplifications when converting graph topology into text prompts."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AVeqvEINC6", "forum": "ZKkeA1G935", "replyto": "ZKkeA1G935", "signatures": ["ICLR.cc/2026/Conference/Submission1449/Reviewer_FyMh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1449/Reviewer_FyMh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1449/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760764638305, "cdate": 1760764638305, "tmdate": 1762915772336, "mdate": 1762915772336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the problem of graph continual learning and proposes a method based on LLMs. Different from the previous settings, the authors provide a new setting called global testing and construct a benchmark. Based on the benchmark, a new method based on LLMs and prototype learning is proposed."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and easy to follow. The code is released.\n\n2. A new benchmark is proposed to evaluate the performance of LLMs and graph-enhanced LLMs.\n\n3. The authors identify the flaw of existing GCL settings and propose global testing. To utilize the generalization capacity of LLMs, a GLM-based approach is proposed."}, "weaknesses": {"value": "1. The constraint of setting each task to have a unified sample size is unreasonable, and the label imbalance problem is the real challenge that should be addressed.\n\n2. The introduction of global testing is not very clear. More clear figures or visualizations are needed.\n\n3. The used graphs are all text-attribute graphs (TAGs). Can the proposed method be extended to non-TAGs?\n\n4. Experimental details should be included in the main paper to provide readers with a general picture of the experimental settings.\n\n5. There are some typos, and the authors should carefully revise the paper."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "tys4mYy3Gm", "forum": "ZKkeA1G935", "replyto": "ZKkeA1G935", "signatures": ["ICLR.cc/2026/Conference/Submission1449/Reviewer_FJeP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1449/Reviewer_FJeP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1449/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761037997022, "cdate": 1761037997022, "tmdate": 1762915772087, "mdate": 1762915772087, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates whether large language models can alleviate catastrophic forgetting in graph continual learning (GCL). The authors identify flaws in existing GCL evaluation protocols—particularly task ID leakage—and propose a revised global testing setup. They introduce LLM4GCL, a new benchmark encompassing multiple GNN-, LLM-, and GLM-based methods across seven text-attributed graph datasets, and propose SimGCL that combines graph-structured prompts with prototype-based prediction. Experimental results indicate that SimGCL performs competitively under various GCL settings, suggesting that pretrained LLMs have potential for continual graph learning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper tackles an underexplored question—whether large language models (LLMs) can mitigate catastrophic forgetting in graph continual learning.\n2. A benchmark, LLM4GCL, is developed."}, "weaknesses": {"value": "1. My biggest concern lies in the motivation. The primary goal of continual learning is to enable efficient adaptation under limited resources, whereas LLMs are inherently computationally expensive. It is unclear whether the significant computational cost introduced by LLMs can truly justify the efficiency-driven learning protocol that continual learning aims to achieve.\n\n2. Following this point, I believe the comparison should include GCL methods that allocate additional parameters (expansion-based) or memory (experience-replay-based) to narrow the substantial computational gap between LLMs and traditional GNNs. However, the authors compare their method only with regularization-based approaches, which are the most resource-limited class of GCL methods. Furthermore, the comparisons are arguably unfair since the methods rely on different backbone architectures for graph prediction.\n\n3. The authors acknowledge task ID leakage and address it by introducing a global testing protocol, which is commendable. Nonetheless, all the datasets used (e.g., Cora, Citeseer, WikiCS) are widely used text-attributed benchmarks that may overlap with the pretraining corpora of LLMs. The paper does not verify whether such overlap exists, leaving potential knowledge leakage from pretraining unaddressed.\n\n4. I also find the fairness of the LLM4GCL benchmark setup questionable. The LLM baselines are not fine-tuned on the same datasets and therefore lack domain knowledge of LLM4GCL, making the comparison asymmetric. The proposed method appears less focused on mitigating catastrophic forgetting and more on task-specific instruction tuning, which may even result in overfitting to the given dataset. This is evidenced by the large performance gap between the proposed method and other LLM-based baselines on LLM4GCL, in contrast to the much smaller gap observed on standard public datasets. Overall, the comparisons and evaluations in this paper feel ambiguous, making it difficult to discern the central message or takeaway the authors intend to convey."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WeCnigr8U7", "forum": "ZKkeA1G935", "replyto": "ZKkeA1G935", "signatures": ["ICLR.cc/2026/Conference/Submission1449/Reviewer_PWgw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1449/Reviewer_PWgw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1449/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761700703421, "cdate": 1761700703421, "tmdate": 1762915771859, "mdate": 1762915771859, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an extension of the Online Graph Learning problem formulation, aiming to address some of the limitations typically found in existing literature. Based on this revised formulation, the authors define two scenarios: a standard setting and a few-shot setting. They evaluate both conventional graph-based approaches and LLM-based methods. Finally, the paper introduces SimCML, a model that leverages a single round of instruction tuning to directly produce class prototypes from the embeddings generated by its fine-tuned LLM."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper explores a novel approach that connects LLMs with the graph continual learning framework. Moreover, it analyzes the commonly used GCL scenario, revealing an interesting limitation and proposing a solution to address this issue."}, "weaknesses": {"value": "The paper presents several issues, mainly related to the clarity of presentation and the design of the experimental framework.\nRegarding the presentation, the paper does not clearly explain the proposed model or the models used for comparison. As a result, many methodological choices are not properly justified. Going into more detail, in the introduction, the authors claim that there is a lack of investigation into the rationality of the common experimental setup used for GCL. It is worth noting that a recent study has already explored this aspect [1]. Another meaningful reference that should be considered and discussed is [6].\nIn the background section, the authors correctly highlight one of the main limitations of the commonly adopted GCL setting, which I agree with, and propose the idea of global testing. However, it is not clear how this proposal relates to the subsequent discussion about inter-task edges, which the authors claim not to consider in their tasks. This choice isolates subgraphs, making the problem closer to the original formulation. This point should be discussed and clarified in greater depth. Furthermore, the removal of the limited-representation classes appears to be a strong design choice that requires a more thorough discussion, particularly regarding its advantages and potential drawbacks.\nIn Section 3.2, the authors claim that the considered datasets cover a wide range of possible sizes. However, in practice, the investigation is limited to relatively small datasets. Large-dimensional datasets, such as OGN-Products and Reddit [2], are not considered. Moreover, most of the selected datasets are citation networks. Considering that the goal of the paper is to establish a benchmark for testing models in GCL, the dataset selection appears rather limited. Another important distinction that can significantly impact the GCL scenario is the difference between heterophilous and homophilous datasets, which is not addressed in this work.\nIn the paper, both the definitions of the literature methods and that of the proposed SimCML are not presented clearly, which makes it difficult to follow the flow of the discussion and to evaluate the novelty of the proposed approach. For instance, the discussion of the LLM baseline is very limited, the authors only state that it is nascent and that no methods have yet been specifically designed for CGL tasks. What remains unclear is how the LLM baselines are actually applied in the context of CGL, and consequently how the reported results are obtained. Regarding the models considered, it is surprising that the authors do not include several of the most promising replay-based approaches, such as CaT [3], PDGNN [4], SSM [5], among others. Another major issue is the lack of explanation regarding the experimental setting and the validation policy. While the appendix lists the hyperparameters considered, many of them are fixed, and it is not clear how these values were selected. Considering the aim of the paper, this represents a significant limitation. Moreover, the results reported in the tables do not include any measures of variance or standard deviation, raising concerns about whether the experiments were run only once. If this is the case, it is unclear how the authors assess the stability of the results or the statistical significance of the differences between models. This is particularly important for the LLM application, where variance in results is typically more pronounced.\n\n\n[1] Donghi, G., Pasa, L., Zambon, D., Alippi, C. and Navarin, N., 2025. Online Continual Graph Learning. arXiv preprint arXiv:2508.03283.\n\n[2] Zhang, X., Song, D. and Tao, D., 2024. Continual learning on graphs: Challenges, solutions, and opportunities. arXiv preprint arXiv:2402.11565.\n\n[3] Liu, Y., Qiu, R. and Huang, Z., 2023, December. Cat: Balanced continual graph learning with graph condensation. In 2023 IEEE International Conference on Data Mining (ICDM) (pp. 1157-1162). IEEE.\n\n[4] Zang, X., Song, D., Chen, Y. and Tao, D., 2024, August. Topology-aware embedding memory for continual learning on expanding networks. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (pp. 4326-4337).\n\n[5] Zhang, X., Song, D. and Tao, D., 2022, November. Sparsified subgraph memory for continual graph representation learning. In 2022 IEEE International Conference on Data Mining (ICDM) (pp. 1335-1340). IEEE.\n\n[6] Huang, S., Parviz, A., Kondrup, E., Yang, Z., Ding, Z., Bronstein, M., Rabbany, R. and Rabusseau, G., 2025. Are Large Language Models Good Temporal Graph Learners?. arXiv preprint arXiv:2506.05393."}, "questions": {"value": "-Could the authors clarify and provide more details on the proposed SimCML model and the LLM baselines, particularly how these baselines are applied in the context of GCL?\n\n-Could the authors provide more information on how the hyperparameters were selected and the validation protocol used? Additionally, were the experiments repeated to assess the stability and statistical significance of the results?\n\n-Considering the goal of establishing a benchmark for GCL, could the authors comment on the choice of datasets and whether including large-dimensional datasets or heterophilous/homophilous distinctions might affect the evaluation?\n\n-Could the authors discuss the rationale for not including certain replay-based approaches, such as CaT, PDGNN, and SSM, and how their inclusion might impact the evaluation of SimCML?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Jt6m0PfM5S", "forum": "ZKkeA1G935", "replyto": "ZKkeA1G935", "signatures": ["ICLR.cc/2026/Conference/Submission1449/Reviewer_Sw4z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1449/Reviewer_Sw4z"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1449/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761761212385, "cdate": 1761761212385, "tmdate": 1762915771475, "mdate": 1762915771475, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a systematic and timely investigation into the potential of large language models (LLMs) to mitigate catastrophic forgetting in graph continual learning (GCL). They introduce a more rigorous global testing setup and develop LLM4GCL, a comprehensive benchmark evaluating nine LLM-based and graph-enhanced LLM (GLM) methods across seven text-attributed graph datasets under both node-level class-incremental (NCIL) and few-shot NCIL (FSNCIL) settings. They propose SimGCL, a simple yet effective GLM-based approach that combines graph-structured prompting, LoRA-based instruction tuning, and training-free prototype classification. This method enables LLMs to capture graph structural information while maintaining strong generalization and avoiding parameter updates that induce forgetting. Extensive experiments demonstrate that SimGCL consistently outperforms existing GNN-, LLM-, and GLM-based baselines—achieving up to 20% higher accuracy under rehearsal-free conditions."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Critical Re-evaluation of GCL Benchmarks:\nThe paper makes a valuable methodological contribution by identifying and empirically demonstrating a task ID leakage issue in existing Graph Continual Learning (GCL) benchmarks. This flaw—previously overlooked in the community—renders many reported results unreliable. By introducing a corrected global testing setup, the authors establish a fair and realistic evaluation framework for future GCL research.\n\n2. Bridging GCL and Foundation Models:\nConceptually, the paper establishes an important connection between graph continual learning and pretrained foundation models. By demonstrating that LLMs can serve as effective continual learners on graph-structured data when appropriately prompted, the study opens a new research direction for integrating graph reasoning with large-scale language models.\n\n3. Comprehensive and Insightful Experimental Analysis：\nThe paper provides a detailed and balanced experimental study, including comparisons among GNNs, LLMs, and GLMs across diverse datasets and settings. The analysis offers clear empirical insights—such as why GLMs may underperform and how prototype-based designs and model scaling influence continual learning performance—making the work informative beyond its own method."}, "weaknesses": {"value": "1. Limited Theoretical Justification for SimGCL:\nWhile SimGCL shows strong empirical results, the paper provides little theoretical or analytical grounding for why the combination of graph prompts, LoRA fine-tuning, and prototype-based classification alleviates forgetting. The approach appears largely empirical, and the mechanism behind its robustness (e.g., whether prototype stability or prompt alignment is the key factor) is not formally analyzed. Adding theoretical reasoning or ablation-based evidence would strengthen the scientific depth of the contribution.\n\n2. Overstatement of SimGCL’s generality and simplicity:\nThe paper claims that SimGCL “greatly alleviates catastrophic forgetting” and “surpasses all existing baselines” under a rehearsal-free constraint. While the reported results do show strong gains (up to 20%), these improvements are dataset-dependent — performance drops significantly on sparse or long-session datasets (e.g., Arxiv-23, FSNCIL). Hence, calling it universally effective may be an overstatement; the method is empirically strong but not universally superior.\n\n3. Assertion of “efficiency” and “low cost”:\nThe authors emphasize SimGCL’s efficiency due to LoRA-based tuning and prototype inference. However, they provide no runtime, memory, or scaling benchmarks to substantiate this claim. Given that LLM fine-tuning is resource-intensive, this efficiency claim seems qualitative and not empirically validated, representing a mild overstatement."}, "questions": {"value": "Q1. Clarification on the mechanism of forgetting alleviation\nYou claim that SimGCL “greatly alleviates catastrophic forgetting” through training-free prototype classification. Could you provide concrete evidence (e.g., forgetting curves, representation drift analysis, or embedding similarity metrics) showing that forgetting is truly reduced, rather than simply avoided by freezing parameters?\n\nQ2. Computational efficiency validation\nThe paper repeatedly highlights SimGCL’s “efficiency,” but no runtime or GPU memory statistics are presented. Could you quantify the actual training and inference cost (in FLOPs, GPU hours, or wall-clock time) compared to other LLM-based and GNN-based baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xybenD8Ttx", "forum": "ZKkeA1G935", "replyto": "ZKkeA1G935", "signatures": ["ICLR.cc/2026/Conference/Submission1449/Reviewer_ZnXD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1449/Reviewer_ZnXD"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission1449/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984945406, "cdate": 1761984945406, "tmdate": 1762915771071, "mdate": 1762915771071, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}