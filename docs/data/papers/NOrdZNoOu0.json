{"id": "NOrdZNoOu0", "number": 10348, "cdate": 1758167852494, "mdate": 1759897657015, "content": {"title": "Angular and Shell-Aware Deep Potential Energy Model for Molecular Dynamics", "abstract": "Angular information, especially involving the first and second coordination shells, is critical for accurately describing the potential energy surface (PES) in molecular systems. \nHowever, existing machine learning PES models either neglect this information or indiscriminately process it from all neighbors, blurring the critical contributions of distinct shells and compromising their predictive accuracy.\nIn this work, we propose the Angular and Shell-Aware Deep Potential (ASDP), a novel architecture designed to overcome this limitation. \nBased on the DPA-1 attention mechanism, ASDP integrates a specialized encoding module that selectively processes angular information confined within the first two coordination shells. \nThis shell-aware approach allows for a more physically meaningful representation of the local atomic environment. \nExperimental results show that by capturing crucial shell-specific angular dependencies, ASDP represents the PES of various molecular systems with the \\textit{ab initio} quantum mechanics (QM) accuracy,\noutperforming many existing methods and offering a new direction for creating highly accurate and robust machine learning potentials.\nOur code can be found in \\url{https://anonymous.4open.science/r/ASDP-ICLR-code}.", "tldr": "This paper introduces ASDP, a novel deep potential that integrates a shell-aware angular bias into an attention mechanism for highly accurate potential energy surface modeling.", "keywords": ["Machine Learning Potentials (MLP); Potential Energy Surface (PES); Molecular Dynamics (MD); Deep Potential (DP); Quantum Mechanics (QM) Accuracy"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/bab81e01d1569b5012537b82390b7e5671d3beac.pdf", "supplementary_material": "/attachment/49cfdf93a71b18914e3c629e634bda7edd87cf43.zip"}, "replies": [{"content": {"summary": {"value": "Authors highlight that existing machine-learning potentials often treat angular information uniformly across all neighbors within a large cutoff, ignoring its limited physical range. To address this, they propose the new architecture  Angular and Shell-Aware Deep Potential (ASDP) that explicitly encodes angular features within the first and second coordination shells through an additive attention bias. This design aims to suppress distant, uncorrelated angular noise. The model builds upon DPA-1 and is benchmarked on several datasets with molecular and periodic systems showing improved energy and force prediction accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- The work introduces a physically motivated inductive bias into attention-based deep potential models by explicitly restricting angular information to atoms within the first two coordination shells. This “shell-aware” cutoff excludes distant, angularly uncorrelated neighbors, reducing noise while preserving chemically relevant geometry. The motivation is clear, and the architectural diagrams effectively show how the additive angular bias is integrated into the attention mechanism.\n- The approach is benchmarked on both molecular and crystalline datasets, indicating that the proposed mechanism can generalize across different chemical domains."}, "weaknesses": {"value": "- The paper essentially proposes an attention mechanism modification for the DPA family of models (DPA-1 and DPA-2) and only experimentally validates the effect of the modification on a single model (DPA-1). This raises serious concerns about the generalizability of the proposed method and the value of the paper to the broad scientific community.\n- The paper proposes two changes to the attention mechanism: incorporating angular information via bias and limiting angular information to atoms within the second coordination shell. However, no ablations (to the best of my understanding) demonstrate the significance of proposed modifications individually. \n- The first four angular features were chosen without clear theoretical or empirical justification. The ablation study only compares 4 vs 6 features, never testing which of the first four are essential. This makes the feature design appear ad-hoc rather than physically motivated.\n- The shell neighbor number $s = N_2$ is fixed manually for each dataset based on \"chemical intuition\". This prevents transferability across systems and requires manual tuning for every new domain. For molecules or disordered systems with variable coordination, such as static or lattice-based, the criterion is questionable. Moreover, The neighbor count method is density-independent and may not adapt to systems with changing local density (e.g., liquids or amorphous phases).\nA continuous, distance-based smooth cutoff approximating the boundary of the second coordination shell would likely provide a more transferable and physically consistent solution. I suggest the authors evaluate this alternative in additional experiments.\n- The molecular benchmarks are limited. Evaluation of the method on more recent datasets like SPICE2.0, nablaDFT or OMol25 with more complex organic and biomolecular systems would better test generalization.\n- The chosen baselines (DeepPot-SE, DPA-1/2, NequIP, Allegro) don’t include stronger modern equivariant GNNs and force-field models (e.g.,DimeNet++, PaiNN, MACE ,GemNet). The paper compares mostly within DeepMD-style descriptors, so claims of state-of-the-art performance are weakly supported."}, "questions": {"value": "- How sensitive are results to the manual choice of $N_2$ if we vary it by ±1? Could a small smooth spherical cutoff for angular bias perform comparably?\n- Why were datasets with larger molecules or condensed-phase configurations omitted?\n- Could the additive bias formulation in ASDP be integrated into existing attention MLFFs for a fairer comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KMvrN2QvwW", "forum": "NOrdZNoOu0", "replyto": "NOrdZNoOu0", "signatures": ["ICLR.cc/2026/Conference/Submission10348/Reviewer_yLZ1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10348/Reviewer_yLZ1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10348/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761842435171, "cdate": 1761842435171, "tmdate": 1762921679179, "mdate": 1762921679179, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new model architecture for neural network based potential energy surfaces (PESs). Such PESs ideally hard code as much physics as possible (for example to improve robustness or minimize the necessary number of training samples) without introducing unphysical biases. \n\nIt is argued that previous models introduce such a bias by including angular information in terms of cosine similarities. This way certain important physical properties are not modeled. Moreover, the different impact of angular information depending on proximity to the particle that defines the neighbourhood is not taken into account. \n\nBased on these observations a new model is constructed that overcomes these issues. Experiments suggest that the new model retains the accuracy of previous sota models while offering increased robustness.\n\nWhile the concrete changes might be somewhat incremental, they have a concrete physical interpretation and offer new and general insights on the construction of robust PES models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper contributes to an important field. It identifies a critical shortcoming of previous approaches and fixes it by introducing a new architecture. This is a nice and significant contribution."}, "weaknesses": {"value": "The shell parameter s is fixed and requires either domain expertise or tuning. However, it is written that adaptively choosing s is subject to future work by the authors. \n\nMoreover, one could argue that the architectural changes are somewhat incremental to previous model."}, "questions": {"value": "none"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "none"}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UhFWyQIUOU", "forum": "NOrdZNoOu0", "replyto": "NOrdZNoOu0", "signatures": ["ICLR.cc/2026/Conference/Submission10348/Reviewer_cRzg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10348/Reviewer_cRzg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10348/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907047785, "cdate": 1761907047785, "tmdate": 1762921678694, "mdate": 1762921678694, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ASDP, a descriptor-based ML potential for molecular dynamics that injects angular information as an additive bias into attention, while being “shell-aware”: it only encodes angles formed within the first and second coordination shells. This is meant to emphasize chemically relevant geometry (directional bonds in the first shell; many-body/torsional effects in the second) and avoid noisy long-range angles. Across six molecular benchmarks, ASDP reports competitive or improved energy/force errors vs. DPA-1 and some equivariant GNNs, with good training stability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The key innovation of ASDP lies in introducing an explicit angular inductive bias into neighborhood attention, something not explored in prior descriptor-based potentials. By encoding three-body angular information as an additive bias within the attention mechanism, the model guides the attention layer to respect local geometric structure without overcomplicating the representation. \n2. The paper includes reasonable ablations to justify design choices. In Table 2, they show that using both first and second shells (s=N2) is generally better than using no angular information (s=0) or an overly large cutoff (s=30)\n3. The paper is easy to read and follow"}, "weaknesses": {"value": "1. A key concern is that the paper does not establish how ASDP scales to much larger or more diverse datasets. All six benchmarks have at most on the order of 10^5 training frames, while the mainstream MLIPs (eSEN, UMA, GemNet, etc) has been trained on dataset with more than 100M samples (such as OC, OMat, OMol). At least showing generalizability on a few million sample of diverse dataset, such as OMol 4M, would be helpful for understanding the usability of such approach.\n2. The proposed shell-aware angular bias is a sensible innovation, but it is largely an incremental modification of the existing DPA-1 framework rather than a fundamentally new paradigm. Prior models (e.g. DimeNet, GemNet) have also incorporated angular terms and even dehegral terms into learned descriptors. The main novelty here is the additive form of the bias in attention. While the paper argues this fixes some issues of DPA-1, one could question whether this change alone warrants a full new architecture. In particular, the need for explicitly encoding angles at all (versus letting a sufficiently expressive graph network learn them) is a design choice that trades off generality for built-in structure. \n3. ASDP’s performance gains are not uniform across tasks. For some benchmarks (e.g. AlMgCu and ANI-1) the original DPA-1 model actually had lower energy errors than ASDP. The paper does not deeply discuss these cases, instead focusing on where ASDP wins (SSE-PBE, organic reaction, etc.). This raises questions: why does the more complex model underperform on some datasets? Is it due to overfitting the chosen shells, or noise from added features (as hinted by the 4 vs 6 feature ablation)? The lack of consistency suggests the benefit of ASDP’s module maybe context-dependent.\n4. ASDP requires setting the shell cutoffs in advance (the number of neighbors to consider). The authors fix this per dataset from chemical knowledge. In practice this means a user must know how many neighbors form each shell for their system, which may not be obvious for new materials. Moreover, the need to tune or guess this hyperparameter for each new task reduces the model’s few-shot usability. The ablation study shows that choosing s suboptimally (too small or too large) can degrade accuracy, so its setting is crucial. The paper could be strengthened by providing guidance on selecting or learning this parameter, but as-is this reliance on domain-specific priors is a limitation.\n5. Relatedly, the experimental scope, while diverse, is still limited. All datasets are from materials/chemistry; none are, say, biological macromolecules or other domains where ML potentials are used. The model’s behavior in very large-scale MD (many thousands of atoms) is not assessed. There is also no evaluation of MD simulation outcomes (e.g. energy conservation, observables) Finally, the reported results lack uncertainty measures or statistical variance.\n6. Implementing the angular encoding is non-trivial: one must compute angles for all neighbor-triplets in the first two shells and generate multiple trigonometric features. This adds code complexity and computational overhead. Although the authors show inference is still competitive, training time and GPU memory requirements are not reported. It is unclear how much longer ASDP takes to train compared to DPA-1. The reviewer is concerned that for very large systems or datasets, the combinatorial cost of angles (O(s^2) per atom) could become significant. In practice, the need to hand-tune features (4 vs 6) and manage these computations could be a barrier."}, "questions": {"value": "1. The paper fixes s (the second-shell cutoff) based on prior chemical knowledge. How sensitive are the results to this choice? Could s be learned or adapted automatically? It would be useful to know how ASDP performs if s is mis-specified, or if one tries a data-driven selection.\n2. The paper reports inference times but does not detail training efficiency. How much longer (in wall-clock time or epochs) does ASDP take to train compared to DPA-1 on the same hardware? \n3. The authors use 6 features per angle (cos, sin, sin(2\\theta), von Mises, and two distance sums/differences). Is this feature set universal, or tailored to these tasks? Could simpler or different features suffice?\n4. How does the parameter count and memory footprint of ASDP compare to DPA-1 and the equivariant models? I.e. is the experiment controlled on the number of parameters?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "F4xWlZcdyg", "forum": "NOrdZNoOu0", "replyto": "NOrdZNoOu0", "signatures": ["ICLR.cc/2026/Conference/Submission10348/Reviewer_nqCL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10348/Reviewer_nqCL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10348/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762161045966, "cdate": 1762161045966, "tmdate": 1762921678243, "mdate": 1762921678243, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces ASDP, which is an upgrade to the recent DPA-1 potential for learning interatomic potentials (forces). DPA-1 is a rather simple transformer based architecture based on Euclidean relative position vectors and (implicitly) dot products between them. The present paper explains that this approach has inherent limitations in terms of its expressive power. The simplest concern is that when two position vectors are perpendicular, their dot product is zero so they will not contribute to the attention scores at all. Instead, ASDP uses a rather elaborate mechanism to reoncode angular information with internal parameters in a special bias matrix that is added to the attention weights. Empirical results show that this is a possible way to improve DPA-1, although the results are far from unequivocal."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Learning interatomic potential is an important, DPA-1 is a strong competitor in this field and ASDP represents one way in which it could be further improved\n- The mechanism by which angular information is encoded is novel and might inspire new ideas for other architectures as well\n- The architecture is motivated by some chemical intuition"}, "weaknesses": {"value": "- The mechanism by which the bias matrix is computed involving sines and cosines and a two-layer MLP (which is the paper calls \"sophisticated\") is very very ad-hoc.\n- Full SO(3)-equivariant (or SE(3)-equivariant) architectures based on the representation theory of the underlying groups, which the paper refers to as spherical-harmonic based potentials, have the advantage that they do not need such extra devices because they do not suffer from the representational limitations of just dot products. While most of the SE(3)-equivariant potentials cited in the paper are classical convolutional types architectures, there exist transformer variants of these as well. For a fair comparison ASDP should really be compared to these potentials.\n- Relatedly, the authors should evaluate ASDP on the standard benchmarks that the community has been using going back to QM9, not just on the six hand-picked molecular systems appearing in Table 1.\n- It seems like there is a hard radial cutoff between atoms that are deemed to be in the first two coordination shells vs the rest. The existence of such a hard cutoff introduces a discontinuity in the learned representation in the space of possible configurations, which can be a problem.\n- Overall, the proposed modification to DPA-1 is interesting, but a little unconvining because it is very heuristic and not thoroughly compared to the competitors."}, "questions": {"value": "n/a"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Rdn6KQSN4i", "forum": "NOrdZNoOu0", "replyto": "NOrdZNoOu0", "signatures": ["ICLR.cc/2026/Conference/Submission10348/Reviewer_7via"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10348/Reviewer_7via"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10348/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762318155132, "cdate": 1762318155132, "tmdate": 1762921677647, "mdate": 1762921677647, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}