{"id": "wT45bJeDb3", "number": 12909, "cdate": 1758211546643, "mdate": 1763344988811, "content": {"title": "[ICLR 2026] The role of diversity in in-context learning for large language models", "abstract": "In-context learning (ICL) is a crucial capability of current large language models (LLMs), where the selection of examples plays a key role in performance. While most existing approaches focus on selecting the most similar examples to the query, the impact of diversity in example selection remains underexplored. We systematically investigate the role of diversity in in-context example selection through experiments across a range of tasks, from sentiment classification to more challenging math and code problems. Experiments on Llama-3.1, Gemma-2, and Mistral-v0.3 families of models show that diversity-aware selection methods im9 prove performance, particularly on complex tasks like math and code, and enhance robustness to out-of-distribution queries. To support these findings, we introduce a theoretical framework that explains the benefits of incorporating diversity in in-context example selection.", "tldr": "We systematically investigate the role of diversity in in-context example selection for large language models, and show that diversity-aware selection methods improve performance on complex tasks and enhance robustness to out-of-distribution queries.", "keywords": ["Data selection", "Diversity", "In-context Learning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/8ae712e1c208559dd81cbb68e106a09efc2f8999.pdf", "supplementary_material": "/attachment/99d7a0b54b6e95e6d696c7bb1c379d372854da5f.zip"}, "replies": [{"content": {"summary": {"value": "This paper explores in-context learning (ICL) abilities of large language models (LLMs), focusing on the effect of demonstration diversity on downstream tasks. Specifically, authors conducted experiments on 5 tasks and 3 open-source LLMs and claimed three findings: diversity matters for 'challenging' questions."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This paper is well-written and easy to follow.\n- The research topic of this paper is interesting."}, "weaknesses": {"value": "1. Authors claim in the abstract  that 'the impact of diversity in example selection remains underexplored. '  However,  there has been many works exploring the diversity in ICL demonstration both theoretically and empirically. For example,  [1-5].\n\n2. The paper's central claim relies on the notion that diversity helps on \"harder\" tasks, but \"difficulty\" is never rigorously defined. The proxy used in Table 3 (fine-tuning-based classification) is limited to two datasets and doesn't generalize. In other words, this claim is rather subjective instead of proved quantitatively.\n\n3. The distinction between coverage-based benefits and \"beyond coverage\" effects is central to the paper's contribution, but the evidence is insufficient. Section 3.2 and Appendix C.5 provide limited experiments on only SQuAD with data perturbations.\n\n4. The theoretical justification (Theorems E.2, E.3) uses toy linear regression with binary embeddings and assumes min-norm solutions (Assumption E.1). The gap between these idealized settings and real language tasks with continuous embeddings and complex LLM behaviors is vast. Thus, this is questionable.\n\n5. Many reported improvements are <1% (e.g., Table 7 shows average Δ of 0.27% for simple tasks). Given the standard deviations in Table 10 (often 0.3-0.6%), many differences may not be statistically significant. \n\n6. While the paper tests different α values (TopK-Div) and subset sizes (Div), the analysis is fragmented across appendices without clear prescriptive guidelines. Practitioners need to know how to set these hyperparameters.\n\n7. On SST-2, TopK consistently outperforms diversity methods by 1-2% (Table 1), but the paper dismisses this as \"simple tasks prefer TopK\" without deeper analysis. \n\n8. Appendix D.5 shows that method rankings can change with different embeddings (BM25 vs. BertScore vs. Sentence-BERT), suggesting findings are highly embedding-dependent. \n\n9. One major concern is that Diversity-aware methods require computing pairwise similarities or running greedy selection algorithms, which have higher computational costs than simple TopK. This is never discussed.\n\n10. Table 2 shows mixed OOD results. For sentiment (SST-2 to IMDB), TopK-Div helps; but for commonsense reasoning (CsQA to ARC-Easy), the benefit is inconsistent (0.4% to 1.0% depending on model). \n\n11. The paper uses a specific diversity formulation (Equation 2: 1 - average similarity), but other diversity metrics exist (e.g., determinantal point processes, MaxMin diversity, entropy-based measures). Further diversity metrics exploration are needed.\n\n12. While Appendix D.2 shows results for varying K, the main paper only tests k in {4,8}. The relationship between diversity benefits and K is complex (Figure 6 shows non-monotonic trends). \n\n13. Most experiments use open-source models from three families (Llama, Gemma, Mistral). Only two commercial models tested briefly in Appendix D.1 (Table 14). Results may not generalize to other model families or architectures. \n\n14. The paper claims novelty in studying diversity vs. coverage-based methods, but doesn't clearly delineate how TopK-Div and Div differ from these prior coverage-focused approaches beyond conceptual level.\n\n\nReferences\n\n[1]Diverse Demonstrations Improve In-context Compositional Generalization https://aclanthology.org/2023.acl-long.78.pdf\n\n[2]Exploring the Role of Diversity in Example Selection for In-Context Learning https://arxiv.org/abs/2505.01842\n\n[3]Enhancing Contrastive Demonstration Selection with Semantic Diversity for Robust In-Context Machine Translation\n\n[4]In-Context Learning with Iterative Demonstration Selectionhttps://arxiv.org/abs/2504.09305\n\n[5]Affinity and Diversity: A Unified Metric for Demonstration Selection via Internal Representations https://arxiv.org/abs/2502.14380"}, "questions": {"value": "Please see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Wbz5fZXimS", "forum": "wT45bJeDb3", "replyto": "wT45bJeDb3", "signatures": ["ICLR.cc/2026/Conference/Submission12909/Reviewer_ZTFq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12909/Reviewer_ZTFq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760897549792, "cdate": 1760897549792, "tmdate": 1762923683895, "mdate": 1762923683895, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "6BhCLXAmLP", "forum": "wT45bJeDb3", "replyto": "wT45bJeDb3", "signatures": ["ICLR.cc/2026/Conference/Submission12909/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12909/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763344987585, "cdate": 1763344987585, "tmdate": 1763344987585, "mdate": 1763344987585, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates how diversity in demonstration selection impacts in-context learning (ICL) for large language models. It introduces four selection methods: Rand (random), TopK (most similar examples), Div (diverse coreset with similarity), and TopK-Div (a method balancing similarity and diversity). Theoretical analysis shows that diversity improves both coverage and generalization. Experiments are conducted across tasks including sentiment classification, commonsense reasoning, math, code, and reading comprehension, using models like Llama-3, Gemma-2, and Mistral. Results show that diversity-aware methods, especially TopK-Div, significantly improve performance on complex and out-of-distribution tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed TopK-Div method offers a flexible trade-off between similarity and diversity, making it practical and easily adaptable.\n\n2. It provides formal theoretical analysis explaining why diversity helps in ICL, including scenarios where it goes beyond simple feature coverage.\n\n3. The paper conducts extensive experiments across a wide range of tasks (classification, reasoning, generation) and models (Llama-3, Gemma-2, Mistral), demonstrating the robustness of the findings."}, "weaknesses": {"value": "1. The assumptions in the analysis framework are strong, which may not clearly reflect the true underlying mechanism of the in-contex learning.\n\n2. The downstream tasks used in the paper are relatively simple, making it difficult to demonstrate whether the proposed method is applicable to real-world scenarios—for instance, the industry has already adopted challenging datasets such as AIME.\n\n3. More discussion about diversity and related baselines(see Question2-4)."}, "questions": {"value": "1. Is there any method here that can quickly determine α based on the characteristics of the dataset and the model?\n\n2. The effectiveness of this method depends on the performance of the embedding model; if the embedding model fails to effectively capture the information in the data, the resulting diversity will be inaccurate. Could data diversity be considered from more dimensions? (keywords, gradient or other domain-related metrics)\n\n3. Following Question 2, it is worth investigating what \"diversity\" truly means in the context of In-Context Learning (ICL). If diversity is assessed solely based on embeddings, it appears to be unrelated to the final model performance (e.g., Llama-3.1, Gemma-2, and Mistral-v0.3). Would model-aware metrics—such as those based on gradients—provide a better measure of diversity? \n\n4. Moreover, the idea of jointly considering diversity and similarity has already been addressed in ICML 2025 by [1], which employs coreset [2] and optimal transport. Could you clarify the similarities and differences between your method and that of [1]?\n\n[1] Coresets for Data-efficient Training of Machine Learning Models\n[2] Tarot: Targeted data selection via optimal transport"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pWgp2la4j4", "forum": "wT45bJeDb3", "replyto": "wT45bJeDb3", "signatures": ["ICLR.cc/2026/Conference/Submission12909/Reviewer_DtJJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12909/Reviewer_DtJJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761466491737, "cdate": 1761466491737, "tmdate": 1762923683568, "mdate": 1762923683568, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work investigates the impact of diversity in example selection for in-context learning (ICL) in large language models (LLMs). The authors analyze five example selection methods: Rand, TopK, Div-S3, Div, and TopK-Div. A theoretical framework is introduced to explain how diversity enhances coverage and generalization. Through a series of experiments across various NLP tasks, including sentiment classification, commonsense reasoning, math, code, and reading comprehension, the authors demonstrate that diversity-aware methods—especially TopK-Div—outperform traditional methods like Top-K. The experiments show that these methods improve performance on complex and out-of-distribution tasks, supporting the idea that diversity is crucial for effective in-context learning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe paper is easy to follow overall.\n\n2.\tIt presents robust and convincing findings supported by extensive and detailed experiments across multiple tasks (classification, reasoning, and generation) and models (Llama-3, Gemma-2, and Mistral).\n\n3.\tThe work also provides preliminary theoretical analysis and proofs to support and explain the empirical observations."}, "weaknesses": {"value": "1.\tThe assumptions made in the analytical framework appear rather strong and may not accurately capture the true underlying mechanisms of in-context learning.\n\n2.\tThe performance gaps between different methods are not very pronounced, and the errors introduced during the evaluation process may lead to performance differences."}, "questions": {"value": "1.\tLine 1015-1018: The authors mention, \"we compute the logit for 'great' and 'terrible' respectively, and predict the sentiment to be positive if the logit for 'great' is larger than that for 'terrible'.\"What is the rationale behind this evaluation processing? Why were 'great' and 'terrible' selected instead of 'positive' and 'negative'?\n\n2.\tLine 1019-1021: The authors state, \"we pick the option with the smallest average cross-entropy loss.\" What is the basis for this evaluation processing? Why is it preferred over the evaluation processing method used in the classification tasks?\n\n3.\tLine 260-261: The authors mention using an instruction-tuned model for math-related tasks, but a base model is used for other tasks. What is the difference between these two models? Would using the instruction-tuned model for open-ended generation tasks be more aligned with real-world applications?\n\n4.\tLine 1597-1598: Could the authors clarify the meaning and role of the index $j$ in $S = {(e_{j_i}, y_{j_i})}^K_{i=1}$?\n\n5.\tKapuriya et al. [1] have investigated a nearly identical research topic to the one presented in this paper. I believe this may be a crucial reference that has not been discussed.\n[1] Kapuriya, Janak, et al. \"Exploring the role of diversity in example selection for in-context learning.\" Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2025."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "none"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TmGsSy0Odq", "forum": "wT45bJeDb3", "replyto": "wT45bJeDb3", "signatures": ["ICLR.cc/2026/Conference/Submission12909/Reviewer_JBs8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12909/Reviewer_JBs8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791504388, "cdate": 1761791504388, "tmdate": 1762923683248, "mdate": 1762923683248, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a systematic study on the role of diversity in in-context learning (ICL) for large language models (LLMs). While previous works focus primarily on selecting demonstrations most similar to the query, this work investigates whether and when diverse examples improve ICL performance. The authors evaluate several diversity-aware selection strategies—Div, Div-S3, and TopK-Div—across five task categories (classification, reasoning, math, code generation, reading comprehension) and three major open-source model families (LLaMA-3.1, Gemma-2, Mistral-v0.3)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This is one of the first comprehensive studies to quantify the impact of diversity in retrieval-based ICL across various models and task types.\n\n2. Extensive experiments across multiple datasets and model scales (1B–70B) support the claims, with consistent results.\n\n3. The paper provides actionable insights—e.g., use diversity for complex or OOD settings and similarity for simple tasks.\n\n4. The inclusion of baselines (TopK, Rand, Div-S3) and the introduction of the tunable TopK-Div strategy are well-motivated."}, "weaknesses": {"value": "1. Although a theoretical framework is mentioned, it remains underdeveloped and placed mostly in the appendix. The main text lacks rigorous formalization or proofs explaining why diversity helps beyond coverage.\n\n2. The diversity methods (Div, TopK-Div) are adaptations of existing techniques (e.g., DPP, submodular selection). The contribution lies more in systematic evaluation than methodological innovation.\n\n3. The experiments focus on English text tasks only. The generality of the findings to multimodal, multilingual, or conversational settings is untested.\n\n4. The reported improvements (1–3% on difficult tasks) are statistically small, though consistent. A discussion of variance and significance would strengthen the argument. \n\n5. The paper could benefit from qualitative examples showing how diverse demonstrations change model reasoning patterns or attention distributions."}, "questions": {"value": "1. Strengthen the theoretical analysis in the main text—possibly connecting diversity to representation coverage, mutual information, or implicit gradient-based learning in ICL.\n\n2. Include statistical tests (e.g., paired t-tests) to demonstrate the significance of performance differences.\n\n3. Provide qualitative or visualization-based analysis showing how diversity changes the model’s behavior (e.g., activation patterns, attention focus).\n\n4. Discuss computational cost implications of diversity-aware selection methods.\n\n5. Explore cross-lingual or domain-specific tasks (e.g., medical, legal) to validate generality.\n\n6. Compare against recent retrieval-enhanced ICL methods (e.g., Dr.ICL, RePrompt, or reinforcement-based retrievers)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7M7qRFrVrQ", "forum": "wT45bJeDb3", "replyto": "wT45bJeDb3", "signatures": ["ICLR.cc/2026/Conference/Submission12909/Reviewer_EFVC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12909/Reviewer_EFVC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12909/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991647894, "cdate": 1761991647894, "tmdate": 1762923683007, "mdate": 1762923683007, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}