{"id": "a1zBg9cBvt", "number": 8212, "cdate": 1758074434086, "mdate": 1759897799822, "content": {"title": "Language in the Flow of Time: Time-Series-Paired Texts Weaved into a Unified Temporal Narrative", "abstract": "While many advances in time series models focus exclusively on numerical data, research on multimodal time series, particularly those involving contextual textual information, remains in its infancy. With recent progress in large language models and time series learning, we revisit the integration of paired texts with time series through the Platonic Representation Hypothesis, which posits that representations of different modalities converge to shared spaces. In this context, we identify that time-series-paired texts may naturally exhibit periodic properties that closely mirror those of the original time series. Building on this insight, we propose a novel framework, Texts as Time Series (TaTS), which considers the time-series-paired texts to be auxiliary variables of the time series. TaTS can be plugged into any existing numerical-only time series models and effectively enable them to handle time series data with paired texts. Through extensive experiments on both multimodal time series forecasting and imputation tasks across benchmark datasets with various existing time series models, we demonstrate that TaTS can enhance multimodal predictive performance without modifying model architectures.", "tldr": "", "keywords": ["Time Series Modeling", "Multimodal Learning", "Time Series Forecasting"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/514d5ff6760b4d3284b4e7a5541977b253647f5c.pdf", "supplementary_material": "/attachment/0b35ce5753bc3e7ff0637899ef4e491ee916cb11.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces the TaTS framework, a novel approach for integrating contextual textual information with numerical time series data to significantly enhance forecasting accuracy. The authors propose a method that projects auxiliary variables from paired texts to augment the original time series representation, theoretically underpinned by the Platonic Representation Hypothesis, which posits a convergence of multimodal representations into shared spaces. The central contribution lies in the demonstrated effectiveness of this multimodal fusion: empirical results across nine diverse real-world domains consistently show that TaTS achieves an average of approximately 14% improvement in forecasting Mean Squared Error (MSE), justifying the minor incurred computational overhead of around 8% in training time."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Significant Empirical Improvement: The framework demonstrates a substantial and consistent performance gain (around 14% MSE reduction) across a wide array of domains (e.g., Economy, Climate, Health), indicating high robustness and generalizability.\n\n2. Sound Theoretical Grounding: The methodology is well-motivated by the Platonic Representation Hypothesis, providing a strong conceptual basis for unifying textual and numerical time series representations.\n\n3. Practical Efficiency Analysis: The paper includes a necessary trade-off analysis, clearly quantifying that the high performance benefits come with only a marginal and acceptable increase in computational overhead (around 8%)."}, "weaknesses": {"value": "1. Interpretability of Textual Influence: While the model is effective, the specific mechanism by which the projected auxiliary variables qualitatively impact or modulate the time series dynamics is not deeply explored. More detailed visualization or ablation studies on the how the text is woven into the temporal narrative would strengthen the paper.\n\n2. Scalability to Text Length/Complexity: The paper does not thoroughly discuss the framework's scalability or performance behavior when dealing with significantly longer or structurally complex paired texts (e.g., full documents vs. short captions).\n\n3. Sensitivity to Text Quality: A crucial missing component is an analysis of how the model performs when the paired text is noisy, weakly correlated, or intentionally irrelevant, which would better demonstrate the robustness of the feature extraction mechanism."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9MCED1aleW", "forum": "a1zBg9cBvt", "replyto": "a1zBg9cBvt", "signatures": ["ICLR.cc/2026/Conference/Submission8212/Reviewer_1Lkf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8212/Reviewer_1Lkf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8212/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761554863175, "cdate": 1761554863175, "tmdate": 1762920159969, "mdate": 1762920159969, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces TaTS, a simple framework that integrates timestamped text with numerical time series by converting text embeddings into auxiliary features for standard models. It is motivated by Chronological Textual Resonance (CTR), which captures periodic alignment between textual and numeric signals, and defines TT-Wasserstein to quantify this alignment. TaTS works with existing architectures without modification, improving forecasting and imputation performance across multiple datasets while adding minimal computational cost."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Evaluated across multiple datasets and diverse time-series backbones, supporting robustness and generalizability.\n- Clear, well-structured framework: CTR (motivation), TaTS (mechanism), and TT-Wasserstein (diagnostic) are distinctly defined and complement each other.\n- Plug-and-play simplicity: TaTS adds a small projector to turn per-timestamp texts into features and works with existing TS backbones without architecture changes."}, "weaknesses": {"value": "- CTR/TT-Wasserstein focus on magnitude-only spectral alignment, favoring stable periodicities and largely ignoring phase—so they can undervalue datasets where texts are leading or lagging indicators or where alignment is time-varying/non-stationary, even if the texts are predictive.\n- Limited discussion of TS→text (inverse direction): brief related-work mention and a single zero-shot ChatTime baseline; no deeper analysis or dedicated experiments.\n- Limited native multimodal baselines: ChatTime is the only truly native multimodal method evaluated, while others are adapted uni-modal TS models; MM-TSFLib is further extended for imputation since it doesn’t support it natively."}, "questions": {"value": "Please address the identified weaknesses and limitations noted above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Y5QsyzHWfc", "forum": "a1zBg9cBvt", "replyto": "a1zBg9cBvt", "signatures": ["ICLR.cc/2026/Conference/Submission8212/Reviewer_aWnj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8212/Reviewer_aWnj"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8212/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761624274492, "cdate": 1761624274492, "tmdate": 1762920158628, "mdate": 1762920158628, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents TaTS, a plug-in framework that treats timestamp-aligned texts as auxiliary variables for time-series models. By embedding the texts, projecting them through a small MLP, and concatenating them to numeric inputs, the approach allows standard forecasters and imputers to exploit textual signals without changing their architectures. The work is motivated by Chronological Textual Resonance (CTR), the observation that paired texts often share periodic structure with the target series, and it introduces TT-Wasserstein to quantify this alignment. Extensive experiments across varied datasets and backbones indicate consistent gains, particularly when TT-Wasserstein suggests strong alignment. The computational overhead is modest, which enhances the practical appeal of the method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper introduces a simple, model-agnostic plug-in that treats text embeddings as auxiliary variables, simplifying integration into existing pipelines while keeping computational overhead low.\n- The work provides an interpretable alignment rationale via CTR and the TT-Wasserstein metric, which helps explain when and why text improves performance and guides practical deployment.\n- Extensive experiments with clear ablations (shuffle/drop text, encoder swaps, multiple backbones and datasets) demonstrate stable gains."}, "weaknesses": {"value": "- The central mechanism is projection followed by concatenation, which may be outperformed by comparably simple baselines, such as gated residuals or lightweight cross-attention, unless comparisons are conducted under strict parameter matching.\n- The definition and estimation of TT-Wasserstein lack sufficient statistical treatment; sensitivity to windowing, normalization, and frequency resolution is not examined, and confidence intervals are absent.\n-  The data-splitting procedure is not described in adequate detail, creating uncertainty about potential information leakage from contemporaneous or retrospective texts.\n- The framework offers no automatic protection against negative transfer when CTR is weak, which could undermine robustness in noisy or weakly aligned settings."}, "questions": {"value": "- How are splits constructed per dataset to ensure texts at time t do not reveal contemporaneous or near-future outcomes, and are audits/filters applied for retrospective or outcome-summarising language?\n- Which FFT, windowing, and normalization settings are used for both modalities, how sensitive are results to these choices, and can confidence intervals be reported for the correlation?\n- How does TaTS compare with (a) a small gated residual that can down-weight text channels and (b) a parameter-matched cross-attention/FiLM block?\n- Has weighting or dropping text channels based on TT-Wasserstein been tested to mitigate negative transfer when alignment is weak?\n- What are the training/inference wall-clock costs for different text encoders (e.g., GPT-2, BERT, LLaMA), and what rule of thumb should practitioners use to choose an encoder?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sdIWVEa7Tk", "forum": "a1zBg9cBvt", "replyto": "a1zBg9cBvt", "signatures": ["ICLR.cc/2026/Conference/Submission8212/Reviewer_w9od"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8212/Reviewer_w9od"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8212/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761653303786, "cdate": 1761653303786, "tmdate": 1762920158188, "mdate": 1762920158188, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TaTS, a new multimodal time series forecasting benchmark compatible with any time series forecasting model. TaTS embeds the textual descriptions of time series, projects them using an MLP, and then combines them with the original time series to create a new input for forecasting models. The motivation behind this architecture is that time series paired with text often exhibit periodic patterns that reflect the dynamics of the numerical time series. Additionally, the authors introduce TT-Wasserstein, a metric designed to evaluate the alignment between the time series and the associated text."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed architecture is model agnostic and delivers good improvement of the base model.\n\n2. Incorporate textual information into time series if timely and interesting."}, "weaknesses": {"value": "1. The paper lacks comparison with other multimodal algorithms. For example, the authors don't compare their approach with TimeMMD, which is also model-agnostic and offers similar improvements over unimodal models. There are also several other multimodal algorithms available that could serve as valuable comparisons.\n\n2. The method requires access to a textual description for each timestamp, which may be difficult to obtain in real-world applications."}, "questions": {"value": "1. How did you choose the competitors and why not incorporating multimodal algorithms?\n\n2. How the method can adapt if not enough textual descriptions are not available for each time stamp if there are not alignment between time series and text or at least it is not known ?\n\n3. it seems the information from the text is not complementary but redundant information with the time series as captured by the low TT-Wasserstein. In this redundant information case one would expect the text not to improve the result and expect more an improvement when the information is complementary and critical for the forecast?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nz4A2yuqSn", "forum": "a1zBg9cBvt", "replyto": "a1zBg9cBvt", "signatures": ["ICLR.cc/2026/Conference/Submission8212/Reviewer_vhxM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8212/Reviewer_vhxM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8212/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761837452157, "cdate": 1761837452157, "tmdate": 1762920157620, "mdate": 1762920157620, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}