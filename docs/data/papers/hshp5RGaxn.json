{"id": "hshp5RGaxn", "number": 21823, "cdate": 1758322284180, "mdate": 1759896901250, "content": {"title": "Certifiably Robust Classifiers: Bridging the Gap Between Theory and Practice", "abstract": "Deep learning models are vulnerable to adversarial attacks, raising important concerns for their use in safety-critical applications.\nExisting defense methods such as empirical defenses are effective in practice but lack theoretical guarantees, while provable defenses provide a certified robustness radius which is significantly smaller than that achieved by empirical defenses. In this work, we design robust classifiers that leverage the structure of the underlying data distribution, bridging the gap between theoretical certification and strong practical performance. First, we focus on a simple setting where the data distribution is a Gaussian mixture and provide necessary and sufficient conditions under which a robust classifier is guaranteed to exist. We also propose a provably robust classifier along with its certificate of robustness and a generalization guarantee for the learnt certified radius. Next, we generalize our approach to any complex data distribution by using an encoder network to map the input data to a mixture of Gaussians. We also provide a robust classifier with a guaranteed certificate of robustness. Experiments on benchmark datasets indicate that our method outperforms existing top baselines for certified accuracy on CIFAR-10 dataset, while achieving competitive performance on ImageNet even against computationally demanding prior methods.", "tldr": "", "keywords": ["adversarial robustness", "certified robustness", "deep learning theory"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/19166d506f6f9be500375f3baebb1b0077c3b323.pdf", "supplementary_material": "/attachment/439f87482726999647c0cb588a87adf73a3cfb2a.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes a certifiably robust classification framework that leverages the underlying data distribution's structure. The paper first establishes theoretical guarantees for Gaussian Mixture Models (GMMs) and then generalizes to complex distributions via a Lipschitz encoder."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper provides a theoretical foundation with explicit conditions for robust classifier existence in GMMs.\n\n2. The proposed method is computationally efficient compared to expensive methods like diffusion-based certification."}, "weaknesses": {"value": "1. The proposed method may rely on accurately estimating the Lipschitz constant of the encoder, which can be challenging in practice.\n\n2. The proposed method mainly focuses on l2 norm without generalization to lp norm perturbation.\n\n3. Although the proposed is efficient than diffusion based methods, its effectiveness is lower."}, "questions": {"value": "Please refer to the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "h43Pxt0npw", "forum": "hshp5RGaxn", "replyto": "hshp5RGaxn", "signatures": ["ICLR.cc/2026/Conference/Submission21823/Reviewer_nXZV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21823/Reviewer_nXZV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761488364495, "cdate": 1761488364495, "tmdate": 1762941944344, "mdate": 1762941944344, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a model architecture that has well-characterized theoretical robustness properties against $\\ell_2$-norm bounded perturbations.\n\nThe proposed architecture uses a locally-lipschitz encoder head to transform the data distribution to a Gaussian Mixture Model (GMM).\nThen, a simple \"nearest-ellipse\" classifier, essentially quadratic discriminant analysis (QDA), solves the classification task.\n\nThe theoretical guarantees build on [Pal et al. (2024)](https://arxiv.org/abs/2405.14176), adapting the distribution agnostic localization notions to the special case of $d$-dimensional GMMs.\nIn this setting, the authors can issue simple margin-based robustness certificates.\nThe utilization of Lipschitz encoder models allows for the transfer of these results to arbitrary distributions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **(S1) Clear Writing**: The story is compelling, the manuscript is well-written and well-structured with a clear outline of the central question and the core contributions.\n\n- **(S2) Elegant Methodology**: The proposed method is conceptually very elegant, and in the transformed data distribution, margin-based robustness certificates are a very natural approach. The approach seems to be novel in the context of robustness guarantees.\n\n- **(S3) Sound Theoretical Results**: The presented theory seems to be correct. The proofs are correct and complete after a surface-level check, although I did not fully check Theorem 3.2.\n\n- **(S4) Testing of assumptions in practice**: A very important strength in the experimental evaluation is that the authors perform tests to check their assumption that the encoder transforms data to GMMs.\n  This is essential to ensure that their theory actually applies and is clean work.\n\n- **(S5) Good experimental evaluation**: The experimental results are well-presented and properly contextualized; the chosen experimental setup makes sense to validate the proposed method empirically."}, "weaknesses": {"value": "I like the approach of the paper, which feels like a reparameterization trick to obtain robustness bounds easily.\nThe main weaknesses are that the used classifier and Theorem 3.1. can be linked to QDA, but no connection is mentioned (W1, W2).\nI think it is important that the authors address these two points and properly contextualize their work.\n\nMinor points of critique are that the theorems stating the existence of robust classifiers in Section 2 seem disconnected from the rest of the paper (W3), experimental details and code availability (W4, W5), as well as several presentation details.\n\n## Content\n\n- **(W1) QDA:** Section 3 introduces the \"nearest ellipse classifier\", which is stated to be the Bayes-optimal classifier with a robustness certificate in Theorem 3.1.\nHowever, the authors do not explicitly state that this is the well-known Quadratic Discriminant Classification (QDA) rule (e.g., [Bishop (2006) Chapter 4](https://link.springer.com/book/9780387310732).\nI interpret the phrasing in the abstract and introduction as if the authors **propose** this classification rule, which is, however, well-established [e.g., in scikit-Learn](https://scikit-learn.org/stable/modules/lda_qda.html).\nI think that the authors should mention this connection and be careful with the wording of their contribution, as the classifier, in my understanding, is not novel.\n\n- **(W2) Theorem 3.1:** In the context of QDA, the robustness certificate stated in Theorem 3.1 can be rephrased as a distance-lower-bound of a given point $x$ to the QDA decision boundary.\nI feel the result in Theorem 3.1. could be presented as a proposition instead of a theorem.\nIt should be clarified that the result is a consequence of the quadratic nature of the classifier, and can be applied to other simple model classes (Linear Discriminant Analysis (LDA), Support Vector Machines (SVMs) with simple kernels) in much the same way.\nConcepts $W$ and $c_M$ could be explicitly named, to make it clearer what the theoretical background of the stated robustness certificate is.\n\n\n- **(W3) Section 2:** Section 2 offers theoretical results that are not referenced in the rest of the manuscript at all.\nThe results are, in my understanding, an improvement on existing work for a special case of GMM distributions.\nWhen viewed critically, it is not clear how the stated conditions are linked to the rest of the paper, as the concept of (strong) localization is not explicitly invoked later.\nDid I miss the connection?\n\n- **(W4) Experimental Baseline:** While the theoretical advantage of this method is clear, in the experimental settings, the details of **obtaining** the required encoder network are a bit vague.\nThis raises the question of whether a well-behaved encoder can be obtained in general.\nAdditionally, an ablation study with a non-robust baseline in the experiments would ground the results and show how much performance is sacrificed to obtain the robustness certificates.\nThe authors also do **not provide access to their code**, which makes it impossible to check the details of their procedure and the implementation of their ellipse classifier, beyond the surface-level description provided in the manuscript.\n\n- **(W5) Discussion of Performance:** A minor point: In the appendix, additional results in the comparison with randomized smoothing show that sometimes the provided results underperform against randomized smoothing.\nThis is more pronounced when the distances $R$ are small, and there are more classes.\nWhile I do not hold this against the method, I wonder if there is any intuition the authors can provide for why this happens, as this seems to follow a clear pattern.\n\n\n## Presentation\n\nThese issues do not impact the overall quality of the contribution a lot, but they should be taken care of.\nI do not expect the authors to address these points in a response.\n\n(WP1) The manuscript is well-structured, but it notably does not have a preliminary section.\nIn Section 2, to my understanding, the authors adapt the notions of (strong) data localization, but do not at any point introduce the concepts.\nBecause of this, it is slightly ambiguous which part of the notions and results are from [Pal et al. (2024)](Link) and which part is the contribution of the authors, as mentioned above.\n\n\n(WP2) While the writing and structure of the manuscript are good, there seem to be leftover notation slips.\n- Most notably, in both theorems mention indices $i_2, i_2'$, which are not used.\nTheorem 3.1 mentions a data point $(x,y)$ but does not use the label $y$.  \n- The ELLIPS model outputs a label $y$, which is defined above as integer between 1 and $K$.\nThen, an index $i^\\*$ of the predicted label is introduced and used.\nThis seems redundant to me and reads like leftover old notation.\nIt seems that either $y$ or $i^*$ could be used consistently.\n- In Theorem 4.1, $L$ is used but not introduced until later in the text, and is not defined.\n- In the proof of Theorem 3.1. in the appendix $i$ seems to be accidentally defined as $\\max$ instead of $\\arg\\max$ of the classifier scores.\n\n(WP3) The plots are a bit rushed, with very, very tiny labels.\nBetween experiments, the colors of the empirical PGD and the presented bounds swap, which can be confusing to the reader.\n\n(WP4) A tiny nitpick, but the manuscript has multiple runts (i.e., very short lines at the end of paragraphs), which can be avoided, are a bit unaesthetic, and waste space."}, "questions": {"value": "I would appreciate a brief response from the authors addressing my concerns in W1, W2, and maybe W3.\nIn addition, I have the following questions, of which I consider Q1 to be the most important.\n\n- **(Q1) Theorem 3.2:** The generalization bound in Section 3, Theorem 3.2, is phrased in a way that is slightly confusing.\nDoes $\\epsilon_{\\min}$ impose a condition on the choice of $\\epsilon$?\nDoes it depend on the (unknown) covariance matrices of the true GMM QDA, or the learned parameters?\nAnd can it be the case that $\\epsilon_{\\min}$ can be 0? \nDoes the generalization bound then not apply in this case, as there is no $0<\\epsilon<0?\n\n\n- **(Q2) Ad W3:** Section 2 gives conditions when robust classifiers can and must exist.\nWhile these results are interesting, they seem a bit disconnected from the later sections of the paper.\nIs there a way to utilize these results in practical settings, especially when using an actual encoder head?\nE.g., can a straightforward statement be made when a robust GMM can be **produced** by an $L$-Lipschitz encoder, or used as a diagnostic tool?\n\n\n- **(Q3) Theorem 4.1. under imperfect distribution approximations**: Theorem 4.1 assumes that the encoder head produces a GMM.\nIt is great to see that the authors actually check in their experimental evaluation whether this assumption holds.\nHowever, it still seems to me like a small theoretical gap.\nRather than a normality test, could the presented result be relaxed to incorporate, e.g., small total variation (TV) shifts between a proper GMM and the produced distribution?\nSome discussion of this would round out the theoretical approach for me.\nI think it is worth mentioning in the main text that the quality of the distribution produced by the encoder needs to be **tested**.\n\n---\n\n## Verdict\n\nIn conclusion, I would rate the paper a **weak accept** as I like the approach, and I think there is novelty in this two-step simplification for robust methods.\nThe theoretical results are sound, and they investigate the different aspects of the problem, but do not provide all the context I feel is necessary.\nI would be open to raising my score if the authors adequately discuss this.\n\n---\n\n## References\n\n- Pal, A., Vidal, R., & Sulam, J. (2024). *Certified Robustness against Sparse Adversarial Perturbations via Data Localization*. arXiv. https://arxiv.org/abs/2405.14176\n\n- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer. https://link.springer.com/book/9780387310732\n\n- scikit-learn developers. (n.d.). *1.2. Linear and Quadratic Discriminant Analysis*. scikit-learn Documentation. https://scikit-learn.org/stable/modules/lda_qda.html"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "w9zgvUhOul", "forum": "hshp5RGaxn", "replyto": "hshp5RGaxn", "signatures": ["ICLR.cc/2026/Conference/Submission21823/Reviewer_HWLv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21823/Reviewer_HWLv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761690669368, "cdate": 1761690669368, "tmdate": 1762941943918, "mdate": 1762941943918, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper first provides a sufficient condition for a classifier to be certifiably robust against L2 norm bounded adversarial attacks on a Gaussian mixture model (GMM). Then, the authors propose a method that maps samples to a GMM using a Lipschitz encoder. The authors test their method on synthetic data, and CIFAR-10."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The writing is fine. The paper is not particularly hard to read\n2. This work build on the theory from prior work to develop a robust classifier for Gaussian mixture distributions"}, "weaknesses": {"value": "The main weakness of this work is its limited applicability, especially so for a paper that purports to bridge the gap between theory and practice. Specifically, this work does the following.\n\n**Theory:** The theory part basically says that if the data follows a GMM model where each class is a Gaussian component, then any x close to the center of a component is classified as that class with high probability, and any x and x’ close to the same center are classified as the same class. The generalization bound in Theorem 4.2 basically says that one can estimate the mean and covariance matrix of each component given sufficient samples. I don’t find any of these results interesting, novel or technically difficult to prove.\n\n**Method:** The proposed method tries to find a Lipschitz encoder that maps the samples to such a GMM. This is strictly more difficult than learning a robust classifier. If there is a method that can produce such an encoder, one can use this method and train a linear layer on top to obtain a robust classifier. Thus, there is no reason that the proposed method makes it easier to learn a robust classifier.\n\n**Experiments:** Real data is not GMM so the experiments on synthetic data is not really representative. On CIFAR-10, the authors only compare their method with an old method from 2019 and another paper, though there are dozens of papers in this field. The results are hard to verify, and even if they are correct, the improvements seem incremental.\n\nThus, I lean towards rejection."}, "questions": {"value": "1. Do you think the assumptions about low Lipschitz constants and Gaussian-like embeddings would still hold up for large realistic datasets? How practical is it to train a Lipschitz-continuous encoder for larger models? \n2. Is it possible to scale this approach to certify the robustness any given model without depending on a Lipschitz-continuous encoder?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Lvb8uyTNE4", "forum": "hshp5RGaxn", "replyto": "hshp5RGaxn", "signatures": ["ICLR.cc/2026/Conference/Submission21823/Reviewer_wf1r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21823/Reviewer_wf1r"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761961048186, "cdate": 1761961048186, "tmdate": 1762941943592, "mdate": 1762941943592, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies certifiable adversarial robustness by exploiting distributional structure. Starting from a Gaussian-mixture setting the authors (1) derive concrete, verifiable localization conditions under which a robust classifier must exist (Theorems 2.1–2.2); (2) propose a nearest-ellipsoid classifier (ELLIPS) and give a closed-form robustness certificate and a generalization bound for the learned certified radius (Theorems 3.1–3.2); (3) extend the pipeline to arbitrary input distributions by training / using a Lipschitz encoder that maps inputs into a GMM latent and show how the certified radius composes through the encoder (GENELLIPS, Theorem 4.1); and (4) provide synthetic experiments plus CIFAR-10 / ImageNet results that compare to randomized smoothing and other SoK baselines. The theoretical results and the experimental pipeline (including use of CLEVER to estimate local Lipschitz constants) are documented and proven in the appendix."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) Solid theory-to-practice pipeline: The paper does not stop at abstract existence results: it gives explicit localization sets for GMMs, a concrete nearest-ellipsoid classifier (ELLIPS), a robustness certificate (Theorem 3.1), and then shows how to combine that with a Lipschitz encoder to handle natural data (Theorem 4.1). This end-to-end bridging is valuable.\n\n2) Closed-form, geometry-aware certificate:  The certifying radius depends on the local geometry (covariance differences, λ_min, Mahalanobis margins), which can yield tighter local certificates than coarse global bounds. This is a useful conceptual advance relative to black-box smoothing.\n\n3) Experimental validation on multiple fronts: The paper verifies theoretical claims on synthetic GMMs, randomized smoothing, and SoK baselines on CIFAR-10 and ImageNet, and shows competitive or superior certified accuracy (especially CIFAR-10)."}, "weaknesses": {"value": "1) Practical estimation of Lipschitz constant L and dependence on CLEVER: Theorem 4.1 requires a Lipschitz constant L (or local L(x)). In practice the paper uses CLEVER (Weng et al., 2018) with 1,000 MC samples and a 99.9% CI. CLEVER produces estimates with substantial variance and is itself expensive.\n\n2) Compute & memory / wall-clock comparisons missing: The paper claims its approach is less computationally demanding than diffusion-based certification. Please include measured certification runtime (per image) and memory usage for GENELLIPS vs randomized smoothing (with the sample counts used) and diffusion denoising methods. Practitioners will care about the tradeoff of certificate tightness vs compute cost.\n\n3) Hidden/strong assumptions about covariances and eigenvalue gaps: Several results depend on λ_min of differences of inverse covariances and other spectral quantities. These can be small or negative in practice. The paper should (a) discuss how frequently these spectral assumptions hold empirically (both in GMM synthetic settings and the learned latent GMM), (b) provide robustified alternatives or fallback behavior when λ_min is near zero or negative, and (c) if negative λ_min is allowed, explain numerical stability and examples"}, "questions": {"value": "1) How sensitive are the results to the number of GMM components? For ImageNet you likely need many components; how did you pick K and how does certified accuracy scale with K?\n\n2) How robust is ELLIPS to estimation error of µ̂_i, Σ̂_i when classes are multi-modal or when covariances are poorly conditioned? Is any regularization (shrinkage) used when estimating Σ̂_i?\n\n3) Why does L2 adversarial robustness (including certified) matter in practice? The Lp norm might be convenient but unrealistic attack. And the performance degrades. What's the accuracy on the clean imagenet examples? What are benefits of certified models that outweigh cost to clean accuracy or compute? But I appreciate you are trying to bridge the gap between theory and practice"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "JULros9b2o", "forum": "hshp5RGaxn", "replyto": "hshp5RGaxn", "signatures": ["ICLR.cc/2026/Conference/Submission21823/Reviewer_2rab"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21823/Reviewer_2rab"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21823/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976865773, "cdate": 1761976865773, "tmdate": 1762941943321, "mdate": 1762941943321, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}