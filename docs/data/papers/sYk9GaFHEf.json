{"id": "sYk9GaFHEf", "number": 20436, "cdate": 1758306153639, "mdate": 1759896977568, "content": {"title": "CERTIFIED VS. EMPIRICAL ADVERSARIAL ROBUSTNESS VIA HYBRID CONVOLUTIONS WITH ATTENTION STOCHASTICITY", "abstract": "We introduce Hybrid Convolutions with Attention Stochasticity (HyCAS), an adversarial defense that narrows the long-standing gap between provable robustness under ℓ2 certificates and empirical robustness against strong ℓ∞ attacks, while preserving strong generalization on both natural- and medical-image tasks. HyCAS unifies deterministic and randomized principles by coupling 1-Lipschitz, spectrally normalized convolutions with two stochastic components—spectral normalized random-projection filters and a randomized attention-noise mechanism. Injecting smoothing randomness inside the architecture yields an overall ≤ 2- Lipschitz network with formal certificates. Extensive experiments on diverse benchmarks—including CIFAR-10/100, ImageNet-1k and NIH Chest X-ray—show that HyCAS surpasses prior certified and empirical defenses, boosting certified accuracy by up to ≈ 7.3% and empirical robustness by up to ≈ 3.3%, without sacrificing clean accuracy. These results demonstrate that a hybrid deterministic–stochastic design can harmonize provable and empirical adversarial robustness, fostering safer deployment of deep models in high-stakes applications.", "tldr": "", "keywords": ["Certified Defense", "Empirical Defense", "Adversarial Robustness"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f2982cff18e0a22c1e4e671f36821422b4c97c7b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces an architectural modification to standard CNNs that makes them more robust to (particularly $\\ell_\\infty$) adversarial attacks. HyCas has 3 components, each of which are 2-Lipschitz, and are fused via a convex operation, which allows them to obtain an $\\ell_2$ robustness certificate. There are some works that also introduce 1-Lipschitz or spectrally normalized CNNs, but I find the internal stochasticity introduced in HyCas (via random projections, random attention noise), to be principled and interesting, and also standing out as novel in comparison to prior work. I also find the work to be refreshing from the perspective of tackling the adversarial robustness problem in a new way, as opposed to yet another method for solving the vanilla $\\ell_2$/$\\ell_\\infty$ robustness problem. Experiments convincingly demonstrate the practical utility of the proposed method."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "-- A new architecture, with several novel components, which are both well motivated and nicely executed\n\n-- Bridges a key gap between certified and empirical robustness\n\n-- Provide formal proofs that the network is 2-Lipschitz, which to my reading are convincing\n\n-- Benchmark on both natural and medical image datasets\n\n-- Comprehensive experiments in terms of number of defenses compared to"}, "weaknesses": {"value": "-- The three parallel streams plus convex gating presumably increase parameter count and compute cost. But the authors do not report FLOPs or latency.\n\n-- There is no comparison to some new methods e.g. TRADES [1] or HR [2]. \n\n[1] https://arxiv.org/pdf/1901.08573\n[2] https://arxiv.org/abs/2303.02251"}, "questions": {"value": "-- What is the parameter and FLOP overhead relative to a standard ConvNet block?\n\n-- Are the certificates costly to obtain (i.e. via Monte-Carlo)?\n\n-- Have the authors considered salience maps to visualize the sensitivity to input perturbations as opposed to standard l2 robustness methods. I think it would be interesting to see as an additional insight."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6uYUDo3vqK", "forum": "sYk9GaFHEf", "replyto": "sYk9GaFHEf", "signatures": ["ICLR.cc/2026/Conference/Submission20436/Reviewer_roSN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20436/Reviewer_roSN"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20436/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761151065549, "cdate": 1761151065549, "tmdate": 1762933878688, "mdate": 1762933878688, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores a new adversarial defense. The main contribution of the paper is to narrow the gap between the work that has been done for certified defenses under the l2 norm and empirical defenses that use the l-inf norm. This is accomplished through the use of Hybrid Convolutions with Attention Stochasticity, a new method proposed in this paper. Experimentally the results of the new method are shown on a wide range of datasets including, CIFAR-10/100, ImageNet-1K and NIH Chest X-ray."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The paper has an interesting approach to adversarial robustness and the experimental results are comprehensive in terms of the datasets used."}, "weaknesses": {"value": "=In the abstract the metrics mentioned don’t give any specific dataset. A 7.3% better robustness is achieved with respect to which dataset? \n\n=I would avoid the use of the word harmonize in the abstract. It is not clear what you mean when you say you harmonize provable and empirical adversarial robustness. Robustness is a measurement. If I said that I was going to harmonize kilometers and miles, would you understand what that meant? Obviously not. \n\n“the underlying randomness in these defences is static or easily inferred once seeds are fixed, rendering them vulnerable to adaptive attacks and offering no formal guarantees.”\n\n=In the introduction this is a very bold claim and no citations are given to back up this statement. Why would seeds be fixed? Why is the underlying randomness considered static? This is not at all clear. I would need to see several citations in the literature to back up such arguments. Otherwise it is just conjecture. \n\n=I don’t understand why you use the term “natural” and “medical” imaging domains to describe the datasets. I know CIFAR-10, CIFAR-100, ImageNet type of datasets are images and so are chest x-rays. It sounds like you are just trying to make the empirical work more impressive when all you did is test on image datasets. You should really remove this terminology natural/medical from the paper.\n\n=For the experiment for Figure 2, I am not convinced by the results. PGD is a very old attack. For credibility the authors at least need to update to APGD: https://arxiv.org/pdf/2003.01690\n\nAlso as far as I can tell, figure 2 is actually never referenced in the main body of the paper. Why do you have experimental results with no further explanation? \n\n=I think the terminology is confusing when you mention that your technique is a hybrid deterministic-stochastic defense. In theory if you add randomness to a deterministic defense, we would call that defense a randomized defense. In this case your paper is combining both deterministic and stochastic defenses, but this would then mean it is stochastic. E.g., any time a deterministic defense includes randomization, it is no longer random. I am concerned that mixing such terms as you do in your paper will really confuse readers. \n\n=Experimentally I don’t understand why so much space is wasted testing on PGD. In security we care about the strongest possible attacker. At this point PGD has widely been accepted as inferior to APGD. Therefore, there is NO reason to report PGD results in the main body of the paper. A huge  amount of space could be saved, simply by pushing all PGD results to the appendix. \n\n=I notice certain experiments are referenced in the main body but only shown in the appendix. E.g. Figure 7. I don’t think this follows the rules because it forces reviewers to look at appendix material when we should only be considering the main body. \n\nMy overall opinion of the paper is that the experimental results offer a marginal improvement at best. However, the use of extremely convoluted writing techniques throughout the paper (natural/medical), “harmonize” and mixing up what is really a new stochastic defense that they call a nonsensical term “deterministic-stochastic”, all lead me to strong reject. I think the authors should resubmit only after major revisions are done to the writing and terminology of the paper."}, "questions": {"value": "1. Why is the terminology so misused and convoluted? Can you fix the writing of the paper?  \n2. Why are you referencing results that only appear in the appendix? \n3. Why did you not use APGD for all experiments instead of PGD?\n4. How can you claim that your defense that has randomization is deterministic-stochastic?\n5. Can you remove all PGD experiments from the paper and appendix and replace them with APGD?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2Unz5gEUR2", "forum": "sYk9GaFHEf", "replyto": "sYk9GaFHEf", "signatures": ["ICLR.cc/2026/Conference/Submission20436/Reviewer_yF4E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20436/Reviewer_yF4E"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20436/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761574445576, "cdate": 1761574445576, "tmdate": 1762933877818, "mdate": 1762933877818, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes HyCAS, a hybrid defense combining deterministic 1-Lipschitz convolutions with two stochastic components, namely, random-projection filters and randomized attention noise, to yield both high certified $l_2$ robustness and empirical $l_\\infty$ robustness. The method claims state-of-the-art results on both natural and medical imaging benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) The method yields the state-of-the-art certified robustness, outperforming previous considered certified methods on CIFAR-10, ImageNet, and medical datasets (NIH-CXR, HAM10000), with up to $+7.3$ per cent gain at large radii.\n\n2) By tuning the smoothing noise level, the robustness for large radii can be improved with minimal clean accuracy drop, namely, increasing $\\sigma$ from $0.25$ to $0.50$ boosts the certified accuracy (specifically, from $8.5$ per cent to $12.5$ on CIFAR-10 at $r=2.0$)."}, "weaknesses": {"value": "1) The paper asserts HyCAS is the first method to offer both certified and empirical robustness, which is inaccurate: there were works incorporating randomization techniques and empirically robust modules, such as [1] and [2]. \n\n2) The main theoretical result ($\\le2$-Lipschitz bound) is loose in comparison to the one in the baseline work [3]. Consequently, the robust radius is loose too; it raises the question how does HyCAS achieves higher certified robustness in comparison to RS (Table 1)? Does it happen purely because of a higher accuracy on clean, unperturbed data? If so, that limits the theoretical contribution. Overall contribution seems incremental. \n\n3) Noise resampling protocol is not clear: are attention masks resampled per image or per batch during inference? \n\n4) Computational overhead of additional modules is not reported (in terms of memory, inference time).\n\n\n\n\n[1] Dong, M. and Xu, C.Adversarial robustness via random projection filters.In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.  4077–4086, 2023.\n\n[2] Yanxiang Ma, Minjing Dong, and Chang Xu. Adversarial robustness through random weight sampling. In Advances in Neural Information Processing Systems (NeurIPS), 2023.\n\n[3] Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified adversarial robustness via randomized\nsmoothing. In International Conference on Machine Learning (ICML), 2019."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7nTmt0IVGO", "forum": "sYk9GaFHEf", "replyto": "sYk9GaFHEf", "signatures": ["ICLR.cc/2026/Conference/Submission20436/Reviewer_YBxJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20436/Reviewer_YBxJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20436/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920540289, "cdate": 1761920540289, "tmdate": 1762933877168, "mdate": 1762933877168, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}