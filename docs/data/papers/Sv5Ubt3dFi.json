{"id": "Sv5Ubt3dFi", "number": 13834, "cdate": 1758223392706, "mdate": 1759897409538, "content": {"title": "High-Order Matching for One-Step Shortcut Diffusion Models", "abstract": "One-step shortcut diffusion models [Frans, Hafner, Levine and Abbeel, ICLR 2025] have shown potential in vision generation, but their reliance on first-order trajectory supervision is fundamentally limited. The Shortcut model's simplistic velocity-only approach fails to capture intrinsic manifold geometry, leading to erratic trajectories, poor geometric alignment, and instability-especially in high-curvature regions. These shortcomings stem from its inability to model mid-horizon dependencies or complex distributional features, leaving it ill-equipped for robust generative modeling. In this work, we introduce HOMO (High-Order Matching for One-Step Shortcut Diffusion), a game-changing framework that leverages high-order supervision to revolutionize distribution transportation. By incorporating acceleration, jerk, and beyond, HOMO not only fixes the flaws of the Shortcut model but also achieves unprecedented smoothness, stability, and geometric precision. Theoretically, we prove that HOMO's high-order supervision ensures superior approximation accuracy, outperforming first-order methods. Empirically, HOMO dominates in complex settings, particularly in high-curvature regions where the Shortcut model struggles. Our experiments show that HOMO delivers smoother trajectories and better distributional alignment, setting a new standard for one-step generative models.", "tldr": "", "keywords": ["High-Order Matching", "Diffusion Model", "One-Step Shortcut"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c52172f317c0fcbf437a819feb095714446d4c8b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes an extension of shortcut diffusion models: HOMO which allows for the inclusion of higher-order terms in the objective to improve the ability of learned models to capture flow trajectories.\nFurthermore, the paper provides theoretical justification for the importance of incorporating higher-order terms and evaluates HOMO on 2D toy distributions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The main idea behind the paper is well-founded and motivated, as it makes a lot of sense to expect that further guidance from higher order terms should help performance.\n* The theoretical justification for the use and importance of higher order terms in HOMO is, as far as I can see, good.\n* The paper does include a lot of empirical results, from providing many ablations with different combinations of M1, M2, SC."}, "weaknesses": {"value": "* The main issue with the paper is that all reported results are on 2D toy experiments. For instance, there are no large scale evaluations on problems of actual interest such as CIFAR or ImageNet, as well as baselines with other relevant methods on one-step/few-step generative models, like [1, 2] etc.\n\n* The main point that the paper needs to make is that the computational trade-off of additional computation from handling higher-order term, pays off in terms of performance. From Appendix H, there is a decent analysis of this. However, this is critically limited as the reported numbers are only for CPU performance, whereas practically, we need information about GPU performance. \n\n* The language used in the paper is way too overstated, such as \"a game-changing framework that leverages high-order supervision to revolutionize distribution transportation\" (line 19) and \"setting a new standard for one-step generative models\" (line 26) etc., especially, since the empirical evaluation of HOMO is so limited that it does not actually justify such statements \n\n* I find the inclusion of Appendix B on LLMs to be very strange, since as far as I can see, this section bears no relevance to the actual contents of the paper. This needs to be removed.\n\n[1] Consistency Models (2023)\n[2] Inductive Moment Matching (2025)"}, "questions": {"value": "* How sensitive is performance from the choice of discretisation of d?\n* Did you explore any weighting schemes for the new collection of different loss terms?\n* Do you believe that the trend reported in the current empirical results will be able to translate to large scale datasets of practical interest? \n* Why did you include Appendix B?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5qVnutvJST", "forum": "Sv5Ubt3dFi", "replyto": "Sv5Ubt3dFi", "signatures": ["ICLR.cc/2026/Conference/Submission13834/Reviewer_k7cZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13834/Reviewer_k7cZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13834/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761945690109, "cdate": 1761945690109, "tmdate": 1762924357275, "mdate": 1762924357275, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper takes the paper of [Frans et al. 2025] cited in the abstract, and updates it to add learnable second order taylor expansions rather than just the velocity fields of the particles. It has also some convergence bounds, which adapt proofs from a previous work by [Fukumizu et al. 2024] and some toy case experiments confirming that Taylor series of second order approximate better than first order."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The main strength is that the paper has a good idea, namely to use second order taylor approximation in the setting of [Frans et al. 2025], however I think that this paper is not in final form."}, "weaknesses": {"value": "The main weakness is the experiments. If the claim is that second or higher order is better than the original, then it should be tested on the same datasets and prove stronger performance there. \n\nTesting on 2D distributions does not convince very much, because we all know that higher dimensional geometry has sometimes counterintuitive properties that are not easily captured by just testing on distributions (as complex as they may be called) in R^2.\n\nThe proofs of the main theorems (appendices. C, D) are not a big step away from the work [Fukumitzu et al. 2024] but this is fair enough, if a big step is not needed then why do it.\n\nAlso, the paper has a series of typos and weird formulations, so can you re-read it a bit, and maybe pass it through a spellchecker?\nSome examples:\n- line 106: \"knowledge of only $x_t$ renders it a random variable\" what do you mean? it's not the knowledge of $x_t$ that matters, but the fact that $x_0$ is random, no?\n- line 114 \"the denoising ODEs\" .. are there more than one ODE?\n- line 132 \"gradient\" and \"second-gradient\" sounds weird.. you mean time derivative and second time derivative right?\n- line 133 \"reprectively\"\n- in all definitions you define $\\Delta t = 1/128\" with no explanation, and then take d to belong to a tuple, sometimes including 0 sometimes not.. based on what criterion I don't understand \n- in definition 3.2 the smallest allowed value of d is 1/128, but then the condition d<1/128 appears in line 144.. I don't follow much, can you revise/explain?\n- in definition 4.1 the only allowed value of d<1/128 is d=0 right? and you take $\\Delta t =1/128$ and you then stipulate when defining $x_{t+d}$ that when d<1/28 (i.e. when d=0 which was the only choice smaller than 1/128) you replace that by 1/128.. this is overwhelmingly strange.. can you explain?\n- line 147: \"first order term\" of what? you never talked about terms before.. \n- Def. 4.2: \"Let $u_{1,\\theta_1}$ be the networks\" -- it's only one network though no?\n- Remark 4.4: \"we denote first-order matching as M1, which implies that HOMO is optimized solely by the first-order loss\".. this has to be reworded, it's not the fact that you denote something that implies that HOMO is optimized in a way or another.. also, it's not optimized by some loss, is trained to optimize some loss I guess?\n\nI stopped annotating typos after arriving at section 5, but there may be more, please have a check.."}, "questions": {"value": "Can you compare your method to others on more realistic datasets/tasks?\n\nWhat are the drawbacks in terms of compute time or in terms of scaling, for the higher order methods you propose? Can you comment/compare on these, in case you decide to do more realistic experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "r2uLRwiUKR", "forum": "Sv5Ubt3dFi", "replyto": "Sv5Ubt3dFi", "signatures": ["ICLR.cc/2026/Conference/Submission13834/Reviewer_q2v7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13834/Reviewer_q2v7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13834/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959563250, "cdate": 1761959563250, "tmdate": 1762924356722, "mdate": 1762924356722, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes HOMO, a higher-order Shortcut diffusion model that augments first-order (velocity) supervision with acceleration (and optionally jerk) along $x_t = \\alpha_t x_0 + \\beta_t x_1$. Each order is predicted by its own network and trained with losses for first/second-order matching plus a self-consistency constraint from composing small steps. They provide training/sampling schemes and show experiments on synthetic and curve datasets."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The core idea of explicitly modeling higher-order terms along the transport path with separate networks is simple and potentially broadly applicable. The paper gives concrete training and sampling procedures that are easy to implement, and on standard 2D benchmarks it shows consistent improvements over a first-order shortcut baseline."}, "weaknesses": {"value": "The writing quality materially hurts readability. For example, the text says \"we define Shortcut model compute next field\" which is ungrammatical and obscures meaning. On the theory side, the approximation bounds are not informative for learning: even with large models, the bound in 5.1 retains an additive term $\\mathbb{E} \\left[\\|\\dot x_{\\text{true}}-\\ddot{x}_{\\text{true}}\\|^2\\right]$ that does not vanish. The results do not show that the learned velocity and acceleration converge to the truth nor that the minimizer of the proposed loss recovers a correct generative model of the data. The loss design is also unconvincing. If the Shortcut first order objective is optimized to match the path velocity, no second order correction should be needed, and the paper does not explain why adding a second order term helps. In addition there is likely an error in the objective as written since the M1 loss appears to evaluate $u_1(x_t,t,2d)$ rather than the instantaneous argument. Finally, the empirical scope is narrow since there are no image or other high dimensional experiments, so it is unclear whether any gains extend beyond two dimensional toys."}, "questions": {"value": "1) The approximation bounds include a non-vanishing term $\\mathbb{E} \\left[|\\dot x_{\\text{true}}-\\ddot{x}_{\\text{true}}|^2\\right]$. Could the authors clarify how this bound provides any guarantee that the learned model converges to the true generative process or that the proposed losses identify the correct flow?\n\n2) Why is the first-order M1 loss evaluated with $u_1(x_t,t,2d)$ rather than at the instantaneous argument $u_1(x_t,t,0)$? If this is intentional, what theoretical justification ensures that using a finite step size does not bias the learned dynamics?\n\n3) All reported experiments are on 2D toy datasets. Have the authors tested the approach on any image or high-dimensional generative tasks, and if not, what challenges prevent such evaluation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uiDLv8zcws", "forum": "Sv5Ubt3dFi", "replyto": "Sv5Ubt3dFi", "signatures": ["ICLR.cc/2026/Conference/Submission13834/Reviewer_r58d"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13834/Reviewer_r58d"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13834/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762125393377, "cdate": 1762125393377, "tmdate": 1762924356275, "mdate": 1762924356275, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}