{"id": "6L3yCjx9s3", "number": 19231, "cdate": 1758294622014, "mdate": 1759897051087, "content": {"title": "Dimension-Adaptive MCTS: Optimal Sample Complexity for Continuous Action Planning", "abstract": "We study continuous-action Monte Carlo Tree Search (MCTS) in a $d$-dimensional action space when the \noptimal action-value function $Q^*(s,\\cdot)$ is $\\beta$-Hölder continuous with constant~$L$. We show that a \ndimension-adaptive $\\varepsilon$-net schedule combined with power-mean backups and a polynomial exploration \nbonus finds an $\\varepsilon$-optimal action in  $ \\tilde{O}\\left(\\sigma^2 L^{d/\\beta} \\varepsilon^{-(d/\\beta+2)}\\right) $\nsimulations, matching standard continuum-armed lower bounds up to logs while remaining practical \nvia on-demand, capped random nets. We further demonstrate that our method significantly outperforms \nbaseline methods on continuous control planning problems. Our work bridges the gap between theoretical \nreinforcement learning and practical planning algorithms, providing a principled approach to \nhigh-dimensional continuous action space exploration.", "tldr": "", "keywords": ["Monte-Carlo Tree Search; Continuous Reinforcement Learning Planning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/65dcc80a0ba3e9b6af3a6062955e6870b7104aca.pdf", "supplementary_material": "/attachment/d155ed9437f53f07c724a0f1343d800541feaff5.zip"}, "replies": [{"content": {"summary": {"value": "This paper discusses the challenge of extending Monte Carlo Tree Search (MCTS) to high-dimensional continuous action spaces, where existing methods suffer from exponential sample complexity and lack theoretical guarantees. The authors highlight that while prior works like progressive widening offer empirical success, they fail to capture the relationship between dimensionality, smoothness, and efficiency. The paper introduces Power-Mean Dimension-Adaptive MCTS (PM-DA-MCTS) — an algorithm that combines adaptive discretization of the action space with power-mean backups and polynomial exploration bonuses. The proposed method achieves provably optimal sample complexity and good empirical performance in stochastic, high-dimensional environments.\n\n."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1- well-written paper and easy to read.\n2- Correct and solid theorems and theoretical results."}, "weaknesses": {"value": "1- The theoretical contribution is incremental. The idea is to extend an established convergence analysis in discrete-action spaces to continuous action spaces by discretizing the continuous space with a dimension-adaptive scheme, effectively reducing the problem to the discrete-action setting.\n\n2- The use of power-mean operators and a polynomial exploration bonus is not novel; both have been used in prior planning methods.\n\n3- Regarding the results, UCT is a very basic baseline, yet it performs comparably to PM-DA-MCTS in most domains. The only domain showing a significant difference is MountainCar, which I believe is due to the environment’s characteristics and the paper’s exploration strategy.\n\n4- To better evaluate the discretization strategy, more high-dimensional environments are needed; only two are provided."}, "questions": {"value": "1- Is POLY-HOOT (2020) the SOTA performance of MCTS in continuous-action domains?\n\n2- How does your method perform in high-dimensional domains with sparse feedback, such as goal-conditioned mazes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "ewJHOcBoB6", "forum": "6L3yCjx9s3", "replyto": "6L3yCjx9s3", "signatures": ["ICLR.cc/2026/Conference/Submission19231/Reviewer_azdV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19231/Reviewer_azdV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942617028, "cdate": 1761942617028, "tmdate": 1762931213185, "mdate": 1762931213185, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the Monte Carlo Tree Search (MCTS) problem in a random environment with a $d$-dimensional continuous action space. The authors propose a new algorithm named \"Power Mean Dimension Adaptive MCTS\" (PM-DA-MCTS), which combines three new techniques: 1) an adaptive $\\epsilon$ based on the $\\epsilon$-net discretization strategy of dimension $d$ and the $\\beta$-Holder continuity of the value function; 2) a power mean backtracking operator for the random environment; 3) a polynomial exploration reward. The core contribution of this work is that it theoretically proves that the algorithm can find an $\\epsilon$-optimal action with an optimal sample complexity of $\\tilde{\\mathcal{O}}(\\epsilon^{-(d/\\beta+2)})$, and it significantly outperforms existing continuous action MCTS baseline methods in empirical evidence."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper presented the theoretically grounded MCTS algorithm for high-dimensional continuous action spaces that\nachieves optimal sample complexity bounds while using power mean backup in stochastic\nenvironments.\n2. This method overcomes the problem of lack of theoretical guarantee in existing work and successfully extends the recent theoretical progress on power averaging estimators (originally limited to discrete settings) to the continuous action space.\n3. The experiment results show that PM-DA-MCTS outperforms multiple baselines in both mean and variance on several low-dimensional and high-dimensional tasks in the style of MuJoCo, supporting the theoretical claims."}, "weaknesses": {"value": "1. The paper explains in detail that its adaptive discretization is based on \"uniform grid discretization\". All theoretical analysis strictly depend on this structured uniform grid. However, this discretization is exponential to $d$: $\\mathcal{N}_k = O((1/\\epsilon_k)^d)$. The paper does not fully explain how a uniform grid can be \"lazily\" loaded in high-dimensional space while maintaining computational feasibility.\n2. In abstract, the author mentioned that :\"matching standard continuum-armed lower bounds up to logs while remaining practical via on-demand, capped random nets\". What does \"capped random nets\" mean? It seems that this paper did not detailedly discuss this issues.\n3. I wonder if the experiments for HUMANOID ($d = 17$) involves such capped method to maintain practical efficiency.  If directly apply the  algorithm in Section 4, does the algorithm still maintain computationally feasible in the experiement settings?\n\nI would like to raise my score if authors could well address my concerns."}, "questions": {"value": "See weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xAUBamoOaa", "forum": "6L3yCjx9s3", "replyto": "6L3yCjx9s3", "signatures": ["ICLR.cc/2026/Conference/Submission19231/Reviewer_xF1x"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19231/Reviewer_xF1x"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965603644, "cdate": 1761965603644, "tmdate": 1762931212818, "mdate": 1762931212818, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors address planning on continuous action spaces via Monte-Carlo tree search. Under a standard Holder smoothness assumption, they propose an adaptive discretization schedule, and incorporate it into other tweaks proposed within recent literature. The resulting procedure achieves the minimax lower bound. Empirically, numerical experiments justify performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper offers a theoretically sound contribution for continuous action planning with MCTS. This is especially nice since planning has been underaddressed within recent literature. \n- The authors provide a discretization strategy, and analyze its performance along a host of other tweaks present in the literature to obtain rigorous convergence guarantees. \n    - Said discretization strategy, in particular, could indeed be valuable in practice, though a user is likely to randomly sample along the lines of the scale suggested in the paper in practice instead. \n- The method achieves the minimax lower bound, up to a logarithmic term. \n- The experiments are not bad at all for a theory paper."}, "weaknesses": {"value": "1. **Limited novelty.** The algorithm amounts to MCTS with a confidence bonus, plus a clever discretization. It is nice that it accommodates power mean Bellman backups, but this does not seem to be necessary for the convergence of the MCTS procedure. The polynomial exploration bonus is not new either, following Shah et al. (2022).\n- As such, the contribution is sound, albeit limited -- the only novelty in algorithmic design appears to be in the choice of discretization. Accordingly, the analysis appears to follow from the analysis of Dam et al. (2024), Dam et al. (2025).\n2. **Clarity and formatting.** \n- While the power mean backups are attributed to Dam et al. (2019) and the polynomial bonus to Shah et al. (2022) within the paper, it is not clearly stated within the section on key contributions (to be fair, it is stated before it, but not during it) and the algorithm overview. An inattentive reader could mistakenly attribute the contribution to this paper.\n- There are quite a few issues with the formatting. \n    - In the section on key contributions, there is quite a bit of ``\\vspace{}`` abuse present to make the bullet points more condensed. This is not necessarily a problem in itself, but the settings are far too aggressive to not be noticed. \n    - The authors should have used ``\\citep{}`` and not ``\\cite{}`` in many places."}, "questions": {"value": "1. Is there novelty in the theoretical analysis beyond Dann et al. (many papers), Shah et al. (2022), and other recent literature, beyond incorporating the discretization error into the convergence bound?\n2. Methodologically, is the adaptive discretization the only new methodological contribution?\n\nMy concerns mainly relate to novelty, and to some lesser degree clarity. At the moment, I am on the fence between a 4 and a 6, and am willing to increase my score if I am proven wrong or my concerns are addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nx7uN8NdzA", "forum": "6L3yCjx9s3", "replyto": "6L3yCjx9s3", "signatures": ["ICLR.cc/2026/Conference/Submission19231/Reviewer_TSvv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19231/Reviewer_TSvv"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970025906, "cdate": 1761970025906, "tmdate": 1762931212424, "mdate": 1762931212424, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes PM-DA-MCTS, a planning algorithm for continuous-action reinforcement learning based on Monte-Carlo Tree Search (MCTS) under the assumption that the optimal value function is β-Hölder smooth. The method adaptively discretizes the action space, uses power-mean backups to trade off between optimistic and average value estimates, and employs polynomial-confidence exploration bonuses to manage noisy returns. The authors prove high-probability sample-complexity bounds that match minimax rates for continuum-armed bandits up to logarithmic factors, and present experiments on MuJoCo environments showing improvements over progressive widening, HOOT, and other MCTS baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The work analyzes continuous-action MCTS and achieves optimal dimension-dependent sample-complexity rates under β-Hölder smoothness. Extending non-asymptotic MCTS analysis to adaptive discretization with stochastic returns is a meaningful contribution.Combining dimension-adaptive grids, power-mean backup operators, and polynomial concentration bonuses is conceptually interesting and grounded in existing theory. Experiments on MuJoCo tasks demonstrate tangible improvements over established MCTS methods, and ablations highlight the contribution of each algorithmic component."}, "weaknesses": {"value": "I do not have many complaints. \n1. While technically sound, the exposition could be improved somewhat to convey the necessity behind the power-mean operator, and the role of polynomial concentration. \n2. Regarding the empirical evaluations, the comparison to MCTS baselines is appropriate for validating the planning approach. However, since continuous control is often handled with policy-gradient methods (e.g., PPO, SAC), benchmarking against such baselines research would better contextualize practical usefulness."}, "questions": {"value": "If we consider the finite action set case (which is trivially embeddable in d=|A| dimensions), it seems that we recover a sample complexity that is exponential in |A|. Is this the correct rate for MCTS in the finite-action setting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7HT5wVygqT", "forum": "6L3yCjx9s3", "replyto": "6L3yCjx9s3", "signatures": ["ICLR.cc/2026/Conference/Submission19231/Reviewer_pCZE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19231/Reviewer_pCZE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19231/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762297778231, "cdate": 1762297778231, "tmdate": 1762931211941, "mdate": 1762931211941, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Global clarifications (all reviewers)"}, "comment": {"value": "We thank all reviewers for the careful and constructive feedback. Several comments converge on two themes: (i) the precise novelty of our work relative to Dam et al. and Shah et al., and (ii) whether the experimental section is sufficient for a theory‑driven paper. We address these points here.\n\n### Novelty and scope\n\nOur paper is first and foremost **a theoretical planning paper**. The central goal is to understand how continuous‑action *tree search* can achieve minimax‑optimal, dimension‑aware sample complexity under β‑Hölder smoothness and stochastic rollouts. Within that scope, our main new contributions are:\n\n1. A **dimension‑adaptive $\\varepsilon$‑net schedule for continuous‑action MCTS**, together with a visit‑based refinement rule, that yields the first **finite‑variance, high‑probability *sample‑complexity* bound for continuous‑action MCTS**:\n   $$\n   N(\\varepsilon,\\delta)=\\tilde O \\big(\\sigma^2 L^{d/\\beta}\\varepsilon^{-(d/\\beta+2)}\\big),\n   $$\n   matching continuum‑armed lower bounds up to logarithmic factors.\n\n2. A **theoretical guarantee that this rate is preserved under a practical, capped on‑demand \"random net'' implementation**, i.e., without ever materialising the full exponential grid, via a high‑probability coverage argument along the *realised* search.\n\n3. A **systematic empirical study of stochastic high‑dimensional planning** (Walker2d, Ant, Humanoid) showing that this theory‑driven design yields consistent gains over strong continuous‑action MCTS baselines (HOOT, POLY‑HOOT, PW, UCT) and is competitive with the CEM planner on Humanoid, with dramatically reduced variance.\n\nWe explicitly *do not* claim power‑mean backups or polynomial bonuses as new: these come from Power‑UCT / Stochastic Power‑UCT and Shah et al. Our contribution is to **combine** these tools with a dimension‑adaptive discretization and show that, under finite‑variance rollouts, this leads to an optimal $N(\\varepsilon,\\delta)$ for *continuous‑action tree search*.\n\n### Why power‑mean + polynomial concentration + $\\varepsilon$‑nets fit together\n\nConceptually, the three ingredients play distinct roles:\n\n* The **power‑mean backup** provides a family of estimators whose **polynomial tails survive depth‑wise composition** through the tree under the polynomial bonus.\n* The **polynomial exploration bonus** (rather than a log‑UCB term) gives **non‑asymptotic, depth‑indexed concentration exponents** $(\\alpha_h,\\zeta_h,b_h)$ that we can control at each node.\n* The **dimension‑adaptive $\\varepsilon$‑net schedule** is tuned so that, at the refinement level where we stop, the geometric discretization error $L\\varepsilon_k^\\beta$ and the statistical error from these polynomial tails are of the same order. This is what converts node‑wise concentration into a **dimension‑aware global bound** with the optimal $L^{d/\\beta}\\varepsilon^{-d/\\beta}$ factor.\n\nThus, rather than three unrelated tricks, the backup, bonus, and $\\varepsilon$‑net geometry are chosen to be analytically compatible and to hit the continuum‑armed lower bound with finite‑variance rollouts.\n\n### Experimental scope for a theory paper\n\nGiven that the paper is primarily theoretical, our aim in the experiments is to **demonstrate that the theory‑guided design is not purely abstract**, not to exhaustively benchmark all planners. We therefore:\n\n* Cover both **low‑dimensional** and **high‑dimensional** continuous‑control tasks (Walker2d ($d=6$), Ant ($d=8$), Humanoid ($d=17$)),\n* Compare against **strong tree‑based baselines** (HOOT, POLY‑HOOT, progressive widening, UCT), and\n* Include a comparison to **CEM** on Humanoid, showing higher mean return and an order‑of‑magnitude lower variance under the same per‑decision simulation budget.\n\nWe believe this level of empirical validation is appropriate for a theory‑focused paper whose main contribution is an optimal, dimension‑explicit sample‑complexity analysis for continuous‑action MCTS."}}, "id": "bGTK0jXeB3", "forum": "6L3yCjx9s3", "replyto": "6L3yCjx9s3", "signatures": ["ICLR.cc/2026/Conference/Submission19231/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19231/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission19231/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763466312048, "cdate": 1763466312048, "tmdate": 1763466312048, "mdate": 1763466312048, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}