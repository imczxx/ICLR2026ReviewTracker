{"id": "F536F9LvVH", "number": 19722, "cdate": 1758298840519, "mdate": 1759897023154, "content": {"title": "AutoLumNet: A Bi-Branch Exposure-Aware Network for Low- and High-Exposure Image Enhancement", "abstract": "Enhancing images captured under challenging illumination is difficult because real-world scenes often contain both severely under-exposed shadows and over-exposed highlights. Existing low-light enhancement methods primarily address under-exposure, while multi-exposure fusion requires multiple bracketed shots, which are rarely available in practice. We propose AutoLumNet, a bi-branch exposure-aware network that performs single-shot exposure correction. AutoLumNet decomposes input features into dual branches specialized for shadows and highlights, then adaptively fuses them via spatial attention. To ensure that the corrected luminance distribution aligns with natural photographs, we introduce an optimal-transport-based exposure distribution alignment mechanism, theoretically guaranteeing monotonicity and preventing spurious extrema. Training is guided by a unified exposure-aware objective combining reconstruction fidelity, distribution alignment, perceptual consistency, and regularization terms. Extensive experiments on SICE, LOL, and MIT-Adobe FiveK demonstrate that AutoLumNet achieves state-of-the-art results across under-, over-, and mixed-exposure conditions, outperforming both single-image enhancement and multi-exposure fusion baselines in PSNR/SSIM, perceptual metrics, and user studies. Our approach bridges the gap between low-light enhancement and exposure fusion, offering a principled and practical solution for real-world photography.", "tldr": "We propose AutoLumNet, a bi-branch exposure-aware image enhancement network with a shared encoder, dual decoders, and a learnable gating module. Trained on paired low/high-light data, it adaptively corrects exposure across diverse lighting conditions", "keywords": ["Image Enhancement", "Exposure Correction", "Deep Curve Estimation", "Bi-Branch Network"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/92fd2e4f60a5278d452d26da9c045050751b069a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors claim to address both under- and over-exposure within a unified framework, but the overall contribution of this paper is very limited and lacks innovation. The so-called bi-branch architecture that designed to separately process shadows and highlights before adaptive fusion is not novel at all; similar dual-path and attention-fusion designs have already been extensively explored in the fields of image enhancement and exposure correction. The proposed “optimal transport–based exposure distribution alignment” is essentially a repackaged version of traditional histogram matching or tone mapping, without any solid theoretical derivation or sufficient experimental and mathematical validation. The training objective is also uninspired, simply combining pixel reconstruction, perceptual consistency, and regularization losses—almost identical to existing image enhancement frameworks.\n\nThe experimental results appear comprehensive at first glance, but the actual improvements are minimal. Compared with baselines such as Zero-DCE, LLFlow, and EMEF, the gains are only about 0.5–1 dB, with no statistical significance analysis or user study to substantiate the claims. The ablation study is poorly designed and fails to isolate whether the improvements stem from the dual-branch structure, the optimal transport module, or mere parameter tuning. Although the qualitative results show slight visual improvement, the outputs tend to suffer from over-smoothing and unnatural color tones.\n\nFurthermore, the overall writing and formatting quality of the paper are very poor. The layout is loose with excessive white space, the paragraph organization is messy, and the presentation lacks compactness. In addition, the paper does not even include a single complete model architecture or pipeline figure, making it difficult for readers to understand the network design and data flow that greatly undermining readability and academic rigor. The manuscript contains a large amount of redundant wording and lengthy descriptions, the language is not concise, and the overall readability is very poor."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The only strength of this paper is that the mathematical formulations are clearly presented, however, the use of the “#” symbol in some equations is quite unconventional and confusing."}, "weaknesses": {"value": "1.The paper lacks genuine novelty and conceptual contribution. The proposed bi-branch architecture, exposure-aware fusion, and optimal transport–based luminance alignment are all incremental ideas already explored in existing literature. Dual-path or attention-based networks such as KinD (Zhang et al., 2019), LIEN-MFC (Zhang et al., 2023a), and LLFlow (Wang et al., 2022a) have addressed similar goals. \n\n2.The paper does not demonstrate any clear theoretical or methodological advance beyond reusing these established components. The so-called “optimal transport–based exposure alignment” is essentially a reformulation of traditional histogram equalization or tone mapping, without rigorous mathematical justification or insightful analysis.\n\n3.The experimental validation is weak and unconvincing. The reported quantitative improvements over strong baselines are marginal (only about 0.5–1 dB PSNR), and there is no statistical analysis to verify whether the improvements are significant. \n\n4.The experiments are limited to standard benchmarks and do not evaluate robustness under unseen lighting conditions or diverse image types, which is essential for single-shot exposure correction. The ablation study is simplistic and fails to separate the individual contributions of the dual-branch design, the optimal transport alignment, and the perceptual loss, making the source of improvement unclear.\n\n5.The paper’s presentation quality is very poor, which further undermines its technical claims. There is no figure showing the overall model structure, feature flow, or pipeline diagram, making it difficult for readers to understand how the network operates. The formatting is unprofessional, with excessive white space and uneven layout that make the paper appear unfinished. Although the equations are generally clear, the use of the “#” symbol in some formulations is unconventional and confusing for readers unfamiliar with this notation.\n\n6.The theoretical rigor of the paper is also insufficient. Although the authors claim “theoretical guarantees” of monotonicity and exposure consistency, no formal derivations or proofs are provided. The connection between optimal transport and exposure correction is discussed only at a conceptual level, without mathematical grounding or convergence analysis. \n\n7.The proposed loss functions are standard components widely used in image restoration tasks and do not provide new insights or theoretical advances.\n\n8.The visual comparison experiments are also insufficient. The paper includes only one qualitative example, which is far from enough to evaluate visual realism or color consistency across different illumination conditions. The provided comparisons are not comprehensive and omit several strong baselines. \n\n9.No user study or perceptual evaluation is conducted to verify whether the method actually produces more natural-looking results, which undermines the credibility of the claimed perceptual advantages."}, "questions": {"value": "1.The paper presents AutoLumNet as a “bi-branch exposure-aware” framework, but similar dual-path or illumination-decomposition architectures already exist (e.g., KinD, LIEN-MFC, LLFlow). Could the authors clarify what is fundamentally new in this design beyond separating shadow and highlight processing? How does the proposed approach differ conceptually or mathematically from these prior models?\n\n2.The “optimal transport–based exposure distribution alignment” appears very similar to histogram equalization or tone mapping. Could the authors explicitly explain how their use of the Sinkhorn divergence provides a genuine improvement over simpler histogram-matching strategies? Please also clarify the notation “#” in Eq. (9), since it is nonstandard and confusing.\n\n3.The paper claims “theoretical guarantees” for monotonicity and exposure consistency but does not provide formal derivations. Could the authors include a mathematical proof or at least a more rigorous argument showing that their transport formulation indeed enforces these properties under all conditions?\n\n4.The paper currently contains no schematic of the proposed network, which makes it very difficult to follow. Could the authors add a complete diagram showing the encoder, dual branches, adaptive fusion, and transport alignment modules, along with data flow and dimensional details?\n\n5.The experiments are limited to SICE, LOL, and FiveK. To demonstrate generalization, could the authors test AutoLumNet on additional datasets such as DICM, NPE, HDR+, or real-world mobile datasets? Also, could they report runtime comparisons and memory usage to evaluate the practical feasibility of the approach?\n\n6.The qualitative results are limited to one or two examples. Could the authors include more visual comparisons across diverse lighting scenarios, including strong baselines like Retinex-MEF and diffusion-based models? Additionally, would a user study or perceptual preference test support the claim of improved visual naturalness?\n\n7.The ablation study is too brief. Could the authors expand it to show how much each part (dual-branch, OT alignment, perceptual loss, chroma guard, regularization) contributes quantitatively and visually? This would make the analysis more convincing.\n\n8.The paper lacks any statistical validation. Could the authors provide standard deviations or confidence intervals for PSNR/SSIM across test samples to show whether the observed improvements are statistically significant?\n\n9.What are the typical failure modes of AutoLumNet. For example, extremely dark scenes, strong glare, or motion blur? A short section discussing limitations and possible future improvements would make the paper more balanced and credible.\n\n10.The paper’s presentation quality is far below conference standards. Could the authors tighten the writing, reduce redundancy, and fix the layout issues (e.g., large white spaces, uneven paragraphs)? Including clearer mathematical notation and a figure summarizing the workflow would greatly enhance readability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "BqPsJOMB9l", "forum": "F536F9LvVH", "replyto": "F536F9LvVH", "signatures": ["ICLR.cc/2026/Conference/Submission19722/Reviewer_Buh8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19722/Reviewer_Buh8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19722/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761433913403, "cdate": 1761433913403, "tmdate": 1762931559319, "mdate": 1762931559319, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduced AUTOLUMNET, a unified network designed to handle both low- and high-exposure images. A dual-branch architecture is employed to correct each type of distortion, while an additional exposure-distribution alignment scheme ensures stable fusion. Experimental results on five benchmark datasets demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written and easy to follow. The proposed method is clearly described and well motivated. Extensive experiments demonstrate its effectiveness, and no major technical concerns are identified."}, "weaknesses": {"value": "However, I consider that the technical contribution does not meet the level required for acceptance at ICLR. Although the authors emphasize that handling both over- and under-exposure within a single neural network is a novel idea, I respectfully disagree.\n\nThis concept is not new. Several prior studies have already explored similar directions, but the paper does not provide a thorough discussion or sufficient experimental comparisons with them.\n\nFor example, earlier works have addressed the same problem using cascaded approaches [Ref1] or parallel architectures [Ref2]. Fourier-domain [Ref3] and Laplacian-domain [Ref4] methods have also been introduced. The proposed method is particularly similar to [Ref2] and its follow-up studies, where the network is divided into over-exposure and under-exposure branches, and a fusion module combines the results. The exposure alignment mechanism is also closely related to previous works [Ref5,6]. While there are some differences in fusion and feature alignment, I do not find them to be substantial.\n\nConsidering the aforementioned and other related studies, the paper’s technical contribution appears limited. As it lacks a systematic review, detailed discussion, and comprehensive experimental comparison with closely related methods, I recommend rejection at this time.\n\n[Ref1] Unified-EGformer: Exposure Guided Lightweight Transformer for Mixed-Exposure Image Enhancement, ICPR 2024\n[Ref2] Local Color Distributions Prior for Image Enhancement, ECCV 2022\n[Ref3] Deep Fourier-based Exposure Correction Network with Spatial-Frequency Interaction\n[Ref4] Learning Multi-Scale Photo Exposure Correction, CVPR 2021\n[Ref5] Exposure Normalization and Compensation for Multiple-Exposure Correction, CVPR 2022\n[Ref6] Learning Exposure Correction via Consistency Modeling, BMVC 2021"}, "questions": {"value": "I do not have specific questions, as the paper is clearly explained. However, it requires substantial revisions to address the concerns outlined in the Weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "e87Th1NMO2", "forum": "F536F9LvVH", "replyto": "F536F9LvVH", "signatures": ["ICLR.cc/2026/Conference/Submission19722/Reviewer_cwnG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19722/Reviewer_cwnG"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19722/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761443173966, "cdate": 1761443173966, "tmdate": 1762931558643, "mdate": 1762931558643, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work considers to address the problem of enhancing both low-exposure and high-exposure areas for an image in one pipeline. The proposed AutoLumNet is a bi-branch exposure-aware network that performs single-sot exposure correction. The authors sue optimal-transport-based algorithm to ensure the corrected luminance aligns with natural image distribution. The algorithm achieves promising results on SICCE, LOL, and FiveK dateset."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses a practical aspect in image enhancement.\n- Excellent writing and the paper is easy to follow."}, "weaknesses": {"value": "1. The paper does not include an essential baseline comparisons.\n    - To solve the problem, here are two simple baselines: 1) for a given image, applying an  underexpose photo enhancement algorithm and then an overexpose photo enhancement (ue + oe). And 2) similarly oe+ue.\n2. The pipeline of AutoLumNet does not address the roots of underexposed- and overexposed photo enhancement. As far as the review understands, the core of UPE is to reduce noises; while the core of OPE is to recover information loss incurred by overexposure. However, it is not clear that how the pipeline addresses the rots.\n3. The evaluation is limited on underexposed photo enhancement datasets (LOL, FiveK). The paper would benefit from more results on mix-exposure dataset such as SICE.\n4. The baselines in the paper seem outdated. More recent more on UPE includes [a] [b] [c].\n\n[a] Reti-Diff: Illumination Degradation Image Restoration with Retinex-based Latent Diffusion Model. ICLR 25.\n\n[b] HVI: A New Color Space for Low-light Image Enhancement. CVPR 25.\n\n[c] RT-X Net: RGB-Thermal cross attention network for Low-Light Image Enhancement.  ICIP.\n\n5. Some design choices in the method are not clear.\n    - In eq. 6, $s_{ue}^i (p)$ is not defined or explained.\n    -  In eq. 7, The authors claim the constraint as “convexity constraint”.   How it is related to convexity?\n    - In Lines 166-168, the author claims that the enhanced output lies on the manifold of naturally exposed photographs. However, in methodology part, “the manifold of naturally exposed photographs” is a simple “fixed prior”, such as a truncated Gaussian. The novelty is hence limited."}, "questions": {"value": "Please address the concerns 1-5 as stated in Weakness part.\nThe review will raise my rating if my concern gets solved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4QH8rJRyUg", "forum": "F536F9LvVH", "replyto": "F536F9LvVH", "signatures": ["ICLR.cc/2026/Conference/Submission19722/Reviewer_Zth8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19722/Reviewer_Zth8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19722/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761757372858, "cdate": 1761757372858, "tmdate": 1762931558156, "mdate": 1762931558156, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces AutoLumNet, a dual-branch neural network designed for single-shot correction of images with both under- and over-exposed regions. The core contributions are a bi-branch architecture to separately handle shadows and highlights, and a novel exposure distribution alignment module based on Optimal Transport (OT) to enforce global luminance statistics. The method is evaluated on several standard datasets and shows strong empirical performance against existing low-light enhancement and multi-exposure fusion techniques."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "The paper's main strength lies in its formulation of the problem and the novel introduction of Optimal Transport (OT) for exposure alignment. This provides a principled mathematical framework for ensuring the global naturalness of the output, a significant departure from prior heuristic-based methods. The dual-branch design is an intuitive and well-motivated architectural choice that directly reflects the bimodal nature of the underlying problem. The method demonstrates state-of-the-art performance across multiple datasets and a comprehensive set of metrics, suggesting its practical effectiveness."}, "weaknesses": {"value": "The description of the method is critically insufficient, making the work impossible to reproduce. The paper provides no information on how the similarity computation network (h_ue) and the difference inference network (h_oe) are architecturally implemented or trained. How does the model learn to specialize each branch? T\n\nhe network that predicts the OT parameters a(p) and b(p) is not described. There is no discussion of how the canonical target distribution P* is defined or derived. This is a central component of the OT module, yet its implementation is left entirely to the reader's imagination."}, "questions": {"value": "1. The training of the dual branches (h_ue, h_oe) and the OT module is unclear. Are these components trained end-to-end from scratch? Is there a specific strategy to encourage branch specialization? The paper claims these networks can generalize well, but without information on their training, this claim is difficult to verify.\n\n2. Could you please provide a precise definition of the canonical target distribution P* used in your experiments? Was it a fixed analytical distribution (e.g., a Gaussian), and if so, with what parameters? Or was it estimated from the training data, and if so, what was the estimation procedure?\n\n3. To properly validate the necessity of the dual-branch design, could you provide an ablation study comparing your full model to a single-branch variant with a comparable number of parameters?\n\n4. Please provide a detailed network architecture diagram. Furthermore, could you provide specifics on the network architectures (e.g., layer types, kernel sizes, channel counts) for the dual branches and the OT parameter prediction head, perhaps in an appendix?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "a3EVzqGP8q", "forum": "F536F9LvVH", "replyto": "F536F9LvVH", "signatures": ["ICLR.cc/2026/Conference/Submission19722/Reviewer_6oJR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19722/Reviewer_6oJR"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19722/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920943841, "cdate": 1761920943841, "tmdate": 1762931557759, "mdate": 1762931557759, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}