{"id": "6wNx3KpS3d", "number": 14567, "cdate": 1758239101398, "mdate": 1759897361958, "content": {"title": "Understanding Graph Self-Supervised Pre-training under Distribution Shifts: A Scaling Law Perspective", "abstract": "Scaling laws have played a fundamental role in the development of foundation models for NLP and vision, but their applicability to large-scale pretrained graph-based models remains unclear—particularly under distribution shifts intrinsic to graph data. In this work, we systematically investigate how model capacity and data scale affect downstream performance in graph pre-training under distribution shifts. To disentangle how distribution shifts impact the scaling, we construct synthetic benchmarks based on contextual stochastic block models, with precise control over both structural and feature-level shifts across the pre-training and testing graphs. Our initial experiments on GCN, a standard Graph Neural Network (GNN) baseline, reveal a striking asymmetry: increasing model capacity consistently improves performance, while increasing data size often degrades it, even under mild shift. We show that this degradation is not inevitable; properly configuring the pretraining model with deeper, wider, and transformer-based architectures enables favorable data scaling, even when distribution shifts. As data scales, graph transformer models achieve up to +9\\% gains over GCN, which holds for both synthetic and real-world graph domain adaptation tasks. To explain this phenomenon, we develop a theoretical framework based on Fisher separability and Wasserstein domain divergence, which formally characterizes how distribution shifts affect representation transferability. Our results highlight architecture- and shift-aware strategies as the key to unlock scalable graph-based model pre-training.", "tldr": "", "keywords": ["Graph Self-Supervised Pre-training", "Scaling Law"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/937c9d4f992d0342c8977922412b16026c1fc5c0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents a nice innovation and introduces innovative ideas about scaling laws for graph-based pre-training under distribution changes. However, I think this paper lacks an overall framework diagram and a clearer visual description of the novel contributions, which would further improve the completeness and clarity of the paper. In addition, the results section is relatively thin, and a visual presentation of the method will enhance the persuasive power of the method and also help the reader better understand the experimental setup. Finally, the comparison with existing SOTA methods is not explicitly emphasized in this paper, making it difficult to measure the relative advantages of the proposed method. Including. Overall, this work is promising, but would benefit from improved presentations and stronger empirical analysis."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The originality of this paper is good, the quality is acceptable, but the explanation of the problem is not clear enough. Graph neural network is a good research direction, and it is very meaningful to explore the influence of model capacity and data scale on the downstream performance of graph pre-training under the condition of distribution shift."}, "weaknesses": {"value": "In my opinion, the biggest problem of this paper is that the summary of the problem solved is not concise enough, and there is no prominent point in the description of the method. If the overall framework diagram can be added, this paper will be more complete. At the same time, the comparison with the existing baseline or similar methods will make the innovation points of this paper more convincing."}, "questions": {"value": "1.It would be helpful to include a diagram illustrating the key innovations or core concepts of the paper.\n2.The overall framework could be further streamlined for clarity.\n3.Try to add more visualized results to enhance the presentation of your findings."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "15qbbO3ANM", "forum": "6wNx3KpS3d", "replyto": "6wNx3KpS3d", "signatures": ["ICLR.cc/2026/Conference/Submission14567/Reviewer_R8F9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14567/Reviewer_R8F9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14567/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761909454107, "cdate": 1761909454107, "tmdate": 1762924957645, "mdate": 1762924957645, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The scaling law for graphs is an important issue. This work focuses on this point and demonstrates that graph transformers are the architectures capable of scaling. Additionally, the authors construct a framework to characterize the relationship between distribution shift and representations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Originality: The authors’ work is original and goes beyond a simple combination of existing ideas (i.e., not merely “A + B”). They identify and address an important problem with their own thoughtful perspective and answer. \n\nQuality: The quality of the work is substantial. The experiments, hypotheses, and interpretations are well-aligned and mutually supportive. \n\nClarity: The manuscript is clearly written and free of confusing or ambiguous passages. \n\nSignificance: The question of scaling laws for graphs is an important and timely topic in the field."}, "weaknesses": {"value": "The authors should provide a more detailed description of the datasets in the main experiments, rather than using an oversimplified notation like `USA → EU`. Although they mention that more details are available in the appendix, I was unable to locate them.\n\nThe experiments appear to involve only the same underlying data with different representations—i.e., graph data of the same type but with varying node attributes. In my view, this level of analysis are far from scaling law on graph."}, "questions": {"value": "1. Do you  have experimental results that examine shifts across fundamentally different types of graph data? E.g., a graph-level data shift to a node-level data?\n\n2.This paer employed three GNN variants and one graph transformer variant. Have you considered other graph transformer architectures as well?\n\n\nI understand that conducting extensive additional experiments during the rebuttal period is impractical; therefore, the authors could instead clarify their claims through illustrative examples or simple pilot experiments.\n\nOverall, the problem this paper address is critical. However, the limited experimental validation raises concerns."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2acCAmZEa1", "forum": "6wNx3KpS3d", "replyto": "6wNx3KpS3d", "signatures": ["ICLR.cc/2026/Conference/Submission14567/Reviewer_Dzgb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14567/Reviewer_Dzgb"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14567/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910185540, "cdate": 1761910185540, "tmdate": 1762924957342, "mdate": 1762924957342, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a systematic investigation of scaling laws in graph self-supervised pre-training, with a particular focus on the challenges posed by distribution shifts. The authors construct a synthetic benchmark based on the Contextual Stochastic Block Model (CSBM), which enables precise and independent control over both structural and feature-level distribution changes between pre-training and evaluation graphs. Through extensive experiments, the paper uncovers a striking asymmetry: while increasing model capacity consistently improves transferability under distribution shift, merely increasing the amount of pre-training data can degrade performance, especially when the source and target graph distributions differ. The authors further demonstrate that expressive architectures—particularly deep and wide Graph Transformer models—can overcome this negative scaling effect and benefit from larger datasets. On the theoretical side, the paper develops a unified framework grounded in Fisher separability and Wasserstein domain divergence, providing a principled explanation of how distribution shifts affect representation transferability and why higher model capacity is crucial for positive data scaling."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper pioneers the study of scaling laws under distribution shifts in graph self-supervised learning — a gap in the current literature where most scaling analyses focus on NLP and vision.\n2.The paper's use of CSBM for synthetic data generation is a major advantage. It provides the authors with fine-grained control to isolate feature-level and structural distribution shifts, which is crucial for a clean causal analysis. This makes the findings substantially more reliable than those derived from observations on a handful of real-world graphs.\n3.The paper demonstrates an asymmetry between model size and data size — making the model larger steadily improves performance, but when a distribution shift occurs, adding more data can actually hurt. This finding challenges the common belief that “more data always leads to better results.”"}, "weaknesses": {"value": "1.The authors have developed a strong and formal theoretical analysis to support their claims. A potential area for improvement could be in bridging the formal mathematics with more accessible, intuitive commentary. For instance, walking the reader through the intuition behind why certain assumptions are made, or what a particular theorem implies in practice, could make this dense but valuable section more digestible for a wider audience.\n2.The paper strongly advocates for the Graph Transformer as the key architecture for solving data scaling challenges. However, it completely overlooks the high computational and memory complexity of these models relative to traditional GNNs, thereby ignoring the critical trade-off between performance and efficiency.\n3.The conclusion that Graph Transformers outperform GCNs under distribution shift is not particularly surprising, given that their powerful global attention mechanism is inherently better suited for complex scenarios. While the paper's contribution lies in connecting this to data scaling, it fails to clearly distinguish its novel perspective from the common understanding that Transformers are simply more powerful models."}, "questions": {"value": "1.The real-world experiments in Section 3.5 simulate data scaling by using fractions of a single source graph. This tests scaling within one distribution, whereas Graph Foundation Models (GFMs) are typically pre-trained on multiple, heterogeneous domains. How do the paper's findings on data scaling generalize to this more realistic multi-domain GFM setting, where adding new domains introduces more diverse distribution shifts?\n2.Your striking finding about negative data scaling is primarily demonstrated on a synthetic CSBM benchmark. Is it possible that this phenomenon is an artifact of the specific data generation process, where all source graphs are drawn from the same distribution? Have you observed similar strong negative trends on a more diverse collection of real-world pre-training datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MfPCUjZyBk", "forum": "6wNx3KpS3d", "replyto": "6wNx3KpS3d", "signatures": ["ICLR.cc/2026/Conference/Submission14567/Reviewer_wJjp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14567/Reviewer_wJjp"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14567/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910989819, "cdate": 1761910989819, "tmdate": 1762924956848, "mdate": 1762924956848, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work systematically explores scaling laws in graph self-supervised pre-training under distribution shifts, addressing the ambiguity of their applicability in graph-based pretrained models. It constructs synthetic benchmarks (via CSBM) to control structural and feature-level shifts, and conducts experiments on GNNs (e.g., GCN) and graph transformers. Key findings include: increasing model capacity consistently boosts performance, while data scaling often degrades it, though deep/wide or transformer-based architectures enable favorable data scaling. A theoretical framework based on Fisher separability and Wasserstein domain divergence explains these phenomena."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Provides systematic analysis of graph pre-training scaling laws under distribution shifts.\n2. Combines empirical results with theoretical insights, offering both practical guidance and principled explanations.\n3. Uses controllable synthetic benchmarks to disentangle structural and feature shifts."}, "weaknesses": {"value": "1. In line 66, the authors mention \"whether the absence of scaling is due to intrinsic limitations of graph models or the insufficiency of available data\". In fact, there is also a lack of data. The experiments using data generated by CSBM proposed in the paper seem difficult to reflect the limitations of graph models in real-world scenarios. Although I notice the use of real datasets (USA, Europe, Brazil), these datasets are very small in scale, and the paper lacks cases with large-scale data.\n2. Could the authors explore the impact of different pretraining tasks on transfer performance? Besides model architecture and parameters, the choice of graph pretraining tasks may also have a significant impact. However, the paper only seems to adopt the GraphMAE task. This could help us investigate which tasks are suitable for studying scaling laws.\n3. Is the selection of structural shifts (Shift 3–5) rather simplistic? They seem to only reflect differences in data augmentation. Could CSBM be used to control the degree of structural shifts? In line 153, Shift 1 and Shift 2 appear to be indistinguishable, as both reduce inter-class separation. What is the significance of setting these two separate shifts?\n4. The paper focuses primarily on node classification, which limits insights into other graph tasks (e.g., link prediction, graph classification)."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "esXQZ6H1pl", "forum": "6wNx3KpS3d", "replyto": "6wNx3KpS3d", "signatures": ["ICLR.cc/2026/Conference/Submission14567/Reviewer_fheK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14567/Reviewer_fheK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission14567/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761990174590, "cdate": 1761990174590, "tmdate": 1762924956379, "mdate": 1762924956379, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the scaling behavior of graph self-supervised pre-training under distribution shifts. The authors design controlled synthetic benchmarks using contextual stochastic block models and examine how model capacity and data scale influence transferability. They find that while increasing model capacity consistently improves performance, enlarging the pre-training dataset can hurt accuracy under distribution shifts. Through experiments on GCN, GraphSAGE, GAT, and graph transformers, the study shows that transformers exhibit more stable and positive scaling effects. The authors further propose a theoretical framework based on Fisher separability and Wasserstein divergence to explain why model capacity helps while data scaling can fail."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper addresses an important and timely problem which is understanding scaling laws for graph foundation models, especially under distribution shifts that are inherent to real-world graph data. The motivation is clear, the methodology is well-structured, and the experiments are described clearly. The proposed synthetic benchmark provides controlled conditions for studying the phenomenon, and empirical results show clear improvements of graph transformers over GCN-based baselines."}, "weaknesses": {"value": "The paper a little lacks novelty to me. In detail, the experimental setup mainly repackages known components such as CSBM data, GraphMAE pretraining. The related work section is incomplete and does not sufficiently compare to concurrent studies on graph scaling or graph foundation models, graph learning under distribution shifts. The empirical evaluation includes only limited baselines, and important state-of-the-art SSL methods and graph distribution shifts methods are not fully considered. The theoretical part is more descriptive, and the connection between the derived inequalities and observed empirical trends is not convincingly supported."}, "questions": {"value": "Can the authors clarify how the proposed theoretical framework improves over existing analyses of domain shift in GNNs? Also, since the synthetic benchmarks are highly controlled, how confident can we be that the same scaling behavior generalizes to complex real-world graph distributions beyond the small domain adaptation examples presented?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "KftQ4QuDQj", "forum": "6wNx3KpS3d", "replyto": "6wNx3KpS3d", "signatures": ["ICLR.cc/2026/Conference/Submission14567/Reviewer_v8ML"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14567/Reviewer_v8ML"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission14567/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762013005751, "cdate": 1762013005751, "tmdate": 1762924955625, "mdate": 1762924955625, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work presents the systematic study of scaling laws in graph self-supervised pretraining under distribution shifts. The key finding is that increasing model capacity consistently enhances transferability, whereas the benefits of data scaling depend on model expressiveness and architecture."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The investigation on scaling law for graph pre-training is interesting.\n2. The experimental setting is well designed.\n3. The results are interesting and well justified."}, "weaknesses": {"value": "1. The evaluation is limited to only four graph self-supervised learning (SSL) methods, all of which are not the most recent, ranging from 2016 to 2022. This makes the study less representative of the current state of graph SSL. Additionally, evaluating only four methods is insufficient to draw strong conclusions. To strengthen their claims, the authors are expected to include more recent and diverse graph SSL methods in the evaluation. Authors may consider incorporating some of the following works [1-7] for comprehensive evaluation.\n\n[1] Bo, Deyu, et al. \"Graph contrastive learning with stable and scalable spectral encoding.\" Advances in Neural Information Processing Systems 36 (2023): 45516-45532.\n\n[2] Hou, Zhenyu, et al. \"Graphmae2: A decoding-enhanced masked self-supervised graph learner.\" Proceedings of the ACM web conference 2023. 2023.\n\n[3] Li, Wen-Zhi, et al. \"Homogcl: Rethinking homophily in graph contrastive learning.\" Proceedings of the 29th ACM SIGKDD conference on knowledge discovery and data mining. 2023.\n\n[4] In, Yeonjun, Kanghoon Yoon, and Chanyoung Park. \"Similarity preserving adversarial graph contrastive learning.\" Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2023.\n\n[5] Xiao, Teng, et al. \"Simple and asymmetric graph contrastive learning without augmentations.\" Advances in neural information processing systems 36 (2023): 16129-16152.\n\n[6] Wan, Guancheng, et al. \"S3GCL: Spectral, swift, spatial graph contrastive learning.\" Forty-first International Conference on Machine Learning. 2024.\n\n[7] Ji, Cheng, et al. \"Regcl: Rethinking message passing in graph contrastive learning.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 8. 2024."}, "questions": {"value": "1. in the feature construction, can authors provide more details on how to obtain the soft labels?\n\n2. Regarding feature perturbation, do the authors apply normalization to the node features before feeding them into the GNN during both the pre-training and linear probing stages?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "qRt8kITtgt", "forum": "6wNx3KpS3d", "replyto": "6wNx3KpS3d", "signatures": ["ICLR.cc/2026/Conference/Submission14567/Reviewer_c78t"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14567/Reviewer_c78t"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission14567/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762157282477, "cdate": 1762157282477, "tmdate": 1762924954340, "mdate": 1762924954340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}