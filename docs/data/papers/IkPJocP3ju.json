{"id": "IkPJocP3ju", "number": 12713, "cdate": 1758209655682, "mdate": 1759897492029, "content": {"title": "Breaking the Total Variance Barrier: Sharp Sample Complexity for Linear Heteroscedastic Bandits with Fixed Action Set", "abstract": "Recent years have witnessed increasing interests in tackling heteroscedastic noise in bandits and reinforcement learning \\citep{zhou2021nearly, zhao2023variance, jia2024does, pacchiano2025second}. In these works, the cumulative variance of the noise $\\Lambda = \\sum_{t=1}^T \\sigma_t^2$, where $\\sigma_t^2$ is the variance of the noise at round $t$, has been used to characterize the statistical complexity of the problem, yielding simple regret bounds of order $\\tilde{\\mathcal O}(d \\sqrt{\\Lambda / T^2})$ for linear bandits with heteroscedastic noise \\citep{zhou2021nearly, zhao2023variance}. \nHowever, with a closer look, $\\Lambda$ remains the same order even if the noise is close to zero at half of the rounds, which indicates that the $\\Lambda$-dependence is not optimal.\n\nIn this paper, we revisit the linear bandit problem with heteroscedastic noise. We consider the setting where the action set is fixed throughout the learning process. We propose a novel variance-adaptive algorithm VAEE (Variance-Aware Exploration with Elimination) for large action set, which actively explores actions that maximizes the information gain among a candidate set of actions that are not eliminated. With the active-exploration strategy, we show that VAEE achieves a *simple regret* with a nearly *harmonic-mean* dependent rate, i.e. $\\tilde{\\mathcal O}\\Big(d\\Big[\\sum_{t = 1}^T \\frac{1}{\\sigma_t^2} - \\sum_{i = 1}^{\\tilde{O}(d)} \\frac{1}{[\\sigma^{(i)}]^2} \\Big]^{-\\frac{1}{2}}\\Big)$ where $d$ is the dimension of the feature space and $\\sigma^{(i)}$ is the $i$-th smallest variance among $\\\\{\\sigma_t\\\\}_{t=1}^T$. For finitely many actions, we propose a variance-aware variant of G-optimal design based exploration, which achieves a \n$\\tilde {\\mathcal O}$ $\\bigg(\\sqrt{d \\log |\\mathcal A| }\\Big[ \\sum\\_{t = 1}\\^T \\frac{1}{\\sigma\\_t\\^2}- \\sum\\_{i = 1}^{\\tilde{O}(d)} \\frac{1}{[\\sigma^{(i)}]^2} \\Big]^{-\\frac{1}{2}}\\bigg)$  simple regret bound. We also establish a nearly matching lower bound for the fixed action set setting indicating that \\emph{harmonic-mean} dependent rate is unavoidable. To the best of our knowledge, this is the first work that breaks the $\\sqrt{\\Lambda}$ barrier for linear bandits with heteroscedastic noise.", "tldr": "", "keywords": ["linear bandits", "heteroscedastic noise", "simple regret"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2d557236c4316c3348868e39dd06496781021511.pdf", "supplementary_material": "/attachment/a1e436167d094c3f57b03f0b250905733a89ccb1.pdf"}, "replies": [{"content": {"summary": {"value": "The paper studies linear bandits with heteroscedastic noise under a fixed action set, aiming to improve simple regret beyond the classical dependence on the cumulative noise variance $\\Lambda$ (“total variance”). It proposes two variance-adaptive algorithms:\n\n* VAEE (Variance-Aware Exploration with Elimination) for large/continuous action sets, which selects actions by maximizing information gain while progressively eliminating arms.\n* VAGD (Variance-Adaptive G-Optimal Design) for finite action sets, combining approximate G-optimal design with variance-adaptive sampling.\n\nBoth algorithms yield harmonic-mean–type simple-regret bounds of the form \n*  $\\tilde{O}\\left(d \\Big[\\sum_t 1/\\sigma_t^2 - \\sum_{i=1}^{\\tilde O(d)} 1/\\sigma_{(i)}^2\\Big]^{-1/2}\\right)$  for VAEE and \n\n* $\\tilde{O}\\left(\\sqrt{d\\log |{\\mathcal A}|}  \\Big[\\sum_t 1/\\sigma_t^2 - \\sum_{i=1}^{\\tilde O(d)} 1/\\sigma_{(i)}^2\\Big]^{-1/2}\\right)$ for VAGD,\n \nwhich the authors position as breaking the classic $\\sqrt{\\Lambda}$ barrier in simple regret. A matching instance-dependent lower bound (Theorem 6.1) shows a $\\Omega \\big(d (\\sum_t 1/\\sigma_t^2)^{-1/2}\\big)$ dependence."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. **Clear statement of contributions and rates (with concrete formulas)**. \nThe abstract precisely states the harmonic-mean–dependent rates (including the subtracting of the  $\\tilde O(d)$ smallest variances) for both VAEE and VAGD, and emphasizes that this breaks the $\\sqrt{\\Lambda}$ barrier in simple regret.\n\n2. **Well-motivated setting and assumptions.** \nThe fixed action set requirement is explicitly justified: when contexts change adversarially, $\\sqrt{\\Lambda}$ remains unavoidable.\n\n3. **Accessible algorithmic presentation.** Algorithm 1 (VAEE) and Algorithm 2 (VAGD) are spelled out line-by-line, including the elimination step for VAEE (Line 8) and the variance-weighted design logic for VAGD (Lines 1–8 and estimator definition).\n\n4. **Thoughtful comparisons and intuition.** The case study in Section 4.1 contrasts VAEE with Weighted OFUL under a low-variance window and shows how VAEE reallocates exploration to weak coordinates; the discussion quantifies the differing simple-regret decay. Table 2 further compares simple and cumulative regrets across noise profiles.\n\n5. **Lower bound with standard, transparent techniques.** Theorem 6.1’s proof uses Le Cam’s method and Pinsker’s inequality, clearly documented in Appendix C. This makes the paper more complete."}, "weaknesses": {"value": "1. **Lack of clear separation between settings.**\n   The paper studies both infinite and fixed action sets, but Table 1 does not indicate which results correspond to each case. A new column or clearer labeling would make the distinction explicit.\n\n2. **Unsubstantiated claim of “breaking the $\\sqrt{\\Lambda}$ barrier.”**\n   The main text claims improvement over the $\\sqrt{\\Lambda}$ bound but does not point to the derivation showing this. Equation (4.2) and Appendix B contain the critical argument and should be cited when stating the main contributions.\n\n3. **Unclear source of improvement in Algorithms 1–2.**\n   It remains ambiguous whether the tighter regret stems from (a) the elimination step, (b) a sharper analysis, or (c) the fixed-action assumption. A short discussion quantifying computational or analytical contributions would improve transparency.\n\n4. **Missing or delayed notation definitions.**\n   Several symbols appear before definition. For example, \n     - the global window $W$ (in line **278**), \n     - the terms $\\mathrm{UCB}_x(t)$, $\\mathrm{UCB}_0(t)$, $\\mathrm{UCB}_1(t)$ (in lines **284–286**), and \n     - $\\mathcal{P}(\\mathcal{A}*{\\ell})$ (in line 400). \n\n   Early or inline definitions would improve readability.\n\n5. **Lack of Empirical Illustration**\n\n    Despite the clear theoretical development and the well-specified variance settings in Table 2 (e.g., fast-decay, spiky variance profiles), the paper provides no empirical or synthetic validation.\n    Since the variance is explicitly given, a simple simulation would be straightforward and would help demonstrate the practical relevance of the proposed regret bounds and constants.\n    The absence of such experiments weakens the overall empirical support for the claimed improvements."}, "questions": {"value": "1. **Isolation of the Key Driver**\n\n   For VAEE, what component is primarily responsible for achieving the harmonic-mean regret rate — (i) the elimination step (Algorithm 1, Line 8), (ii) the variance-weighted estimator and confidence sets, or (iii) the fixed-action structure noted in Remark 3.1?\n   A brief ablation-style analysis or a theoretical “swap-in/swap-out” comparison would help clarify the main driver of improvement.\n\n2. **Complexity–Regret Trade-offs**\n\n   What are the computational complexities of VAEE (both per round and overall, including elimination checks) and VAGD (computing or approximating the design with $|\\mathrm{supp}(\\pi)| \\le 4d\\log\\log d + 16$)?\n   Some discussion on the scalability or possible computational bottlenecks would strengthen the practical perspective.\n\n3. **Unknown or Misspecified $\\sigma_t$**\n\n   Assumption 3.2 assumes conditionally $\\sigma_t$-sub-Gaussian noise with known bounds $(\\sigma_{\\min}, \\sigma_{\\max})$.\n   How robust are the results if $\\sigma_t$ is unknown or mis-specified? Additionally, can the heavy-tailed extension mentioned in the remarks achieve the same harmonic-mean dependence? A short discussion in the main text would help.\n\n4. **Non-Spanning Action Sets**\n\n   Theorem 5.2 assumes that $\\mathcal{A}$ spans $\\mathbb{R}^d$. What if this condition does not hold? Could the authors formalize the subspace reduction and restate Theorem 5.3 with $d'$ denoting the rank of $\\mathcal{A}$? In other words, if $\\mathcal{A}$ lies within a lower-dimensional linear subspace of dimension $d'$, can the existing bounds be adapted by replacing $d$ with $d'$?\n   Clarifying this case would enhance the completeness and generality of the theoretical results."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2t9oFL05cL", "forum": "IkPJocP3ju", "replyto": "IkPJocP3ju", "signatures": ["ICLR.cc/2026/Conference/Submission12713/Reviewer_btFg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12713/Reviewer_btFg"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12713/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761507014239, "cdate": 1761507014239, "tmdate": 1762923540234, "mdate": 1762923540234, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of heteroscedastic stochastic linear bandits, i.e. where the variance proxy of the subgaussian noise at each round is time-variant (but known). Prior work on this problem has given regret upper and lower bounds that scale with the arithmetic mean of the variance proxies. This work instead designs algorithms with regret that depends on the harmonic mean of the variance proxies. They give a lower bound with the same rate (ignoring log factors). They give an algorithm with $d$ dimension dependence for possibly-infinite action sets, and $\\sqrt{d \\log(|\\mathcal{A}|)}$ dependence for finite action sets. Their algorithms are phased elimination-based."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. To my knowledge, the paper fills an important gap in the literature in studying algorithms with regret that depends on the harmonic mean of the variance proxies (rather than just arithmetic mean). This then motivates a novel algorithm design to address this new setting.\n2. I found the paper to be very thorough in its results and the discussion about these results. These discussion made it very clear how their results relate to prior work. For example, it includes the following along with its main results:\n   - Motivation for the use of simple regret (Remark 3.4)\n   - Justification for use of elimination algorithms rather than optimistic algorithms (Section 4.1)\n   - Comparison with prior work in specific instances (Table 2)\n\nTo comment on each of the dimensions:\n- originality: new idea of studying harmonic mean, and new algorithm\n- significance: filling clear gap in the literature\n- quality: thorough results (although I didn't check all of the proofs)\n- clarity: clear presentation overall (other than points discussed in Questions box)"}, "weaknesses": {"value": "1. A weakness is that the regret bounds have an added dependence on the dimension, meaning that the bound is slightly weaker than the exact harmonic mean (at least when $d$ is similar in scale to $T$ ). The justification for this (Remark 4.3) was somewhat unclear to me. See Questions (1).\n2. A possible weakness is that the results do not extend to the contextual setting, although they provided strong justification (in my opinion) for studying the non-contextual setting. In particular, their comments suggest (in Remark 3.1) that the arithmetic mean-dependence is tight for the contextual setting, while the harmonic mean-dependence is tight for the non-contextual setting."}, "questions": {"value": "1. Could you provide a more concrete description of the argument in Remark 4.3 as to why there is there the additional term in the regret bound? (Ideally, this would be in the form of a lower bound, but I understand that that it might be too much to ask at this point.)\n2. In Table 2, the comparisons are under the assumption that the $\\sum_{t=1}^T 1/\\sigma^2 \\gg \\sum_{i=1}^{\\tilde{O}(d)} 1/[\\sigma^(i)]^2$ as discussed in Section 4.2. Does this hold for all of the scenarios considered in Table 2? At a glance, it seemed to, but I think its important to verify.\n3. In line 369, the paper says \"Therefore, our regret bound is always sharper\". However, it seems that this is only under the assumption mentioned above. As such, I would suggest modifying the wording to acknowledge this.\n4. I found Section 4.1 somewhat hard to follow. Some suggestions to improve this are to explicitly state what the action set is in the example, and to be explicit about what the simplifying assumptions are, e.g. what exactly does \"$UCB \\approx$\" mean?\n5. In lines 469-471, it seems that when discussing the lower bounds in Table 1, the authors are referring to the lower bounds in prior work (and not their lower bound). However, it is not said so explicitly, making it somewhat confusing."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RW5ojujrBX", "forum": "IkPJocP3ju", "replyto": "IkPJocP3ju", "signatures": ["ICLR.cc/2026/Conference/Submission12713/Reviewer_KTha"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12713/Reviewer_KTha"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12713/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761773419572, "cdate": 1761773419572, "tmdate": 1762923539994, "mdate": 1762923539994, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studied linear bandits with heteroscedastic noise, i.e. the variance of the noise can change from round to round.\n1. For both infinite-armed and finite-armed case, this paper proved a variance-aware regret bound, and provided an algorithm that achieved the bound.\n2. The paper showed that for the infinite-armed case, the regret bound was tight up to log factors.\n3. This paper provided a novel version of elliptical potential lemma for the heteroscedastic noise case in linear bandits.\n3. This paper provided some novel lower bound proof techniques for heteroscedastic linear bandits."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper provides the first near-optimal regret bound for variance-aware linear bandits.\n2. This paper provides new insight that the confidence ellipsoid in heteroscedastic linear bandits should scale with the harmonic mean of the noise variances."}, "weaknesses": {"value": "1. The author didn't show a matching lower bound for the finite-armed case.\n2. For the upper bound, the main technical contribution of this paper seems to be limited to page 16, where the authors extended the ellipsoid potential lemma to the weighted case.\n3. For the lower bound, the construction of the adversarial instances seemed also to be classical."}, "questions": {"value": "1. Can the authors confirm if $\\tilde O$ also omits $\\log \\log |\\mathcal A |$ factors or not?\n2. Can we show a matching lower bound for the finite-aremd case, e.g., by following the lower bound proof in https://arxiv.org/pdf/1904.00242?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mZIfpB9JX9", "forum": "IkPJocP3ju", "replyto": "IkPJocP3ju", "signatures": ["ICLR.cc/2026/Conference/Submission12713/Reviewer_frPW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12713/Reviewer_frPW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12713/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762186081962, "cdate": 1762186081962, "tmdate": 1762923539433, "mdate": 1762923539433, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}