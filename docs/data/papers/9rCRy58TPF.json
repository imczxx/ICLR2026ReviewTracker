{"id": "9rCRy58TPF", "number": 3103, "cdate": 1757334603487, "mdate": 1759898109141, "content": {"title": "SPICE: Submodular Penalized Information–Conflict Selection for Efficient Large Language Model Training", "abstract": "Information-based data selection for instruction tuning is compelling: maximizing the log-determinant of the Fisher information yields a monotone submodular objective, enabling greedy algorithms to achieve a $(1-1/e)$ approximation under a cardinality budget. In practice, however, we identify alleviating gradient conflicts, misalignment between per-sample gradients, is a key factor that slows down the decay of marginal log-determinant information gains, thereby preventing significant loss of information. We formalize this via an $\\varepsilon$-decomposition that quantifies the deviation from ideal submodularity as a function of conflict statistics, yielding data-dependent approximation factors that tighten as conflicts diminish. Guided by this analysis, we propose SPICE, a conflict-aware selector that maximizes information while penalizing misalignment, and that supports early stopping and proxy models for efficiency. Empirically, SPICE selects subsets with higher log-determinant information than original criteria, and these informational gains translate into performance improvements: across 8 benchmarks with LLaMA2-7B and Qwen2-7B, SPICE uses only 10% of the data, yet matches or exceeds 6 methods including full-data tuning. This achieves performance improvements with substantially lower training cost.\nCode is available at https://anonymous.4open.science/r/SPICE-6DF7/README.md.", "tldr": "We prove gradient conflicts accelerate marginal log-det FIM decay through ε-analysis , and introduce SPICE—an adaptive conflict-penalized greedy selector that matches full-data results with 10% data.", "keywords": ["Data selection; Submodular; Log-determinant Fisher information; Instruction tuning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4caad4d436a7782115258c82d9d5b6f6b48668e5.pdf", "supplementary_material": "/attachment/4c3a28ecb7503b35d6855f9dbdf1576a453c6309.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the problem of selecting a small subset of instruction-tuning data for large language models in order to fine-tune efficiently. The authors observe that while maximizing the log-determinant of the empirical Fisher information matrix yields a submodular objective, in practice marginal gains collapse quickly due to gradient misalignment among samples. They formalize this by decomposing the marginal information gain into a base term and an interaction term, and conclude that controlling gradient conflict is key to sustaining information gain. Based on this, they propose SPICE: a selection algorithm that (1) uses a scoring function that subtracts a conflict penalty from the marginal information gain, (2) optionally stops early once the marginal gain falls below a threshold, and (3) uses a proxy (smaller) model to compute the gradients efficiently. They empirically show that on multiple benchmarks, using only ~10% of data, SPICE matches or exceeds full-data fine-tuning and outperforms several baselines, while reducing computation cost."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The method addresses both effectiveness (maintaining or improving performance with fewer training samples) and efficiency (using proxy model selection & early stopping) — a nice combination.\n\nEmpirical results are broad (multiple benchmarks, models, tasks) and show impressive savings (≈10% data) with no performance loss and even gains in some cases.\n\nThe algorithm is extensible: the idea of “penalize conflict” could be applied in other data-selection or multi-task contexts."}, "weaknesses": {"value": "The current scope of experiments is limited to ~7 B-parameter models and instruction-tuning; extension to larger models (>30 B), multimodal tasks, or RLHF settings remains to be seen.\n\nThe proxy-to-target model transfer is shown only within same architecture family; cross-architecture transfer (e.g., completely different model family) may degrade and is less explored.\n\nThe cost comparison, while present, could be strengthened with more granular breakdowns (selection cost vs fine-tune cost) across all baselines under identical hardware settings.\n\nThe penalty on “conflict” implicitly biases toward samples aligned with current gradient direction—there is a risk that samples with contradictory but important signals might be under-selected; more analysis of diversity vs conflict trade-offs would help."}, "questions": {"value": "How sensitive is SPICE to the choice of proxy model? If the proxy model differs in architecture or domain from the fine-tune target, how does performance vary?\n\nIn domains with heterogeneous instruction types (e.g., chat, coding, planning) where gradient directions may naturally differ, how does the conflict penalty trade off between “reducing harm” vs “reducing diversity”? Have you analysed domain-coverage of the selected subset?\n\nCould you provide more detailed hardware/GPU-hour breakdowns (selection + fine-tune) for each baseline method (e.g., LESS, SelectIT, FisherSFT) under identical hardware, to strengthen the cost-efficiency claim?\n\nHave you tested SPICE on larger models (>30 B) or other modalities (vision+language) or RLHF settings? If not yet, what do you foresee as the main challenge in scaling?"}, "flag_for_ethics_review": {"value": ["No ethics review needed.", "Yes, Discrimination / bias / fairness concerns"]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gOB8Vf7voN", "forum": "9rCRy58TPF", "replyto": "9rCRy58TPF", "signatures": ["ICLR.cc/2026/Conference/Submission3103/Reviewer_KYWw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3103/Reviewer_KYWw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3103/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761473438919, "cdate": 1761473438919, "tmdate": 1762916551208, "mdate": 1762916551208, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a submodular framework for data-efficient language model fine-tuning, introducing a conflict-aware selection mechanism that balances information gain and gradient disagreement. The method improves greedy subset selection efficiency and achieves competitive results."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel insight into the fast decay of marginal contribution to enhance greedy submodular optimization.\n2. Comprehensive experiments and ablations supporting the method’s effectiveness.\n3. Decent performance on various benchmarks."}, "weaknesses": {"value": "1. High computational cost due to gradient retrieval for each selection step.\n2. Possible misalignment between the theoretical motivation and empirical design; the overall selection pipeline remains somewhat unclear (see questions).\n3. Limited baseline comparisons (see questions)."}, "questions": {"value": "1. *Theorem 1 (rows 167–169):* Why do large perturbations lead to faster decay? Shouldn’t it be the difference between successive perturbations, not the absolute magnitude of a perturbation, that drives faster decay?\n2. *Definition 4:* Corollary 1 penalizes both similar and opposite gradients via squared inner products, while Definition 4 only penalizes opposite ones. Why are similar gradients (redundancy) ignored, given that the theory penalizes both?\n3. *Pipeline clarity:*\n    - Section 4.3 (row 346): When stating “at each iteration, we select one sample using our conflict-aware greedy algorithm,” does ‘one sample’ refer to a single example or a mini-batch of k samples? If it refers to a single example, does the model get updated after each selection (get updated after seeing a new example) when T=1?\n    - Section 5 (row 372): How is the 120-sample candidate pool formed? Is it randomly drawn from D with size k×T?\n    - Is the proxy model updated after each cycle?\n4. *Baselines and related work:*\n    - If the proxy model is periodically updated and selection occurs within a randomly sampled “candidate pool”, the setup seems closer to online batch selection, making comparisons to FisherSFT, LESS, or IFD, a non-periodic selection mechanism, potentially unfair. It remains unclear whether SPICE’s performance gains stem from the periodic schedule or the proposed selection mechanism.\n    - Representation-based selection methods [1] and other recent instruction-tuning data selection works [2-4] are not discussed.\n5. *Complexity analysis:* Could the authors provide an explicit asymptotic analysis of time complexity? Algorithm 1 appears to require gradient computation over the entire dataset D for each selection, which seems computationally expensive.\n\n[1] Ivison, H., Zhang, M., Brahman, F., Koh, P. W., & Dasigi, P. (2025). *Large-Scale Data Selection for Instruction Tuning*. arXiv preprint arXiv:2503.01807.\n\n[2] Liu, Z., Karbasi, A., & Rekatsinas, T. (2024). *TSDS: Data Selection for Task-Specific Model Finetuning*. In *The Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS 2024)*.\n\n[3] Wang, J., Lin, X., Qiao, R., Koh, P. W., Foo, C.-S., & Low, B. K. H. (2025). *NICE Data Selection for Instruction Tuning in LLMs with Non-differentiable Evaluation Metric*. In *Forty-second International Conference on Machine Learning (ICML 2025)*.\n\n[4] Chen, Y., Li, Y., Hu, K., Ma, Z., Ye, H., & Chen, K. (2025). *MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space*. In *Findings of the Association for Computational Linguistics: ACL 2025*."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "epudZa9BN2", "forum": "9rCRy58TPF", "replyto": "9rCRy58TPF", "signatures": ["ICLR.cc/2026/Conference/Submission3103/Reviewer_Xhgm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3103/Reviewer_Xhgm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3103/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761827441144, "cdate": 1761827441144, "tmdate": 1762916551024, "mdate": 1762916551024, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies selecting instruction-tuning datasets by proposing to avoid gradient conflicts. The authors develop an epsilon-decomposition that splits the Fisher gain into a baseline and a perturbation term and showed that the perturbation is upper bounded by squared gradient inner products. The authors proposed SPICE, a greedy data selection algorithm that scores a candidate example by the marginal gain as well as a gradient penalty term. Empirically, the authors demonstrated that at 10% data matches or outperforms full-data SFT and several baselines while reducing selection/training cost."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- This paper is very well written - clear and flows well from theory to an a practical algorithm inspired by the theory. The experiments seemed pretty complete as well.\n- The proposed SPICE selection algorithm is simple and intuitive as well\n- The experiments compared several baselines on multiple benchmarks. The gain is pretty consistent."}, "weaknesses": {"value": "- It would be interesting if the authors can demonstrate whether the finding can be extended to larger corpus / base LMs as behaviour might change as we scale up the model size.\n- It would be nice if the authors could provide us with qualitative examples to better understand what constitute examples that has low/high gradient conflict. Is there some intuition as to what they might imply to the data."}, "questions": {"value": "n/a"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "zA2leRccyl", "forum": "9rCRy58TPF", "replyto": "9rCRy58TPF", "signatures": ["ICLR.cc/2026/Conference/Submission3103/Reviewer_rHBr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3103/Reviewer_rHBr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3103/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876686497, "cdate": 1761876686497, "tmdate": 1762916550844, "mdate": 1762916550844, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SPICE, a conflict-aware data selection method for instruction tuning. It starts from the submodular log-det(Fisher) objective, shows that marginal information gains decay faster when gradient conflicts are high, and formalizes this using an ε-decomposition → curvature analysis. SPICE scores each sample by (Fisher marginal) − λ·conflict (conflict = negative cosine to the running mean gradient), supports early stopping, and allows proxy models for efficiency. On LLaMA2-7B and Qwen2-7B, using ~10% of data, SPICE matches or exceeds full-data and several selectors (LESS, Fisher, SelectIT, IFD) across 8 benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Clear theory–practice link: ε-decomposition → curvature explains greedy degradation under gradient conflicts.\n\nSimple, practical selector: Fisher-marginal − λ·conflict with early stopping and proxy models; easy to drop into pipelines.\n\nSolid empirical sweep: two bases (Qwen2-7B, LLaMA2-7B), 8 benchmarks, cost/ablation studies; strong gains on IFEval/MMLU at ~10% data."}, "weaknesses": {"value": "Assumption fragility: bounds rely on α‖F‖<1 and AdaFisher approximations; reported violation rates in higher-conflict regimes weaken guarantees.\n\nLimited baselines: several strong recent selectors and tiny-data LoRA baselines are missing; Random is competitive in places.\n\nConflict proxy is heuristic (−cosine to mean gradient); sensitivity to optimizer/state/batch is underexplored, and cross-architecture transfer is weak."}, "questions": {"value": "Benchmark coverage. Please add stronger baselines, e.g., the method in arXiv:2402.02318 and a LoRA-only tiny-data baseline (e.g., 0.5–2% data) to show SPICE’s advantage at very small budgets.\n\nTiny-data behavior. How does SPICE compare to straightforward LoRA with small training sets across tasks? Any regime where plain LoRA beats SPICE-selected 5–10%?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bhmDs0CUVF", "forum": "9rCRy58TPF", "replyto": "9rCRy58TPF", "signatures": ["ICLR.cc/2026/Conference/Submission3103/Reviewer_Y2FZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3103/Reviewer_Y2FZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3103/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762048443386, "cdate": 1762048443386, "tmdate": 1762916550612, "mdate": 1762916550612, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes SPICE, a conflict-aware data selection method for instruction tuning. It starts from the submodular log-det(Fisher) objective, shows that marginal information gains decay faster when gradient conflicts are high, and formalizes this using an ε-decomposition → curvature analysis. SPICE scores each sample by (Fisher marginal) − λ·conflict (conflict = negative cosine to the running mean gradient), supports early stopping, and allows proxy models for efficiency. On LLaMA2-7B and Qwen2-7B, using ~10% of data, SPICE matches or exceeds full-data and several selectors (LESS, Fisher, SelectIT, IFD) across 8 benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Clear theory–practice link: ε-decomposition → curvature explains greedy degradation under gradient conflicts.\n\nSimple, practical selector: Fisher-marginal − λ·conflict with early stopping and proxy models; easy to drop into pipelines.\n\nSolid empirical sweep: two bases (Qwen2-7B, LLaMA2-7B), 8 benchmarks, cost/ablation studies; strong gains on IFEval/MMLU at ~10% data."}, "weaknesses": {"value": "Assumption fragility: bounds rely on α‖F‖<1 and AdaFisher approximations; reported violation rates in higher-conflict regimes weaken guarantees.\n\nLimited baselines: several strong recent selectors and tiny-data LoRA baselines are missing; Random is competitive in places.\n\nConflict proxy is heuristic (−cosine to mean gradient); sensitivity to optimizer/state/batch is underexplored, and cross-architecture transfer is weak."}, "questions": {"value": "Benchmark coverage. Please add stronger baselines, e.g., the method in arXiv:2402.02318 and a LoRA-only tiny-data baseline (e.g., 0.5–2% data) to show SPICE’s advantage at very small budgets.\n\nTiny-data behavior. How does SPICE compare to straightforward LoRA with small training sets across tasks? Any regime where plain LoRA beats SPICE-selected 5–10%?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bhmDs0CUVF", "forum": "9rCRy58TPF", "replyto": "9rCRy58TPF", "signatures": ["ICLR.cc/2026/Conference/Submission3103/Reviewer_Y2FZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3103/Reviewer_Y2FZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3103/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762048443386, "cdate": 1762048443386, "tmdate": 1763662002756, "mdate": 1763662002756, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}