{"id": "V1i58pZmp3", "number": 16705, "cdate": 1758267856628, "mdate": 1759897223874, "content": {"title": "Optimal transport unlocks end-to-end learning for single-molecule localization", "abstract": "Single‑molecule localization microscopy (SMLM) surpasses the diffraction limit by detecting and localizing individual fluorophores - fluorescent molecules stained onto the observed specimen - over time to reconstruct super‑resolved images. Conventional SMLM requires non‑overlapping emitting fluorophores, leading to long acquisition times that hinders live‑cell imaging. Although recent deep‑learning approaches can handle denser emissions, they rely on non‑maximum suppression (NMS) layers, which are non‑differentiable and may discard true positives with their local fusion strategy.\nIn this presentation, we reformulate the SMLM training objective as a set‑matching problem, deriving an optimal‑transport loss that eliminates the need for NMS during inference and enables end‑to‑end training.\nAdditionally, we propose an iterative neural network that integrates knowledge of the microscope’s optical system inside our model.\nExperiments on synthetic benchmarks and real biological data show that both our new loss function and architecture surpass the state of the art at moderate and high emitter densities. Code and data are provided in the supplementary material.", "tldr": "We present an end-to-end learning model for single-molecule localization microscopy that combines an optimal transport loss function with an iterative neural network. It achieves state-of-the-art performance on synthetic benchmarks and real images.", "keywords": ["Single Molecule Localization Microscopy", "SMLM", "High-Density", "Learning", "Deep Learning", "Inverse Problems", "Iterative Refinement"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c1703205ac11938b83e63b558a989bb1568332c1.pdf", "supplementary_material": "/attachment/a3b9dfb75fadcf7e5568edb3346031b240cb3bd2.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel method for single-molecule localization microscopy (SMLM). The authors formulate the SMLM task as a set matching problem and employ the optimal transport cost as the loss function.\nFurthermore, the proposed method utilizes a refinement model that integrates embedded features extracted from the input image, the previous prediction step, and a reconstructed image generated through an image formation model. This design effectively incorporates prior knowledge derived from an approximate point spread function into the molecular localization process.\n\nExperimental results demonstrate that the proposed framework outperforms existing deep learning–based approaches quantitatively and qualitatively, particularly under high-density conditions."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly written and easy to follow, with a well-articulated background on single-molecule localization microscopy (SMLM). The formulation of SMLM as a set matching problem and the use of the optimal transport (OT) distance as a loss function are original and technically interesting. The refinement model is also a valuable contribution: it effectively integrates features from the input image, the previous prediction step, and a reconstructed image generated from the previous output, while maintaining a simple and lightweight network architecture.\nFurthermore, the ablation study demonstrates the effectiveness of both the loss formulation and the proposed modeling approach."}, "weaknesses": {"value": "While the use of the optimal transport (OT) distance for SMLM is original, its motivation is not clearly articulated. The paper refers to the proposed framework as “end-to-end learning,” but the meaning of this term is somewhat ambiguous in this context (see comments in Section 7-1 for further detail). In addition, the paper criticizes LiteLoc in the Introduction for using an NMS layer, but LiteLoc does not actually employ such a layer. As a result, it is unclear what specific limitation or issue of LiteLoc the proposed method aims to address.\n\nIn addition, the paper presents two seemingly independent contributions—a new loss function and a new network architecture—but the connection between them is not clearly established. The architecture does not appear to leverage the properties of the proposed loss, which weakens the methodological coherence of the work. The authors should better justify why both components are included in a single framework and discuss whether one could be used meaningfully without the other.\n\nFurthermore, the training process is insufficiently described. In particular, it remains unclear what the network (especially the decoder) outputs and what training data correspond to these outputs (see also the suggestion in Section 7-2). This lack of clarity makes it difficult to assess the effectiveness of using the OT distance as a loss function."}, "questions": {"value": "7-1. What is the intended meaning and benefit of “end-to-end learning” in this paper?\n\nIt is true that, in general, loss functions for set-matching problems are non-smooth, making it difficult to compute gradients through cost functions that depend on the network outputs, such as coordinates or confidence scores.\nHowever, although the authors describe SMLM as a set-matching problem, the estimation in this work appears to be performed in a pixel-wise manner, where each predicted pixel can be directly compared with its corresponding ground-truth pixel. In this case, solving a set-matching problem is unnecessary, and the network can be trained end-to-end as in DECODE.\n\nConversely, using the OT distance as a loss function may actually hinder end-to-end learning rather than enable it. It is therefore unclear why a set-based formulation is necessary or what specific benefits it is expected to provide.\n\nIn addition, the idea of formulating SMLM as a set-matching problem is closely related to [1], where the maximum mean discrepancy (MMD) is used as a loss function to quantify the difference between the estimated and ground-truth molecule sets, while the estimation is performed for the whole image rather than in a pixel-wise manner.\n\n[1] Boyd, N.; Jonas, E.; Babcock, H.; Recht, B. DeepLoco: Fast 3D Localization Microscopy Using Neural Networks. 2018. https://doi.org/10.1101/267096.\n\n\nSuggestion\n7-2. Clarify the network output and loss design.\nAlthough the authors state that the number of candidates d is a hyperparameter, it appears to depend on the input image size (H, W), with predictions made for every four pixels. From the appendix, each pixel’s offset is up to three times larger than a pixel, which markedly differs from prior works. Since the estimation is performed pixel-wise, the ground-truth coordinate set can also be converted into pixel-wise labels—indicating whether a molecule exists and, if so, its offset within the pixel. In this case, the prediction and ground-truth representations share the same structure and ordering, and the OT loss effectively reduces to a sum of pixel-wise losses when the OT map becomes the identity. The authors should clarify how this formulation differs from a conventional pixel-wise loss, possibly by analyzing the learned transport map.\n\n7-3. Analyze OT map\nThe transport cost design suggests that information from neighboring pixels might also contribute to molecular localization. Examining the OT map could help explain why, even with lower Jaccard scores, the estimated coordinates remain close in high-density cases (as in Table 1, 8.0). An ablation study comparing the OT loss with a simple pixel-wise loss would clarify the true contribution of OT and the extended offset range.\n\nMinor Comments\n\n- On page 7, line 366, the citation of DECODE refers to a different paper. The original DECODE paper is by Speiser et al., Nature Methods, 2021.\n- Plese define RMSE_vol in Table 3.\n- The reported E_{3D} values for DECODE differ by 0.001 between Table 1 and Table 3. Please clarify the reason for this discrepancy."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "2DY7J6qxNO", "forum": "V1i58pZmp3", "replyto": "V1i58pZmp3", "signatures": ["ICLR.cc/2026/Conference/Submission16705/Reviewer_pzpv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16705/Reviewer_pzpv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761436524262, "cdate": 1761436524262, "tmdate": 1762926757588, "mdate": 1762926757588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Recent deep-learning methods for high-density single-molecule localization microscopy (SMLM) typically depend on non-differentiable post-processing steps, such as non-maximum suppression, to extract the final set of emitter coordinates. This paper reformulates emitter localization as a set-matching problem and introduces an entropy-regularized optimal transport loss that enables fully differentiable, end-to-end training without the need for heuristic post-processing. Furthermore, the proposed iterative refinement architecture integrates the microscope’s image formation model during inference, making the approach physics-aware and potentially enhancing robustness in real experimental conditions. Experiments on synthetic and real datasets demonstrate state-of-the-art performance, particularly in moderate and high emitter density regimes."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper is original in framing single-molecule localization as a set-matching problem and introducing an entropy-regularized optimal transport loss that removes the need for non-differentiable post-processing, enabling genuine end-to-end learning. The technical quality is high, with a carefully designed architecture that incorporates a physically accurate forward model of the imaging system, explicitly modeling shot, readout, and amplification noise. The results are clearly presented and demonstrate strong generalization from synthetic to real biological datasets, underscoring the method’s robustness and practical significance. Overall, the paper combines conceptual novelty, methodological rigor, and empirical clarity, marking a meaningful advance in the application of deep learning to super-resolution microscopy."}, "weaknesses": {"value": "While the paper is strong overall, a few aspects could be clarified or expanded. First, the motivation for using an entropy-regularized optimal transport (OT) loss over standard bipartite matching approaches, such as the Hungarian assignment followed by pairwise regression losses (as employed in DETR and related works), remains insufficiently justified. A direct comparison or ablation highlighting the practical advantages of the entropic formulation—such as smoother gradients, faster convergence, or improved stability—would strengthen the claim. Second, the related work section omits several important prior efforts that jointly optimized the point-spread function (PSF) and the localization model for dense 3D SMLM, most notably DeepSTORM3D (Nehme et al., 2020). Including and discussing these works would provide a more balanced contextualization of the paper’s contributions. Finally, DECODE is excluded from the qualitative comparisons in Figure 4 under the justification that its results resemble LiteLoc; however, DECODE additionally provides per-emitter uncertainty estimates that can be leveraged for post-hoc filtering and might alter the visual comparison. A brief discussion or experiment acknowledging this aspect would help ensure a fairer and more complete evaluation."}, "questions": {"value": "1) Could the authors clarify the motivation for adopting an entropy-regularized optimal transport loss (via the Sinkhorn–Knopp algorithm) instead of a DETR-style bipartite matching loss? In particular, what empirical or theoretical advantages (e.g., smoother optimization, differentiability, computational speed) motivated this choice, and how many Sinkhorn iterations were used in practice to approximate the transport plan?\n2) How is the gradient of the Sinkhorn-based loss computed during backpropagation? Is there a closed-form analytical expression for the gradient, or is it obtained by unrolling the Sinkhorn iterations? Providing this clarification—ideally with a short note or derivation in the appendix—would significantly improve the clarity of the method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "dJfh1R4ZvD", "forum": "V1i58pZmp3", "replyto": "V1i58pZmp3", "signatures": ["ICLR.cc/2026/Conference/Submission16705/Reviewer_gn8m"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16705/Reviewer_gn8m"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762114042848, "cdate": 1762114042848, "tmdate": 1762926756939, "mdate": 1762926756939, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a methodology to train neural networks for detection of activations in single-molecule localization microscopy. The main premise of the paper is that optimal transport can serve as a tool to design loss functions that are fully differentiable and better performing for solving this problem. The proposed optimal transport objective matches activation points with detected observations in the images. The proposed architecture also incorporates an iterative refinement feedback which reconstructs the image with an image formation simulation given the model detections."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Formulation of a differentiable loss function to detect activation points in single-molecule localization microscopy. \n* Effective use of optimal transport theory to design the proposed method.\n* Natural design of the iterative refinement strategy based on physical image-formation principles.\n* Experimental evaluation with multiple performance metrics and relevant baselines.\n* Qualitatively, the methodology also improves detections in real world data."}, "weaknesses": {"value": "* While the application of optimal transport in SMLM is novel, it has been used before for similar detection and localization problems.\n* The performance metrics seem to be saturated in the selected datasets for evaluation. The performance gains seem marginal."}, "questions": {"value": "* What makes the formulation novel in the context of object detection or point localization?\n* Does the SMLM problem really need a new methodology, given that other methods perform comparably?\n* What other benefits (computational, speed, etc) can be obtained from the proposed formulation?\n* Is this applicable to other microscopy imaging types?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Oz9enGlOdW", "forum": "V1i58pZmp3", "replyto": "V1i58pZmp3", "signatures": ["ICLR.cc/2026/Conference/Submission16705/Reviewer_4CME"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16705/Reviewer_4CME"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762121984093, "cdate": 1762121984093, "tmdate": 1762926756080, "mdate": 1762926756080, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper treats the problem of single molecule light microscopy reconstruction as a set matching problem, which is a sound strategy. The authors develop an optimal transport loss and a model architecture to solve this problem. The strategy and results are promising, but the robustness and generalization of the method need to be evaluated further."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "This work introduces two key computational innovations to single-molecule localization microscopy (SMLM). First, the authors reformulate SMLM as a set-matching problem and derive an optimal transport loss function, enabling end-to-end differentiable training . This is the first application of optimal transport theory to SMLM, to the best of my knowledge, and represents a principled approach to handling variable-size sets of fluorophore detections. Second, they propose an iterative refinement architecture that explicitly integrates knowledge of the microscope's optical system by simulating expected frames from current predictions using the known point spread function (PSF), allowing computation of loss between experimental data and estimated molecular distribution.  The combined approach achieves state-of-the-art performance on the E3D metric across multiple density regimes, with particularly strong improvements in localization accuracy (lowest RMSE) at high densities (density 8.0), demonstrating the method's potential to enable faster acquisition times for live-cell imaging."}, "weaknesses": {"value": "The following limitations can constrain the practical applicability of current method. First, the method exhibits consistently lower recall than competitors across all experiments (Table 1), meaning it misses more true fluorophores despite having excellent precision—this trade-off could lead to incomplete biological reconstructions. It is not clear from the paper which aspects of data or optimization influence precision and recall. \n\nSecond, the approach requires precise PSF calibration using fluorescent beads and the method's robustness to PSF miscalibration or drift remains unexplored. The iterative architecture incurs 3× higher computational cost during training (20 hours) and slower inference compared to single-pass models. \n\nThird, the high-density validation on real biological data uses temporal binning as a proxy, which artificially improves signal-to-noise ratio through averaging rather than testing true high-density, low-SNR conditions that would occur in practice. Majority of training relies on synthetic simulations with uniform priors (10-30 activations, uniform spatial distribution), which may not capture the structured, heterogeneous distributions in real biological specimens."}, "questions": {"value": "Majority of my concerns are centered on evaluation of the robustness of the method to unwanted aberrations in imaging, density of fluorophores, and quantum efficiency of fluorophores.\n\nI suggest a systematic series of simulations and experiments to address these. For example,\n1. Consider adding a learned layer to the image formation model that learns a single 3D kernel that allows the image formation model to adapt aberrations in the data.\n2. Simulate data with varying quantum efficiencies and aberrations different from training data, and evaluate the sensitivity of a trained model to these imperfections in real data.\n3. Evaluate feature activations at the end of the encoder and at the end of the decoder for specific raw data frames to test that the estimated localizations make sense, and models are truly learning a relationship between the intensity distributions and the localization of emitters."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GPDRho9QbE", "forum": "V1i58pZmp3", "replyto": "V1i58pZmp3", "signatures": ["ICLR.cc/2026/Conference/Submission16705/Reviewer_VfVn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16705/Reviewer_VfVn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762267403665, "cdate": 1762267403665, "tmdate": 1762926755584, "mdate": 1762926755584, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}