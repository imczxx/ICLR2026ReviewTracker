{"id": "Ax02eR2c3d", "number": 7741, "cdate": 1758034327732, "mdate": 1759897835855, "content": {"title": "Beyond Static Vision: Scene Dynamic Field Unlocks Intuitive Physics Understanding in Multi-modal Large Language Models", "abstract": "While Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in image and video understanding, their ability to comprehend the physical world has become an increasingly important research focus. Despite their improvements, current MLLMs struggle significantly with high-level physics reasoning. \nIn this work, we investigate the first step of physical reasoning, i.e., **intuitive physics understanding**, revealing substantial limitations in understanding the dynamics of continuum objects. \nTo isolate and evaluate this specific capability, we introduce two fundamental benchmark tasks: Next Frame Selection (NFS) and Temporal Coherence Verification (TCV). Our experiments demonstrate that even state-of-the-art MLLMs perform poorly on these foundational tasks. \nTo address this limitation, we propose Scene Dynamic Field (SDF), a concise approach that leverages physics simulators within a multi-task fine-tuning framework. \nSDF substantially improves performance, achieving up to $20.7\\%$ gains on fluid tasks while showing strong generalization to unseen physical domains. This work not only highlights a critical gap in current MLLMs but also presents a promising cost-efficient approach for developing more physically grounded MLLMs. Our code and data will be publicly available.", "tldr": "This paper introduces two low-level tasks to test intuitive physics understanding and proposes Scene Dynamic Field, a method to integrate visual representation from physics simulators to MLLMs while showcasing generalization.", "keywords": ["Multi-modal LLM", "Intuitive Physics"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f0e5fe3c8d52fcf8bdcd09a58db1aeac47ebde14.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses a critical limitation in MLLMs: their poor understanding of intuitive physics, particularly for continuum objects like fluids. The authors introduce two diagnostic tasks—Next Frame Selection (NFS) and Temporal Coherence Verification (TCV)—to systematically evaluate low-level physical perception. They reveal that even state-of-the-art MLLMs perform poorly on these tasks, often near random baselines. To bridge this gap, the authors propose Scene Dynamic Field (SDF), a method that leverages physics simulators to generate visual prompts representing motion dynamics. Through multi-task fine-tuning, SDF significantly improves model performance and generalizes well to unseen physical domains like cloth and smoke."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is interesting for addressing the problem of poor low-level physical perception by proposing practical physics simulators for visual prompting to improve performance.\n\n2. The paper is well-organized and accessible, with clear explanations of both the problem and the solution."}, "weaknesses": {"value": "1. Limited Scope of Transfer Experiments: While the transfer experiments across continuum domains (cloth, sand, smoke, plasticine) are promising, the scope remains limited. The paper would be significantly strengthened by evaluating the method's generalization to other fundamental physical phenomena, such as rigid-body dynamics, collisions, or optical effects. \n\n2. Experimental Design and Baselines: To provide a more comprehensive performance comparison, we suggest expanding Table 1 to include additional baseline models. Specifically, it would be informative to compare against larger models with more parameters.\n\n3. Dependence on Synthetic Data and Real-World Applicability: The SDF method's reliance on synthetic data from simulators is a potential limitation, as such data may not fully capture the complexity and noise of real-world physical systems. The paper could be improved by discussing the feasibility and potential challenges of applying this method to real-world physics problems. For instance, how would the SDF approach perform with real sensor data that is often incomplete or noisy?\n\n4. Analysis of MLLM Limitations: The paper identifies that MLLMs struggle with low-level dynamics but does not deeply investigate the root cause. A more thorough analysis is needed to determine whether these failures stem from architectural limitations (e.g., an inductive bias towards high-level semantics) or a bias in the pre-training data (e.g., a lack of low-level physical reasoning examples). Uncovering this would provide valuable insight for future research."}, "questions": {"value": "See weaknesses. I am willing to discuss with the authors"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZLs3U9qGC9", "forum": "Ax02eR2c3d", "replyto": "Ax02eR2c3d", "signatures": ["ICLR.cc/2026/Conference/Submission7741/Reviewer_HQBD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7741/Reviewer_HQBD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7741/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760575789632, "cdate": 1760575789632, "tmdate": 1762919792420, "mdate": 1762919792420, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes two low level tests for intuitive physics in MLLMs, Next Frame Selection and Temporal Coherence Verification, focused mainly on fluids. It introduces Scene Dynamic Field, a simulator derived motion visualization used as a visual prompt within a multi task fine tuning scheme, and reports sizable gains on the proposed tests with some transfer to cloth, sand, smoke, and plasticine."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Clear problem decomposition toward low level dynamics rather than high level QA\n- Simple intermediate representation that is easy to plug into existing MLLMs\n- Ablations on stride, prompts, model scale, and expert vs self distilled data\n- Some transfer beyond fluids and an attention analysis that supports the claim that SDF shifts focus to earlier frames"}, "weaknesses": {"value": "- The weakest point is that there is no comparison to strong motion baselines. SDF is a velocity magnitude style visual prompt, which is conceptually close to optical flow magnitude, flow stacks, dynamic images, or even simple frame differencing. Without head to head baselines under the same training data and budget, the gains could come from adding any explicit motion cue rather than from SDF itself. This leaves the central claim unproven.\n\n- Benchmarks are author designed and multiple choice, so improvements may reflect distractor design rather than genuine physics understanding\n\n- Absolute accuracy remains low, so practical impact is unclear\n\n- Limited evaluation beyond fluids for rigid body scenes or causal reasoning tasks, so the title and claims feel broader than what is shown\n- Distractor pruning uses SigLIP embeddings which are related to encoders used by evaluated models, creating a risk of bias\n\nMy recommendation is reject. The idea is interesting and the empirical gains are clear on the authors benchmark, but the evaluation misses strong motion baselines, relies on potentially biased distractor construction, and the absolute performance and scope do not yet support the paper’s broad claims."}, "questions": {"value": "- How does SDF compare to simple optical flow overlays, grayscale motion magnitude, or event frame stacks when training with the same budget?\n\n- Are results robust when distractors are generated with a feature space disjoint from any model under test?\n\n- Can you evaluate on external physics benchmarks without re curating the data to validate generality?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9jqfHq2fY4", "forum": "Ax02eR2c3d", "replyto": "Ax02eR2c3d", "signatures": ["ICLR.cc/2026/Conference/Submission7741/Reviewer_Vi2b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7741/Reviewer_Vi2b"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7741/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761847611971, "cdate": 1761847611971, "tmdate": 1762919792082, "mdate": 1762919792082, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper focuses on the task of fluid and physical scene understanding. It makes two primary contributions:\n\n1. The authors build a comprehensive benchmark for physical reasoning from videos, introducing two key tasks — Next Frame Selection (NFS) and Temporal Coherence Verification (TCV). The dataset is constructed from multiple sources, including ContPhy, PhysBench, and real-world video clips, to cover both synthetic and natural dynamics.\n\n2. The paper proposes the Scene Dynamic Field, a framework that leverages physical simulation principles and integrates Chain-of-Thought (CoT) reasoning with explicit physics modeling. This approach enables multimodal models to reason about scene dynamics beyond static appearance, bridging the gap between perception and physical understanding."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper tackles an important and challenging problem — physical and fluid scene understanding — which is a key step toward enabling models to reason about real-world dynamics.\n\nThe proposed explicit physical reasoning task is interesting and well-motivated, encouraging models to go beyond visual perception and engage in physically grounded understanding.\n\nThe paper is generally well-written and structured, with a clear motivation and logical flow from problem definition to methodology and experiments."}, "weaknesses": {"value": "1. Limited physical understanding of only fluid dynamics. The proposed framework primarily focuses on liquid and fluid dynamics, which narrows the generality of the method. Extending the benchmark and tasks to cover a broader range of physical interactions — such as rigid-body motion, collision, or elastic deformation — would strengthen the overall contribution.\n\n2. Few missing references to physical reasoning VQA. The paper could benefit from citing and discussing more recent physical understanding and VQA-related research, such as Comphy (https://arxiv.org/abs/2205.01089) and DynSuperCLEVR (https://arxiv.org/abs/2406.00622), which address the VQA for physical reasoning."}, "questions": {"value": "1.  Data Modality and Encoder Usage:\nWhat is the exact data format of the SDF samples used for training? From Figure 3, the SDF appears to be an RGB-like image generated through velocity-to-color mapping. Could the authors clarify whether these SDF images are indeed three-channel RGB inputs, and if they are processed by the same image encoder as the regular video frames during training?\n\n2. Ablation on the SDF Step in CoT Fine-Tuning. In the SDF-guided Chain-of-Thought fine-tuning process, the framework first predicts the SDF representation and then predicts the next frame based on that SDF. What would happen if we retain the same training pipeline but skip the explicit SDF step, i.e., directly fine-tune the model with simplified CoT instructions to predict the RGB frame without generating the SDF?\nThis comparison would help clarify how much the explicit SDF stage contributes to physical reasoning, especially since the SDF image appears visually similar to the original frame except for color-coded fluid regions (as shown in Figure 3). Such an ablation could reveal whether the SDF acts mainly as a visual prompt or as a truly distinct physical representation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7lO4v3XW1q", "forum": "Ax02eR2c3d", "replyto": "Ax02eR2c3d", "signatures": ["ICLR.cc/2026/Conference/Submission7741/Reviewer_deha"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7741/Reviewer_deha"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7741/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988231608, "cdate": 1761988231608, "tmdate": 1762919791682, "mdate": 1762919791682, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper try to addresses the gap in MLLMs understanding of intuitive physics, particularly for continuum objects like fluids. The authors first introduce two low-level benchmark tasks, next frame selection and temporal coherence verification, to demonstrate that current MLLMs perform poorly at perceiving physical dynamics. To solve this, they propose SDF, an intermediate representation generated by physics simulators that visually encodes motion (e.g., velocity as color intensity). Through a multi-task fine-tuning strategy, their SDF-enhanced model achieves substantial gains on fluid tasks and shows strong generalization to unseen physical domains like cloth and sand."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The motivation of the paper correctly focuses on a simpler, core problem, which is just perceiving physical motion, separating it from complex, high-level reasoning.\n\n- Using a visual map (SDF) from a physics simulator to train the model works. This helps the model learn the idea of dynamics, letting it generalize from fluids to unseen materials like cloth or sand.\n\n- The authors built a strong benchmark by mixing simulated data with real-world videos, and they ran thorough experiments to validate their approach.\n\n- The paper is well presented with clear logic."}, "weaknesses": {"value": "- The SDF representation is very basic, encoding just the projected velocity magnitude into one color channel. It's questionable if this simple map captures enough information for complex interactions, or if it needs to include more data like 3D vector direction or using optical flow (which avoids physics simulation). A discussion comparing the performance, advantages, and disadvantages of these different representations would greatly strengthen the analysis.\n\n- The pipeline is complex. It requires a full-parameter fine-tuning process, data from simulators, and knowledge distilled from expert models, which is computationally expensive and hard to scale."}, "questions": {"value": "See in the weekness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "El4N02cPEa", "forum": "Ax02eR2c3d", "replyto": "Ax02eR2c3d", "signatures": ["ICLR.cc/2026/Conference/Submission7741/Reviewer_tuv4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7741/Reviewer_tuv4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7741/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762127704670, "cdate": 1762127704670, "tmdate": 1762919791310, "mdate": 1762919791310, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}