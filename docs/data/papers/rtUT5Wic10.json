{"id": "rtUT5Wic10", "number": 16313, "cdate": 1758263048921, "mdate": 1759897248234, "content": {"title": "Extending Fourier Neural Operators for Modeling Parameterized and Coupled PDEs", "abstract": "Parameterized and coupled partial differential equations (PDEs) are central to modeling phenomena in science and engineering, yet neural operator methods that address both aspects remain limited. We extend Fourier neural operators (FNOs) with minimal architectural modifications along two directions. For parameterized dynamics, we propose a hypernetwork-based modulation that conditions the operator on physical parameters. For coupled systems, we conduct a systematic exploration of architectural choices, examining how operator components can be adapted to balance shared structure with cross-variable interactions while retaining the efficiency of standard FNOs. Evaluations on benchmark PDEs, including the one-dimensional capacitively coupled plasma equations and the Gray–Scott system, show that our methods achieve up to 55~72% lower errors than strong baselines, demonstrating the effectiveness of principled modulation and systematic design exploration.", "tldr": "", "keywords": ["neural operators", "Fourier neural operators", "parameterized dynamics", "couple"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/301663cb0a362e307531ebad0b1f67d95e798ca0.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes two architectural extensions to Fourier Neural Operators (FNOs) to better handle two important classes of PDEs: (i) parameterized dynamics with fixed initial conditions, and (ii) systems of coupled PDEs with interacting physical fields. For parameterized dynamics, the authors introduce a lightweight hypernetwork that modulates FNO layers based on physical parameters. For coupled PDEs, they perform a systematic architectural design study to determine where and how to introduce cross-variable coupling, ultimately proposing a Fourier-space interaction scheme. The final model, FNOx (and its parametric variants pFNOx, hpFNOx), achieves significant gains over strong baselines — including coupled multiwavelet neural operators — on both a newly proposed 1D capacitively coupled plasma benchmark and the standard Gray–Scott system."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* **Addresses underexplored settings**: The paper targets two highly practical yet understudied scenarios in neural operator learning — parameterized dynamics with fixed initial conditions, and multiple interacting PDE fields. Both are common in engineering and physics simulations.\n\n* **Effective, minimal extensions**: The proposed improvements are simple but well-motivated. The hypernetwork-based modulation (hpFNOx) conditions model behavior across parameters without blowing up model size, and the spectral-domain coupling design elegantly leverages FNO’s strengths.\n\n* **Systematic architectural study**: The paper carefully explores different configurations (shared vs separate layers, coupling placements) and justifies its final FNOx architecture based on empirical and structural considerations.\n\n* **Strong empirical results**: On both benchmarks, the proposed models achieve large performance gains — often reducing error by 50–70% relative to the best baseline — while maintaining similar runtime and parameter count.\n\n* **New benchmark dataset**: The 1D plasma physics setup with tunable parameters offers a meaningful and realistic testbed for studying parametric and coupled operator learning.\n\n* **Clarity and reproducibility**: The paper is generally well-written, with detailed experimental setups and promised code release. It adheres to good reproducibility practices."}, "weaknesses": {"value": "* **Incremental novelty**: The core ideas — hypernetwork modulation and coupling in neural operators — are grounded in existing techniques. HyperFNO and related works already explored hypernetwork-based parameter conditioning, and Fourier-space coupling is a natural extension within FNOs.\n\n* **Narrow scope**: The benchmarks, while appropriate, are relatively small-scale and low-dimensional (1D/2D). It’s unclear how well the approach generalizes to larger or more complex systems (e.g. 3D Navier–Stokes, multiple coupled fields).\n\n* **Limited analysis of generalization**: There’s little discussion on how well hpFNOx handles out-of-distribution parameters or extrapolation, which is a practical concern in real applications of parameterized PDE solvers.\n\n* **Brief treatment of second benchmark**: The Gray–Scott results are reported only briefly in the main paper, which weakens the case for generality."}, "questions": {"value": "1. **How does the hypernetwork-modulated FNO behave on out-of-distribution (OOD) physical parameters?** Would performance degrade sharply or smoothly? Have you tested its extrapolation limits?\n\n2. **Why is the coupling introduced only in the Fourier domain?** Have you explored combining it with local (real-space) cross-variable interactions, and how would that affect performance or efficiency?\n\n3. **Can your proposed architecture scale to PDE systems with more than two coupled fields?** If not, what limitations would arise — architectural, memory, or training-related?\n\n4. **How would the design choices in FNOx (e.g., Q2c, L2, G) transfer to more challenging PDE domains like turbulent 2D/3D fluid flow or real-world inverse problems?** Do you expect the same configurations to hold?\n\n5. **To what extent does the performance improvement come from architectural tuning versus true modeling of coupled/parameterized dynamics?** Could stronger baselines (e.g. HyperFNO, CoDA-NO) close the gap?\n\n6. **In the case of high-dimensional parameter spaces (e.g., 10–20 physical parameters), would the hypernetwork remain effective without overfitting or becoming too large?** How would you scale it?\n\n7. **How sensitive is the performance to the size and architecture of the hypernetwork?** Could a different modulation scheme (e.g., multiplicative gating) outperform simple bias shifts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ea4uvIcM87", "forum": "rtUT5Wic10", "replyto": "rtUT5Wic10", "signatures": ["ICLR.cc/2026/Conference/Submission16313/Reviewer_UVnJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16313/Reviewer_UVnJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761325301809, "cdate": 1761325301809, "tmdate": 1762926452244, "mdate": 1762926452244, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper extends Fourier Neural Operators (FNOs) to handle parameterized and coupled PDEs. The authors propose two lightweight modifications: (1) conditioning FNOs on physical parameters through either input concatenation (pFNO) or a small hypernetwork modulation (hpFNO), and (2) enabling coupling between multiple PDE variables by performing cross-variable mixing in Fourier space. The resulting framework (FNOx, pFNOx, hpFNOx) retains the efficiency of standard FNOs while improving accuracy for systems with varying parameters or interacting fields. The authors introduce a new benchmark based on a 1-D capacitively coupled plasma model and also evaluate on the Gray–Scott equations. The proposed hpFNO achieves up to 55–72 % error reduction over strong baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Addresses a timely and important gap: FNOs are increasingly popular for PDE surrogates, yet parameterization and coupling remain under-explored.\n\n- The architecture modifications are simple and principled—hypernetwork modulation and Fourier-space coupling can be integrated into existing FNOs with minimal effort.\n\n- The approach is general and modular, applicable to multidimensional parameter fields and different neural-operator families.\n\n- Demonstrates comparisons across multiple strong baselines (FNO, CFNO, MWT, DeepONet, U-Net) with solid quantitative gains.\n\n- Introduces a new plasma-physics benchmark that could be useful to the community."}, "weaknesses": {"value": "1. Writing is meandering and often unfocused; core ideas and notation could be stated more directly.\n\n2. Organization: the Related-Work section appears late; it would be clearer to position it before the Methods.\n\n3. The Gray–Scott example feels secondary, lacking detailed analysis or ablation—appears appended to strengthen results. In fact, the experiments are limited and cannot demonstrate general applicability. The paper should be enhanced with more experiments from different PDEs.\n\n4. The claimed generality for “parameterized and coupled PDEs” is convincing for 1-D cases but not well demonstrated on higher-dimensional or more complex systems.\n\n5. Limited qualitative insight—plots focus on error metrics. The authors should delve deeper into the interpretation of learned coupling or modulation effects.\n\n6. typos like \"learable\". should have numbered the equations."}, "questions": {"value": "1. How sensitive is the hpFNO performance to the design of the hypernetwork (depth, parameterization, modulation type)?\n\n2. Could the same effect be achieved by allowing \\( W_\\ell(\\mu) \\) (parameter-dependent local maps) instead of additive \\( s_\\ell(x, \\mu) \\) biases?  \n\n3. Are there stability or extrapolation limitations when \\( \\mu \\) lies outside the training range?  \n\n4. How does coupling only in Fourier space compare to coupling in both spatial and spectral domains?\n\n5. Can the authors comment on scalability to 2-D/3-D PDEs and memory growth with the number of coupled variables?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "5odrjFTdgm", "forum": "rtUT5Wic10", "replyto": "rtUT5Wic10", "signatures": ["ICLR.cc/2026/Conference/Submission16313/Reviewer_6Lqg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16313/Reviewer_6Lqg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761677595586, "cdate": 1761677595586, "tmdate": 1762926451712, "mdate": 1762926451712, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper extends the Fourier Neural Operators (FNOs) to handle coupled and parameterized PDEs by introducing new architectures. The authors propose designs that model parametrized dynamics and coupled systems and evaluate it on a newly developed 1D capacitively coupled plasma and Gray-Scott dataset. Experimental results demonstrate that the proposed hpFNO models achieve higher predictive accuracy compared to existing FNO variants."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "* The introduction clearly motivates the need for efficient operator learning on coupled and parametrized PDEs.\n* The proposed pFNO, and hpFNO architectures aim to improve representations for coupled and parametrized PDEs, and the results on the benchmarks are promising.\n* The ablation study thoughtfully analyzes the effects of design components, showing careful empirical work."}, "weaknesses": {"value": "1. Lack of architectural visualization : The paper introduces multiple new and extended operators, but there is no schematic figure summarizing the overall architecture.\n2. Unclear explanation for “best 5 of 10 runs” in Table 2 : Why is this criterion used for $T_{in} = 2$ and $T_{in} = 1$?\n3. Sparse content in Section 4.3 : This section contains only a brief summary and refers the reader to the appendix. Including a compact summary table would be better for understanding cross-domain generalization."}, "questions": {"value": "1. What exactly does “acc” in Figure 3 represent? It seems the lower is better, so 'acc' might be misleading.\n2. How many CCP benchmark data were generated, and how were they split into training/test sets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "aRzY4AhHmq", "forum": "rtUT5Wic10", "replyto": "rtUT5Wic10", "signatures": ["ICLR.cc/2026/Conference/Submission16313/Reviewer_FkHd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16313/Reviewer_FkHd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965501364, "cdate": 1761965501364, "tmdate": 1762926451107, "mdate": 1762926451107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "1. The paper is well-written, easy to follow, and clearly motivated.\n\n2. The experimental results are impressive, demonstrating a 55-72% reduction in error over strong baselines and confirming the value of the principled design.\n\n3. I am not an expert in this area and will defer to the other reviewers for their expert opinions on the technical contribution"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written, easy to follow, and clearly motivated.\n\n2. The experimental results are impressive, demonstrating a 55-72% reduction in error over strong baselines and confirming the value of the principled design."}, "weaknesses": {"value": "The manuscript would benefit from additional visualizations, such as a diagram illustrating the model architecture, to help readers better understand the proposed method."}, "questions": {"value": "What is the key difference between your method and the baselines, and why does your approach work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Qi2sgU0NdV", "forum": "rtUT5Wic10", "replyto": "rtUT5Wic10", "signatures": ["ICLR.cc/2026/Conference/Submission16313/Reviewer_tkqC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16313/Reviewer_tkqC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16313/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762152253628, "cdate": 1762152253628, "tmdate": 1762926450444, "mdate": 1762926450444, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}