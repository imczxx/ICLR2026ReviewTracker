{"id": "1ludR5XHnB", "number": 17806, "cdate": 1758280686057, "mdate": 1763121894251, "content": {"title": "DisIR: Disentangled Learning of Controllable All-in-One Image Restoration under Composite Degradations", "abstract": "Composite degradation scenarios, in which multiple types of degradation are mixed together, have attracted increasing interest in the development of restoration models. Although prior knowledge of degradation types exists, the challenge of precise image restoration persists, particularly when multiple degradations are intricately mixed, and selectively handling individual degradations poses considerable difficulty. To tackle this challenge, we propose DisIR, a novel disentangled framework that learns controllable representations for composite image restoration through four distinct training objectives. First, we introduce an identity embedding as a prompt, along with an identity loss that guides the model to reproduce the input without modification. Second, we design a ratio control mechanism where the identity embedding can be linearly combined with degradation-specific embeddings at controllable ratios, enabling fine-grained restoration intensity control through a dedicated ratio control loss. Third, to disentangle multiple degradations, we incorporate an intermediate loss that supervises intermediate outputs, each aimed at selectively removing only one type of degradation among multiple composite degradations. Fourth, a permutation-invariant loss is applied to enforce consistent restoration results, regardless of the order in which multiple degradations are removed. By focusing on the training pipeline, our method acts as a versatile enhancement that can be integrated into controllable architectures without requiring their structural redesign. Experimental results demonstrate that our DisIR achieves state-of-the-art performance on composite degradation benchmarks while enabling flexible and selective removal of multiple degradations, either sequentially or in a single step, through a fused embedding with user-controlled intensity ratios.", "tldr": "", "keywords": ["Image restoration", "All-in-One"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/2dd58f05fc85110a614f2b580d1b816f42624952.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper tackles the problem of restoring images corrupted by multiple overlapping degradations (e.g., haze and snow). The authors argue that while existing \"all-in-one\" models can handle such composite inputs, they lack fine-grained controllability. They propose DisIR, a novel framework that introduces a disentangled learning pipeline to enable precise control over the restoration process. The core of their method is a set of four specialized loss functions designed to guide the model to: preserve the original image when requested, remove degradations at a controllable intensity, selectively target specific degradations while leaving others untouched, and produce consistent results regardless of the processing order. The proposed method is evaluated on a new benchmark, CCDD-11, and is shown to outperform existing approaches, offering a solution towards more flexible and user-directed image restoration systems."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The concept of the \"ratio control embedding\" – a linear interpolation between identity and degradation embeddings – is an elegant and intuitive solution for achieving continuous control over restoration intensity. This is a notable technical contribution.\n* The paper provides extensive comparative experiments on the proposed CCDD-11 dataset, demonstrating superior overall performance against a wide range of baselines."}, "weaknesses": {"value": "* My major concern lies in the ablation study. It fails to isolate the contribution of each component (e.g., the Identity loss is active in all rows). and relies solely on final PSNR on a single dataset, providing no dedicated metrics to quantify the claimed controllability (e.g., accuracy of selective removal, linearity of ratio control). \n* There is no analysis of the model's generalization to real-world data or other degradation benchmarks, leaving the robustness and broader applicability of the method in question.\n* The description of the proposed method in Section 3 is disjointed and lacks a coherent narrative. The core concept of \"disentangled learning\" is not formally defined or motivated. The presentation jumps between architectural components (embeddings) and training objectives (loss functions) without a clear, unifying framework. This makes it difficult to discern the fundamental algorithmic contribution beyond the introduction of several additive components (new embeddings and new losses) to a strong baseline."}, "questions": {"value": "See weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "x7gQ0oMXWT", "forum": "1ludR5XHnB", "replyto": "1ludR5XHnB", "signatures": ["ICLR.cc/2026/Conference/Submission17806/Reviewer_sL2r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17806/Reviewer_sL2r"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760891894642, "cdate": 1760891894642, "tmdate": 1762927649979, "mdate": 1762927649979, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "1iHhvGP3FA", "forum": "1ludR5XHnB", "replyto": "1ludR5XHnB", "signatures": ["ICLR.cc/2026/Conference/Submission17806/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17806/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763121580675, "cdate": 1763121580675, "tmdate": 1763121580675, "mdate": 1763121580675, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DisIR to address mixed degradation restoration, especially in cases of complex mixtures of multiple degradation types, by selectively processing individual degradation types. However, the next task seems to lack practical applications: no one needs to intentionally preserve other degradations when restoring low-quality images. \n\nFurthermore, although this paper claims that DisIR can be integrated into a controllable architecture without redesigning its architecture, it has only been validated on one architecture (OneRestore), failing to demonstrate its compatibility with traditional image restoration networks (SwinIR, NAFNet, Restormer) or current diffusion-based ones. \n\nFinally, while this paper claims to solve the complex degradation problem, validation was only performed on mixed weather datasets, not on broader scenarios such as low-light + blur + noise, downsampling + blur + noise + compression, etc.\n\nOverall, I believe this paper has significant room for improvement and is not suitable for publication now."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is well-structured.\n2. The proposed method is novel and well-developed. However, due to insufficient experiments, its transferability and effectiveness have not been strongly verified."}, "weaknesses": {"value": "1. The existing work is not well reviewed. Lines 54-55 state that \"most all-in-one restoration studies have focused on treating the types of degradation individually.\" This might have been true a year ago. However, nowadays, many works address mixed degradation restoration, such as DCPT [1] and MoceIR [2], have been validated on CDD. UniRes [3], for example, addresses a broader range of hybrid degradation problems. Similarly, in the related work section, this paper only lists work from 2024 onwards, ignoring a significant amount of existing work, such as VLUNet [4] and UniRestore [5].\n2. This paper lacks sufficient experiments.\n- This paper claims that DisIR applies to multiple architectures, but the experimental results do not reflect this, as it was only tested on the OneRestore architecture.\n- This paper claims that DisIR can solve the problem of mixed degradation, but the experimental results do not reflect this, as it was only tested on mixed weather datasets, and its effectiveness on a wider range of mixed degradation (e.g., low-light + blur + noise LoL-Blur [6] dataset, downsampling + blur + noise + compression Real-world Super-resolution) has not been verified.\n- The visual improvements given in the appendix are not significant enough.\n\n[1] Universal Image Restoration Pre-training via Degradation Classification. ICLR 2025.\n\n[2] Complexity Experts are Task-Discriminative Learners for Any Image Restoration. CVPR 2025.\n\n[3] Universal Image Restoration for Complex Degradations. ICCV 2025.\n\n[4] Vision-Language Gradient Descent-driven All-in-One Deep Unfolding Networks. CVPR 2025.\n\n[5] UniRestore: Unified Perceptual and Task-Oriented Image Restoration Model Using Diffusion Prior. CVPR 2025.\n\n[6] LEDNet: Joint Low-light Enhancement and Deblurring in the Dark. ECCV 2022."}, "questions": {"value": "1. On the CDD dataset, it should also be compared with state-of-the-art methods [1,2]. However, this paper shows a significant performance gap compared to MoceIR and DCPT. Is this due to limitations in the number of parameters?\n\n[1] Universal Image Restoration Pre-training via Degradation Classification. ICLR 2025.\n\n[2] Complexity Experts are Task-Discriminative Learners for Any Image Restoration. CVPR 2025."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "haLr6IvLRx", "forum": "1ludR5XHnB", "replyto": "1ludR5XHnB", "signatures": ["ICLR.cc/2026/Conference/Submission17806/Reviewer_Ms95"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17806/Reviewer_Ms95"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761893679887, "cdate": 1761893679887, "tmdate": 1762927649149, "mdate": 1762927649149, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces DisIR, a new training framework that turns an existing all-in-one restoration network into a controllable system for composite degradations."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This work applies continuous intensity control and selective single-degradation removal in an all-in-one model without architectural redesign."}, "weaknesses": {"value": "1. The novelty of this work is not so significant. All technical contributions reside in loss functions; the encoder–decoder and embedder are imported unchanged from OneRestore. Discuss whether the same losses can be layer-wise or attention-head-wise regularisers inside the SDTB block, or provide a theoretical justification that architectural change is unnecessary.\n2. Paper concedes that training becomes “impractical” for triple-composite images; yet real photos can contain five or more degradations (blur, noise, JPEG, haze, rain, low-light, glare, etc.). Report compute/memory growth w.r.t. number of degradations d (approx. O(d²) pairs for permutations). Evaluate on a 5-degradation subset or discuss hierarchical or recursive application of DisIR.\n3. The latest related work was published in 2024. The reviews don't contain the all-in-one work published in 2025. As far as I know, there are many excellent works in 2025. Additionally, the experiments should contain these methods."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "qguCDAwy7H", "forum": "1ludR5XHnB", "replyto": "1ludR5XHnB", "signatures": ["ICLR.cc/2026/Conference/Submission17806/Reviewer_2mxA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17806/Reviewer_2mxA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762100544585, "cdate": 1762100544585, "tmdate": 1762927648750, "mdate": 1762927648750, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}