{"id": "0QNm991Py5", "number": 22990, "cdate": 1758337869328, "mdate": 1759896837189, "content": {"title": "The Thinking Spectrum: An Empirical Study of Tunable Reasoning in LLMs Through Model Merging", "abstract": "The growing demand for large language models (LLMs) with tunable reasoning capabilities in many real-world applications highlights a critical need for methods that can efficiently produce a spectrum of models balancing reasoning depth and computational cost. Model merging has emerged as a promising, training-free technique to address this challenge by arithmetically combining the weights of a general-purpose model with a specialized reasoning model. While various merging techniques exist, their potential to create a spectrum of models with fine-grained control over reasoning abilities remains largely unexplored. \nThis work presents a large-scale empirical study evaluating a range of model merging techniques across multiple reasoning benchmarks. We systematically vary merging strengths to construct accuracy-efficiency curves, providing the first comprehensive view of the tunable performance landscape. Our findings reveal that model merging offers an effective and controllable method for calibrating the trade-off between reasoning accuracy and token efficiency, even when parent models have highly divergent weight spaces. \nCrucially, we identify instances of Pareto Improvement, where a merged model achieves both higher accuracy and lower token consumption than one of its parents. Our study provides the first comprehensive analysis of this tunable space, offering practical guidelines for creating LLMs with specific reasoning profiles to meet diverse application demands.", "tldr": "Simple model merging can effectively achieve tunable accuracy-cost trade-offs in LLMs.", "keywords": ["Large Reasoning Models; Model Merging"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f10bec0060bb251c660ef27248659cce8b01132e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work conducts an empirical study on using model merging to create LLMs with tunable reasoning capabilities. It identifies Pareto Improvements where merged models achieve both higher accuracy and lower token consumption than their parent models."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper systematically evaluates 7 merging techniques across 5 diverse benchmarks (AIME24, AIME25, HMMT25, GPQA, Creative Writing) and two model scales (4B dense and 30B MoE), constructing complete accuracy-efficiency curves."}, "weaknesses": {"value": "1. The comparison between NeuralBeagle14-7B and Turdus (Section 3) could be strengthened. Their small parameter distance (0.5%) may primarily reflect alignment strategy differences rather than capability shifts. Additionally, comparing this pair with the Qwen series introduces potential confounds from different architectures and training strategies, which could make interpretation challenging. The study would benefit from more carefully matched baselines or an explicit discussion of these confounding factors.\n2. The paper would be strengthened by a deeper analysis of why merging works effectively. Given that simple linear interpolation yields competitive or superior results compared to sophisticated algorithms (TIES, DARE, LORE), it would be valuable to discuss whether more scenarios might benefit from complex methods.\n3. The paper over-relies on parameter distance as a connectivity proxy without directly measuring loss landscapes along interpolation paths, which would provide stronger evidence for the checkpoint sampling hypothesis.\n4. Lack of Qualitative Analysis: How does the merged model actually solve problems differently from its parents? Without examining reasoning chains, the paper only shows metric improvements but doesn't explain how the model's thinking changes( through shorter reasoning, different strategies, or skipping steps ?)."}, "questions": {"value": "1. How do results generalize to other model families beyond Qwen?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9kroMCUyOz", "forum": "0QNm991Py5", "replyto": "0QNm991Py5", "signatures": ["ICLR.cc/2026/Conference/Submission22990/Reviewer_RF2r"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22990/Reviewer_RF2r"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22990/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761149658320, "cdate": 1761149658320, "tmdate": 1762942467767, "mdate": 1762942467767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates model merging as a training-free method for producing LLMs with tunable reasoning depth, positioned between “direct” (fast, shallow reasoning) and “thinking” (slow, chain-of-thought-heavy) models.\nUsing Qwen3-4B and Qwen3-30B models, it merges a reasoning-optimized model (θ_think) and a direct model (θ_direct) via various algorithms (Weighted Average, SLERP, DARE, TIES, EMR, LORE, TWIN, etc.).\nAcross multiple benchmarks (AIME24/25, HMMT25, GPQA-Diamond, Creative Writing), the authors analyze accuracy–efficiency trade-offs,"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Introduces the “Thinking Spectrum” as a continuous axis between direct and thinking models, an appealing abstraction for reasoning control.\n2. Evaluates seven established merging algorithms plus custom heuristics across multiple datasets and model sizes.\n3. Demonstrates meaningful control of reasoning depth without any retraining, relevant for resource-limited applications."}, "weaknesses": {"value": "1. The central hypothesis (“merging ≈ checkpoint sampling”) remains purely speculative with no mathematical support or gradient-path analysis.\n2. Claims that direct and thinking models share a connected basin are asserted but not proven (no loss-surface probing or interpolation-loss plots).\n3. Heavy reliance on mathematical reasoning datasets; generalization to broader reasoning types (commonsense, multi-hop, scientific) is untested.\n4. No systematic study of the impact of architecture scale, base model family, or tokenizer differences on merge viability.\n5. Statistical analyses are mostly descriptive; lacks formal significance testing, variance reporting across seeds, or ablation of random initialization.\n6. “Token length” is used as proxy for cost, but latency or FLOPs would be more accurate measures of efficiency.\n7. No direct quantitative comparison versus SFT-on-short-CoT, RLHF-pruning, or distillation baselines."}, "questions": {"value": "-"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "s017xO07Fc", "forum": "0QNm991Py5", "replyto": "0QNm991Py5", "signatures": ["ICLR.cc/2026/Conference/Submission22990/Reviewer_godS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22990/Reviewer_godS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22990/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761573889125, "cdate": 1761573889125, "tmdate": 1762942467193, "mdate": 1762942467193, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper shows an empirical study of model merging between base and thinking models for reasoning tasks. The authors find that the merged models can surpass their parent thinking model in both reasoning accuracy and token efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper shows some findings of model merging between base and thinking models, such as the merged model can achieve comparable reasoning accuracy with less token consumption.\n2. The study is exceptionally thorough, evaluating seven merging techniques (e.g., Linear, SLERP, TIES, DARE) and three custom strategies across two model scales (4B and 30B parameters) and five diverse benchmarks."}, "weaknesses": {"value": "1. The experiments are confined to the Qwen family of models.\n2. The study briefly mentions artifacts like formatting inconsistencies and stray reasoning tags (<think>) in merged model outputs. These issues related to output stability, controllability, and potential failure modes are critical for real-world deployment but are not analyzed in depth.\n3. The paper acknowledges the lack of a formal theory to explain why merging works so well despite the large parameter-space divergence between the parent models."}, "questions": {"value": "1. Can a formal mathematical framework be developed to explain the surprising effectiveness of model merging?\n2. How does model merging compare to model distillation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "J4xSUcsx5d", "forum": "0QNm991Py5", "replyto": "0QNm991Py5", "signatures": ["ICLR.cc/2026/Conference/Submission22990/Reviewer_WYxG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22990/Reviewer_WYxG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22990/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761962821617, "cdate": 1761962821617, "tmdate": 1762942466874, "mdate": 1762942466874, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}