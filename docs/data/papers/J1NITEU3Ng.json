{"id": "J1NITEU3Ng", "number": 18994, "cdate": 1758292608743, "mdate": 1763703672974, "content": {"title": "ATEX-CF: Attack-Informed Counterfactual Explanations for Graph Neural Networks", "abstract": "Counterfactual explanations offer an intuitive way to interpret graph neural networks (GNNs) by identifying minimal changes that alter a model’s prediction, thereby answering “what must differ for a different outcome?”. In this work, we propose a novel framework, ATEX-CF that unifies adversarial attack techniques with counterfactual explanation generation—a connection made feasible by theirshared goal of flipping a node’s prediction, yet differing in perturbation strategy:adversarial attacks often rely on edge additions, while counterfactual methods typically use deletions. Unlike traditional approaches that treat explanation and attack separately, our method efficiently integrates both edge additions and deletions, grounded in theory, leveraging adversarial insights to explore impactful counterfactuals. In addition, by jointly optimizing fidelity, sparsity, and plausibility under a constrained perturbation budget, our method produces instance-level explanations that are both informative and realistic. Experiments on synthetic and real-world node classification benchmarks demonstrate that ATEX-CF generates faithful, concise, and plausible explanations, highlighting the effectiveness of integrating adversarial insights into counterfactual reasoning for GNNs.", "tldr": "", "keywords": ["Graph Neural Network", "Counterfactual Explanation", "Adversarial Attack"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c77a46442bf34b60e5bd3f56b95f582bef3ae13c.pdf", "supplementary_material": "/attachment/275791875a952b5724cbee12339197b25e8e3696.pdf"}, "replies": [{"content": {"summary": {"value": "The paper proposes the ATEX-CF framework, which applies adversarial attack techniques to help with the generation of counterfactual explanations, which explain what factors must differ in order to produce a different result. This is within the context of graph neural networks, where the counterfactual explanation addresses the least amount of changes to the graph needed to alter the model’s prediction on a node in the graph. Adversarial attacks have overlap with counterfactual explanations as these attacks focus on undermining GNNs by making deliberate minor changes to a graph to change a node’s predicted class. ATEX-CF specifically incorporates the technique of adding edges to a graph that is used in adversarial attacks, in addition to the edge deletion techniques used in counterfactual explanations. By incorporating edge additions, ATEX-CF can also capture previously missing relations between nodes, by adding in the edge that denotes the possible/probable relationship. The paper additionally is the first to make the connection between counterfactual explanations and adversarial attacks, and leveraging the two together to perform a task."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The novelty or originality of the paper is a strength. This work is the first to make the connection between the techniques and goals of adversarial attacks and counterfactual explanations. Both involve either making or examining the minimal changes that can be made to a graph to change the outcome of a prediction made on that graph or its nodes. The paper leverages and highlights the similarity of the two methods in terms of objective to alter predictions and their approach of minimal alterations to the graph and consolidates them in order to improve on counterfactual explanations giving rise to their ATEX-CF framework. The usage of node deletion from traditional factual explanation generation and node addition from adversarial attacks enables the graph to capture previously missing relationships within the graph, by providing edges between nodes that have a plausible relation, and allows counterfactual explanations to overcome some limitations it previously faced with only node deletions such as overlooking the possibility of edges already missing within the graph. In addition to this, the paper incorporates sparsity and plausibility constraints into the framework in order to effectively add nodes into the graph with ATEX-CF. This paper can be significant in the way its method far outperformed other baselines and initiates a conversation of looking at counterfactual explanations with adversarial attacks and bridges a gap between the two topics which have evolved in isolation.\n\nThe quality of the paper does not lack either, it is a good quality paper, providing mathematical/theoretical backing for the proposed method ATEX-CF which is sound and logical and clearly sets up the problem definition and notation in section 2 so that the reader can follow along for the subsequent sections. The paper presents a quite comprehensive appendix to follow up on derivations of propositions in the paper and theory is formatted so that it is easy to read and follow. The paper is nicely structured such that the sections slowly build on and introduce the components involved in the ATEX-CF framework and the preliminary concepts and intuition for the framework are ordered so that the reader understands how the method is being developed. Also the inclusion of figures depicting the overall framework or examples of the interactions between nodes and edges help the reader gain intuition on the problem and solution being proposed by the paper. The framework employs preexisting techniques to tackle the defined problem such as GOttack which helps to generate candidate edges that would be used in adversarial attacks. Additionally, the authors make the source code involved available for others to reproduce the experiment and results. The experiments are performed on both synthetic and real world datasets demonstrating the ability of ATEX-CF to perform in real world situations and the usage of known benchmarking datasets/methods helps contextualize the performance of ATEX-CF. The experiment results support the notion of the proposed method’s effectiveness as it is able to outperform the baselines with the best (lowest) overall rank and wins 18/25 of the datasets, while other baselines don’t come close to this performance. Additionally, an ablation study is done to examine the effects of toggling different loss components in ATEX-CF and help outline what component influences the performance of the framework in a certain manner."}, "weaknesses": {"value": "A minor weakness would be while the paper does mention the limitations to this study being the assumption of addition and deletion of edges in the graph always being possible when really, it may not be possible in some real world graphs, which would be the end goal of the framework to perform on, the limitation is only disclosed in the appendix. The paper would benefit from disclosing this information in the actual paper and providing some discussion on the limitation would inform the readers and allow them to understand the state of ATEX-CF. Although it is good to gear a future step towards eliminating this limitation which is mentioned in the section of the limitation in the appendix."}, "questions": {"value": "What is the future with this framework or research, what are some future directions to take this or what further implications can be gleaned from this work?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ng02EIvjMT", "forum": "J1NITEU3Ng", "replyto": "J1NITEU3Ng", "signatures": ["ICLR.cc/2026/Conference/Submission18994/Reviewer_M2c7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18994/Reviewer_M2c7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18994/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761680646049, "cdate": 1761680646049, "tmdate": 1762931047282, "mdate": 1762931047282, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose ATEX-CF, a counterfactual explainer for GNNs that leverages adversarial insights by allowing both edge additions (common in attacks) and deletions (common in counterfactuals). This increases flip probability under a small perturbation budget and aids interpretability: deletions assess the impact of existing connections, additions probe plausible new ones. The objective balances flip, sparsity, and plausibility, with plausibility penalizing degree and local motif jumps. Experiments span BA-SHAPES, TREE-CYCLES, Loan-Decision, Cora, and ogbn-arxiv."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Originality: The paper connects adversarial edge additions to counterfactual generation, which usually uses edge deletions instead.\n- Solid optimization mechanics: The paper involves signed mask with ternary forward discretization, top-κ budget, and minimality-aware pruning that reduces edits/runtime while preserving flips/plausibility.\n- Reproducibility and robustness checks: Code and configs released with means/SDs across seeds; sensitivity and pruning analyses quantify stability and efficiency."}, "weaknesses": {"value": "- Theory: “Hypothesis 1” is asserted as “proved” in the appendix but functions more as an assumption tied to empirical overlap; this weakens guarantees.\n- Plausibility metric is coarse: degree/clustering penalties may not capture domain constraints like temporal or type compatibility; evaluation reuses the same surrogate.\n- Dependence on attack generator: Candidate additions come from GOttack; robustness to this choice and ablations vs. simpler heuristics are unclear.\n- Scope: Only node classification; no feature-perturbation counterfactuals; limited real-world user studies for “plausibility.”\n(regarding format: Related Work is in Appendix A.2, not a proper main-text section)"}, "questions": {"value": "- How sensitive are results to the attack method? It would be interesting to replace GOttack with random-orbit, k-hop heuristics, or Nettack-style candidates and report deltas.\n- Why optimize an implausibility loss instead of pruning edits that violate constraints? It would be interesting to compare both.\n- Please report full metrics for each dataset (not only average ranks) for all κ values,, and include confidence intervals where missing.\n- Section 3 cites structural evasion. Why does the paper focus on it specifically? It would be interesting to discuss other attack types and whether conclusions change."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FGDp6ULKTK", "forum": "J1NITEU3Ng", "replyto": "J1NITEU3Ng", "signatures": ["ICLR.cc/2026/Conference/Submission18994/Reviewer_GcK9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18994/Reviewer_GcK9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18994/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761884923345, "cdate": 1761884923345, "tmdate": 1762931046783, "mdate": 1762931046783, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper claims that existing counter-factual (CF) explanation methods for GNNs mainly focus on edge removing, while largely overlooking edge adding as a perturbation method. They explained (with examples) why edge adding is also important in counter-factual explanation, and also showed that GNN attack methods often employ edge adding as a perturbation method. Motivated by this, they combine edge removing (in conventional CF-Explaination methods) with edge adding (in GNN attack scenarios) to obtain a new method for GNN CF-explanation. Next, they perform experiments to study the effectiveness. While the idea looks interesting, I have some concerns regarding some claims and the experiment studies (please the weak points)."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The idea is interesting. While some recent work also considered edge adding, it is still novel to use GNN attack as a source of obtaining edges to add;\n2. The paper is easy to follow as they spent many efforts to motivate their research and explain their methodology. However, the space left for the experiments looks relatively too short (this can be improved);\n3. The related work section (though in the appendix) is very detailed."}, "weaknesses": {"value": "The experiments are not convincing due to two facts:\n\n1. They considered very limited baselines. Particularly, as a CF-explanation method, they only considered one method (CF-GNNExplainer) as a baseline. However, there are so many other CF-explanation methods (they also reviewed these methods in related work), including RCExplainer, GNN-MOExp, CF$^2$, NSEG, Banzhaf, CF-GFExplainer; INDUCE, C2Explainer, CLEAR, GCFExplainer, etc. (Actions: add more baselines in this category)\n\n2. The datasets considered are limited and may be flawed. They considered only five datasets, including BA-SHAPES, TREE-CYCLES, Loan-Decision, Cora, ogbn-arxiv. Besides, as pointed in [1], the explanations given in these datasets might not be reliable, using wrong/unreliable ground-truth to evaluate GNN explanation methods is not convincing [2]. (Actions: Discussion on potential issues of these datasets, adding more real or synthetic datasets)\n\nBesides, the authors claim that ``ATEX-CF generates explanations that are not only faithful but also informative.\" Without solving these potential flaws in the dataset, it is hard to say whether the explanations are \"faithful\". Moreover, without a real use-case, it is hard to judge whether the explanation is \"informative\". (Actions: investigating and solving/mitigating flaws in these datasets, providing a use-case)\n\nMoreover, although the authors have considered using plausibility loss to prevent generating out-of-distribution explanations, the OOD problem is actually very domain-specific. Avoiding implausible degree jumps and implausible clustering jumps (namely these techniques used in the paper) can only slightly mitigate these issues. (Actions: I would like to see more discussions regarding this and maybe other solutions to avoid generating OOD explanations).\n\n\n## Reference\n\n[1] Agarwal, Chirag, Owen Queen, Himabindu Lakkaraju, and Marinka Zitnik. \"Evaluating explainability for graph neural networks.\" Scientific Data 10, no. 1 (2023): 144.\n\n[2] Faber, Lukas, Amin K. Moghaddam, and Roger Wattenhofer. \"When comparing to ground truth is wrong: On evaluating gnn explanation methods.\" In Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining, pp. 332-341. 2021."}, "questions": {"value": "Please see the weak points."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RiybRX2v42", "forum": "J1NITEU3Ng", "replyto": "J1NITEU3Ng", "signatures": ["ICLR.cc/2026/Conference/Submission18994/Reviewer_wuaS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18994/Reviewer_wuaS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18994/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761911019650, "cdate": 1761911019650, "tmdate": 1762931046287, "mdate": 1762931046287, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses a key limitation in GNN counterfactual (CF) explanations, CF methods relying only on edge deletion often cannot find a counterfactual, especially when the prediction hinges on the absence of certain edges. The authors propose ATEX-CF, a hybrid framework that intelligently combines edge additions and deletions. It first uses an adversarial attack (GOttack) to identify impactful candidate additions and then jointly optimizes both additions and deletions. It also prunes the resulting edits for minimality. The authors theoretically prove situations where deletions fail , and empirically show deletion only methods frequently fail on some datasets. Across synthetic and real world benchmarks (like Cora and ogbn-arxiv), ATEX-CF demonstrated higher flip rates with fewer, more plausible edits than existing CF and attack baseline."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Strong theoretical and empirical evidence justifies including edge additions for counterfactual explainability.\n2. The attack guided candidate generation is innovative; the signed mask, STE, and pruning pipeline coherently addresses both search efficiency and plausibility.\n3. ATEX-CF achieves higher flip rates using fewer, more plausible edits across various datasets and GNN models.\n4. The work is framed as the first to bridge GNN adversarial attacks with counterfactual explanations, distinguishing it from prior deletion only or unguided addition methods."}, "weaknesses": {"value": "1. The pipeline is complex and densely explained.\n2. The  additions and deletions are assumed to be equally feasible, asymmetric costs are not explored.\n3. Evaluation misses some recent counterfactual baselines that also permit additions, such as (InduCE: InduCE: Inductive Counterfactual Explanations for Graph Neural Networks | OpenReview ), slightly weakening the claim of empirical dominance.\n4. Released GitHub code is difficult for international researchers to reproduce, as some comments are in different languages other than english.\n5. Novelty claims (bridging attacks and CFs) are specific to GNNs; this conceptual link was explored earlier in other domains (e.g., The Intriguing Relation Between Counterfactual Explanations and Adversarial Examples | Minds and Machines  )."}, "questions": {"value": "* Could you compare against recent non attack guided CF explainers that also use edge additions to isolate the benefit of the “attack informed” step?\n* It would be nice to ablate the candidate generation strategy (e.g., replacing attack guided edges with simpler heuristics such as random sampling, degree based, or feature similarity based candidates) to quantify how much this  guidance  step contributes to the final performance.\n* Can the framework handle domains where additions are infeasible or more expensive than deletions? Have you tried asymmetric action costs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iXNKXcHp1u", "forum": "J1NITEU3Ng", "replyto": "J1NITEU3Ng", "signatures": ["ICLR.cc/2026/Conference/Submission18994/Reviewer_7BBe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18994/Reviewer_7BBe"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18994/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762086387292, "cdate": 1762086387292, "tmdate": 1762931045851, "mdate": 1762931045851, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}