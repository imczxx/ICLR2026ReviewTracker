{"id": "DREMM6MxYg", "number": 5534, "cdate": 1757918450802, "mdate": 1759897968942, "content": {"title": "LLM Hallucination Detection: A Fast Fourier Transform Method Based on Hidden Layer Temporal Signals", "abstract": "Hallucination remains a critical barrier for deploying large language models (LLMs) in reliability-sensitive applications. Existing detection methods largely fall into two categories: factuality checking, which is fundamentally constrained by external knowledge coverage, and static hidden-state analysis, that fails to capture deviations in reasoning dynamics. As a result, their effectiveness and robustness remain limited.\nWe propose HSAD (Hidden Signal Analysis-based Detection), a novel hallucination detection framework that models the temporal dynamics of hidden representations during autoregressive generation. HSAD constructs hidden-layer signals by sampling activations across layers, applies Fast Fourier Transform (FFT) to obtain frequency-domain representations, and extracts the strongest non-DC frequency component as spectral features. Furthermore, by leveraging the autoregressive nature of LLMs, HSAD identifies optimal observation points for effective and reliable detection.\nAcross multiple benchmarks, including TruthfulQA, HSAD achieves over 10 percentage points improvement compared to prior state-of-the-art methods. By integrating reasoning-process modeling with frequency-domain analysis, HSAD establishes a new paradigm for robust hallucination detection in LLMs.", "tldr": "", "keywords": ["Large Language Model; Hallucination Detection; Fast Fourier Transform; Hidden Layer Temporal Signals; Spectral Feature"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/158010a86556f648fa34091e6e5f0c2c0a3e4418.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes HSAD (Hidden Signal Analysis-based Detection), a novel method for detecting hallucinations in large language models (LLMs). The central idea is to treat hidden states across layers as a temporal signal, then apply Fast Fourier Transform (FFT) to capture frequency-domain features. These spectral features are subsequently used to train a classifier for hallucination detection. The method is inspired by human deception detection mechanisms, and the authors show improvements over prior baselines across multiple benchmarks, including TruthfulQA, TriviaQA, SciQ, and NQ Open. Overall, the paper introduces an original perspective on hallucination detection by shifting focus from external factuality checks to the temporal dynamics of hidden representations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe task under study – hallucination detection – is very timely and important.\n2.\tThe idea of applying Fourier analysis to hidden layers, by treating them as temporal signals is intersting.\n3.\tThe method is conceptually elegant."}, "weaknesses": {"value": "1.\tMy main concern with this work, is the justification of Fourier Transform applied. While treating hidden states as temporal signals and applying FFT is a clever idea, the motivation and justification for this choice feel somewhat underdeveloped, and lacks comparison to relevant baselines, I will elaborate.\n- A comparison with a simple linear probe over the best-performing single layer (selected via validation) would be an important baseline. Since this proposed approach also involves learning over features (spectral features), such a comparison is important in my opinion.\n- A comparison with ACT-ViT [1] is also important. ACT-ViT is an architecture that learns over the “entire” internal state of the LLM and could in principle capture similar spectral information by simply learning them. Demonstrating that HSAD outperforms ACT-ViT would highlight the value of the spectral inductive bias, which is the main idea behind this work.\n- There is no qualitative analysis over the spectral features, which I believe is important in this case. More specifically, the paper does not provide illustrative examples or case studies that justify the spectral approach. For instance, as a first step, showing how different semantics lead to distinct spectral signatures, while semantically similar content produces similar frequency patterns, could provide more motivation for the use of spectral features.\n\n2.\tThe experimental scope is narrow. The current evaluation focuses only on hallucination detection in a limited setting. I believe the following setups should be explored as well in this work:\n- Cross-LLM generalization experiments (as in [1]) to examine if there exist robustness across model families.\n- Cross-dataset generalization experiments (as in [1,2]) to test whether spectral features generalize beyond the training data. \nIn my opinion, both of the above would add significant credibility and practical impact to the work, and improve the quality of the paper.\n\nTo summarize, I believe this paper presents an interesting idea. However, in order for it to be ready for acceptance at a top-tier conference, additional work is needed—particularly more comprehensive comparisons with strong baselines and further exploration of details, such as the ones I presented above.\n\n**References:**\n\n[1] Beyond Token Probes: Hallucination Detection via Activation Tensors with ACT-ViT. NeurIPS 2025\n\n[2] LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations. ICLR 2025"}, "questions": {"value": "1.\tHow were the hallucination labels for the datasets collected?\n2.\tYou write that the method is “analogous to the human deception detection mechanism.” This feels like a vague or overstated claim. Could you elaborate on what evidence supports this analogy?\n3.\tThere seems to be a missing citation around Line 110. Could you please add it?\n4.\tIn Equation 5, the notation involving the superscript for “A” is confusing, since it is defined later but not explained when first introduced. Could you clarify this earlier for readability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Y5TSGNfzNZ", "forum": "DREMM6MxYg", "replyto": "DREMM6MxYg", "signatures": ["ICLR.cc/2026/Conference/Submission5534/Reviewer_LXXf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5534/Reviewer_LXXf"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761285548965, "cdate": 1761285548965, "tmdate": 1762918117184, "mdate": 1762918117184, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes **HSAD** (Hidden Signal Analysis–based Detection), a method for hallucination detection in LLMs that treats *cross-layer hidden activations for a chosen token* as a 1-D signal. HSAD concatenates four per-layer vectors (attention output, attention residual, MLP output, and layer output), applies an FFT, and uses the *strongest non-DC frequency component per hidden dimension* as features. An MLP classifies these spectral features as hallucinated vs. not. Labels are formed by thresholding BLEURT similarity between the generated answer and a reference answer. Experiments on TruthfulQA, TriviaQA, SciQ, and NQ-Open with LLaMA-3.1-8B and Qwen-2.5-7B-Instruct report AUROC gains over a set of baselines, with best performance when observing hidden states at the end of the generated answer and when using all layers."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- **(S1)** Cross-layer sampling + FFT is clean and inexpensive to compute. The ``A-end'' observation heuristic is intuitive. \n- **(S2)** On Qwen-2.5-7B-Instruct, HSAD outperforms prior methods on all four datasets. On LLaMA-3.1-8B, improvements are also consistent. \n- **(S3)** The ablation studies contribute some insights about the proposed method. Frequency-domain modeling beats a time-domain variant; performance improves as more layers are included. ``A-end'' observation point works best."}, "weaknesses": {"value": "- **(W1) Lack of clarity/rigor in presentation**:\n    - Terms and notation are used before being formally defined.\n    - Ambiguous use of $A$ for both reference answer (Eq. 11) and the FFT output (Eq. 5). \n    - Disorganized structure: Figures and equations are referenced out of order, with equations cited immediately before they appear.\n    - Frequent misuse of citation commands (should use ‘\\citep’ for parenthetical citations), making sentences awkward to read.\n    - Missing citation on line 110.\n    - The signal varies across *layers for a single token*, not across decoding steps. Calling it ``temporal'' might be rhetorically appealing, but technically confusing, as the paper does not analyze token-time dynamics. Consider clarifying that the axis is *depth-wise*. \n- **(W2) Usefulness** \n    - HSAD needs per-layer activations, limiting utility on closed APIs. \n    - It appears detectors are trained per base model; there’s no explicit cross-model generalization test (train on Qwen, test on LLaMA, or vice versa). That limits practical transfer. \n    - There are no wall-clock/runtime/memory numbers. \n- **(W3)** Ground-truth hallucination labels come from *BLEURT similarity to a reference answer* with an (unspecified) threshold $\\tau$. This conflates *semantic overlap with one gold answer* and *factual correctness*, and can mislabel e.g., valid paraphrases or alternate facts. The paper should justify BLEURT, report $\\tau$, and show robustness to different labelers. \n- **(W4)** The ``theoretical derivations'' are primarily definitions of hidden-state sampling and FFT features; no formal link is given between spectral peaks and hallucination causality. \n- **(W5)** The authors refer to methods, models, and datasets in Section 5 *without citations*. The coverage of related work is also superficial.\n- **(W6)** The paper suggests\n  >Duan et al. Greenblatt et al. (2024) empirically showed distinct hidden states for truthful vs. fabricated responses, while Zhou et al. He et al. (2024a) applied Fourier analysis to reveal frequency-domain features.\n  \n  However, the authors do not claim how their work differs from these works. More importantly, He et al. (2024a) does not apply Fourier transform at al, and ``Zhou et al'' is not a proper citation.\n- **(W7)** LLM USAGE STATEMENT is missing."}, "questions": {"value": "- **(Q1)** What is the novelty of your work compared to other methods that already use FFT to extract frequency-domain features from LLMs?\n- **(Q2)** The term \"Enhanced MLP\" is capitalized as a proper noun, suggesting it's an established method. Either provide a citation if this refers to existing work or remove the capitalization and clearly explain what makes this MLP ``enhanced'' compared to a standard MLP architecture. The current appears to be a standard MLP.\n- **(Q3)** On line 478, the authors claim:\n  >This study not only provides a novel perspective for analyzing the mechanisms of LLM hallucinations but also offers a theoretical foundation \n  \n  Please expand on the theoretical foundation.\n- **(Q4)** The choice to extract only the maximum magnitude non-DC frequency component for each dimension (Eq. 11) seems arbitrary and unconventional. Standard frequency-domain analysis typically selects the *same* frequency bins across all samples to maintain consistent spectral interpretation. Additionally, by taking only the magnitude, the phase component of the FFT is discarded. Is there a theoretical or empirical justification for this design choice? \n- **(Q5)** What BLEURT threshold $\\tau$ did you use, and how sensitive are results to $\\tau$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "FJeVEQhmTT", "forum": "DREMM6MxYg", "replyto": "DREMM6MxYg", "signatures": ["ICLR.cc/2026/Conference/Submission5534/Reviewer_LqKE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5534/Reviewer_LqKE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761753169650, "cdate": 1761753169650, "tmdate": 1762918116767, "mdate": 1762918116767, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes HSAD (Hidden Signal Analysis-based Detection), a novel hallucination-detection framework for LLMs. The key idea is to model the hidden activations across transformer layers as a temporal signal and then apply Fast Fourier Transform (FFT) to extract frequency-domain features. The strongest non-DC frequency component across each hidden dimension is used as a signature feature for hallucination detection."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Clear motivation: Pointed critique of knowledge-based detectors and static-state probing approaches \n- Strong empirical performance: Consistent SOTA gains across TruthfulQA, TriviaQA, SciQ,  in AUROC benchmarks"}, "weaknesses": {"value": "- Limited model scale evaluation. Experiments are only conducted on ~7B–8B models; it is unclear whether the method scales effectively to larger foundation models (e.g., 32B, 70B+) or to frontier systems.\n- Training protocol and generalization unclear. The paper does not clearly describe how the hallucination detector is trained, nor whether it generalizes across datasets and base models. For example, can a detector trained on dataset A and model X transfer to dataset B and/or model Y?\n- Potential inference overhead not reported. Extracting hidden activations across all layers and performing FFT may introduce non-trivial latency or memory overhead. The impact on original model inference performance is not measured.\n- Feature choice seems heuristic: Only strongest non-DC frequency magnitude is used; unclear why this specific statistic is theoretically optimal."}, "questions": {"value": "- Scaling to larger models: Have you tested this approach on larger models (e.g., 30B+, 70B+)? Do the spectral signatures change with scale, and does the detector remain effective?\n- Detector training details: How exactly is the detector trained? Is it model-specific or dataset-specific? Can a detector trained on one model/dataset be applied to another without retraining?\n- Cross-model / cross-dataset generalization: If the spectral behavior of hallucinations is fundamental, does HSAD transfer across settings? If not, what are the limits?\n- How is the threshold $\\tau$ in formula 8 selected ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FiSbdSJYDr", "forum": "DREMM6MxYg", "replyto": "DREMM6MxYg", "signatures": ["ICLR.cc/2026/Conference/Submission5534/Reviewer_gNHn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5534/Reviewer_gNHn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931640466, "cdate": 1761931640466, "tmdate": 1762918116287, "mdate": 1762918116287, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces HSAD, a novel method for detecting hallucinations in LLMs. The core idea is to treat the LLM's forward pass as a dynamic system. It constructs a \"hidden layer temporal signal\" by sampling hidden states across layers for a given token. Inspired by human cognitive neuroscience and lie detection, the authors apply a Fast Fourier Transform (FFT) to this signal to extract spectral features. These frequency-domain features are then fed into a supervised classifier to predict whether the LLM's output is a hallucination. The method is evaluated on several factual question-answering (QA) datasets (TruthfulQA, TriviaQA, NQ Open, SciQ), where it reportedly outperforms existing baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The analogy to cognitive neuroscience is intriguing. Applying signal processing techniques like FFT to the \"temporal\" (i.e., cross-layer) dynamics of hidden states is a novel approach that moves beyond static hidden-state analysis.\n\nExperimental results show the effectiveness of their method on certain tasks."}, "weaknesses": {"value": "W1: The evaluation is confined to simplistic tasks that do not reflect modern LLM use cases.\n\nThe paper's entire empirical validation rests on factual QA datasets. I believe this is not a big problem if this paper was submitted two years ago. However, in the year 2025, datasets like TriviaQA and NQ Open are arguably \"solved\" tasks for modern SOTA LLMs and do not represent the frontier of the current hallucination problem.\nThe critical and challenging applications for LLMs today are in long-form generation, complex reasoning, software development, and acting as autonomous agents. In these scenarios, hallucinations are not just simple factual errors but complex logical inconsistencies, fabricated reasoning steps, or non-existent API calls. \n\nIn short, I believe the datasets are too simple and easy, thus successfully detecting hallucination on these easy datasets is not enough for recent AI applications. \n\n\nW2: The \"last token\" observation point is a critical design flaw for long-form generation.\n\nThe method uses only the hidden state of the final generated token as the \"observation point\".\nIn real-world applications, LLMs produce outputs that are hundreds or thousands of tokens long. A hallucination (e.g., a fabricated fact or a bug in a code block) could occur in the first paragraph, and the model's internal state at the final token may have little to no relevant signal reflecting that earlier error.\n\nThis design choice limits the method to a coarse-grained, response-level label (\"this entire 2000-token output is a hallucination: Yes/No\"), which is of little practical use. For applications like agents or coding, real-time, token-level hallucination detection is essential to pinpoint where the model deviates from a faithful trajectory. The proposed method is incapable of providing this necessary granularity.\n\n\nW3: Critical and highly relevant baselines are missing.\n\nThe paper fails to compare against the most relevant category of competing methods. While it includes some baselines, it omits methods that also use internal states.\n\nSpecifically, a significant body of work (e.g., \"Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models\") develops classifiers that operate directly on the contextualized embeddings (hidden states) of each token in real-time. \n\nComparing HSAD against such a baseline would provide a direct ablation to prove that the proposed FFT-based \"spectral features\" are meaningfully more effective than using the \"spatial/temporal\" hidden-state features directly. \nFurthermore, many of these internal-state-based hallucination detection methods are unsupervised. Comparing a supervised method (HSAD) against SOTA unsupervised methods is a standard and necessary practice to quantify the performance gains achieved by leveraging labeled data.\n\nI am open to increasing my score if the authors address this W3"}, "questions": {"value": "Please refer to the previous section"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "8GVvtIFgJK", "forum": "DREMM6MxYg", "replyto": "DREMM6MxYg", "signatures": ["ICLR.cc/2026/Conference/Submission5534/Reviewer_UiPJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5534/Reviewer_UiPJ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5534/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762013857704, "cdate": 1762013857704, "tmdate": 1762918115892, "mdate": 1762918115892, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}