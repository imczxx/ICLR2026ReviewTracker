{"id": "6fD38Rnmwu", "number": 16007, "cdate": 1758258545000, "mdate": 1759897267761, "content": {"title": "LOAT: Latent-Order Adversarial Training for Efficient and Transferable Robustness", "abstract": "Adversarial training remains computationally prohibitive due to the uniform application of expensive PGD (projected gradient descent) attacks across all training samples. Although prior works identify ``hard'' samples deserving of more computational effort, such approaches require supervised definitions of difficulty and do not capture the complex dynamics of how neural networks naturally learn robust representations. We present Latent-Order Adversarial Training (LOAT), a novel unsupervised method that discovers the emergent structure in adversarial training. It clusters adversarial dynamics using multiple complementary feature views to cluster structural similarities and identify an adaptive path of compatible learned dynamics to more efficiently train sub-models via a generalized set of probabilistic choices. By combining the inherent descriptors in an evolutionary learning model, LOAT creates a global model to transfer a transition matrix $T$ that captures empirical patterns of how training naturally flows between clusters. Experiments on CIFAR-10 demonstrate that this discovered structure can efficiently and adaptively allocate PGD steps per cluster, following the learned transition, reducing computational cost by 40-50\\% while maintaining comparable or better robustness. The transferable global structure of our algorithm contains learnable generalizable patterns independent of potentially biased human notions. LOAT shows that respecting intrinsic dynamics yields significant efficiency gains without sacrificing robustness.", "tldr": "The paper creates a novel teacher-student model used in adversarial training that captures latent ordering in an adaptive and efficient manner.", "keywords": ["adversarial training"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3aad01db7745a9b3bfdd4008e4d71661e2da2ef9.pdf", "supplementary_material": "/attachment/1feee0834c5b96f6c30379ab3199096dd0c34e2e.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Latent-Order Adversarial Training (LOAT), an unsupervised method for improving the computational efficiency of adversarial training. The approach consists of two phases: (1) a teacher model that discovers latent structure in adversarial training dynamics through multi-view clustering and learns a transition matrix capturing sample progression patterns, and (2) a student model that leverages this transferred knowledge to adaptively allocate PGD attack budgets per cluster. Experiments on CIFAR-10 with ResNet-18 demonstrate 40-50% reduction in computational cost while maintaining comparable robustness to baseline adversarial training."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. **Novel unsupervised approach:** The paper presents an interesting perspective by discovering latent structure in adversarial training dynamics rather than relying on supervised hardness metrics. The multi-view feature extraction combining statistics, geometry, confidence patterns, and adversarial dynamics is comprehensive.\n\n2. **Practical efficiency gains:** Demonstrated reduction in PGD calls (from ~4.7M to ~1.9M) while maintaining reasonable robustness represents meaningful computational savings for deployment scenarios.\n\n3. **Teacher-student framework:** The transferable nature of the learned structure is valuable for edge deployment scenarios with limited computational resources.\n\n4. **Thorough feature engineering:** The integration of eight complementary feature views (statistics, geometry, confidence, adversarial dynamics, gradient coherence, activations, consistency, loss landscape) provides a rich representation for clustering."}, "weaknesses": {"value": "1. **Limited experimental scope:**\n- Only evaluated on CIFAR-10 with ResNet-18, which significantly limits claims about generalizability\n- No experiments on CIFAR-100, ImageNet subsets, or other architectures (e.g., WideResNet, which is standard in adversarial training literature)\n\n2. **Weak evaluation setup:**\n- The evaluation relies on using only PGD 20 attack.\n- AutoAttack evaluation should be standard and fully reported, not an afterthought\n\n3. **Methodological concerns:**\n-The choice of 5 clusters appears arbitrary with insufficient justification\n- Authors mention \"three clusters did not\" provide meaningful differentiation but don't show this empirically\n- The differential evolution optimization for feature weights (Eq. 9-10) lacks details on convergence criteria, population size, and sensitivity analysis\n\n4. Presentation and clarity:\n- The paper introduces many components (SimCLR, autoencoder, 8 feature views, differential evolution, UCB, transition matrix) making it difficult to assess which components are essential\n- I personally felt that the paper was very hard to parse as it felt like you were throwing around words with no concern or explanation."}, "questions": {"value": "1. Transition matrix:\n- You mention that \"T[i,j] representing the pedagogical value of teaching cluster i before cluster j\", could you explain how transition probability would provide this information.\n\n2. Why does removing clusters improve efficiency? If clusters capture meaningful structure, removing them should hurt performance. The explanation about \"negative transfer\" suggests the clustering may not be working as intended. Can you provide more insight into what these clusters actually represent? Also, since you have a measure of difficulty of learning a cluster, was there any correlation between the accuracies reported for removal and the difficulty profile? \n\n3. How sensitive is the method to the number of clusters? You mention 3 clusters didn't work and suggest trying 7+. What systematic analysis guided the choice of 5?\n\n4. Can you ablate individual components? It's unclear which of the many components (multi-view features, transition matrix, UCB selection, cluster-adaptive budgets) drive the gains."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lwF6vUs0aD", "forum": "6fD38Rnmwu", "replyto": "6fD38Rnmwu", "signatures": ["ICLR.cc/2026/Conference/Submission16007/Reviewer_wb4e"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16007/Reviewer_wb4e"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890777351, "cdate": 1761890777351, "tmdate": 1762926213795, "mdate": 1762926213795, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Latent-Order Adversarial Training (LOAT), a method that aims to make adversarial training more efficient by discovering a natural learning structure instead of relying on predefined notions of ‚Äúhardness.‚Äù The approach uses a two-phase teacher‚Äìstudent pipeline. In the first phase, a ‚Äúteacher‚Äù model clusters training samples based on diverse features (loss, gradient geometry, etc.) and constructs a transition matrix (T) that represents the natural progression between clusters. In the second phase, a ‚Äústudent‚Äù model trains more efficiently by following this discovered structure, adapting the number of PGD steps per cluster. On CIFAR-10, LOAT reportedly reduces computation by around 40‚Äì50% while maintaining similar robustness. However, the results suggest that most of the gains come from clustering and adaptive budgets, rather than from the latent ordering (T matrix) itself. The claimed ‚Äúlatent order‚Äù contribution remains unproven, as ablations show comparable or even better performance without it."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "I like the idea of going from 'hard' to 'natural learning structure'. \nThe teacher‚Äôs discovery mechanism is clever, using multiple features and an evolutionary search strategy to build clusters and transitions.\nThe proposed teacher‚Äìstudent framework is practical. The heavy computation is done once by the teacher, allowing efficient student training that generalizes well.\nLOAT achieves notable efficiency improvements compared to standard adversarial training and even surpasses Free-AT in efficiency scores (e.g., 0.01559 vs. 0.01278).\nThe paper is clearly written, with well-organized sections and good explanations of motivation and related work."}, "weaknesses": {"value": "1. Only PGD-20 results are reported, while AutoAttack results are mentioned but not provided. For a robustness-focused paper, this omission weakens the empirical credibility.\n2. It would be good to discuss the work on adversarial training given in the following paper. Chhipa, Prakash Chandra, et al. \"ASTRA: adversarial self-supervised training with adaptive-attacks.\" The Thirteenth International Conference on Learning Representations. 2025.\n3. If i understood it well, In Table 4, removing Cluster 1 yields better efficiency than the full model. Why did the teacher not identify and exclude this cluster during discovery? Does this suggest the optimization or curriculum limitations?\n4. How was the number of clusters (five) selected, and what happens when varying it? Does the problematic cluster disappear with a different configuration?"}, "questions": {"value": "Please follow the strengths and weaknesses.\n\nI am open to revising my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DAH97zLnVD", "forum": "6fD38Rnmwu", "replyto": "6fD38Rnmwu", "signatures": ["ICLR.cc/2026/Conference/Submission16007/Reviewer_Ujf8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16007/Reviewer_Ujf8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915978232, "cdate": 1761915978232, "tmdate": 1762926213519, "mdate": 1762926213519, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Latent-Order Adversarial Training (LOAT), a two-phase teacher‚Äìstudent framework for adversarial training. In Phase 1 (teacher), the authors train with TRADES and explicitly add (i) a SimCLR pre-training stage and (ii) an adversarially trained autoencoder to obtain ‚Äúrobust‚Äù latent embeddings, then discover multi-view cluster structure and a cluster-transition matrix T. In Phase 2 (student), a UCB-style scheduler allocates attack budgets per cluster, aiming to reduce total PGD calls while keeping robust accuracy. Experiments are on CIFAR-10 under $l_\\infty$ $\\epsilon$=8/255, reporting improved robust-per-compute efficiency against a 10-epoch PGD baseline and Free-AT."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1.\tInteresting unsupervised curriculum discovery. The paper comprises eight complementary ‚Äúviews‚Äù (statistics, geometry, confidence, adversarial dynamics, gradient coherence, activations, consistency, loss-landscape) and learns view weights via differential evolution before clustering. The method then exports a compact ‚Äúrecipe‚Äù to the student.\n2.\tClear efficiency metric. The paper defines efficiency as robust accuracy divided by PGD calls (in millions), enabling apples-to-apples comparisons when attack steps differ."}, "weaknesses": {"value": "1.\tFairness/accounting of extra training (teacher + pretraining). The teacher pipeline includes 50 epochs of SimCLR and 20 epochs of adversarial-autoencoder training before discovery and TRADES-based AT. The paper also reports the teacher required 12.78M PGD calls with intentionally low efficiency during model building. However, the main comparison tables report student ‚ÄúTraining Calls‚Äù and efficiency without adding the teacher‚Äôs costs; this inflates LOAT‚Äôs end-to-end advantage versus baselines that do not require any teacher or pretraining. At minimum, the paper should present (a) full costs (teacher + student) for a single deployment and (b) amortized costs if the recipe is reused across students, reporting the break-even ùëÄ.\n2.\tPretraining advantage not controlled. Because LOAT‚Äôs student benefits from SimCLR + adversarial-AE features distilled by the teacher, strict fairness requires giving baselines the same initialization (or an equivalent pretraining pipeline) and then comparing compute-normalized robustness. The current tables do not indicate such controls, so part of the reported gain may stem from stronger initial representations rather than the latent-order scheduling itself.\n3.\tScope and strength of evaluation. (1) Dataset/backbone breadth. All results are on CIFAR-10 (teacher: ResNet-18; student: 10-epoch runs). Claims about ‚Äútransferable global structure‚Äù would be much more convincing with cross-dataset (e.g., CIFAR-100, Tiny-ImageNet) and cross-backbone transfer. (2) Attack protocol. Robustness is primarily reported under PGD-20 with restarts, with AutoAttack used only on a few checkpoints and not tabulated. Given the risk of PGD-specific overfitting, the paper should report standard AA across all methods. (3) Effect sizes vs simple schedulers. The efficiency gap between LOAT (no-reuse) and Uniform is small in Table 3 (0.01559 vs 0.01555), despite statistical significance. The practical significance is unclear without wall-clock time (and including teacher overhead)."}, "questions": {"value": "1.\tReport end-to-end and amortized costs. Provide results that (i) include teacher cost in PGD-call totals and (ii) amortize that cost across multiple students to show realistic deployment scenarios.\n2.\tControl for pretraining. Initialize Free-AT, PGD-AT/TRADES, and ‚ÄúUniform‚Äù with the same SimCLR + adversarial-AE representations (or provide ablations removing these components in LOAT) to isolate the marginal contribution of latent-order scheduling. \n3.\tBroaden evaluation. Add CIFAR-100/Tiny-ImageNet and a second backbone for both teacher and student to support transferability claims.\n4.\tAttack-agnostic evaluation. Tabulate standard AutoAttack for all methods to mitigate masking concerns inferred from PGD-20-only reporting.\n5.\tClarify components and sensitivities. Provide precise definitions/costs for each ‚Äúview,‚Äù sensitivity to the number of clusters K, UCB hyperparameters, and ablate the recipe reuse mechanism."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6aGWORzvbO", "forum": "6fD38Rnmwu", "replyto": "6fD38Rnmwu", "signatures": ["ICLR.cc/2026/Conference/Submission16007/Reviewer_uQwB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16007/Reviewer_uQwB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923878939, "cdate": 1761923878939, "tmdate": 1762926213156, "mdate": 1762926213156, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents Latent-Order Adversarial Training (LOAT), an unsupervised approach for improving computational efficiency in adversarial training. The method employs a teacher-student framework where the teacher model identifies emergent clustering patterns in adversarial training dynamics using multiple complementary feature views. A transition matrix T is learned to capture empirical patterns of how training naturally flows between clusters. The student model then uses this transferred knowledge to adaptively allocate PGD attack steps per cluster. Experiments on CIFAR-10 demonstrate that LOAT can reduce computational cost by 40-50% while maintaining comparable or better robustness compared to baseline methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces a multi-view feature learning framework that analyzes adversarial training dynamics through complementary feature perspectives. It enables automatic discovery and utilization of inherent training orderings without relying on predefined difficulty labels, offering a novel curriculum design paradigm for adversarial training.\n2. The framework adopts a teacher-student architecture, decoupling the complex discovery process (teacher) from the efficient training phase (student). This modular design enhances scalability and broadens applicability across diverse machine learning tasks.\n3. The paper proposes a formalized efficiency metric that normalizes model robustness by computational cost, enabling systematic and fair comparison across adversarial training methods."}, "weaknesses": {"value": "1. Reproducibility of Teacher Training: \nThe description of the teacher-training pipeline in Chapter 5‚Äîespecially the joint use of SimCLR and an autoencoder‚Äîomits architectural specifications, loss combinations, and parameter-update protocols. Could you supply a complete, reproducible account of the training objective, network architectures, data flow, and the precise mechanism that converts per-sample PGD-step counts into supervisory signals?\n\n2. Validity of the Efficiency Metric under Performance Mismatch: \nYour metric E = Robust Accuracy / PGD Calls is used to claim superior efficiency, yet both standard and robust accuracies lag well behind baseline methods. Since any fair efficiency comparison must first guarantee equivalent predictive performance, how do you justify reporting efficiency gains while ignoring this prerequisite, and what is your rationale for foregrounding computational savings over the substantial drops in accuracy and robustness?\n\n3. Generalizability and Component Necessity: \nExperiments are restricted to CIFAR-10 and lightweight architectures, with no ablation evidence that the teacher‚Äìstudent split, transition matrix, or sample reordering individually contributes to the final result. How do you expect the method to scale to larger datasets (e.g., CIFAR-100, ImageNet) or deeper networks, and can you provide ablation results that demonstrate each component is necessary?\n\n4. Full-Cost Efficiency Analysis: \nThe efficiency claim tallies only the student‚Äôs PGD calls, ignoring the teacher‚Äôs SimCLR/autoencoder training, attack-step logging, and cluster-discovery phases. Could you present a comprehensive lifecycle accounting that aggregates every FLOP or GPU-hour spent‚Äîfrom teacher pre-training to student graduation‚Äîand explain how the claimed efficiency advantage withstands this complete cost picture?"}, "questions": {"value": "See weaknesses for details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "EK8QhrrUee", "forum": "6fD38Rnmwu", "replyto": "6fD38Rnmwu", "signatures": ["ICLR.cc/2026/Conference/Submission16007/Reviewer_gAz4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16007/Reviewer_gAz4"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16007/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970747748, "cdate": 1761970747748, "tmdate": 1762926212677, "mdate": 1762926212677, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}