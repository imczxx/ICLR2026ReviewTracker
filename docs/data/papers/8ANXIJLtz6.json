{"id": "8ANXIJLtz6", "number": 12921, "cdate": 1758211673011, "mdate": 1759897476456, "content": {"title": "LANO: Large Language Models as Active Annotation Agents for Open-World Node Classification", "abstract": "Node classification is a fundamental task in graph learning. While Graph Neural Networks (GNNs) have achieved remarkable success in this area, their effectiveness relies heavily on large amounts of high-quality labels, which are costly to obtain. Moreover, GNNs are typically developed under a closed-world assumption, where all nodes belong to a fixed set of categories. In contrast, real-world graphs follow an open-world setting, where newly emerging nodes often stem from out-of-distribution (OOD) classes, making it challenging for GNNs to generalize. Motivated by the strong zero-shot reasoning and generalization ability of Large Language Models (LLMs), we propose LANO (LLMs as Active Annotation Agents for Open-World Node Classification). Our framework first aligns GNN representations with LLM token embeddings via instance-aware and feature-aware self-supervised learning, enabling LLMs to serve as zero-shot predictors for graph tasks. LANO then employs an influence- and uncertainty-driven strategy to select the most representative nodes and leverages LLMs for cost-effective pseudo-label generation. To suppress the spread of inaccurate labels and mitigate labeling bias, a soft feedback propagation mechanism disseminates bias-reduced pseudo labels to neighboring nodes with label decay mechanism, followed by iterative GNN optimization. Extensive experiments on multiple benchmarks demonstrate that LANO consistently outperforms popular baselines, showcasing the great potential of LLMs as active annotation agents for advancing open-world graph learning.", "tldr": "", "keywords": ["Node Classification", "Open-world Graph Learning", "Large Language Models"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/36f96ace9831e7d91ec3a4ec8558cb0350141f1a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes LANO, a framework that leverages LLM as active annotation agents for open-world semi-supervised node classification. The method aims to reduce reliance on expensive, high-quality predefined labels by aligning GNN and LLM representations, selecting informative nodes for LLM annotation, and propagating bias-reduced pseudo-labels for iterative GNN training. Experimental results show performance gains over baselines, suggesting that the approach positively impacts open-world scenarios."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The idea of using LLMs as active annotation agents for graph learning is timely and relevant, especially for open-world (novel/unseen class) scenarios.\n2. The paper addresses a real deployment issue (label scarcity and emergent classes), and therefore has clear potential practical value."}, "weaknesses": {"value": "1. Limited novelty and insufficient experiments.  \nUsing LLMs for label generation or annotation assistance has already been explored in prior work. The paper does not clearly articulate what is fundamentally new compared with existing LLM-assisted methods. Conversely, if the main contribution lies in proposing a new framework for LLM utilization, the paper fails to position LANO precisely within related work.  \nIn particular, the only baseline table (from OpenIMA) is not LLM-based. A fair comparison should incorporate LLM-GNN baselines and ablations over different LLM choices, similar to [1].\n\n2. Paper quality and presentation.  \nThe paper contains numerous typographical errors, inconsistent notations, and several malformed or ambiguous equations (including but not limited to detailed list below). These issues significantly reduce readability and raise concerns about correctness and reproducibility.  \n(1) Line 041: “... high-quality labeled, ...” -> should be “high-quality labeled data, ...”  \n(2) Line 126: The explanation for statement $C_l \\cap C_u \\neq \\varnothing$ is misleading. In the source paper [2], $C_u$​ denotes \"the set of classes associated with the nodes in $V_u$\", which is similar but completely different from \"the classes of unlabeled nodes\" as described here. The explanatory sentences are therefore incorrect and must be rewritten to match the formal definitions.  \n(3) Line 127: The adjacency matrix A is referenced, but the graph definition $G=(V,E,X)$ in line 105 does not include A. The usage of A (e.g., how $\\tilde{A}$ is perturbed), probably taken from [3], is also missing. This inconsistency appears inherited from the differnet source papers and not properly corrected.\n(4) Line 133: The subscript $u$ is reused in Eq. (1), where it previously denoted the \"unlabeled set\". Reusing the same symbol for different meanings causes confusion.  \n(5) Line 183: The formatting of Eq. (4) is corrupted.  \n(6) Line 188: Ungrammatical sentence: “To bridge the gap ..., the goal is to ensure...”  \n(7) Figure 4: Lacks clarification and is difficult to interpret. The comparison with different ground truths also appears unfair.  \n\n[1] Wu X, Shen Y, Ge F, et al. When Do LLMs Help With Node Classification? A Comprehensive Analysis[J]. arXiv preprint arXiv:2502.00829, 2025.  \n[2] Wang Y, Zhang J, Zhang L, et al. Open-world semi-supervised learning for node classification[C]//2024 IEEE 40th International Conference on Data Engineering (ICDE). IEEE, 2024: 2723-2736.  \n[3] Wang D, Zuo Y, Li F, et al. Llms as zero-shot graph learners: Alignment of gnn representations with llm token embeddings[J]. Advances in Neural Information Processing Systems, 2024, 37: 5950-5973."}, "questions": {"value": "1. “Two views” in Fig. 2 are not explained in the text. Please clarify what the perturbed views refer to and how they function.  \n2. Eqs. (4) and (5) appear to be modified from (Wang et al. 2024a) with parts of the denominator removed. Why were those terms deleted, as this might affect numerical stability and the behavior of contrastive learning?  \n3. Figure 4 inconsistency. The figure appears to depict a 2×3 grid (two datasets × three label variants: GT / OpenIMA / LANO) but actually contains eight subplots. Why are there duplicated ground-truth plots for the same dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "h1bLJ5T4Rr", "forum": "8ANXIJLtz6", "replyto": "8ANXIJLtz6", "signatures": ["ICLR.cc/2026/Conference/Submission12921/Reviewer_cF53"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12921/Reviewer_cF53"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761135435505, "cdate": 1761135435505, "tmdate": 1762923690619, "mdate": 1762923690619, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper leverages LLMs as zero-shot predictors for open-world node classification. The framework first aligns GNN representations with LLM token embeddings via instance-aware and feature-aware self-supervised learning. Then the paper employs influence- and uncertainty-driven strategies to select representative nodes and leverages LLMs for cost-effective pseudo-label generation. The paper also conducts extensive experiments on benchmark datasets, and the results sound the good performance of the proposed framework."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1- The paper leverages the zero-shot capacities of LLMs for open-world node classification. The motivation is fresh.\n\nS2- The paper aligns the GNN representations with LLM token embeddings. The alignment sounds reasonable.\n\nS3- The results on the benchmark datasets sounds the proposed methods achieve better performance compared with baselines.\n\nS4- The paper is well-written and easy to follow."}, "weaknesses": {"value": "W1- The prompt for the LLM annotations if not detailed. It is suggested for better explain the motivation and how to construct the prompt for the task.\n\nW2- It is suggested to add the scaling factor for in the equation 14 in the parameter sensitivity analysis.\n\nW3- It is recommended to provide a table in the appendix that lists all important notations and their definitions. This would significantly improve the paper's readability and help readers better understand the equations.\n\nW4- There are some typos. For example, in figure 3, the horizontal axis denotes LLM tau. It is suggested to replace with the notation $\\tau$ for better understanding."}, "questions": {"value": "Q1- What is the soft feedback propagation strategy, it is better to explain the strategy in a more detailed way.\n\nQ2- How to calculate the influence quality $r_{v_i}$ in the equation 8. Is the parameter predefined of dynamic changes through the training process?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "SuoFJyjQhJ", "forum": "8ANXIJLtz6", "replyto": "8ANXIJLtz6", "signatures": ["ICLR.cc/2026/Conference/Submission12921/Reviewer_QJvH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12921/Reviewer_QJvH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979681727, "cdate": 1761979681727, "tmdate": 1762923690047, "mdate": 1762923690047, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the problem of leveraging LLMs for open world node classification. It aligns graph node embeddings with an LLM space, queries the LLM only on a small set of high value nodes selected by influence and uncertainty, and then propagates the LLM’s soft labels across the graph with safeguards to limit noise. On five benchmark graphs, LANO improves overall, seen, and especially novel class accuracy over strong open world baselines, and ablations show that removing LLMs or the selection strategy hurts performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The studied problem of open-world node classificaiton is important; using LLMs as flexible annotators to cover those emerging classes is a natural and well motivated direction.\n2. The proposed framele work is reasonable with each step supporting the next one.\n3. The reported gains over recent open world graph learners indicate that LLM supervision actually improves recognition of novel classes."}, "weaknesses": {"value": "1. All evaluations are on relatively small and standard academic benchmarks. These are useful for controlled studies, but they may not stress test scalability like larger graph benchmarks such as those in OGB. Without such results it is hard to judge how the method behaves on real world sizes.\n2. While the paper compares to many open world or open intent graph baselines, it does not run against the newest lines of work that also use LLMs as graph annotators or weak oracles [1]. Since those methods are conceptually closest, omitting them makes it harder to tell how much of the improvement is due to the specific active selection and bias controlled propagation introduced here, and how much is simply the benefit of calling an LLM at all. \n3. The paper does not make the cost of using the LLM explicit. A budget table with number of calls, average prompt length, and wall clock per dataset would make the method much easier to adopt and would clarify its practical limits.\n\n[1] Label-free Node Classification on Graphs with Large Language Models (LLMs). ICLR 2024"}, "questions": {"value": "1. Can the method run on a larger graph (e.g., OGB) without changing the selection strategy?\n2. How many LLM queries did each dataset actually require?\n3. How accurate are the LLM labels by confidence bucket, and how often does the model return “undecidable”?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wpTnnr9ZUN", "forum": "8ANXIJLtz6", "replyto": "8ANXIJLtz6", "signatures": ["ICLR.cc/2026/Conference/Submission12921/Reviewer_31nL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12921/Reviewer_31nL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12921/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762057355043, "cdate": 1762057355043, "tmdate": 1762923689487, "mdate": 1762923689487, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}