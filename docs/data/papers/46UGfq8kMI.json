{"id": "46UGfq8kMI", "number": 7306, "cdate": 1758015015703, "mdate": 1759897860884, "content": {"title": "DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction", "abstract": "The deep-research framework orchestrates external tools to perform complex, multi-step scientific reasoning that exceeds the native limits of a single large language model. However, it still suffers from context pollution, weak evidentiary support, and brittle execution paths.\nTo address these issues, we propose DualResearch, a retrieval and fusion framework that matches the epistemic structure of tool-intensive reasoning by jointly modeling two complementary graphs: a breadth semantic graph that encodes stable background knowledge, and a depth causal graph that captures execution provenance. Each graph has a layer-native relevance function, seed-anchored semantic diffusion for breadth, and causal–semantic path matching with reliability weighting for depth. To reconcile their heterogeneity and query-dependent uncertainty, DualResearch converts per-layer path evidence into answer distributions and fuses them in log space via an entropy-gated rule with global calibration. The fusion up-weights the more certain channel and amplifies agreement.\nAs a complement to deep-research systems, DualResearch compresses lengthy multi-tool execution logs into a concise reasoning graph, and we show that it can reconstruct answers stably and effectively. On the scientific reasoning benchmarks HLE and GPQA, DualResearch achieves competitive performance. Using log files from the open-source system InternAgent, its accuracy improves by 7.7% on HLE and 6.06% on GPQA.", "tldr": "", "keywords": ["DeepResearch", "Graph", "Multi-Agent"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/aca346e891640190ef51e5b90968e5f19dc2fb90.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents DualResearch, a dual-graph retrieval and fusion framework that enhances reasoning systems integrating Large Language Models (LLMs) with external tools. The central idea is to jointly model two sources of evidence: a Breadth Semantic Graph (BG) that captures stable, cross-document background knowledge, and a Depth Causal Graph (DG) that records reliable, execution-based procedural traces from tool interactions. Each graph produces an answer distribution, and these are adaptively fused through an entropy-gated mechanism that calibrates confidence and balances semantic versus causal evidence. Experiments on the Humanity’s Last Exam (HLE) and GPQA-Diamond benchmarks demonstrate consistent improvements over the baseline InternAgent and outperform several recent deep-research systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The separation into breadth (semantic) and depth (causal) graphs seems novel for tool-augmented LLMs.\n- Experimental results on HLE and GPQA benchmarks demonstrate consistent improvements over baseline in different domains.\n- The dual-graph design produces verifiable evidence chains, addressing transparency issues,  which are bottlenecks in current scientific and reasoning-oriented LLM systems."}, "weaknesses": {"value": "- The experiments are restricted to the HLE and GPQA benchmarks. Broader evaluation on datasets such as BrowseComp or GAIA would strengthen the claim of generalizability across domains and tasks.\n- The paper omits several recently released deep-research systems, such as TongYi-DeepResearch and Kimi-Researcher, that were available before submission. Including these would provide a more comprehensive and fair comparison of competitiveness.\n- The proposed framework assumes access to well-structured, high-quality execution logs from agents. In realistic scenarios with noisy or incomplete logs, the system’s performance and stability may degrade, raising concerns about robustness in uncontrolled environments.\n- Building and maintaining dual graphs with per-layer relevance and edge reliability may be computationally intensive for large-scale or streaming research workflows. The paper lacks runtime or scalability analysis to justify feasibility for real-world deployment.\n- While the case studies emphasize successful instances, the paper provides little insight into failure cases, such as when semantic and causal graphs conflict or when entropy gating misjudges evidence balance."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UCuh8ZQc8L", "forum": "46UGfq8kMI", "replyto": "46UGfq8kMI", "signatures": ["ICLR.cc/2026/Conference/Submission7306/Reviewer_63yC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7306/Reviewer_63yC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7306/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761641159192, "cdate": 1761641159192, "tmdate": 1762919422490, "mdate": 1762919422490, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DualResearch which is designed to enhance the reliability and evidence quality of answers generated by multi-step, tool-intensive deep-research systems. The method's core strength lies in jointly modeling two complementary structures: a breadth semantic graph encoding stable background knowledge and a depth causal graph tracking the execution provenance of the reasoning chain.. The authors propose an entropy-gated rule to fuse the distributions from two graphs, which dynamically up-weights the information channel exhibiting higher certainty, thus mitigating context pollution. The experiments  demonstrate stable and effective performance gains on scientific reasoning benchmarks like HLE and GPQA, suggesting DualResearch is a valuable post-processing complement to existing complex reasoning frameworks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "a. The DualSearch framework jointly models a breadth semantic graph and a depth causal graph, capturing both stable background knowledge and reasoning provenance.\n\nb. The critical entropy-gated fusion rule dynamically enhances the reliability of the final answer by prioritizing the information channel (breadth or depth) that exhibits higher certainty, effectively mitigating context pollution and weak evidence.\n\nc. The method achieves stable performance gains on challenging scientific reasoning benchmarks HLE and GPQA by reusing the log of the baselines."}, "weaknesses": {"value": "a. DualResearch is explicitly presented as more of a \"post-processing complement\" to existing deep-research systems (like InternAgent). While this is valuable, it means the framework is not a standalone reasoning method. This makes it difficult to assess its direct performance gain versus a fundamentally better end-to-end LLM/tool-use setup.\n\nb. The success of the proposed method largely depends on the quality of both the semantic graph  and the causal graph. This quality is influenced by the log file from the baseline and also the method of graph construction. How to ensure the quality of graphs during construction?\n\nc. X-masters have provided their score on HLE in each subset in https://github.com/sjtu-sai-agents/X-Master. But the authors only reported the score on Bio/Med subset and claim achieving SOTA or second-best performance. X-Master has higher performance in MATH and chemistry compared with DualResearch."}, "questions": {"value": "a. How to construct the breath semantic graph and the depth causal graph?\n\nb. How to compute the confidence s_{b}(e) and s_{d}(e)?\n\nc. Will the code be open-sourced for reproductivity？"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "82ZjTT0DFZ", "forum": "46UGfq8kMI", "replyto": "46UGfq8kMI", "signatures": ["ICLR.cc/2026/Conference/Submission7306/Reviewer_QuQf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7306/Reviewer_QuQf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7306/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761810528529, "cdate": 1761810528529, "tmdate": 1762919422079, "mdate": 1762919422079, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DualResearch, a framework designed to enhance tool-intensive scientific reasoning systems. The core innovation is the joint modeling of two complementary graphs: a Breadth Semantic Graph for stable background knowledge and a Depth Causal Graph for procedural provenance from tool execution logs. The framework employs an entropy-gated fusion mechanism to reconcile the heterogeneous evidence from these graphs, adaptively weighting the more certain channel."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1）The proposed dual-graph architecture is a novel approach to addressing the distinct challenges of semantic coverage and causal consistency in complex reasoning. The layer-native retrieval functions (e.g., seed-anchored semantic diffusion for breadth, causal-semantic path matching for depth) are well-motivated and tailored to their respective graph structures.\n\n2）The entropy-gated fusion mechanism provides a theoretically grounded method for combining evidence from heterogeneous sources. The empirical results, showing consistent and significant improvements over strong baselines by reusing their execution logs, are compelling and highlight the practical utility of the method."}, "weaknesses": {"value": "1）While the paper heavily emphasizes reproducibility and verifiability as key advantages, it does not sufficiently clarify the specific application scenarios where these properties are critically demanded. In many LLM applications, diversity and creativity are valued over strict reproducibility. The argument for this as a primary innovation would be stronger if supported by clear examples of domains (e.g., clinical decision support, regulatory compliance) where reproducible reasoning chains are non-negotiable.\n\n2）The readability of the paper is hampered in several sections. The descriptions of the graph construction, path scoring, and fusion mechanics are highly technical and dense, making them difficult to follow without more illustrative examples and intuitive explanations."}, "questions": {"value": "1）The paper argues that \"retrieval and aggregation should reflect the epistemological structure of the task\" as a direct response to the limitations of deep-research systems. However, the logical leap from the mentioned issues (e.g., noisy retrieval, missing causal constraints) to this specific conclusion feels abrupt. If the cited work by Huang et al. (2025) explicitly identifies the lack of a step-by-step logic chain as a root cause for hallucinations or errors, this connection should be made explicit. \n\n2）The depth similarity in Section 3.1 is conceptually sound but abstract. Providing a concrete, minimal example in the main text (or a detailed one in the appendix) comparing the operation sequences for a query and a candidate path would greatly enhance comprehension.\n\n3）Line 181 lists six relation types for the Breadth Graph. What are the relative proportions of these relation types in the constructed graphs? Is the coverage of these six types comprehensive, or is there a long tail of other relations that were excluded? \n\n4）There appears to be a typo in Table 1, where two rows are labeled \"HLE Text-Only.\" This should be corrected for clarity; presumably one is meant to be \"HLE All-Set.\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SrMli68kRa", "forum": "46UGfq8kMI", "replyto": "46UGfq8kMI", "signatures": ["ICLR.cc/2026/Conference/Submission7306/Reviewer_8gvY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7306/Reviewer_8gvY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7306/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939114547, "cdate": 1761939114547, "tmdate": 1762919421570, "mdate": 1762919421570, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work builds on compound systems (iterative / multi-agent) for solving complex tasks that require tool calls for pulling external information and performing complex data manipulation. In particular, it attempts to improve systems on Humanity's Last Exam (HLE) and Google-Proof Q&A (GPQA).\n\nThe paper proposes an approach to review the logs of existing compound research systems (InternAgent, X-Masters) and refine them using a two-channel scoring mechanism. In particular:\n1. DualResearch takes the execution trace of an existing research system (InternAgent in the main paper) and extracts two graphs with edges scored by confidence of extraction:\n    1. Breadth Semantic Graph: Nodes are entities, paraphras, table spans. Edges show how the spans relate to each other\n    2. Depth Causal Graph: Graph nodes are tool calls, results and validator outputs. Edges link tool calls to corresponding outputs and so on.\n2. On the extracted graph, the method first retrieves a subgraph based on relevance to the question. The relevance function on the breadth graph uses node similarity to the query. The relevance function on the depth graph measures the alignment of paths to the query.\n3. Each candidate answer entity is scored by using path scores from both graphs and computing a weighted average using the uncertainty in each channel. (Theoretical results show that the uncertainty weighted average achieves a lower regret than using each channel individually)\n4. The scoring process is used to extract supporting evidence in terms of the highest scored path that leads to the answer entity.\n\nThe method is applied to research logs from InternAgent and X-Masters, and shows consistent improvements with different backbone LLMs. A case study is provided to show how DualResearch compresses the logs of InternAgent for further processing. Ablations show the gains from combining the two channels (each channel on its own is not able to improve significantly over the baseline).\n\nThe biggest weakness of the paper is that a lot of the details are vaguely described. Moreover, the total additional LLM calls are not discussed."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. DualResearch operates on a compressed and structured representation of the execution trace of existing agents and uses this representation to improve accuracy\n    - The case study highlights how the log space of the original agent can be compressed significantly (10x fewer tokens) to reduce drift and erroneous reasoning\n2. Ablations show that the full scoring mechanism (uncertainty weighted average of scores from both channels) is necessary to improve over the baseline agent\n3. Additional Experiments that show the effect of building subject level graphs are interesting"}, "weaknesses": {"value": "1. Several components in the paper are not described in detail. (See questions below).\n    - Most importantly, the graph extraction module is not described. Is it general or does it need to be specifically designed for each base agent?\n    - I believe that the proposed structured representation is a major contribution of the paper but it is not described with enough detail to be reproducible.\n2. The paper assumes that supporting evidence exists as a chain of steps. But if there are multiple query entities, won't the evidence for a DAG (query entities to the answer entity) instead of a chain? It is unclear how evidence paths are defined.\n3. What is the run-time of the DualResearch system? How many additional LLM calls are required per query?\n    - DualResearch works on top of execution traces of other systems. However, none of the baselines can refine the logs. I believe DualResearch will perform better than naive methods that try to refine the logs but this is not established or discussed."}, "questions": {"value": "Clarifications about the method\n---\n1. Is it correct to say that the method cannot improve over the baseline agent if the correct answer is not an entity in the execution log?\n\nClarifications related to Weakness 1\n---\n2. Sec 3.1: How are the two graphs extracted from the logs?\n3. Sec 3.1: What are the encoding functions for the query and the graph nodes?\n4. Line 206: How is $O(q)$ extracted from the query?\n5. Eq 2: What is $t$ and $\\mathcal{P}_{\\leq L}(t)$?\n6. Sec 3.2: This step assumes that candidate answer entities are known. But not all queries in HLE have choices provided. How do you define the answer set in such cases?\n7. Sec 3.2: How do you define the set of paths $P_B(a)$ and $P_D(a)$? Are all possible non-asnwer entities considered as starting points?\n8. Eq 3: What is $w_e^B$?\n9. Eq 3: How is the Offtopic score calculated?\n10. Eq 4: How many terms are in the sum over paths?\n11. Line 408: How would DualResearch without entropy-based aggregation enlarge the solution space? The ablation should have no effect on the set of candidate answers.\n\nClarifications related to Weakness 3\n---\n12. How many additional LLM calls are required in DualResearch starting from the InternAgent log?\n13. Can you provide a discussion on how DualResearch is better than naively refining the logs with additional validation agent calls?\n\nOther clarifications\n---\n14. Line 198: What is lightly averaged?\n15. Line 203: What does it mean by \"This one-hop smoothing avoids multi-step diffusion and hyperparameters\". i.e. what does avoid hyperparameters mean?\n16. Line 218: Are you referring to multi-step diffusion in the original execution log?\n17. What is Signal graph? I am not familiar with this terminology. It seems to be related to building individual graphs per query."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wJB4B0nSAZ", "forum": "46UGfq8kMI", "replyto": "46UGfq8kMI", "signatures": ["ICLR.cc/2026/Conference/Submission7306/Reviewer_j5EC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7306/Reviewer_j5EC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7306/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762009282983, "cdate": 1762009282983, "tmdate": 1762919421175, "mdate": 1762919421175, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}