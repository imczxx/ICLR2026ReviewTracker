{"id": "LGmO9VvuP5", "number": 12919, "cdate": 1758211658915, "mdate": 1759897476652, "content": {"title": "$\\tau^2$-bench: : Evaluating Conversational Agents in a Dual-Control Environment", "abstract": "Existing benchmarks for conversational AI agents simulate **single-control environments**, where only the AI agent can use tools to interact with the world, while the user remains a passive information provider. This differs from real-world scenarios like technical support, where users need to actively participate in modifying the state of the (shared) world. In order to address this gap, we introduce $\\tau^2$-bench, with four key contributions: \n\n1. A novel **Telecom dual-control domain** modeled as a Dec-POMDP, where both agent and user make use of tools to act in a shared, dynamic environment that tests both agent coordination and communication,\n\n2. A **compositional task generator** that programmatically creates diverse, verifiable tasks from atomic components, ensuring domain coverage and controlled complexity,\n\n3. A **reliable user simulator** tightly coupled with the environment, whose behavior is constrained by tools and observable states, improving simulation fidelity,\n\n4. **Fine-grained analysis of agent performance** through multiple ablations including separating errors arising from reasoning vs communication/coordination.\n\nIn particular, our experiments show significant performance drops when agents shift from no-user to dual-control, highlighting the challenges of guiding users. Overall, $\\tau^2$-bench provides a controlled testbed for agents that must both reason effectively and guide user actions.", "tldr": "$\\tau^2$-bench introduces a new way to test AI agents by letting both the agent and a simulated user interact in a shared \"telecom\" world. This allows for creating diverse, verifiable tasks and better user simulation.", "keywords": ["Benchmark", "Evaluation", "Dual Control", "Conversational AI Agents", "User Simulation"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/33da0388f77abc07d3e2ab9412f06b5e9877d35a.pdf", "supplementary_material": "/attachment/8b48cc64ff465b28013ae01fd8893c0783d35e67.zip"}, "replies": [{"content": {"summary": {"value": "This is an extension of Tao-Bench with an additional new domain of customer support. For that additional domain, they use sophisticated DEC-POMDP approach for establishing agent and user simulator dialogues."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper reads like an incremental work, like adding a third domain to well known Tao-Bench. This is an under-sell. The authors should emphasize the decentralized multi-agent POMDP based platform for establishing user simulator and agent conversations. The content should also provide more details on how these POMDP models are trained."}, "weaknesses": {"value": "One big weakness of this benchmark, and same for Tao-Bench, is that the dialogues only follow some golden path towards task completion. In real life the users are not that collaborative, and there are a bunch of back and forth with the customer service reps. This enables differentiating real life agents being robust to such error recovery cases, and user characteristics. Like users sometimes say \"I do not understand what you want me to do\" or \"I hate this phone, nothing works\", and good agents are supposed to handle such cases in a more realistic benchmark. The second concern is that the business rules, defining the dialogue workflow is trivial. There are no such policy actions, as in dialogue managers to handle. For example, one rule can say, if the phone model is X do not suggest Y unless the OS is at least version Z. And one can have thousands of such policy rules. Most real world customer service representatives deal with such policy guidelines. Maybe these can be mentioned as future work."}, "questions": {"value": "I assume POMDP is not used to train the models (since proprietary models are used), but to train a collaboration model. That part is not clear. What type of a model is trained using POMDP and how exactly is it used for prompting closed models."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "SJX2zDLW6z", "forum": "LGmO9VvuP5", "replyto": "LGmO9VvuP5", "signatures": ["ICLR.cc/2026/Conference/Submission12919/Reviewer_DvCS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12919/Reviewer_DvCS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12919/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761677078354, "cdate": 1761677078354, "tmdate": 1762923690501, "mdate": 1762923690501, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces τ²-Bench, an extension of τ-Bench that evaluates conversational AI agents in dual-control environments where both the agent and the user possess tool-using capabilities. It defines a Dec-POMDP-based setup allowing both sides to act on a shared world state, implemented in a telecom domain with compositional task generation and a tightly coupled user simulator. Experiments across multiple models (GPT-4.1, o4-mini, Claude-3.7-Sonnet) show marked performance degradation when moving from single-control to dual-control settings, isolating reasoning versus coordination failures. The benchmark also provides diagnostic insights into user simulation reliability and introduces structured task creation pipelines ensuring domain coverage and controlled complexity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The paper makes a clear and well-motivated advancement in benchmarking agentic systems by introducing the dual-control paradigm, a crucial step toward realistic evaluation of human-AI collaboration. The Dec-POMDP formalization provides a principled theoretical grounding and distinguishes τ²-Bench from purely empirical benchmarks. The telecom domain design, complete with compositional task generation and programmatic verification, adds rigor and reproducibility. The ablation studies are also insightful and the comparison of dual-degree v/s single degree User Simulation is also very insightful and could be helpful for other domains as well where LLMs are utilised to simulate real world users."}, "weaknesses": {"value": "While the benchmark is thoughtfully designed, the paper could better contextualize why the dual-control setting matters beyond the telecom example. Also, the evaluation focuses primarily on accuracy (pass^k metrics), with little analysis of qualitative coordination behaviors, there has been a recent surge in Communication protocols for multi agents systems such as google's Agent-to-Agent, the current metrics primarily focuses on evaluating the final outpu, extending the metrics to incorporate more qualitative aspects can further enhance the usability of the benchmark into properly evaluating more complex aspects of multi agent systems."}, "questions": {"value": "* How do existing AI or agentic frameworks (for example, tool-use agents or dialogue planners) align with the dual-control abstractions introduced here? Which components are novel in practice rather than merely reformulated theoretically?\n\n* How do the theoretical coordination challenges observed in τ²-Bench correspond to practical system limitations seen in real multi-agent or user-in-the-loop deployments?\n\n* Could controlled experiments involving minimal cross-domain extensions (for example, retail dual-control) or user simulator variants demonstrate the benchmark’s generality and stability more concretely?\n\nAlso refer the weaknesses section above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pmR5Bfvter", "forum": "LGmO9VvuP5", "replyto": "LGmO9VvuP5", "signatures": ["ICLR.cc/2026/Conference/Submission12919/Reviewer_CRMZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12919/Reviewer_CRMZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12919/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994483968, "cdate": 1761994483968, "tmdate": 1762923690023, "mdate": 1762923690023, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces τ²-Bench, a novel benchmark for evaluating conversational agents in dual-control environments, where both the user and the agent can perform actions to affect the shared world state. Unlike prior single-control setups (τ-Bench), τ²-Bench models realistic collaborative tasks, such as telecom troubleshooting, using a Decentralized Partially Observable Markov Decision Process (Dec-POMDP) formulation. The benchmark features:\n\n- A compositional task generator that assembles complex, multi-step tasks from atomic subtasks.\n- A dual-control user simulator that interacts consistently and realistically with the agent.\n- An evaluation methodology that separates reasoning from communication/coordination via ablation settings (Default, No-User, Oracle Plan).\n\nExperiments on telecom, retail, and airline domains reveal that large LLMs (GPT-4.1, Claude-3.7-Sonnet, etc.) experience a significant performance drop (~20%) when coordinating with users compared to acting alone. The benchmark also demonstrates improved simulator reliability and fine-grained diagnostic capabilities compared to prior frameworks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Dual-Control Realism – Unlike τ-Bench, which assumes single-agent control, τ²-Bench models dual-control settings where both user and agent can act. This reflects realistic collaborative tasks (e.g., troubleshooting or co-working) and exposes coordination challenges absent in prior benchmarks.\n\n2. Reduced Simulator Errors and Improved Reliability – τ²-Bench’s affordance-based simulator design cuts total error rates from ~40–47% in τ-Bench to ~16% (6% critical), making evaluations far more stable and trustworthy.\n\n3. Compositional Task Generator for Greater Scalability and Control – τ²-Bench replaces τ-Bench’s hand-curated tasks with a programmatic, compositional framework that builds tasks from atomic subtasks (`init`, `solve`, `assert`). This ensures *logical correctness*, *diversity*, and *reproducibility*, while enabling fine-grained control over task complexity and automatic generation of thousands of domain-consistent scenarios, offering far greater scalability and flexibility than τ-Bench’s static design.\n\n4. Fine-Grained Analysis – τ²-Bench separates reasoning (no-user mode) from communication/coordination (dual-control mode), which allows to pinpoint failure sources. τ-Bench conflated these dimensions, making it difficult to isolate why an agent failed.\n\n5. Quantitative and Qualitative results – τ²-Bench provides detailed ablations and performance decompositions (Default, No-User, Oracle Plan), revealing that LLMs drop ~20% in success rate when coordinating with users, previously not measurable under τ-Bench’s single-agent regime."}, "weaknesses": {"value": "1. **Limited Modularity and Domain Portability** – Although τ²-Bench generalizes τ-Bench conceptually, creating new task domains still requires rebuilding much of the system, including domain-specific tools, task generators, and simulators. This limits modularity and makes scaling to new environments labor-intensive and dependent on expert curation.\n\n2. **Lack of Human-in-the-Loop Evaluation** – The benchmark relies entirely on simulated users and agents, with no human studies to validate realism or real-world transfer. Incorporating human participants, either as users or agents, would provide stronger evidence of practical effectiveness and ecological validity."}, "questions": {"value": "1. **How does τ²-Bench fundamentally differ from τ-Bench beyond the dual-control setting?**\nFor instance, are there changes in task semantics, evaluation metrics, or simulator-agent interaction logic that might independently contribute to the observed performance drop?\n\n2. **How sensitive is τ²-Bench performance to the choice of agent prompting or policy design?**\nSince different LLMs and prompting strategies can give very different communication behaviors, it would be useful to understand whether τ²-Bench exposes consistent weaknesses across models or is heavily policy-dependent.\n\n3. **How transferable are policies across domains?**\nIf a model performs well in τ²-Bench’s telecom setting, does that translate to improved coordination in τ-Bench’s retail or airline domains?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ouVuIiT46J", "forum": "LGmO9VvuP5", "replyto": "LGmO9VvuP5", "signatures": ["ICLR.cc/2026/Conference/Submission12919/Reviewer_BQA3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12919/Reviewer_BQA3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12919/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762253167045, "cdate": 1762253167045, "tmdate": 1762923689427, "mdate": 1762923689427, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "τ²-Bench introduces a novel benchmark for evaluating conversational agents in a dual-control setting, meaning both the AI agent and the user can perform actions that change the environment state.Unlike prior benchmarks such as τ-Bench,which modeled multi-turn tool use with a passive user. τ²-Bench addresses a missing realism: the user is an active participant. It simulates scenarios (in a telecom technical support domain) where the user must collaborate with the agent by also using tools to modify the shared world state. It interoduce a compositional task generator, such that tasks are built from atomic subtasks (e.g., connectivity issues, account errors), supporting scalable, diverse, and verifiable evaluations. The benchmark also supports ablation settings (e.g., Oracle Plan, No-User) that help isolate reasoning errors from communication failures, offering insight into agent shortcomings in coordination-heavy tasks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Novel Dual-Control Paradigm: The benchmark targets a unique challenge not covered by prior agent benchmarks – the need for an AI agent to collaborate with an active user. This dual-control setup (modeled as a Dec-POMDP) is highly realistic for many applications (e.g., troubleshooting, collaborative tasks) and exposes failure modes (coordination, communication)\n2. Comprehensive and Rigorous Benchmark Design: The paper introduces a well-thought-out domain (telecom support) with a structured approach to generate tasks of varying complexity.\n3. Strong Experimental Analysis: The evaluation of agent performance is very thorough. The authors perform ablations that isolate different challenges"}, "weaknesses": {"value": "1. Limited Domain Scope: A notable limitation is that τ²-Bench’s dual-control evaluation is conducted in only a single domain (telecom support). While this domain is well-chosen and convincingly complex, the benchmark would be stronger if the approach was demonstrated on multiple domains or scenarios.\n2. Assumptions in User Simulator Behavior: Another minor weakness is the limited user behavior patterns considered. The user simulator is designed to be cooperative (albeit with possible benign mistakes) and has a fixed set of tools. In reality, users might deviate from instructions, provide irrelevant information, or have varying degrees of proactiveness"}, "questions": {"value": "How easily can the τ²-Bench framework be extended to new domains beyond telecom? The current implementation required manual curation of schemas, tools, and policies. Do the authors envision automating more of this process?\nGiven the Dec-POMDP formulation, one could view the problem as a collaborative multi-agent game between the assistant and the user. Have authors tried applying multi-agent RL or self-play techniques in this context?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HuOBlVkdLG", "forum": "LGmO9VvuP5", "replyto": "LGmO9VvuP5", "signatures": ["ICLR.cc/2026/Conference/Submission12919/Reviewer_rbPG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12919/Reviewer_rbPG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12919/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762804782006, "cdate": 1762804782006, "tmdate": 1762923689185, "mdate": 1762923689185, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}