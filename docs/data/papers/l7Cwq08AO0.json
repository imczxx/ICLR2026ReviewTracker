{"id": "l7Cwq08AO0", "number": 16762, "cdate": 1758268444628, "mdate": 1759897220840, "content": {"title": "Adaptive Augmentation-Aware Latent Learning for Robust LiDAR Semantic Segmentation", "abstract": "Adverse weather conditions significantly degrade the performance of LiDAR point cloud semantic segmentation networks by introducing large distribution shifts.\nExisting augmentation-based methods attempt to enhance robustness by simulating weather interference during training. \nHowever, they struggle to fully exploit the potential of augmentations due to the trade-off between minor and aggressive augmentations. \nTo address this, we propose A3Point, an adaptive augmentation-aware latent learning framework that effectively utilizes a diverse range of augmentations while mitigating the semantic shift, which refers to the change in the semantic meaning caused by augmentations. \nA3Point consists of two key components: \nsemantic confusion prior (SCP) latent learning, which captures the model's inherent semantic confusion information, and semantic shift region (SSR) localization, which\ndecouples semantic confusion and semantic shift, enabling adaptive optimization strategies for different disturbance levels.\nExtensive experiments on multiple standard generalized LiDAR segmentation benchmarks under adverse weather demonstrate the effectiveness of our method, setting new state-of-the-art results. The code will be released.", "tldr": "", "keywords": ["LiDAR Semantic Segmentation", "Autonomous Driving", "Robust Learning for Adverse Weather", "Data Augmentation", "Domain Generalization"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/62be26d5fb73a3a6f6c69145067df2c2c3a64455.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors proposes an adaptive augmentation-aware latent learning framework to enhance single-source domain generalization for LiDAR semantic segmentation in poor weather conditions. The main idea is to separate semantic confusion that is built into the model from semantic shift that is caused by augmentation. Per-class VQ-VAE learns discrete \"semantic confusion priors\" from predictions that haven't been augmented, and then a frozen encoder uses latent-space anomaly detection (diagonal Gaussian around each code, threshold t) to find semantic shift on augmented scans. Training takes into account the regions: cross-entropy on semantic-consistent regions (SCR) and latent-space distillation toward the global nearest code on semantic-shift regions (SSR). Coupled with a broadened augmentation space (wide point-drop ratios and jitter std), A3Point yields consistent, sizable gains on SemanticKITTI→SemanticSTF and SynLiDAR→SemanticSTF, improving mIoU over a Minkowski baseline by +9.9 and +11.7, respectively, with similar improvements on SPVCNN and on SemanticKITTI-C."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Originality: Decoupling model-inherent confusion from augmentation-induced shift through a per-class discrete latent prior, followed by regional supervision, transcends traditional augmentation and consistency frameworks.\n\nQuality: Consistent, sizable mIoU gains on SemanticKITTI→SemanticSTF and SynLiDAR→SemanticSTF (+9.9/+11.7 over Minkowski baseline), plus improvements on SemanticKITTI‑C, with thorough ablations of components and hyperparameters.\n\nClarity: The pipeline, losses, and masks (SCR/SSR) are clearly defined, and figures 1–3 and the appendix algorithm help make it possible to reproduce the results.\n\nSignificance: It is very important for safety that things are strong enough to handle bad weather. The method works with any architecture (SPVCNN, Minkowski) and uses latent modeling during training without changing the architectures used for inference."}, "weaknesses": {"value": "Direct comparisons to consistency-regularization or teacher–student DG variants (e.g., mean-teacher on augmentations), label-noise robust losses, or distributionally robust objectives are absent, making relative advantage boundaries less clear.\n\nThe dataset set [A][B][C][D] are defined after the performance tables, which can be confusing for readers when reading the performance tables. \"SCP\" should be where \"SCR latent learning module\" is. There is an extra \"s\" in the caption for Table 1. Appendix I/J has two copies of \"More Qualitative Results.\""}, "questions": {"value": "Please make sure that no SemanticSTF target frames, even unlabeled ones, were used in any way during training. Is there any hyperparameters were chosen using [C]-val.\n\nWhy pick the global nearest code as the SSR goal? Please give us a controlled comparison: global vs. class-conditional nearest code; latent-space distillation vs. soft CE with temperature on logits; and consistency with the original (pre-augmentation) prediction.\n\nCould you compare the parameter size and, if possible, the FLOPs of the baseline and the A3Point modules to prove that the performance gains are not mostly due to the increased model capacity and not the proposed learning scheme."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eJWfp3M9gt", "forum": "l7Cwq08AO0", "replyto": "l7Cwq08AO0", "signatures": ["ICLR.cc/2026/Conference/Submission16762/Reviewer_My2N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16762/Reviewer_My2N"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760777022870, "cdate": 1760777022870, "tmdate": 1762926807699, "mdate": 1762926807699, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "LiDAR semantic segmentation networks struggle in adverse weather (fog, snow, rain) due to distribution shifts. Existing augmentation-based methods face a dilemma: (1) Mild augmentations fail to simulate severe weather. (2) Aggressive augmentations cause semantic shift (labels no longer match distorted regions).\n\nThis paper introduces two distinct error sources: (1) Semantic Confusion: Network's inherent difficulty distinguishing similar classes (e.g., road vs. sidewalk) - exists in both original and augmented data. (2) Semantic Shift: Augmentation-induced mismatch between labels and distorted regions - only exists in augmented data. The proposed method A3Point contains two main parts: (a) Semantic Confusion Prior (SCP) Latent Learning, which use VQ-VAE to learn discrete latent representations of confusion patterns. (b) Semantic Shift Region (SSR) Localization, which treats semantic shift detection as anomaly detection in the discrete latent codebook space and use the frozen encoder to map augmented predictions to latent space for Semantic Shift Regions (SSR) detection. With the detected semantic shift region, the paper propose a distillation loss."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. A3Point is well-motivated and the proposed semantic shift detection method makes a lot of sense.\n\n2. The experiments are thorough and extensive.\n\n3. The results show the effectiveness of the proposed method."}, "weaknesses": {"value": "1. The authors do not discuss the computational efficiency during training. To the reviewer's understanding, the VQ-VAE part and distillation loss part only appear during training and are discarded during testing. Thus the computational efficiency during testing remain the same with other methods. However, a quantitative evaluation of the computational and memory consumption overhead during training is not provided.\n\n2. Although demonstrated by the experiment results, the reviewer is concerned about the design of the distillation loss. The reviewer understand the detection of semantic shift region part and agree that the proposed method makes sense. However, after detecting the semantic shift region, it might be more reasonable to directly eliminate those points in the loss instead of the proposed distillation loss."}, "questions": {"value": "1. Could the authors provide a quantitative evaluation of  A3Point's computational and memory consumption overhead during training?\n\n2. Could the authors provide a more in-depth analysis on the proposed distillation loss? Or maybe conduct additional experiments on simply eliminate the detected region in the loss computation.\n\n3. It could be better if the authors could provide experiment results using previous methods with stronger augmentation.\n\n4. Could the authors provide some visualization of the learned VQ-VAE codebook? For example, using different colors to indicate different entry in the codebook.\n\nThe reviewer is willing to raise the score if the questions are well-resolved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ey9VyRYCfc", "forum": "l7Cwq08AO0", "replyto": "l7Cwq08AO0", "signatures": ["ICLR.cc/2026/Conference/Submission16762/Reviewer_GuJ4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16762/Reviewer_GuJ4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761882249618, "cdate": 1761882249618, "tmdate": 1762926806975, "mdate": 1762926806975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tries to answer an important question in LiDAR augmentation for adverse weather: how to utilize a larger augmentation space while mitigating semantic shift. In this paper, A3Point is introduced, an adaptive augmentation-aware latent learning framework for point cloud semantic segmentation, based on disentanglement of semantic confusion and semantic shift. Experiments on domain generalization benchmarks demonstrate the effectiveness of A3Point, particularly in transferring from normal weather to a wide range of adverse weather conditions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(Problem definition) This paper defines two factors that affect to the prediction performance: semantic confusion and semantic shift. The proposed framework is based on a clear observation that that semantic confusion is consistent across domains (raw and augmented data) while semantic shift occurs only in augmented data.\n\n(Effectiveness)  Experimental results verify the effectiveness of the proposed framework under various conditions, consistently outperforming previous approaches."}, "weaknesses": {"value": "(Universality of semantic confusion) As the semantic confusion is identified using a learned model, the semantic confusion might have a sort of dependency with the learned model. For example, I guess the semantic confusion identified based on the consistency in predictions (the key idea of this paper) is not consist across models used for prediction with different discriminative power. (i.e., the confusion matrix shown in Figure 2-(a) could be different when a smaller/larger model is used for prediction.) In-depth discussion on this would be recommended. In addition, can we take a benefit from identifying universal semantic confusion using multiple learned models, if possible?\n\n(Dependency of semantic shift to model) In Figure 2(b), how to encode each point to draw t-SNE visualization? If a learnable encoder was used, then the distribution shift in t-SNE may be due to the semantic confusion (or lack of discriminative power) of the encoder, too. I agree that there could be “semantic shift” due to an augmentation (e.g., if an augmentation removes too many points on a “bus” object so that only a single large plane is remained, then there is no way to distinguish the augmented points between bus and wall; i.e., an inherent information that makes the set of points (bus) different from the other classes is damaged.), but the t-SNE visualization doesn’t seem to confirm the existence of semantic shift in a strict sense.\n\n(Efficiency) The discrimination of SCR and SSR is performed from inferences on augmented data, which requires additional computation for learning encoder/decoder in SCP latent learning and computing SSR localization. According to Table 6, online training of SCP learning leads the best performance, which means the additional network (for SCP latent learning) has to be trained simultaneously and severe inefficiency during training is caused. \n\n(Lack of analysis) In Table 1 and 2, Oracle (training on target domain) shows 0.0 IoU on certain classes: motorcycle, motorcyclist, but this is improved a lot in A3Point (e.g., 0.0 → 57.5 IoU, 0.0 → 46.4 IoU). What makes this drastic improvement?\n\n(Concern about overclaiming) The paper claims that the proposed module is architecture-agnostic; however, experiments were only conducted on SPVCNN and MinkowskiNet, both voxel-based models. It would be interesting to see if the semantic confusion and shift happen in a similar way on projection-/point-based approaches."}, "questions": {"value": "(Effectiveness on safely allowing a larger augmentation space) I’m curious to see if the proposed semantic shift detection pipeline is effective in enabling the utilization of “a large augmentation space”. A trivial approach for enlarging the augmentation space might be to train models with multiple augmentation spaces (hyperparameter search). But considering the augmentation space is multi-dimensional with many variables, it’s not a scalable way. In this regard, the proposed method seems to have a capability to safely allow a larger augmentation space by detecting and handling semantic shifts from augmentation, so that the performance drop caused by the use of too excessive augmentation space can be mitigated. If so, it would be great to provide an experiment on training with arbitrary large augmentation spaces lead similar performance.\n\n(Extension of A3Point) As the semantic confusion matrices from baseline and A3Point must be different, the A3Point method can be treated as a training framework to gradually improve confusion matrix of a learned model. It leads an idea of iterative applying A3Point framework with varying augmentation space. Adding a discussion on this could suggest a future research direction to readers.\n\n(Lack of experiment setting) The class mapping between the source datasets [A, B] and the target dataset [C] is not clearly explained."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "m4kcgYg3Gh", "forum": "l7Cwq08AO0", "replyto": "l7Cwq08AO0", "signatures": ["ICLR.cc/2026/Conference/Submission16762/Reviewer_79Cq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16762/Reviewer_79Cq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761967750633, "cdate": 1761967750633, "tmdate": 1762926806131, "mdate": 1762926806131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on augmentation-based methods among existing approaches for domain generalization under adverse weather conditions. This paper assert that previous augmentation-based methods suffered from the issue that strong augmentations caused semantic shifts, which interfered with training. In this study, the authors propose a framework using VQ-VAE to distinguish between semantic confusion and semantic shift, and they claim to address the problem by introducing a distillation-based loss that prevents semantic shift from disrupting the training dynamics."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tNew idea\n2.\tClearly identifies the weaknesses of existing weather-augmentation approaches\n3.\tThe method that separates SSR from SCR is highly sophisticated\n4.\tThrough performance gains and ablations, the authors show strong effectiveness for LiDAR semantic segmentation under adverse weather. Notably, there are large improvements on SynLiDAR → SemanticSTF, where prior methods achieved limited gains."}, "weaknesses": {"value": "1.\tThe method appears applicable to domain generalization beyond adverse weather; there is no compelling reason it must be evaluated specifically on SemanticSTF.\n2.\tBy the same logic, even if strong augmentation produces SSR, wouldn’t training those regions with the original ground truth still be effective? Why deliberately block cross-entropy learning there? Is there any convincing reason that training with GT in SSR is not good? In real weather conditions, distortions can be just as strong.\n3.\tIt is unclear whether the method actually performs well within SSR regions (i.e., the detected regions during training, or the highly distorted areas within a single sample at inference).\n4.\tTraining time appears to be very long.\n5.\tCouldn’t a simple prototype-based method separate SCR and SSR without a VQ-VAE? If not, why not? If feasible, that alternative would likely incur much lower training cost.\n6.\tOn LiDARWeather the training schedule uses 15 epochs, but you train for 50. Why? The gains might simply come from longer training.\n7.\tIn Table 1, among the “things” classes, person and motorcyclist presumably have more samples and should be easier to improve, yet they are not; in my knowledge, this is unexpected. Please provide the confusion matrix.\n\n(Minor)\n1.\tIn “Weather-level Comparison” of experiment, please indicate which table the reader should consult.\n2.\tIn Table 1, the experimental results for LiDARWeather and NTN appear to be swapped.\n3.\tXiao et al., 2023 primarily proposed SemanticSTF; it is not the work that established point dropping and jittering as the main disturbances in LiDAR data."}, "questions": {"value": "See the above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6i1cHutGui", "forum": "l7Cwq08AO0", "replyto": "l7Cwq08AO0", "signatures": ["ICLR.cc/2026/Conference/Submission16762/Reviewer_wTLP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16762/Reviewer_wTLP"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16762/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762150757906, "cdate": 1762150757906, "tmdate": 1762926805801, "mdate": 1762926805801, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}