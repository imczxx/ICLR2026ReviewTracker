{"id": "fUXNRKUPiy", "number": 19806, "cdate": 1758299510013, "mdate": 1763687473490, "content": {"title": "DexBench: Benchmarking LLMs for Personalized Decision Making in Diabetes Management", "abstract": "We present DexBench, the first benchmark designed to evaluate large language model (LLM) performance across real-world decision-making tasks faced by individuals managing diabetes in their daily lives. Unlike prior health benchmarks that are either generic, clinician-facing or focused on clinical tasks (e.g., diagnosis, triage), DexBench introduces a comprehensive evaluation framework tailored to the unique challenges of prototyping patient-facing AI solutions in diabetes, glucose management, metabolic health and related domains. Our benchmark encompasses 7 distinct task categories, reflecting the breadth of real-world questions individuals with diabetes ask, including basic glucose interpretation, educational queries, behavioral associations, advanced decision making and long term planning. Towards this end, we compile a rich dataset comprising one month of time-series data encompassing glucose traces and metrics from continuous glucose monitors (CGMs) and behavioral logs (e.g., eating and activity patterns) from 15,000 individuals across three different diabetes populations (type 1, type 2, pre-diabetes/general health and wellness). Using this data, we generate a total of 360,600 personalized, contextual questions across the 7 tasks. We evaluate model performance on these tasks across 5 metrics: accuracy, groundedness, safety, clarity and actionability. Our analysis of 8 recent LLMs reveals substantial variability across tasks and metrics; no single model consistently outperforms others across all dimensions. By establishing this benchmark, we aim to advance the reliability, safety, effectiveness and practical utility of AI solutions in diabetes care.", "tldr": "", "keywords": ["large language models", "evaluation", "decision making", "diabetes", "glucose", "wearable data"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9bf7d73b12db8ff9dee0aaa7f4ddd5b3be9e6c3b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents DexBench, a benchmark designed to evaluate large language models on real-world, patient-facing diabetes management tasks. Built from data of 15,000 individuals across type 1, type 2, and prediabetes populations, it generates 360,600 contextualized questions covering seven representative tasks derived from CGM and behavioral data. The authors also design a five-dimensional evaluation framework (accuracy, groundedness, safety, clarity, and actionability) and assess eight diverse LLMs. The study offers a framework for assessment of LLM performance in diabetes-related contexts."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The study constructs a large, diverse, and multimodal patient-facing diabetes dataset, covering comprehensive real-world management tasks and complementing existing benchmark efforts. \n\n2. It systematically evaluates multiple LLMs, discusses their strengths and limitations, and provides some useful insights for improving diabetes-specific model capabilities."}, "weaknesses": {"value": "1. As acknowledged by the authors, the dataset lacks detailed demographic information (e.g., age) and omits important variables such as insulin use and medication data. In addition, it relies heavily on wearable and self-reported inputs, which may be sparse, noisy, and limit the robustness and representativeness of the benchmark.\n\n2. The evaluation is primarily based on model-generated responses, which may introduce bias. Incorporating domain-specific diabetes knowledge or clinical expertise into the evaluation process could improve the rigor and reliability of model assessment."}, "questions": {"value": "1. Could the authors clarify the dataset source in detail—specifically, how the real-world data were collected and whether the reported cohort of 15,000 individuals includes any synthetically generated data? ps. The prediabetes/health and wellness group may not be a true diabetes population; clarification in terminology would improve precision.\n\n2. Although the paper notes missing demographic (e.g., age, sex) and treatment variables (insulin, medications), , the benchmark distinguishes adults and adolescents in Task 2. Could the authors provide basic dataset statistics, such as the proportion of adults vs. adolescents and the completeness rate of self-logged data? This information would help assess the representativeness and generalizability of the bench.\n\n3. Lines 190-191 mention that a human expert manually confirms the quality of generated questions. Could the authors elaborate on the review process and criteria used to judge question quality?\n\n4. The related work section states that previous diabetes benchmarks are clinician-facing, but some prior efforts are not strictly clinician-oriented. The authors may consider clarifying or citing those examples for completeness.\n\n5. Given that most evaluations rely on model-based scoring, how do the authors ensure scoring fairness, especially when the scoring model itself may not be the strongest performer? What were the considerations in selecting the scoring model? In addition, for binary criteria, could a graded or probabilistic scoring scheme provide a more nuanced assessment?\n\n6. Lines 713-715 describe accuracy as “agreement with ground-truth values within ±2 mg/dL, with no calculation errors permitted.” Could the authors clarify this definition? There seems to be a potential inconsistency. Besides, not all metrics (e.g., TIR) are expressed in mg/dL.\n\n7. Regarding the clarity metric (Flesch-Kincaid Grade Level), could the authors explain how this measure was implemented and validated for health communication contexts?\n\n8. The reported benchmark scores are relatively high. Does this suggest that the current benchmark may not pose sufficient challenge to newer models? How might future updates maintain or enhance its discriminative ability?\n\n9. The paper mentions that it plans to extend DexBench to other health domains. Could the authors elaborate on how the framework could be adapted to chronic conditions such as hypertension or obesity? Have any preliminary steps been taken in that direction?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Xrm4Pg1Bk7", "forum": "fUXNRKUPiy", "replyto": "fUXNRKUPiy", "signatures": ["ICLR.cc/2026/Conference/Submission19806/Reviewer_FnwP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19806/Reviewer_FnwP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761825849634, "cdate": 1761825849634, "tmdate": 1762931659383, "mdate": 1762931659383, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents DexBench, a benchmark designed to evaluate large language models on real-world, patient-facing diabetes management tasks. Built from data of 15,000 individuals across type 1, type 2, and prediabetes populations, it generates 360,600 contextualized questions covering seven representative tasks derived from CGM and behavioral data. The authors also design a five-dimensional evaluation framework (accuracy, groundedness, safety, clarity, and actionability) and assess eight diverse LLMs. The study offers a framework for assessment of LLM performance in diabetes-related contexts."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The study constructs a large, diverse, and multimodal patient-facing diabetes dataset, covering comprehensive real-world management tasks and complementing existing benchmark efforts. \n\n2. It systematically evaluates multiple LLMs, discusses their strengths and limitations, and provides some useful insights for improving diabetes-specific model capabilities."}, "weaknesses": {"value": "1. As acknowledged by the authors, the dataset lacks detailed demographic information (e.g., age) and omits important variables such as insulin use and medication data. In addition, it relies heavily on wearable and self-reported inputs, which may be sparse, noisy, and limit the robustness and representativeness of the benchmark.\n\n2. The evaluation is primarily based on model-generated responses, which may introduce bias. Incorporating domain-specific diabetes knowledge or clinical expertise into the evaluation process could improve the rigor and reliability of model assessment."}, "questions": {"value": "1. Could the authors clarify the dataset source in detail—specifically, how the real-world data were collected and whether the reported cohort of 15,000 individuals includes any synthetically generated data? ps. The prediabetes/health and wellness group may not be a true diabetes population; clarification in terminology would improve precision.\n\n2. Although the paper notes missing demographic (e.g., age, sex) and treatment variables (insulin, medications), , the benchmark distinguishes adults and adolescents in Task 2. Could the authors provide basic dataset statistics, such as the proportion of adults vs. adolescents and the completeness rate of self-logged data? This information would help assess the representativeness and generalizability of the bench.\n\n3. Lines 190-191 mention that a human expert manually confirms the quality of generated questions. Could the authors elaborate on the review process and criteria used to judge question quality?\n\n4. The related work section states that previous diabetes benchmarks are clinician-facing, but some prior efforts are not strictly clinician-oriented. The authors may consider clarifying or citing those examples for completeness.\n\n5. Given that most evaluations rely on model-based scoring, how do the authors ensure scoring fairness, especially when the scoring model itself may not be the strongest performer? What were the considerations in selecting the scoring model? In addition, for binary criteria, could a graded or probabilistic scoring scheme provide a more nuanced assessment?\n\n6. Lines 713-715 describe accuracy as “agreement with ground-truth values within ±2 mg/dL, with no calculation errors permitted.” Could the authors clarify this definition? There seems to be a potential inconsistency. Besides, not all metrics (e.g., TIR) are expressed in mg/dL.\n\n7. Regarding the clarity metric (Flesch-Kincaid Grade Level), could the authors explain how this measure was implemented and validated for health communication contexts?\n\n8. The reported benchmark scores are relatively high. Does this suggest that the current benchmark may not pose sufficient challenge to newer models? How might future updates maintain or enhance its discriminative ability?\n\n9. The paper mentions that it plans to extend DexBench to other health domains. Could the authors elaborate on how the framework could be adapted to chronic conditions such as hypertension or obesity? Have any preliminary steps been taken in that direction?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Xrm4Pg1Bk7", "forum": "fUXNRKUPiy", "replyto": "fUXNRKUPiy", "signatures": ["ICLR.cc/2026/Conference/Submission19806/Reviewer_FnwP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19806/Reviewer_FnwP"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761825849634, "cdate": 1761825849634, "tmdate": 1763652593422, "mdate": 1763652593422, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces DexBench, a comprehensive benchmark designed to evaluate large language models (LLMs) on patient-facing diabetes management tasks. It covers seven real-world decision-making tasks, uses data from 15,000 individuals across three diabetes populations, and evaluates models on five metrics: accuracy, groundedness, safety, clarity, and actionability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper has several strong aspects as below\n- DexBench addresses a critical gap in healthcare AI by focusing on patient-facing tasks, which are often overlooked in existing benchmarks. Crucially, the use of a large-scale dataset from real-world users provides valuable context for evaluating LLM performance in realistic scenarios.\n- The evaluation framework covers multiple aspects of model performance, including accuracy, safety, and actionability, ensuring a holistic assessment.\n- The paper provides extensive results comparing eight LLMs across various tasks, highlighting strengths and weaknesses for each model."}, "weaknesses": {"value": "There are some key drawbacks in the dataset as below\n\n- The dataset may lack critical information such as demographic details and specific medical conditions like insulin use, which could affect task performance.\n- The reliance on synthetic data (e.g., GlucoSynth) for certain tasks raises concerns about the benchmark's real-world applicability.\n- Advanced tasks like advanced reasoning and planning may require more sophisticated models to handle complex logic and context."}, "questions": {"value": "- How was the dataset ensured to be diverse enough across diabetes populations, age groups, and other demographic factors?\n- What steps were taken to ensure synthetic data does not skew results or limit the benchmark's generalizability?\n- Why did certain diabetes cohorts (e.g., T2D) perform better on average? Are there specific reasons tied to task requirements or model capabilities?\n- How was hallucination detected and addressed in the evaluation process, especially for complex tasks requiring accurate medical reasoning?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Lx9x3KbpDP", "forum": "fUXNRKUPiy", "replyto": "fUXNRKUPiy", "signatures": ["ICLR.cc/2026/Conference/Submission19806/Reviewer_L5it"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19806/Reviewer_L5it"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951995007, "cdate": 1761951995007, "tmdate": 1762931657759, "mdate": 1762931657759, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a benchmark for LLMs on decision-support tasks for managing diabetes. They discuss 7 task categories: glucose math, education, simple and advanced reasoning, decision making, planning, and triage. It is noted that the performance results across all tasks are relatively high, with GPT-5-mini achieving 99.7% in safety and 98.3% in actionability."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- With the increasing use of LLMs in diabetes management, the problem domain of the paper is interesting. If done properly, this addresses a gap in AI benchmarking for healthcare and decision making tasks.\n- The figures and detailed tasks (in appendices) are clear.\n- Investigates 7 task categories in multiple criteria (accuracy, groundedness, safety, clarity, actionability)"}, "weaknesses": {"value": "- Limited information on human experts, annotation processes, and task coverage\n- There are many confounding factors, such as experimental settings, token limits, and handling of errors/faults... which were not appropriately addressed\n- Limited information on the data, even though the source code is downloadable\n- Despite impressive numbers in the dataset, it is important for authors to prompt their motivations, aims and novelty of this type of research. It is relatively easy for researchers to create such a dataset, using curated data, with LLM-generated questions, and the use LLM evaluations (potential circularity?). Real impacts are far more important than getting papers accepted (even elsewhere)."}, "questions": {"value": "- How can the research rigour of this paper be addressed? For example, the formulation of tasks and criteria is simply developed by \"human experts\" - there are many methodological approaches to this.\n- How can the research data be validated? What are the details on human experts and annotation processes?\n- Any researcher can come up with a list of tasks, criteria, and generated questions using LLMs. What are the real values and impacts of this research work?"}, "flag_for_ethics_review": {"value": ["Yes, Potentially harmful insights, methodologies and applications", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TP6mIkqMmp", "forum": "fUXNRKUPiy", "replyto": "fUXNRKUPiy", "signatures": ["ICLR.cc/2026/Conference/Submission19806/Reviewer_rVP1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19806/Reviewer_rVP1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761992716068, "cdate": 1761992716068, "tmdate": 1762931656699, "mdate": 1762931656699, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces DexBench, a large-scale benchmark for evaluating large language models (LLMs) on context-aware, personalized decision-making tasks. Unlike prior health-AI benchmarks focused on clinician reasoning, DexBench targets user-facing reasoning that supports daily self-management of chronic conditions, exemplified through diabetes care. The benchmark defines seven task categories, from Glucose Math and Education to Planning and Alert/Triage, spanning quantitative reasoning to long-term guidance. Using 30-day CGM and behavioral data (sleep, meals, exercise) from 15,000 individuals, DexBench generates 360,600 personalized questions.\nOutputs are evaluated across five binary metrics—accuracy, groundedness, safety, clarity, and actionability—using a structured pipeline that combines automated Gemini grading and expert review. Evaluating eight LLMs (Gemini, GPT-5, DeepSeek, Qwen, Llama, MedGemma), the study finds proprietary models strongest in safety and factual accuracy, while open-source models lag in groundedness and readability. Analyses of latency, modality, and thinking-budget reveal trade-offs between reasoning depth, efficiency, and safety in real-world applications."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- DexBench contributes not merely a dataset but a generalizable evaluation framework for multimodal reasoning and safety assessment. Its five-axis scoring scheme (accuracy/groundedness/safety/clarity/actionability) and multi-task taxonomy formalize a principled way to measure contextual reasoning quality—an under-explored but central topic in current ICLR research.\n- The seven tasks form a structured reasoning hierarchy, from immediate quantitative interpretation to sequential planning and triage. This mirrors the cognitive spectrum of everyday decision-making and extends evaluation beyond static QA to dynamic, data-grounded reasoning.\n- With 15,000 users, three diabetes cohorts, and longitudinal data spanning 30 days, DexBench represents one of the most comprehensive real-world datasets for patient-facing reasoning—far larger and richer than previous health benchmarks such as Diabetica or MedGPTEval.\n- The authors detail transparent stages, data curation, question generation, automatic and human validation, and ethical safeguards (Appendix A.1), providing reproducibility and regulatory awareness rarely seen in benchmark design.\n- The latency, modality, and “thinking-budget” experiments yield general insights about compute–accuracy–safety trade-offs in LLM reasoning. These findings speak directly to the broader LLM community, not just health applications."}, "weaknesses": {"value": "- Use of synthetic glucose traces (GlucoSynth) and LLM-generated questions introduces potential bias. The paper lacks quantitative evidence of expert agreement (e.g., Cohen’s κ), which limits confidence in the reliability of the “accuracy” and “groundedness” metrics.\n- The same model family (Gemini 2.5 Flash) is used for both question generation and grading, raising the possibility of alignment leakage. Independent or cross-model evaluation would strengthen fairness.\n- Behavioral features are limited to sleep, meals, and exercise; omitting insulin dosage, medication adherence, or stress reduces ecological realism for decision support.\n- A 0/1 metric oversimplifies nuanced criteria such as clarity and actionability. Continuous or rubric-based scoring, as in HealthBench, would better reflect performance differences.\n- The related-work section should acknowledge concurrent benchmarks (MedGUIDE 2025, HELM 2.0, etc.) and clarify that DexBench’s novelty lies in its temporal, behavior-linked reasoning framework rather than being the first diabetes-oriented benchmark.\n- Although Table 4 lists typical errors, the paper could offer a causal taxonomy (e.g., temporal misalignment, hallucination under uncertainty) to better guide model improvement."}, "questions": {"value": "- How does DexBench’s multi-axis evaluation differ from LLM-CGM and MedGUIDE in modeling patient-facing reasoning?\n- Was inter-rater reliability (e.g., κ-score) computed for expert validations?\n- Could grading bias from Gemini 2.5 Flash be tested through cross-model adjudication?\n- Are multimodal modalities (voice, sensor streams, graphical plots) planned for future releases?\n- How well does the evaluation framework generalize to other continuous-monitoring domains (e.g., hypertension, sleep, fitness)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "U4l1Kv9rBG", "forum": "fUXNRKUPiy", "replyto": "fUXNRKUPiy", "signatures": ["ICLR.cc/2026/Conference/Submission19806/Reviewer_1mbx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19806/Reviewer_1mbx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19806/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762006899639, "cdate": 1762006899639, "tmdate": 1762931655869, "mdate": 1762931655869, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "We sincerely thank all reviewers for their thoughtful feedback, which has significantly improved the quality and clarity of our paper. We have uploaded a revised version with all changes highlighted in red for ease of review."}}, "id": "EMATPmdjA9", "forum": "fUXNRKUPiy", "replyto": "fUXNRKUPiy", "signatures": ["ICLR.cc/2026/Conference/Submission19806/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19806/Authors"], "number": 18, "invitations": ["ICLR.cc/2026/Conference/Submission19806/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763687790479, "cdate": 1763687790479, "tmdate": 1763687790479, "mdate": 1763687790479, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}