{"id": "ZC5QBfdOw7", "number": 20595, "cdate": 1758308095250, "mdate": 1759896968836, "content": {"title": "How Text Quality Interventions Reshape Neural Scaling Laws for LLMs: Empirical Study", "abstract": "Neural scaling laws are widely used for performance projection and resource planning, yet their sensitivity to data quality interventions remains poorly understood.  We present an empirical study of how interventions—deduplication, heuristic filtering, and LLM-guided rewriting—reshape scaling behavior in large language model training. Using QualityPajama, a suite of 23 systematically filtered and synthetic datasets, we train over 2,000 models (100M–8B parameters, 100M–200B tokens) to measure how data quality affects scaling-law parameters and compute-optimal design decisions. Our results show that data interventions reshape scaling dynamics in non-trivial ways not captured by current theory, simultaneously moving exponents, coefficients, and constants in conflicting directions that exert opposing forces on loss. For example, an intervention may improve constants but hurt the exponents. Strategies that appear optimal at small scale can reverse at larger scale, and compute-optimal token–parameter ratios can vary by orders of magnitude depending on the intervention. These findings demonstrate that data curation and scaling strategy are deeply intertwined, and that evaluating interventions only at fixed scales can lead to misleading conclusions. We recommend evaluating interventions through their full scaling trajectories using scaling law projections.", "tldr": "We present the first large-scale empirical study showing how text quality interventions reshape neural scaling laws and compute-optimal strategies for training LLMs, highlighting the need to rank data strategies using scaling law curves.", "keywords": ["Neural Scaling law", "Text quality"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/671ba7e8477b82a01d221528ad4a7474992e8103.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "training LLM's is very cost intensive, i.p. w.r.t. required number of tokens. recent pretraining dataset filters battle claiming faster downstream performance adoption. most prominent are heuristic quality filters or synthetic data augmentation. this paper is a massive evaluation on several models and datasets , claiming in fact that correlations between quality interventions and scaling law parameters can be found."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- trained on lots of models to provide robust empirical evidence that data quality influences the exponents, not just coefficients of scaling laws\n- very relevant for future vvery costly model trainings\n- they publish a QualityPajama benchmark suite, again very relevant"}, "weaknesses": {"value": "W1 it empirically measures some correlation to exponents, but with little theoretical explanations or evidence. there is only that vague dismissal of zipfian theory\n\nW2 unfortunately i don't see a strong correlation in the quality filter domains and to validations sets, while it appears rather clear / obvious to hold in the synthetic LLM data augmentation. i therefore think it should be phrased that way from the very beginning? renders interpretation of the claimed findings a bit weird.\n\nW3 for the quality filters it seems strange and outdated filters are used. recently most significant are bert-style quality filters, however the authors rely on rather old pagerank?\n\n(W4 the only chosen metric the authors compare to is perplexity, but i also wouldn't know what to do otherwise in this scale.)"}, "questions": {"value": "addressing aboves weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "N9KBkQfzVd", "forum": "ZC5QBfdOw7", "replyto": "ZC5QBfdOw7", "signatures": ["ICLR.cc/2026/Conference/Submission20595/Reviewer_922u"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20595/Reviewer_922u"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20595/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927553017, "cdate": 1761927553017, "tmdate": 1762934004006, "mdate": 1762934004006, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper asks how interventions on data quality shape LLM scaling behavior. They introduce a benchmark named QualityPajama that consists of 23 datasets derived from CommonCrawl and train >2K models on the datasets. Analyzing the scaling laws, they find that different data quality interventions lead to different relations between parameters, and that picking the optimal (given compute) token-to-parameter ratio depends on the data quality intervention."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Experiments are extensive, covering 2000 models across a large range of model sizes.\n- Some of the key findings, for example that the intervention of deduplication can yield large compute savings, have practical downstream utility for people training models with limited compute."}, "weaknesses": {"value": "The paper lacks a theoretical framework through which to understand the extensive empirical results. In particular, the paper would be greatly strengthened if it introduced a new scaling law to relate data quality interventions to other parameters and to explain the empirical findings."}, "questions": {"value": "Formatting notes:\n- Line 39: Citations are formatted weirdly\n- Line 87: Missing space\n- Line 123: period should be comma\n- Line 178: formatting of paragraph is weird and inconsistent"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Bjch2s7wY0", "forum": "ZC5QBfdOw7", "replyto": "ZC5QBfdOw7", "signatures": ["ICLR.cc/2026/Conference/Submission20595/Reviewer_TyiW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20595/Reviewer_TyiW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20595/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946290659, "cdate": 1761946290659, "tmdate": 1762934003405, "mdate": 1762934003405, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies the effect of data quality on LLM scaling law. The authors start from the RedPajama dataset, consider 14 Heuristic-based data quality interventions and 9 synthetic ones, and applied them in combination to induce various quality-intervened training datasets. For each such quality-invented training dataset, the authors use it to train various sized LLaMA models and evaluate their scaling law. Many findings on the specific effect of different data quality interventions on scaling laws are discussed."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is written excellent, easy to read and follow.\n2. To my knowledge, it is the first work that analyses how specific dataset filtering methods as quality inventions affect specific coefficients in the scaling law. And the authors consider all coefficients rather than just the dataset size coefficient D.\n3. Many findings that I expect to be practically helpful in guiding training data preparation as an integral part of model training are discussed."}, "weaknesses": {"value": "1. a small point for improvement is that for Figure 3, 4, 5, the legends block significant portion of the figures (especially Figure 4) and makes the figure less readable. I suggest the authors improve the presentation of these figures so that legends do not block figures.\n\n2. The paper focuses on the classic form of the scaling law and it mentions in related work that Chang et al. (2024) and Muennighoff et al. (2023) introduces the effective dataset size D'. And there might be other extended forms of the scaling laws. Could the authors consider re-run the fitting and analysis with these extended forms beside the classic one? I believe it will be very helpful because (1) it will be an ablation study strengthening the validity of the findings and (2) these extended forms might have better goodness of fit because they have more variables in the system and might fit the scaling law better."}, "questions": {"value": "no questions"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "nAw7VfKcki", "forum": "ZC5QBfdOw7", "replyto": "ZC5QBfdOw7", "signatures": ["ICLR.cc/2026/Conference/Submission20595/Reviewer_Mu49"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20595/Reviewer_Mu49"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20595/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997764509, "cdate": 1761997764509, "tmdate": 1762934002911, "mdate": 1762934002911, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a large scale empirical study of how data quality interventions (deduplication, heuristic filtering and LLM-guided rewriting) affect neural scaling laws in large language model training. They use 23 systematically curated datasets to train over 2,000 models to measure how text quality interventions reshape scaling law components (coefficients A, B and exponents α, β). A key finding is that data quality interventions shift both exponents and coefficients, fundamentally changing scaling dynamics in ways not predicted by existing theory."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper addresses a practically important question that has been largely neglected despite being central to LLM development.\n2. Over 2000 model training runs across multiple scales (100M–8B parameters) and token ranges (100M–200B) provides strong empirical support.\n3. Clear demonstration that optimal token-to-parameter ratios vary significantly  across interventions at the same compute scale.\n4. Well written paper with clear progression from dataset design → empirical findings → interpretations → implications."}, "weaknesses": {"value": "1. While the paper shows that data interventions shift all scaling law components, it provides limited mechanistic understanding of WHY this happens. The discussion of Zipfian theory (Appendix G) shows weak correlations but doesn't propose alternative explanations. There is critique of existing theory (data manifold, Zipfian distribution) but it is somewhat superficial. Would have been interesting to see more discussion here.\n2. Filters are applied sequentially, but the order matters (acknowledged in Section 4). The paper doesn't fully disentangle whether observed component shifts are due to the filter itself or the interaction order.\n3. The 0.3-0.5 Spearman correlation for heuristic filters is interesting but not fully explained. Why do natural filters show lower consistency across validation sets than synthetic filters (0.91 for B)?\n4. The paper makes several claims about deduplication efficiency that appear to use different baselines or comparison points:\n  - \"Exact deduplication reduces data volume to 83% of original yet yields a 100× gain in compute efficiency\" (L431-432)\n  - \"Fuzzy deduplication (0.7) requires approximately 3× less compute than 0.9, 10× less than exact deduplication, and 300× less than no deduplication\" (L459-461)\n  - These statements are difficult to compare together. If exact dedup achieves 100× gain, is fuzzy 0.7 achieveing \"300× less” than the baseline or exact dedup? What am I missing here?\n\n5. All experiments use llama3-style transformer. Results may not generalize to other architectures (mixture-of-experts, alternative attention mechanisms, etc.). This doesn’t require more experiments, but limitation discussion could be clearer on this.\n6. The claim that \"deduplication could expand the data manifold\" is counterintuitive and under-explained. Deduplication removes redundant documents. If a document is a duplicate, removing it changes weighting of the remaining documents but how does this expand the manifold? This needs clarification or revision.\n\n## Minor\n- The paper uses \\citet in several places where \\citep would be more appropriate. Many claims about what \"prior work overlooks\" (e.g., L58 \"what prior work overlooks other components?\") lack supporting citations. Strengthen argumentative claims with explicit references.\n- L116 The statement that α, β, etc \"are constants\" is not helpful. What do these constants model/support? Provide intuitive descriptions (e.g., \"α quantifies model scaling efficiency\").\n- Consider inverting the right column of figures so that \"higher is always better\" visually. This would make the figure easier to interpret as a whole.\n- “LLM” is not abbreviated on first use in the intro. It should be defined on first use then re-used."}, "questions": {"value": "1. How sensitive are the scaling law components to the curve-fitting method? Have you tested non-parametric approaches or Bayesian inference?\n2. The paper uses single-epoch training. How would results change with data repetition? Does the data manifold interpretation change?\n3. For synthetic data generation, did you experiment with different generator models or temperature settings?\n4. Can you provide theoretical intuition for why data interventions shift both exponents and coefficients rather than just one?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "c2c71CIKSv", "forum": "ZC5QBfdOw7", "replyto": "ZC5QBfdOw7", "signatures": ["ICLR.cc/2026/Conference/Submission20595/Reviewer_1zGS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20595/Reviewer_1zGS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20595/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997792777, "cdate": 1761997792777, "tmdate": 1762934002502, "mdate": 1762934002502, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}