{"id": "oKG6F733z6", "number": 11839, "cdate": 1758204189347, "mdate": 1763536978160, "content": {"title": "Gradient Correction in Federated Learning with Adaptive Optimization", "abstract": "In federated learning (FL), model training performance is strongly impacted by data heterogeneity across clients. Client-drift compensation methods have recently emerged as a solution to this issue, introducing correction terms into local model updates. To date, these methods have only been considered under stochastic gradient descent (SGD)-based model training, while modern FL frameworks also employ adaptive optimizers (e.g., Adam) for improved convergence. However, due to the complex interplay between first and second moments found in most adaptive optimization methods, naively injecting correction terms can lead to performance degradation in heterogeneous settings. In this work, we propose {\\tt FAdamGC}, the first algorithm to integrate drift compensation into adaptive federated optimization. The key idea of {\\tt FAdamGC} is injecting a pre-estimation correction term that aligns with the moment structure of adaptive methods. We provide a rigorous convergence analysis of our algorithm under non-convex settings, showing that {\\tt FAdamGC} results in better rate and milder assumptions than naively porting SGD-based correction algorithms into adaptive optimizers. Our experimental results demonstrate that {\\tt FAdamGC} consistently outperform existing methods in total communication and computation cost across varying levels of data heterogeneity, showing the efficacy of correcting gradient information in federated adaptive optimization.", "tldr": "The paper proposed a gradient correction method to apply onto federated adaptive optimization algorithms, which greatly improves the performance against data heterogeneity.", "keywords": ["Machine Learning", "Federated Learning", "Adaptive Optimization", "Gradient Tracking"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9588044cfcf97a9e85ec1943e4694c98be11310f.pdf", "supplementary_material": "/attachment/75b342dea415a4438acb84885a430e9eb2d6eb22.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses the problem of client-drift caused by data heterogeneity in FL with adaptive optimizers. The authors propose FAdamGC, the first algorithm to integrate gradient-tracking-based drift compensation into adaptive federated optimization. The authors conduct a rigorous theoretical convergence analysis under non-convex settings and perform extensive empirical studies, showing that their method outperforms prior correction schemes in terms of communication and computation efficiency across varying data heterogeneity."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. FAdamGC is the first work to consider integrating gradient-tracking-based client-drift compensation with adaptive optimizers in federated learning, thereby addressing a meaningful challenge in the field. \n2. The proposed pre-estimation correction method is technically sound: it ensures that the gradient correction term aligns with the complex update format of adaptive methods (which a naive “post-estimation” approach fails to achieve). \n3. The paper presents a rigorous convergence analysis and extensive empirical studies, which together convincingly demonstrate the superior performance of the proposed method."}, "weaknesses": {"value": "The writing and experimental setup of this work can be further improved, please refer to the question part."}, "questions": {"value": "1. For the system model: in order to be rigorous, it is recommended to write $f_i$ in the form of the empirical risk and defining $\\mathcal{D}_i$ as the empirical distribution constructed by i.i.d. sampling from the local data distribution — that is, the local training set.\n2. Regarding the Adam‐optimizer used in this work (lines 160–161): it appears that the correction terms (bias correction) have not been included. Would adopting the bias‐corrected version of Adam affect the theoretical analysis in this paper?\n3. In the section “Problem with naive application of compensation,” the authors could provide further explanation as to why — in the SGD setting — despite the heterogeneity of data and thus $\\nabla f_i(x^*) \\neq 0$, SGD can still use the original correction term.\n4. For the experimental part, it is recommended to use momentum for estimating the gradient‐correction term, and then compare this method against the “pre-estimation correction term” method proposed in this paper.\n5. The authors could also consider including, in the communication‐rounds/simulated-time versus loss/accuracy curves, the mean values and corresponding standard deviations across multiple runs, in order to reflect the robustness of different algorithms/settings."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "S6eT15NYq3", "forum": "oKG6F733z6", "replyto": "oKG6F733z6", "signatures": ["ICLR.cc/2026/Conference/Submission11839/Reviewer_XP38"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11839/Reviewer_XP38"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760841497419, "cdate": 1760841497419, "tmdate": 1762922858358, "mdate": 1762922858358, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces FAdamGC, a novel algorithm to mitigate client drift in federated learning with adaptive optimizers like Adam. Arguing that naive correction fails, the authors propose a \"pre-estimation\" correction applied to raw gradients before moment computation. They provide convergence analysis and extensive experiments on image and language tasks to demonstrate FAdamGC's superior performance and stability in heterogeneous settings"}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. Addresses the critical and timely problem of making adaptive optimizers robust to data heterogeneity in FL.\n2. Presents extensive and convincing empirical results across diverse tasks (CNNs, LLM PEFT) and metrics, consistently outperforming strong baselines."}, "weaknesses": {"value": "1. (Major) The central claim of providing the first convergence guarantee for an adaptive FL method without a bounded gradient assumption appears to be incorrect. The paper \"Problem-Parameter-Free Federated Learning\" has already presented an adaptive FL algorithm and proven its convergence without this assumption. This significantly diminishes the claimed novelty of Theorem 5.2. The authors must acknowledge this prior art, thoroughly discuss it, and compare their theoretical framework, proof techniques, and resulting convergence rates. The current framing of the theoretical contribution is misleading and needs to be fundamentally revised.\n\n[1] Yan, Wenjing, et al. \"Problem-Parameter-Free Federated Learning.\" The Thirteenth International Conference on Learning Representations. 2025.\n\n2. The core algorithmic idea, termed \"Gradient Correction\" or \"pre-estimation correction,\" where control variates are used to correct the raw gradient before it enters the moment accumulators, is presented as a key contribution. However, this exact mechanism was already proposed and analyzed in the paper \"[1] Problem-Parameter-Free Federated Learning.\" The current paper fails to cite and compare against this work.\n\n3. The main theoretical result that forgoes the bounded gradient assumption (Theorem 5.2) is derived for the special case where β2 = 0. This setting reduces the optimizer to a method more akin to momentum with normalization, rather than the full Adam algorithm. Theorem 5.4. is based on bounded gradient assumption, which seems more strong. The paper should be more transparent about this limitation in the main text and abstract, as the current presentation might imply the result holds for the general Adam optimizer."}, "questions": {"value": "1. What are the primary technical hurdles that prevent the extension of the bounded-gradient-free analysis from the β2 = 0 case to the general case where β2 > 0?\n\n2. The empirical results for the language tasks (e.g., QQP, QNLI) show exceptionally large performance gains for FAdamGC. Do the authors have a hypothesis for why this specific correction mechanism is so particularly effective in the context of Parameter-Efficient Fine-Tuning (PEFT) with LoRA?\n\n3. In Figure 4, it is shown that the number of clients participating in tracking updates (Se) can be reduced significantly with only a minor impact on performance. Is there a theoretical relationship between the degree of data heterogeneity (α) and the minimum required Se to maintain stable convergence?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "R5REPSeH8e", "forum": "oKG6F733z6", "replyto": "oKG6F733z6", "signatures": ["ICLR.cc/2026/Conference/Submission11839/Reviewer_Gf9b"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11839/Reviewer_Gf9b"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791308523, "cdate": 1761791308523, "tmdate": 1762922858005, "mdate": 1762922858005, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FAdamGC, a novel federated optimization algorithm that integrates client-drift compensation into adaptive methods like Adam. The key idea is to inject a \"pre-estimation\" gradient correction term before the moment accumulation step to mitigate the effects of data heterogeneity. The authors provide a convergence analysis for non-convex settings, demonstrating that FAdamGC achieves a standard O(1/√SKT) rate without requiring a bounded data heterogeneity assumption in certain cases. Comprehensive experiments on both image classification and LLM fine-tuning tasks show that FAdamGC outperforms existing SGD-based and adaptive FL baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is well-written and clearly organized, making the proposed method and its analysis easy to follow.\n* The experimental evaluation is comprehensive, covering both image classification and large language model (LLM) fine-tuning tasks against several relevant baselines.\n* The core idea of injecting a gradient correction term before moment accumulation is intuitive and well-motivated."}, "weaknesses": {"value": "* The method requires transmitting both model parameters (x) and correction terms (y) in each round, which doubles the communication payload compared to methods like LocalAdam. While the paper provides Simulated Run Time (SRT) and total volume metrics, a direct plot of accuracy versus communication bits/volume would more clearly illustrate the efficiency trade-offs.\n* The paper empirically shows that β₂ > 0 is better than β₂ = 0, but an intuitive explanation for why the second-moment information is particularly beneficial in this corrected framework is expected.\n* When β₂ = 0, the update in Eq. (2) resembles gradient normalization, making the algorithm conceptually similar to the one in [a]. Consequently, the convergence analysis in Theorem 5.2 and the empirical performance would be expected to be similar. A direct comparison and discussion with this highly relevant work are needed to better position the paper's contribution.\n* Following the point above, if a key contribution is the inclusion of the second-moment term (β₂ > 0), its impact needs clearer justification. In the experiments, β₂ is set to 0.99, which is very close to 1. Additionally, an ablation study on the value of β₂ would be beneficial to understand its sensitivity and demonstrate its importance.\n\n[a] Yan, W., Zhang, K., Wang, X., & Cao, X. (2025). Problem-Parameter-Free Federated Learning. In The Thirteenth International Conference on Learning Representations."}, "questions": {"value": "* Table 1 provides a theoretical comparison of convergence rates. What would be the theoretical convergence rate for SCAFFOLD-M, and how would it compare to FAdamGC? This would provide a more complete picture, especially since SCAFFOLD-M is a key baseline in the experiments.\n* In lines 251-257 and Eq. (4), the paper argues that injecting the correction term ∇f(x*) − ∇fi(x*) makes the global optimum x* a fixed point. Could the authors provide a more detailed intuition for this? Furthermore, why here the correction is applied to the gradient for the first moment (m) but not for the second moment (v) in the denominator?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8KAsG5XlkM", "forum": "oKG6F733z6", "replyto": "oKG6F733z6", "signatures": ["ICLR.cc/2026/Conference/Submission11839/Reviewer_k38c"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11839/Reviewer_k38c"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946906357, "cdate": 1761946906357, "tmdate": 1762922857497, "mdate": 1762922857497, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a variant of the Adam optimizer that incorporates client-drift compensation, making it suitable for federated learning settings. This approach aims to address the limitations of naive client-drift handling and improves upon existing adaptive methods such as FedAvg and FA-NT."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The main contributions include (1) an algorithm with a novel gradient correction mechanism designed to stabilize updates across heterogeneous clients, (2) a theoretical convergence analysis that supports the proposed method, and (3) experimental results that demonstrate its effectiveness. The paper is clearly written and well-organized, making it easy to follow the motivation, methodology, and results. The authors present their technical novelty in a transparent and understandable manner."}, "weaknesses": {"value": "That said, the literature review appears rather limited. The discussion could be strengthened by including a broader comparison with recent federated optimization approaches and by justifying the choice of Adam as the base optimizer. In modern machine learning applications, alternative optimizers such as Muon or other momentum-based methods often demonstrate superior empirical performance, so the rationale for building upon Adam should be clarified.\n\nIn terms of experiments, the reported test accuracies are surprisingly low, which is unexpected for methods that explicitly address client-drift. It would be helpful if the authors could provide an explanation—perhaps related to dataset characteristics, hyperparameter choices, or implementation details. Overall, the work is clearly presented and methodologically sound, but the empirical results and contextualization within the broader literature could be improved.\n\nNote: there are a few formatting issues (margin violations), authors should double-check for those"}, "questions": {"value": "It would be valuable if the authors could address the questions and concerns outlined in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "O5u1ALoGTI", "forum": "oKG6F733z6", "replyto": "oKG6F733z6", "signatures": ["ICLR.cc/2026/Conference/Submission11839/Reviewer_t86o"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11839/Reviewer_t86o"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996362922, "cdate": 1761996362922, "tmdate": 1762922856994, "mdate": 1762922856994, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces FAdamGC, an adaptive gradient correction optimization algorithm that facilitates drift compensation using the Adam algorithm at the clients to address data heterogeneity. The algorithm utilizes a pre-estimation correction term based on Adam's moments. The theoretical analysis shows that FAdamGC provides better convergence guarantees than SGD-based corrective algorithms like SCAFFOLD under milder assumptions. The method achieves linear speedup convergence to stationary points. FAdamGC outperforms existing baselines empirically, although it requires additional communication costs. The paper also presents a selective tracking mechanism that chooses a subset of participating clients for updating correction terms, thereby reducing communication overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper provides sufficient motivation for all the ideations. It justifies using Adam at the client level because FedAdam is more sensitive to gradient noise. The paper also explains why naively adapting a SCAFFOLD-like strategy for client drift mitigation in adaptive algorithms yields suboptimal results, and it carefully constructs a control variate strategy for the Adam optimiser. \n\nThe paper proposes a drift compensation method for the Adam optimizer used by clients in federated learning, based on a fixed-point structure, which brings a new perpective to improve the horizontal FL.\n\nThe algorithm incorporates a drift compensation term by averaging the gradient of a client over local rounds and utilises this correction to construct a data heterogeneity-robust algorithm. The paper demonstrates that their algorithm is more robust compared to the naïve approach, as it converges with fewer global communication rounds. The analysis also supports that under milder assumptions, the algorithm achieves the convergence rate for general non-convex federated learning objectives.  \n\nThe paper is well-written, with clearly stated assumptions, detailed notations and results, and a well-articulated motivation for the research. The theorems and results were systematically laid out."}, "weaknesses": {"value": "The paper noted that drift compensations should intuitively include the fixed-point structure needed for consistent convergence across different clients. However, the fixed-point structure discussed relates to a single client, since the update rule used for fixed-point problem formulation corresponds to each client's local optimizer. A discussion on how this fixed-point structure is maintained in the multi-node FL optimization problem would clarify how this intuition applies to FL, where multiple local updates and clients are involved."}, "questions": {"value": "In Algorithm 1, $y^{(1)}$ and $y_i^{(1)}$ are not assigned any initial value. Can you recheck and justify?\n\nPractically, $y_i^{(t)}$ is the local rounds' average of batch gradients for the client. Then, $y^{(t+1)}$ is computed using the aggregate of the differences between $y_i^{(t+1)}$ and $y_i^{(t)}$. How does this serve as a proxy for the theoretical pre-estimation correction term \\nabla $f(x^\\ast)-\\nabla f_i(x^\\ast)$? \n\nThe performance of FAdamGC is claimed to be superior to existing algorithms, and the experiment setup is explained in detail. However, the experiments are conducted by setting a target accuracy for each dataset, and then the performance of the algorithms is measured based on the total number of global rounds and the simulated runtime (in minutes) required to reach that target accuracy. Why does the paper not compare training loss and test accuracy in the main text, which is standard? \n\nFigure 1 (3) shows that the gradient correction enables updates to move toward the global objective, but I do not understand how this demonstrates that client drift is being mitigated. Could you please elaborate?\n\nIn Theorem 5.2, the proof uses $\\beta_2=0$ compared to $\\beta_1=0$ in the proof of FedAdam, and there is no restriction on momentum terms in FedAMS. How are the assumptions considered milder, only because the gradient boundedness assumption is not needed in the proof if $\\beta_2=0$? In that case, for FedAdam and FedAMS, do those algorithms also not require a gradient bound for convergence if we take $\\beta_2=0$ in their analysis? \n\nI would like to understand why the substitution $\\tilde{m}$ is valid in equation (16). \n\n$c^{(k)}$ used in the proof of Theorem 5.2; is it $c^{(k,0)}$ as used in the proof of Theorem 5.4? \n\nHow is the expectation dropped in the first term of equation (92), and then how is it resolved to the square root of a squared term in equation (94) if the term should have an expectation there? \n\nBetter remove extra equation numbers for every line while formatting the appendix.\n \nIn [1], it is discussed that proper tuning of local and global step sizes in the implementation of FedAdam mitigates the effect of data heterogeneity but does not eliminate it. How does learning rate tuning for FAdamGC affect the performance? \n\n[1] Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konĕcnỳ, Sanjiv Kumar, and H Brendan McMahan. Adaptive federated optimization. arXiv preprint arXiv:2003.00295, 2020."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "upXlE30GQk", "forum": "oKG6F733z6", "replyto": "oKG6F733z6", "signatures": ["ICLR.cc/2026/Conference/Submission11839/Reviewer_rhHF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11839/Reviewer_rhHF"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission11839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762642095854, "cdate": 1762642095854, "tmdate": 1762922856536, "mdate": 1762922856536, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}