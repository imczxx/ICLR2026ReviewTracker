{"id": "NnlelrGapm", "number": 12720, "cdate": 1758209730899, "mdate": 1759897491532, "content": {"title": "UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Decision-Making", "abstract": "As Large Language Models (LLMs) are integrated into safety-critical applications involving sequential decision-making in the real world, it is essential to know when to trust LLM decisions. Existing LLM Uncertainty Quantification (UQ) methods are primarily designed for single-turn question-answering formats, resulting in multi-step decision-making scenarios being underexplored. In this paper, we introduce a principled, information‑theoretic framework that decomposes LLM sequential decision uncertainty into two parts: (i) internal uncertainty intrinsic to the current decision, which is focused on existing UQ methods, and (ii) extrinsic uncertainty, a Mutual-Information (MI) quantity describing how much uncertainty should be inherited from preceding decisions. We then propose UProp, an efficient and effective extrinsic uncertainty estimator that converts the direct estimation of MI to the estimation of Pointwise Mutual Information (MPI) over multiple Trajectory-Dependent Decision Processes (TDPs). UProp is evaluated over extensive multi-step decision-making benchmarks, e.g., AgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and DeepSeek-V3. Experimental results demonstrate that UProp significantly outperforms existing single-turn UQ baselines equipped with thoughtful aggregation strategies. Moreover, we provide a comprehensive analysis of UProp, including sampling efficiency, potential applications, and intermediate uncertainty propagation, to demonstrate its effectiveness.", "tldr": "", "keywords": ["LLM Uncertainty Quantification", "LLM Sequential Decision-Making"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/70f1e2301be1ad79e369d2f17751f311017da9ba.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper addresses the problem of uncertainty quantification in large language models within multi-step decision-making scenarios. It proposes an information-theoretic framework that decomposes uncertainty into ​intrinsic uncertainty​ and ​extrinsic uncertainty. The authors introduce the ​UProp method, which efficiently estimates extrinsic uncertainty by sampling from a ​trajectory-dependent decision process (TDP)​​ and approximating ​pointwise mutual information (PMI)​, thereby tackling the challenge of the inherent non-computability of extrinsic uncertainty. Experiments conducted on benchmarks including ​AgentBench-OS, HotpotQA, and StrategyQA​ validate the superiority of UProp, demonstrating AUROC improvements of 2.3% to 11%. Further analyses on sampling efficiency and applications such as selective prediction are also provided."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Framework Novelty. It is the first to decompose multi-step decision-making uncertainty into Intrinsic Uncertainty (IU) and Extrinsic Uncertainty (EU), providing a principled framework.\n2. Theoretical Soundness and Methodological Innovation. The convergence proofs and the local smoothness assumption enhance the method's credibility. UProp addresses the high computational complexity of Mutual Information (MI) estimation through Trajectory-Dependent Decision Process (TDP) sampling and Pointwise Mutual Information (PMI) approximation, effectively balancing efficiency with accuracy.\n3. Comprehensive experiments. The evaluation covers realistic scenarios such as operating system interactions and multi-hop question answering, and includes comparisons with multiple baselines, making the results highly convincing."}, "weaknesses": {"value": "1. High Sampling Dependency.​​ The TDP sampling process requires multiple LLM invocations, which may introduce inference latency issues.\n2. Dependence on Theoretical Assumptions.​​ The local smoothness assumption may not always hold in highly uncertain decision chains.\n3. Lack of Theoretical Boundary Analysis.​​ The study fails to explicitly specify the upper bound of the impact of PMI estimation errors on the overall uncertainty quantification (UQ) results."}, "questions": {"value": "1. How does the estimation error of Extrinsic Uncertainty (EU) propagate as the number of steps increases?​ Is there an analysis of an upper bound for this error?​\n2. In the context of extremely long decision sequences, does extrinsic uncertainty exhibit cumulative drift?​\n3. In large-scale tasks, particularly when the decision space expands rapidly, the computational burden of Monte Carlo sampling may become non-negligible. How can the algorithm be optimized to maintain efficiency when handling larger-scale decision-making tasks, especially for application scenarios with high real-time requirements?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "SvS1y9DEjt", "forum": "NnlelrGapm", "replyto": "NnlelrGapm", "signatures": ["ICLR.cc/2026/Conference/Submission12720/Reviewer_oBFz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12720/Reviewer_oBFz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761661422937, "cdate": 1761661422937, "tmdate": 1762923545070, "mdate": 1762923545070, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "Thank you for this interesting paper. I enjoyed reading it and have a question regarding the formulation in lines 213-221.\nYou state that: \"Conditioned on the realizations within TDP, the mutual information (MI) $I(y_t; y_{t−1}|x)$ over TDP at step t becomes a pointwise mutual information (PMI).\" Could you please elaborate on why this is the case?\nMy confusion stems from the relationship between PMI and KL divergence. According to the standard definition, the PMI is calculated as:\n$$PMI(y_t;y_{t-1}=y_{t-1}^{(k)}|x) = \\log \\frac{p_{\\theta}(y_t,y_{t-1}^{k}|x)}{p_{\\theta}(y_t|x)p_{\\theta}(y_{t-1}^{k}|x)}$$\nFrom my understanding, $p_{\\theta}(y_t|y_{t-1}^{(k)},x) \\cdot PMI(y_t;y_{t-1}=y_{t-1}^{(k)}|x)$ is equivalent to the KL divergence: $D_{KL}(p_{\\theta}(y_t|y_{t-1}^{(k)},x)\\parallel p_{\\theta}(y_t|x))$\n\nThis seems to contradict the equation in your paper, where you state that:\n\n$$PMI(y_t;y_{t-1}=y_{t-1}^{(k)}|x)=D_{KL}(p_{\\theta}(y_t|y_{t-1}^{(k)},x)\\parallel p_{\\theta}(y_t|x))$$\n\nFurthermore, regarding the approximation of MI with PMI, the standard expression for MI is an expectation over the PMI:\n\n$$I(y_t;y_{t-1}|x) = \\mathbb{E}{p_{\\theta}(y_t,y_{t-1}|x)} \\left[ \\log \\frac{p_{\\theta}(y_t,y_{t-1}|x)}{p_{\\theta}(y_t|x)p_{\\theta}(y_{t-1}|x)} \\right]$$\n\nThis definition, which involves the joint probability $p_{\\theta}(y_t,y_{t-1}^{(k)}|x)$, does not seem to be equivalent to directly using the PMI as an approximation for MI.\nCould you please provide a detailed explanation for these points? I want to ensure I haven't misunderstood something. Is it possible that I have made an error in my derivation, or perhaps I am missing some context about the problem? Alternatively, is this a common approximation or technique in uncertainty estimation that I am not aware of?\nThank you for your time and clarification."}}, "id": "T7kmW2eraj", "forum": "NnlelrGapm", "replyto": "NnlelrGapm", "signatures": ["~Zhizhao_Liu1"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "~Zhizhao_Liu1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12720/-/Public_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762963235756, "cdate": 1762963235756, "tmdate": 1762964338533, "mdate": 1762964338533, "parentInvitations": "ICLR.cc/2026/Conference/-/Public_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes UProp, a method to quantify uncertainty in Large Language Models for multi-turn question-answering and sequential decision-making—critical for judging when to trust LLM outputs. UProp decomposes uncertainty into two parts: Intrinsic Uncertainty(IU) and Extrinsic Uncertainty(EU). And Uprop calculates the EU through Trajectory-Dependent Pointwise MI since directly calculating EU is intractable. Experiments across multi-turn benchmarks (e.g., AgentBench-OS, HotpotQA) and state-of-the-art LLMs show UProp achieves more accurate uncertainty quantification than single-turn UQ baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is clearly written and aims to tackle the more realistic and challenging setting of multi-turn QA, providing a rigorous, information-theoretic foundation for it.\n2. UProp proposes a novel perspective for quantifying uncertainty in multi-turn question-answering. Its \"PMI in TDP\" method offers an efficient solution by converting the computationally expensive direct estimation of Mutual Information (MI) into a tractable process."}, "weaknesses": {"value": "1. Although UProp employs sampling to approximate distributions, this strategy introduces non-trivial computational costs, resulting in slower inference speeds and increased resource consumption. These factors may limit the method's applicability in real-time or large-scale deployment scenarios.\n2. The method heavily depends on a smoothness assumption. While intuitive, this assumption lacks theoretical grounding and may not hold in all practical conditions, potentially compromising the framework's generalizability.\n3. UProp is primarily evaluated on commonsense reasoning tasks with definitive answers. Consequently, its effectiveness and contributions remain unclear for other problem categories, such as those involving open-ended generation or creative tasks.\n4. There are some typos in the paper, e.g, Figure 1, Section 5."}, "questions": {"value": "1. The results on StrategyQA (Table 1) show a higher success rate for Qwen2.5 but a much lower AUROC compared to Gemma-2. Please discuss this result. Does it indicate that the estimated uncertainty does not always directly correlate with the final task success rate?\n2. Could the authors elaborate on the potential of Uprop in more exploratory environments (e.g., creative writing, simulations), where leveraging uncertainty is crucial for guiding the agent's actions to achieve higher performance?\n3. Is it possible to integrate the EU component with other single-turn UQ methods, and if so, what would be the effect?\n4. UProp employs ReAct as the reasoning method. How well would it perform with other reasoning methods?\n5. Quantifying output uncertainty in LLMs is a critical consideration, and recent work, PlanU [1], explores a similar direction. PlanU extends uncertainty quantification to the context of LLMs in reasoning tasks, aligning with the objectives of UProp. However, PlanU also introduces the additional aspect of considering environmental uncertainty. It would be valuable to further explore the distinctions between UProp and PlanU, especially in terms of how each approach handles their implications for uncertainty quantification.\n\n[1] PlanU: Large Language Model Reasoning through Planning under Uncertainty. NeurIPS 2025"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xYbUchEYue", "forum": "NnlelrGapm", "replyto": "NnlelrGapm", "signatures": ["ICLR.cc/2026/Conference/Submission12720/Reviewer_MkZL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12720/Reviewer_MkZL"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761713640748, "cdate": 1761713640748, "tmdate": 1762923544737, "mdate": 1762923544737, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of Uncertainty Quantification (UQ) for LLMs in multi-step decision-making. The authors propose UProp, a method that decomposes the total uncertainty into Intrinsic Uncertainty (IU) from the current decision and Extrinsic Uncertainty (EU) inherited from previous steps, and efficiently estimates the computationally challenging EU."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The research topic is valuable, targeting the under-explored uncertainty propagation in LLM multi-step decision-making (a critical issue for reliable agentic LLMs), the work aligns with current academic and industrial needs.\n2. UProp avoids complex auxiliary models or exponential space exploration, relying on lightweight sampling and approximation—striking a good balance between computational efficiency and estimation accuracy."}, "weaknesses": {"value": "- The reliance on a simple random sampling strategy for trajectory candidates lacks justification. The lack of discussion or ablation studies on sampling strategies leaves open the question of how sensitive UProp's performance is to the quality and diversity of the sampled trajectories.\n- The paper quantifies extrinsic uncertainty but does not verify its correlation with final decision error rates (e.g., whether higher extrinsic uncertainty correlates with more frequent multi-step reasoning errors)\n- Unaddressed performance in long-sequence scenarios, no experiments or discussions are provided on UProp’s behavior in multi-step decisions with over 10 steps (e.g., whether step-length normalization fully mitigates length bias, or if PdMI approximation error accumulates), limiting the method’s applicability to complex long-horizon tasks."}, "questions": {"value": "- How was the sampling strategy designed? Could the estimator's accuracy be significantly improved by employing a more intelligent sampling technique that prioritizes informative or diverse decision paths?\n- Is there a measurable correlation between the estimated extrinsic uncertainty and the actual error rate in multi-step decisions? Could the authors provide experimental evidence (e.g., error rate vs. EU scatter plots) to strengthen the practical utility of UProp?\n- How does UProp perform in long-sequence decision tasks? If estimation accuracy degrades with more steps, what strategies could be applied to maintain stability and mitigate bias?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "lcO06JwPec", "forum": "NnlelrGapm", "replyto": "NnlelrGapm", "signatures": ["ICLR.cc/2026/Conference/Submission12720/Reviewer_4e7F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12720/Reviewer_4e7F"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761728449733, "cdate": 1761728449733, "tmdate": 1762923544186, "mdate": 1762923544186, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an estimate method to estimate the LLM sequential decision uncertainty. First, the paper decomposes LLM sequential decision uncertainty into two parts, including internal uncertainty intrinsic to the current decision and extrinsic uncertainty as a Mutual-Information (MI) quantity of how much uncertainty is inherited from preceding decisions. Second, the proposed method as UProp achieves effective extrinsic uncertainty estimation, which converts the direct estimation of MI to the estimation of Pointwise Mutual Information over multiple Trajectory-Dependent Decision Processes. The results show that UProp significantly outperforms existing single-turn Uncertainty Quantification baselines, including sampling efficiency, potential applications, and intermediate uncertainty propagation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The theoretical analysis is relatively rigorous.\n2. The experimental results show that the algorithm is effective.\n3. The method simply estimates the proposed Extrinsic uncertainty in the multi-step decision-making of LLM with the pointwise mutual information by the Monte Carlo sampling."}, "weaknesses": {"value": "1. The innovation of the paper needs further clarification.\n2. There is a lack of computational cost analysis of the method.\n3. The method may be hard to generalize due to the large output space and hallucination of LLM."}, "questions": {"value": "1. Did you first propose to decompose the uncertainty of decision-making into intrinsic and extrinsic uncertainty with the information theory? If not, please introduce some previous related work. If yes, please provide more evidence.\n2. The backbone of LLM model may be additionally selected, including Claude 3 or Gemini 2.5 Pro, which has a powerful ability of decision-making or reasoning.\n3. Please add some benchmarks such as complex mathematical reasoning tasks or long-chain knowledge reasoning, etc.\n4. After quantifying intrinsic and Extrinsic uncertainties, how can you optimize LLM decisions through ReAct-style prompts?\n5. There are some problems with the manuscript. Why are some words underlined? And the symbols such as “➋” are uncommon in the academic papers. The researchers usually use “2)” or “b.” instead."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZP8hKMU5f7", "forum": "NnlelrGapm", "replyto": "NnlelrGapm", "signatures": ["ICLR.cc/2026/Conference/Submission12720/Reviewer_i8hd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12720/Reviewer_i8hd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761802033886, "cdate": 1761802033886, "tmdate": 1762923543826, "mdate": 1762923543826, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}