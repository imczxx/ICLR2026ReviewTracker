{"id": "3CPzUWIoNf", "number": 10189, "cdate": 1758163392839, "mdate": 1763715973220, "content": {"title": "A$^2$Search: Ambiguity-Aware Question Answering with Reinforcement Learning", "abstract": "Recent advances in Large Language Models (LLMs) and Reinforcement Learning (RL) have led to strong performance in open-domain question answering (QA). However, existing models still struggle with questions that admit multiple valid answers. Standard QA benchmarks, which typically assume a single gold answer, overlook this reality and thus produce inappropriate training signals. Existing attempts to handle ambiguity often rely on costly manual annotation, which is difficult to scale to multi-hop datasets such as HotpotQA and MuSiQue.\nIn this paper, we present A$^2$Search, an annotation-free, end-to-end training framework to recognize and handle ambiguity. At its core is an automated pipeline that detects ambiguous questions and gathers alternative answers via trajectory sampling and evidence verification. The model is then optimized with RL using a carefully designed $\\mathrm{AnsF1}$ reward, which naturally accommodates multiple answers.\nExperiments on eight open-domain QA benchmarks demonstrate that A$^2$Search achieves new state-of-the-art performance. With only a single rollout, A$^2$Search-7B yields an average $\\mathrm{AnsF1}@1$ score of $48.4$% across four multi-hop benchmarks, outperforming all strong baselines, including the substantially larger ReSearch-32B ($46.2$%). Extensive analyses further show that A$^2$Search resolves ambiguity and generalizes across benchmarks, highlighting that embracing ambiguity is essential for building more reliable QA systems.", "tldr": "", "keywords": ["Multi-hop QA;Reinforcement Learning; GRPO; Large Language Model; LLM agent"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/5ba811d87138019b4342b7e5e37e2e3e60a6acfc.pdf", "supplementary_material": "/attachment/bce6f96dd8f0a494f4035ae1d85a874dd8ba9245.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes A²SEARCH—an end-to-end RL framework that requires no manual annotation. Its core contribution lies in designing an automated annotation pipeline that automatically identifies ambiguous questions in multi-hop question-answering datasets and generates alternative, valid answers through trajectory sampling, evidence filtering, and LLM-based validation. After RL training, A²SEARCH can automatically identify ambiguous questions, enabling the model to output all reasonable answers within a single inference trajectory, thereby improving the realism of the training signal and the reliability of the evaluation. Experimental results show that A²SEARCH-7B achieves SOTA  performance on eight open-domain QA benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-  The paper clearly points out the pervasive mismatch between existing QA benchmarks (which assume a single gold answer) and real-world QA scenarios (where multiple valid answers exist). It is the first to propose a large-scale, annotation-free ambiguity solution specifically for the challenging multi-hop QA setting.\n-  The proposed four-step automated pipeline (Sampling, Filtering, Verification, and Grouping) is a significant technical contribution. It effectively utilizes the capabilities of existing LLMs to automatically discover and verify alternative answers, demonstrating a viable and scalable approach to augmenting training data without costly manual annotation.\n-  A2SEARCH-7B achieves SOTA results on multi-hop QA using only a single greedy decoding rollout. When compared to baseline models that typically require multiple sampled rollouts, this demonstrates the model's precise ambiguity-sensing capability and the significant efficiency of the proposed training paradigm."}, "weaknesses": {"value": "Although the model performs exceptionally well on the AnsF1 metric, the source of this performance gain is insufficiently distinguished in the methodology. \nIt is unclear whether the improvement stems from genuinely solving ambiguities across different semantic levels or merely from increasing the recall of paraphrased variants of a single reference answer. \n\nThe use of a single-rollout comparison for A2SEARCH (@1) against multi-rollout estimation for baselines (@3) may potentially overstate its advantage relative to the baselines' true underlying capability."}, "questions": {"value": "- The Attribution of Performance Improvements: Can a more detailed analysis be provided to better demonstrate the actual value of \"ambiguity perception\"? When A2SEARCH outputs multiple answers, what is the precision of its predicted answers? Does the model tend to over-generate to achieve higher recall, especially when the final answer is a single, unambiguous response? Is part of the model's superior performance merely due to being trained to output answers in a list format, which differs from baseline models that are optimized to provide a single best answer? The authors need to more clearly demonstrate that the benefits arise from the recognition of ambiguity, rather than just the output format of multiple answers.\n- Additional experiments: Based on the previous point of inquiry, could you provide a comparative model that is trained on the original single definitive answer but is capable of outputting a list of multiple answers? This would allow for a comparison to demonstrate the contribution of the ambiguity-aware data itself. Additionally, it would be beneficial to constrain A2SEARCH to output only the most likely single answer and compare its performance on AnsF1@1 with that of baseline models. This would help to demonstrate whether the introduction of ambiguity information during training has enhanced the model's single-answer reasoning capability.\n- Source of Baseline AnsF1/Recall@3 Data: What is the specific source for the baseline models' AnsF1/Recall@3 data reported in Table 1 and Table 2? Were these results taken directly from the original papers, or were they reproduced and estimated by the authors themselves using the specified sampling procedure?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sqnaeUZOxk", "forum": "3CPzUWIoNf", "replyto": "3CPzUWIoNf", "signatures": ["ICLR.cc/2026/Conference/Submission10189/Reviewer_FJjM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10189/Reviewer_FJjM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10189/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761728106498, "cdate": 1761728106498, "tmdate": 1762921555307, "mdate": 1762921555307, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles ambiguity in open-domain QA (i.e. the cases where a question has multiple valid answers) by proposing $A^2-SEARCH$, an annotation-free RL framework that automatically mines alternative answers via an evidence-based pipeline and trains an LLM with an answer-level F1 (AnsF1) reward that balances precision and recall in multi-answer settings. Experiments on eight benchmarks show state-of-the-art results with single-rollout decoding."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper proposes a method that addresses a significant problem in QA.\n- The authors present convincing empirical evidence supporting their claims, using several baseline models of various sizes and several datasets to check the performance of their model."}, "weaknesses": {"value": "- The paper does not address unanswerable queries - cases where retrieval fails and the model should abstain (e.g., say “I don’t know”). This omission is a substantial gap that limits real-world applicability of the framework.\n- At \"Step 1: Sampling\" (lines 248-258) the pipeline generates millions of trajectories, which may be computationally infeasible for many users; clearer reporting of the time cost of these experiments would be valuable.\n- If I understand correctly, the authors applied their training recipe exclusively to Qwen-family models to produce their $A^2-SEARCH$ model. I.e. they don't provide evidence for cross-family generality of this training approach (see \"Questions\" section).\n- Verification phase fully relies on proprietary models (Claude 3.5/3.7, OpenAI o3/o4-mini). Unpredictable availability of proprietary models and model drift may affect reproducibility and future re-runs; more results with open verifiers (or human audits at scale) would help.\n- Some parts of the paper are written in unclear way (see \"Questions\" section)."}, "questions": {"value": "- How sensitive are results to the choice/mix of verifiers? Could an all-open pipeline (e.g., Llama- or Qwen-based judge + open retriever) approach the same agreement/coverage?\n- What \"△\", \"□\", \"○\" symbols mean on the Figure 2?\n- What's going on in the \"Step 2\" on the Figure 2?\n- Do I understand correctly that you use Qwen-2.5-Intrusct 3B/7B specifically as a base models for your $A^2-SEARCH$ 3B and 7B correspondingly in the Tables 1 and 2?\n- Did you try other models, NOT from Qwen family, as a base models for your $A^2-SEARCH$? What is the difference in the performance for other models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "kEQlfcKgVJ", "forum": "3CPzUWIoNf", "replyto": "3CPzUWIoNf", "signatures": ["ICLR.cc/2026/Conference/Submission10189/Reviewer_wyg8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10189/Reviewer_wyg8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10189/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761734874289, "cdate": 1761734874289, "tmdate": 1762921554683, "mdate": 1762921554683, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the challenge of ambiguity in open-domain QA, noting that standard benchmarks often rely on a single reference answer, overlooking the reality that many questions admit multiple equally valid responses. To counter this, the paper proposes A^2 SEARCH, an annotation-free, end-to-end RL framework designed to recognize and handle ambiguity. This work proposes automated data generation pipeline that detects ambiguous questions and collects alternative answers via trajectory sampling and evidence verification. The subsequent RL training uses GRPO and an answer-level F1 reward, a metric tailored to accommodate multiple correct answers by rewarding coverage while penalizing over-generation. Eight open-domain QA benchmarks demonstrates that the approach achieves new state-of-the-art results, confirming that embracing ambiguity is essential for developing more reliable QA systems that can learn to sense ambiguity and retrieve multiple valid answers."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The motivation for this work is well explained, and the paper is generally well written. The paper effectively highlights the significant challenge posed by ambiguity in open-domain QA. The recognition that current RL pipelines deliver misleading signals by rewarding only the reference answer and penalizing valid alternatives provides a strong foundation for the proposed framework.\n\n- The proposed method is its fully automated pipeline for identifying ambiguous questions and gathering alternative answers via trajectory sampling and evidence verification. This annotation-free approach is critical, especially since scaling costly manual annotation to complex multi-hop datasets like HotpotQA and MuSiQue is difficult. This automation makes the approach highly practical and scalable.\n\n- The paper includes rich and detailed experiments, encompassing a variety of ablation studies and case analyses.\n\n- Models trained with the proposed method show high efficiency, achieving strong recall levels with fewer average tool calls compared to baselines, demonstrating more effective utilization of reasoning steps."}, "weaknesses": {"value": "- While the overall framework is effective, the novelty of the core learning method and reward design is moderate. The reward structure employs an outcome-only design and incorporates Answer-level F1 (AnsF1), which is derived from standard precision and recall metrics but tailored for multiple answers. The novelty lies primarily in the application of these existing mechanisms to the specific problem of ambiguity resolution, coupled with the sophisticated automated data pipeline, rather than new architectural or objective function designs.\n\n- While the paper confirms that the generated alternative answers are semantically distinct from the reference answer and evidence-supported, a more detailed breakdown of why they constitute genuine ambiguity is helpful. A statistical analysis quantifying the frequency of these different types of ambiguity (e.g., linguistic vs. entity vs. scope ambiguity) across the derived dataset would enrich the findings of the paper."}, "questions": {"value": "- Why are K LLM verifiers necessary? Just for the ensemble?\n- L174 - what is the meaning of a n_hat s?\n- How does performance increase even on non-ambiguity datasets? Are ambiguous answers substantially included in datasets like HotpotQA?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QHPRLfjxWQ", "forum": "3CPzUWIoNf", "replyto": "3CPzUWIoNf", "signatures": ["ICLR.cc/2026/Conference/Submission10189/Reviewer_6bRw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10189/Reviewer_6bRw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10189/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998385368, "cdate": 1761998385368, "tmdate": 1762921554192, "mdate": 1762921554192, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}