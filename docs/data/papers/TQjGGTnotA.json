{"id": "TQjGGTnotA", "number": 10691, "cdate": 1758179643341, "mdate": 1763434406010, "content": {"title": "Steering Merged LLMs for Multilingual Reasoning with Coefficient Optimization", "abstract": "Model merging has recently proven effective in enhancing the cross-lingual capabilities of reasoning models by integrating them with multilingual language models. However, existing methods typically apply a uniform merging strategy across languages, leading to a trade-off: while low-resource languages may benefit, high-resource languages such as English often suffer performance degradation. We attribute this limitation to insufficient coordination between the multilingual and reasoning models, where suboptimal representation merging impairs generalization. To mitigate this, we introduce **SteMerger**, a preference-driven framework that dynamically **steers** the model **merger** by optimizing the merging coefficients. Experiments on multilingual reasoning benchmarks show that SteMerger consistently improves performance across a wide range of languages, outperforming several strong baselines.", "tldr": "Steering Merged LLMs for Multilingual Reasoning with Coefficient Optimization", "keywords": ["multilingual reasoning", "LLM", "steering", "model merging"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/cc04d74f13c9ccb8447c19fa16eef222f976b74a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper argues that there is a limitation of insufficient coordination between the multilingual and reasoning models in model merging, leading to suboptimal representation merging impairs generalisation. To address this issue, the authors introduce a preference-driven framework that dynamically steers the model merger by optimising the merging coefficients."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper introduces a model merging framework for multilingual reasoning, which dynamically coordinates the merging process through optimising two adapters in different models.\n- The authors conduct extensive experiments on three different reasoning tasks, demonstrating that the proposed method consistently outperforms several baselines.\n- The analysis and observation on the trade-off between the multilingual model and the reasoning model in Section 3 is interesting, which might provide important insight for future research."}, "weaknesses": {"value": "- Since the preference data is generated by the multilingual model and reasoning model, it is interesting to see the win-rate result between the models for each language, which can serve as a plus for Section 3\n- In lines 267-269, it misses some important details about iteration, including: (1) is it online or offline generation? (2) how many iterations do you have? (3) the preference data is generated by the multilingual model and reasoning model in the first iteration, what about the following iterations?\n- This paper argues that translation incurs a high cost, while the proposed method requires additional cost to generate preference data\n- The experimental setting is somewhat unfair because the backbone comes from a baseline MindMerger. It would be more fair to have the same start point for all experiments\n- The performance improvement is limited: (1) compared to the backbone, the performance gain of the proposed method is limited (the percentage point improvement of the three tasks is 1.2, 0.3, and 1.4, respectively); (2) English still has performance degradation (Table 3), which is the main problem in the previous work proposed in this paper\n\nOthers:\n- Line 362: no space between footnote number and text\n- What is the difference between Merger* and SteMerger?"}, "questions": {"value": "See above Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RyFNHOmKPA", "forum": "TQjGGTnotA", "replyto": "TQjGGTnotA", "signatures": ["ICLR.cc/2026/Conference/Submission10691/Reviewer_Q1YD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10691/Reviewer_Q1YD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10691/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760698149168, "cdate": 1760698149168, "tmdate": 1762921935456, "mdate": 1762921935456, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "r86rS6dDwZ", "forum": "TQjGGTnotA", "replyto": "TQjGGTnotA", "signatures": ["ICLR.cc/2026/Conference/Submission10691/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10691/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763434405169, "cdate": 1763434405169, "tmdate": 1763434405169, "mdate": 1763434405169, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses a limitation in model merging approaches that combine multilingual and reasoning LLMs. Existing methods merge model representations uniformly across languages, which helps low-resource languages but often degrades performance in high-resource ones like English. This imbalance stems from the lack of coordination between multilingual and reasoning representations.\n\nTo solve this, the authors propose SteMerger, a preference-driven, coefficient-optimization framework that dynamically adjusts how much each source model (multilingual and reasoning) contributes during inference. Instead of fixed merging weights, SteMerger learns optimal coefficients via Direct Preference Optimization (DPO), using pairwise preferences between model outputs to guide training. This allows the merged model to “steer” its behavior based on input language or task context."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Novel model-merging framework with optimized coefficients instead of fixed blending.\n- Lightweight implementation via adapters.\n- Balanced performance across low- and high-resource languages."}, "weaknesses": {"value": "- The architectural novelty is limited and mainly extends existing merging and preference optimization methods.\n- The approach strongly depends on the quality of generated preference data.\n- There is no human evaluation of reasoning quality or linguistic fluency.\n- The paper does not analyze scaling behavior across larger models."}, "questions": {"value": "- Are there existing coefficient optimization methods (e.g., AdamMS) that inspired this approach?\n- Can SteMerger generalize beyond multilingual reasoning, for instance, to multimodal tasks?\n- How are preference pairs labeled when outputs differ subtly (e.g., semantically correct but numerically inaccurate)?\n- How are low-resource and high-resource languages defined quantitatively?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rOlo2yF9Lm", "forum": "TQjGGTnotA", "replyto": "TQjGGTnotA", "signatures": ["ICLR.cc/2026/Conference/Submission10691/Reviewer_6VRg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10691/Reviewer_6VRg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10691/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761574424933, "cdate": 1761574424933, "tmdate": 1762921934588, "mdate": 1762921934588, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SteMerger, a framework that iteratively generates cross-model preference pairs by creating pairs of answers from a multilingual model (in this case, mT5-xl) and a reasoning model (based on llama2-7B), henceforth LLM. Then, preferences are generated by checking the correctness of each answer. \n\nBoth models are optimized via adapters using DPO (Rafailov et al., 2023) and a weighted supervised fine-tuning loss. The model merging is done via concatenating (1) representations from the multilingual model, mapped into LLM representation space via a two-layer MLP (trained) and (2) representations from the 'native' LLM, and passed to the LLM for response generation, only the mapper and boundary tokens are updated. The method can be done in multiple iterations of obtaining data and training.\n\nThis method is applied and tested on three multilingual datasets: MGSM (Shi et al., 2023), a math dataset; X-CSQA (Lin et al., 2021), a multiple-choice QA dataset; and XNLI (Conneau et al., 2018), a natural language inference dataset. The paper compares against six baselines and shows that SteMerger has higher performance.\n\nIn the ablations, (1) the paper investigates how the merging affects the representations of the target language compared to English in MGSM. The paper shows that using SteMerger yields higher cosine similarity. (2) The paper investigates answer consistency in MGSM (?) where it shows that SteMerger yields more consistent answers. (3) The paper shows that using training data from multiple sources improves performance and that leaving out components such as the SFT loss and iterative training degrades performance. (4) In the last analysis, the paper shows that SteMerger works best for Bengali and English."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper depicts a relatively simple method to improve model merging for multilingual reasoning.\n- The method improves upon baselines in the framing of the paper.\n- The method is applied to a diverse set of tasks (math, MCQA, NLI)."}, "weaknesses": {"value": "- The writing can be improved. In many cases, there is guesswork left for the reader. \n    - For example, in analysis Q2, it is investigated whether the proposed method provides consistent answers. (1) It is implied that the analysis is done on MGSM, but not explicitly written. (2) Over how many predictions is this calculated?\n    - It is mentioned that the method can be applied for multiple iterations. How many worked best?\n    - As the experiments have already been conducted over three random seeds, why is the standard deviation not shown or a statistical significance test being conducted in Table 2, 3, and 4? The differences in performance seem marginal. As in analysis Q1 the paper applied statistical significance testing, it is missing from the rest of the experiments.\n-  The core method is weighting the supervised fine-tuning loss of the correct label (L225). The proposed range is [0.1, 0.2] (L362), why was this deemed the best? This analysis/ablation seems critical but is missing from the paper."}, "questions": {"value": "- Typological diversity in languages is a laden concept. How is this determined in this work and previous work it has been based on?\n- Why is reasoning only important for math?\n- How many samples are being filtered out of the answers are not correct (L222)?\n- Not a weakness: As the paper has adopted the same architectures as previous work, did the authors try more capable/recent models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vqby4snBJ6", "forum": "TQjGGTnotA", "replyto": "TQjGGTnotA", "signatures": ["ICLR.cc/2026/Conference/Submission10691/Reviewer_rWdp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10691/Reviewer_rWdp"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10691/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761584919651, "cdate": 1761584919651, "tmdate": 1762921934184, "mdate": 1762921934184, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies composing a multilingual model with a reasoning-oriented LLM (a “merger” framework). It aims to adaptively balance contributions from the multilingual encoder/representations and the reasoning model by training lightweight residual adapters with a preference-optimization objective (DPO) plus an NLL loss term. The method targets better trade-offs across high-resource and low-resource languages and evaluates on multilingual reasoning/understanding benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Important problem: Composition/merging of multilingual and reasoning abilities is an impactful direction, and the paper provides empirical results demonstrating consistent (if modest) gains on multiple multilingual tasks.\n* Lightweight & implementable: The approach freezes backbones and only trains small adapters/coefficients with standard losses (DPO + NLL), making it easy to integrate into existing pipelines.\n* Comprehensive analysis: The paper includes correlation analyses, ablations (e.g., removing NLL or iterations), and qualitative diagnostics (e.g., cross-language consistency), which help interpret where the gains come from."}, "weaknesses": {"value": "1. Limited novelty: At its core, the method reduces to training small adapters on a composed model using standard DPO (with an auxiliary NLL). The “adaptive gate” is largely conceptual—there is no explicit gating module, and the work does not introduce a fundamentally new optimization or architectural mechanism.\n2. Loose method–motivation alignment: The paper motivates an input-adaptive gating to balance multilingual vs. reasoning signals, but the implementation does not expose or analyze an explicit gate (granularity, parameterization, routing behavior). It remains unclear whether DPO-trained adapters truly realize the hypothesized gating dynamics beyond generic fine-tuning effects.\n3. Clarity issues:\n   - The description of the “gate/coefficients” is ambiguous (global vs. layer-wise vs. head-wise; conditioned on language ID or not; token- vs. sequence-level).\n   - The construction of DPO triplets is under-specified: What exactly is the query distribution, and what is the reference policy in DPO?\n\n4. Generalization & robustness under-evaluated: Results are shown for one primary composition pair, lacking of results on other model pairs. \n\n5. Efficiency trade-offs (latency/memory at inference) vs. baseline mergers."}, "questions": {"value": "What is the exact parameterization of the “coefficients/gate”? \n\n How are DPO triplets formed concretely? What are the queries (datasets/subsets), and how are wins/losses adjudicated per task? What is the reference model selected?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lZ6g4EKPSa", "forum": "TQjGGTnotA", "replyto": "TQjGGTnotA", "signatures": ["ICLR.cc/2026/Conference/Submission10691/Reviewer_rPTC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10691/Reviewer_rPTC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10691/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761790407151, "cdate": 1761790407151, "tmdate": 1762921933794, "mdate": 1762921933794, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}