{"id": "gPTjQxC74G", "number": 11971, "cdate": 1758204937391, "mdate": 1759897541808, "content": {"title": "Joint Adaptation of Uni-modal Foundation Models for Multi-modal Alzheimer's Disease Diagnosis", "abstract": "Alzheimer’s Disease (AD) is a progressive neurodegenerative disorder and a leading cause of dementia worldwide. Accurate diagnosis requires integrating diverse patient data modalities. With the rapid advancement of foundation models in neurobiology and medicine, integrating foundation models from various modalities has emerged as a promising yet underexplored direction for multi-modal AD diagnosis. A central challenge is enabling effective interaction among these models without disrupting the robust, modality-specific representations learned from large-scale pretraining. To address this, we propose a novel multi-modal framework for AD diagnosis that enables joint interaction among uni-modal foundation models through modality-anchored interaction. In this framework, one modality and its corresponding foundation model are designated as an anchor, while the remaining modalities serve as auxiliary sources of complementary information. To preserve the pre-trained representation space of the anchor model, we propose modality-aware Q-formers that selectively map auxiliary modality features into the anchor model’s feature space, enabling the anchor model to jointly process its own features together with the seamlessly integrated auxiliary features. We evaluate our method on AD diagnosis and progression prediction across four modalities: sMRI, fMRI, clinical records, and genetic data. Our framework consistently outperforms prior methods in two modality settings, and further demonstrates strong generalization to external datasets and other neurodegenerative diseases such as Parkinson’s disease.", "tldr": "We propose a multi-modal framework for Alzheimer’s Disease diagnosis that facilitates interaction among four modalities and their foundation models.", "keywords": ["Artificial Intelligence for sciences; Alzheimer's disease; multi-modal diagnosis; Foundation Models"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/13cf91c36b758fa90f34603b62b27294ae358134.pdf", "supplementary_material": "/attachment/7c13b05d8641855bfeaeed774b5ddca6c8d53b00.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a multi-modal framework for AD diagnosis that enables joint interaction among uni-modal foundation models through modality-anchored interaction. The experimental results show the effectiveness of the proposed framework."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) This paper proposes modality-aware Q-formers that selectively map auxiliary modality features into the anchor model’s feature space, enabling the anchor model to jointly process its own features together with the seamlessly integrated auxiliary features.\n\n (2) The proposed method is evaluated on AD diagnosis and progression prediction tasks involving the four most common data modalities, and experimental results validate the effectiveness of the proposed framework."}, "weaknesses": {"value": "(1) This paper designates one modality’s foundation model as an anchor and freezes most of its parameters to preserve its feature space, while projecting auxiliary modalities’ features extracted by other foundation models into this space for cross-modal interaction. This technical novelty is very limited.\n\n (2) There are several existing works about Modality-aware Q-formers (Tong et al., 2024; Zong et al., 2024; Alayrac et al., 2022; Liu et al., 2023a). Thus, it is not clear about the difference between the proposed model with these existing works. \n\n(3) This paper should compare the proposed model with more state-of-the-art AD diagnosis methods.\n\n (4) The authors should clearly summarize the contributions of this paper."}, "questions": {"value": "(1) There are several existing works about Modality-aware Q-formers (Tong et al., 2024; Zong et al., 2024; Alayrac et al., 2022; Liu et al., 2023a). Thus, it is not clear about the difference between the proposed model with these existing works. \n\n(2) This paper should compare the proposed model with more state-of-the-art AD diagnosis methods.\n\n(3) The authors should clearly summarize the contributions of this paper."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZVaweTFsEe", "forum": "gPTjQxC74G", "replyto": "gPTjQxC74G", "signatures": ["ICLR.cc/2026/Conference/Submission11971/Reviewer_okfp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11971/Reviewer_okfp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11971/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761829361511, "cdate": 1761829361511, "tmdate": 1762922969354, "mdate": 1762922969354, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a novel multi-modal framework for diagnosing Alzheimer's Disease (AD) through the joint adaptation of uni-modal foundation models. The central concept is the utilization of a \"modality-anchored interaction\" strategy. In this strategy, the foundation model of one modality serves as an anchor, and features from other auxiliary modalities are projected into its feature space via a proposed \"Modality-aware Q-former\". This enables interaction among modalities while maintaining the pre-trained representations of the anchor model. The framework is evaluated in the context of AD diagnosis and progression prediction, leveraging four modalities: sMRI, fMRI, clinical records, and genetic data, and it showcases superior performance compared to previous approaches."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- The proposed modality-anchored interaction framework for integrating uni-modal foundation models is a novel and interesting approach.\n- The paper addresses the important problem of multi-modal AD diagnosis, which has significant clinical relevance. The use of foundation models is a promising direction.\n- The method shows strong performance on AD diagnosis and progression prediction, outperforming several baselines. The generalization experiments on external datasets are a key strength."}, "weaknesses": {"value": "- The proposed framework is quite complex, involving multiple foundation models, Q-formers, and a two-stage training process. This might make it difficult to reproduce and apply in practice.\n- While the paper provides some analysis, more in-depth ablation studies could further clarify the contribution of each component (e.g., the cross-modal Q-former, the LoRA fine-tuning).\n- The paper states that each modality is used as an anchor in turn, and the final prediction is an aggregation. It would be interesting to see an analysis of how the choice of anchor modality affects performance. Is there an optimal anchor?"}, "questions": {"value": "1.  Could you provide more details on the computational cost of the proposed framework, both during training and inference?\n2.  Have you experimented with other methods for aggregating the predictions from the different anchor models? For example, a weighted average based on the confidence of each model.\n3.  How sensitive is the model to the number of learnable queries in the Q-formers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "2mQMDRX6iL", "forum": "gPTjQxC74G", "replyto": "gPTjQxC74G", "signatures": ["ICLR.cc/2026/Conference/Submission11971/Reviewer_gHU6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11971/Reviewer_gHU6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11971/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761919412862, "cdate": 1761919412862, "tmdate": 1762922968774, "mdate": 1762922968774, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to use multiple Q-formers to align various medical modalities for Alzheimer's disease prediction. The authors specifically use train these Q-formers by taking one modality as an anchor, and aligning the other modalities to the latent space of the anchored modality."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The quantitative results are quite convincing, the authors compare the method across three different datasets, and they perform various ablation studies."}, "weaknesses": {"value": "1) The authors focus a lot on classification performance, but there are many other tasks that are possible within these datasets. Specifically, to further strengthen their results the authors can show that their model also performs better when predicting biomarkers, age, etc. The classification tasks, although important, are not the only way to evaluate these models.\n2) The approach is not that technically novel. There are many papers that align modalities using Q-formers, and it is therefore unclear to me what the technical novelty is in this paper beyond a new application area. A paper that mostly focuses on a new application area is fine, but the application area is quite limited (the authors restrict themselves to Alzheimer's disease instead of broadly neurological disorders), and although results are clearly better in the tables, it is unclear how significant these results are.\n3) This brings me to the third point, which is that the authors do not seem to use cross-validation when evaluating their model(s), and do not compute confidence intervals or standard deviations for their results. Especially in neuroimaging, where the exact training and test subsets can have a large impact on the results, it is important to perform experiments over multiple training and test sets, and even initialization seeds, to ensure results are repeatable.\n4) The authors mention modality-aware Q-formers in the introduction, but do not discuss the referenced papers in depth in the related work section. In general, I think the authors can do a much better job at placing their work into the context of current work, especially given how large the field of multimodal foundation models is. Make sure to highlight exactly how your model and use of Q-formers is different, and why this is leading to performance improvements."}, "questions": {"value": "1) Figure 2: What is the difference between the authors' method and a Q-former?\n2) The unimodal performance for the M4Survive and LateFusion models is sometimes worse than the unimodal performance, which begs the question: How fair are the comparisons with the baselines? Do the authors use the same unimodal foundation models and fine-tuning approaches? For example, in the authors' model they use fine-tuned unimodal foundation models, is this also the case for the multimodal baselines?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HTD0JyMJ1j", "forum": "gPTjQxC74G", "replyto": "gPTjQxC74G", "signatures": ["ICLR.cc/2026/Conference/Submission11971/Reviewer_x1Jq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11971/Reviewer_x1Jq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11971/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761929035917, "cdate": 1761929035917, "tmdate": 1762922968318, "mdate": 1762922968318, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a multi-modal framework for Alzheimer’s Disease (AD) diagnosis that integrates several uni-modal foundation models (for sMRI, fMRI, clinical records, and genetic data). The core innovation is the modality-anchored interaction mechanism, where one modality serves as an anchor, and others act as auxiliary inputs. To align heterogeneous feature spaces, the authors introduce modality-aware Q-formers, transformer-based connectors that selectively map auxiliary features into the anchor modality’s feature space. The method is evaluated on ADNI, OASIS-3, and PPMI datasets for AD and Parkinson’s disease, showing state-of-the-art accuracy and generalization under both modality-complete and modality-incomplete scenarios."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Innovative framework: The modality-anchored interaction and modality-aware Q-former are novel and conceptually strong for integrating pre-trained models across heterogeneous medical modalities.\n2. Strong performance: The proposed method consistently outperforms baselines across tasks, achieving superior accuracy, specificity, and sensitivity in AD diagnosis and progression prediction.\n3. Comprehensive evaluation: Results are validated on multiple datasets (ADNI, OASIS-3, PPMI), demonstrating solid generalization to out-of-distribution data and to a different disease.\n4. Thorough experimentation: Includes modality-complete/incomplete settings, ablation on foundation model choice, number of queries, and visualization of attention maps for interpretability."}, "weaknesses": {"value": "1. Limited interpretability for clinicians: While attention visualization is provided, the interpretability of the fused multimodal decision process remains abstract; more clinical linkage to specific biomarkers would be valuable.\n2. Complexity and scalability: The two-stage fine-tuning pipeline increases computational demands; practical feasibility in clinical deployment is not analyzed.\n3. Dependence on large pre-trained models: The framework assumes availability of powerful foundation models, which may not always be accessible or easy to fine-tune with limited resources.\n4. Limited cross-modal interpretive analysis: The paper would benefit from a deeper analysis of why certain modality combinations improve results (e.g., specific complementarity between clinical and imaging data)."}, "questions": {"value": "1. Q-former Configuration: How sensitive are the results to the number of queries and attention heads in the modality-aware Q-former? Could a lighter version achieve comparable performance?\n2. Scalability: Can the approach be generalized to more than four modalities or to non-neuroimaging domains?\n3. Interpretability: Can the method mechanisms be linked to specific neurobiological or genetic markers for clinical interpretability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "p2UVRJF7qh", "forum": "gPTjQxC74G", "replyto": "gPTjQxC74G", "signatures": ["ICLR.cc/2026/Conference/Submission11971/Reviewer_bkBU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11971/Reviewer_bkBU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11971/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762047115647, "cdate": 1762047115647, "tmdate": 1762922967893, "mdate": 1762922967893, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}