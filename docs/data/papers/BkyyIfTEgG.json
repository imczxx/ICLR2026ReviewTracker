{"id": "BkyyIfTEgG", "number": 12364, "cdate": 1758207289444, "mdate": 1759897514550, "content": {"title": "On Differential Private $\\ell_1$, $\\ell_2$ and $\\ell_p^p$ Distance Queries", "abstract": "We introduce a refined differentially private (DP) data structure for kernel density estimation (KDE) with $\\ell_1$, $\\ell_2$ and $\\ell_p^p$ kernels. \nThis new DP data structure offers not only improved privacy-utility tradeoff but also better query efficiency over prior results.\nSpecifically, we study the mathematical problem: given a similarity function $f$ (or DP KDE) and a private dataset $X \\subset \\mathbb{R}^d$, our goal is to preprocess $X$ so that for any query $y\\in\\mathbb{R}^d$, we approximate $\\sum_{x \\in X} f(x, y)$ in a differentially private fashion.\nThe best previous algorithm for $f(x,y) =\\| x - y \\|_1$ is the node-contaminated balanced binary tree by [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024]. \nTheir algorithm requires $O(nd)$ space and time for preprocessing with $n=|X|$. \nFor any query point, the query time is $\\alpha^{-1}d \\log^2 n$, with an error guarantee of $(1+\\alpha)$-approximation and $\\epsilon^{-1} \\alpha^{-0.5} d^{1.5} R \\log^{1.5} n$. \n\nIn this paper, we use the same space and pre-processing time, improve the best previous result [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024] in three aspects\n- We reduce query time by $\\alpha^{-1} \\log n$ factor\n- We improve the approximation ratio from $\\alpha$ to $1$\n- We reduce the error dependence by a factor of $\\alpha^{-0.5}$\n\nFrom a technical perspective, our method of constructing the search tree differs from previous work [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024]. \nIn prior work, for each query, the answer is split into $\\alpha^{-1} \\log n$ numbers, each derived from the summation of $\\log n$ values in interval tree countings. \nIn contrast, we construct the tree differently, splitting the answer into $\\log n$ numbers, where each is a smart combination of two distance values, two counting values, and $y$ itself. \nWe believe our tree structure may be of independent interest.", "tldr": "", "keywords": ["Differential Privacy", "Kernel Density Estimation", "Distance Query", "Data Structure", "Balanced Binary Tree"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/0f5a578105d86fe503172380bc5b09b5372a33c9.pdf", "supplementary_material": "/attachment/a074f7df53f424f54229478bb7dfaed3f0dbce79.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a refined differentially private data structure for kernel density estimation with $l_1$, $l_2$, and $l_p^p$ distance kernels. The proposed method theoretically improves upon the current state-of-the-art (Backurs et al., ICLR 2024) in query time, approximation ratio, and additive error. While the theoretical contribution is significant, the experimental validation is somewhat limited, and the writing contains several typographical errors that need addressing."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Theoretical Contribution: This paper makes a clear and valuable theoretical advance. The novel balanced binary tree structure, which stores both distance sums and counts, successfully reduces the query time by a factor of $\\alpha^{-1} \\log n$ and improves the error bounds by eliminating the multiplicative $(1+\\alpha)$ approximation and reducing the additive error dependence on $\\alpha$.\n2. Technical Novelty: The key observation (Lemma 3.1) that decomposes the $l_1$ distance into four components is elegant and drives the efficiency gains. This core idea is cleanly extended to $l_2$ and $l_p^p$ distances in the appendices, demonstrating the generality of the approach.\n3. Rigorous Analysis: The paper provides a thorough theoretical analysis, including proofs for initialization time, query time, differential privacy guarantees (using the Laplace mechanism), and error bounds. The analysis appears sound and follows established DP composition theorems."}, "weaknesses": {"value": "1. Limited Experimental Evaluation: The experiments are conducted only for the 1-dimensional $l_1$ case, leaving the performance on higher-dimensional data and for $l_2$/$l_p^p$ kernels invalidated. The scale of the experiments is relatively small (n ≤ 4096), and it is unclear how the method performs on large-scale, real-world datasets. The figures (e.g., Figure 3) lack clear axis labels and detailed captions, making them difficult to interpret and the results hard to reproduce.\n2. Writing and Presentation: There are several typos and unclear statements throughout the text. The error analysis in the proof of Lemma 3.6 contains confusing formula references. The range and impact of the parameter p in the $l_p^p$ section could be explained more clearly. Some proofs, particularly for the high-dimensional extensions, are somewhat terse and could benefit from more detailed exposition.\n3. Practical Limitations: The proposed data structure is designed for static datasets and does not support dynamic updates. The space complexity of $O(nd)$ could become a bottleneck for very high-dimensional data."}, "questions": {"value": "1. Experimental Evaluation: Can the authors provide experimental results for higher dimensions (d > 1) and for the $\\ell_2$ and $\\ell_p^p$ kernels to comprehensively validate the theoretical claims?  Could the algorithm be compared against a wider range of baseline methods, such as DP-KDE methods based on hashing or sampling? Furthermore, the number of baselines compared in this paper is insufficient. It should include comparisons with more high-level methods and the design of additional experimental schemes, as the current experimental content appears rather limited.\n2. References: The references are not sufficiently up-to-date. The authors should pay attention to more high-quality literature published since 2025. Additionally, this paper has cited an excessive number of arXiv preprints. Is this appropriate? The authors should thoroughly review the related work and references. Moreover, the writing styles of the abstract and conclusion in this paper do not seem to conform to standard conventions. The authors should further enhance their presentation in this regard.\n3. Theoretical Details: For $l_p^p$ queries, how does the value of p impact practical performance? Does the method support non-integer p? Has the authors considered using other noise mechanisms (e.g., Gaussian noise) to achieve $(\\epsilon, \\delta)$-DP, and how would that affect the error bounds?\n4. Writing Improvements: It is recommended to number all Algorithms/Equations and reference them clearly in the main text. All figures should be improved with proper axis labels, legends, and descriptive captions. A thorough proofreading is necessary to correct typographical errors and improve the clarity of explanations.\n5. The supplementary code material is incomplete and lacks explanations for reproduction. The authors need to provide complete and credible reproducible code."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "iV6xtGM6dP", "forum": "BkyyIfTEgG", "replyto": "BkyyIfTEgG", "signatures": ["ICLR.cc/2026/Conference/Submission12364/Reviewer_zMT4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12364/Reviewer_zMT4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12364/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760950795164, "cdate": 1760950795164, "tmdate": 1762923276489, "mdate": 1762923276489, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a refined differentially private (DP) data structure for kernel density estimation (KDE) with multiple distance kernels. The theoretical results significantly improve the best-known results in terms of query efficiency and approximation factor, while reducing additive errors. Numerical experiments also demonstrate the effectiveness of the proposed method in a proof-of-concept manner."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "**S1.** The theoretical results improve upon the best-known results and make clear novel contributions.\n\n**S2.** The proposed methods show good technical quality.\n\n**S3.** The paper is well-organized, and the presentation is generally clear and easy to follow.\n\n**S4.** The methods and theoretical results present great significance in the domain of theoretical ML."}, "weaknesses": {"value": "**W1.** There are some inconsistencies between $O(\\cdot)$ and $\\cdot$. The authors should double-check whether an expression indicates a specific number or a magnitude for complexity.\n\n**W2.** The experiments are somehow insufficient. The authors can conduct additional experiments on real-world datasets or with other distance kernels to further validate the effectiveness of the proposed methods."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "etLFji460h", "forum": "BkyyIfTEgG", "replyto": "BkyyIfTEgG", "signatures": ["ICLR.cc/2026/Conference/Submission12364/Reviewer_7WQm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12364/Reviewer_7WQm"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12364/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761667390393, "cdate": 1761667390393, "tmdate": 1762923276204, "mdate": 1762923276204, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Let $R > 0$, and let $X \\subseteq [0, R)^d$ be a dataset of size $|X| = n$.  \nThe paper studies the problem of constructing an $\\epsilon$-differentially private data structure that can answer queries of the form\n$$\n    \\sum_{x \\in X} \\Vert x - y \\Vert_1 = \\sum_{i = 1}^d \\sum_{x \\in X} \\vert x_i - y_i \\vert,\n$$\nwhere $y \\in [0, R)^d$ is a query vector.\n\nTo address this, the paper reduces the problem to designing $\\epsilon$-differentially private data structures that estimate $\\sum_{x \\in X} \\vert x_i - y_i \\vert$ for each coordinate $i \\in [d]$, since the overall $\\ell_1$ distance is simply the sum of these estimates.  \nThe key observation is that\n$$\n    \\sum_{x \\in X} \\vert x_i - y_i \\vert \n        = y_i \\cdot |\\{ x \\in X : x_i < y_i \\}| - \\sum_{x \\in X : x_i < y_i} x_i\n          + \\sum_{x \\in X : x_i > y_i} x_i - y_i \\cdot |\\{ x \\in X : x_i > y_i \\}|.\n$$\nHence, it suffices to construct data structures that estimate:\n1. $|\\{ x \\in X : x_i < y_i \\}|$ and $|\\{ x \\in X : x_i > y_i \\}|$, and  \n2. $\\sum_{x \\in X : x_i < y_i} x_i$ and $\\sum_{x \\in X : x_i > y_i} x_i$.\n\nThe data structure is built as follows:\n1. Partition $[0, R)$ into $n$ equal-sized intervals, each of length $R/n$. For simplicity, assume $n$ is a power of $2$. Each $x \\in X$ is assigned to the interval it belongs to.  \n2. Treat each interval as a leaf node and construct a complete binary tree over these nodes.  \n3. For each node, maintain two quantities:  \n   - the sum of all $x \\in X$ belonging to the leaf nodes covered by this node, and  \n   - the count of such $x$.  \n4. Add Laplace noise to each node to ensure differential privacy.\n\nGiven a query $y$, let $I_y$ denote the leaf node containing $y$, and let $X_{I_y}$ be the subset of $X$ that falls in $I_y$.  \nUsing the binary tree, one can compute a noisy estimate of $\\sum_{x \\in X \\setminus X_{I_y}} |x_i - y_i|$ in $O(\\log n)$ time.  \nFor the leaf node error, we have $\\sum_{x \\in X_{I_y}} |x_i - y_i| \\le n \\cdot (R/n) = R$.\n\nThis approach removes the multiplicative error in Backurs et al. (2024) while also reducing both the additive error and the query time.\n\nThe paper further extends the results to the $\\ell_2$ and more general $\\ell_p$ norms, although the improvements in these cases are less significant than in the $\\ell_1$ case."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper achieves state-of-the-art error bounds and query times.  \n\n2. The manuscript is well written, with clearly presented ideas and carefully chosen notations.  \n\n3. The proposed algorithm leverages the structure of the $\\ell_1$ distance in a clever way, leading to a simple and elegant design."}, "weaknesses": {"value": "I did not identify any significant drawbacks in the paper."}, "questions": {"value": "Typo (lines 217–218). The additive error is stated incorrectly. It should be\n$$\nO\\big(\\epsilon^{-1} R \\log^{3/2} n\\big),\n$$\ninstead of the currently printed expression."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "X9J1bQ4KpK", "forum": "BkyyIfTEgG", "replyto": "BkyyIfTEgG", "signatures": ["ICLR.cc/2026/Conference/Submission12364/Reviewer_wUxb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12364/Reviewer_wUxb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12364/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761843177680, "cdate": 1761843177680, "tmdate": 1762923275973, "mdate": 1762923275973, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper is about the (very important) problem of differentially-private kernel density estimation, offering significant improvements over the previous SOTA algorithm (Backurs 2024). Formally, the problem is to compute the following sum.\n\n$$\\sum_{x \\in X} \\|x - y\\|_1$$\n\nThe algorithm of Backurs et. al. considers each dimension separately, reducing the d-dimensional problem to d instances of the 1-dimensional problem. For each dimension $i$, the algorithm (1) discretizes each entry from the dataset $X$ to a multiple of $R / N$, (2) counts the number of values that map to each of the $N$ discretization points, and (3) constructs a binary interval tree over the discretization points, where each node contains the sum of its childrens' counts. To query the structure, we issue interval-count queries around $y_i$ with geometrically increasing interval sizes. $\\log(N)/\\alpha$ interval queries are needed for the approximation (where $\\alpha$ is the multiplicative approximation error) and each one has complexity $\\log(N)$, which determines the overall time complexity.\n\nIn this paper, the authors modify the tree representation of Backurs et. al. in a clever way. The authors show that one can decompose the L1 distance into two sums that can be pre-computed and two sums that are query-dependent. By modifying the tree to store the pre-computed sums,\nPrivacy is then achieved using methods similar to prior work. The really interesting part is that this alternative representation allows us to use a different interval strategy (linear intervals that subdivide $[0,1]$ rather than geometric intervals that surround $y_i$). \n\nThe result is an algorithm that improves on both the query time and the approximation error."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper contains the best known algorithm for DP distance queries, an important problem and active area of research.\n2. The arguments of the paper are presented in a way that is very easy to follow. I particularly appreciated Section 3.1 - the argument about Lemma 3.1 made the whole strategy clear.\n3. The algorithm is intuitive and elegant."}, "weaknesses": {"value": "This is a solid paper. While it could be improved by a stronger empirical evaluation (the Backurs paper had results for KDE as well as for distance queries, and unless I am mistaken there are not KDE experiments here).\n\nMy other request would be to show a diagram with your vs. their interval strategy (and perhaps a motivating example showing why the extra intervals are not necessary). It took me some time to understand how you were able to reduce the number of calls to the interval tree."}, "questions": {"value": "Is your distance decomposition necessary to be able to use your linear intervals? I guess this is probably true, since they would fail with the old algorithm when $\\|x - y\\| = 0$. I suppose the reason why it works is because your strategy multiplies by $y$ after doing the interval count?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4FDGIOLOuA", "forum": "BkyyIfTEgG", "replyto": "BkyyIfTEgG", "signatures": ["ICLR.cc/2026/Conference/Submission12364/Reviewer_VCiU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12364/Reviewer_VCiU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12364/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763081460855, "cdate": 1763081460855, "tmdate": 1763081460855, "mdate": 1763081460855, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}