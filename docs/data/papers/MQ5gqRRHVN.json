{"id": "MQ5gqRRHVN", "number": 10274, "cdate": 1758165710215, "mdate": 1763710569901, "content": {"title": "Facts in Stats: Impacts of Pretraining Diversity on Language Model Generalization", "abstract": "Language models are pretrained on sequences that blend statistical regularities (structures making text fluent) with factual associations between specific tokens (corresponding to world knowledge). While recent work suggests that the variability of their interaction, such as paraphrases of factual associations, critically determines generalization ability, we lack a systematic analysis of these multifaceted impacts. This paper introduces a flexible synthetic testbed that combines a statistical stream of generic tokens with an abstract factual stream of source-target token pairs, enabling fine-grained control over their interaction. Specifically, the design enables the independent control of diversity nature by manipulating stream composition (contextual structure) and the level of diversity by varying which statistical streams each fact appears in. Through controlled experiments, we find that while higher contextual diversity delays in-distribution (ID) factual accuracy, its effect on out-of-distribution (OOD) generalization depends critically on contextual structure. In some cases, OOD performance follows the same trend as ID, but in others, diversity becomes essential for non-trivial factual learning. Even when low diversity prohibits factual recall, optimal diversity levels depend on training duration. Beyond factual recall failures, we identify structures where statistical generalization fails independently, and others where both capabilities collapse simultaneously. This demonstrates how the interplay between contextual design and diversity level impacts different aspects of generalization. Through detailed mechanistic analysis of transformer components, we find that learned embeddings are key to successful generalization under high-diversity data. Overall, our synthetic framework allows us to isolate effects that would be confounded in large-scale studies, thus offering a controlled testbed for future investigations.", "tldr": "In a synthetic playground that disentangles statistical patterns from factual relations, we empirically study the training dynamics and show how context diversity shapes their interplay.", "keywords": ["data diversity", "factual recall", "Markov chains", "language models", "transformers", "training dynamics"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c43f7fdcfdbb8f1c7dd275d63166e7299cfd2e5a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates how language models learn and distinguish factual knowledge from statistical patterns during pretraining. It investigates how the diversity of contexts in which a fact appears (i.e., paraphrasing) impacts both factual recall and statistical generalization. The paper's primary contribution is the introduction of a synthetic testbed that decouples the training data into a \"statistical stream\" (templates with controllable statistical) and a \"factual stream\" (atomic source-target pairs). This framework allows for fine-grained, independent control over the level of diversity (how many different templates a fact is seen in) and the contextual structure (how the templates themselves vary), which the authors argue was a key limitation in previous, less-controlled studies.\n\nUsing this testbed, the paper investigates the relationship between diversity and generalization. For example, while high diversity (seeing a fact in many different templates) slows down in-distribution (ID) factual learning, it is often crucial for out-of-distribution (OOD) generalization. A mechanistic analysis identifies that learned embeddings and the unembedding layer are the primary components enabling factual generalization under high diversity, while attention mechanisms are key for statistical learning. This work moves beyond prior synthetic studies, which often used fixed templates and focused solely on factual recall, by being the first to systematically model and analyze the interplay and trade-offs between statistical learning and factual acquisition."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper's primary strength is its experimental design. By cleanly decoupling statistical and factual streams, it offers fine-grained control over diversity and contextual structure â€” a significant advance over prior work. This design compellingly allows the authors to move beyond just factual recall and be one of the first to systematically investigate the interplay and trade-offs between statistical generalization and factual acquisition.\nWhat's more, the paper provides a strong mechanistic analysis to explain why these trade-offs occur, identifying distinct optimization bottlenecks for each learning type . The fact that this minimal, reproducible testbed can still capture these phenomena (like stage-wise learning) seen in larger-scale studies is a plus."}, "weaknesses": {"value": "My main concerns with this paper relate to its translation to realistic LLM training. My biggest question is about the distinct, non-overlapping vocabularies for statistical and factual tokens. This design removes the real-world ambiguity where a single token must participate in both roles, forcing the model to rely on context. [cite_start]I wonder if this simplification artificially affects the learning dynamics, perhaps exacerbating the observed importance of the (un)embedding layers in separating these tokens, rather than testing the internal processing required in a more realistic, mixed-vocabulary setting.\n\nA secondary concern is the deliberately small model size. While I appreciate the authors' open acknowledgment and justification for this (tractability and reproducibility), and their checks on 1- and 10-layer models, it does leave open the question of how these specific bottlenecks might shift in the larger architectures."}, "questions": {"value": "Do I understand correctly that the models are trained single-epoch? Whenever a statistical template is used, the actual tokens are sampled anew; and only the fact tokens are repeatedly found at their respective positions?\n\nWhat is effective token frequency for fact vs. statistical tokens / how often do they appear throughout the whole training set? It appears with so many fact tokens and only few statistical tokes, there might be a significant imbalance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gm8Jegee82", "forum": "MQ5gqRRHVN", "replyto": "MQ5gqRRHVN", "signatures": ["ICLR.cc/2026/Conference/Submission10274/Reviewer_Rbvz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10274/Reviewer_Rbvz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10274/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761935450968, "cdate": 1761935450968, "tmdate": 1762921627942, "mdate": 1762921627942, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studied the learning and generalization of \"statistical structure\" (different Markov chain structures) vs \"facts\" (particular tokens that ) in small transformers, using a synthetic setting designed to emulate those aspects of natural language pretraining data.. They swept across many parameters controlling data diversity (and also freezing various parts of the network after training in different regimes), and investigated the effects on learning and generalization of the \"statistics\" and \"facts\", and learning dynamics."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* very nice coverage of the parameter space. it can be difficult to study the effects of parameters on training in an exhaustive way, which they did well\n* nice breakdown of the three types of learning: \"positions\" vs \"statistics\" vs \"facts\"\n* interesting results, esp how diversity doesn't monolithically affect the different types of generalization"}, "weaknesses": {"value": "* limited scale \n* Can you motivate more why it seems necessary to study the learning of facts and linguistic structure simultaneously? Why not e.g. facts vs reasoning, or facts vs learning larger scale statistical structure. Or each of them alone. Unclear why this is an important question\n* I find the experimental setup very interesting. However, can you provide more precise motivation for why the Markov chain structure mirrors the statistical structure of natural language, while the two positions for \"fact insertion\" are a good representation of \"facts\"? Theoretically and/or empirically"}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Fge9ixOQrN", "forum": "MQ5gqRRHVN", "replyto": "MQ5gqRRHVN", "signatures": ["ICLR.cc/2026/Conference/Submission10274/Reviewer_CxgV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10274/Reviewer_CxgV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10274/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761971199227, "cdate": 1761971199227, "tmdate": 1762921627441, "mdate": 1762921627441, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The author investigate how linguistic diversity influences factual and statistical learning in language models. They design a controllable synthetic testbed separating a statistical stream and a factual stream, allowing independent control of context structure and diversity level. They that higher diversity delays factual recall within distribution but is necessary for robust out-of-distribution generalization, while low diversity can cause failures in both factual and statistical learning."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- To study this, the authors design a controllable synthetic framework that separates statistical structures from factual associations, enabling the study of their interaction during training.\n- They systematically examine how diversity level and contextual structure affect in-distribution."}, "weaknesses": {"value": "- I think the setting is a bit overly simplified, Markov templates and atomic facts miss real linguistic hierarchy and semantic interference---this could limit the external validity.\n- The uniform sampling of diversity overlooks long-tailed frequency patterns in real corpora, this could possibly misrepresent the true diversity effects."}, "questions": {"value": "What diversity level is actually needed to improve generalization? Does the model learns true fact template separation or just memorizes within templates?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QVngtomiuE", "forum": "MQ5gqRRHVN", "replyto": "MQ5gqRRHVN", "signatures": ["ICLR.cc/2026/Conference/Submission10274/Reviewer_q86T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10274/Reviewer_q86T"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10274/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997037885, "cdate": 1761997037885, "tmdate": 1762921626955, "mdate": 1762921626955, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the impact of pretraining data diversity on language model generalization. The authors introduce a novel synthetic testbed that combines statistical streams (templates) with factual streams (source target pairs). This setup allows fine grained control over the diversity level, meaning how many different templates a fact appears in , and the contextual structure, meaning how templates vary statistically or positionally. Key findings show that while high diversity can slow in distribution fact learning , it is critical for out of distribution generalization. The specific effects depend heavily on the contextual structure."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The synthetic testbed is a primary strength. It is cleverly designed to isolate and control the interactions between statistical learning and factual memorization.\n2. The paper provides a nuanced analysis of diversity. The finding that high diversity slows ID convergence but is essential for OOD generalization is a valuable insight.\n3. The discovery of a temporal trade off where optimal diversity levels depend on the training duration is an interesting and practical finding."}, "weaknesses": {"value": "1. The primary limitation is the simplicity of the synthetic data. While tractability is a goal , the first order Markov chain used for the statistical stream  is a very simplified model of language. It is unclear how these findings translate to the complex, long range dependencies of natural text.\n2. The experiments are conducted on very small transformer models. Although the authors show results on 1 to 10 layer models , it remains an open question if these specific mechanisms and bottlenecks are the same in SotA models with hundreds of billions of parameters.\n3. The paper's findings are dense. While the figures are informative, the interplay between the three contextual structures (MC10Pos1, MC1Pos10, MC10Pos10) and the three metrics  can be difficult to follow."}, "questions": {"value": "1. The paper convincingly argues that low diversity creates a non generalizing minimizer . Could this be overcome with optimization changes, such as a different optimizer, learning rate schedule, or regularization, or is it a fundamental property of the low diversity data landscape?\n2. How do you hypothesize these findings would change if the statistical stream was more complex than a first order Markov chain? For example, if it included simple grammatical structures, would the sharp distinction between statistical and factual learning bottlenecks  still hold?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Xz8vzWVsmR", "forum": "MQ5gqRRHVN", "replyto": "MQ5gqRRHVN", "signatures": ["ICLR.cc/2026/Conference/Submission10274/Reviewer_oCE1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10274/Reviewer_oCE1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10274/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762237812939, "cdate": 1762237812939, "tmdate": 1762921626250, "mdate": 1762921626250, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Updates to the Paper"}, "comment": {"value": "We thank all the reviewers for their time and feedback. We have revised the paper and added new experimental results in the Appendix to address several concerns raised in the reviews. The major updates and new material are listed below, with new sections highlighted in blue in the PDF:\n\n- **Updated Introduction**: We have updated Figure 1 and the contribution summary in Section 1.1 to provide a clearer roadmap and a more detailed overview of the paper's key results.\n\n- **Impact of Hyperparameter Tuning (Appendix F.1):** We include new experiments investigating the impact of hyperparameter tuning, considering both the high-diversity and low-diversity regimes.\n\n- **Variations on the statistical stream (Appendix F.2):** We add new experiments replacing the first-order Markov Chain (MC) with Hidden Markov Models (HMM) to study the impact of long-range dependencies in the statistical stream.\n\n- **Token Ambiguity (Appendix F.3):** We provide new experiments with token ambiguity, where the generic (statistical) and fact vocabulary are not disjoint and share an overlap."}}, "id": "B7KEuitSss", "forum": "MQ5gqRRHVN", "replyto": "MQ5gqRRHVN", "signatures": ["ICLR.cc/2026/Conference/Submission10274/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10274/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission10274/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763753377745, "cdate": 1763753377745, "tmdate": 1763753377745, "mdate": 1763753377745, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}