{"id": "Zf8nLbYkdS", "number": 3077, "cdate": 1757328590090, "mdate": 1759898110323, "content": {"title": "The Unanticipated Asymmetry Between Perceptual Optimization and Assessment", "abstract": "Perceptual optimization is primarily driven by the fidelity objective, which enforces both semantic consistency and overall visual realism, while the adversarial objective provides complementary refinement by enhancing perceptual sharpness and fine-grained detail. Despite their central role, the correlation between their effectiveness as optimization objectives and their capability as image quality assessment (IQA) metrics remains underexplored. In this work, we conduct a systematic analysis and reveal an unanticipated asymmetry between perceptual optimization and assessment: fidelity metrics that excel in IQA are not necessarily effective for perceptual optimization, with this misalignment emerging more distinctly under adversarial training. In addition, while discriminators effectively suppress artifacts during optimization, their learned representations offer only limited benefits when reused as backbone initializations for IQA models. Beyond this asymmetry, our findings further demonstrate that discriminator design plays a decisive role in shaping optimization, with patch-level and convolutional architectures providing more faithful detail reconstruction than vanilla or Transformer-based alternatives. These insights advance the understanding of loss function design and its connection to IQA transferability, paving the way for more principled approaches to perceptual optimization. Code and models will be released publicly.", "tldr": "This work systematically examines the unanticipated asymmetry between perceptual optimization and assessment.", "keywords": ["Perceptual Optimization", "Image Quality Assessment", "Fidelity Metrics", "Adversarial Objective"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f592fc9bd54294b941bf85b824e35c2a2dc507f6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates the relationship and potential asymmetry between perceptual optimization objectives and their effectiveness as image quality assessment (IQA) metrics in image super-resolution (SR) tasks. The authors construct a family of DISTS-style perceptual metrics with diverse backbone architectures, design an array of adversarial discriminators, and perform comprehensive experiments on SwinIR. They report that the best-performing IQA metrics do not necessarily yield superior perceptual optimization, and adversarially trained discriminators, while effective at artifact suppression, do not transfer as strong initializations for IQA models. The work highlights the critical influence of discriminator design, particularly patch-level convolutional architectures, on optimization results and training stability."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Comprehensive Experimental Evaluation: The paper presents an controlled empirical study, spanning multiple backbone architectures (VGG-16, ResNet-50, ConvNeXt, CLIP-ViT, Swin-T, and DINOv2) for both perceptual losses and discriminators. This breadth adds significant credibility to the claims.\n2. Systematic Analysis of Loss Design: The explicit formulation and analysis of the DISTS-style perceptual metric and its alternative feature backbones is thorough, with concrete mathematical details provided.\n3. Insight into Optimization-Assessment Asymmetry: The study surfaces a well-supported, thought-provoking observation that high IQA performance does not guarantee optimization efficacy.\n4. Strong Visualizations: The qualitative figures are well-chosen and annotated, highlighting subtle texture and artifact differences that strengthen the analysis."}, "weaknesses": {"value": "1. Limited Generalization Beyond SR and SwinIR: The study is conducted entirely within the SwinIR SR framework, with all optimization experiments targeting one architecture. There is no evidence showing similar asymmetries arise for other image-to-image or generative tasks.\n2. Superficial Discussion of Optimization Failures: While the work documents the underwhelming performance of some metrics in optimization, it rarely delves into why this happens.\n3. Insufficient Theoretical Context: While the empirical results are robust, the theoretical motivation for the observed asymmetry is shallow.\n4. Overreliance on NR-IQA for Main Evaluation: Table 1 uses NR-IQA scores as the primary measure for comparing perceptual optimization effectiveness. While defensible given the issues noted for FR-IQA, this risks circularity: the choice of NR metric may bias the conclusions, especially if the NR metric is itself optimized using similar backbones."}, "questions": {"value": "1. On Generalization: Can the observed asymmetry between optimization and assessment be demonstrated for tasks beyond SR or architectures beyond SwinIR?\n2. Metric Structure and Failure Analysis: Have you conducted feature visualizations or layer-wise analyses to pinpoint why certain backbones or perceptual metrics perform poorly during optimization?\n3. NR-IQA Metric Bias: Your evaluation heavily relies on a set of modern NR-IQA methods. How sensitive are your findings to this choice? Did you observe substantially different trends using alternative NR or FR-IQA metrics?\n4. Explaining Training Instabilities (Figure 7): Do you have further diagnostics explaining why DINOv2-based discriminators degrade at higher GAN weights, while ResNet-50 remains robust?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "538f9HLoyc", "forum": "Zf8nLbYkdS", "replyto": "Zf8nLbYkdS", "signatures": ["ICLR.cc/2026/Conference/Submission3077/Reviewer_EoiF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3077/Reviewer_EoiF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761288692879, "cdate": 1761288692879, "tmdate": 1762916541368, "mdate": 1762916541368, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper reveals a surprising mismatch between image quality assessment (IQA) metrics and their usefulness as training objectives: metrics that score highly for IQA donâ€™t necessarily improve perceptual optimization, and this gap widens with adversarial training. It also finds that while GAN discriminators help suppress artifacts and boost realism, especially patch-level, convolutional designs, their learned features transfer poorly when reused to initialize IQA models. Overall, adversarial supervision tends to dominate outcomes once a reasonable perceptual loss is present, challenging the common practice of equating IQA strength with optimization effectiveness."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1.\tThis finding shows that high-scoring IQA metrics do not necessarily make better optimization objectives, overturning a long-held assumption and opening a new direction for perceptual loss design.\n2.\tThe study presents a carefully controlled experimental framework spanning multiple loss compositions, discriminator architectures, and perceptual backbones, ensuring robust and reproducible findings.\n3.\tThe paper is clearly written, with concise exposition and high readability."}, "weaknesses": {"value": "1.\tThe analysis should be supplemented with results on additional architectures such as HAT and other models to verify whether the same properties persist beyond the SwinIR-based cases.\n2.\tThe paper should include a user study to mitigate potential inaccuracies of NR-IQA scores and verify that the observed improvements align with human judgments.\n3.\tFigure 7 should include additional GAN loss weights (at least six) to better illustrate the effects."}, "questions": {"value": "N.A."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "r4HVTUqph7", "forum": "Zf8nLbYkdS", "replyto": "Zf8nLbYkdS", "signatures": ["ICLR.cc/2026/Conference/Submission3077/Reviewer_iVQ1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3077/Reviewer_iVQ1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761615893137, "cdate": 1761615893137, "tmdate": 1762916541074, "mdate": 1762916541074, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper conducts systematic experiments to investigate the relationship between perceptual optimization and image quality assessment. Using image-super-resolution with SwinIR as the testbed, this work constructs and evaluates a family of DISTS-style perceptual metrics using various backbones and examines whether discriminator features learned during adversarial training can transfer to IQA tasks. Meanwhile, analyses on the choices of GAN-based initialization and architecture of discriminator are provided."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The study systematically evaluates multiple backbones, discriminator designs, and loss combinations, revealing that good IQA metrics are not necessarily effective for perceptual optimization."}, "weaknesses": {"value": "1. The experiments are restricted to super-resolution using SwinIR. As this study focuses on revealing the effectiveness of different IQA metrics and discriminator designs, the choice of backbone architecture is necessary and should be considered.\n2. Although the asymmetry is clearly demonstrated empirically, there is limited theoretical analysis explaining why high-performing IQA metrics fail in optimization. Meanwhile, the results in Sec 3.4 suggest that Transformer-based discriminators perform poorly and are more unstable. However, it lacks detailed analysis on attention behaviors or feature maps.\n3. This work has limited practical guidance. For instance, if IQA metrics and optimization are misaligned, what practical heuristics should be followed when selecting losses? \n4. In Table 2, the extremely low performance of DINOv2 using ImageNet initialization on TQD is not explained."}, "questions": {"value": "Please refer to the weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "pntSt9MVVB", "forum": "Zf8nLbYkdS", "replyto": "Zf8nLbYkdS", "signatures": ["ICLR.cc/2026/Conference/Submission3077/Reviewer_22QZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3077/Reviewer_22QZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3077/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876070322, "cdate": 1761876070322, "tmdate": 1762916540823, "mdate": 1762916540823, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}