{"id": "uNZtg4l9dF", "number": 21075, "cdate": 1758313467481, "mdate": 1759896943398, "content": {"title": "Token-Level Early Fusion Model Bridging Text and 3D Electron Density Grids in Chemistry", "abstract": "We present 3DGrid-LLM, a multimodal foundation model designed to integrate natural language with three-dimensional electron density grids for applications in molecular and materials science. The architecture extends a large decoder-only language model by incorporating discrete volumetric representations obtained through a 3D VQGAN, enabling joint token-level processing of spatial and textual modalities within a unified framework. Pre-trained on a diverse corpus of molecular and materials datasets, 3DGrid-LLM supports bidirectional text–grid generation, multimodal question answering, and retrieval-augmented 3D reconstruction. Comprehensive evaluations demonstrate consistent improvements over baseline methods in multimodal VQA, chemically informed text generation, and property-aligned retrieval tasks, yielding outputs that are both accurate and physically consistent.", "tldr": "", "keywords": ["early-fusion", "multimodal foundation model", "3D density grids", "textual information"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/47cf99410bc37f7cce77036c006ca0e6311f0088.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces 3DGrid-LLM, a multimodal foundation model designed for molecular and materials science. The method performs token-level early fusion between natural language and 3D electronic density grids."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper is well-structured and clearly written, providing a concise and accessible overview of the problem and the proposed solution.\n* This work demonstrates the potential of token-level early fusion strategies for advancing multimodal exploration in AI4Science."}, "weaknesses": {"value": "* In this work, can the model ensure equivariance for the 3D electronic density grids? The performance on datasets such as QM9 is significantly poorer than that of domain-specific models—could this be due to the lack of equivariance?\n* How well does the 3D electronic density grid generalize? For molecules and materials of varying sizes, how is the fidelity of the 3D electronic density representation maintained?\n* The paper employs VQGAN to encode 3D volumetric grids. It would be valuable to include comparisons and discussions with VQVAE-related approaches [1-3].\n\n[1] Van Kempen M, Kim S S, Tumescheit C, et al. Fast and accurate protein structure search with Foldseek[J]. Nature biotechnology, 2024, 42(2): 243-246.\n\n[2] Gao K, Wang Y, Guan H, et al. Tokenizing 3d molecule structure with quantized spherical coordinates[J]. arXiv preprint arXiv:2412.01564, 2024.\n\n[3] Li X, Wang L, Luo Y, et al. Geometry Informed Tokenization of Molecules for Language Model Generation[J]. arXiv preprint arXiv:2408.10120, 2024."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eHu50dEbRR", "forum": "uNZtg4l9dF", "replyto": "uNZtg4l9dF", "signatures": ["ICLR.cc/2026/Conference/Submission21075/Reviewer_1EeF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21075/Reviewer_1EeF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761746475978, "cdate": 1761746475978, "tmdate": 1762999979428, "mdate": 1762999979428, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose 3DGrid-LLM, an early-fusion multimodal foundation model that bridges language modality and 3D grids modality. By tokenizing the 3D grids, the authors input them into a pretrained language model, to enable multiple downstream tasks, such as, multimodal VQA, semantic text generation, and property-aligned retrieval."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper is easy to follow and the design of the framework is generally reasonable.\n\n2. The authors test the framework on 32 tasks, which demostrates its improved performce.\n\n3. The topic that including into 3D grid into large language model is interesting and important."}, "weaknesses": {"value": "1. The baselines are largely missing. The authors conduct 3 kinds of experiments, and only include one baseline in one of them. This even makes the claim 'improvements over baselines' to be 'improvements over baseline'. (Line 018).\n\n2. The authors do not property discuss their motivation in the experimental part. The first motivation, some existing methods only employ the 1D or 2D data. The authors should at least conduct some experiments on 1D or 2D data to show the improvement from introducing 3D grid. Another way is to introduce strong related baselines. Similarly, the authors also claim their method benefits from early fusion. However, there is no such ablation study or baselines to support the claim.\n\n3. The method is quite straightforward, and lacks of novelty. It seems the only novelty of this paper is putting text and 3D grid into the LLM together, which is clearly below the bar of ICLR.\n\n4. The quality of presentation can be improved. The fonts in the figures are too small and resulting the SMILES in the figure is head to read."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "stlE2bAKGv", "forum": "uNZtg4l9dF", "replyto": "uNZtg4l9dF", "signatures": ["ICLR.cc/2026/Conference/Submission21075/Reviewer_vdw2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21075/Reviewer_vdw2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761748831176, "cdate": 1761748831176, "tmdate": 1762940646714, "mdate": 1762940646714, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces 3DGrid-LLM, a multimodal foundation model designed to integrate natural language with 3D electron density grids for applications in chemistry and materials science. The core idea is to achieve \"early fusion\" at the token level. It employs a 3D VQGAN to discretize the 3D electron density grids into volumetric tokens. These grid tokens are then combined with text tokens into a single, unified sequence that is processed by a decoder-only large language model (LLM) fine-tuned with LoRA adapters. The authors demonstrate the model's capabilities on tasks like multimodal question answering (VQA), 3D-to-text generation, and retrieval-augmented text-to-3D generation."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "1. The choice of electron density grids as the 3D modality is well-justified. This representation is information-rich and captures more fine-grained electronic and spatial features than atomistic point clouds.\n\n2. Empirical Results: On the self-defined VQA and retrieval tasks, the model shows consistent improvements over the \"3DGrid-VQGAN\" baseline, particularly with few-shot prompting."}, "weaknesses": {"value": "This paper suffers from significant weaknesses that, in my opinion, make it fall below the standards of a top-tier conference like ICLR.\n\n1. The paper's central claim to novelty is its \"token-level early fusion\", which it contrasts with late-fusion architectures. However, this architectural concept is not new. Ignoring both projector-based (3D-MoLM) and other token-based (3D-MolT5) state-of-the-art methods, the authors have failed to situate their work in the current research landscape.\n\n2. Citation format error.\n\n3. Reproductivity and ethic statement missed.\n\n4. The method needs to be compared with more baselines, both LLM-based and conventional approaches."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ORnhHzA562", "forum": "uNZtg4l9dF", "replyto": "uNZtg4l9dF", "signatures": ["ICLR.cc/2026/Conference/Submission21075/Reviewer_VMfj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21075/Reviewer_VMfj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805973799, "cdate": 1761805973799, "tmdate": 1762940645845, "mdate": 1762940645845, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces 3DGrid-LLM, a novel multimodal language model designed to jointly process textual input and 3D electron density grids of chemical structures. To enable the model to handle electron density grids, the authors employ a VQGAN to encode them into discrete token sequences. In addition, they propose a retrieval-augmented evaluation framework for assessing the generated electron density grids by retrieving the most similar chemical structures from a curated database of experimentally or computationally derived materials."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper explores an original and promising direction by using electron density grids as input data for language model training. This idea opens new avenues for integrating quantum chemistry principles into multimodal language modeling and for leveraging the abundance of existing quantum-chemical data.\n\nFurthermore, the proposed retrieval-augmented evaluation approach is conceptually interesting. It offers a potential pathway for evaluating molecular generative models by mapping their outputs into structured chemical or material spaces, such as the domain of synthesizable molecules. This perspective could inspire future research on aligning molecular representations with experimentally verifiable chemical spaces."}, "weaknesses": {"value": "While the paper introduces interesting ideas, its experimental validation remains limited, leaving several key questions unresolved.\n\n1. [major] The paper does not sufficiently justify why electron density grids should be preferred over more conventional molecular representations such as 3D atomic coordinates (molecular conformations). Recent works ([a, b, c]) have already introduced spatial molecular language models operating on atomic structures using both text and specialized encoders. A comparative evaluation against such baselines is essential to substantiate the advantages of using electron density grids. Ideally, the authors should also present use cases or experiments showing scenarios where electron density grids yield clear performance or interpretability gains.\n2. [major] Although the retrieval-augmented evaluation framework is novel, it inherently limits assessment to the space of existing molecules and thus cannot evaluate the model’s ability to generate truly novel structures. It is also unclear whether the proposed system can reconstruct explicit novel molecular structures from the generated electron density grids, or if it merely identifies the nearest match within a pre-existing dataset. If the latter, the practical applicability of the approach for generative tasks is significantly reduced.\n3. [major] The paper mentions combining several open-access molecular and materials datasets, augmented with computed properties and textual descriptions, as well as a benchmark of 100 textual prompts designed to elicit diverse structural and electronic characteristics. However, the description of the dataset construction process is insufficient. A reproducibility statement should be included, along with high-level details about the data preparation pipeline, prompt generation examples, and data availability. These additions—possibly in the Supplementary Materials—would greatly improve transparency and replicability.\n4. [minor] The section on Model and Training Configuration could be condensed or moved to the Supplementary Materials to improve readability. The main text could then focus more on experimental results and analysis, strengthening the empirical foundation of the work.\n\na. BindGPT: A Scalable Framework for 3D Molecular Design via Language Modeling and Reinforcement Learning, Zholus et al.\n\nb. Towards 3D Molecule-Text Interpretation in Language Models, Li et al.\n\nc. nach0-pc: Multi-task Language Model with Molecular Point Cloud Encoder, Kuznetsov et al."}, "questions": {"value": "In addition to the points raised above, I have the following question:\n\nIn Table 5, all evaluation metrics are reported as “Accuracy,” yet some of the tasks involve continuous (real-valued) predictions. Could the authors clarify how “accuracy” is computed in those cases? For instance, are thresholds applied, or are these values discretized in some way?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9EWIo1VQRL", "forum": "uNZtg4l9dF", "replyto": "uNZtg4l9dF", "signatures": ["ICLR.cc/2026/Conference/Submission21075/Reviewer_82hd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21075/Reviewer_82hd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761870935102, "cdate": 1761870935102, "tmdate": 1762940645177, "mdate": 1762940645177, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces 3DGrid-LLM, an early-fusion multimodal foundation model that unifies natural language and 3D electron-density grids for molecular and materials science. It extends a large decoder-only LLM with volumetric tokens from a 3D-VQGAN so that spatial and textual information are processed together at the token level. Trained on 12.5 M text–grid pairs (QM9, QMOF, PubChem), it supports bidirectional generation (text→3D grid and 3D→text), scientific VQA, and retrieval-augmented grid generation. Experiments show higher accuracy than a 3DGrid-VQGAN baseline across 32 tasks and strong semantic and retrieval alignment, demonstrating that early token-level fusion enables physically consistent multimodal reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Achieves consistent performance gains and realistic bidirectional generation outputs illustrated in Figure 2.\n- The architecture (3D VQGAN + LLM + LoRA adapters) and multimodal training pipeline are well-described.\n- Benchmarked on diverse molecular and crystallographic datasets (PubChem, QM9, QMOF) with both VQA and retrieval metrics."}, "weaknesses": {"value": "- The method mainly adapts existing 3D VQGAN tokenization and LoRA-based fine-tuning; architectural innovation is limited.\n- No experiments isolating the impact of early fusion vs. late fusion or LoRA adaptation."}, "questions": {"value": "- How is the 100 diverse textual prompts generated? \n- The section 4.3 evaluation relies on the 3DGrid-CLIP embedding, how sensitive are the retrieval metrics to biases or saturation in that embedding space? Do the retrieved nearest neighbors correspond to physically similar electron densities, or just ones with correlated textual descriptions?\n- How can the model deal with the token-level artifacts or unrealistic density patterns in 3D geometry generation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ujekroUXDa", "forum": "uNZtg4l9dF", "replyto": "uNZtg4l9dF", "signatures": ["ICLR.cc/2026/Conference/Submission21075/Reviewer_huvC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21075/Reviewer_huvC"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission21075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987625563, "cdate": 1761987625563, "tmdate": 1762940644504, "mdate": 1762940644504, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}