{"id": "BiXwSIIMIq", "number": 19688, "cdate": 1758298414846, "mdate": 1759897025870, "content": {"title": "Taming Score-Based Denoisers in ADMM: A Convergent Plug-and-Play Framework", "abstract": "While score-based generative models have emerged as powerful priors for solving inverse problems, directly integrating them into optimization algorithms such as ADMM remains nontrivial. Two central challenges arise: i) the mismatch between the noisy data manifolds used to train the score functions and the geometry of ADMM iterates, especially due to the influence of dual variables, and ii) the lack of convergence understanding when ADMM is equipped with score-based denoisers. To address the manifold mismatch issue, we propose ADMM plug-and-play (ADMM-PnP) with the AC-DC denoiser, a new framework that embeds a three-stage denoiser into ADMM: (1) auto-correction (AC) via additive Gaussian noise, (2) directional correction (DC) using conditional Langevin dynamics, and (3) score-based denoising. In terms of convergence, we establish two results: first, under proper denoiser parameters, each ADMM iteration is a weakly nonexpansive operator, ensuring high-probability fixed-point *ball convergence* using a constant step size; second, under more relaxed conditions, the AC-DC denoiser is a bounded denoiser, which leads to convergence under an adaptive step size schedule. Experiments on a range of inverse problems demonstrate that our method consistently improves solution quality over a variety of baselines.", "tldr": "", "keywords": ["diffusion", "score model", "inverse problem", "convergence", "optimization", "generative model"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2d9518d71ccc9892d92e72c8e0accb640da9098e.pdf", "supplementary_material": "/attachment/e161b59faf1c5076af560092feb978e1efb68830.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces a new plug-and-play ADMM framework that integrates score-based denoisers derived from pretrained diffusion models. The contribution lies in two main aspects: (1) addressing the  manifold mismatch between the noise-trained score manifolds and the actual ADMM iterates, particularly due to dual-variable effects and (2) the lack of convergence guarantees when using score-based denoisers within ADMM.\n\nThe author propose using a three-stage denoiser called AC–DC (Auto-Correction + Directional Correction + Score Denoising), where in the AC step,  Gaussian noise is added to align iterates with score manifolds, in the DC step  conditional Langevin dynamics is used to refine the direction toward the true data manifold and in the score denoising, pre-trained score model is applied. They provide theoretical results for the cases of convex data-fidelity with weakly contractive denoisers and noncovex case. \n\nExperiments on image inverse problems (super-resolution, inpainting, motion deblurring) show performance gains over methods like DDRM, DiffPIR, and DPS."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The combination of ADMM with a diffusion-based denoiser that explicitly accounts for manifold mismatch  is conceptually fresh. Previous works used diffusion models in proximal steps or as score priors, but rarely in a primal–dual ADMM context with noise manifold adjustment. \n\nThe authors provide theoretical analysis regarding the convergence of the proposed denoiser. \n\nThe experimental results demonstrate that the proposed denoiser is indeed effective in solving inverse problems. \n\nThe approach tackles a real gap between diffusion-based inference and optimization-based inverse problem solvers."}, "weaknesses": {"value": "Some of the assumptions are strong. Theorem 2 requires stationarity of the inner Langevin DC step at each iteration and smoothness/coercivity of –log p(x); these are hard to ensure in high-dimensional image spaces. Is there anyway authors could test this on the empirical images or a toy problem?"}, "questions": {"value": "Could the author comment on the computation complexity added by using the AC-DC denoiser as opposed to simply apply the score-based denoiser with adjusting to the noise manifold?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2CKYTKBDw3", "forum": "BiXwSIIMIq", "replyto": "BiXwSIIMIq", "signatures": ["ICLR.cc/2026/Conference/Submission19688/Reviewer_zbpZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19688/Reviewer_zbpZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19688/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761256399481, "cdate": 1761256399481, "tmdate": 1762931530269, "mdate": 1762931530269, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "## Summary\nThis paper proposes an AC-DC denoiser within an ADMM plug-and-play (PnP) framework for inverse problems. The denoiser couples an annealed correction (AC) step with a drift-correction (DC) step inspired by score-based diffusion, and the theory aims to show convergence of ADMM-PnP with this denoiser under high-probability weak nonexpansiveness. Theoretical results include: (i) convergence under strong convexity of the fidelity term via a fixed-point argument; (ii) a high-probability weak nonexpansiveness result under a schedule for σ(k) that decays to zero, leading to convergence with fixed ρ; and (iii) a convergence result without convexity of ℓ by adopting an adaptive-ρ scheme (Chan et al., 2016), under boundedness assumptions on the data domain and the score, and an assumption of bounded gradients of ℓ."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "## Strengths\n\n1. The paper tackles an important and timely problem: how to safely and provably integrate score-based denoisers within PnP/ADMM. The AC-DC design is intuitive and practically relevant.\n\n2. The high-probability analysis for weak nonexpansiveness is interesting; to my knowledge, there are relatively few works that attempt to rigorously control the stochasticity induced by score-based denoisers within PnP iterations.\n\n3. The boundedness result under adaptive ρ and a vanishing σ(k) schedule is a useful step toward understanding convergence without convexity.\n\n4. The empirical results suggest the method is competitive across a range of inverse problems."}, "weaknesses": {"value": "## Major concerns\n\nDespite the nice contributions, I have the following major concerns.\n\n### 1 AC-DC denoiser\n\n> Algorithm 1 injects noise inside the AC-DC denoiser. As implemented, Dσ is a stochastic operator: given the same input, it can return different outputs due to the injected noise (both in the AC step and in the DC sampling/evolution).\nHowever, the convergence analysis treats Dσ as a deterministic mapping z → Dσ(z), i.e., a point-to-point operator. This is a mismatch. It seems that the current deterministic analysis does not rigorously cover the algorithm being evaluated experimentally.\n\n### 2. Theorem 1\n\n> 2.1 The proof strategy follows the fixed-point iteration approach of Ryu et al. This requires the fidelity ℓ to be µ-strongly convex. This is violated in many applications highlighted by the paper itself: deblurring, super-resolution, compressed sensing, MRI, and inpainting (e.g., rank-deficient A or non-strongly-convex penalties).\n\n> 2.2 The parameter condition involving ε and µ may be restrictive. In particular, as ε → 1, the factor (1 + ε − 2ε^2) → 0, making the right-hand side ε/(µ(1 + ε − 2ε^2)) blow up. Then the condition 1/ρ > ε/(µ(1 + ε − 2ε^2)) is practically impossible to satisfy. This contradicts with the experimental setup, where Table 3 indicates ρ ≥ 100 in all cases, which violates the small-step requirement in the theorem.\n\n### 3. Theorem 2\n\n> The assumption “the DC step reaches the stationary distribution for each k” is strong. \n\n### 4. Theorem 3\n\n> 4.1 The analysis follows Chan et al. (2016): boundedness of the denoiser, vanishing noise schedules, and adaptive ρ yield convergence to a fixed point. While this shows stability, it does not characterize the limit point as a solution to any explicit optimization problem. As a result, the algorithm’s fixed point lacks interpretability: it is not known to minimize a well-defined objective nor to satisfy an equilibrium condition like a monotone inclusion. This is a conceptual limitation of the framework that should be acknowledged and discussed more candidly.\n\n> 4.2 The assumption may be strong: The requirement that ||∇ℓ(x)||/√d ≤ R < ∞ for all x is generally false for common inverse problems (deblurring, super-resolution, compressed sensing, MRI, inpainting) unless x is constrained to a compact set. For instance, with ℓ(x) = (1/2σ2)||Ax − y||2, the gradient norm grows with ||x|| unless constrained.\n\n\n## Overall assessment\nThis work addresses an important problem and proposes a practically relevant denoiser within PnP/ADMM, with nontrivial theoretical attempts. However, the current theoretical results rely on assumptions that do not match the algorithm as implemented (notably, treating a stochastic denoiser as deterministic and assuming stationarity per iteration), and on conditions that are violated in key applications and in the reported experiments (strong convexity of ℓ; parameter inequalities incompatible with large ρ; bounded gradient assumptions). I believe the paper would be significantly strengthened by a proper stochastic operator analysis and by reconciling the parameter/schedule assumptions with the experimental setup. \n\nIf the authors address some of the issues mentioned above, I would consider to increase my score."}, "questions": {"value": "Please see the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AaQdIH9D86", "forum": "BiXwSIIMIq", "replyto": "BiXwSIIMIq", "signatures": ["ICLR.cc/2026/Conference/Submission19688/Reviewer_srVv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19688/Reviewer_srVv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19688/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761778855352, "cdate": 1761778855352, "tmdate": 1762931529897, "mdate": 1762931529897, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel Plug-and-Play (PnP) framework that integrates score-based denoisers into the ADMM optimization algorithm for solving inverse problems. The key contribution is a three-stage denoiser, termed AC-DC, designed to address the manifold mismatch problem: the fact that ADMM iterates (influenced by dual variables) do not lie on the noisy data manifolds on which the score functions were trained. The AC (Auto-Correction) stage adds Gaussian noise to the iterate, while the DC (Directional Correction) stage uses conditional Langevin dynamics to refine the iterate towards the correct noisy manifold before final score-based denoising. The authors provide a comprehensive convergence analysis, showing both fixed-point ball convergence under a constant step size and convergence under an adaptive step size schedule. Experiments across various inverse problems demonstrate improved performance over several baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper clearly identifies and addresses a significant, underexplored challenge in the PnP literature: the mismatch between the geometry of optimization iterates (especially in primal-dual methods like ADMM) and the manifolds on which score-based denoisers are trained. This is a pertinent and non-trivial issue.\n\n- The proposed AC-DC denoiser is a novel and intuitive solution to the manifold mismatch problem. The idea of proactively \"correcting\" the iterate onto the score function's domain, rather than simply applying the denoiser, is innovative.\n\n- The paper validates the method on a wide range of inverse problems (inpainting, deblurring, super-resolution, phase retrieval) and against a diverse set of modern baselines, showing consistent and often superior performance."}, "weaknesses": {"value": "1. **Questionable Core Assumption**: A central weakness lies in the justification of the DC step. As outlined in the derivation leading to Eq. (10), the method assumes the residual s^(k) follows a Gaussian prior. This assumption appears to contradict the paper's primary motivation—that the noise in the ADMM iterate is not Gaussian and is off-manifold. If s^(k) can be reasonably modeled as Gaussian, the necessity of the complex DC correction is significantly undermined, as a simpler Gaussian denoiser might suffice. The paper lacks a compelling empirical or theoretical justification for this critical assumption.\n\n2. **Lack of Clarity on Method Variants**: The distinction between the two presented variants, \"Ours-tweedie\" and \"Ours-ode,\" is not clearly explained in the main text. The reader is left to infer the difference from the appendix, which is unsatisfactory. The core methodological description should explicitly state what these variants are.\n\n3. **Insufficient Discussion of Related Work**: The proposed correction mechanism bears a conceptual resemblance to the Onsager correction in Denoising Approximate Message Passing (D-AMP) algorithms [1, 2], which also handles structured iteration noise. Furthermore, the nature of iteration noise in PnP algorithms has been explicitly studied in works like TFPnP [3] (Section 6.2 -- Iteration Noise of PnP Methods). The paper would be significantly strengthened by discussing these connections and clearly delineating how the proposed approach differs from or relates to these ideas.\n\n4. **Inadequate Discussion of Computational Cost**: The AC-DC denoiser, particularly the DC step which involves multiple (J=10) Langevin steps, drastically increases the number of score function evaluations (NFE) per ADMM iteration compared to a standard PnP step. While the appendix includes an NFE analysis, the main text should frankly acknowledge this as a significant limitation and discuss the trade-off between performance and computational efficiency.\n\nGiven these issues, my initial rating is Borderline Reject. However, I would be inclined to raise my score if the authors can:\n- Provide a convincing rationale for the Gaussian assumption in Equation (10),\n- Clarify the differences between \"Ours–tweedie\" and \"Ours–ode,\"\n- Thoroughly discuss relevant prior work (e.g., D-AMP and TFPnP), and \n- Acknowledge and analyze the computational limitations of the AC-DC denoiser.\n\n### References  \n[1] From Denoising to Compressed Sensing, TIT 2016  \n[2] Denoising AMP for MRI Reconstruction: BM3D-AMP-MRI, 2018  \n[3] TFPnP: Tuning-free Plug-and-Play Proximal Algorithms with Applications to Inverse Imaging Problems, JMLR 2022"}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ciPwFpsurt", "forum": "BiXwSIIMIq", "replyto": "BiXwSIIMIq", "signatures": ["ICLR.cc/2026/Conference/Submission19688/Reviewer_JtYg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19688/Reviewer_JtYg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19688/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761936470011, "cdate": 1761936470011, "tmdate": 1762931529238, "mdate": 1762931529238, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new plug-and-play (PnP) ADMM method using score-based priors. Since score networks are trained on noisy manifolds, while ADMM iterates (due to dual variables) may not lie near those manifolds, score-based denoisers perform poorly, and the convergence theory is unclear. To address this, the paper proposes the AC–DC denoiser inside ADMM, consisting of three stages:\nAC: add Gaussian noise to push iterates toward score training manifolds;\nDC: short Langevin update guided by both the score and a quadratic prior; and\nFinal denoising via Tweedie score formula. \nUnder the strong convexity of the data fidelity term, the paper shows that the ADMM iteration is weakly nonexpansive and converges to a fixed point (up to a $\\delta$ ball). Experiments on several inverse problems (inpainting, deblurring, SR, phase retrieval) show improvements over PnP baselines (DiffPIR, DDRM, DPS, RED-diff, DPIR, etc.)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses a real gap: score-based priors in ADMM are harder than proximal-gradient PnP, mainly due to dual variable noise geometry.\n- The method conceptually simple: AC noise + short Langevin DC + score denoise.\n- The paper extends PnP-ADMM convergence analysis to score models and Langevin steps. \n- Broad experiments across common inverse problems show the practical utility of the method."}, "weaknesses": {"value": "- Noise addition before score application already appears in recent PnP diffusion works (which the paper also acknowledges). In this respect, the novelty seems incremental. \n- The DC step, a short Langevin refinement combining the score and a quadratic potential, structurally resembles diffusion posterior correction schemes, where noise injection is followed by brief score-based Langevin updates to pull iterates back toward the learned distribution. The paper’s approach integrates this idea into ADMM, but conceptually overlaps with prior noise-add-and-refine mechanisms.\n- The AC and DC schedules appear heuristic. The issue of stability is unclear across tasks without tuning.\n- Theorem 2 assumes that DC reaches the stationary distribution each iteration, which is unrealistic in practice with only a few Langevin steps.\n- With strong convexity of the fidelity term, only convergence to a ball is ensured, not a point. Without strong convexity, an adaptive ADMM penalty schedule is required.\n- The experiments use a pre-trained score model, so the advantages are partly dependent on that backbone.\n- Many baselines are not ADMM-PnP, so the comparison may be apples-to-oranges from an optimization perspective."}, "questions": {"value": "- The DC step convergence assumption seems very strong. In practice, you run a few steps; how sensitive is the method to DC iteration count?\n- How is $\\sigma^{(k)}$ chosen in the AC step? Is there a principled schedule, or is the choice purely empirical?\n- Can the method diverge with fixed $\\rho$ for non-convex cases? Any empirical failures?\n- Can you provide some empirical evidence that dual variables distort score manifold geometry?\n- Does AC–DC satisfy a consensus Equilibrium interpretation?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "8Iy6Fst2wQ", "forum": "BiXwSIIMIq", "replyto": "BiXwSIIMIq", "signatures": ["ICLR.cc/2026/Conference/Submission19688/Reviewer_uYpW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19688/Reviewer_uYpW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19688/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762018379828, "cdate": 1762018379828, "tmdate": 1762931528675, "mdate": 1762931528675, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}