{"id": "0NkXZ98BjJ", "number": 1839, "cdate": 1756950998330, "mdate": 1763651751113, "content": {"title": "ProstaTD: Bridging Surgical Triplet from Classification to Fully Supervised Detection", "abstract": "Surgical triplet detection is a critical task in surgical video analysis, with significant implications for performance assessment and training novice surgeons. However, existing datasets like CholecT50 lack precise spatial bounding box annotations, rendering triplet classification at the image level insufficient for practical applications. The inclusion of bounding box annotations is essential to make this task meaningful, as they provide the spatial context necessary for accurate analysis and improved model generalizability. To address these shortcomings, we introduce ProstaTD, a large-scale, multi-institutional dataset for surgical triplet detection, developed from the technically demanding domain of robot-assisted prostatectomy. ProstaTD offers clinically defined temporal boundaries and high-precision bounding box annotations for each structured triplet activity. The dataset comprises 71,775 video frames and 196,490 annotated triplet instances, collected from 21 surgeries performed across multiple institutions, reflecting a broad range of surgical practices and intraoperative conditions. The annotation process was conducted under rigorous medical supervision and involved more than 60 contributors, including practicing surgeons and medically trained annotators, through multiple iterative phases of labeling and verification. To further facilitate future general-purpose surgical annotation, we developed two tailored labeling tools to improve efficiency and scalability in our annotation workflows. In addition, we created a surgical triplet detection evaluation toolkit that enables standardized and reproducible performance assessment across studies. ProstaTD is the largest and most diverse surgical triplet dataset to date, moving the field from simple classification to full detection with precise spatial and temporal boundaries and thereby providing a robust foundation for fair benchmarking.", "tldr": "We introduce a new supervised surgical triplet detection task, a novel dataset, two innovative annotation tools, a comprehensive evaluation toolkit, a new benchmark, and a tailored method.", "keywords": ["Surgical Triplet", "Endoscopy", "Benchmark", "Dataset", "Evaluation"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e81d9720bf6f8750841aca72607c62bd8174fddc.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "ProstaTD is a large-scale dataset for surgical triplet detection in robot-assisted prostatectomy videos. It contains 71,775 annotated frames with 196,490 triplet instances from 21 surgeries across three institutional sources. The dataset addresses limitations in existing surgical video datasets by providing precise spatial bounding box annotations rather than relying solely on image-level labels, and by implementing clinically grounded temporal boundaries for surgical actions. The annotation taxonomy consists of 7 instrument types, 10 actions, and 10 anatomical targets. All annotations were created under medical supervision to ensure clinical validity. The temporal labelling scheme distinguishes between continuous actions (such as grasping) and momentary actions (such as cutting), which improves annotation consistency compared to prior datasets. The dataset exhibits higher surgical complexity than comparable laparoscopic datasets, with more concurrent instruments per frame reflecting actual surgical conditions. The authors benchmarked multiple state-of-the-art detection architectures on ProstaTD. Results show that fully supervised models using bounding box annotations substantially outperform weakly supervised methods that use only class labels. The authors propose TDnet, a new architecture that combines spatial detection with action-target recognition."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "The paper uses a cross institutional dataset to create a dataset with detailed surgical annotations supervised by experts. Usually the available datasets in this area come from a single institution and one or few surgeons, and the limited variability is known to affect the results. The additional variability will allow testing the generalisation of these methods more thoroughly\n\nThe dataset will be open sourced and baselines of appropriate methods are provided for the predictive Task. The authors also proposed their own variation of a Neural Network that outperforms commonly used methods in the field.\n\nThe dataset includes bounding boxes of the triplets, which is not offered by previous datasets, and it contains more labeled instances of triplets (tool, action, anatomical object) than any previous dataset. The earlier datasets in the field that offer bounding boxes of triplet instances have less than half the annotated instances than this dataset."}, "weaknesses": {"value": "The details of the proposed Neural Network, TDnet, are not in the main paper but in the appendix. Although the main contribution is an open source dataset, ICLR is mostly a Machine Learning conference and putting forward an algorithmic proposition for the proposed task would make. \n\nWhile TDnet is sensible, including new dependencies in the labels to the optimisation process, it would also be a lot more interesting to propose substantially more innovative algorithmic propositions. Also, TDnet as the best performing model is significant enough to be presented in the main paper and not the appendix.\n\nI am not sure what is the role bounding box detection in this problem. Usually you need a bounding box to identify interactions between objects in an image or something of that sort. However, if you have triplets that consider action you already cover that with a classification problem. I assume the authors have some aspiration in robotics that was not clarified in the paper."}, "questions": {"value": "How do you plan to address the class imbalance of rare triplets ?\n\nIn which clinical context does object detection offer information that the triplet (with action) classification does not account for?"}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Responsible research practice (e.g., human subjects, annotator compensation, data release)"]}, "details_of_ethics_concerns": {"value": "The dataset contains surgical videos on humans. \nIt seems to be anonymised but in such tasks indirect identification is sometimes possible."}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6jF0njlkzG", "forum": "0NkXZ98BjJ", "replyto": "0NkXZ98BjJ", "signatures": ["ICLR.cc/2026/Conference/Submission1839/Reviewer_PPXn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1839/Reviewer_PPXn"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761869505008, "cdate": 1761869505008, "tmdate": 1762915905384, "mdate": 1762915905384, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a novel dataset comprising multi-rater triple annotations and instrument bounding boxes for 21 robot-assisted prostatectomies, totaling 71,000 frames, sourced from multiple centers. Moreover, the paper presents the performance of a novel neural network “TDnet” that has been trained on the dataset. The paper also makes the two annotation tools that were used during the dataset's creation available to the public. The appendix, which is extensive in nature, provides insights into a number of areas. These include the annotation software, the model architecture, the experimental setup and the ablation studies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. important topic that proposes an extensive multi-center multi-rater dataset driving forward the field of triplet detection, encompassing 89 triplets of 7 instruments, 10 actions and 10 targets on 71k frames\n2. The dataset is compared to other triplet datasets, clearly pointing out its benefits.\n3. Further the paper implements a benchmark using state-of-the-art network architectures and the novel TDnet."}, "weaknesses": {"value": "1. The paper devotes substantial space to criticizing CholecT50 rather than focusing on the independent contributions of the presented dataset.\n2. The description of the TDnet architecture, the experimental design and ablation study are not contained in the paper but only in the appendix.\n\nMinor Comments:\nM1. The highlighting in Appendix Table 10 is inconsistent, as the higher value is not always highlighted in bold.\nM2. The paper cites 7 arXiv sources. Are peer-reviewed publications for these papers available?"}, "questions": {"value": "1. The paper claims no bounding boxes are available in CholecT50. However, the datasets overlaps partially with the CholecTrack20 datasets, which provides bounding boxes [1].\nIs the annotation available from both datasets comparable to the presented annotations?\n2. The paper claims inconsistent annotation boundaries in CholecT50, but at the same time relaxes the temporal definition on “momentary action” to “include up to 2 seconds before and after [] the contact“. How is a consistent temporal annotation between annotators ensured?\nHow is the start and end defined when it is not the exact time of contact?\n3. The dataset merged the triplets of the aspirator sucking fluid, smoke and blood, resulting in the second most common triplet. Especially concerning the intraoperative importance of bleeding, why were these triplets merged?\n4. The paper claims a higher complexity compared to CholecT50 as a single frame on average contains more triplets. This is due to the fact that CholecT50 contains laparoscopic surgeries and ProstaTD robot-assisted surgeries. In the later one of the three attached tools is not being used. This is further reflected in the fact that over one quarter of all triplets are made up by an instrument with null action and null target. Is the complexity of the dataset still higher when these null triplets are factored out?\n5. The benchmark is evaluated using mAP, Precision, Recall and F1-Score. All these metrics only distinguish correct and incorrect triplets. Does the impact of confusion differ between detecting the wrong tool compared only confusing the action? Could an ordinal metric like estimated cost provide further insights into the actual confusion of instruments, actions, or targets?\n\n[1] https://github.com/CAMMA-public/cholectrack20"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WV5nRf1hO4", "forum": "0NkXZ98BjJ", "replyto": "0NkXZ98BjJ", "signatures": ["ICLR.cc/2026/Conference/Submission1839/Reviewer_wQHi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1839/Reviewer_wQHi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896453653, "cdate": 1761896453653, "tmdate": 1762915905190, "mdate": 1762915905190, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces ProstaTD, a multi‑institutional dataset for fully supervised surgical triplet detection (⟨instrument, verb, target⟩) in robot‑assisted prostatectomy, with 71,775 frames, 196,490 instances, 89 triplet classes, 7 instruments / 10 actions / 10 targets, dense instrument bounding boxes, and clinically defined temporal boundaries. It also releases two tailored annotation tools and an evaluation toolkit, establishes a 5‑fold video‑level protocol, and provides a baseline (TDnet) with instance‑level self‑distillation. On the benchmark, TDnet achieves mAP_{IVT}@0.5 = 36.1% (vs. YOLOv12 34.3%) and F1 = 32.8% (Table 4–5). The work moves the community from frame‑level triplet classification (e.g., CholecT45/50) to full detection with explicit spatial/temporal supervision."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Data contribution: First full‑procedure, multi‑institutional, box‑supervised triplet dataset with standardized temporal boundaries; strong annotation process and κ=0.82.\n\nBenchmark breadth: Comprehensive baselines (from SSD/Faster R‑CNN to RT‑DETR/YOLOv10‑12) with accuracy‑speed trade‑offs.\n\nTools & reproducibility: Open annotation apps + evaluation toolkit; 5‑fold protocol.\n\nEmpirical insight: Higher concurrency/scene density than CholecT50, stressing realistic IVT detection."}, "weaknesses": {"value": "Domain generalization not tested: No leave‑one‑source‑out (e.g., train on PWH+ESAD, test on PSI‑AVA). Report would bolster the “multi‑institutional” claim.\n\nMissing target boxes: Only instrument boxes are annotated; lack of target localization limits explicit interaction modeling; consider target boxes/segmentation or relation heads.\n\nMethod novelty modest: TDnet is effective but incremental; limited exploration of explicit relation modeling or stronger temporal modules."}, "questions": {"value": "Can you report leave‑one‑source‑out IVT mAP/F1 to assess cross‑hospital generalization?\n\nAny plan to add target boxes (or weak labels/segmentation) to better learn instrument–target spatial relations?\n\nHow robust are results under video‑wise metrics in the main text (now in Appendix F.2)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics review needed."}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6H4Gavr8gK", "forum": "0NkXZ98BjJ", "replyto": "0NkXZ98BjJ", "signatures": ["ICLR.cc/2026/Conference/Submission1839/Reviewer_WshK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1839/Reviewer_WshK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959266455, "cdate": 1761959266455, "tmdate": 1762915905003, "mdate": 1762915905003, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents ProstaTD, a surgical triplet dataset composed of 21 prostatectomy videos, annotated with instrument-action-target triplets. The dataset integrates multiple source datasets to increase diversity in instruments, actions, and surgical contexts. To support future research, the authors also propose TDnet, a baseline network with self-distillation and multi-task learning for triplet detection. Additionally, they provide two annotation tools and an evaluation toolkit. The dataset aims to support generalizable surgical action recognition and provide a benchmark for surgical triplet detection."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "(1)ProstaTD integrates multiple sources (ESAD, PSI, PWH), covering different surgical styles, instrument usage, and rare triplets, increasing clinical coverage and the complexity of real-world surgical scenarios.\n(2)The authors developed dedicated software (Triplet-LabelMe and SurgLabel) supporting structured triplets, temporal propagation, and batch operations. Both tools are open-source, significantly accelerating surgical video annotation and improving reproducibility.\n(3)The ivtdmetrics package unifies I-V-T and IVT metric computation, supports video-wise evaluation, mAP@50:95, and multi-component statistics, facilitating fair comparisons across models.\n(4)ProstaTD and its accompanying tools are planned for open-source release, making high-quality surgical triplet data and annotation tools widely accessible for algorithm development and benchmarking."}, "weaknesses": {"value": "(1)A large portion of the manuscript is devoted to describing the dataset composition, annotation tools, and triplet statistics, while the experimental contribution is relatively limited. \n(2)Although the TDnet baseline is proposed, the comparisons are primarily against standard detectors. The paper lacks exploration of different architectures, hyperparameter sensitivity, or deeper ablation studies. Additionally, it does not demonstrate the dataset’s utility on other downstream tasks such as surgical phase recognition or multi-instrument tracking.\n(3)While the long-tail distribution is discussed, the paper lacks systematic strategies or metrics to evaluate model generalization on rare or unseen triplets. Additional ablation studies or case analyses would strengthen the argument regarding the dataset’s ability to support learning from rare events.\n(4)Although the dataset is claimed to be procedure-agnostic, there are no experiments demonstrating its transferability to other types of surgeries. The paper lacks quantitative evidence or experiments to support the dataset’s claimed generalizability."}, "questions": {"value": "The paper is relatively long, with overly detailed and occasionally repetitive descriptions of dataset statistics, annotation tools, and evaluation protocols. It is recommended to consolidate the key points and emphasize the core contributions, namely the dataset, the TDnet baseline, and the evaluation experiments, to improve readability."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UVGvrQloYF", "forum": "0NkXZ98BjJ", "replyto": "0NkXZ98BjJ", "signatures": ["ICLR.cc/2026/Conference/Submission1839/Reviewer_TsFH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1839/Reviewer_TsFH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1839/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988179401, "cdate": 1761988179401, "tmdate": 1762915904865, "mdate": 1762915904865, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overall response to reviewers"}, "comment": {"value": "Dear Reviewers,\n\nWe sincerely thank the chairs and reviewers for their thoughtful feedback and the time invested in reviewing our paper. Your comments were extremely helpful in improving both the clarity and quality of our work. In response, we have carefully revised the manuscript and added new analyses and experiments. Key updates include:\n\n* Added new ablations, including TDnet with YOLOv10/YOLOv11 extractors, a hyperparameter sensitivity study on MTL self‑distillation fusion weights and Rare-triplet mAP comparison. (Appendix F.3)\n* Included single component normalized confusion matrices analysis on ProstaTD. （Appendix F.4 and Figure 10)\n* Performed leave‑one‑source‑out cross‑hospital experiments to evaluate domain generalization across PWH, ESAD, and PSI‑AVA. (Appendix F.7)\n* Introduced a cost‑aware IVT metric assigning different weights to bounding box, instrument, action, and target errors for fine‑grained error analysis. (Appendix F.6)\n* Replaced arXiv citations with peer-reviewed conference/journal references where available.\n* Clarified and expanded the Limitations and Future Work section. (Appendix G.3 and G.4)\n* Reorganized the paper by moving core TDnet architectural details from the appendix into the main text, while streamlining descriptive sections to improve clarity and focus. （Section E)\n\nDetailed responses are provided inline with each reviewer comment. We truly appreciate your insights and are happy to make further revisions if needed.\n\n\nSincerely,\n\nThe Authors"}}, "id": "5sxE27QQxw", "forum": "0NkXZ98BjJ", "replyto": "0NkXZ98BjJ", "signatures": ["ICLR.cc/2026/Conference/Submission1839/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1839/Authors"], "number": 14, "invitations": ["ICLR.cc/2026/Conference/Submission1839/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763651632655, "cdate": 1763651632655, "tmdate": 1763651632655, "mdate": 1763651632655, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}