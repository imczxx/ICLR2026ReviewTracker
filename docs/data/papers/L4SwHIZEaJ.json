{"id": "L4SwHIZEaJ", "number": 21508, "cdate": 1758318364409, "mdate": 1759896918443, "content": {"title": "The Lattice Geometry of Neural Network Quantization: A Short Equivalence Proof of GPTQ and Babai's algorithm", "abstract": "We explain how data-driven quantization of a linear unit in a neural network corresponds to solving the closest vector problem for a certain lattice generated by input data. We prove that the GPTQ algorithm is equivalent to Babai's well-known nearest-plane algorithm. We furthermore provide geometric intuition for both algorithms. Lastly, we note the consequences of these results, in particular hinting at the possibility of using lattice basis reduction for improved quantization.", "tldr": "We prove that the GPTQ quantization algorithm is equivalent to Babai's nearest-plane algorithm.", "keywords": ["quantization", "lattices", "GPTQ", "Babai"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cf377172c4e691e3cd31ea0a4e8ac98376fd46ab.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors show that a recently proposed algorithm for neural network quantization, GPTQ, is equivalent to Babai's well-established nearest-plane algorithm appearing in lattice problems. \nBased on this equivalence and the long history of Babai's algorithm, they highlight that the algorithm is associated to known guarantees, and they describe possible improvements and extensions including a) the possibility of a pre-processing step involving basis reduction with the LLL algorithm, to improve performance guarantees; b) the extension to multilayer quantization."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "Showing that a recent empirical approach to neural network quantization is in fact equivalent to a well-established tool from lattice geometry is important. Besides bringing clarification to the field, this also establishes connections that are potentially very fruitful: the paper notably mentions existing guarantees, and describes a number of convincing potential improvements. Some of these consequences also involve the analysis of Qronos, another recent quantization approach.  The paper is well-written, concise and clear.  The proof technique (proving equivalence to Babai-Proj-Rec, and to Babai_{\\kappa_i} is very neat."}, "weaknesses": {"value": "There is overlap between the contribution of this paper and a recent preprint by Chen et al. Chen et al provide numerical experiments, this paper does not.  Yet, the authors are explicit about this, both papers seem to have been produced at about the same time, and the absence of experiments in this submission actually also contributes to its elegance, concision, and focused viewpoint, which are all rather strengths. \n\nIt is not completely straightforward to check that the paper's description of GPTQ and Babai's algorithm fully matches the description of these algorithms in the corresponding references (by the way a chapter number would have helped when referring to Nguyen and Vallée)."}, "questions": {"value": "Can you detail why the algorithms you detail exactly match GPTQ and Babai's algorithm ?\n\nMinor suggestions: \n-elaborate on the impact of your viewpoint on the analysis of Qronos, which seems to be a distinctive feature of your analysis compared to that of Chen et al.\n-include an explicit summary of the numerical improvements \"mentioned in the paper\" in section 3.\n-write more explicitly that \"what `t' is in the first recursion\" (page 6) means \"in the first call to line 6 of BABAI-PROJ-REC\"\n-clarify in section 2.3 what the \"green sub lattice\" is.\n-to help the reader it may be useful to state after (3) that from now on k always assumed to be larger than n.\n-top of page 3: the \"projection\" is a linear map, not a projection, right ?\n-below (10): writing explicitly X_{>=2} (w+...) as an equation would seem clearer than spelling it out with words, and would ease the connection with (11); \n-spell out GPTQ the first time this acronym is used"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KIJLEYnG21", "forum": "L4SwHIZEaJ", "replyto": "L4SwHIZEaJ", "signatures": ["ICLR.cc/2026/Conference/Submission21508/Reviewer_Xcva"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21508/Reviewer_Xcva"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760976648837, "cdate": 1760976648837, "tmdate": 1762941810319, "mdate": 1762941810319, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "NA"}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "NA"}, "weaknesses": {"value": "NA"}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "GYWX6TveFb", "forum": "L4SwHIZEaJ", "replyto": "L4SwHIZEaJ", "signatures": ["ICLR.cc/2026/Conference/Submission21508/Reviewer_K3b5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21508/Reviewer_K3b5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761864456038, "cdate": 1761864456038, "tmdate": 1762941810065, "mdate": 1762941810065, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper establishes a formal connection between the problem of post-training weight quantization for linear layers in neural networks and the classical Closest Vector Problem (CVP) from lattice theory.\n\nThe central contribution of the work is a concise proof demonstrating that GPTQ is mathematically equivalent to Babai's nearest-plane algorithm. The authors discuss several consequences of this equivalence, including potential numerical stability improvements for GPTQ, handling quantization across multiple layers, and leveraging lattice basis reduction techniques to potentially enhance quantization performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "I think the paper is easy to follow and has an interesting topic. \n\nIt takes expertise from both domains (Quantization and Lattice Geometry) to notice the equivalence between GPTQ and Babai. And it is valuable that Lattice Geometry knowledge from decades ago can help design better quantization algorithms.\n\nThe proof is more concise than the concurrent work mentioned in this manuscript."}, "weaknesses": {"value": "The paper is purely theoretical and lacks experimental validation. This is an omission in a field as applied as model compression. The authors propose several compelling consequences in Section 3, most notably the use of lattice basis reduction (LBR) to improve quantization performance. However, these claims remain speculative. Critical questions regarding the computational overhead of LBR, its impact on the final model's generalization (the authors themselves note a risk of overfitting and generating large weight values ), and its actual impact on metrics like perplexity are left unaddressed.\n\nThe paper reads more like a well-written proof-of-concept than a complete ICLR-level publication. While the authors acknowledge an overlap in the manuscript with the concurrent work of Chen et al., it still impacts the novelty since the major conclusions of the two papers are the same."}, "questions": {"value": "The paper acknowledges \"significant overlap\" with Chen et al. (2025). I do understand Chen et al is a concurrent arXiv paper, and it won't affect the review process of this manuscript. But I'm wondering, could the authors please elaborate on the specific, unique insights that your proof methodology provides?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "E5MeUWoxZv", "forum": "L4SwHIZEaJ", "replyto": "L4SwHIZEaJ", "signatures": ["ICLR.cc/2026/Conference/Submission21508/Reviewer_w5cR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21508/Reviewer_w5cR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762156461559, "cdate": 1762156461559, "tmdate": 1762941809747, "mdate": 1762941809747, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors present a relatively straightforward equivalence proof between GPTQ (a well-known data-driven quantization approach for linear units in a neural network) and the classic Babai’s algorithm (a nearest-plane algorithm). After an in-depth discussion of both algorithms, including visualizations describing the underlying geometry, the equivalence proof is built by constructing recursive versions of both algorithms.\n\nThe paper concludes with a short discussion of the consequences of the equivalence, e.g., easier handling of quantization over multiple layers for GPTQ and the construction of an algorithm using lattice basis reduction."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper is well written and includes an in-depth discussion of background, making it easy to follow. The presented equivalence has potential for significant impact."}, "weaknesses": {"value": "While the presented equivalence has potential for significant impact, the paper as it stands does not provide sufficiently strong evidence for this. The final consequences and future work section provides some interesting insights, but to warrant publication at ICLR, I believe that at least some of these observations have to be experimentally validated.\n\nMost important in this regard is showing that the discussed numerical improvements hold and that the WithReduction algorithm provides the improvements the paper hints at. The correct handling of quantization over multiple layers would also be beneficial to study, though it may be hard to demonstrate."}, "questions": {"value": "Not at this time."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "F5WgQMwmmj", "forum": "L4SwHIZEaJ", "replyto": "L4SwHIZEaJ", "signatures": ["ICLR.cc/2026/Conference/Submission21508/Reviewer_8GUU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21508/Reviewer_8GUU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21508/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762224319120, "cdate": 1762224319120, "tmdate": 1762941809489, "mdate": 1762941809489, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}