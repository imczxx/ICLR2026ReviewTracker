{"id": "QBTNpmtYmQ", "number": 18227, "cdate": 1758285386688, "mdate": 1759897117936, "content": {"title": "Global Pivots, Local Unknowns: Stable Federated Open-Set Semi-Supervised Learning", "abstract": "We study Federated Open-Set Semi-Supervised Learning (FOSSL) under a labels-at-server regime, where the server holds a small labeled set of in-distribution (ID) classes while clients contribute only unlabeled, non-IID data that may include unknown classes. This setting is practically important yet under-explored and poses distinctive challenges: pseudo-label brittleness and intensified heterogeneity from diverse out-of-distribution (OOD) categories. We propose OpenFL, a server-guided framework that stabilizes training and exploits only reliable ID signals. The server maintains a round-wise EMA (R-EMA) model to smooth round-to-round drift, uses EMA-derived global pivots to anchor representation learning, and aggregates clients by reliability-aware weights (alignment quality) rather than data size. Clients apply dual-gated pivot alignment, attracting only high-confidence ID samples, while uncertain/OOD samples receive a mild angular repulsion from all pivots via the normalization term. Across CIFAR-10, CIFAR-100, and FashionMNIST with diverse inlier/outlier splits and unseen OOD tests, OpenFL consistently improves both ID accuracy and OOD detection (AUROC) and remains stable where federated adaptations of strong SSL/OSSL baselines become unstable. This work establishes labels-at-server FOSSL as a benchmark problem and provides a principled solution framework.", "tldr": "This paper introduces Federated Open-Set Semi-Supervised Learning (FOSSL) under labels-at-server, identifies its challenges, and proposes a global-pivot–centric framework that achieves stable gains in ID accuracy and OOD detection.", "keywords": ["Federated Learning", "Federated Semi-Supervised Learning", "Open-set Semi-Supervised Learning"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7e9cb2efd2bf89dd6187e65a0a8cef154c7f76d7.pdf", "supplementary_material": "/attachment/d085cae11c79651373dce9595f9c1cb3bb68f623.zip"}, "replies": [{"content": {"summary": {"value": "1. The paper formalizes Federated Open-Set Semi-Supervised Learning (FOSSL) in a \"labels-at-server\" regime, where clients hold only unlabeled, non-IID, open-set data, posing challenges of pseudo-label brittleness and intensified heterogeneity from diverse unknown classes.\n2. It proposes OpenFL, a server-guided framework that stabilizes training using three components: Round-wise EMA (R-EMA) for a stable server-side model, Pivot-guided Open-set Alignment to guide clients with stable class references, and Reliability-Aware Aggregation (RAA) to weight clients by update quality rather than data size.\n3. OpenFL consistently improves both in-distribution (ID) accuracy and out-of-distribution (OOD) detection (AUROC) across CIFAR-10, CIFAR-100, and FashionMNIST, remaining stable where federated baselines fail.\n\nWhile effective, the work is primarily compositional in nature, drawing from established techniques, and thus fails to provide sufficient novelty."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The open-set formulation is novel.\n2. All the proposed components of the training method are effective and improve performance empirically."}, "weaknesses": {"value": "1. Using a moving average at the server has been done before, both in a centralized iteration-based fashion and in a federated round-based setting[1,2].\n2. Guiding aggregation weights by the loss has been done before [3,4], using specific losses is not sufficient grounds for novelty.\n3. No theoretical guarantees are provided.\n4. All experiments are conducted on small-scale computer vision datasets (FashionMNIST, CIFAR-10, CIFAR-100) using a relatively shallow backbone. These benchmarks do not adequately represent the challenges of modern deep learning. It is unclear if the proposed methods would remain effective when fine-tuning or pre-training large-scale foundation models.\n\n[1] Zhang, et.al; \"How Does Critical Batch Size Scale in Pre-training?\"\n\n[2] Zhou, et.al; \"Understanding and Improving Model Averaging in Federated Learning on Heterogeneous Data\"\n\n[3] Li, et.al; \"Fair Resource Allocation in Federated Learning\"\n\n[4] Li, et.al; \"Tilted Empirical Risk Minimization\""}, "questions": {"value": "1. How does the computational complexity of your method scale as the model size increases, particularly with the embedding dimension and the number of classes?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "mYYJEBeKY9", "forum": "QBTNpmtYmQ", "replyto": "QBTNpmtYmQ", "signatures": ["ICLR.cc/2026/Conference/Submission18227/Reviewer_9cdJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18227/Reviewer_9cdJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18227/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761604036448, "cdate": 1761604036448, "tmdate": 1762927966541, "mdate": 1762927966541, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper attempts to address the problem of Federated Open-Set Semi-Supervised Learning (FOSSL) in labels-at-server setting. In this setting, a central server holds a small amount of labeled ID data, while clients possess only unlabeled data that contains both ID and OOD samples. The authors claim that existing methods fail due to pseudo-label brittleness and data heterogeneity. They propose OpenFL,which combines three main components: (1) R-EMA model on the server, (2) a pivot-guided alignment where clients align high-confidence samples to server-computed class prototypes, and (3) RAA scheme that weights clients based on the inverse of their alignment loss. The experiments show that their method achieves great ID accuracy and OOD detection."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The empirical study in Section 3, which demonstrates the failure modes of naively applying existing FSSL and OSSL methods to this setting, providing a clear motivation for the problem.\n2. The paper is well-written and most parts are clearly explained."}, "weaknesses": {"value": "1. OpenFL appears to be little more than a combination of existing, well-known ideas stitched together, such as exponential moving average (common strategy in SSL methods) and prototype learning. So in my opinion, the contribution is negligible.\n2. The use of globally fixed thresholds for the dual-gate selection is sub-optimal. A good confidence score on a client with clean data might be a bad one on a client swamped with OOD samples.\n3. The federated adaptations of centralized OSSL methods, particularly FedSCOMatch and FedProSub, perform exceptionally poorly, often leading to model collapse. Can the authors provide evidence that these are not strawman implementations? Please detail the specific adaptation strategies and hyperparameters used, and justify why you believe this represents a fair comparison."}, "questions": {"value": "See in Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YmJ7aSyH0Q", "forum": "QBTNpmtYmQ", "replyto": "QBTNpmtYmQ", "signatures": ["ICLR.cc/2026/Conference/Submission18227/Reviewer_wDvA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18227/Reviewer_wDvA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18227/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761727937753, "cdate": 1761727937753, "tmdate": 1762927966116, "mdate": 1762927966116, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work tackles the challenging Federated Open-Set Semi-Supervised Learning setting where labeled training data is uniquely located on the server. The authors proposed OpenFL, a novel framework that enables the server to control the federated training and guide clients to meaningfully contribute to the global model, even though they don’t possess any labelled training samples. OpenFL comprises a series of techniques such as round-wise exponential moving average, global pivots, and reliability-aware client weights aggregation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- S1. The authors tackle a challenging and critical federated learning setting.\n- S2. The authors propose a full end-to-end method to robustly train federated models where clients' training data is completely unlabelled.\n- S3. The proposed method’s ML performance is evaluated across standard benchmarks in a meaningful setting."}, "weaknesses": {"value": "- W1. Limited novelty – Many components of OpenFL (e.g., using a global pivot model or EMA updates) have been proposed previously (e.g., in recent federated semi-supervised methods like FedAnchor [1]). While OpenFL’s combination of these techniques in the FOSSL setting is useful, the approach feels incremental rather than introducing a fundamentally new concept.\n- W2. Complex tuning – OpenFL introduces numerous new hyperparameters (e.g., for the EMA decay, pivot selection, client weighting). This added complexity could make the method hard to tune in practice, potentially limiting its real-world applicability. This concern is heightened by the fact that the experiments were on well-established benchmarks with presumably careful tuning; deploying OpenFL in the wild might be challenging without guidance on choosing these hyperparameters.\n- W3. Limited evaluation scope – The experimental settings are not fully representative of challenging real-world federated scenarios. For instance, the paper evaluates on at most 20 clients with reasonably large local datasets, but does not test cases with a huge number of clients or with extremely scarce data per client. This omission leaves it unclear how OpenFL performs in more extreme or realistic federated conditions (e.g., hundreds of clients or clients with only a handful of samples).\n\n[1] Xinchi Qiu, Yan Gao, Lorenzo Sani, Heng Pan, Wanru Zhao, Pedro PB Gusmao, Mina Alibeigi, Alex Iacob, and Nicholas D Lane. Fedanchor: Enhancing federated semi-supervised learning with label contrastive loss for unlabeled clients. arXiv preprint arXiv:2402.10191, 2024."}, "questions": {"value": "- Q1. The abstract currently spends a lot of space on method details. Could the authors revise it to highlight the key challenges of the FOSSL setting more explicitly, rather than the implementation specifics of OpenFL?\n- Q2. Can the authors clarify how abundant they assume the server training dataset is compared to the local client datasets? It is critical for setting the context of the applicability of the OpenFL method.\n- Q3. Can the authors discuss more explicitly in the introduction what key challenges the components of OpenFL are meant to address?\n- Q4. How would OpenFL perform in scenarios of extreme data scarcity? Consider two cases: (a) the server’s labeled dataset is very scarce relative to clients (e.g., only 1–10% the size of the total client data), and (b) each client’s local dataset is so small that a full batch can’t be formed without reusing data. Can the authors discuss how OpenFL would handle these situations?\n- Q5. Despite being unpublished work, how do the authors think OpenFL compares to Fedanchor [1]? I would like to read their opinion comparing the two methods on: (a) general setting; (b) motivating examples; (c) basic working principle; (d) performance (if they have sufficient time to try to reproduce, but this point is not crucial).\n- Q6. Can the authors add a fitting line in Figure 3 to help readability and quantify the correlation they claim?\n- Q7. How many global pivots does OpenFL require to perform sufficiently well?\n- Q8. Can the authors add to each table and figure reporting results from the ablation/sensitivity studies (tables 2 and 3, and figure 4) a horizontal line showing the performance of the best baseline method as well?\n- Q9. Given that the authors used open-source software to implement and test OpenFL, will they make the code publicly available?\n\n[1] Xinchi Qiu, Yan Gao, Lorenzo Sani, Heng Pan, Wanru Zhao, Pedro PB Gusmao, Mina Alibeigi, Alex Iacob, and Nicholas D Lane. Fedanchor: Enhancing federated semi-supervised learning with label contrastive loss for unlabeled clients. arXiv preprint arXiv:2402.10191, 2024."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xmPS4RJb9y", "forum": "QBTNpmtYmQ", "replyto": "QBTNpmtYmQ", "signatures": ["ICLR.cc/2026/Conference/Submission18227/Reviewer_bpFb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18227/Reviewer_bpFb"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18227/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930481219, "cdate": 1761930481219, "tmdate": 1762927965802, "mdate": 1762927965802, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the Federated Open-Set Semi-Supervised Learning (FOSSL) problem, where the server has access to a small labeled dataset of in-distribution (ID) classes, while clients hold only unlabeled, non-IID data that may include out-of-distribution (OOD) samples.This paper proposes OpenFL with three components: Round-wise EMA (R-EMA): A round-wise exponential moving average model; Pivot-Guided Open-Set Alignment: Global pivots guide client-side alignment, attracting high-confidence ID samples while mildly repelling uncertain/OOD samples; Reliability-Aware Aggregation (RAA): Client contributions are weighted based on alignment loss."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Foucs on a practical and underexplored problem.1\n\n2. Comprehensive evaluation. The study includes relevant baselines, such as SemiFL, FedFixMatch, and federated adaptations of centralized OSSL methods. The experiments cover diverse datasets, client partitioning schemes (IID and non-IID), and multiple challenging splits, providing a broad evaluation of the proposed method.\n\n3. Good presentation and writing."}, "weaknesses": {"value": "1. Technical Novelty\n\nThe proposed method combines widely adopted techniques, including EMA, prototype-based alignment, and loss reweighting mechanisms. Each of these components is well-established in related works. For example: EMA is a standard stabilization technique in many learning systems. Pivot-based alignment is a direct extension of prototype methods used in centralized contrastive learning and semi-supervised learning. Reliability-aware aggregation using alignment loss is conceptually similar to weighting schemes, e.g., importance sampling or quality-based aggregation.\n\nThe combination of these components is incremental and does not introduce a new \\textbf{insight} or novel \\textbf{technique}.\n\n2. High Sensitivity to Hyperparameters. The method relies heavily on existing loss functions and their combinations (e.g., FixMatch consistency loss, OOD detection losses from OpenMatch, SSB, etc.). It introduce multiple hyperparameters, making the method parameter-sensitive and hard to be generalized. The sensitivity analysis in the experiments demonstrates that performance can vary significantly depending on these choices.\n\n3. Limited Applicability to Real-World Federated Settings\n\nServer-side pivots are computed from a small labeled dataset, limiting the scalability of real-world application. If possible, please use large-scale dataset."}, "questions": {"value": "Beyond the above concerns on Weaknesses, please answer:\n\n1. Novelty Clarification\n\n2. Dataset Scalability\n\n3. Sensitivity Analysis of Hyperparameters Across Different Settings and Datasets\n\nThe hyperparameters in this method are highly sensitive across different datasets and settings."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lKTfOGPogP", "forum": "QBTNpmtYmQ", "replyto": "QBTNpmtYmQ", "signatures": ["ICLR.cc/2026/Conference/Submission18227/Reviewer_pWQc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18227/Reviewer_pWQc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18227/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761982788406, "cdate": 1761982788406, "tmdate": 1762927965375, "mdate": 1762927965375, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}