{"id": "iDki7djO2K", "number": 9120, "cdate": 1758111960507, "mdate": 1763471398255, "content": {"title": "Forgetting is Everywhere", "abstract": "A fundamental challenge in developing general learning algorithms is their tendency to forget past knowledge when adapting to new data.\n    Addressing this problem requires a principled understanding of forgetting; yet, despite decades of study, no unified definition has emerged that provides insights into the underlying dynamics of learning.\n    We propose an algorithm- and task-agnostic theory that characterises forgetting as a lack of self-consistency in a learner's predictive distribution over future experiences, manifesting as a loss of predictive information. \n    Our theory naturally yields a general measure of an algorithm's propensity to forget. \n    To validate the theory, we design a comprehensive set of experiments that span classification, regression, generative modelling, and reinforcement learning.\n    Across these domains, we empirically demonstrate how forgetting is present across all learning settings and plays a significant role in determining learning efficiency.\n    Together, these results establish a principled understanding of forgetting and provide a foundation for analysing and improving the information retention capabilities of general learning algorithms.", "tldr": "We propose and evaluate a formal definition of forgetting that unifies phenomena in supervised and reinforcement learning settings.", "keywords": ["Forgetting", "Bayesian learning", "Reinforcement learning", "Supervised learning"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e260903db26f39a0516b3119beb866a5b8aa92b1.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes a unified and universal theoretical framework to characterize “forgetting.” Based on the theory of “predictive distribution self-consistency,” the authors define the essence of forgetting: when learners alter their predictions upon encountering expected data, this change signifies the loss of previously acquired capabilities. Building on this concept, the paper introduces operational metrics to quantify the forgetting tendency of learning algorithms during sequential training. The authors also conduct extensive empirical experiments across multiple learning paradigms, revealing the universality of the forgetting phenomenon and the trade-off between forgetting and training efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper presents a clear and relatively general formal definition that not only explores forgetting in supervised learning but also extends to generative modeling and reinforcement learning, demonstrating the widespread nature of the forgetting phenomenon. \n2. Experiments reveal that optimal training efficiency does not correspond to minimal forgetting but rather involves a trade-off, offering valuable insights for designing learning algorithms.\n3. The paper is well-structured and well-written, and generally easy to follow."}, "weaknesses": {"value": "1. Although experimental results cover multiple learning paradigms, they primarily present trends rather than delving into underlying mechanisms. For instance, in reinforcement learning, where forgetting is severe, they remain largely observational and lack analysis of reasons such as network architecture, state space, or optimizer hyperparameters.\n2. While the paper presents theory and metrics, it offers limited suggestions on “how to design algorithms that reduce forgetting.” It fails to provide sufficient guidance for practitioners seeking to know “how to improve training.”"}, "questions": {"value": "1. In practical continuous learning tasks, do the metrics proposed in this paper outperform traditional indicators? How should practitioners adopt these different metrics based on prior knowledge?\n2. Moderate forgetting may correspond to optimal efficiency. Is this conclusion robust across different conditions such as model architecture, dataset size, and optimization hyperparameters (e.g., momentum, learning rate)? Can more actionable recommendations be provided?\n3. When learning involves significant randomness or occurs in unstable tasks, inconsistent expectations due to distribution shifts may be caused by the task itself rather than by forgetting. Does the definition of forgetting presented in this paper remain valid in such cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2g74JN6qup", "forum": "iDki7djO2K", "replyto": "iDki7djO2K", "signatures": ["ICLR.cc/2026/Conference/Submission9120/Reviewer_xrmZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9120/Reviewer_xrmZ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9120/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761816258539, "cdate": 1761816258539, "tmdate": 1762920815989, "mdate": 1762920815989, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Response to All Reviewers"}, "comment": {"value": "We thank the reviewers for their feedback, which improved the paper’s presentation, empirical section, and clarity of scope. All changes are marked in violet in the revised manuscript.\n\nOverall, we were encouraged by the reviewers' enthusiasm regarding the ambition, clarity, and novelty of the work, as well as the recognition that a principled, task-agnostic conceptualization of forgetting \"could serve as a foundational framework for theoretical analysis in the community.\" The reviews raised excellent questions that helped us identify where the scope and intent of the paper were insufficiently clear, and motivated us to strengthen the empirical analysis and refine key assumptions.\n\nAcross the reviews, we observed four recurring themes:\n\n1. Requests for increased empirical depth and stronger takeaways.\n2. Confusion regarding the role of parameter/belief updates in forgetting.\n3. Uncertainty about whether the formalism applies beyond stationary settings.\n4. Comments about forgetting in CL vs. forgetting more generally.\n\nWe address each of these concerns below.\n\n1. **Expanded empirical section.**\n\nTo address requests for more empirical depth, we:\n\n- added a subsection on unforgetful learners demonstrating that parameter changes do not imply forgetting (§5.1),\n- improved the momentum-forgetting figure to show the forgetting-training efficiency trade-off plots, and added another plot to show the generality of this proposition figure (lines 468-485, 1193-1210),\n- strengthened the takeaways (lines 350, 422, 465, 520) such that they offer more concrete insights,\n- added additional reinforcement learning (RL) plots in the appendix to demonstrate the importance of forgetting in RL when changing hyperparameters (Appendix E.2),\n- included an algorithm for computing the propensity to forget in the appendix (lines 1160-1177).\n\n2. **Parameter changes do not imply forgetting.**\n\nWe clarify that **forgetting and belief/parameter updates are distinct phenomena**: Not all changes to parameters entail forgetting. We have added a discussion of this point in the related work (lines 103-116, 306-313) and empirically demonstrated it in a new section: the unforgetful Bayesian learner (§5.1). This misconception further **demonstrates the need for a comprehensive definition and conceptualisation of forgetting** that applies to all learning settings and learners, regardless of how they are implemented.\n\n3. **Theoretical foundation and stationarity.**\n\nThe reviewers made us realise that we had insufficiently explained the predictive Bayesian perspective we took in the paper. We therefore added a dedicated subsection (lines 228-234) clarifying that predictive Bayes underlies our notion of the induced futures/predictive distribution and that it:\n\n- is a standard and well-established theoretical tool,\n- does not assume Bayesian learners (as predictive Bayes is a perspective on knowledge, not a restriction on learning algorithm), and\n- does not require stationarity.\n\nTo further clarify the scope, we added text to the paper  (lines 352-359) that explicitly details the limits of the theory. Overall, our theory applies equally to stationary, non-stationary, task-structured, and unstructured settings.\n\n4. **Forgetting as a general property of learning**\n\nOur goal is to **study forgetting as a fundamental property of learning**, independent of any particular domain or architecture. The learning setting we adopt (CL, RL, or otherwise) and the specific class of learner (neural networks, Bayesian, and so on) serve as instances of a broader phenomenon. Our aim was to formulate a general theory of forgetting that can accommodate all of these settings. In light of the reviewers’ feedback, we have **added a new paragraph to the introduction (lines 39-43) as well as to the related work section (lines 103-116)**, which motivates the need for a general, task- and algorithm-agnostic conceptualisation of forgetting.\n\nWe view this generality as a strength of the work, as it enables broad analysis and framing across learning settings and algorithmic approaches.\n\n**We believe these clarifications and additions have substantially strengthened the paper. Below, we address each reviewer's comments in detail.**"}}, "id": "ZxPshCCn8o", "forum": "iDki7djO2K", "replyto": "iDki7djO2K", "signatures": ["ICLR.cc/2026/Conference/Submission9120/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9120/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9120/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763471573541, "cdate": 1763471573541, "tmdate": 1763471573541, "mdate": 1763471573541, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a general theoretical and empirical framework for understanding forgetting in machine learning systems, treating forgetting as a universal property of adaptive learners, not just in CL settings. It formalizes the forgetfulness of a system through the concept of k-step self-consistency in predictive distributions, i.e., the divergence between the learner's updated model and its hypothetical consistent model."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. It is interesting to study forgetting issue as a general property of machine learning models. The idea is novel. \n\n2. It is novel to measure the forgetfulness as the propensity to forget, i.e., how much the learner system's internal representation of the future drifts purely due to its own updates, independent of environmental changes. \n\n3. The paper conducts experiments spanning multiple machine learning settings, such as regression, classification, and reinforcement learning, leading to some insightful findings."}, "weaknesses": {"value": "1. The paper lacks the theorectical grounding to justify the notion of predictive consistency.\n\n2. It is unclear what the direct benefits of understanding forgetfulness of a learner's sytems are, especially, how it can contribute to the downstream tasks. It would be more interesting to investigate how the understanding can help mitigate the forgetting issues.\n\n3. The paper focuses on the analysis on a system's self consistency in predictive disributions, treating the system as a blackbox and offering limited interpretability. It doesn't look into the internal representations or parameter dynamics (e.g., drift in embedding space) contribute to forgetting, which could be more useful to explain the forgetting phenomenon."}, "questions": {"value": "1. Can you analyze the reliablity of the forgetfulness measurement? \n\n2. Can you compare the forgetfulness and the typical forgetting metrics (such as accuracy drop) in current CL settings?\n\n3. What is the computational cost of evaluating the forgetfulness of a model, especially for those large scale models? \n\n4. What are the direct benefits of understanding the forgetfulness of a model? How can it be leveraged to mitigate the forgetting issues."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fBGRKNeFks", "forum": "iDki7djO2K", "replyto": "iDki7djO2K", "signatures": ["ICLR.cc/2026/Conference/Submission9120/Reviewer_qboB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9120/Reviewer_qboB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9120/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880930273, "cdate": 1761880930273, "tmdate": 1762920815558, "mdate": 1762920815558, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a unified theoretical framework to explain forgetting across diverse learning settings, including Reinforcement Learning, Continual Learning, and Generative Modeling. The authors argue that forgetting should be viewed separately from prediction accuracy and instead defined as a change in the induced future. A metric named “propensity to forget” is introduced to measure this change, along with empirical studies to support the theory."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is generally well written and organized (though a few statements may need improvement).\n\n- The work introduces a novel conceptual angle by defining forgetting based on induced futures rather than accuracy degradation."}, "weaknesses": {"value": "- The statement in Lines 45–47 appears too strong (and several other statements in the paper with this assumption). The claim assumes that the learner does not gain any new information. However:\n\n  - How can we ensure the learner indeed learns nothing new during such updates, especially under stochasticity?\n  - If the data distribution changes (e.g., under distribution shift or class-incremental settings), changes in induced futures may come from newly acquired knowledge, not forgetting.\n\n  This suggests that the theory may be limited to stationary environments or require clear assumptions about what constitutes “new information.”\n\n- The analysis seems largely limited to forgetting caused by the stochastic nature of training (e.g., momentum changes in Figure 2), rather than more widely studied sources of forgetting, such as task interference.\n\n- Some concepts are vague and would benefit from clearer definitions:\n\n  - Lines 216–219: What exactly is meant by “performance”? Because there are metrics that incorporate forgetting and accuracy (e.g, Backward Transfer) \n\n  - Line 242: Clarify what is meant by “exposed”: does this refer to training or inference?\n\n  - Line 242: What does “data it already expects” refer to: historical data, or future trajectories?\n\n- It would strengthen the paper to include a concrete algorithm or procedural guide to compute Equation (9).\n\n**Minor:**\n\n- Although Y is defined, it is sometimes confusing with ground-truth labels (e.g., Line 128).\n- Line 130: Next observations do not always depend on history (e.g., i.i.d)."}, "questions": {"value": "Please refer to the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lrfTbRImZd", "forum": "iDki7djO2K", "replyto": "iDki7djO2K", "signatures": ["ICLR.cc/2026/Conference/Submission9120/Reviewer_LfRt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9120/Reviewer_LfRt"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9120/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925829703, "cdate": 1761925829703, "tmdate": 1762920814898, "mdate": 1762920814898, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a unified theoretical framework for forgetting, defining forgetting as the inconsistency of a mode's predictive distribution under self-consistent conditions. Starting from the interaction between a learner and its environment, the authors establish a general probabilistic process model and derive a computable measure of forgetting. Through experiments on regression, classification, generative modeling, continual learning, and reinforcement learning, they show that forgetting is ubiquitous across paradigms and that a moderate amount of forgetting can actually enhance learning efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Strengths\n\n1. The paper is theoretically innovative, proposing a task-agnostic and algorithm-agnostic definition of forgetting that could serve as a foundational framework for theoretical analysis in the community.\n\n2. The mathematical derivations are rigorous and the concepts are clearly defined.\n\n3. The experiments cover multiple learning paradigms.\n\n4. The finding that \"moderate forgetting leads to optimal learning efficiency\" is insightful."}, "weaknesses": {"value": "Weaknesses\n1. First, the \"powerful insight\" stated in the introduction is, while correct, rather self-evident and perhaps too simple to be considered an insight. In deep learning, it is well known that parameter updates via back-propagation naturally change the model's internal representations and thereby its predictions on data, which in turn causes forgetting. This seems more like a direct consequence of parameter modification than a novel conceptual observation.\n\n2. The paper presents basic yet comprehensive theoretical analyses, but it remains unclear how much new understanding or inspiration these analyses bring to the community. Valuable conclusions only appear starting from Section 4, and this part is relatively short. I noticed that the appendix contains additional experiments and some impressive findings; some of them could be moved into the main text, possibly reducing earlier theoretical exposition. Even then, the empirical conclusions still seem limited in value — for example, Takeaway 4.1 is an interesting idea, but the supporting experiments are overly simple; merely changing the momentum in SGD is insufficient to substantiate the claim. Moreover, the discussion in Takeaway 4.2 is somewhat vague: I do not fully understand its connection to real-world reinforcement learning settings or what concrete insights it offers."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7Sq8wc9YcN", "forum": "iDki7djO2K", "replyto": "iDki7djO2K", "signatures": ["ICLR.cc/2026/Conference/Submission9120/Reviewer_GaRd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9120/Reviewer_GaRd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9120/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762002318956, "cdate": 1762002318956, "tmdate": 1762920814464, "mdate": 1762920814464, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}