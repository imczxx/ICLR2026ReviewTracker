{"id": "kFgsebdKje", "number": 9740, "cdate": 1758137254492, "mdate": 1759897701275, "content": {"title": "TGM: A Modular and Efficient Library for Machine Learning on Temporal Graphs", "abstract": "Well-designed open-source software drives progress in Machine Learning (ML) research. While static graph ML enjoys mature frameworks like PyTorch Geometric and DGL, ML for temporal graphs (TG), networks that evolve over time, lacks comparable infrastructure. Existing TG libraries are often tailored to specific architectures, hindering support for diverse models in this rapidly evolving field. Additionally, the divide between continuous- and discrete-time dynamic graph methods (CTDG and DTDG) limits direct comparisons and idea transfer. To address these gaps, we introduce Temporal Graph Modelling (TGM), a research-oriented library for ML on temporal graphs, the first to unify CTDG and DTDG approaches. TGM offers first-class support for dynamic node features, time-granularity conversions, and native handling of link-, node-, and graph-level tasks. Empirically, TGM achieves an average 7.8× speedup across multiple models, datasets, and tasks compared to the widely used DyGLib, and an average 175× speedup on graph discretization relative to available implementations. Beyond efficiency, we show in our experiments how TGM unlocks entirely new research possibilities by enabling dynamic graph property prediction and time-driven training paradigms, opening the door to questions previously impractical to study.", "tldr": "We present TGM, a modular research library for efficient and reproducible machine learning on temporal graphs.  TGM supports both discrete and continuous-time temporal graph methods.", "keywords": ["Temporal Graph Learning", "Dynamic Graphs", "Deep Learning", "Programming Framework", "Software Libraries"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/25e5205738518a5b4528de8cb009f1d959a02532.pdf", "supplementary_material": "/attachment/34e5c371575da820efe5432795766e53fa6a143e.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces a new library for temporal graph learning that unifies CTDG and DTDG, supporting a wide range of tasks and methods efficiently. The work includes several novel components, notably the unification of CTDG and DTDG and the hook management mechanism for obtaining training features. Its modular design is well-conceived and will allow researchers to easily develop, extend, and evaluate new methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 4}, "strengths": {"value": "The proposed library is timely and represents a valuable contribution to the field of temporal graph learning. It offers a convenient experimental infrastructure and a fair evaluation platform that can accelerate research progress. Compared with existing libraries, it appears more general and efficient, and it provides a diverse collection of datasets and methods to facilitate easy and consistent comparison across studies."}, "weaknesses": {"value": "W1. My primary concern lies in the writing. First, while the authors emphasize the efficiency of TGM, the paper lacks a detailed explanation or analysis clarifying why TGM is more efficient than existing methods. Second, Section 3 spans nearly two pages but presents multiple items in a disconnected manner, making it difficult to follow the logical flow of ideas.\n\nW2. I also noticed that a prior study, TGB-Seq, introduced several new datasets and integrated them into DyGLib. It would be better if the authors could incorporate the TGB-Seq datasets into TGM as well, since these datasets have been widely adopted in recent research."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "JMA6SleBjp", "forum": "kFgsebdKje", "replyto": "kFgsebdKje", "signatures": ["ICLR.cc/2026/Conference/Submission9740/Reviewer_pG5Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9740/Reviewer_pG5Q"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761357964250, "cdate": 1761357964250, "tmdate": 1762921235889, "mdate": 1762921235889, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces TGM, a research-oriented library for Temporal Graph Learning (TGL) \nthat supports both continuous-time (CTDG) and discrete-time (DTDG) dynamic graphs within a single modular system. \nThe library proposes a formal unification of both paradigms via the notion of graph discretization and time granularity. \nTGM supports link-, node-, and graph-level tasks and demostrantes significant efficiency gains over prior libraries such as DyGLib and UTG."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper addresses a timely and relevant problem in dynamic graph learning, where current frameworks lag behind static counterparts (e.g., PyG, DGL) in terms of flexibility, modularity, and computational efficiency.\n- The manuscript is well written and clearly structured, providing sufficient context and motivation for the proposed library.\n- If properly released and maintained as open-source, TGM could serve as a standard reference library for temporal graph learning research.\n- The framework demonstrates substantial efficiency gains across multiple models and tasks, indicating careful engineering and system design."}, "weaknesses": {"value": "- The empirical section primarily focuses on efficiency metrics and new results on CTDG tasks solved using DTDG-based models. However, these results offer limited analysis of performance in comparison with prior libraries and existing literature.\n- Some aspects are insufficiently detailed:\n    1) It is not clear whether experiments across libraries use identical data splits, hyperparameters, preprocessing, etc.\n    2) The paper does not clearly explain how batches are processed, specifically, whether events or snapshots within a batch are handled in parallel or sequentially, and if parallel processing is used, if temporal causality is preserved.\n    3) The treatment of deletion events (e.g., node removal) is not detailed in the paper.\n    4) It is unclear if irregularly sampled snapshot-based tasks (e.g., as in [4,5]) can be processed within TGM.\n- TGM currently implements tasks for CTDGs and enables DTDG models to operate on these tasks. However, the TGL community would greatly benefit if TGM also supported tasks specifically designed for DTDGs, such as Metr-LA and Pems-Bay [6], making it a truly unified library that facilitates research across both CTDG and DTDG paradigms.\n- When evaluating DTDG-based models, the authors should include comparisons against dedicated DTDG frameworks, such as Torch Spatiotemporal or PyTorch Geometric Temporal, to reduce the large number of unsupported baselines reported in Tables 3, 4, and 9.\n- The unified conceptual view connecting CTDGs and DTDGs is interesting; however, the theoretical relationship between these two temporal graph paradigms has already been discussed in prior works, including [1, 2, 3].\n  Although not implemented in a general-purpose library, these contributions should be properly acknowledged in the manuscript.\n- Given the growing interest on long-range information propagation and oversquashing in temporal GNNs [7], the authors should consider including CTAN [8], a model specifically designed to address this problem, within the TGM. This addition would further broaden the TGM's coverage and enhance its utility for research on novel temporal GNN architectures.\n\n-----\n\n[1] [Representation Learning for Dynamic Graphs: A Survey. JMLR 2020](https://jmlr.csail.mit.edu/papers/volume21/19-447/19-447.pdf)\n\n[2] [Deep learning for dynamic graphs: models and benchmarks. IEEE TNNLS 2024](https://ieeexplore.ieee.org/document/10490120)\n\n[3] [Graph neural networks for temporal graphs: State of the art, open challenges, and opportunities. TMLR 2023](https://openreview.net/pdf?id=pHCdMat0gI)\n\n[4] [Graph Neural Controlled Differential Equations for Traffic Forecasting. AAAI 2022](https://cdn.aaai.org/ojs/20587/20587-13-24600-1-2-20220628.pdf)\n\n[5] [Temporal Graph ODEs for Irregularly-Sampled Time Series. IJCAI 2024](https://www.ijcai.org/proceedings/2024/0445.pdf)\n\n[6] [Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. ICLR 2018](https://arxiv.org/abs/1707.01926)\n\n[7] [Over-squashing in Spatiotemporal Graph Neural Networks. 2025](https://arxiv.org/pdf/2506.15507)\n\n[8] [Long Range Propagation on Continuous-Time Dynamic Graphs. ICML 2024](https://openreview.net/pdf?id=gVg8V9isul)"}, "questions": {"value": "Refer to the paper’s weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "feXH5z6to6", "forum": "kFgsebdKje", "replyto": "kFgsebdKje", "signatures": ["ICLR.cc/2026/Conference/Submission9740/Reviewer_KuR4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9740/Reviewer_KuR4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824835594, "cdate": 1761824835594, "tmdate": 1762921235264, "mdate": 1762921235264, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a research‑oriented software library that unifies continuous‑time and discrete‑time learning on temporal graphs under one formal and practical framework. The authors introduce a typed hook abstraction for composing common temporal operations, and they formalize time‑granularity conversion via a discretization operator, enabling iteration either by events or by time. The system follows a three‑layer architecture, supports node and edge events, and implements representative models spanning message‑passing, transformer‑based, and snapshot methods. Empirically, TGM reports stronger efficiency  than DyGLib and UTG. It also enables research case studies on dynamic graph properties, snapshot granularity, and batching effects."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. This paper is generally well-writen and easy to follow.\n\nS2. This paper proposes a clean theoretical unification of CTDG and DTDG via the notion of a native time granularity and a principled discretization operator.\n\nS3. This paper introduces a typed hook formalism with explicit dependency contracts, which makes complex temporal pipelines composable and easier to reason about and test. \n\nS4. This paper provides a well‑architected system that separates data storage, execution, and model layers. the proposed framework demonstrates broad coverage of tasks and models."}, "weaknesses": {"value": "W1. This paper’s primary contribution is a software framework. While the system is valuable, the methodological novelty is limited relative to prior unification attempts (e.g., UTG) and existing libraries (e.g., DyGLib), raising questions about the conceptual contributions beyond engineering improvements.\n\nW2. This paper claims to unify CTDG and DTDG approaches, and it indeed provides a conceptual bridge through an event-sequence formulation and discretization operator. However, the empirical section does not yet demonstrate unification beyond efficiency. For example, there is no study comparing a CTDG model and a DTDG model on exactly the same data, tasks, and evaluation protocol.\n\nW3. The coverage of DTDG methods in the library and experiments is limited. The implemented and evaluated snapshot-based models are mainly GCN, GCLSTM, and T-GCN, while stronger or more representative DTDG baselines such as EvolveGCN[1] and DySAT[2] are neither implemented nor evaluated.\n\nW4. The experimental section focuses heavily on efficiency, but it does not verify correctness against the original authors’ official implementations or reported numbers across multiple metrics. As a result, the validity of the re-implemented models cannot be fully confirmed.\n\nW5. This paper lacks empirical comparisons with PyG Temporal[3] and Torch Spatiotemporal[4], two DTDG-oriented libraries that are discussed in the related-work section but not benchmarked in Section 5.\n\nMinor Typos. \n\n+ \"up to 246× than DyGLib\" -> \"up to 246× faster than DyGLib\". \n\n+ The spelling of behavior and behaviour should be made consistent.\n\n+ Table 8 \"first and second are highlighted\" -> \"First and second best are highlighted\"\n\n\n\nReference\n\n[1] EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs\n\n[2] Dynamic Graph Representation Learning via Self-Attention Networks\n\n[3] PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models\n\n[4] https://github.com/TorchSpatiotemporal/tsl"}, "questions": {"value": "1. Will the framework be adapted to text-attributed dynamic graphs[1]?\n\n[1] DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "NH8FN36r3b", "forum": "kFgsebdKje", "replyto": "kFgsebdKje", "signatures": ["ICLR.cc/2026/Conference/Submission9740/Reviewer_SxD6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9740/Reviewer_SxD6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761894646795, "cdate": 1761894646795, "tmdate": 1762921234464, "mdate": 1762921234464, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces TGM, a modular and efficient open-source library for temporal graph learning. \nIt unifies continuous-time and discrete-time dynamic graph paradigms within a single framework, providing native support for time operations, event-driven iteration, and node/edge dynamics. \nTGM uses a _hook_ abstraction to implement flexible composition of temporal graph operations and efficient workflows. \nThe experiments show convincing speedups on a broad set of models."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Unification: Comprehensive integration of CTDG and DTDG models under a single abstraction.\n\n- Technical design and efficiency: The hook-based modularity and vectorized implementation lead to significant computational gains.\n\n- Empirical validation and usability: Extensive benchmarks on multiple datasets and models."}, "weaknesses": {"value": "-Limited novelty beyond software engineering: While the framework is well-engineered, the conceptual contribution (e.g., the hook abstraction) is mostly organizational rather than methodological.\n\n- Evaluation scope: The Experiments focus mainly on efficiency and reproducibility; some examples showing directions of possible novel research would strengthen the claim of scientific impact."}, "questions": {"value": "Apart from the points discussed above, there are the following minor points:\n\n- Could the authors clarify how hooks differ from standard PyTorch data transformations or DGL message-passing pipelines conceptually?\n\n- The paper mentions “dynamic graph property prediction” as a novel task; could more examples or datasets be shown?\n\n- How does discretization handle overlapping time intervals or missing timestamps in real-world data? Or edges appearing and disappearing within the same time interval.\n\n- Are there guidelines for selecting optimal time granularities, given their strong impact on performance?\n\n- Representing Continuous-Time and Discrete-Time Graphs: A similar idea has been used already in [1], Definition 2 and 3.\n\n[1] A. Longa et al., Graph Neural Networks for Temporal Graphs: State of the Art, Open Challenges, and Opportunities, TMLR (2023)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "sTg61ZSVmD", "forum": "kFgsebdKje", "replyto": "kFgsebdKje", "signatures": ["ICLR.cc/2026/Conference/Submission9740/Reviewer_zkoA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9740/Reviewer_zkoA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9740/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762252936453, "cdate": 1762252936453, "tmdate": 1762921234050, "mdate": 1762921234050, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}