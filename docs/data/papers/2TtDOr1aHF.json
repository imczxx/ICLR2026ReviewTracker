{"id": "2TtDOr1aHF", "number": 8502, "cdate": 1758088048232, "mdate": 1763730576943, "content": {"title": "ParamAgent: Language Agents with Parametric Knowledge", "abstract": "Large Language Models (LLMs) have demonstrated strong reasoning abilities, yet existing agent frameworks remain constrained by two limitations. First, they typically operate at the per-instance level, confining signals to individual problems and overlooking transferable patterns across tasks. Second, while some approaches attempt to incorporate global information through external memory, these are non-parametric in nature, and thus capture only shallow interactions across instances, failing to uncover deeper regularities.\nTo overcome these limitations, we propose $\\texttt{ParamAgent}$, a language agent framework that leverages a domain-adaptive parametric module to internalize knowledge across samples into model parameters. In addition to capturing cross-sample regularities, $\\texttt{ParamAgent}$ provides twofold flexibility: (i) the parametric module can supply different forms of knowledge depending on various domains, and (ii) the same module can be integrated with different base LLMs, making $\\texttt{ParamAgent}$ broadly applicable. Moreover, $\\texttt{ParamAgent}$ naturally promotes diversity of outputs by adjusting the sampling temperature of the parametric module.\nExperiments on programming, math reasoning, and multi-hop question answering benchmarks show that $\\texttt{ParamAgent}$ consistently outperforms state-of-the-art baselines, surpassing the best baseline by up to $7.90\\\\%$, $9.41\\\\%$, and $24.30\\\\%$ respectively.", "tldr": "", "keywords": ["LLM", "agents", "reasoning", "external memory", "parametric knowledge"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6fd279a95ad885a82e6e1490d7aef90ab2b6c508.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces ParamAgent, a language agent framework designed to overcome the limitations of instance-level reasoning and non-parametric memory. The core idea is to augment a base LLM with a domain-adaptive, external parametric module. This module is fine-tuned to internalize domain knowledge. The authors demonstrate the framework's flexibility by instantiating this module in two ways: (1) a reflection-oriented module (Mr) for programming and math tasks, which synthesizes global reflections on common pitfalls, and (2) a decomposition-oriented module (Mp) for multi-hop QA, which breaks down complex questions into structured semantic units.\n\nThe framework is shown to be compatible with different base LLMs and can be combined with existing memory mechanisms like episodic reflection and retrieval-based memory banks. Extensive experiments on programming (HumanEval, MBPP), math reasoning (MATH), and multi-hop QA (HotpotQA, 2WikiMultiHopQA) benchmarks show that ParamAgent and its variants consistently and significantly outperform state-of-the-art baselines, demonstrating the power of integrating parametric knowledge into agentic reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The primary strength is the concept of a parametric knowledge module. This approach elegantly sidesteps the limitations of both purely instance-level reasoning (by incorporating global patterns) and non-parametric retrieval (by allowing the synthesis of novel, context-specific insights rather than just recalling past traces)."}, "weaknesses": {"value": "- Dependency on a \"Teacher\" Model: The parametric module M* is trained on data generated by GPT-4o-mini, a highly capable proprietary model. This means the method relies on knowledge distillation from a superior \"teacher\" model. It would be valuable to understand how much of the performance gain is due to the ParamAgent architecture itself versus the distilled knowledge from a stronger model. An ablation study where M* is trained on data generated by a weaker model (e.g., the base agent itself) would help isolate the architectural benefits.\n- Static Parametric Memory: The core design of M* is that it is trained offline and remains static during inference. It introduces a significant limitation: the agent cannot generalize new experiences learned \"on the fly\" into its long-term parametric knowledge.\n- Comparison to Simpler Alternative Frameworks: The paper overlooks comparisons to other established, and potentially simpler, paradigms for knowledge internalization. For example: (1) Direct Fine-tuning/Distillation: A straightforward alternative would be to collect successful solution trajectories from an agent (or a teacher model) and directly fine-tune the base LLM on them. (2) RL: Agentic reasoning tasks can be framed as sequential decision-making problems, making them amenable to RL methods like PPO/GRPO. \n- Lack of Novelty: The proposed framework can be viewed as a sophisticated form of knowledge distillation. It distills domain-specific heuristics from a powerful teacher model (GPT-4o-mini) into a specialized module (M*) that generates a structured form of CoT-style guidance. This paradigm lacks the ability for true dynamic learning through environmental interaction. The agent cannot acquire genuinely new knowledge beyond what was pre-digested in M*'s offline training.\n- Too Old Benchmarks and Base LLMs. There are many new, challenging benchmarks (e.g., SimpleQA, GPQA, SuperGPQA, LiveCodeBench) and SOTA LLMs (e.g., Qwen3 series). The old benchmarks and LLMs used in the paper make the results inconvicing."}, "questions": {"value": "Please see Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IqCfFYoOSM", "forum": "2TtDOr1aHF", "replyto": "2TtDOr1aHF", "signatures": ["ICLR.cc/2026/Conference/Submission8502/Reviewer_p3C1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8502/Reviewer_p3C1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8502/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760593682843, "cdate": 1760593682843, "tmdate": 1762920373540, "mdate": 1762920373540, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ParamAgent, a framework that coordinates multiple agents for reasoning tasks such as mathematics, programming, and multi-hop question answering. Specifically, the framework involves a main reasoning agent, an LLM that provides reflections, and another LLM that performs question decomposition for multi-hop QA. Empirical results suggest that ParamAgent outperforms both prompting-based and retrieval-based reflection methods, as well as a model-based reflection variant used as an ablation.\n\nMy concerns are twofold:\n\n1. Limited technical novelty.\n ParamAgent appears to be an ensemble of existing ideas rather than a conceptually new framework. It builds upon well-known paradigms such as multi-agent collaboration [1], reflexion [2], and question decomposition [3,4]. From the presentation, the authors seem to emphasize the parameterization of external reflection memory as their main contribution (hence the name ParamAgent). However, according to Algorithm 1, the method still relies on self-reflection and external memory to store the self-generated reflections and uses a retriever to query relevant ones. This design choice raises questions about the true motivation and distinctiveness of the work. The authors criticize prior self-reflection methods for their lack of population-level insights and retrieval-based methods for shallow interaction, yet ParamAgent itself remains heavily dependent on self-reflection and retrieval. Moreover, removing these components causes a notable drop in performance (as shown by the comparison between ParamAgent and the model-based variant). Taken together, the technical contribution seems incremental.\n\n\n2. Weak empirical justification.\n The experimental setup does not convincingly demonstrate the practical usefulness of ParamAgent. The base models used in the experiments are considerably weaker than current state-of-the-art systems. In practice, users are more likely to employ stronger open-source models such as Qwen3 or DeepSeek-r1. Under such circumstances, the relevance of the reported improvements is unclear. The comparison with Reflexion may also be unfair, since that method was primarily verified with large-scale closed-source LMs. Finally, it would be informative to include a simpler baseline—for example, removing Line 5 from Algorithm 1—to clarify whether ParamAgent offers substantial benefits over minimal modifications to the workflow.\n\n[1] Qingyu Wu et al., AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation\n\n[2] Noah Shinn et al., Reflexion: Language Agents with Verbal Reinforcement Learning\n\n[3] Danny Zhou et al., Least-to-Most Prompting Enables Complex Reasoning in Large Language Models\n\n[4] Jian Guan et al., AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback"}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. A multi-agent system for reasoning\n2. the system is verified with multiple types of reasoning tasks"}, "weaknesses": {"value": "see my comments in Summary"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tz960c6dXC", "forum": "2TtDOr1aHF", "replyto": "2TtDOr1aHF", "signatures": ["ICLR.cc/2026/Conference/Submission8502/Reviewer_zuPE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8502/Reviewer_zuPE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8502/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761496752942, "cdate": 1761496752942, "tmdate": 1762920373060, "mdate": 1762920373060, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses two key limitations of existing Large Language Model (LLM)-based agent frameworks: their confinement to per-instance reasoning (overlooking cross-task transferable patterns) and reliance on nonparametric external memory (capturing only shallow cross-instance interactions). To solve these issues, the authors propose ParamAgent, a language agent framework that integrates a domain-adaptive parametric module (M*) to internalize cross-sample knowledge into model parameters."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tParamAgent addresses critical gaps in existing agents by using parametric memory to internalize deep cross-sample regularities—avoiding the shallowness of nonparametric memory (e.g., retrieval logs) and the inefficiency of per-instance reasoning.\n2.\tThe modular design of  M_r and M_p enables customization for distinct tasks (programming/math vs. multi-hop QA), and the framework works with diverse base LLMs (from 1.5B to 70B scales), enhancing its practical applicability.\n3.\tRigorous Experimental Design: Evaluations cover three distinct, challenging tasks with well-known benchmarks (HumanEval, MATH, HotpotQA) and multiple base models, ensuring generalizability. Ablation studies (e.g., reflection format, iteration count) and extended tests with 70B-scale LLMs provide deep insights into the framework’s behavior."}, "weaknesses": {"value": "1. The authors should have clearly explained how M* works, as this is the core of the paper. However, it is placed in the appendix algorithm-3 section. Besides the algorithm, there should be a framework to illustrate how the proposed method works.\n\n2. The paper relies on synthetic data generated by GPT-4o-mini to train M*, but provides insufficient details on: Whether the framework’s performance is sensitive to the size or diversity of the synthetic dataset (e.g., would smaller datasets degrade M* effectiveness?).\n\n3. The paper claims “distribution mismatch” and “general capability degradation” of fine-tuning the base LLM, does this occurs during fine-tuning the M*?\n\n4. What’s the difference between the paramagent and multi-agent?"}, "questions": {"value": "The same as weaknesses:\n\n\n1. The authors should have clearly explained how M* works, as this is the core of the paper. However, it is placed in the appendix algorithm-3 section. Besides the algorithm, there should be a framework to illustrate how the proposed method works.\n\n2. The paper relies on synthetic data generated by GPT-4o-mini to train M*, but provides insufficient details on: Whether the framework’s performance is sensitive to the size or diversity of the synthetic dataset (e.g., would smaller datasets degrade M* effectiveness?).\n\n3. The paper claims “distribution mismatch” and “general capability degradation” of fine-tuning the base LLM, does this occurs during fine-tuning the M*?\n\n4. What’s the difference between the paramagent and multi-agent?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vOY8eV06EV", "forum": "2TtDOr1aHF", "replyto": "2TtDOr1aHF", "signatures": ["ICLR.cc/2026/Conference/Submission8502/Reviewer_2AZY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8502/Reviewer_2AZY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8502/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831059625, "cdate": 1761831059625, "tmdate": 1762920372754, "mdate": 1762920372754, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents  new agentic framework called ParamAgent, where reflections for the task at hand are produced by a fine-tuned model along with self-reflections. Main goal of the paper is to gather global signals for a problem at hand with reflections from fine-tuned ParamAgent. Paper presents results on programming, math and multi-hop QA datasets with the proposed approach and show significant gains on all three tasks to show the effectiveness of the approach.  ParamAgent has two different forms parametric knowledge: 1) is global reflection useful for programming and reasoning tasks 2) semantic decomposition useful for QA tasks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Paper is very well written and easy to follow. \n2. Thorough experimentation to show the effectiveness of the proposed approach on three different types of benchmarks."}, "weaknesses": {"value": "Model context slightly increases in all cases with more tokens provided across tasks. \nNice to have some experiments where multi-turn conversations are present, and how this works in those contexts?"}, "questions": {"value": "1. When you use model based reflection, do you retain the reflections at each step or is it similar to ParamAgent case where its only appended to the current turn? if its former then how does it fare if you use it only for current turn?\n2. Most of these datasets are single query followed by models reasoning to arrive at the answer, how does this framework fare in cases of conversational or multi-turn interactions with the model, like Agentic use cases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2sKg1HxKZO", "forum": "2TtDOr1aHF", "replyto": "2TtDOr1aHF", "signatures": ["ICLR.cc/2026/Conference/Submission8502/Reviewer_QdAz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8502/Reviewer_QdAz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8502/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931466187, "cdate": 1761931466187, "tmdate": 1762920372402, "mdate": 1762920372402, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}