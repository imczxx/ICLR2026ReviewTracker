{"id": "B41gsMOD26", "number": 2400, "cdate": 1757072859485, "mdate": 1763704757609, "content": {"title": "From Prediction to Perfection: Introducing Refinement to Autoregressive Image Generation", "abstract": "Autoregressive (AR) models have emerged as a powerful framework for image generation, yet they remain bound by a fundamental limitation: once a prediction is made, it cannot be revised. Each step marches forward in a strict left-to-right sequence, causing small errors to accumulate and compromise the final image. In this work, we reimagine this process with TensorAR, a decoder-only AR model that shifts from predicting discrete tokens to predicting overlapping tensor windows. This simple change transforms image synthesis into a process of next-tensor prediction, enabling the model to refine earlier outputs while preserving the causal structure that defines autoregression. To guard against information leakage during training, we introduce a discrete tensor noising mechanism inspired by discrete diffusion theory, which injects categorical noise into input tensors. TensorAR is designed to be plug-and-play: unlike masked AR methods, it requires no architectural modifications, and unlike autoregressive diffusion, it preserves the familiar AR training paradigm. We evaluate TensorAR across both class-to-image and text-to-image tasks, showing consistent gains in generation quality and instruction-following ability, while achieving a superior balance between quality and latency. In doing so, TensorAR offers a new path forward for autoregressive generation---one where predictions are not just produced, but continually refined.", "tldr": "", "keywords": ["Auto-Regressive Image Generation", "Discrete Diffusion"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3d9261827db1d25d4c63767b1ba441605c6a8255.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this work, the authors present TensorAR, an improvement over standard AR vision generative models. Unlike standard AR where one token is generated at a time, TensorAR predicts overlapping tensor windows. This allows correction of predicted tokens in inference. The authors also proposed noise mechanism to avoid information leakage in training. Empirical results on class-conditioned image generation and text-to-image generation show that TensorAR tuning on AR models improve performance while adding relatively small computation overhead."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The motivation to allow correction in AR image generation is valid and effective in improving generative models. \n2. TensorAR is easy to implement and a plug-and-play module for standard AR models. \n3. Empirical results demonstrate effectiveness of TensorAR on most benchmarks."}, "weaknesses": {"value": "1. In abstract, the authors mention TensorAR to predict overlapping tensor windows. However, the definition of the tensor window is vague. Adding explanation to clarify this can help audience better understand the work. \n2. How is w_j in Eq.5 defined in training?\n3. In Table 2, are numbers of the baselines (ie, Open-MAGVIT2 and LlamaGEN) evaluated with or without finetuning? It would help better illustrate the improvement of TensorAR if compared with baselines that are finetuned for same iterations but with standard AR strategy. \n4. Do authors have quantitative measure of additional computational overhead (eg, FLOPs) with TensorAR compared to standard AR models (ie, Open-MAGVIT2 and LlamaGEN)? \n5. Do authors have quantitative measures of the portion of tokens that are flipped in inference? I'm curious whether the improvement roots from actually flipping the prediction or the additional information in each step. \n6. In Table 5a, the column names of IS and FID seem to be wrong."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "56fDFSoIOQ", "forum": "B41gsMOD26", "replyto": "B41gsMOD26", "signatures": ["ICLR.cc/2026/Conference/Submission2400/Reviewer_JNGB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2400/Reviewer_JNGB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2400/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760918704610, "cdate": 1760918704610, "tmdate": 1762916220596, "mdate": 1762916220596, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces an enhanced paradigm for autoregressive image modeling, where instead of generating a single token at each step, the model is trained to produce multiple tokens in a sliding window manner. As a result, each token is generated multiple times across steps, allowing for iterative refinement. However, because some target output tokens are presented in the input, the model may learn to simply copy inputs to outputs. To mitigate this shortcut, the authors propose adding noise to the input tokens. Experiments demonstrate that applying the proposed method to LlamaGEN and Open-MAGVIT2 leads to improved image generation quality on ImageNet."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* The paper is well-written.\n\n* The proposed method is simple and easy to implement. It can be plugged into most of the existing image AR models.\n\n* The paper demonstrates the effectiveness of the method across multiple image AR models and multiple tasks (class-conditioned generation and text-to-image generation)."}, "weaknesses": {"value": "* The paper contains many typos, though they are minor and should be easy to fix."}, "questions": {"value": "I reviewed this paper in a previous venue. This version has addressed most of my earlier concerns, particularly regarding the text-to-image generation experiments and the improved balance between generation quality and latency. Therefore, I continue to support the paper and keep recommending a positive score. Below, I list my new questions for this round of review.\n\n* There are numerous citation-related typos throughout the paper. For example:\n    * Missing spaces before citations, e.g., \"frameworks(Pang et al., 2024\" (line 36), \"standard AR models(Pang et al., 2024\" (line 42)\n    * Incorrect citation formatting — \\citep should be used instead of \\citet in many cases, e.g., \"multimodal integrationWu et al. (2024); Team (2024).\" (line 40), \"Discrete diffusion models Sohl-Dickstein et al. (2015)\" (line 164), \"existing studies Zheng et al. (2023)\" (line 169).\n\n* One limitation of auto-regressive models is their slow sampling speed. A promising direction to mitigate this issue is to distill pre-trained auto-regressive models into one-step samplers using Distilled Decoding (https://arxiv.org/abs/2412.17153, https://arxiv.org/abs/2510.21003), which aims to retain the high generation quality of AR models while achieving fast sampling. (For the second paper, I understand that the authors are not expected to be aware of or discuss it given its very recent publication; I include it here only for completeness.) It would be interesting to discuss whether TensorAR is compatible with such an approach (i.e., applying distilled decoding on TensorAR models).\n\n\n* What is the rationale behind using \"1/(k/2)\" in the exponent of the exponential schedule? In general, any decreasing function of k could be applied in the exponent, so it would be helpful to clarify why this particular form was chosen.\n\n* Compared to the previous submission, the performance of TensorAR on LlamaGEN models has improved substantially, which is great to see. I notice that one difference is that the TensorAR models were made larger (according to Table 2). I have a few follow-up questions:\n(1) Which parameters were modified to increase the model size?\n(2) Was this the only change, or were there other factors contributing to the improved performance?\n\n* In the previous version, experiments were also conducted on RAR models (which was a valuable addition), but they appear to have been removed in the current version. Could the authors clarify the reasoning behind this decision?\n\n* Figure 4 does not appear to match the results reported in Table 2. Specifically, the smallest models in Table 2 have FIDs of 5.46 (base model) and 4.71 (TensorAR), whereas the highest points in Figure 4 show FIDs around 3.5–4 (base model) and 3–3.5 (TensorAR). My assumption is that different models were selected for Table 2 and Figure 4. It would be helpful if the authors could clarify this discrepancy.\n\n* If I understand correctly, all TensorAR models in the experiments are fine-tuned from pretrained AR models. Would TensorAR still perform well when trained from scratch, or does it rely on a well-trained base model to achieve good performance? It would be great to include some discussion on this point, though additional experiments are not necessary.\n\n* In Table 5(a), the column headers for IS and FID appear to be reversed.\n\n* In Table 6, it would be helpful to include the results of the base models to make it easier to support the statement that \"all four schedules yield substantial gains over the base configuration\" (line 420).\n\n* Line 436 claims that \"d = 2 achieves the lowest Fr´echet Inception Distance (FID)\". However, in Figure 5(b), d=1 has the best FID.\n\n* Line 53: \"AR\" should be \"VAR\"\n\n* I am a bit confused about the title of Section 2 — is “TensorAR-T2I” a typo? Should it instead be “TensorAR”?\n\n* Line 224: it would be better to change \"(x_i,...,x_{i+k-1}^ * )\" to \"(x_i, x_{i+1}^ * , ..., x_{i+k-1}^ * )\" (i.e., adding \"x_{i+1}^*\"). Otherwise, it is unclear if \" * \" should be applied on x_{i+1}, ..., x_{i+k-1}.\n\n* Eq 4: The index of x (2, ... k-1) is incorrect, given that Line 228 discusses \"x_t, ..., x_{t+k-1}\"\n\n* In Eq 5, the function q has j as a condition. However, in Eq. 4, this condition is missing. I think it would be more rigorous to have this condition.\n\n* Eq. 5: It would be more accurate to place the summation before the expectation, since the variables involved in the expectation (i.e., those in the subscript of E) depend on the definitions of i and j.\n\n* Line 262 states that \"when k equals the total number of image patches T, TensorAR becomes equivalent to a discrete variant of a diffusion process.\" This is not exactly accurate, since the denoising order differs: in TensorAR, the clean tokens are revealed from left to right, whereas in discrete diffusion, the order can be random."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jFaf85n0ZP", "forum": "B41gsMOD26", "replyto": "B41gsMOD26", "signatures": ["ICLR.cc/2026/Conference/Submission2400/Reviewer_nvDe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2400/Reviewer_nvDe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2400/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761714681867, "cdate": 1761714681867, "tmdate": 1762916219988, "mdate": 1762916219988, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes TensorAR, a novel autoregressive method for image generation that introduces a refinement mechanism by shifting from next-token to next-tensor prediction. TensorAR predicts overlapping tensor windows, allowing later predictions to revise earlier ones. The method is designed as a plug-and-play extension to existing AR models. Experiments on class-conditional and text-to-image generation show consistent improvements in FID."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is well-written and provides a thorough and accurate explanation of the main methods.\n2. The core idea of \"next-tensor prediction\" is simple yet powerful. It provide a new approach to bridge the gap between autoregressive generation and refinement-based paradigms.\n3. TensorAR requires no modification to the base AR architecture or training objective, making it highly practical and easy to integrate with existing models.\n4. The author conducted experimental verifications on various autoregressive models, including Open-MAGVIT2, LlamaGen and Janus-Pro."}, "weaknesses": {"value": "1. Lack of a stronger explanation or demonstration of refinement: The paper claims that tokens are \"refined\" over multiple steps, but it does not provide direct evidence  that the model actually revises its predictions meaningfully during refinement steps, rather than simply generating forward. TensorAR improves the T2I generation effect as shown in Figure 7. The baseline fails on \"a person stands with another man\" but TensorAR succeeds—is this due to refinement of earlier tokens, or improvement in the ability to follow the text after additional fine-tuning?\n2. The visualization results for the T2I generation are missing: The results of LlamaGen+TensorAR presented by the author in Table 1 (0.61) far exceed those of LlamaGen itself (0.31). The improvement in its visualization results should be more significant than that of Janus-Pro-7B, but no comparison of the visualization results are given.\n3. Incorrect interpretation of the results of the ablation experiment: The author explains Table 5b in section 3.3 by saying: \"... d = 2 achieves the lowest\nFr´echet Inception Distance (FID) ...\", But this does not match the result given in the table.\n4. The names of the indicators in the table are misaligned. In Table 5a, \"IS\" and \"FID\" are written in reverse."}, "questions": {"value": "1. Have you ever tried a larger k value? To what extent can FID be optimized when k approaches the sequence length.\n2. Can you explain that why is the exponential noise schedule superior?  Is there an intuitive or theoretical justification, or is it purely empirical?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Vg6lCt6Abm", "forum": "B41gsMOD26", "replyto": "B41gsMOD26", "signatures": ["ICLR.cc/2026/Conference/Submission2400/Reviewer_ojZ8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2400/Reviewer_ojZ8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2400/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761908792288, "cdate": 1761908792288, "tmdate": 1762916219784, "mdate": 1762916219784, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces TensorAR, a plug-and-play autoregressive image generation framework that replaces traditional next-token prediction with next-tensor prediction, enabling iterative refinement of previously generated content while preserving causality. By incorporating a discrete tensor noising mechanism inspired by diffusion theory and lightweight input/output modules, TensorAR consistently improves generation quality and instruction-following ability across class-conditional and text-to-image tasks without altering the base architecture or training paradigm."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "(1) The overall paradigm is very interesting, which naturally combines the traditional AR image generation with the diffusion model.\n(2) The method is effective. Extensive experiments over Open-MAGVIT and LlamaGEN have proven its effectiveness."}, "weaknesses": {"value": "1. The illustration in Fig. 1 is not intuitive.\n2. The llamagen baselins is a little weak. AS I know, SimpleAR (https://github.com/wdrink/SimpleAR) is a stronger baseline. The experiments could be improved by utilizing SoTA baselines."}, "questions": {"value": "1. Fig. 7 shows the visual comparison between Janus-Pro-7B and Janus-Pro-7B+TensorAR. The visualization is nice. As I know, Janus-Pro is an understanding and generation unified model. Does Janus-Pro + TensorAR support unified understanding and generation? If yes, how about the generation performance?\n2. The name TensorAR may not directly reflect the core methodology. I think \"GroupAR\" may be better aligned with the method."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "1SHbiaBe9P", "forum": "B41gsMOD26", "replyto": "B41gsMOD26", "signatures": ["ICLR.cc/2026/Conference/Submission2400/Reviewer_rrSZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2400/Reviewer_rrSZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2400/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762136202499, "cdate": 1762136202499, "tmdate": 1762916219618, "mdate": 1762916219618, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}