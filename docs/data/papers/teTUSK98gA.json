{"id": "teTUSK98gA", "number": 13097, "cdate": 1758213574937, "mdate": 1763100676558, "content": {"title": "Diffusion^2: Turning 3D Environments into Radio Freqneucny Heatmaps", "abstract": "Modeling radio frequency (RF) signal propagation is essential for understanding the environment as RF signals offer valuable insights beyond the capabilities of RGB cameras, which are limited by the visible light spectrum, lens coverage, and occlusions. It is also useful for supporting wireless diagnosis, deployment, and optimization. However, accurately predicting RF signals in complex environments remains challenging because of interactions with obstacles such as absorption and reflection. We introduce Diffusion^2, a diffusion-based approach that leverages 3D point clouds to model the propagation of RF signals across a wide range of frequencies, from Wi-Fi to millimeter waves. To effectively capture RF-related features from 3D data, we present the RF-3D Encoder, which encapsulates the complexities of 3D geometry along with signal-specific details. These features undergo multi-scale embedding to simulate the actual RF signal dissemination process. Our evaluation, based on synthetic and real-world measurements, demonstrates that Diffusion^2 accurately estimates the behavior of RF signals in various frequency bands and environmental conditions, with an error margin of just 1.9 dB and 27x faster than the existing methods, marking a significant advancement in the field. Refer to https://rfvision-project.github.io/ for more information.", "tldr": "Diffusion^2 turns 3D environments into RF heatmaps and videos with high accuracy and up to 27x faster inference than prior methods, using only minimal measurements.", "keywords": ["Wireless Networks", "Diffusion"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/e87afc6eca3836c327bbc1cb67151d9d4640a017.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Diffusion2 is a generative diffusion model that predicts high-fidelity RF heatmaps from 3D point clouds with only 15 pre-measurements, supporting Wi-Fi and mmWave bands. It introduces an RF-3D Encoder for multi-modal fusion and an RF-3D Pairing Block for conditioned denoising, enabling accurate multipath modeling and dynamic scene generation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+ The diffusion-based methodology provides a solid foundation for future multimodal unification. Its probabilistic denoising framework supports flexible conditioning on diverse inputs such as 3D geometry, 2D images, and RF signals, enabling seamless integration of additional modalities like audio, inertial, or environmental data to enhance holistic wireless scene understanding in 6G applications."}, "weaknesses": {"value": "- While Diffusion2 applies diffusion models to RF heatmap generation from sparse 3D points, its novelty is modest. The method mainly reuses standard DDPM/DDIM pipelines, latent diffusion encoding, and simple additive conditioning without introducing new RF-specific mechanisms. Its modules, such as the RF-3D Pairing Block and RF-3D Encoder, assemble existing components like MinkUNet, Swin Transformer, and Fourier embeddings, mirroring prior multi-modal diffusion works.\n\n\n- While the RF-3D Encoder presents an innovative fusion of multi-modal inputs, including 2D images, 3D geometry via MinkUNet, and RF signals through Fourier embeddings, its use of simple element-wise addition for feature fusion may fail to capture complex non-linear relationships among modalities. This simplification can cause misalignment or feature dilution in cluttered or heterogeneous environments. Although ablation results show that each modality improves accuracy, the lack of cross-modal attention or comparisons with more advanced fusion mechanisms leaves uncertainty about the model’s robustness and generalization in real-world scenarios such as lighting variations or occlusions.\n\n- The paper omits an essential baseline by not comparing with WRF-GS (Wen et al., 2024), which shares the same objective as Diffusion2 and NeRF2. If Diffusion2 can be evaluated against NeRF2, it should likewise be compared with WRF-GS, which performs comparable tasks at a significantly lower runtime. Without this comparison, it is difficult to assess whether Diffusion2 achieves comparable or superior efficiency and accuracy.\n\n\n\n- Its practicality is constrained by low output resolution and restrictive input requirements. The generated heatmaps with resolutions of 352×705 for images and 52×72 for videos are too coarse for dense receiver grids or detailed multipath analysis, which limits their value for high-precision 6G diagnostics. Data collection using smartphone-based LiDAR scans introduces variability caused by occlusions and lighting conditions. The fixed use of 15 pre-measured points also appears arbitrary, as performance is sensitive to this choice without adequate justification or analysis."}, "questions": {"value": "Please see the points raised in the Weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xjX1E61xnY", "forum": "teTUSK98gA", "replyto": "teTUSK98gA", "signatures": ["ICLR.cc/2026/Conference/Submission13097/Reviewer_QhzM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13097/Reviewer_QhzM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761774437599, "cdate": 1761774437599, "tmdate": 1762923828324, "mdate": 1762923828324, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "RAikqIO3sM", "forum": "teTUSK98gA", "replyto": "teTUSK98gA", "signatures": ["ICLR.cc/2026/Conference/Submission13097/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13097/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763100675391, "cdate": 1763100675391, "tmdate": 1763100675391, "mdate": 1763100675391, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Diffusion^2, a diffusion-based model that generates RF heatmaps from 3D point clouds. The key contribution is the RF-3D Encoder, which effectively integrates 3D geometry, 2D overview images, and RF signal features to condition the diffusion process. The method achieves high accuracy (1.9 dB error) and significant speedup (27×) compared to existing approaches, while requiring only minimal pre-measurements (15 points). The extension to video generation for dynamic environments further enhances its practical value."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "First to use diffusion models for RF heatmap generation from 3D point clouds. Strong empirical results with minimal measurements and fast inference.  \n\nBridges generative AI and wireless communication, enabling efficient and scalable RF modeling.  \n\nThe paper is well-organized and easy to follow."}, "weaknesses": {"value": "The use of a ray-tracing simulator (AutoMS) as ground truth may limit the validity of “accuracy” claims in real physical environments.  \n\nThe sensitivity of performance to the location of the 15 pre-measurement points is not thoroughly analyzed."}, "questions": {"value": "1. How sensitive is the model’s performance to the spatial distribution of the 15 pre-measurement points? Would poorly distributed points harm the results?\n﻿\n2. Since the ground truth is generated by a simulator, to what extent does the model capture true physics versus approximating the simulator’s behavior?\n﻿\n3. Does the model’s performance depend heavily on the pre-trained 3D segmentation model (MinkNet)? How does it generalize to unseen object categories?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "B0dIcNDfBV", "forum": "teTUSK98gA", "replyto": "teTUSK98gA", "signatures": ["ICLR.cc/2026/Conference/Submission13097/Reviewer_FByQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13097/Reviewer_FByQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901725881, "cdate": 1761901725881, "tmdate": 1762923823959, "mdate": 1762923823959, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- The paper proposes a novel approach to conditionally generate RF heatmaps (RSSI specifically) based on 3D point cloud information.\n- The crux of the proposed is leveraging a 2-stage diffusion model (akin to Stable Diffusion and DiffuionDepth).\n- A specific novelty is use of 3D scene-specific data to provide conditional guidance during generation using a \"RD-3D Encoder\" that constructs a 3D-based feature map (using some 3D knowledge of the scene e.g., mesh reconstruction) and injects this at each step of the denoising process.\n- The approach is evaluated both on synthetic (AutoMS) and real-world measurement data.\n- Evaluation on a range of frequencies, static and dynamic scenes, synthetic and real data shows promising improvements (esp. in data-limited regimes) when compared to relevant baselines (e.g., NeRF^2)"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The \"hybrid\" nature of the approach is well-motivated and practical i.e., using both 3D scene priors (much like conventional ray tracers) and data-driven learning (in this case with diffusion models)\n2. The manner in which 3D priors are leveraged is compelling -- the colors and visual features are used (which provide a good proxy to underlying RF material properties). Ablations also indicate these provide meaningful gains.\n3. The evaluation is comprehensive and addresses a range of scenarios (e.g., multi-frequency, dynamic scenes, limited data)"}, "weaknesses": {"value": "**1. RF signal features**\n- It appears that only the location of the tx/rx is considered (L265-269). However, RF propagation is highly-directional (esp. in mmWave scenarios). It is unclear how the approach handles or generalizes to these nuances (esp. when tx and rx antenna boresight direction is not aligned)\n- Although this term is supposed to capture RF features, it also appears to include mesh. It is not justified why duplicating (or perhaps even providing richer information compared to 3D point clouds) is necessary. Importantly, this term appears quite critical and might overshadow the 2D/3D features. It would be interesting to re-run the ablation (Table 1) in reverse order i.e., evaluating marginal gains of 2D/3D features over the RF signal term (which already contains 3D information).\n\n**2. Training and Evaluation data - details unclear**\n- The training and evaluation data details is largely unclear, and this is an obstacle to better understanding the evaluation setting.\n- Specifically, L315-317 mentions \"55k samples from diverse 3D environments\". Many details are unclear e.g., whether dataset is publicly available, are they indoor/outdoor, number of samples per environment.\n- Given that the data underpins the paper's good empirical results, I believe it is crucial to elaborate on the data.\n- Furthermore, L321-323 also mentions that the ground-truth data is derived from \"AutoMS\" approach. This appears to imply that the proposed approach is evaluated on predictions of another model, and the accuracy is highly dependent on how accurate AutoMS is.\n\n**3. Relies on high-quality training data and generalization**\n- L317 remarks split of the data: 80-20% train-test split. It is unclear how the split is done (is it IID?)\n- Importantly, is part of the model evaluation performed in scenes and measurements that appeared during training? In which case, this would undermine the claims around using \"15 points\"."}, "questions": {"value": "1. Does the approach account for directional antenna?\n2. Why does the RF signal feature term contain the mesh?\n3. Please elaborate on the details of training and test data.\n4. \"15 training datapoints\": how are these sampled? How is this different from the 80% of the 55k sample dataset?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iYZ28uMDET", "forum": "teTUSK98gA", "replyto": "teTUSK98gA", "signatures": ["ICLR.cc/2026/Conference/Submission13097/Reviewer_m8tc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13097/Reviewer_m8tc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994337830, "cdate": 1761994337830, "tmdate": 1762923823196, "mdate": 1762923823196, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "[Will fill in 12h if SAC/PC reviews Non-Anonymous issue and decides to move forward with reviewing.]"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "[Will fill in 12h if SAC/PC reviews Non-Anonymous issue and decides to move forward with reviewing.]"}, "weaknesses": {"value": "[Will fill in 12h if SAC/PC reviews Non-Anonymous issue and decides to move forward with reviewing.]"}, "questions": {"value": "[Will fill in 12h if SAC/PC reviews Non-Anonymous issue and decides to move forward with reviewing.]"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JLmT6vpG6P", "forum": "teTUSK98gA", "replyto": "teTUSK98gA", "signatures": ["ICLR.cc/2026/Conference/Submission13097/Reviewer_euLv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13097/Reviewer_euLv"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13097/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997282862, "cdate": 1761997282862, "tmdate": 1762923822835, "mdate": 1762923822835, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}