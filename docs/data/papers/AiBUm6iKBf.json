{"id": "AiBUm6iKBf", "number": 1705, "cdate": 1756909586211, "mdate": 1759898193698, "content": {"title": "SERUM: Simple, Efficient, Robust, and Unifying Marking for Diffusion-based Image Generation", "abstract": "We propose SERUM: an intriguingly simple yet highly effective method for marking images generated by diffusion models (DMs). We only add a unique watermark noise to the initial diffusion generation noise and train a lightweight detector to identify watermarked images, simplifying and unifying the strengths of prior approaches. SERUM provides robustness against any image augmentations or watermark removal attacks and is extremely efficient, all while maintaining negligible impact on image quality. In contrast to prior approaches, which are often only resilient to limited perturbations and incur significant training, injection, and detection costs, our SERUM achieves remarkable performance, with the highest true positive rate (TPR) at a 1% false positive rate (FPR) in most scenarios, along with fast injection and detection and low detector training overhead. Its decoupled architecture also seamlessly supports multiple users by embedding individualized watermarks with little interference between the marks. Overall, our method provides a practical solution to mark outputs from DMs and to reliably distinguish generated from natural images.", "tldr": "We propose a simple yet highly effective method for marking diffusion-based image generation by adding a unique watermark noise to the initial diffusion noise and training a lightweight detector to reliably identify watermarked images.", "keywords": ["watermarks", "diffusion models", "marking", "computer vision", "image generation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6fd936d956f9865ab648435059f90797b3a0af27.pdf", "supplementary_material": "/attachment/7dd27a2eb7f987018b8d992074b9b7cfd19c80eb.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces SERUM, a watermarking method for diffusion-based image generation models that adds a normalized Gaussian watermark noise to the initial diffusion noise and trains a lightweight external detector to identify watermarked images directly, avoiding costly diffusion inversion. Key contributions include high robustness to perturbations and removal attacks, with minimal impact on image quality, and support for multi-user scenarios through individualized noise patterns and detectors. Evaluated on Stable Diffusion variants, SERUM outperforms baselines like Stable Signature, RingID, and GaussMarker in TPR@1%FPR across various perturbation experiments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Good Paper Writing: with well-structured sections, a detailed method description. Also, the authors provide a good theoretical argument in the Appendix.\n\n2. Good Method Robustness: The method's primary strength is its exceptional performance. SERUM consistently outperforms strong baselines across all tested models (i.e., SD 1.4, 2.0, 2.1). It shows remarkable resilience to advanced watermark removal attacks (as shown in Table 2).\n\n3. High Efficiency in Watermark Processing: By eliminating the need for DDIM inversion, and using a simple forward pass through the encoder and a small CNN, SERUM's detection is significantly faster than some classic methods. Besides, the simple noise addition strategy also brings a near-zero-cost injection process, which provides insights for future research and becomes a potential option for real-world applications."}, "weaknesses": {"value": "1.  Limited Ablation Studies: The method's strong robustness stems from both its architectural design (i.e., using initial noise injection, latent space detection) and its sophisticated training strategy, which includes dynamic augmentations sampled via Prioritized Experience Replay and a multi-component loss function. However, the paper provides limited ablation studies to disentangle these effects. It is unclear how much of the performance gain is attributable to the core architectural ``trade-off\" versus the advanced training techniques. Adding ablations that isolate the impact of the PER sampler and the specific loss terms (e.g., the temperature) would provide a clearer picture of the true sources of the method's advantage.\n\n2.  Unclear Efficiency in Multi-User Training Scenarios: The paper claims support for multi-user scenarios by training a separate detector $D_i$ for each user $i$. While the performance and accuracy for this setup are reported (refer to Figure 3), the time consumption is conspicuously absent. From my understanding, the proposed detection method scales linearly, $O(k)$, with the number of users $k$ being checked, as each detector must be run. This computational cost is not reflected in the main runtime analysis and may not meet expectations for a \"highly scalable\" or \"efficient\" system in practice, especially one with a large user base (p.s., if it takes 9.48 hrs for each user training, it can be even more expensive than the existing methods).\n\n3.  Limited Scope of Experimental Validation: The paper's convincingness is constrained by two factors: (a) Limited Baselines (Optional, since the authors mentioned that the selected methods are the existing SOTAs, but 3 baselines are still limited): The experimental comparison is restricted to only three baseline methods. While these are relevant, a more comprehensive comparison against a wider array of recent watermarking techniques would be necessary to substantiate the claim of state-of-the-art performance fully. (b) Insufficient Focus on Advanced Attacks: The paper dedicates significant evaluation to robustness against standard image perturbations (Table 1). However, robustness to such traditional edits (e.g., compression, noise, blur) is largely a solved problem for modern, DL-based watermarks. The true challenge lies in resilience to advanced, generative-AI-based attacks. The paper's evaluation on this front is a good start, but it is not comprehensive. To truly prove its robustness, the method should be tested against more diverse and practical generative editing attacks, such as regional editing, diffusion-based inpainting, object composition, and even more challenging topics of image-to-video transformations (optional, I understand it is highly difficult), and then demonstrate successful watermark retrieval."}, "questions": {"value": "To better indicate the sources of robustness, could the authors provide an ablation study on the impact of the Prioritized Experience Replay (PER) sampler? This would help distinguish architectural gains from training strategy gains.\n\nCan the authors comment on the method's portability and generality to newer architectural paradigms? The field of diffusion models is rapidly shifting from UNet-based backbones to Diffusion Transformer (DiT) architectures. Given that the proposed method injects noise at the initial stage and detects it in the latent space, how readily can SERUM be adapted to these new DiT-based frameworks, and what challenges are anticipated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pGi9Zi9xZz", "forum": "AiBUm6iKBf", "replyto": "AiBUm6iKBf", "signatures": ["ICLR.cc/2026/Conference/Submission1705/Reviewer_cDi8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1705/Reviewer_cDi8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761067970869, "cdate": 1761067970869, "tmdate": 1762915861975, "mdate": 1762915861975, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose SERUM, a watermarking method for diffusion models that injects the watermark into the model’s initial noise and trains a lightweight detector to extract it."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Method-wise, the pipeline is simple in design and the description is clear and easy to understand. Experiment-wise, the authors conduct experiments on SD1.4, SD2.0, and SD2.1, with a fairly comprehensive amount of evaluation."}, "weaknesses": {"value": "1. Robustness to Crop and Scale remains an issue. The choice to retain 75% in evaluation is relatively weak. I think it quite common to retain 50% of image in life. What will the performance be like if under stronger Crop and Scale attack?\n2. The metric TPR at 1% FPR is weak. Scores are all close to 100%, which makes it hard to distinguish performance differences between methods. Although prior work used this evaluation metric, I still recommend controlling FPR at a much smaller range, for example 10e-6.\n3. In the multi-user setting, SERUM needs to train one detector per user. Considering that training a detector requires 40,000 images (the authors mention 40,000 prompts, and I assume each prompt is used at least once), this will introduce significant overhead and makes the multi-user scenario impractical. In Section 4.5 the authors test only 10 users, which indirectly demonstrates this point. I think its an important weakness needs to be addressed."}, "questions": {"value": "1. Why design an AugSampler and also precompute the perturbation? Is it because of augmentations like JPEG compression? I did not see which augmentations were precomputed in the paper and I think it needs to be explained.\n2. Can you use a stronger Crop and Scale attack setting like retain 50% or 25%? How does it compare to Stable Sig under such conditions?\n3. You design $A \\sim \\mathcal{N}(0, I)$ so that the watermark does not change the Gaussian nature of the initial noise. However, Table 5 still shows a drop in FID. Could you explain whether the FID drop is due to reduced diversity in the generated results after adding the watermark?\n4. In real-world scenarios, a platform can easily have thousands or even tens of thousands of users. Can SERUM handle 10,000 user setting?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "tIjQ3Favzj", "forum": "AiBUm6iKBf", "replyto": "AiBUm6iKBf", "signatures": ["ICLR.cc/2026/Conference/Submission1705/Reviewer_Emwh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1705/Reviewer_Emwh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761483496578, "cdate": 1761483496578, "tmdate": 1762915861734, "mdate": 1762915861734, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of marking images generated by diffusion models to distinguish them from real images and ensure content traceability. SERUM embeds a unique Gaussian watermark in the initial noise of the diffusion process and trains an external detector to identify watermarked images. Evaluated on multiple Stable Diffusion versions and against existing methods, SERUM shows strong robustness to image perturbations and removal attacks, preserves watermark detectability after model fine-tuning, and has minimal impact on image quality."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**Originality:**\n\nThis work introduces a new approach to diffusion model watermarking by injecting a unique Gaussian watermark into the initial noise and employing a lightweight external detector. The technique is distinct in its simplicity, enabling scalable multi-user attribution without modifying the underlying generative model.\n\n**Quality:**\n\nThe methodology is supported by comprehensive experiments on multiple Stable Diffusion models, benchmarking detection robustness against diverse perturbations and removal attacks. The empirical results are thorough and reproducible, substantiating the efficacy and efficiency of the proposed method.\n\n**Clarity:**\n\nThe paper is well organized, with clear exposition of problem motivation, methodological details, and experimental results. Figures and comparative analyses further enhance the transparency and accessibility of the work.\n\n**Significance:**\n\nSERUM addresses a challenge in generative AI: reliable attribution and provenance of synthetic images. Its robust, efficient, and scalable design substantially advances the practical enforcement of content identification and AI governance in contemporary applications."}, "weaknesses": {"value": "1. Although the detector is described as lightweight, performance scaling to much larger numbers of unique watermarks (multi-user setting) may face practical bottlenecks. The paper assesses up to 10 users. In a real-world application, it will be hundreds and even thousands of users. I suggest that the author should invest further in a large-scale application if possible. \n2. The work primarily compares SERUM to recent DM watermarking approaches like Stable Signature, RingID, and GaussMarker, but post-processing and hybrid watermarking methods (e.g., non-diffusion-based or steganographic approaches) may offer complementary strengths. Including such baselines—even if weaker in some respects—could clarify SERUM’s advantages and limitations in broader practical contexts.\n3. Although architectural details and loss functions are provided, some choices (e.g., watermark noise hyperparameters, batch size, augmentation prioritization) could benefit from clearer justification or ablation. \n4. several section titles in the paper are overly long and verbose, detracting from professional presentation. For instance, Section 3 titled \"Our Screen Watermark Method for Diffusion Model\" could be concisely phrased as \"Screen Watermark Method.\" Similarly, Sections 4.2 and 4.3 use full sentences as titles, which appear unprofessional and lack clarity. More concise alternatives such as \"Robustness to Image Perturbations\" (for 4.2) and \"Robustness to Watermark Removal Attacks\" (for 4.3) would improve readability and presentation. Revising section titles throughout the manuscript to be clear and succinct is recommended to strengthen the overall professional quality and accessibility."}, "questions": {"value": "• Given that watermarking enables not just content detection but also tracking of model and user identities, what is the primary motivation for framing this work as a detection task rather than as a comprehensive provenance or attribution framework?\n\n• Based on the simplicity illustrated in Figure 1, can the authors elaborate on the specific technical challenges addressed by their approach? In what ways does the method go beyond the obvious, and what unique difficulties does it solve?\n\n• Have the authors compared SERUM to non-watermarking detection baselines? How does the method perform when only a simple classifier or traditional watermark is employed instead?\n\n• Does the paper’s contribution fundamentally change our understanding of the detection/provenance problem for AI-generated images, or is it an incremental improvement in watermarking as a technology?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MFQJCJwGcT", "forum": "AiBUm6iKBf", "replyto": "AiBUm6iKBf", "signatures": ["ICLR.cc/2026/Conference/Submission1705/Reviewer_fqMS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1705/Reviewer_fqMS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761703268699, "cdate": 1761703268699, "tmdate": 1762915861532, "mdate": 1762915861532, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "- This paper proposes a new watermarking framework for DMs that is simpler, more efficient and more robust than existing DM methods.\n- Watermarking: A fixed user specific pattern of Gaussian noise is combined (additively) with the initial random noise vector before the diffusion generation process begins. The authors also provide a theoretical guarantee of low KL divergence between the distributions of watermarked and non-watermarked noises due to watermark injection to explain the high output image fidelity using this method\n- Detection: A lightweight external detector, which is a CNN is trained to identify the signature of this watermark directly in the VAE latent space of the generated image. Therefore this avoids the need for expensive diffusion inversion for detection which is used in prior tuning free works\n- Results: \n   1. The method achieves SOTA robustness against a wide variety of image perturbations and advanced generative watermark removal attacks\n  2. The method is efficient - it has fast injection and detection times and low training overhead with a low impact on the perceptual quality of the generated images\n  3. The method is practical - the authors demonstrates the practical utility through its support for multi user scenarios\n  4. The method is shown to have a high degree of 'radioactivity' - the watermark remains detectable even in models that have been finetuned on watermarked data"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The main idea proposed in the paper is simple but effective. By decoupling the watermark embedding in the initial noise from the detection mechanism which is a separate and lightweight classifier, the method avoids the bottlenecks of prior works - DDIM inversion which is slow, and expensive finetuning\n- The authors have presented sufficient proof to validate better robustness of this method in Table 1 against 3 other DM based methods on all standard perturbations. In addition to the method achieving a high average TPR and low FPR across the 8 perturbations, it also shows consistently high performance across perturbations in comparison to the other methods that have failures on certain transformations ex: RingID on Crop+Scale which falls to 5-6% TPR and Stable Signature on Gaussian Noise which falls to 48-52% TPR\n- The method shows superior performance against advanced removal attacks in Table 2 maintaining high TPRs against all baselines and its performance does not collapses under more aggressive attacks like Regen-30 unlike the other methods\n- The explanation of generalization in Appendix E and the empirical demonstration that the DDIM inversion process used by the other models actually amplifies the distortions caused by perturbations, making the watermark signal harder to recover is compelling. The method's inversion free, latent space detection is therefore more robust by design\n- The method is practical for real world deployment. Table 8 shows that SERUM's detection is orders of magnitude faster than inversion based methods ex: 2.5 min vs 117-140 min to check 5000 images. Watermark injection is 17 ms, and the total detector training time ~9 hrs, including data generation is a fraction of that required for model fine tuning in Stable Signature which is ~57 hours.\n- SERUM has a negligible impact on image quality, as confirmed by FID and CLIP scores in Table 4 that are very close to clean generation, and by qualitative examples in Figures 2 and 8"}, "weaknesses": {"value": "- Multi user support involves training a unique detector for each user's unique noise pattern. Figure 3 demonstrates that this approach works well for up to 10 users, but this does not guarantee its viability at a large scale. A system with millions of users would require managing millions of individual detector models. As the number of unique noise patterns grows, the probability of 'collisions' where a pattern coincidentally produces a signature detectable by another user's detector may increase. The paper does not provide an analysis of cross detection scores to quantify this risk.\n- The evaluation of radioactivity results is confined to a full model fine-tuning scenario. It does not investigate the watermark's persistence under more modern and widely used PEFT methods, such as LoRA."}, "questions": {"value": "- Can the authors comment on the theoretical/empirical limits of one detector per user approach? Have they analyzed the cross detection score distributions to assess the probability of false user identification as the number of users grows into the thousands or millions? \n- Can the authors explain on whether the SERUM watermark would be expected to survive parameter-efficient finetuning methods like LoRA where the majority of the base model's weights remain frozen?\n- The paper mentions using an augmentation sampler inspired by Prioritized Experience Replay to focus training on more difficult transformations (Appendix A). Can the authors provide an ablation study/further analysis on the impact of this adaptive sampling strategy? How much does it contribute to the final robustness metrics compared to a simpler uniform sampling of augmentations during detector training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "68grvgJcMI", "forum": "AiBUm6iKBf", "replyto": "AiBUm6iKBf", "signatures": ["ICLR.cc/2026/Conference/Submission1705/Reviewer_9VoN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1705/Reviewer_9VoN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1705/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994652791, "cdate": 1761994652791, "tmdate": 1762915861251, "mdate": 1762915861251, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}