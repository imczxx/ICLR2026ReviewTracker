{"id": "bFxBBUFm18", "number": 22766, "cdate": 1758335216632, "mdate": 1759896847828, "content": {"title": "AppoloConv: Multi-Scale Frequency-Aware Convolutions for Robust Multivariate Time Series Forecasting", "abstract": "Time series forecasting requires models that balance expressive power with computational efficiency. While convolutional neural networks offer efficient temporal modeling, their inherent translation invariance often misaligns with the recency bias and non-stationary dynamics present in real-world time series. We propose ApolloConv, a convolutional architecture that enhances temporal inductive bias through integrated time–frequency modeling. ApolloConv incorporates (i) a multi-scale embedding stem that captures local-to-global patterns while emphasizing recent context, (ii) a lightweight spectral gating mechanism that modulates periodic components in the frequency domain while preserving phase coherence, and (iii) an adaptive dilated convolution block that prioritizes recent time steps through logarithmically scaled receptive fields. Together, these components enable effective handling of multi-scale seasonality, trend structures, and cross-variable dependencies with near-linear complexity. Extensive experiments on benchmark datasets demonstrate that ApolloConv consistently outperforms state-of-the-art CNN-based models such as TimesNet, TVNet, and ModernTCN across both short- and long-term forecasting settings, while matching or exceeding Transformer-based counterparts with significantly lower computational cost. ApolloConv provides a robust and efficient convolutional alternative for practical time series forecasting.", "tldr": "", "keywords": ["Time Series Forecasting", "Convolutional Neural Networks", "Adaptive Receptive Fields"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3103fae7b6f7d496d877c534116a49676a345660.pdf", "supplementary_material": "/attachment/28ecdff72fa63a03fa48d5316111f4c79cb0bc54.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes ApolloConv, a CNN-based model for robust multivariate time series forecasting. It addresses key limitations of traditional convolutional models in time series forecasting, including translation invariance and noise sensitivity, through three core components: a multi-scale embedding stem that captures local-to-global temporal patterns, a spectral gating mechanism that filters periodic noise in the frequency domain, and an adaptive dilated convolution block that models long-term dependencies efficiently. Experiments show that ApolloConv achieves state-of-the-art performance with lower complexity than prior CNN-based models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.\tApolloConv provides better accuracy than lightweight linear models and competitive performance to Transformer-based models, with faster training and reduced complexity.\n2.\tApolloConv consistently achieves superior accuracy across both long-term and short-term forecasting benchmarks on multiple datasets.\n3.\tThe proposed multi-scale temporal embedding effectively overcomes the fixed downsampling limitation of ModernTCN."}, "weaknesses": {"value": "1. Formatting issues: The method name “ApolloConv” is misspelled as “AppoloConv” multiple times throughout the manuscript, including in the title, and appears in inconsistent formats (all caps, italics, or regular text) and in Section 5.2 the term “Adaptive Dilated Convolutional Block” is written as “Adaaptive.” Section 3.4 includes an unnecessary period in the title, and figure references alternate between “Fig.” and “Figure.” There is an unresolved citation (“trends(?)”) in the Introduction. \n2. Similarity in experimental description: The Implementation Details section (Section C.2, “Short-Term Forecasting”) shows some overlap in phrasing with the corresponding section of the ICLR 2024 Spotlight paper ModernTCN: A Modern Pure Convolution Structure for General Time Series Analysis (Luo & Wang, 2024), likely due to similarities in experimental setup and reporting style.\n3. Lack of novelty: The paper lacks strong novelty, as the proposed architecture mainly combines existing convolutional and frequency-domain techniques without introducing a fundamentally new idea.\n4. Missing figure reference: Figure 2 is not referenced or described in the text. The paper should briefly explain the overall architecture and data flow corresponding to this figure.\n5. Unclear notation: The notation U_jin Eq. (1) is not explicitly defined. It is unclear whether it denotes the number of output channels or the temporal length after convolution.\n6. Complexity explanation issue: The complexity terms in Table 1 lack derivation or justification (e.g., why TVNet is O(TD^2)instead of O(TD)). Providing brief reasoning or references for each method’s complexity would improve clarity and fairness of comparison.\n7. Issues in Ablation Study: The purpose and setup of each ablation are not clearly described—for example, it is unclear what specific components are removed in “w/o Forecasting Head” or “w/o Adaptive Dilated Block.” Table 4 lists results but provides no quantitative or causal analysis of the observed changes, and the discussion only repeats that “performance decreases.”"}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HQo8rW8wKu", "forum": "bFxBBUFm18", "replyto": "bFxBBUFm18", "signatures": ["ICLR.cc/2026/Conference/Submission22766/Reviewer_sF7T"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22766/Reviewer_sF7T"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22766/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761292612193, "cdate": 1761292612193, "tmdate": 1762942377920, "mdate": 1762942377920, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel time series forecasting framework that integrates trend decomposition with frequency-domain transformations. The method introduces a Multi-Scale Temporal Embedding module to capture recent and long-term dynamics, and a phase-preserving spectral gate to enhance periodic feature modeling. Furthermore, an Adaptive Dilated Convolutional Block expands the receptive field logarithmically to balance locality and efficiency. Experiments across several benchmark datasets show consistent improvements over recent CNN- and transformer-based baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper provides a clear motivation for combining time-domain trend extraction with frequency-domain modulation.\n2. The model design achieves efficiency improvements over transformer-based methods by relying on lightweight convolutional and spectral operations.\n3. The paper benchmarks across multiple datasets, showing consistent performance gains, which support the generalization ability of the proposed method.\n4. The proposed phase-preserving spectral gate is a novel sound attempt to capture global periodicity while maintaining causal structure — a meaningful contribution compared to conventional spectral filters.\n5. The combination of trend decomposition (time domain) and spectral gating (frequency domain) enables the network to capture complementary dynamics that single-domain models typically miss."}, "weaknesses": {"value": "1. Can you provide ablations that separately remove (i) the multi-scale CNN and (ii) the phase-preserving spectral gate in Section 3.1 (Multi-Scale Temporal Embedding)? Is there experimental evidence showing that phase-preserving spectral gating outperforms standard spectral filtering? Does fixing the phase limit the model’s ability to capture frequency drift in non-stationary signals? \n2. What concrete advantage does the logarithmic dilation strategy ($S \\approx \\log T$) bring compared to standard dilation schemes? Prior works also employ dilated convolutions — how does your approach differ? Could you include comparative experiments or replace the dilated convolution modules in these baselines to validate the effectiveness and superiority of your strategy?\n\n3. In the motivation, you state that combining trend decomposition with frequency-domain transformations allows the model to distinguish recent (green) and distant (beige) segments with similar past patterns. Could you provide experiments or visualizations demonstrating that your module indeed differentiates between near-term and long-term similar patterns? Moreover, in the Adaptive Dilated Convolutional Block, why does logarithmic scaling (“this logarithmic scaling prioritizes recent localities via small dilations”) favor recent information, given that dilation growth expands the receptive field? Is this empirically validated?\n4. In the expression “until the receptive field reaches $T \\cdot$ rf_ratio,” how is this ratio determined? The manuscript does not clearly describe its selection process — is there any hyperparameter sensitivity analysis provided?\n5. Why is the second spectral gate necessary in FORECASTING HEAD? What issue does it address compared with the first gate in the embedding stage? \n6. In Section 5.2, Ablation Analysis, the first experiment is misnamed. It should read “Ablation of Multi-Scale Temporal Embedding”, not “Ablation of Forecasting Head (Downsampling + Frequency Gate)”."}, "questions": {"value": "See **Weaknesses**."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "2UnSj7HOPD", "forum": "bFxBBUFm18", "replyto": "bFxBBUFm18", "signatures": ["ICLR.cc/2026/Conference/Submission22766/Reviewer_vVkP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22766/Reviewer_vVkP"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22766/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761722895578, "cdate": 1761722895578, "tmdate": 1762942377609, "mdate": 1762942377609, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ApolloConv, a CNN-based architecture for time series forecasting that combines multi-scale convolutions for trend extraction with frequency-domain gating for periodicity modeling. The design also incorporates adaptive dilated convolutions and group-wise mixing to model long-range dependencies while emphasizing recent dynamics. The authors claim that ApolloConv addresses CNN limitations such as recency bias and nonstationarity, achieving performance comparable to Transformers but with lower computational cost. Experiments show modest improvements over other CNN-based baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper highlights an intuitive limitation of CNNs (translation invariance overlooking recency) and proposes a solution that is easy to understand.\n2. The architecture is engineering-wise reasonable and scalable, combining multi-scale convolutions, frequency-domain gating, and adaptive dilations in a coherent pipeline.\n3. Experimental results indicate slight improvements over existing CNN-based models with lower computational cost, which may be useful in practice."}, "weaknesses": {"value": "1. The problem statement is not clearly defined. It’s unclear whether the paper aims to solve the inefficiency of attention models, the lack of recency awareness in CNNs, or the handling of nonstationarity. The motivation feels scattered.\n2. The proposed method lacks real novelty. Multi-scale convolutions and frequency-domain processing are already widely used in recent CNN-based forecasting models, so it’s hard to see what is fundamentally new here.\n3. The claim that ApolloConv overcomes “recency” and “nonstationarity” limitations is not convincingly supported by experiments — there’s no specific analysis or ablation verifying these effects.\n4. The performance gain over strong CNN baselines is marginal (around 1%), which makes the practical significance questionable.\n5. The paper contains typos and some figures (e.g., Fig. 1) are unclear, which makes parts of the explanation hard to follow."}, "questions": {"value": "1. Please report multi-run results (mean and std) to demonstrate the robustness of the proposed method.\n2. How exactly does ApolloConv address the recency bias and nonstationarity of CNNs, and can the authors provide targeted ablation or analysis to support this claim?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FFApcqc2Ua", "forum": "bFxBBUFm18", "replyto": "bFxBBUFm18", "signatures": ["ICLR.cc/2026/Conference/Submission22766/Reviewer_SLAf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22766/Reviewer_SLAf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22766/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761810618737, "cdate": 1761810618737, "tmdate": 1762942377393, "mdate": 1762942377393, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}