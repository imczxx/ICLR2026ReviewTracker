{"id": "hEqX9dIaqy", "number": 2691, "cdate": 1757209526605, "mdate": 1759898133072, "content": {"title": "Is it Bigger than a Breadbox: Efficient Cardinality Estimation for Real World Workloads", "abstract": "DB engines produce efficient query execution plans by relying on cost models. Practical implementations estimate cardinality of queries using heuristics, with magic numbers tuned to improve average performance on benchmarks. Empirically, estimation error significantly grows with query complexity. Alternatively, learning-based estimators offer improved accuracy, but add operational complexity preventing their adoption in-practice. Recognizing that query workloads contain highly repetitive subquery patterns, we learn many simple regressors online, each localized to a pattern. The regressor corresponding to a pattern can be randomly-accessed using hash of graph structure of the subquery. Our method has negligible overhead and competes with SoTA learning-based approaches on error metrics. Further, amending PostgreSQL with our method achieves notable accuracy and runtime improvements over traditional methods and drastically reduces operational costs compared to other learned cardinality estimators, thereby offering the most practical and efficient solution on the Pareto frontier. Concretely, simulating JOB-lite workload on IMDb speeds-up execution by 7.5 minutes (>30%) while incurring only 37 seconds overhead for online learning.", "tldr": "Cardinality Estimation (number of records that will be returned given a query) by many local regression models, one model per isomorphic group of graphs. Each graph corresponds to sub-query.", "keywords": ["Local regression", "Graph Hashing", "Cardinality Estimation", "Cost Models", "Databases", "Query Optimization"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6d78278b5b48b559f252785ce706c65b72232487.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a cardinality estimation for SQL queries based on kernel regression and handcrafted features. \nThe method has quite small overhead and competes with SoTA learning-based approaches on error metrics. \nFurther, amending PostgreSQL with the method achieves notable accuracy and runtime improvements over traditional methods and drastically reduces operational costs compared to other learned cardinality estimators, thereby offering the most practical and efficient solution on the Pareto frontier."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The language of the paper is fine, main ideas are easy to follow.\n2. Empirical results show that the proposed method has quite fast inference (not sure about training?), when compared to alternatives."}, "weaknesses": {"value": "1. The performance is lower than some baselines (Table 3).\n2. The equation (6) is not clear. In ML, one should use train/test split of a dataset to avoid overfitting.\n3. Figure 5 caption: missing reference \n4. It seems that your method is called \"LITECARD\". But it was never introduced formally.\n5. The main idea of the proposed method is a specific vectorization of execution DAGs. The features (Appendix D) are very domain specific and lack generality. I propose to resubmit the manuscript to VLDB or KDD.\n6. A comparison with standard GCN, GAT is not provided.\n7. I can't find proofs that the proposed method  (i) can run from cold-start, requiring no upfront training; (ii) can adapt to changes in workloads or data shifts"}, "questions": {"value": "1. Can you compare your method with:\n* P. Negi, R. Marcus, H. Mao, N. Tatbul, T. Kraska, and M. Alizadeh, ‘‘Cost-guided cardinality estimation: Focus where it matters,’’ in Proc. IEEE 36th Int. Conf. Data Eng. Workshops (ICDEW), Apr. 2020, pp. 154–157. \n* J. Sun and G. Li, ‘‘An end-to-end learning-based cost estimator,’’ 2019, arXiv:1906.02560.\n* J. Sun, J. Zhang, Z. Sun, G. Li, and N. Tang, ‘‘Learned cardinality estimation: A design space exploration and a comparative evaluation,’’ Proc. VLDB Endowment, vol. 15, no. 1, pp. 85–97, 2021\n\n2. How your paper is related to:\nWoltmann, L., Hartmann, C., Thiele, M., Habich, D., & Lehner, W. (2019, July). Cardinality estimation with local deep learning models. In Proceedings of the second international workshop on exploiting artificial intelligence techniques for data management (pp. 1-8) ?\n\n3. It is not clear how the model is trained. Is it trained online or query dataset is divided into train/test splits?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "7VSOyyEUsa", "forum": "hEqX9dIaqy", "replyto": "hEqX9dIaqy", "signatures": ["ICLR.cc/2026/Conference/Submission2691/Reviewer_FAp8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2691/Reviewer_FAp8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2691/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761580698358, "cdate": 1761580698358, "tmdate": 1762916333013, "mdate": 1762916333013, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents LITECARD, an online, pattern-based learned cardinality estimator for relational databases. The key idea is to exploit the repetitive nature of sub-query patterns in real-world workloads by grouping isomorphic subquery graphs and training lightweight regressors (e.g., locally weighted linear regression or decision forests) per pattern."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "S1. Practical motivation: The paper addresses a genuine gap in learned cardinality estimation research, bridging the accuracy of learned models with the low overhead needed for production DBMS integration.\n\nS2. Novel technical framing: The use of graph-local learning combined with hash-based partitioning of isomorphic subqueries is original and conceptually neat. The hierarchical (H1–H3) partitioning and incremental online updates are well-justified.\n\nS3. System integration: Implementing the method in PostgreSQL and demonstrating measurable runtime improvement (e.g., 7.5 min, around 30% reduction on IMDb) is good."}, "weaknesses": {"value": "W1. Unclear pattern detection pipeline.\nIt is unclear how the query patterns are discovered or clustered online. The paper seems to assume that the graph of subqueries is already extracted from query plans, but does not explain whether clustering or pattern identification contributes to the overhead. Clarifying the computational cost and scalability of this step is essential.\n\nW2. Dependence on historical query plans.\nThe method appears to rely on a corpus of historical queries and their plans to build pattern-specific models. This raises several questions:\n\n- Are the query plans generated by PostgreSQL itself?\n\n- Is it fair to compare against methods that do not assume access to such historical execution traces?\n\n- How is the cold-start phase (when no history exists) handled?\n\nW3. Generalization and workload shift.\nSince models are trained per pattern derived from past workloads, the approach seems inherently query-driven. How well does it transfer to new workloads or schema variations? If a new workload introduces unseen patterns, does the system re-hash and retrain? Are such adaptation costs included in the reported “37 s overhead”? Clarifying this is crucial for evaluating the claim of “negligible overhead.”\n\nW4. Scalability with large workloads.\nThe method’s efficiency is evaluated on IMDb (about 5 k queries). How does performance scale when the number of query patterns grows (e.g., 50 k queries or more)? The memory cost of maintaining many regressors and hash tables may become significant, while data-driven baselines remain unaffected by query count.\n\nW5. Experimental scope and baseline selection.\nThe evaluation focuses primarily on IMDb. It would strengthen the paper to include other complex benchmarks (e.g., STATS, StackOverflow, or TPC-DS) that feature multi-table joins and diverse predicates.\nAlso, the baselines are limited to DeepDB and FactorJoin as “data-driven” methods, but several  approaches (e.g., NeuroCard 2021, FLAT 2021, CardBench baselines) could provide a fairer SoTA comparison. The authors should justify why these were omitted.\n\nMinor issues.\n\nFigure 5 caption contains a typo: “Eq. ??” should reference the correct equation number.\n\nThe paper sometimes intermixes the terms LITECARD and ours; consistent terminology would improve clarity."}, "questions": {"value": "Q1. How are query patterns identified? Is there an explicit clustering step, and is its cost part of the 37 s overhead?\n\nQ2. How are query plans obtained for historical queries? If the system requires pre-existing plans, does that imply an extra source of information unavailable to other baselines?\n\nQ3. How does LITECARD handle new query workloads or schema changes where the subquery graphs differ from historical ones?\n\nQ4. How does performance and overhead scale as the number of unique query patterns increases (e.g., beyond 50 k)?\n\nQ5. Why is IMDb the only dataset tested? Would the method generalize to datasets with more complex join paths or string predicates (e.g., STATS, TPC-DS)?\n\nQ6. Why were only DeepDB and FactorJoin chosen as data-driven baselines, and are they considered current SoTA for this comparison?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gnZjsViAnR", "forum": "hEqX9dIaqy", "replyto": "hEqX9dIaqy", "signatures": ["ICLR.cc/2026/Conference/Submission2691/Reviewer_zkyh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2691/Reviewer_zkyh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2691/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761621610630, "cdate": 1761621610630, "tmdate": 1762916332398, "mdate": 1762916332398, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript delineates an innovative approach to cardinality estimation called LITECARD, which addresses the trade-off between the inaccurate, fast heuristics of traditional database systems (like PostgreSQL's per-column histograms) and the accurate, slow deep learning models that are often too complex to deploy in practice. The LITECARD works by decomposing the query space and applying graph-local learning, which exhibits an amalgamation of pattern recognition, custom kernel, local models, and hierarchical fallback, a combination that endows the model with superior performance in comparison to baseline methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. The paper's significance is underscored by its contribution of a novel cardinality estimator that 1) can run from a cold-start (no upfront training), 2) can adapt to changes in workloads or data shifts, and 3) has negligible update and inference time.\n\nS2. The estimator's novelty is encapsulated in its graph-local learning - an amalgamation of pattern recognition, custom kernel, local models, and hierarchical fallback.\n\nS3. The evaluation is comprehensive, with comparisons to baseline methods providing a compelling demonstration of the superior performance of the proposed method."}, "weaknesses": {"value": "W1. While the median error (P50) is highly competitive (1.70), the tail errors (worst-case errors) are significantly worse than the most accurate learned estimators, DeepDB and FactorJoin.\n\nW2. The core efficiency and low overhead rely on the assumption that highly repetitive subquery patterns exist in the workload. For a workload with extremely low query template reuse or high churn in unique query patterns, the model would frequently fall back to the base PostgreSQL estimator or have to train local models on very sparse data, undermining its advantage.\n\nW3. The local learning models are simple and established. While simplicity contributes to the low overhead, relying on models that only consider local feature proximity might limit their ability to capture complex non-linear feature interactions within a query pattern, potentially contributing to the high tail errors. The novelty rests more on the system-level integration and workload decomposition strategy rather than the machine learning models themselves."}, "questions": {"value": "See \"weaknesses\" above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xtZrk4V9hX", "forum": "hEqX9dIaqy", "replyto": "hEqX9dIaqy", "signatures": ["ICLR.cc/2026/Conference/Submission2691/Reviewer_NayK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2691/Reviewer_NayK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2691/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761745193374, "cdate": 1761745193374, "tmdate": 1762916332254, "mdate": 1762916332254, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a lightweight online learning approach for query cardinality estimation in relational databases. Instead of using a single large model, it maintains multiple small regressors, each specialized for a subquery pattern represented as a graph and retrieved via hashing. The method continuously updates online with minimal overhead and integrates into PostgreSQL, achieving accuracy comparable to state-of-the-art learned estimators while reducing training cost and runtime overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem studied in this paper is important.\n2. The presentation is good."}, "weaknesses": {"value": "1. Unclear novelty. The paper does not clearly explain how it differs from existing learned optimizers and cardinality estimation methods.\n2. Insufficient scalability analysis. The paper lacks detailed discussion and evaluation of how the method scales with larger datasets and workloads."}, "questions": {"value": "I have two main concerns about the paper: novelty and scalability.\n\n1. Novelty\nThe paper discusses several existing learned optimizers and cardinality estimation approaches. However, the fundamental novelty of this work remains unclear. Please clarify what distinguishes the proposed method from prior works — for example, what new information or mechanisms are introduced in the learning process, and how these lead to fundamentally different behavior or advantages compared with existing models.\n\n2. Scalability and Training Overhead\nSection 4.1 reports a total overhead of about 37 seconds for 5k queries on the IMDb dataset, but it is unclear how this overhead scales with larger workloads. Specifically:\n\t•\tHow does the system perform as the number of stored subquery patterns or regressors increases (e.g., 100k queries or multi-terabyte datasets)?\n\t•\tDoes the memory footprint or lookup latency grow linearly with the number of hashed entries?\n\t•\tSince each pattern maintains a separate model, could model management or hash collisions become a bottleneck for very large workloads?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RkeJSTCv3v", "forum": "hEqX9dIaqy", "replyto": "hEqX9dIaqy", "signatures": ["ICLR.cc/2026/Conference/Submission2691/Reviewer_AwTu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2691/Reviewer_AwTu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2691/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960491274, "cdate": 1761960491274, "tmdate": 1762916332113, "mdate": 1762916332113, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}