{"id": "dRuwfxCCpF", "number": 17219, "cdate": 1758273603650, "mdate": 1759897190218, "content": {"title": "Focused Diffusion GAN: Object-Centric Image Generation Using Integrated GAN and Diffusion Frameworks", "abstract": "Generative Adversarial Networks (GANs) and Diffusion Models (DMs) have shown significant progress in synthesizing high-quality object-centric images. However, generating realistic object-centric images remains challenging when training datasets are limited or contain degraded images (e.g., privacy-induced face blurring). Under these conditions, existing generative models frequently produce images that lack perceptual quality or exhibit overfitting to the training examples. To overcome these limitations, we propose a novel hybrid generative model, \\textit{Focused Diffusion-GAN (FDGAN)}, targeting low-data object-centric regimes, which integrates a GAN discriminator directly into the diffusion model at intermediate denoising stages. Central to FDGAN is an Additional Noise Perturbation Module (ANPM) that selectively activates the GAN component only for images sufficiently denoised, ensuring the discriminator receives meaningful input. Additionally, ANPM applies targeted noise perturbations within predefined bounding-box regions, implicitly guiding the model’s focus toward key objects. FDGAN differs from other models like LayoutDiffusion, which explicitly conditions synthesis on fixed bounding-box layouts, or Diffusion-GAN and StyleGAN2-ADA, which employ noise augmentation throughout the entire training process, by combining adversarial training with targeted noise perturbations at specific intermediate diffusion steps. We evaluate FDGAN on three small object-centric datasets (Cityscapes subset, Traffic-Signs, and MS-COCO ``potted plant'') and, against strong GAN, diffusion, and object-centric baselines, show improved perceptual quality (Fréchet Distance) and reduced overfitting (Feature Likelihood Score). Ablation studies indicate that selective mid-timestep adversarial guidance together with ANPM improves the realism–overfitting trade-off in limited-data generative tasks.", "tldr": "Hybrid Diffusion - GAN model", "keywords": ["Generative Models", "Diffusion Models", "Object-Centric", "hybrid model"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/35c15834e7145ee8e73ba6f51875020c2a50af3e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces FDGAN, a method that combines GAN and diffusion models for low-data, object-aware synthesis aimed at augmenting downstream object detectors such as YOLO and DETR. While the idea of integrating these models is potentially interesting, the paper fails to provide a clear big picture or logical foundation for the approach. It primarily focuses on implementation details without explaining the underlying principles, and the experimental validation does not adequately support the claims made in the introduction."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "The attempt to merge GAN and diffusion models for data augmentation in low-data scenarios is a relevant and timely topic.\n\nThe paper presents a structured method with multiple loss functions, which could be a basis for further development."}, "weaknesses": {"value": "Lack of Conceptual Clarity and Big Picture\n- The paper does not sufficiently explain the core principles behind fusing GAN and diffusion models. For instance, it describes how the models are combined but fails to justify why this fusion is theoretically sound or beneficial. This omission makes it difficult to assess the novelty and contribution of the work.\n\nExcessive Repetition in Citations\n- The paper suffers from redundant citations, which reduce its readability and professionalism. For example, in the first paragraph of page 2, \"Karras et al., 2020a\" is cited four times. This indicates a need for better citation management to avoid clutter.\n\nInsufficient Experimental Validation\n- The introduction claims that FDGAN is an object-aware synthesizer for augmenting detectors like YOLO and DETR, but the experiments do not provide evidence to support this. There are no results demonstrating improved performance on downstream detection tasks, which undermines the paper's main motivation.\n\nMethodological Justification\n- The method section introduces three loss functions but does not explain the rationale for their selection or combination. Without a principled discussion of why these losses are chosen and how they interact, the approach appears ad hoc and lacks theoretical grounding."}, "questions": {"value": "Can the authors provide a more detailed theoretical explanation for the fusion of GAN and diffusion models? \n\nHow does the object-aware synthesis specifically benefit downstream detectors? The authors should include experiments that evaluate FDGAN's impact on detector performance (e.g., using metrics like mAP for YOLO or DETR) to validate the claims.\n\nPlease justify the combination of the three loss functions: what is the principle behind each loss, and how do they collectively contribute to the model's objectives?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "HqnZdtwlyh", "forum": "dRuwfxCCpF", "replyto": "dRuwfxCCpF", "signatures": ["ICLR.cc/2026/Conference/Submission17219/Reviewer_vyDD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17219/Reviewer_vyDD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17219/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761639923762, "cdate": 1761639923762, "tmdate": 1762927183227, "mdate": 1762927183227, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Focused Diffusion-GAN (FDGAN), a hybrid generative model designed for object-centric image generation in low-data regimes. The key innovation is integrating a GAN discriminator into intermediate denoising stages of a diffusion model through an Additional Noise Perturbation Module (ANPM). ANPM selectively activates adversarial training at specific timesteps and applies targeted Gaussian noise within bounding-box regions to guide the model's attention toward objects. The authors evaluate FDGAN on three small datasets: Cityscapes-Pedestrian, Traffic-Signs, and MS-COCO potted plants, demonstrating improvements in perceptual quality and reduced overfitting compared to GAN-only, diffusion-only, and hybrid baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The selective integration of adversarial training at intermediate diffusion timesteps (t < t_early) is an interesting approach that differs from prior hybrid methods.\n- Detailed ablation studies demonstrating the effectiveness of each component (GAN/ANPM, reconstruction losses, weighting schemes)."}, "weaknesses": {"value": "- The evaluation is restricted to only three small datasets, all at 256×256 resolution. The generalizability to other domains, higher resolutions, or multi-class scenarios remains unclear. \n- The main part of the method is performing GAN training on intermediate diffusion timesteps, which can be regarded as a hyper-parameter tuning. And the justification (theory / empirical investigation) is insufficient, resulting in limited novelty. \n- Although the BB noise is highlighted in the abstract, there is no ablation study on it."}, "questions": {"value": "- See Weaknesses.\n- Why use diffusion loss instead of consistency loss in training? I think the consistency loss aligns closer with the GAN, I feel strange about the usage of diffusion loss."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IcoJtKDh9E", "forum": "dRuwfxCCpF", "replyto": "dRuwfxCCpF", "signatures": ["ICLR.cc/2026/Conference/Submission17219/Reviewer_5wXS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17219/Reviewer_5wXS"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17219/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925108836, "cdate": 1761925108836, "tmdate": 1762927182963, "mdate": 1762927182963, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Focused Diffusion-GAN (FDGAN), a hybrid generative model that integrates a GAN discriminator into a diffusion model at intermediate denoising stages. The method introduces an Additional Noise Perturbation Module (ANPM) that selectively activates the adversarial branch when samples are sufficiently denoised and applies localized noise within bounding-box regions to guide object-centric focus. The paper targets low-data object-centric regimes, evaluating on three small datasets (Cityscapes–Pedestrian, Traffic-Signs, COCO “potted plant”). Experimental results demonstrate improved perceptual fidelity and reduced overfitting compared to diverse baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Task focus: The focus on limited-data, object-centric scenarios is well-motivated and practical (e.g., privacy-blurred faces, small datasets).\n2. Comprehensive evaluation: Benchmarks include both GANs and DMs, using DINOv2-based metrics and traditional FID/Precision/Recall."}, "weaknesses": {"value": "1. Marginal FID improvements: The proposed method performs worse than Diffusion-GAN on FID across all datasets.\n2. Novelty scope: The hybridization of diffusion and GANs has been explored. The core novelty lies mainly in localized noise perturbation (ANPM) and timestep scheduling, which might be seen as incremental.\n3. Effectiveness evidence: Since FDGAN aims to be \"a low-data, object-aware synthesizer for augmenting downstream detectors (e.g., YOLO/DETR)\", including downstream detection fine-tuning results would strengthen claims."}, "questions": {"value": "1. How sensitive is FDGAN to the choice of the timestep threshold $t_\\text{early}$ and noise strength $\\gamma$ in ANPM?\n2. Can the ANPM mechanism generalize to non-bounding-box settings (e.g., segmentation masks or text prompts)?\n3. Sections 4.1 and 4.2 share the same table (Table 1) without explicit reference to it, and the order of the models in the table is chaotic. It is not friendly to performance comparison and analysis. Improvements are recommended."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "geaOpXCcMX", "forum": "dRuwfxCCpF", "replyto": "dRuwfxCCpF", "signatures": ["ICLR.cc/2026/Conference/Submission17219/Reviewer_kNpS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17219/Reviewer_kNpS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17219/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762145729634, "cdate": 1762145729634, "tmdate": 1762927182553, "mdate": 1762927182553, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This manuscript investigates how to enhance the quality of object-centric image generation when training data is limited(e.g. <3k) or contains degraded images. The authors propose a hybrid GANs-Diffusion framework that integrates a discriminator into the intermediate denoising steps of the diffusion process to improve visual fidelity. An Additional Noise Perturbation Module is also introduced to steer the model's focus toward predefined bounding boxes containing key objects. The proposed method has been experimentally validated on complex scene datasets—including Cityscapes-pedestrian, Traffic-Signs, and MS-COCO(Potted Plant)—demonstrating its effectiveness in generation tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The research problem addressed in this manuscript—generation with limited data—is highly meaningful. The approach of integrating a GANs discriminator to enhance quality is well-justified, and the idea of leveraging bounding boxes to prioritize the generation quality of key objects is particularly suitable for complex scene generation. Experimental results demonstrate a clear improvement in generated quality compared to existing methods."}, "weaknesses": {"value": "The experimental analysis appears somewhat fragmented and would benefit from consolidation and restructuring. The current evaluation is incomplete, as it fails to demonstrate the method's effectiveness in downstream tasks—particularly as data augmentation. Moreover, the study lacks intuitive assessments of generation quality, such as visual comparisons of generated images. Additionally, discussions and comparisons with existing methods in the field of generation with limited data are notably absent."}, "questions": {"value": "1.The manuscript should discuss recent work on few-shot sample generation, which is highly relevant to the presented approach.\n\n2.Several notation issues are present in Equations (7) and (8). For instance, the time step 't' is missing in Equation (8), and the origin of the variable x^is not defined.\n\n3.Both the diffusion loss and the reconstruction loss pertain to reconstruction. Please clarify the distinct roles and motivations for including both terms in the objective function.\n\n4.While the introduction claims that the method is intended for augmenting downstream detectors, no experiments are conducted to evaluate the utility of the generated samples in such downstream tasks.\n\n5.How does the performance vary with different scales of training data (e.g., 100, 1,000 samples)? An analysis of the method's sensitivity to training set size is needed.\n\n6.The experiments primarily follow a single-objective-per-dataset setting (e.g., pedestrians, traffic signs, potted plants). The applicability of the method to multi-object generation scenarios should be discussed, as this is critical for complex real-world applications."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3SFz6MungF", "forum": "dRuwfxCCpF", "replyto": "dRuwfxCCpF", "signatures": ["ICLR.cc/2026/Conference/Submission17219/Reviewer_SMqy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17219/Reviewer_SMqy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17219/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762222340091, "cdate": 1762222340091, "tmdate": 1762927182230, "mdate": 1762927182230, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}