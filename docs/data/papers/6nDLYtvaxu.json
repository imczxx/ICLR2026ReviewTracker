{"id": "6nDLYtvaxu", "number": 1833, "cdate": 1756949916194, "mdate": 1763705628014, "content": {"title": "OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching", "abstract": "Flow-based text-to-image models follow deterministic trajectories, forcing users to repeatedly sample to discover diverse modes, which is a costly and inefficient process. We present a training-free, inference-time control mechanism that makes the flow itself diversity-aware. Our method simultaneously encourages lateral spread among trajectories via a feature-space objective and reintroduces uncertainty through a time-scheduled stochastic perturbation. Crucially, this perturbation is projected to be orthogonal to the generation flow, a geometric constraint that allows it to boost variation without degrading image details or prompt fidelity. Our procedure requires no retraining or modification to the base sampler and is compatible with common flow-matching solvers. Theoretically, our method is shown to monotonically increase a volume surrogate while, due to its geometric constraints, approximately preserving the marginal distribution. This provides a principled explanation for why generation quality is robustly maintained. Empirically, across multiple text-to-image settings under fixed sampling budgets, our method consistently improves diversity metrics such as the Vendi Score and Brisque over strong baselines, while upholding image quality and alignment.", "tldr": "We proposed a framework to enable the flow-matching based generative model to generate samples which are both diverse and of high quality.", "keywords": ["Stochastic Control", "Training-Free Guidance", "Sample Diversity", "Quality-Diversity Balance", "Flow Matching"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/aeec9536675d1d1ae35040cf30b2f39e0e7d3e08.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes OSCAR, a training-free inference-time method to increase set-level diversity in flow-based text-to-image models. At each step, OSCAR predicts endpoints with a Heun extrapolation and encodes them into a semantic space, and maximizes feature-volumes to get diversity. They also propose orthogonal projection to feature volume gradient and stochastic noise and redundancy-aware reweighting on the feature Gram matrix to preserve fidelity while getting enough diversity. Experiments on COCO class-conditional and text-to-image generation show improved coverage and intra-set diversity with comparable fidelity across CFG scales."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The combination between feature volume gradient and stochastic noise makes sense.\n- Projecting both feature volume gradient and noise onto the subspace orthogonal to the base velocity is a reasonable way to separate the quality from diversity.\n- The experiments show improvements compared to the baselines"}, "weaknesses": {"value": "- Tab. 2 reports large drops when either OP or RR is removed, yet there is no step-by-step ablation starting from a naïve setup without both components; as a result, the individual contributions of OP and RR remain unclear. Moreover, the ablated variants still underperform training-free guidance baselines (e.g., PG, DPP in Table 1), which is counterintuitive—in my knowledge, DiverseFlow should be at least comparable to a naïve setup. This discrepancy raises concerns about the evaluation process.\n- In Tab. 1 and Tab. 6, the proposed method attains the best diversity scores, but FID and CLIP show substantial overlap in mean ± std with baselines. Please include additional perceptual quality metrics (e.g., VQA, ImageReward) to verify that visual quality is truly preserved while diversity increases.\n- In Fig. 3 and Fig. 8, OSCAR’s PRD curves appear below certain baselines over parts of the recall range, yet the caption/text claim higher AUC. Please recompute and verify the PRD and AUC, and ensure the reported AUCs align with the plotted curves; as currently shown, the trade-off does not look better than some baselines.\n- While Tab. 1 reports improvements, Tab. 4–5 show mixed performance across classes. There is no analysis of expected diversity on subsets of classes, which limits the practical significance of the claims. Please report per-class variance and expected diversity over random class subsets."}, "questions": {"value": "- What is the actual wall-clock inference time of OSCAR relative to each baseline? Since the method uses second-order Heun both for endpoint prediction and for the update step, please report per-image (or per-set) latency and FLOPs, and clarify whether all baselines use the same solver (or were re-run with Heun) to ensure a fair comparison.\n- Could you provide additional results on other pretrained flow/rectified-flow models beyond the main backbone? Demonstrating consistent gains across multiple architectures would strengthen the claim that the method generalizes."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yTAtJlj6tB", "forum": "6nDLYtvaxu", "replyto": "6nDLYtvaxu", "signatures": ["ICLR.cc/2026/Conference/Submission1833/Reviewer_c5nD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1833/Reviewer_c5nD"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1833/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761652431216, "cdate": 1761652431216, "tmdate": 1762915903845, "mdate": 1762915903845, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **OSCAR**, a training-free, inference-time diversity enhancement method for flow-matching models. The core idea is to inject orthogonal ``lateral\" perturbations into the sampling trajectory. This design increases semantic and visual diversity across a set of parallel trajectories while preserving per-sample quality."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Clear motivation and elegant formulation.** The paper identifies the lack of diversity in deterministic flow-matching samplers and proposes a geometrically principled orthogonal control solution that is simple, modular, and theoretically grounded.\n2. **Training-free and plug-and-play.** OSCAR can be added to any flow-matching, requiring no model finetuning or architectural modification.\n3. **Good empirical results.** The method substantially improves set-level diversity metrics while maintaining comparable single-image quality and alignment scores.\n4. **Efficiency and analysis.** The O(m²) implementation with leverage-based reweighting is more scalable than prior set-based methods such as DiverseFlow."}, "weaknesses": {"value": "1. **General quality evaluation.**  \n   Current experiments focus on concept-specific prompts. To demonstrate generalization and verify that OSCAR does not systematically degrade single-sample quality, the authors should also report results on large, random prompt suites (e.g., FID-30K, or ImageNet-256) using one image per prompt, with FID, CLIPScore, etc.\n\n2. **Feature-space dependence.**  \n   The volume objective relies on representations from a specific feature encoder (e.g., CLIP). If that encoder is biased or poorly aligned with human perception, OSCAR might optimize for feature-space diversity rather than semantic diversity. It would strengthen the paper to analyze sensitivity to the encoder choice.\n\n3. **Relation to high-order samplers (e.g., DPM-Solver++, UniPC).**  \n   Since these solvers are also training-free inference methods, it would be useful to clarify whether OSCAR is complementary to or conflicting with them. Can OSCAR be stacked on top of higher-order samplers, or does its orthogonal control interfere with their integration accuracy? A brief discussion or experiment combining the two would clarify their compatibility."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Ws6BYYEydM", "forum": "6nDLYtvaxu", "replyto": "6nDLYtvaxu", "signatures": ["ICLR.cc/2026/Conference/Submission1833/Reviewer_avHk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1833/Reviewer_avHk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1833/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997191858, "cdate": 1761997191858, "tmdate": 1762915903663, "mdate": 1762915903663, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a method for increasing in-sample diversity in flow-based generative models and evaluate it empirically, primarily on text-to-image benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The proposed method seems to perform well empirically (Table 1) across different metrics, compared to baselines."}, "weaknesses": {"value": "I think that the biggest weakness of the method is that there are many \"moving parts\" in the proposed algorithm, and it is unclear how big an overhead this is compared to baselines. Specifically, the proposed method should be compared with baselines both on runtime and memory consumption. For example, at each sampling step, the proposed method requires\n\n* A Heun second-order extrapolation (which, btw, I do not think is defined in the paper), I believe, requires at least one extra NFE, and it is not discussed how accurate it is\n* Then, we need to create Z based on the estimate of the final sample, which needs access to a pretrained feature predictor\n* When we need to evaluate the energy, its gradient, VJP of the feature predictor, and VJP of the Heun extrapolation.\n\nApart from that, the results on the precision-recall do not seem very strong. The gains compared to baselines do not seem consistent across CFG weights (Figure 3) and do not hold for other concepts (Figure 8).\n\nThe method overall seems complicated (Algorithm 1), and has five hyperparameters. There is some discussion on sensitivity in section 5.2 and figure 7, which shows that the choice of parameters matters. However, it seems like the analysis was performed for a single model. It is unclear whether the same choice of hyperparameters holds for different models, or would the user need to tune them separately for different models.\n\nSome other notes:\n1. I don't understand Figure 2. What is the true distribution that you are trying to model? Perhaps Standard FM covers it better than OSCAR? I wouldn't say that FM's behaviour in this example is \"mode collapse\" without knowing what the distribution is that we are trying to model\n2. line 216 - can the authors elaborate on the choice of $\\hat{\\psi}$? How is it defined? How do we know it's \"accurate\"? I see that it is defined in line 16 of Algorithm 1; it should be in the main text. Since it amounts to a single step 2nd order Euler step, I think one could argue that it is not very accurate, especially for models with highly curved trajectories. Perhaps it would be helpful to show a few examples, where we compare the final sample with the Heun approximation? For example EDM2 models use the Heun 2nd order sampler, but they still require 32 sampling steps to get good results (instead of a single step)\n3. Equation 3 - this either needs an elaboration or a citation. It is not explained why this really corresponds to a notion of volume, especially since it uses hyperparameters $\\tau, \\varepsilon$.\n4. Similarly, equation 4. It wouldn't hurt to have some explanation/derivation for why it is defined the way it is.\n    *  I can see it appears in Lemma 1, but it is not referenced in the main text\n5. The term \"stochastic control\" is a bit misleading. Usually, it refers to minimizing the expectation of some penalty which depends on the final endpoint and/or the trajectory. It is usually solved using tools from stochastic analysis.\n6. Appendix B is not very readable. I am not sure where proofs begin and end.\n7. A relevant method, which is not discussed, that allows for increasing diversity by injecting orthogonally projected noise is \"Stochastic Density Guidance\" [1].\n8. Line 254 - \"By applying this projection to both the deterministic control g and the stochastic noise dWt, we ensure our guidance only performs a “lateral spread” to enhance diversity, without interfering with the model’s primary, “forward” trajectory towards a high-fidelity output\". I would consider this approach largely a heuristic. Authors do not prove that this approach theoretically guarantees that the model samples from the correct distribution. I would expect not, similarly to the case of particle guidance, where authors actually characterize the distribution they end up sampling from.\n\n--- \nReferences \n\n[1] Karczewski et. al \"Devil is in the Details: Density Guidance for Detail-Aware Generation with Flow Models\" (ICML 2025)"}, "questions": {"value": "1. Can the authors provide a comparison with baselines in terms of runtime and memory consumption?\n2. Can the authors provide more information about whether the results in Table 1 are statistically significant? Some differences appear very small compared to the standard deviations.\n3. Can the authors show whether the choice of hyperparameters is consistent across different models? Or does it need to be tuned separately for each model?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bP6k2LeWfJ", "forum": "6nDLYtvaxu", "replyto": "6nDLYtvaxu", "signatures": ["ICLR.cc/2026/Conference/Submission1833/Reviewer_yFhz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1833/Reviewer_yFhz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1833/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762121847542, "cdate": 1762121847542, "tmdate": 1762915903344, "mdate": 1762915903344, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors tackle the task of generating diverse outputs from flow matching models. The paper builds on prior works such as Particle Guidance and proposes augmenting the probability flow ODE by introducing both a particle expansion term and stochastic noise. The expansion is achieved by considering the volume of the semantic features at the endpoints of each particle and incorporating a negative gradient that encourages greater spread. This is complemented by a clever reweighting strategy and the addition of stochastic noise to the generation process, with all components orthogonalized to the original flow direction to prevent image quality degradation. The authors evaluate their method against several prior works on text-to-image generation and report improved results."}, "soundness": {"value": 4}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The task of generating diverse outputs from pretrained diffusion or flow-based models is an important one, particularly when dealing with heavily post-trained and distilled models that tend to reduce output diversity.\n- The paper is very well written and easy to follow.\n- The proposed method is simple, intuitive, and elegant.\n- The experimental suite is extensive, featuring an impressive range of metrics, baselines, and ablations."}, "weaknesses": {"value": "- The experiments is missing the simplest baseline: independently generating $N$ samples from the base diffusion/flow model. Additionally, the method can be viewed as a test-time scaling approach for diversity. As described, each denoising step requires one forward pass of the base model plus two reverse-mode VJP operations. So another useful comparison would be the standard FM baseline run with a larger number of particles to match OSCAR’s total computational cost.\n- For the qualitative comparisons in Fig. 6, including OSCAR samples without any ablations would better illustrate the impact of each component.\n- The noise gate parameter $t_{\\text{gate}}$ is unclear in both its role and its effect on performance. It is absent from Algorithm 1 and first appears in Section 5.2 in an ablation. From the main paper, its function is unclear. The ablation suggests high sensitivity to this parameter, with performance degrading substantially as its value increases. In Appendix F.1, $t_{\\text{gate}}$ is not mentioned; instead, $t_{\\text{start}}$ and $t_{\\text{end}}$ are introduced.\n- [Minor] Formatting error in Algorithm 1, Line 1: “Feature Encoder” and “Endpoint Predictor” are incorrectly formatted."}, "questions": {"value": "1. Could the authors please clarify the definition, use, and impact of $t_{\\text{gate}}$, as well as the details of its ablations? Is it a constant scalar (as indicated in Figure 7(c)) or an interval (as shown in Table 3)? If it is the former, how does it relate to $t_{\\text{start}}$ and $t_{\\text{end}}$? If it is the latter, and $t_{\\text{gate}} = [t_{\\text{start}}, t_{\\text{end}}]$, why does Table 7 in Appendix F.2 explore the case where $t_{\\text{start}} = 0.05$ and vary $t_{\\text{end}}$, whereas Figure 15 fixes $t_{\\text{end}} = 0.95$ and varies $t_{\\text{start}}$?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WOwMAA912M", "forum": "6nDLYtvaxu", "replyto": "6nDLYtvaxu", "signatures": ["ICLR.cc/2026/Conference/Submission1833/Reviewer_Q6XH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1833/Reviewer_Q6XH"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1833/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762237540595, "cdate": 1762237540595, "tmdate": 1762915903132, "mdate": 1762915903132, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}