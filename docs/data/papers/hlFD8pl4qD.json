{"id": "hlFD8pl4qD", "number": 20422, "cdate": 1758305924869, "mdate": 1759896978489, "content": {"title": "LLMs for Sequential Optimization Tasks: from Evaluation to Dialectical Improvement", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, opening new possibilities for solving complex optimization problems. This paper investigates the potential of LLMs as end-to-end designers for tackling Sequential Optimization Problems (SOPs), a challenging and pervasive class of tasks. To rigorously evaluate LLM performance, we introduce WorldGen, a dynamic benchmark for generating unseen SOPs with controllable complexity. Our initial findings show that while LLMs perform well on simpler SOPs, their effectiveness declines sharply as complexity increases. To address this, we draw inspiration from philosophical theories of reasoning—specifically, Hegelian Dialectics—and propose ACE, a dialectical framework that enhances LLM performance in SOPs without requiring retraining or fine-tuning.", "tldr": "LLMs struggle with complex sequential optimization tasks—our ACE framework, inspired by Hegelian Dialectics, helps them perform better without retraining or fine-tuning.", "keywords": ["Optimization", "LLM", "Dialectics", "Evaluation"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f581f9263e6d1d03ff47d55fde13805e2affca18.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces **WorldGen**, a dynamic benchmark to test LLMs on **Sequential Optimization Problems (SOPs)** with controllable complexity. It finds that LLMs perform well on simple tasks but degrade as complexity increases. To improve this, the authors propose **ACE (Act, Critique, Evolve)**—a *dialectical reasoning framework* that enhances LLM problem-solving through iterative thesis–antithesis–synthesis cycles. Without retraining, ACE consistently outperforms baselines like Self-Reflection and Debate across multiple models and tasks."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "*  ACE introduces a new reasoning paradigm grounded in dialectics, distinct from prompt-engineering or multi-agent scaffolds.\n*  WorldGen allows scalable, contamination-free evaluation of LLMs in unseen optimization contexts.\n* Seven LLMs across multiple reasoning baselines, with cost analyses and ablations."}, "weaknesses": {"value": "* Current experiments use synthetic 3-D “worlds,” which may not represent real-world sequential optimization (e.g., reinforcement learning, control).\n* The “Expert Solution” is human-crafted and not fully automated.\n* While conceptually elegant, the Hegelian analogy may be seen as rhetorical rather than rigorously formalized.\n* Some experimental details (e.g., number of iterations, random seeds) are omitted from the main text."}, "questions": {"value": "* How does WorldGen scale to higher-dimensional or real-world tasks (e.g., scheduling, control)?\n* Could ACE be formalized more concretely—for example, as an algorithmic update rule or meta-controller?\n* Could the authors share the WorldGen generation code and parameters to ensure reproducibility?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jbU2vV8K4n", "forum": "hlFD8pl4qD", "replyto": "hlFD8pl4qD", "signatures": ["ICLR.cc/2026/Conference/Submission20422/Reviewer_nxjG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20422/Reviewer_nxjG"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20422/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761613407130, "cdate": 1761613407130, "tmdate": 1762933863020, "mdate": 1762933863020, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors claim that large language models (LLMs) have potential for sequential optimization problems. They introduce a benchmark for generating such problems with controllable complexity to evaluate LLM performance. Furthermore, the authors propose a new framework (ACE) to enhance such performance."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "This paper addresses a broad question and could serve as a good position paper if well executed (however, this is not the case; see weaknesses below). The related works section also serves as a good survey."}, "weaknesses": {"value": "The paper suffers from unclear framing, vague methodology, and questionable meaningfulness. The notion of \"sequential optimization problems\", which is central to this paper's framing, is never clearly defined. Trying to decipher it leads to limited results. For example, the statement “the task naturally emerges as finding the maximum (or other extrema) in the generated n-dimensional world” provides no clear formulation of the objective, constraints, or difficulty of the problems being optimized. As a result, it is unclear what problem is actually being solved or how it relates to established optimization research.\n\nOptimization is a broad field with well-defined benchmarks and taxonomies. Without a clear problem class or justification, the work lacks grounding. The proposed ACE is also insufficiently detailed: its mechanisms and implementation are not described in a way that enables reproduction or proper assessment. Such lack of clarity is not limited to a single method: overall, the reproducibility of this paper needs improvements.\n\nAs a result, it is infeasible to evaluate the real contribution of the manuscript. A large portion of the paper is devoted to introductory discussion and related work, while core technical content and empirical analysis are not well grounded. The paper reads more like a position paper rather than a concrete research contribution. While philosophy-inspired methods can be interesting and worth exploring, the work would need a clearer problem definition, rigorous benchmarking, and stronger experimental validation before it could be considered ready for publication."}, "questions": {"value": "(See unclear aspects in the weaknesses section)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "IBuWwth9rf", "forum": "hlFD8pl4qD", "replyto": "hlFD8pl4qD", "signatures": ["ICLR.cc/2026/Conference/Submission20422/Reviewer_gos8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20422/Reviewer_gos8"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20422/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761951339889, "cdate": 1761951339889, "tmdate": 1762933862323, "mdate": 1762933862323, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed a new task for llms, i.e. the optimization task. To systematically test across different LLMs, the paper proposes a new method for providing the optimization task without providing the background. Based on this, the paper proposed a WorldGen benchmark and test across 7 different models on the benchmark. It is found that the harder the task, the lower the performance LLMs are. To increase the performance, the paper proposed ACE, which effectively increase the LLMs' performance without retrainning or finetuning."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 1}, "strengths": {"value": "This paper is the first paper to my knowledge that applies LLMs on optimization tasks, and especially sequential optimization tasks."}, "weaknesses": {"value": "1. The paper is self-contradictory that at the beginning the LLMs are treated as optimizers (get feedback from the environment and send out new queries). However, for the most part the paper, LLMs are designers, which uses different type of optimization methods.\n2. Based on weakness 1, i think the paper is more on applying LLMs onto real world optimization tasks. I do not understand how given the function for X belongs to R^3 can be a good ecological validation of the method. And i highly disagree that such way of formalization the optimization problem does not exist in training regime (since this is what authors' want to achieve). The authors totally misunderstand the specific optimization question and the format of the optimization questions. Rather i would like to see more ecological experiments (like traveler salesman problem).\n3. Although the paper mentions sequential optimization tasks, the optimization problem itself is not SOP (each action is based on previous actions). Instead, it is only the LLM states are self-dependent. Please modify the paper.\n4. Hegelian-Dialectics has a special meaning of development byvercoming internal contradictions. I believe here it is a abuse usage of Hegelian-Dialectics. Please edit the paper.\n5. The definition of budget also feels self-contradictory. It was defined as the queries towards the world. However, it is later defined as the number of tokens. I believe if number of tokens is the budget limit, then grid search is definitely the best way given infinite running time and running memory."}, "questions": {"value": "What is the definition of complexity here?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7919pG2EUq", "forum": "hlFD8pl4qD", "replyto": "hlFD8pl4qD", "signatures": ["ICLR.cc/2026/Conference/Submission20422/Reviewer_PmiA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20422/Reviewer_PmiA"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20422/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981487780, "cdate": 1761981487780, "tmdate": 1762933861368, "mdate": 1762933861368, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper investigates whether off-the-shelf LLMs can serve as end-to-end designers for sequential optimization problems (SOPs). It introduces WorldGen, a procedurally generated benchmark of optimization 'worlds' with adjustable complexity, and ACE (Actor, Critic, Synthesizer), a dialectical inference-time loop that iteratively refines LLM-generated strategies without retraining. Experiments on synthetic 3-D worlds show ACE often increases success rates versus several prompting and multi-agent baselines, at the cost of higher token usage."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Addresses a timely, underexplored question: LLMs as autonomous designers under query budgets.\n\nProposes a practical, inference-time orchestration (Actor/Critic/Synthesizer) that requires no model fine-tuning.\n\nUses procedural instance generation (WorldGen) to mitigate contamination risks and scale difficulty.\n\nProvides qualitative traces and prompt templates that clarify how ACE operates."}, "weaknesses": {"value": "The details on WorldGen are insufficiently specified and not reproducible from the manuscript: missing generator code/pseudocode, families of functions, parameter distributions, formal criteria for L0/L1/L2, number of sampled worlds per level, and random seeds.\n\nKey experimental details are missing: complete prompt templates and hyperparameters for baselines, LLM sampling settings (temperature/top-p), tokenization/token-counting, and the policy for executing model-generated Python (sandboxing, allowed libraries, timeouts, error handling).\n\nNo comparisons to classical black-box optimizers (e.g., Bayesian optimization with sensible kernels/acquisitions, CMA-ES, multi-start local search, random search) under identical query budgets; without these, practical utility is unclear.\n\nInsufficient ablations: lacks experiments that isolate Actor / Critic / Synthesizer contributions, vary number of dialectical rounds, and control for total token/API budget (token-normalized baselines).\n\nStatistical reporting is weak: small number of trials per world, few confidence intervals or significance tests; aggregate numbers may hide per-instance variability.\n\nLimited scope: experiments are restricted to synthetic 3-D worlds; scalability to higher dimensions, noisy or constrained problems, and real-world SOPs is untested.\n\nSecurity/safety concerns from executing arbitrary code are not addressed in detail (sandboxing, reproducibility, allowed libs), and broader misuse risks are not discussed sufficiently.\n\nThe philosophical (Hegelian) framing is evocative but adds little algorithmic novelty beyond existing critique-and-refine / multi-agent methods; superiority claims over debate-style schemes need stronger formal or empirical support."}, "questions": {"value": "Please release WorldGen (code or detailed pseudocode) as part of the supplementary zip: exact families of functions, parameter distributions, formal definitions of L0/L1/L2, number of worlds per level, and random seeds used for reported experiments.\n\nProvide the Expert Solution code and parameter settings used to set query budgets, with justification for why those budgets are fair baselines.\n\nPublish exact prompt templates for every scheme and the LLM runtime settings (temperature, top-p, max-tokens), plus the method used to count/normalize tokens and calls.\n\nDescribe the Python execution environment: sandboxing approach, allowed libraries, timeouts, failure handling, and how execution errors were treated in scoring.\n\nAdd comparisons to classical optimizers (BO with sensible kernels and acquisition functions, CMA-ES, multi-start local search, random search) under identical query budgets and report success rates, queries-to-solution, and compute/token costs.\n\nProvide ablations that (a) isolate each ACE component (Actor-only, Actor+Critic, Actor+Synthesizer), (b) sweep number of dialectical rounds, and (c) include token-normalized baselines (give single-agent extra tokens equal to ACE's total usage).\n\nIncrease statistical rigor: run more worlds and repeats, report standard errors/95% confidence intervals, and perform significance tests (e.g., paired bootstrap) for main comparisons.\n\nReport wall-clock runtime and monetary cost (API-call) estimates in addition to token counts to assess practical feasibility.\n\nDemonstrate or analyze scalability: results or analysis for higher-dimensional problems (n>3), noisy evaluations, and constrained domains, or clearly state limitations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sOMnOJrcZq", "forum": "hlFD8pl4qD", "replyto": "hlFD8pl4qD", "signatures": ["ICLR.cc/2026/Conference/Submission20422/Reviewer_fQM6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20422/Reviewer_fQM6"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20422/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997920021, "cdate": 1761997920021, "tmdate": 1762933860595, "mdate": 1762933860595, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}