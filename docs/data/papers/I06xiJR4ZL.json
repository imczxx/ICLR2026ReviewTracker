{"id": "I06xiJR4ZL", "number": 24213, "cdate": 1758354197474, "mdate": 1759896776432, "content": {"title": "AI-Assisted Medical Triage Assistant", "abstract": "In disaster situations, rapid and accurate decisionmaking is critical for patient outcomes. The improper application of traditional triage protocols like START and JUMPSTART often results in decision errors such as over-triage and under-triage. In this project, we built an AI decision support system that assists in different emergency triage training scenarios designed to improve accuracy, speed, and reliability. Our system analyzes video, audio, and text from virtual emergency simulations and classifies patients into urgency levels (red, yellow, green), depending on who should be treated first in real time, using GPT-4o with vision, real-time audio, and Retrieval-Augmented Generation (RAG) to follow standard protocols. To evaluate performance, we tested different OpenAI models based on accuracy $A$, average response time $T$, and confidence score $C$, in the context of the same medical-triage simulation data. We found that the o4-mini model consistently gave the best accuracy  A=0.667 with an average response time of  T‚âà4.02¬†s, while gpt-4.1-nano was the fastest with T=0.94¬†s, and gpt-4o maintained the highest confidence score ùê∂=0.836.This highlights the trade-offs between speed ($T$), accuracy ($A$), and confidence ($C$) when using AI for medical triage training. These are just the initial results, and as the research progresses with more training data and simulation runs, we expect these metrics to change and improve, leading to more comprehensive evaluations. We also evaluate how AI-human collaboration impacts accuracy, decision speed, and cognitive load, including performance when AI assistance is withdrawn. By doing this, we can better understand how users interact with AI, identify potential risks, and learn how to improve both training and real-world triage performance.", "tldr": "", "keywords": ["Medical Triage", "AI Decision Support", "Multimodal Learning", "Human-AI Collaboration", "Cognitive Load", "Patients priority"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/243e22c263cc186d02bdf6c9c7ce68f9fca5fb32.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "## Summary\nThis paper explores the use of multimodal large language models (LLMs) to support medical triage, particularly in emergency scenarios. The authors propose an AI-based assistant that integrates visual and textual inputs to assess injury severity and provide triage decisions. While the topic is highly relevant and socially impactful, the paper is still in an early stage of development and does not yet meet the level of completeness expected for ICLR."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "## Strengths\n- The problem addressed‚ÄîAI-assisted triage in medical emergencies‚Äîis important and highly relevant to both AI and healthcare research.  \n- The authors correctly acknowledge that their results are preliminary, showing awareness of the work‚Äôs current limitations."}, "weaknesses": {"value": "## Weaknesses\n- The overall contribution is limited. The main novelty lies in the application rather than in a methodological or theoretical advance.  \n- The benchmarking of three OpenAI models provides minimal analytical depth and limited insight into model behavior.  \n- The experimental setup is based entirely on simulated data; while the *60 Seconds to Survival* simulator is referenced, the similarity between simulated and real-world data is not evaluated or quantified.  \n- The dataset construction and ground-truth generation process are under-described and lack sufficient technical detail.  \n- The related work section is superficial and omits key references to prior efforts on AI-assisted triage, multimodal reasoning, and decision-support systems.  \n- Reported results are minimal and do not include statistical analysis, comparisons to baselines, or significance testing.  \n- Figures need better formatting (e.g., Figure 1 exceeds page boundaries)."}, "questions": {"value": "## Detailed Comments\n\n### Section 2 ‚Äî Related Work\nThis section lacks sufficient engagement with the literature. The paper should reference and position itself relative to existing multimodal medical triage systems, clinical decision-support tools, and prior LLM-based healthcare applications.  \n\n### Section 3.1 ‚Äî Data Collection\nData is collected from a simulator, but the simulator‚Äôs implementation and realism are not well described. Although the *60 Seconds to Survival* game is mentioned, its fidelity and alignment with real-world triage data are not evaluated. Quantitative comparison or expert validation would strengthen the work.  \n\n### Section 3.5 ‚Äî Ground Truth Data\nThe process for generating ground-truth labels is not clearly documented. While physician validation is briefly mentioned, the method for ensuring consistency or inter-rater reliability is not specified.  \n\n### Section 4.3 ‚Äî Results\nThe results are presented in a single table comparing model accuracy, response time, and confidence. This provides a starting point but is insufficient for a strong empirical claim. Future versions should include statistical analysis, confidence intervals, and comparison to non-AI baselines.\n\n- **Line 149:** ‚ÄúWithout AI: Users rely on training alone.‚Äù ‚Äî This is unclear; please clarify what type of training and context this refers to.  \n- **Line 161:** ‚ÄúAlthough we have not yet conducted full experiments‚Ä¶‚Äù ‚Äî The paper should be resubmitted once full experiments are completed.  \n\n### Section 4.4 ‚Äî Discussion\nThe discussion is speculative and focuses on future work rather than substantive analysis. The paper would benefit from reflection on ethical implications, failure cases, and deployment challenges.\n\n### Figures\nFigure 1 overflows page boundaries and should be resized or reformatted."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "cViwFy1FtO", "forum": "I06xiJR4ZL", "replyto": "I06xiJR4ZL", "signatures": ["ICLR.cc/2026/Conference/Submission24213/Reviewer_Mciu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24213/Reviewer_Mciu"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24213/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760526879928, "cdate": 1760526879928, "tmdate": 1762943000440, "mdate": 1762943000440, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "the paper offers a preliminary investigation into the development of a multi-modal AI-assisted triage tool for healthcare. The authors describe first results of benchmarking 3 proprietary LLMs against a simulated dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* The topic of the paper is timely and a good solution (which is well-evaluated on real-world studies) could offer real-world practical benefits"}, "weaknesses": {"value": "* The dataset seems to rely heavily on a single simulated and poorly described dataset. This heavily discounts any measured benefit. The data described in ¬ß3.1 describes input modalities of video and text, but the evaluation data described in ¬ß4.1 describes video, text and audio?\n* Many claims are unreferenced and without sufficient backing\n* Most experiments (those which I think are the most important: ones involving humans) not yet conducted (cf. line 161)\n* Experimental findings offer nothing new: \"The choice of model should depend on the operational choices, whether speed or safety is the higher priority\" (cf. line 238)"}, "questions": {"value": "* Are the models fine-tuned?\n* Data privacy is extremely important in environments such as healthcare. Have you considered that benchmarking against proprietary LLMs may be irrelevant because of data privacy concerns?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "8SUz0IkFwx", "forum": "I06xiJR4ZL", "replyto": "I06xiJR4ZL", "signatures": ["ICLR.cc/2026/Conference/Submission24213/Reviewer_WZeF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24213/Reviewer_WZeF"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24213/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761466520179, "cdate": 1761466520179, "tmdate": 1762942998733, "mdate": 1762942998733, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a multimodal, LLM-assisted triage support system for virtual simulations. It claims to integrate video, audio, and text, use GPT-4o family models with a RAG layer tied to START and JUMPSTART, and compare accuracy, speed, and a vague ‚Äúconfidence‚Äù metric. The dataset is from a ‚Äú60 Seconds to Survival‚Äù simulation with physician-validated labels. The work also sketches three human-AI conditions, including AI withdrawal, but the authors state they have not run full experiments yet. Reported accuracies are in the mid-60% range on an unspecified dataset."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "‚Ä¢\tProblem is important. Triage errors are costly, and training support matters.\n\n‚Ä¢\tClear framing of under- and over-triage, with an explicit weighted error that favors safety. \n\n‚Ä¢\tHuman-AI study design lists three useful conditions to probe over-reliance.\n\n‚Ä¢\tLabels are said to be physician-validated, which is the right direction for clinical tasks."}, "weaknesses": {"value": "‚Ä¢\tMissing core experiments. The paper explicitly says full experiments are not yet conducted. For ICLR, this is disqualifying.\n\n‚Ä¢\tNovelty is thin. The method is essentially LLM + RAG + simple preprocessing, then a model choice trade-off. There is no new algorithm, learning objective, or theory. \n\n‚Ä¢\tEvaluation design is underspecified. The scoring function is an undefined f(A, 1/T, C), and ‚Äúconfidence‚Äù is not defined, calibrated, or validated.\n\n‚Ä¢\tDataset is opaque. The paper does not report size, case diversity, splits, inter-rater reliability, noise, or domain shift. Claims rely on a single simulation source.\n\n‚Ä¢\tBaselines are weak. There is no comparison to protocol-faithful decision trees or classic ML using structured features. No ablations for the RAG component.\n\n‚Ä¢\tReported performance is low for triage. Accuracies around 0.64 to 0.67 with no statistical analysis or calibration are not convincing for a safety-critical classifier.\n\n‚Ä¢\tMultimodal story is superficial. Preprocessing is basic and there is no evidence the vision or audio channels materially help beyond text. \n\n‚Ä¢\tClinical safety, ethics, and deployment are not treated. No discussion of bias, IRB, audit, fail-safes, or on-device constraints.\n\n‚Ä¢\tRelated work is light and cites general GPT-4 essays rather than focused clinical decision support or triage literature."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "CHqQKXZD7U", "forum": "I06xiJR4ZL", "replyto": "I06xiJR4ZL", "signatures": ["ICLR.cc/2026/Conference/Submission24213/Reviewer_CzbJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24213/Reviewer_CzbJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24213/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761680930728, "cdate": 1761680930728, "tmdate": 1762942997930, "mdate": 1762942997930, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents an AI-assisted triage support system that uses multimodal data:video, audio, and text, from virtual simulations to classify patients into red, yellow, or green urgency levels following START/JUMPSTART protocols. It benchmarks GPT-4o, GPT-4.1-nano, and o4-mini models, comparing accuracy, inference speed, and confidence. Authors also discuss human-AI collaboration and withdrawal experiments to measure reliance. Overall reads like a feasibility or concept demonstration, not yet a solid technical study."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The topic is relevant and high-impact for emergency response. Multimodal setup is realistic, and authors attempt to connect AI reasoning to training scenarios. Preliminary comparisons of GPT variants provide some insight into performance trade-offs."}, "weaknesses": {"value": "No real experiments, no ablation, and minimal quantitative evidence. Collaboration results are narrative, not measured. Novelty is weak since existing architectures are reused. Dataset and reproducibility details missing. Writing quality and structure reduce clarity.\n\nThe methodology is basic and not validated. Most experiments are simulated with no human testing. Metrics make sense but it‚Äôs unclear how they are combined or statistically analyzed. The study feels more exploratory than scientific, and the claims are not strongly supported.\n\nWriting is repetitive and sometimes awkward, with inconsistent phrasing and redundant figure descriptions. Figures and tables are simplistic. Missing important dataset details and experiment context. The overall flow is okay but lacks polish.\n\nAddresses an important area but novelty is low. The system mainly integrates existing LLMs with a retrieval layer. The human-AI collaboration discussion is largely theoretical. Without stronger experiments or user validation, the work doesn‚Äôt meet ICLR technical depth."}, "questions": {"value": "How large and diverse is the dataset? How is accuracy computed, per scenario or per frame? Any plan to validate with actual human trainees? How is the retrieval module grounded in the protocols? Are there any safeguards for errors or bias in medical contexts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rIrVQCXa7V", "forum": "I06xiJR4ZL", "replyto": "I06xiJR4ZL", "signatures": ["ICLR.cc/2026/Conference/Submission24213/Reviewer_hedX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24213/Reviewer_hedX"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24213/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761946565796, "cdate": 1761946565796, "tmdate": 1762942997653, "mdate": 1762942997653, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}