{"id": "lSGFavwaAm", "number": 24179, "cdate": 1758353732579, "mdate": 1759896778398, "content": {"title": "Improving LLM Reasoning via Symbolic Inference over Logic Graphs", "abstract": "Large language models (LLMs) exhibit strong language understanding but remain limited in logical reasoning, particularly in multi-hop inference involving complex contextual dependencies. \nWe propose Graph-based Planned Reasoning (GPR), a neuro-symbolic framework that enhances LLM reasoning by organizing the process into structured stages.\nGPR builds a logic graph to capture fine-grained symbolic relations from natural language context, then leverages Planner to generate a goal-directed reasoning strategy. \nA dedicated Reasoner conducts step-wise symbolic inference along this plan, while Critic modules act as internal validators, checking and revising the logic graph and the final inference when necessary. \nThis design enables GPR to perform faithful, interpretable reasoning while maintaining robustness against irrelevant or misleading information. \nExperiments across multiple logical reasoning benchmarks demonstrate that GPR consistently outperforms existing reasoning baselines and remains robust under noisy conditions.", "tldr": "", "keywords": ["Logical reasoning", "Large language models", "Neuro-symbolic methods", "Logic graphs", "Symbolic inference"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/09e1cf3e0c777340a10acdcb2b82dd5c320c77e2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes Graph-based Planned Reasoning (GPR), a framework comprising three main modules: Logic Graph Construction, Reasoning Plan Formulation, and Reasoning with Logic Graph and Plan. Extensive experiments across a wide range of benchmarks and diverse LLMs demonstrate that GPR achieves strong performance, maintains high stability, and exhibits robustness to irrelevant information."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed methods are novel and interesting.\n\n- GPR achieves consistent empirical improvements over baseline methods across multiple benchmarks and model architectures.\n\n- The experiments and analyses are comprehensive, and the availability of code enhances reproducibility."}, "weaknesses": {"value": "- The methodology lacks motivation and design rationale. The paper would benefit from explaining why each design choice was made before introducing the method in detail.\n\n- While each component is clearly described, the paper does not sufficiently explain how the components interact as a unified system. As a result, the overall workflow remains somewhat unclear.\n\n- The error analysis is valuable, but the paper could be strengthened by discussing how future research might build upon these findings or what insights they offer for subsequent work."}, "questions": {"value": "- What are the design motivations behind each component?\n\n- How were the node and edge types defined?\n\n- Why were only two symbolic rules chosen when many alternatives exist?\n\n- Which components depend on LLMs, and which are implemented independently? (Related to the methodological clarity mentioned above.)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4te0HsEJZI", "forum": "lSGFavwaAm", "replyto": "lSGFavwaAm", "signatures": ["ICLR.cc/2026/Conference/Submission24179/Reviewer_j6Rz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24179/Reviewer_j6Rz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24179/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761206593497, "cdate": 1761206593497, "tmdate": 1762942978247, "mdate": 1762942978247, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper  proposed Graph-based Planned Reasoning (GPR), a neuro-symbolic framework that enhances LLM reasoning by organizing\nthe process into structured stages."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The paper-writing is largely good."}, "weaknesses": {"value": "1. It is quite clear that the application scope of GPR is limited. The issue of adaptation itself requires the presence of a fairly distinct logical structure, whereas most reasoning problems do not exhibit such characteristics. If the paper’s claim were to enhance logical reasoning, that would seem more reasonable—but the current contribution statement clearly is not.\n\n2. The motivation is unconvincing. Issues such as *irrelevant content distracts* and *disordered premises* mainly appear in simple problems, whereas the difficulty of more complex reasoning tasks (e.g., IMO-level problems) lies elsewhere. Moreover, with the emergence of large reasoning models, these problems can be mitigated through long-cot cognitive mechanisms. Therefore, this part of the claim feels somewhat outdated and needs to be supported by more recent work.\n\n3. No statement of limitations is provided."}, "questions": {"value": "It is essential to clearly specify the adaptation scope of GPR, as this is a critical point. At present, it appears that GPR imposes very strict constraints on structural aspects.\nThe examples presented in Figures 1 and 2 are also overly simplistic—this might have been acceptable for research conducted two years ago (like ACL2024), but not for ICLR2026."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Pt1IrlYGvD", "forum": "lSGFavwaAm", "replyto": "lSGFavwaAm", "signatures": ["ICLR.cc/2026/Conference/Submission24179/Reviewer_HhWq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24179/Reviewer_HhWq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24179/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761396248796, "cdate": 1761396248796, "tmdate": 1762942977900, "mdate": 1762942977900, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper targets on the limited ability of LLM on logical reasoning, particularly in multi-hop inference involving complex contextual dependencies.\nTo mitigate the limitation, the paper proposes a neural-symbolic workflow that enhances LLM reasoning by organizing the process into structured stages.\n\nThis design enables to perform faithful, interpretable reasoning while maintaining robustness against irrelevant or misleading information.\nThe empirical experiments also support this statement."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces a delicately-designed and thoughtfully motivated workflow based on logic graphs to enhance the logical reasoning capabilities of LLMs.\n2. The approach demonstrates strong empirical performance, excelling not only in prediction accuracy but also in robustness.\n3. The experiments evaluate a range of powerful LLMs, including both closed-source and open-source models."}, "weaknesses": {"value": "1. The evaluation is limited to powerful LLMs, leaving the applicability to smaller models (e.g., Qwen3-7B/1.5B) underexplored. The benefits demonstrated on larger LLMs may not directly transfer to smaller ones. For instance, it remains unclear whether smaller LLMs can effectively understand, parse, or verify the constructed logic graphs, which is crucial in this workflow.\n2. The workflow has been evaluated exclusively on logical reasoning benchmarks that are closely tied to the design of logic graphs. However, it remains unclear whether this approach can improve general reasoning abilities in tasks that do not involve explicit logic chains, such as mathematical problems typically addressed by RL-based post-training techniques."}, "questions": {"value": "1. In Table 3, it appears that several neuro-symbolic baselines, as well as the proposed GPR, occasionally undermine the performance of the LLMs.\nCould you elaborate on the possible reasons for this observation? Do these results stem from specific limitations or shortcomings of the neuro-symbolic baselines themselves, or do they highlight broader challenges associated with the neuro-symbolic routine as a whole?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "hfnB5aEHM0", "forum": "lSGFavwaAm", "replyto": "lSGFavwaAm", "signatures": ["ICLR.cc/2026/Conference/Submission24179/Reviewer_1ThG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24179/Reviewer_1ThG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24179/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761863281121, "cdate": 1761863281121, "tmdate": 1762942977617, "mdate": 1762942977617, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Graph-based Planned Reasoning (GPR), a neuro-symbolic framework designed to improve the logical reasoning capabilities of large language models (LLMs). The core contribution is a structured, multi-stage reasoning process. GPR first constructs a logic graph from natural language to capture symbolic relationships. It then uses a Planner module to create a goal-directed reasoning strategy, a Reasoner for step-wise symbolic inference, and a Critic module to validate and revise the process. The authors claim this approach leads to more faithful, interpretable, and robust reasoning, demonstrating state-of-the-art performance on several logical reasoning benchmarks and showing resilience to noisy, irrelevant information."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "*   **Novel Framework:** The proposed GPR framework presents a well-structured and intuitive neuro-symbolic approach to complex reasoning, breaking it down into distinct, manageable stages (graph creation, planning, reasoning, and critique).\n*   **Interpretability and Faithfulness:** By externalizing the reasoning process into a symbolic graph and a clear plan, the method offers a more transparent and potentially more reliable alternative to end-to-end black-box reasoning.\n*   **Robustness Evaluation:** The paper includes experiments specifically designed to test the system's robustness against irrelevant facts, which is a practical and important consideration for real-world applications.\n*   **Comprehensive Experiments:** The authors evaluate their method across four reasoning benchmarks and test it with a good range of different LLMs, comparing it against both prompting and other neuro-symbolic techniques."}, "weaknesses": {"value": "*   **Justification for Graph Formalism:** The paper could better articulate the unique advantages of using a graph formalism over more traditional logical formalisms with inference rules.\n*   **Empirical Support for the Critic Module:** The ablation study (Table 4) shows a very small performance drop when the Critic is removed. This raises questions about its necessity and impact. The claims about its importance are not strongly supported without a statistical significance analysis (e.g., standard deviations or confidence intervals) and a more detailed breakdown of how often and in what ways the critic intervenes.\n*   **Generalization Beyond Benchmarks:** The evaluation is confined to academic benchmarks where the context is often a clean, logical prelude to the question. The paper would be stronger if it discussed or demonstrated how GPR would handle more realistic scenarios where the required conceptual granularity varies and is not explicitly laid out.\n*   **Lack of Detailed Examples:** The paper lacks concrete examples of the logic graphs and reasoning trajectories for specific problems. Including these would significantly improve the reader's understanding of the system's inner workings.\n*   **Potential for Simplification:** It's unclear why the graph construction does not take the question into account. Building a context- and question-aware graph might simplify the architecture by reducing the need for a separate Planner module.\n*   **Inference Cost Analysis:** The GPR framework adds multiple LLM calls for planning and critiquing. A comparison of the total inference budget (e.g., tokens used) against other methods would provide a fairer assessment of its efficiency."}, "questions": {"value": "1.  Could you elaborate on the unique advantages of the graph-based formalism compared to representing the problem using a more traditional logical formalism (e.g., Prolog or first-order logic) and then using an off-the-shelf solver?\n2.  How is the \"semantic alignment\" of the logic graph verified? Are there experiments to validate that the graph accurately captures the semantics of the natural language context?\n3.  Regarding the Critic module: How often does it trigger updates to the graph or reasoning plan in your experiments? What are the most common types of errors it corrects? Given the small performance difference in the ablation study, could you provide a statistical significance analysis?\n4.  Could you provide a comparison of the total computational cost (e.g., total tokens used across all LLM calls) for GPR versus the baseline methods?\n5.  Is the logic graph constructed based only on the context, or does it also take the question into account? If it's only the context, what is the rationale behind this choice? Could incorporating the question during graph construction potentially eliminate the need for the Planner module?\n6.  How do you envision this approach generalizing to tasks where the necessary concepts are not as neatly defined as in the benchmarks used (e.g., reasoning over scientific literature)?\n7.  In the error analysis, what does the \"standard\" condition refer to? Also, could you clarify why a system like LogicLM, which relies on a symbolic reasoner, would not have a Reasoning Consistency Error (RCE) of zero?\n\n\nTo improve the clarity and impact of the paper, I would also suggest the following:\n\n*   **Include Concrete Examples:** Please include one or two detailed examples that walk the reader through the entire GPR process for a specific query. This would involve showing the initial context, the generated logic graph, the plan from the Planner, the step-by-step inference from the Reasoner, and any interventions from the Critic. This would make the system much more understandable.\n*   **Visualize the Logic Graph:** Visualizations of the logic graphs would be extremely helpful in understanding the symbolic representation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "FZqltUjf8M", "forum": "lSGFavwaAm", "replyto": "lSGFavwaAm", "signatures": ["ICLR.cc/2026/Conference/Submission24179/Reviewer_tZtA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24179/Reviewer_tZtA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24179/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895324848, "cdate": 1761895324848, "tmdate": 1762942977197, "mdate": 1762942977197, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}