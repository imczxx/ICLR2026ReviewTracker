{"id": "aR7jXICvcL", "number": 19185, "cdate": 1758294232160, "mdate": 1759897053511, "content": {"title": "SA-PEF: Step-Ahead Partial Error Feedback for Efficient Federated Learning", "abstract": "Biased gradient compression with error feedback (EF) reduces communication in federated learning (FL), but under non-IID data the residual error can decay slowly, causing gradient mismatch and stalled progress in the early rounds. We propose step-ahead partial error feedback (SA-PEF), which integrates step-ahead (SA) correction with partial error feedback (PEF). SA-PEF recovers EF when the step-ahead coefficient $\\alpha=0$ and step-ahead EF when $\\alpha=1$. For non-convex objectives and $\\delta$-contractive compressors, we establish a second-moment bound and a residual recursion that together guarantee convergence to stationarity under heterogeneous data and partial client participation. The resulting rates match standard non-convex Fed-SGD guarantees up to constant factors, achieving $O((\\eta\\\\,\\eta_0TR)^{-1})$ convergence to a variance/heterogeneity floor with fixed inner step size. Our analysis reveals a step-ahead-controlled residual contraction $\\rho_r$ that explains the observed acceleration in the early training phase. Guided by our trade-off analysis, we select a fixed step-ahead weight $\\alpha$ near the theory-predicted optimum that balances SAEF’s rapid warm-up with EF’s long-term stability. Experiments across diverse architectures and datasets show that SA-PEF consistently attains target accuracies faster than EF.", "tldr": "We propose SA-PEF, a step-ahead partial error-feedback method for federated learning that mitigates early gradient mismatch on non-IID data, maintains late-stage stability, and provably converges under biased compression.", "keywords": ["Federated learning", "communication-efficient training", "error feedback", "sparsification", "non-IID data", "partial participation", "local SGD", "non-convex convergence"], "primary_area": "optimization", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/04219a99d1161cd434d4a5ebc1e77a2bda2b6313.pdf", "supplementary_material": "/attachment/171d108602c163712c68a2b6abb390398dd3f62f.zip"}, "replies": [{"content": {"summary": {"value": "The works presents a new combination of compression and error feedback with local steps, for nonconvex distributed optimization and federated learning"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "This is an important topic and new methods with theoretical guarantees are very welcome."}, "weaknesses": {"value": "1) About the SOTA: \"ProxSkip and its variance-reduced variants analyze local steps with general (including contractive) compressors via communication skipping and compressed exchanges\".  Proxskip, more exactly Scaffnew, is an algorithm implementing local training, it should be mentioned after Scaffold in the previous paragraph. There is no compression in Proxskip/Scaffnew. There has been later works on combining Scaffnew with compression: \n\n* CompressedScaffnew in Condat et al. \"Provably Doubly Accelerated Federated Learning:\nThe First Theoretically Successful Combination of Local Training and Communication Compression\"\n\n* TAMUNA, which extends CompressedScaffnew to partial participation in Condat et al. \"TAMUNA: Doubly accelerated distributed optimization with local training, compression, and partial participation\"\n\n* LoCoDL, which uses arbitrary unbiased compressors, not just permutation-based sparsifiers, in Condat et al. \"LoCoDL: Communication-efficient Distributed Learning with Local training and Compression\", ICLR 2025\n\nThese works focus on convex settings, acceleration from local training is lost in nonconvex settings, to the best of my knowledge. \n\n2)  \"This class includes many commonly used compressors, such as Top-k, Rand-k\". If you want to make an unbiased compressor, such as rand-k, contractive, you have to scale it. \n\n3) You have to be precise. When you say that SA-PEF reverts to EF when $\\alpha=0$, is it EF21? The precise relationship should be discussed.\n\n4) Line 267: You should not use $\\xi$ for both the random realization in the stochastic gradient and the noise. Use a different symbol. \n\n5) Assumption 3 is very restrictive. Methods such as EF21 do not require such an assumption.\n\n6) \"Our result matches the standard nonconvex picture for biased compression.\" This discussion deserves much more details. I am familiar with compression, error feedback, and local training, but just by looking at the result, I cannot interpret it. A table comparing existing results with the new ones would be very welcome. And there should be a whole discussion of how $\\delta$, $K$, $\\alpha$ and other parameters influence the convergence speed, according to the theoretical analysis."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DCKF4leFg2", "forum": "aR7jXICvcL", "replyto": "aR7jXICvcL", "signatures": ["ICLR.cc/2026/Conference/Submission19185/Reviewer_xyaS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19185/Reviewer_xyaS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760875747850, "cdate": 1760875747850, "tmdate": 1762931186071, "mdate": 1762931186071, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper tackles communication-efficient FL under non-IID data by refining error-feedback (EF) with biased compressors, which can stall early due to residuals aligning with local gradients and causing gradient mismatch. The proposed Step-Ahead Partial Error Feedback (SA-PEF) introduces a per-round weight $\\alpha\\in[0,1]$ to partially preview the EF residual: each client shifts by $\\alpha e_r^{(k)}$ before local SGD and carries $(1-\\alpha)e_r^{(k)}$ via standard EF, recovering EF at $\\alpha=0$ and SAEF at $\\alpha=1$. The authors prove non-convex convergence with local steps, partial participation, and $\\delta$-contractive compressors, achieving $O(1/(TR))$ to a floor; compression effects enter through $(1-1/\\delta)$ and a new residual-contraction factor $\\rho_r<1$. An optimal $\\alpha_r^*$ (near 1 when local work is small) minimizes $\\rho_r$, explaining faster early progress than EF while retaining EF’s stability. Empirically, on CIFAR-10/100 and Tiny-ImageNet with Top-$k$ sparsification and $K=100$ clients, SA-PEF reaches target accuracy in fewer rounds and fewer bits than EF/SAEF; SAEF often plateaus, whereas SA-PEF continues improving. A gradient-mismatch probe shows SA-PEF keeps mismatch near zero throughout training. Overall, SA-PEF blends step-ahead warm-up with EF stability, improving accuracy-communication trade-offs across datasets and settings."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Novel Algorithmic Idea: SA-PEF is a simple yet effective interpolation between two known techniques (EF and SAEF). Introducing a tunable $\\alpha$ for partial residual preview is an elegant way to control the early-stage acceleration vs. noise trade-off. The method requires minimal changes to existing federated SGD with error feedback, making it a practical drop-in enhancement.\n - Theoretical Rigor: The paper presents a nontrivial convergence analysis under realistic FL conditions. Theorem 1 (with proof in Appendix) covers smooth nonconvex objectives with local SGD and partial client sampling, assuming $\\delta$-contractive compressors. The bounds recover standard FedSGD rates $O((\\eta\\eta_0TR)^{-1})$ up to constants, and explicitly quantify the effect of $\\alpha$ via a residual contraction $\\rho_r<1$. This provides insight into how and why a partial preview improves convergence (smaller residual error constants). To our knowledge, this is the first formal analysis of step-ahead error feedback in a federated/local-updates setting with non-IID data and biased compression. The theory also extends to partial participation (Remark 1), transparently showing the $1/p$ slow-down in optimization as usual.\n - Empirical Validation: Experiments are extensive and well-designed. The authors test across multiple benchmarks (CIFAR-10/100, Tiny-ImageNet) and models, with both IID and strongly non-IID partitions. They compare against relevant baselines (FedAvg, EF, SAEF, CSER) under identical hyperparameter settings, isolating the effect of the SA-PEF modification. The results consistently favor SA-PEF: target accuracies are reached in fewer rounds and less communication. Notably, SA-PEF avoids the late-stage plateaus seen in SAEF, confirming its stability advantage. The gradient-mismatch metric in Figure 3 further supports the claim that partial preview keeps training trajectories well-aligned. The paper also reports thorough implementation details and reproducibility materials (configs, code) in the appendix, which is commendable.\n - Clarity and Insights: The authors clearly explain the motivation and algorithm, including intuitive benefits of partial preview (e.g. “removes most early-round mismatch while injected noise decays as $|e_r|$ shrinks”). The theoretical analysis yields practical takeaways: for small local-work $s_r=\\eta_rLT$, the optimal $\\alpha^*_r\\approx 1/(1+12s_r^2)$ is near 1, giving the strongest contraction. This yields a concise interpretation: SA-PEF improves initial descent constants, leading to a steeper objective decrease under the same stepsizes. These insights bridge theory and experiment nicely."}, "weaknesses": {"value": "- Hyperparameter $\\alpha_r$ Selection: SA-PEF introduces the new parameter $\\alpha$ (or schedule ${\\alpha_r}$). The paper relies on choosing a fixed $\\alpha$ “near the theory-predicted optimum”, but offers little guidance on how to pick $\\alpha$ in practice. The theoretical $\\alpha_r$ depends on unknown smoothness constants and local-work $s_r$, and the paper uses a constant $\\alpha$ across empirical training. It would be helpful to see sensitivity analysis: how critical is the exact value of $\\alpha$? If $\\alpha$ is set too large the residual contraction worsens; if too small, warm-up is limited. The paper mentions decaying $\\alpha_r$ as future work but does not experiment with any schedule (beyond “near-optimal fixed”). In practice, tuning $\\alpha$ adds overhead, and it is unclear how robust the method is to mis-specification.\n - Theoretical Assumptions and Complexity: The convergence proof requires several technical conditions (smoothness, bounded gradient variance, and a small initial step condition $s_0\\le1/8$). While standard, these assumptions may limit the direct applicability of the stated rates. The bounds also involve many constants ($C_\\sigma, C_\\nu, E_{\\max}$, etc.), making it hard to gauge practical significance. In addition, the conclusions hinge on $\\Theta\\le1/2$ (see Theorem 1). It may be worth clarifying in the paper whether these conditions are reasonable for typical FL hyperparameters. Moreover, the improved residual contraction factor $\\rho_r$ is derived assuming $s_r\\le1/8$; if larger local steps are used, it is unclear if SA-PEF still helps.\n - Limited Baseline Comparisons: The experimental evaluation, while solid, omits some potentially relevant baselines. For example, adaptive compression methods (DIANA/MARINA) or other gradient sparsification schemes are not considered. While EF, SAEF, and CSER are appropriate comparisons, it would strengthen the claim to include at least one variance-reduced or unbiased compressor scheme (e.g. QSGD) to contextualize performance. Similarly, the interaction of SA-PEF with other heterogeneity mitigation techniques (FedProx, SCAFFOLD, FedDyn, etc.) is unexplored. It is unclear whether SA-PEF could be combined with those methods, or if its benefits persist in their presence.\n - Scope of Experiments: The paper focuses exclusively on vision benchmarks with ResNets. It would increase confidence if at least one non-vision task or a larger-scale dataset were tested. Although the chosen datasets (CIFAR-10/100, Tiny-ImageNet) cover increasing complexity, they are still relatively small. The gains might differ on more complex or larger-scale problems (e.g. NLP tasks, larger models). Additionally, all compressors tested are Top-$k$; it would be useful to know if SA-PEF helps with quantization or other biased compressors (though theory permits any $\\delta$-contractive operator).\n - Marginal Gains in Mild Regimes: From the presented results, the benefits of SA-PEF are largest under extreme compression and heterogeneity (e.g. Top-1%, $\\gamma=0.1$). In more moderate settings (less compression or more IID data), SA-PEF’s advantage over EF might be smaller. The paper should clarify whether SA-PEF is recommended primarily for such challenging regimes, and whether there is any scenario where it might underperform (e.g. if $\\alpha$ is chosen poorly)."}, "questions": {"value": "1. Can you provide more insights on the theoretical selection of $\\alpha_{r}$ without knowing implicit constant including $s_r$? Empirically what is the selection of the fixed $\\alpha$ value in each experiment setting? How sensitive are results to this choice? Did you experiment with decaying $\\alpha_r$ over rounds (e.g. larger early, then smaller) as suggested by your “moderate or decaying” note? Showing results of ablation studies on different $\\alpha$ and $\\alpha_r$ schedules would be informative.\n2. The main result hinges on $\\Theta\\leq\\frac{1}{2}$ and $s_{0}(s_{r})\\leq\\frac{1}{8}$. Can you give practical sufficient conditions in terms of hyperparameters (such as $\\eta,\\eta_{0},T,\\delta,K$, etc.) that ensure this holds, and confirm numerically that your chosen hyperparameters satisfy them? How does the residual contraction factor $\\rho_r$ behave if $s_r$ or $\\Theta$ exceeds the stipulated bound? What will be the corresponding convergence results? Empirically do you observe degradation or instability? Is there a modified schedule (e.g., shrinking $\\ta_0$ or $\\alpha_r$) that restores $\\rho_r<1$?\n3. You mention in conclusion that integrating SA-PEF with adaptive optimizers or momentum is future work. Do you have any preliminary insights on this? Also, could SA-PEF be combined with control-variate methods like SCAFFOLD or MARINA? Would the partial preview idea remain effective in those contexts?\n4. While the theory allows any $\\delta$-contractive compressor, the experiments only show Top-$k$ sparsification. Have you tried SA-PEF with quantization (e.g. QSGD) or other biased compressors? Does the step-ahead mechanism provide similar benefits there?\n5. How does SA-PEF perform when data is IID across clients, or when compression is mild? The appendix mentions IID control experiments; could you summarize whether SA-PEF still helps, or if it simply matches EF in those cases? Theorem 1 implies a $1/p$ slow-down for participation rate $p$. In practice, how does SA-PEF behave when $p$ is very low (e.g. $p<0.1$)? Is the advantage over EF maintained at very small participation fractions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "dN5FIdEPXY", "forum": "aR7jXICvcL", "replyto": "aR7jXICvcL", "signatures": ["ICLR.cc/2026/Conference/Submission19185/Reviewer_WBBa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19185/Reviewer_WBBa"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761533382480, "cdate": 1761533382480, "tmdate": 1762931185747, "mdate": 1762931185747, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper studies federated learning with **biased uplink compression** and **multiple local SGD steps** (a setting where,as authors claims, vanilla error feedback degrades or diverges). It proposes **SA-PEF** (“Step-Ahead Partial Error Feedback”), which sends a fraction $\\alpha_r\\in[0,1]$ of the *next* client update together with the current compressed residual, modifying the residual recursion (Eq. (12)–(15)) and tightening the residual contraction factor (Lemma 4) relative to EF. Under $L$-smoothness, bounded stochastic variance $\\sigma^2$, and a standard gradient dissimilarity parameter $\\nu^2$ (Assumptions 1–3), **Thm. 1** proves a non-convex rate\n$$\n\\frac{1}{R}\\sum_{r=0}^{R-1}\\mathbb{E}\\|\\nabla f(w_r)\\|^2\n\\le\n\\mathcal{O}\\left(\\frac{f(x_0)-f^\\star}{p\\,\\eta\\,\\eta_0\\,T\\,R}\\right)\n+\\tilde{\\mathcal{O}}\\left(\\frac{\\sigma^2}{m}+\\left(1-\\frac{1}{\\delta}\\right)(\\sigma^2+\\nu^2)\\right).\n$$\n\nwith partial participation fraction $p$ and $\\delta$-contractive compressor; the leading $1/(p\\eta\\eta_0TR)$ term matches EF up to constants, while the step-ahead choice $\\alpha_r^\\star=\\frac{2s_r}{1+12s_r^2}$ (with $s_r=\\eta_rLT$) reduces the residual contraction constant $\\rho_r$ compared to EF (Lemma 4, Prop. 1). Empirically, on CIFAR-10/100 and Tiny-ImageNet with Top-$k$ sparsification and $p\\in\\{0.1,0.5,1.0\\}$, SA-PEF typically reaches target accuracy in fewer rounds (and fewer bits) than EF/CSER and tracks SAEF without late-stage plateaus (Figs. 1,4–7; fairness/tuning protocol specified)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "- **Clear algorithmic modification and analysis.** The step-ahead mechanism is precisely defined (Eq. (12)–(15)) and its effect on the residual is quantified via a refined contraction factor $\\rho_r$, including the analytic optimum $\\alpha_r^\\star$ (Lemma 4).\n- **Non-convex convergence with partial participation.** Thm. 1 extends to client sampling; the averaged bound explicitly shows the **$1/p$ rounds slowdown**, a $1/m$ variance reduction for mini-batch noise, and residual-induced floors scaling with $(1-1/\\delta)$. The analysis explains EF stalling when $p$ is small and compression is aggressive (Remark on $\\rho_r^{\\mathrm{PP}}$).\n- **Experimental protocol is unusually explicit and fairness-minded.** Shared grids, matched bit budgets, shared sampling seeds, and reporting **accuracy vs. rounds and vs. communicated GB** are specified (including how Top-$k$ bit-cost is computed).\n- **Breadth of settings.** Results span multiple datasets, heterogeneity levels (Dirichlet $\\gamma$), participation rates $p$, and compression levels; IID controls and $\\alpha$ ablations are included (App. B; Figs. 4–8).\n- The paper includes a valuable diagnostic analysis of gradient mismatch (Sec. 5.3, Fig. 3). This provides strong empirical evidence for *why* the partial step-ahead mechanism works, showing it effectively keeps the mismatch low and stable throughout training, in contrast to both pure EF and SAEF.\n- The experimental evaluation (Sec. 5) is comprehensive in terms of testing under difficult FL conditions, including high data heterogeneity ($\\gamma=0.1$) and low client participation rates ($p=0.1$), which are common bottlenecks for many FL algorithms."}, "weaknesses": {"value": "- **Missing key baselines / positioning.** Two closely related works—**Fed-EF** (error feedback with local steps and biased compression) by Li & Li (2022) and **SCAFCOM/SCALLION** (Huang, Li & Li, 2023)—are not compared experimentally nor discussed in depth. Li & Li analyze EF with local steps and partial participation and show when SAEF can diverge while EF remains stable; Huang et al. present algorithms supporting **arbitrary heterogeneity, partial participation, and local updates**, with unbiased and biased compressors (via momentum), and emphasize avoiding extra assumptions on compressor errors. \n\nHuang, Xinmeng, Ping Li, and Xiaoyun Li. \"Stochastic controlled averaging for federated learning with communication compression.\" _arXiv preprint arXiv:2308.08165_ (2023).\n\nLi, Xiaoyun, and Ping Li. \"Analysis of error feedback in federated non-convex optimization with biased compression.\" _arXiv preprint arXiv:2211.14292_ (2022).\n\n\n- **No improvement in the leading complexity term.** Thm. 1’s leading rate scales as $\\mathcal{O}\\big((p\\,\\eta\\,\\eta_0TR)^{-1}\\big)$—**identical to EF up to constants**; the benefit is strictly via a smaller $\\rho_r$ constant (and thus smaller residual-induced floors). The paper should state explicitly that there is **no asymptotic speedup**, only better constants.\n- **Assumptions appear not relaxed vs. EF; possibly stricter than some alternatives.** SA-PEF relies on **gradient dissimilarity** (Assumption 3, parameter $\\nu$) and $\\delta$-contractive compressors. In contrast, Huang et al. claim convergence under smoothness and bounded variance **without dissimilarity** for their unbiased variant, and accommodate biased compression with momentum control (SCAFCOM). The manuscript should clarify whether its assumptions are weaker/stronger than these and why they are necessary.\n- **Partial-participation constants opaque.** The PP bound introduces $\\Theta_{\\mathrm{PP}}$ and constants $C_\\sigma,C_\\nu$ depending on $(\\delta,\\alpha_r,s_r)$, but their **explicit forms and practical ranges** are not fully enumerated; the condition $\\Theta_{\\mathrm{PP}}\\le \\tfrac12$ is asserted but not instantiated with realistic hyperparameters (Thm. 1, App. A).\n- **Ablations are incomplete for $\\alpha$.** While constant-$\\alpha$ sweeps are mentioned, there is no **systematic sensitivity** across $(T,p,\\delta)$ to validate the theory-suggested $\\alpha_r^\\star(s_r)$, nor schedules that adapt $\\alpha_r$ as $s_r$ changes. This makes it hard to attribute gains specifically to the theoretical mechanism.\n- **Missing robustness checks.**  Error bars or multi-seed statistics are not shown in the visible figures; the paper states shared seeds and fairness controls but does not report mean±std or significance. \n- **Scale and wall-clock accounting.** Experiments fix $K=100$, $R=200$, and do not report **wall-clock** or the extra compute/latency due to step-ahead packing; downlink is omitted (stated identical across compressed methods), but a **time-to-accuracy** analysis would strengthen claims.\n- The work does not solve the fundamental limitation of error feedback under partial participation. The analysis (App. A.3) acknowledges that SA-PEF inherits the same $\\sqrt{n/m}$ slowdown factor (using notation from Li & Li (2023), where $n$ is total clients and $m$ is participating clients) identified by Li & Li (2023). This limitation arises because in partial participation, inactive clients do not update their error accumulators. When an inactive client rejoins training after several rounds, the error it feeds back is \"stale\"—it corresponds to the compression error from a much older model state. Applying this stale error correction to the current gradient update can misdirect the optimization process, leading to the theoretically predicted slowdown. This \"stale error compensation\" effect is a known drawback of the EF mechanism in FL, which competing methods like SCAFCOM (Huang et al., 2024) are specifically designed to overcome by using control variates that evolve even for inactive clients. SA-PEF is thus an incremental improvement on EF, rather than a solution to its core structural problems in the partial participation setting.\n\n### Formatting & Presentation Issues\n- Some constants/conditions are introduced but not instantiated numerically (e.g., $\\Theta_{\\mathrm{PP}}$, $C_\\sigma,C_\\nu$).\n- Figures in the appendix appear without uncertainty bands and with small fonts in the visible snippets; ensure readability and add error bars where possible (Figs. 4–7).\n- Minor: ensure consistent notation for participation ($p$ vs. $q$) and list **all** hyperparameters actually chosen per run (not just grid ranges).\n- The figures are generally clear but could be improved for accessibility by using distinct markers in addition to colors for each method. This would aid in readability, especially for black-and-white prints or for readers with color vision deficiency."}, "questions": {"value": "1) **Comparisons to Fed-EF and SCAFCOM.** Could you please position SA-PEF relative to SCAFFOLD-based methods for compressed FL, such as SCAFCOM (Huang et al., 2024)? SCAFCOM claims to handle heterogeneity and partial participation without the slowdown factor inherent to EF, and with better complexity. What are the advantages of improving the EF framework with SA-PEF over adopting this alternative approach? Please add experiments (same datasets, $p,T,\\delta$) against Li & Li (2022) and Huang et al. (2023), and **tabulate assumptions** (need for gradient dissimilarity; compressor requirements), **rates**, and **constants**. If SA-PEF’s leading rate equals EF’s, where exactly are the constant-level gains in practice largest? \n2) **$\\alpha$-sensitivity and scheduling.** Please provide $(\\alpha,T,p,\\delta)$ sweeps and a schedule approximating $\\alpha_r^\\star(s_r)$ from Lemma 4, reporting rounds-to-target and **bits & wall-clock**. Does adapting $\\alpha$ materially improve over the best constant $\\alpha$?  \n3) **Constants and feasibility of conditions.** Expand Thm. 1 with explicit expressions for $C_\\sigma,C_\\nu,\\Theta_{\\mathrm{PP}}$; instantiate them for your default $(\\eta,\\eta_0,T,p,\\delta)$ to verify $\\Theta_{\\mathrm{PP}}\\le1/2$ numerically and to clarify the regimes where $\\rho_r^{\\mathrm{PP}}<1$ is guaranteed.  \n4) **Robustness.** Please add results **multi-seed error bars**.\n5) The theoretical analysis for partial participation (PP) predicts a significant slowdown, yet the empirical results at a low participation rate ($p=0.1$ in Fig. 1) appear strong. Can you provide more insight into this theory-practice gap? Is it an artifact of the analysis being loose, or were the experimental settings (e.g., number of rounds, heterogeneity level) not challenging enough to expose this slowdown?\n6) Could you provide an ablation study showing how the final accuracy or rounds-to-target varies with different fixed values of the step-ahead coefficient $\\alpha_r \\in [0, 1]$? This would help practitioners understand the tuning sensitivity of SA-PEF."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "No ethics concerns identified based on the manuscript. The work uses standard public benchmark datasets for fundamental algorithmic research."}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VIJ5aSYK00", "forum": "aR7jXICvcL", "replyto": "aR7jXICvcL", "signatures": ["ICLR.cc/2026/Conference/Submission19185/Reviewer_x7FE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19185/Reviewer_x7FE"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761646360632, "cdate": 1761646360632, "tmdate": 1762931185376, "mdate": 1762931185376, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This submission proposes SA-PEF, an improved Step-Ahead Error Feedback (SAEF) algorithm for communication-efficient federated learning (FL) that uses biased gradient compression. The core idea is to introduce a coefficient that balances the rapid initial convergence of Step-Ahead Error Feedback (SAEF) with the long-term stability of standard Error Feedback (EF). This is achieved by introducing a \"step-ahead\" coefficient, α, which controls what fraction of the accumulated compression error is used to shift the model before local training, while the remaining fraction is carried over in the standard EF manner. The authors provide a solid theoretical analysis for non-convex settings and extensive empirical results demonstrating that SA-PEF can achieve target accuracies faster and with less communication than its predecessors."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Plug and Play Method:  The proposed SA-PEF algorithm is a simple and intuitive solution that interpolates between EF and SAEF.\n- Theoretical Contribution: The paper offers a rigorous convergence analysis for SA-PEF under standard assumptions for non-convex optimization in FL (L-smoothness, bounded variance, gradient dissimilarity). The analysis covers partial client participation and local SGD steps. The final convergence guarantee matches the state of the art for similar methods, converging to a floor dependent on variance and heterogeneity.\n- Sound Experimental Results: The experimental evaluation is comprehensive. The authors test SA-PEF across three datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet), three models (ResNet-9/18/34), and challenging FL settings (low participation rates, high data heterogeneity via Dirichlet partitioning, and aggressive Top-k compression). The comparisons against FedAvg (uncompressed), EF, SAEF, and CSER are convincing. The results in Figures 1 and 2 consistently show that SA-PEF achieves better or comparable accuracy in fewer communication rounds and, crucially, with a significantly lower communication budget (in GB)."}, "weaknesses": {"value": "- The claim in the Sec. Intro. requires evidence. In the introduction, this submission argues that “SAEF can exacerbate the variance of the model” without empirical evidence or reference. Whilst the claim about the “prior analysis” also requires proof. This is very important, for it is the core motivation of this submission.\n- The experimental results do not support the claim that SAEF can mitigate the gradient mismatch. As shown in Fig.3 (b), the SAEF achieves a higher gradient mismatch degree than EF.\n- Practicality and Tuning of $\\alpha_r$: The step-ahead coefficient $\\alpha_r$ is a hyperparameter, and the paper lacks a clear discussion on how to set this value in practice. Also, the experiment setup does not explicitly state nor give the value of the $\\alpha_r$. The ablation studies even indicate that SA-PEF is sensitive to $\\alpha_r$.\n- Comparison with CSER: The experiments show that CSER is a strong baseline, and in the gradient mismatch analysis (Figure 3), it performs similarly to SA-PEF by keeping the mismatch low. However, the paper provides little discussion on the differences and trade-offs between SA-PEF and CSER."}, "questions": {"value": "- The use of momentum (0.9) is mentioned in the experimental setup, but the theory is for SGD without momentum. Would it influence the theoretical results?\n- Others, please refer to the weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3OQhPJsVKj", "forum": "aR7jXICvcL", "replyto": "aR7jXICvcL", "signatures": ["ICLR.cc/2026/Conference/Submission19185/Reviewer_7Yzs"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19185/Reviewer_7Yzs"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission19185/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761663463037, "cdate": 1761663463037, "tmdate": 1762931184848, "mdate": 1762931184848, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}