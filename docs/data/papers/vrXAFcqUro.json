{"id": "vrXAFcqUro", "number": 14155, "cdate": 1758229350307, "mdate": 1759897387410, "content": {"title": "INFER : Learning Implicit Neural Frequency Response Fields for Confined Car Cabin", "abstract": "Accurate modeling of spatial acoustics is critical for immersive and intelligible audio in confined, resonant environments such as car cabin. Current tuning methods are manual, hardware-intensive, and static, failing to account for frequency selective behaviors and dynamic changes like passenger presence or seat adjustments. To address this issue, we propose INFER ( Implicit Neural Frequency Response fields), a frequency-domain neural framework that is jointly conditioned on source and receiver positions, orientations to directly learn complex-valued frequency response fields inside confined, resonant environments like car cabins. We introduce three key innovations over current neural acoustic modeling methods: (1) novel end-to-end frequency-domain forward model that directly learns the frequency response field and frequency-specific attenuation in 3D space; (2) perceptual and hardware-aware spectral supervision that emphasizes critical auditory frequency bands and deemphasizes unstable crossover regions; and (3) a physics-based Kramers–Kronig consistency constraint that regularizes frequency-dependent attenuation and delay. We evaluate our method over real-world data collected in multiple car cabins. Our approach significantly outperforms time- and hybrid-domain baselines on both simulated and real-world automotive datasets, cutting average magnitude and phase reconstruction errors by over 39\\% and 51\\%, respectively. INFER sets a new state-of-the-art for neural acoustic modeling in automotive spaces.", "tldr": "", "keywords": ["Acoustic scene representation", "Implicit representation", "spatial acoustics", "frequency-domain modeling"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b34e84bfabcf4708be3e6bbe40a57b7b99e95d8e.pdf", "supplementary_material": "/attachment/4dbf7c9652bfe396613699f74fd8ce88d1c4afbd.pdf"}, "replies": [{"content": {"summary": {"value": "Authors introduced INFER, a novel spectral-domain framework that models acoustic propagation in\nconfined environments using implicit neural representations. By operating directly in the frequency\ndomain, their method enables perceptually grounded supervision, hardware-aware weighting, and\nphysically consistent regularization through the Kramers–Kronig constraint. They did extensive evaluations on real and simulated car cabin datasets demonstrate that INFER substantially outperforms prior time-domain and\nhybrid approaches, achieving over 50% improvement in phase accuracy and 39% in magnitude fidelity relative to the best baseline."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "INFER substantially outperforms prior time-domain and hybrid approaches, achieving over 50% improvement in phase accuracy and 39% in magnitude fidelity relative to the best baseline. \n\nThey  first propose to encode KK-consistent complex attenuation in a neural acoustic renderer, preventing non-physical phase behavior and improving both interpretability and generalization.\n\nTheir proposed total loss is novel and it is a key for achieving the best accuracy."}, "weaknesses": {"value": "Authors are solving a specific problem of neural modeling for frequency response field for confined car cabins.\nCan this approach be scaled on other applications?"}, "questions": {"value": "It is surprising that this approach, based on vanilla sequence of fully connected layers is outperforming other methods.\nPlease explain why?\nE.g. that means that the baseline is weak, or method in this paper uses additional data which are not used by the baseline?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "MzXdxWctdw", "forum": "vrXAFcqUro", "replyto": "vrXAFcqUro", "signatures": ["ICLR.cc/2026/Conference/Submission14155/Reviewer_qS5V"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14155/Reviewer_qS5V"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission14155/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761874678628, "cdate": 1761874678628, "tmdate": 1762924616757, "mdate": 1762924616757, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Implicit Neural Frequency Response fields (INFER), a neural acoustic field learning framework for confined car cabin.\n\nKey contributions are:\n- First to apply the end-to-end frequency domain modeling for car cabins.\n- Proposed Kramers–Kronig physical consistency regularization to enforce spectral attenuation and phase delay across frequencies.\n- Evaluation on both COMSOL simulated data and real car cabins show that INFER outperforms the other baselines (NAF, INRAS, and AVR)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- **Originality:**\n    \n    INFER is the first to offer fully frequency-domain neural acoustic field modeling for car cabins.\n    Integrating Kramers–Kronig grounded physics in a regularization is novel and well-motivated.\n    \n- **Quality:**\n    \n    The technical presentation is thorough, underlying principles are detailed, and the method is carefully justified physically and psychoacoustically.\n    The evaluations on both synthetic and real environments shows fair benchmark comparisons. Multiple metrics are reported and samples are visualized to support claims.\n    \n- **Clarity:**\n    \n    The paper generally presents its methodology clearly. While there are some omissions, it provides relatively detailed figures, including hyperparameters.\n    \n- **Significance:**\n    \n    *If the author releases the code and data* as promised, this study will be significant as a benchmark. Yet, this reviewer cannot find neither code nor data from the supplementary material at this moment."}, "weaknesses": {"value": "1. **Novelty:**\n\n    The method builds on existing ideas in neural implicit fields for acoustics (NAF, INRAS, AVR).\n    While the application of frequency-domain learning and KK regularization is novel *for car acoustics*, such novelty, as suggested by its distinctions from prior research, is somewhat limited.\n    The frequency-domain modeling is not actually a particularly unique method and has already been applied in many other spatial audio studies [1,2]. As the author also explained, the fact that the frequency-time hybrid approach AVR already exists is in a similar vein. Reports of AVR's inferior performance compared to NAF make one wonder again whether the advantages of frequency-domain modeling truly is significant in this context. For this reason, this reviewer cannot agree with the authors' claim that the 'end-to-end frequency-domain forward model' is novel, as insisted in the key contributions.\n    \n2. **Ablation study:**\n\n    The paper only reports on the proposed approach for the specific case, which is of a car cabin. This alone does not undermine the author's claim, but it does imply that the audience of interested readers may be somewhat limited. Without ablation studies, it is hard to provide meaningful insights unless one is specifically interested in car cabins. For instance, it remains unclear whether frequency modeling or the KK regularization trick also benefits learning indoor acoustic fields (where NAF, INRAS, and AVR were tested on). Therefore, the author's claim is valid only for ‘car cabins’.\n    \n3. **Generalization:**\n\n    The datasets (COMSOL, BUCK, Tesla Model X) are well chosen, and providing details about the measurement setup is much appreciated.\n    However, it is extremely difficult to determine how many source-receiver pairs were sampled per scene and where they were sampled.\n    To my understanding, like many other neural acoustic field learning works, this paper also tackles the problem of generalization within a scene (not across scenes). In this case, it is critical to see how the approach generalizes well for the training data's sparsity and its sampling distribution, as the key issue is \"how sparse the source-receiver pairs used for training can be\".\n    Yet, there are no experiments addressing this at all.\n    \n4. **Interpretability and Physical Plausibility:**\n    \n    The paper enforces KK relationships in loss, but the qualitative impact on physical interpretability is mostly assumed.\n    (For example, do reconstructions violate causality if KK is removed? Do phase/magnitude predictions by INFER become less plausible without such regularization?)\n    More ablation studies on the necessity of KK, and analysis of physical interpretability (not just metric fidelity), would strengthen the claims.\n    \n5. **Baseline Fairness:**\n    \n    The authors explain that all baselines are re-implemented in their codebase. The effort is to be commended, but there could be unintended pitfalls.\n    For example, the baseline was not properly verified, and it is questionable that NAF—which appeared first among NAF, INRAS, and AVR, and has generally been reported to perform worse than INRAS or AVR—shows the second-best performance after INFER.\n    It is unclear whether the automotive cabin environment is exceptionally unique, as there is no way to know (since no comparative experiments were conducted).    \n    \n[1] Lee, J. W., & Lee, K. (2023). Neural fourier shift for binaural speech rendering. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE.\n\n[2] Di Carlo, D., Nugraha, A. A., Fontaine, M., Bando, Y., & Yoshii, K. (2024). Neural Steerer: Novel steering vector synthesis with a causal neural field over frequency and direction. In 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW) (pp. 740-744). IEEE.\n\n[3] Wang, M. L., Sawata, R., Clarke, S., Gao, R., Wu, S., & Wu, J. (2024). Hearing anything anywhere. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 11790-11799)"}, "questions": {"value": "1. Regarding Appendix A7 (Evaluation Metrics), it seems like KK Violation Metric was used, but this metric does not appear anywhere in the paper. Please report this metric?\n\n2. The paper states that “hardware-aware weighting” is a key contribution, but nowhere does it explain *where it originated from* or *how the values were determined*. From reading section 4.3, it seems like $w(f)$ is what the authors mean by \"hardware-aware weighting,\" which turns out to be a heuristic \"frequency-dependent weighting\" in Appendix A3. If this actually improves performance, an ablation study should be included. For example, it should report how much performance drops when this trick is omitted from the proposed methodology, or whether applying this trick to the baseline architecture yields the same performance gains. (The same applies to the KK loss function.)\n\n3. Although the content is repeatedly mentioned under ‘Weakness,’ is the proposal in this paper only applicable to car cabins? Are there no experimental results conducted in a room? Which part of the proposal specifically functions for the car cabins?\n\n4. When will the code and dataset be made available as stated?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dWGPo1fZbu", "forum": "vrXAFcqUro", "replyto": "vrXAFcqUro", "signatures": ["ICLR.cc/2026/Conference/Submission14155/Reviewer_dpmJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14155/Reviewer_dpmJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission14155/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761879566484, "cdate": 1761879566484, "tmdate": 1762924616412, "mdate": 1762924616412, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents INFER, a deep learning algorithm that predicts an acoustic transfer function at a 3D point. INFER is specially designed for environments with non-standard shapes and multiple materials with different absorption and dispersion properties, such as the interior of a car (which is the setting where INFER is tested).\n\nINFER predicts both a complex attenuation factor (with independent predictions for magnitude and phase) as well as a directional retransmission factor. The final transfer function is computed by casting 32 rays from each source and accumulating the effects of each ray across 64 points, until we arrive to the query point. Once the transfer function is accumulated, a loss with 6 terms is computed that ensures the predictions of the network are physically realistic.\n\nEvaluations on both simulated and recorded data such as a model cabin and an actual cabin of a Tesla Model X car show that INFER model the transfer function significantly better than other neural network methods which model the transfer function in the time domain."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* INFER applies machine learning techniques to an interesting domain (transfer function estimation in complex environments), which would be difficult to solve with traditional signal processing techniques.\n* The manuscript contains a useful primer on the physics of audio propagation, making the paper accessible to non-acoustics-experts.\n* The paper is really well motivated, particularly around the need for frequency domain modelling for the neural network."}, "weaknesses": {"value": "* **W1**: While the motivation, related works, and acoustics primer are really well developed; the machine learning aspects, the ray marching strategy, and the evaluation are missing important details and ablations (see questions below for more details).\n\n* **W2**: There is nothing in INFER that limits it to car cabins. In principle, INFER should be able to approximate the transfer function in any environment. Consequently, the contribution of this work could be strengthened if there was an evaluation on other domains (eg. normal rooms, open environments, other complex environments). At the very least, a discussion of what environments INFER is ideal for should be added."}, "questions": {"value": "### Machine Learning Questions\n\n* **Q1**: What is the training set of INFER? Is it a random split of the datasets presented in sec 5.1?\n* **Q2**: How many parameters does each network (attenuation, retransmission) have?\n* **Q3**: What layer from the attenuation network is used for conditioning the retransmission network?\n* **Q4**: [less important] Could you obtain better results with a convolutional neural network (possibly with parallel branches of multiple kernels)? After all, temporal and frequency features in a STFT are highly locally correlated.\n* **Q5** [less important] A diagram of both networks would help better understand the ML contribution.\n\n------\n\n### Ray Marching Questions\n\n* **Q6**: Can you provide further details on the ray marching setting? How do you ensure all the rays converge on p? Do you produce new rays at intermediate points? Do you perform any culling?. Overall, ray marching is only briefly described in the manuscript, but it deserves a more thorough explanation since it is a key part of INFER.\n\n* **Q7**: What are the consequences of increasing/decreasing the number of rays/points for the ray marching?\n\n-----\n\n### Evaluation Questions\n\n* **Q8**: What is the performance with the simulated (COMSOL) module? I was expecting to find those results in Table 1.\n* **Q9**: What is the spread of the prediction errors across different 3d positions and frequencies for each method. Perhaps a heat map plotting {position-across-line x frequency x amplitude/phase error} would be helpful to illustrate the behaviour of INFER?\n* **Q10**: What exactly is being reported in Tables 1 & 2? I assume it's the mean absolute error but this needs to be explicitly specified.\n* **Q11**: How were the T60 and EDT errors computed? I assume directly from the resulting transfer function, but this needs to be explicitly specified.\n* **Q12**: For Table 2, the frequency breakdowns were computed with the simulated, buck or Model X datasets?\n* **Q13**: Can you provide errors for a higher range of frequencies (for instance third-octave)?\n* **Q14**: The loss has many sub terms and the contribution of each one is not well understood. How were the relative loss weights established? Could you ablate the contribution of each term? For instance you could evaluated INFER with $\\\\{\\lambda_\\text{spec}, \\lambda_\\text{mag}, \\lambda_\\text{phase}, \\dots \\\\} = 0$ and record the decrease in performance for each setting.\n* **Q15**: What are the exact terms in $\\lambda_\\text{aux}$? This should at least be defined in the appendix.\n* **Q16**: How were the $\\omega$'s determined? What frequencies were de-emphasised and why?\n* **Q17**: [less important]: I would suggest a user study where some participants (ideally $N>15$) listen to the sounds in the car cabin convolved, and then the same sounds convolved with different transfer functions (INFER, INRAS, AVR, NAF). Participants would then rate their subjective impressions of which one is closer to the baseline. I hypothesise INFER would do better than other baselines, but more importantly such an experiment would tell us how far we are from an \"ideal\" transfer function estimation method.\n* **Q18**: Will the training and evaluation datasets be released? Sec 8 mentions \"demo\" datasets.\n\n-----\n\n### Nitpicks (do not affect rating, no need to follow up on rebuttal)\n\n* **N1**: Lines 70-75 discuss related work, and indeed the same points are repeated in sec 2.1. I would suggest removing them or heavily summarising them.\n* **N2**: $\\Omega$ is undefined in eq. (3). I assume it is the volume being modelled, but this needs to be explicitly specified.\n* **N3**: Sec 3.3 uses $G(x,x')$ but the rest of the manuscript seems to refer to the same concept as $\\delta(x)$. I would stick to one notation to ease readability.\n* **N4**: The bibliography needs cleaning up: some surnames are in all-caps, the same conference is sometimes in title-case, sometimes not.\n* **N5**: What is TOF in Fig1?\n* **N6**: In 4.2 $\\hat{n}$ has unit length right? If so I would explicitly mention this.\n* **N7**: I would suggest using another symbol for the smoothing filter around line 328. $\\mathcal{S}$ is being used to denote the retransmission function.\n* **N8**: In line 403 the model outputs $\\sigma, \\beta$ and $\\mathcal{S}$ rather than $H$ correct? H is computed using equation (7) afterwards, isn't it?. If so line 403 needs to be rephrased."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "eS9GxKVE3y", "forum": "vrXAFcqUro", "replyto": "vrXAFcqUro", "signatures": ["ICLR.cc/2026/Conference/Submission14155/Reviewer_fi6v"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission14155/Reviewer_fi6v"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission14155/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762006431335, "cdate": 1762006431335, "tmdate": 1762924615942, "mdate": 1762924615942, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}