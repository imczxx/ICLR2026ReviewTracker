{"id": "9bkzvYw9ds", "number": 1708, "cdate": 1756909818278, "mdate": 1759898193431, "content": {"title": "Causal Time Series Generation via Diffusion Models", "abstract": "Time series generation (TSG) synthesizes realistic sequences and has achieved remarkable success. Among TSG, conditional models generate sequences given observed covariates, however, such models learn observational correlations without considering unobserved confounding. In this work, we propose a causal perspective on conditional TSG and introduce causal time series generation as a new TSG task family, formalized within Pearl’s causal ladder, extending beyond observational generation to include interventional and counterfactual settings. To instantiate these tasks, we develop CaTSG, a unified diffusion-based framework with backdoor-adjusted guidance that causally steers sampling toward desired interventions and individual counterfactuals while preserving observational fidelity. Specifically, our method derives causal score functions via backdoor adjustment and the abduction–action–prediction procedure, thus enabling principled support for all three levels of TSG.  Extensive experiments on both synthetic and real-world datasets show that CaTSG achieves superior fidelity and also supporting interventional and counterfactual generation that existing baselines cannot handle. Overall, we propose the causal TSG family and instantiate it with CaTSG, providing an initial proof-of-concept and opening a promising direction toward more reliable simulation under interventions and counterfactual generation.", "tldr": "", "keywords": ["Time Series Generation", "Conditional Generation", "Time Series Analysis"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3973c7b2754abc53ef6f6ec136a2fb2ac1bc7552.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a diffusion-based framework that extends observational time series generation (TSG) to interventional and counterfactual TSG under Pearl’s causal hierarchy, addressing unobserved confounding. Specifically, the authors generalize the standard definition of score functions to their causal counterparts under the structural causal model (SCM) framework. Building on this formulation, they propose CaTSG, a model comprising an environment inference module (EnvInfer), a learnable environment bank with an encoder, and a denoiser that integrates both conditional and environmental variables to produce the final samples. The effectiveness of CaTSG is validated on two synthetic and two real-world datasets, demonstrating its capability to learn unobserved confounders and generate coherent counterfactuals."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "•\tThe authors explain the effect of unobserved confounding in the introduction by using an intuitional example, which enhances readers’ understanding of the concept, though I think summer holidays do not “cause” high temperature, but only “coincide” with high temperature instead.\n\n•\tThe concepts of “intervention” and “abduction” are well illustrated in Figure 2.\n\n•\tThe idea of extending CFG and score functions to causal learning is interesting, though there exist some studies that follow similar ideas, such as [1].\n\n•\tThe proposed model consistently outperforms other benchmarks on various types of metrics. The counterfactual analysis on the results for real-world data mostly makes sense.\n\n•\tThe authors explore different combinations of hyperparameters and conduct a brief analysis on the efficiency (e.g., number of inference steps) of the proposed method.\n\nReferences:\n\n•\t[1]. Xia, Tian, et al. \"Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models.\" arXiv preprint arXiv:2506.14399 (2025)."}, "weaknesses": {"value": "•\tIt would be better to further discuss recent studies that utilize diffusion model or Classifier-free Guidance for counterfactual generation, such [1] and [2].\n\n•\tFor other aspects of potential weaknesses, please refer to the “Questions” section.\n\nReferences:\n\n[1]. Komanduri, Aneesh, et al. \"Causal diffusion autoencoders: Toward counterfactual generation via diffusion probabilistic models.\" arXiv preprint arXiv:2404.17735 (2024).\n\n[2]. Wu, Shenghao, et al. \"Counterfactual generative models for time-varying treatments.\" Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2024."}, "questions": {"value": "•\tWhat is the rationale behind the adoption of the swapped loss $\\mathcal{L}_{sw}$? For example, can we use a SimSiam-style loss $\\mathcal{L} = \\frac{1}{2} \\mathcal{D}(h’, w’’) + \\frac{1}{2} \\mathcal{D}(h’’, w’)$ where $\\mathcal{D}(\\cdot)$ is a similarity measure?\n\n•\tSince the environment bank $\\textbf{E}$ is learnable, how shall we initialize it?\n\n•\tAlthough the authors do an ablation study on the hyperparameters of CaTSG including number of environment embeddings $K$ and their dimension $H$, the search space appears to be quite limited. To be specific, how shall we choose $K$ and $H$ when there might exist more than one unobserved confounder?\n\n•\tHave you tried the Flow Matching solver for the denoiser?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yGV9mfHHe2", "forum": "9bkzvYw9ds", "replyto": "9bkzvYw9ds", "signatures": ["ICLR.cc/2026/Conference/Submission1708/Reviewer_zSS3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1708/Reviewer_zSS3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1708/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760922047459, "cdate": 1760922047459, "tmdate": 1762915862831, "mdate": 1762915862831, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this work, the authors propose a causal perspective on conditional time-series generation (TSG) and introduce causal TSG as a new task family. The paper makes three key contributions:\n1.\tCausal expansion of conditional TSG. The authors formalize causal TSG as an extension of conditional TSG along Pearl’s ladder, adding two tasks beyond association—interventional (Int-TSG) and counterfactual (CF-TSG)—to better align generative modeling with real-world decision making.\n2.\tUnified causality-guided diffusion framework. They derive causal score functions via backdoor adjustmentand abduction–action–prediction (AAP), and instantiate CaTSG, which embeds these principles into diffusion sampling. Using backdoor-adjusted guidance and a learnable latent environment bank, CaTSG supports observational, interventional, and counterfactual generation within a single framework.\n3.\tComprehensive empirical evaluation. Across four datasets, CaTSG consistently improves observational fidelity and achieves competitive interventional performance, outperforming the second-best baseline by 2.4%–98.7%across four metrics. For counterfactuals, CaTSG produces accurate CF generations on synthetic datasets (with ground-truth counterfactuals) supported by environment analyses, and yields reasonable CF results on real-world datasets via case-study visualizations.\nEmpirically, CaTSG is evaluated on two synthetic oscillator datasets and two real datasets (Air Quality, Traffic), showing improvements over TimeGAN/WaveGAN/Pulse2Pulse and TimeWeaver variants on MDD, KL, MMD, and J-FTSD; ablations indicate that each component (environment bank, SwAV-style loss, and guidance) contributes to the gains."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The method demonstrates good originality. The idea of using the environment as additional conditioning information is an effective way to help the model learn more stable relationships between X and C. The use of the SwAV-style training paradigm is also an interesting and sensible approach to learn useful \"clustering\" of the (X,C) pairs, enabling the model to absorb the underlying factors that generate the variation in these pairs.\n\nThe paper presents thorough experiments across four datasets and consistently demonstrates strong performance."}, "weaknesses": {"value": "The explanation of how the environment is learned and generated could be clearer. More intuition should be provided regarding why the SwAV-style training task is well-suited for learning the environment.\n\nAdopting the backdoor-adjusted approach is not without its challenges, as it requires learning additional components. Specifically, for each environment, the model needs to learn a conditional distribution P(X∣C,E=e). The paper does not adequately discuss the potential cost of using backdoor adjustment. A possible experiment could involve using untrained or completely noisy environment variables to see how the model performs compared to the unadjusted approach. It would be insightful to observe the negative impact of using backdoor adjustment and how the dimension and complexity of the (uninformative) environment variable might affect performance.\n\nFollowing up on the previous point, causal methods typically target bias reduction. In this case, adding a learned environment variable is intended to decrease the bias in estimating the conditional distribution P(X∣do(C)). Usually, the trade-off is an increase in variance. However, the paper does not address this. Most of the uncertainty quantification analyses show that CaTSG outperforms other methods. This could be because the uncertainty metrics include both bias and variance, so the increase in variance is not separately observable. I recommend adding metrics, plots, or visualizations to demonstrate the increased variance and engineering challenging cases where the variance dominates the bias, causing CaTSG to underperform compared to conventional methods. I believe this experiment is essential to demonstrate the reliability of causal-based methods.\n\nWhile I appreciate the visualization of the entire pipeline for the proposed method, I personally find Figure 3 a bit too dense for easy reading. Perhaps the key components could be emphasized, and less important parts of the method could be removed or downplayed."}, "questions": {"value": "Questions:\n1.\tHave you considered using a continuous or high-dimensional environment variable E? In many cases, splitting the confounding information into K discrete clusters or categories of environments can lead to poor performance, especially when there are many weak confounders that cannot be easily separated into K discrete environments.\n2.\tHave you considered using additional data or information to aid in learning the confounders? For example, instead of using SwAV, could you use supervised learning with additional data/information to predict (X,C), which could help in learning better embeddings for the confounders?\n3.\tHave you considered an inverse probability weighting (IPW) formulation for the problem?\nIf you have considered the above questions, I would be interested to hear why these alternatives were not explored."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "56pugC5ie3", "forum": "9bkzvYw9ds", "replyto": "9bkzvYw9ds", "signatures": ["ICLR.cc/2026/Conference/Submission1708/Reviewer_wJr5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1708/Reviewer_wJr5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1708/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761353058939, "cdate": 1761353058939, "tmdate": 1762915862635, "mdate": 1762915862635, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper formalizes causal time-series generation by extending conditional TSG beyond observation $P(X\\mid C)$ to interventional $P(X\\mid do(C))$ and counterfactual $P(X'\\mid X,C,C')$ tasks. It introduces CaTSG, a diffusion framework that derives causal score functions via backdoor adjustment and the abduction–action–prediction procedure, enabling interventional and counterfactual sampling without ground-truth interventions.  \n\nCaTSG uses a learnable environment bank and an EnvInfer module to approximate latent confounders, trained with a swapped-prediction objective and an orthogonality regularizer; generation combines environment-aware denoiser outputs with posterior weights.  Empirically, across two synthetic and two real datasets, the method reports improved observational fidelity and mostly competitive interventional results against GAN and diffusion baselines, with counterfactual quality demonstrated on synthetic data.  The paper notes limitations from the assumed SCM and finite environment approximation."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "* Thorough derivations and empirical study.\n* Clear, well-structured presentation, helped by a consistent running example.\n* Novel yet practical approach that avoids manual confounder hunting.\n* Strong, natural integration with recent diffusion methods.\n* Unified treatment of observational, interventional, and counterfactual generation."}, "weaknesses": {"value": "* Most points below are already acknowledged by the authors; they’re noted here to contextualize impact rather than as surprises.\n* Dependence on a fixed SCM (E->C, E->X, C->X) can limit validity under feedback, mediators, or time-varying confounding; conclusions may be sensitive to misspecification.\n* Finite “environment bank” approximates latent causes; the choice of $K$ and representation quality could leave residual confounding or introduce bias.\n* Real-data counterfactuals lack ground truth; evidence necessarily leans on synthetic settings or qualitative case studies, which constrains external validity.\n* Robustness to guidance/inference hyperparameters (e.g., the guidance scale $\\omega$) could be probed more systematically across seeds/datasets.\n* Baseline coverage for interventional/counterfactual settings could be expanded where applicable to strengthen comparative claims.\n* Computational overhead from diffusion plus environment inference is non-trivial; clearer wall-clock and memory reporting would help practitioners gauge trade-offs.\n\n### Minor nitpicks\n\n* On the running example, I praise the idea, but for this specific example, I think the direct edge C->X is not clear: is there really an influence of temperature on traffic, that is not a spurious correlation. I think an example where both effects are clear and we want to disentangle them would be more suited.\n* There are several small LaTeX errors in the appendix, mainly missing subscripts (e.g l.791)\n* I think the paper relies a bit too much on the appendix, some important figures are cited in the text, as if we were supposed to read the text with the figure beside it, but the figure is on the appendix (e.g. Fig 7)"}, "questions": {"value": "* If some confounders are observed, can CaTSG directly condition on them instead of learning an environment bank? What changes (if any) to training/sampling are needed?\n* How easily can the framework adapt to other causal graphs (mediators, instrumental variables, partial feedback)? What concrete modifications to the guidance rules would that entail?\n* What (if any) identifiability guarantees exist for the learned environments with finite $K$? Any recommended heuristics for choosing $K$ (and the guidance scale $\\omega$) in practice?\n* How do you diagnose and handle limited overlap/positivity in $(C,E)$ (e.g., rare environment–context pairs)? Would you recommend reweighting, trimming, or curriculum strategies?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IcKfTtiR1O", "forum": "9bkzvYw9ds", "replyto": "9bkzvYw9ds", "signatures": ["ICLR.cc/2026/Conference/Submission1708/Reviewer_AVVu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1708/Reviewer_AVVu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1708/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761846432279, "cdate": 1761846432279, "tmdate": 1762915862452, "mdate": 1762915862452, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}