{"id": "NYvvkBlSX2", "number": 181, "cdate": 1756730438738, "mdate": 1763292001205, "content": {"title": "Incomplete Data, Complete Dynamics: A Diffusion Approach", "abstract": "Learning physical dynamics from data is a fundamental challenge in machine learning and scientific modeling. Real-world observational data are inherently incomplete and irregularly sampled, posing significant challenges for existing data-driven approaches. In this work, we propose a principled diffusion-based framework for learning physical systems from incomplete training samples. To this end, our method strategically partitions each such sample into observed context and unobserved query components through a carefully designed splitting strategy, then trains a conditional diffusion model to reconstruct the missing query portions given available contexts. This formulation enables accurate imputation across arbitrary observation patterns without requiring complete data supervision. Specifically, we provide theoretical analysis demonstrating that our diffusion training paradigm on incomplete data achieves asymptotic convergence to the true complete generative process under mild regularity conditions. Empirically, we show that our method significantly outperforms existing baselines on synthetic and real-world physical dynamics benchmarks, including fluid flows and weather systems, with particularly strong performance in limited and irregular observation regimes. These results demonstrate the effectiveness of our theoretically principled approach for learning and imputing partially observed dynamics.", "tldr": "", "keywords": ["diffusion models", "missing data"], "primary_area": "applications to physical sciences (physics, chemistry, biology, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/14e29fe7743d9b2dbe5aae1bf290e4a8f3cdc844.pdf", "supplementary_material": "/attachment/c52b5f833619a32a257eb0b56c94368b5be4627b.zip"}, "replies": [{"content": {"summary": {"value": "This paper addressed the problem of imputing observational data under unknown dynamics. In diffusion-based imputation models, context mask and query mask are needed to train the model to extend the learned dynamics to impute unobserved data. The authors claim that the unobserved data is structured in reality and that diffusion and mask-based methods lack theoretical foundations, and then they introduce their novel pipeline to address the structured missing prior. The authors theoretically analyzed the correct strategy for context-query mask partitioning and extrapolation, and conducted comprehensive experiments on simulated and real-world datasets against competitive baseline methods. The results demonstrated the superiority of their method and the importance of catering to the structured missing prior in algorithm design. Their work could be a sound analysis platform for future diffusion-based and mask-based methods in data imputation."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1: This paper gives a clear literature review and a contrasting comparison with similar models.\nS2: The algorithm is backed by rigorous theorems and proofs, and additionally addresses the structured missing prior in reality.\nS3: The experiments are thoughtful with ablation studies on the model design and components."}, "weaknesses": {"value": "W1: The explanation of the mask selection strategy is confusing, and Figure 1 is hard to understand. In the series of training data with added noise, all data points seem to be observed once across time. No data point needs to be imputed.\nW2: Sometimes, the mask distribution $p_{mask}$ depends on the data samples $x_0$. For example, a weather station may be damaged by a typhoon's direct impact. Also, cloud blocks weather satellite observing the sea temperature, and high sea temperature also promotes cloud generation.\nW3: The authors proposed that the mask selection strategy for $M_{ctx},M_{qry}$ should align with the mask distribution prior $p_{mask}$ and used a block mask as an example. However, the authors didn't consider the case when the mask distribution pattern cannot tessellate on the whole space.\nW4: The analysis of the paper's limitations is missing in the main text.\nW5: The authors claim that some methods are not scalable, but they have not provided a scalability analysis and report on wall-time across baselines.\n\nMinor remarks:\n1. Line 723 VAE-based \"and\" GAN-based methods.\n2. The definition of $x_\\theta$ is unclear on line 138, and its input and output should be specified.\n3. What is the definition of $i$ in eq. 2? Training instance or feature dimension?\n4. A cross-reference to the proof of Thm 1 should be included in the paragraph starting from line 172.\n5. On line 361, the improvement on MissDiff from noise matching to data matching needs to be quantified.\n6. The margin of the caption of Figure 3 is too narrow."}, "questions": {"value": "Q1: What is the term \"feature\" referring to in the main text? Does it refer to different data modalities or cell grid?\nQ2: We observed a significant improvement from block-wise to pixel-level configuration on the Navier-Stokes dataset in Table 2. Is it because the authors tuned the hyperparameters on the NS dataset, as stated in tables 6-7? This could be a source of evaluation bias.\nQ3: How is the physical dynamic learned? The data is not assumed to include the time dimension, and the \"time\" in the main text only refers to the diffusion time steps."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MD0rW7oOUE", "forum": "NYvvkBlSX2", "replyto": "NYvvkBlSX2", "signatures": ["ICLR.cc/2026/Conference/Submission181/Reviewer_bUgQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission181/Reviewer_bUgQ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761658631788, "cdate": 1761658631788, "tmdate": 1762915463326, "mdate": 1762915463326, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a diffusion-based framework for learning physical dynamics when the training data itself is incomplete. The core contribution is a training strategy termed \"context-query partitioning.\" This strategy partitions the observed data within each incomplete sample into a \"context\" for model input and a \"query\" for loss computation. Theoretically, the authors demonstrate that this approach asymptotically recovers the true data distribution without full supervision, provided the partitioning strategy ensures a non-zero probability for any dimension to be queried. For inference, the paper proposes an ensemble sampling method that reconstructs the complete sample by averaging predictions over multiple, randomly drawn context masks. Empirical results on several PDE and climate datasets demonstrate superior performance over existing baselines, especially in highly sparse observation regimes."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Problem Significance: The paper tackles a crucial and pervasive problem in scientific computing: learning from inherently sparse and incomplete observational data.\nTheoretical Rigor: The paper provides a theoretical justification (Theorem 1) for its proposed training strategy. This principled approach is a clear advantage over prior works that often rely on heuristics.\nStrong Empirical Results: The method demonstrates significant performance improvements across multiple benchmarks, particularly in sparse regimes with very low data coverage (e.g., 1%-20%)."}, "weaknesses": {"value": "- Insufficient Discussion of Related Work: The primary weakness is the failure to adequately discuss the connection to masked signal modeling, such as Masked Autoencoders (MAEs). The \"context-query partitioning\" is conceptually very similar to masking part of the visible data to predict another part. The absence of this discussion makes the core idea seem more novel than it is.\n- Limited Baseline Comparison: While the paper includes recent diffusion-based baselines, the modification of some baselines (e.g., adapting MissDiff to a data matching framework) makes it difficult to assess if the comparison is entirely fair. Furthermore, excluding some theoretically rigorous but computationally expensive methods, while understandable, would be more convincing with a small-scale comparison or a deeper discussion.\n- Scope of Theory: While Theorem 1 is a highlight, it focuses on asymptotic convergence. It doesn't analyze finite sample complexity or the approximation error introduced by the model architecture. The theorem's premise—that the union of query masks covers all dimensions—is satisfied by the design of the sampling strategy, which makes the argument slightly circular."}, "questions": {"value": "1. Could the authors elaborate on the conceptual similarities and differences between the \"context-query partitioning\" strategy and self-supervised learning paradigms like Masked Autoencoders (MAEs)? This is crucial for accurately positioning the paper's novelty.\n2. In the baseline comparisons, were the hyperparameters for all baseline methods tuned with the same rigor as the proposed method? Ensuring a robust comparison is key to validating the claimed performance gains.\n3. The \"distribution-preserving\" sampling strategy mentioned in line 264 appears critical to success. In real-world scenarios where prior knowledge of P_mask(M) might be inaccurate, how sensitive is the method's performance to this \"mask distribution mismatch\"?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HdLkiu8OzZ", "forum": "NYvvkBlSX2", "replyto": "NYvvkBlSX2", "signatures": ["ICLR.cc/2026/Conference/Submission181/Reviewer_7yXe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission181/Reviewer_7yXe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880287993, "cdate": 1761880287993, "tmdate": 1762915463168, "mdate": 1762915463168, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response"}, "comment": {"value": "In response to the reviewers' feedback, we have updated our manuscript with the following revisions, mostly highlighted in color of red:\n\n1. Corrected minor typos highlighted by the reviewers.\n2. Provided a more detailed explanation for excluding certain baselines, including an expanded discussion on their prohibitively high computational costs, which render them unsuitable for our PDE dynamics generation task (see Appendix G).\n3. Clarified the rationale for modifying MissDiff’s experimental setting, emphasizing that the adjustment was necessary to ensure its proper functionality (see Appendix H3).\n4. Added new comparative experiments to investigate the impact of the ensemble size K on the results (see Appendix H4).\n5. Included a discussion on the distinctions between our approach and related works in masked self-supervised learning (see Appendix C5).\n6. Added context and query mask selection algorithm implementation (see Appendix H2)\n7. Added Limitations and Future Work section (see Appendix I) \n\n\n\n# Selection of K and Computational Trade-offs\n\n## How is K selected?\n\nAs shown in Theorem 2 (Eq. 13), increasing K reduces variance terms in the prediction error. The optimal K balances accuracy and computational cost, which is problem-dependent due to varying magnitudes of data variance and model variance across different observation patterns and datasets.\n\nOur experiments show that K=5-10 typically suffices across most scenarios (we set the default K=10). The required K does scale with observation sparsity, and sparser observations generally benefit from a larger K to reduce variance.\n\n\n| K  | NS Error (80%) | NS Error (60%) | NS Error (20%) | Time Ratio |\n|----|----------------|----------------|----------------|------------|\n| 1  | 0.2239         | 0.5652         | 2.1446         | 1.00×      |\n| 2  | 0.2147         | 0.5475         | 2.0822         | 1.81×      |\n| 3  | 0.2119         | 0.5418         | 2.0640         | 2.65×      |\n| 5  | 0.2094         | 0.5371         | 2.0462         | 4.26×      |\n| 10 | 0.2076         | 0.5337         | 2.0343         | 8.32×      |\n| 20 | 0.2068         | 0.5320         | 2.0277         | 16.48×     |\n| 50 | 0.2062         | 0.5308         | 2.0240         | 41.06×     |\n\n## Computational overhead analysis\n\n**Training cost**: Our training procedure has a comparable computational cost to baseline diffusion methods (MissDiff, AmbientDiff) since the network architecture and input/output dimensions are the same. The main difference is in our context-query partitioning strategy during training, which adds negligible overhead.\n\n**Inference cost**: The additional computational cost comes from sampling:\n\nFor **single sample generation** (common in scientific applications):\n- The K forward passes can be executed in parallel since they are independent\n- Wall-clock time increases sub-linearly with K rather than K-fold due to parallel GPU computations\n- On an A800 GPU: K=10 requires 3.36× time of K=1 for 50-frame 32×32 sequences, and 8.32× for 100-frame 64×64 sequences\n- The overhead depends on hardware parallelization efficiency and batch size\n  \nFor **batch generation** of multiple samples:\n- Computational cost scales approximately K times compared to baselines\n- This represents a fundamental trade-off: our method enables learning from realistically incomplete data, a necessity in many scientific domains where complete measurements are physically impossible"}}, "id": "PE7h7mGsgy", "forum": "NYvvkBlSX2", "replyto": "NYvvkBlSX2", "signatures": ["ICLR.cc/2026/Conference/Submission181/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission181/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission181/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763291861083, "cdate": 1763291861083, "tmdate": 1763291861083, "mdate": 1763291861083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a diffusion-based framework for learning physical dynamics from incomplete and irregularly sampled data, a common challenge in scientific domains. The core contribution is a novel training paradigm where each incomplete data sample is partitioned into a \"context\" set and a \"query\" set. A conditional diffusion model is then trained to reconstruct the query portions given the context, without requiring access to complete ground-truth data. The authors provide a theoretical analysis demonstrating that their method asymptotically converges to the true data distribution under certain conditions. Furthermore, they introduce an ensemble sampling technique for inference to reconstruct the complete data. The method is evaluated on several synthetic PDE datasets (Navier-Stokes, Shallow Water, Advection) and the real-world ERA5 climate dataset, showing superior performance over existing baselines, especially in highly sparse settings."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles the critical and practical challenge of learning physical dynamics from inherently sparse and incomplete real-world data.\n\nIt provides a theoretical analysis (Theorem 1 and 2) that offers guarantees for the learning process, explaining how and why the model can learn from incomplete data. This is a notable strength compared to more heuristic approaches."}, "weaknesses": {"value": "Limited Novelty: The core idea of context-query partitioning is conceptually similar to existing masked data training strategies in self-supervised learning and other generative models. The distinction from methods like Ambient Diffusion, which also operate on incomplete data, is not sufficiently pronounced. The contribution seems to be more about a specific, effective sampling strategy rather than a fundamentally new paradigm.\n\nLack of Clarity on Implementation: The \"strategic context-query partitioning\" is the cornerstone of the method, yet its implementation is vaguely described. The paper lacks a clear algorithm or pseudo-code explaining how M_ctx is sampled from a given observation mask M for different structural patterns (e.g., block-wise). This ambiguity hinders reproducibility.\n\nIncomplete Baseline Comparison: Excluding recent methods like those by Chen et al. (2024b), Givens et al. (2025), and Zhang et al. (2025a) due to computational cost weakens the experimental validation. A more thorough comparison, even on a smaller scale, would be necessary to firmly establish state-of-the-art performance.\n\nUnaddressed Inference Cost: The proposed ensemble sampling method for reconstruction requires running the model K times per sample. This introduces a significant computational overhead at inference time, which is a critical factor for many scientific applications. The paper does not analyze this trade-off or discuss how K is chosen."}, "questions": {"value": "Could the authors please elaborate on the key conceptual difference between their method and Ambient Diffusion (Daras et al., 2023)? Both seem to train diffusion models by applying masks to incomplete data. What is the crucial insight that leads to the performance gains shown?\n\nCould you provide a more concrete algorithm or pseudo-code for the \"strategic context-query partitioning\" procedure, especially for the block-wise missing data scenario? For a given observation mask M with 5/9 observed blocks, how exactly is M_ctx (e.g., with 4 blocks) sampled?\n\nRegarding the excluded baselines: Could the authors provide a more detailed justification for their exclusion? Would it be possible to conduct a qualitative or small-scale quantitative comparison to give the reader a better sense of where the proposed method stands?\n\nWhat is the inference-time cost of the ensemble sampling approach? How does the performance (e.g., MSE) and computational cost vary with the number of ensemble members K? What was the value of K used in the experiments?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3A2vxmUHNJ", "forum": "NYvvkBlSX2", "replyto": "NYvvkBlSX2", "signatures": ["ICLR.cc/2026/Conference/Submission181/Reviewer_VhJM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission181/Reviewer_VhJM"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761915412493, "cdate": 1761915412493, "tmdate": 1762915463013, "mdate": 1762915463013, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles a genuinely important problem: learning physical dynamics when training data is inherently incomplete. The authors propose training diffusion models by strategically splitting each incomplete sample into \"context\" (what the model sees) and \"query\" (what it tries to predict), then using ensemble averaging at inference time to reconstruct complete fields.\nThe key idea is that if you carefully design how you partition incomplete observations during training, matching the partition strategy to the underlying observation pattern (e.g., block-wise vs. pixel-wise missing data), one can train a model that learns meaningful conditional expectations even for dimensions that were never observed in the training data. The authors provide a theoretical analysis that proves convergence to the true complete data distribution and validate it on both synthetic PDEs (Shallow Water, Advection, and Navier-Stokes) and real climate data (ERA5)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The incomplete data setting represents a fundamental constraint in scientific applications where complete ground truth observations are physically impossible to obtain (e.g., global weather systems, ocean dynamics). The motivation is well-articulated and substantiated.\n\n- The context-query partitioning strategy constitutes a genuine advancement over existing approaches. The key differentiation with existing lies in training-time strategic partitioning that adapts to observation patterns, rather than inference-time conditioning or generic loss masking. \n\n- Theorem 1, concerning gradient scaling and parameter update frequency, provides meaningful insight into the significance of partitioning strategy selection. Theorem 2's ensemble convergence analysis demonstrates notable rigor, employing Martingale convergence theory rather than heuristic arguments. This theoretical grounding distinguishes the work from purely empirical approaches.\n\n- The performance improvements documented in Table 2 for block-wise observations are substantial. The 1% observation regime results on ERA5 are particularly noteworthy, representing an extremely challenging setting."}, "weaknesses": {"value": "A bit of nitpicking:\n- The manuscript demonstrates conditions under which the method succeeds, but provides insufficient analysis of failure modes. Specifically, when does the information gap exceed the capacity of ensemble averaging to compensate? The cross-distribution experiments (Appendix G.3, Table 8) suggest performance degradation when the training and test observation ratios differ substantially; however, this warrants a more thorough discussion. Are there principled criteria for determining whether a test distribution lies outside the method's applicability range?\n\n- Ensemble averaging during inference requires K forward passes through the model (the paper employs single-step sampling with K context masks). The selection of K and the resulting computational trade-offs are not discussed. For a method targeting scientific applications, these practical considerations are important. The multi-step sampling described in Appendix E further compounds this concern. Quantitative comparison of computational costs relative to baselines would be valuable."}, "questions": {"value": "- How is K selected for ensemble averaging? Is there a principled approach to determining the number of context masks, or is selection based on empirical validation? Does the required K scale with observation sparsity?\n\n- What is the computational overhead of the proposed method? Can you provide wall-clock training and inference times relative to baseline methods? This information is essential for practical implementation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4m8xTotACX", "forum": "NYvvkBlSX2", "replyto": "NYvvkBlSX2", "signatures": ["ICLR.cc/2026/Conference/Submission181/Reviewer_ztBx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission181/Reviewer_ztBx"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission181/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918619724, "cdate": 1761918619724, "tmdate": 1762915462856, "mdate": 1762915462856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}