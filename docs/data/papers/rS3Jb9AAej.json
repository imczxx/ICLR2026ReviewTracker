{"id": "rS3Jb9AAej", "number": 1100, "cdate": 1756840521908, "mdate": 1759898228213, "content": {"title": "Stochastic Self-Organization in Multi-Agent Systems", "abstract": "Large Language Models (LLMs) have enabled multi-agent systems (MAS) where agents collaborate to solve tasks beyond the reach of a single model. Yet most existing approaches rely on fixed topologies, pretrained graph generators, optimization over edges, or external LLM judges, thereby adding complexity. We introduce a response-conditioned framework that adapts communication on-the-fly. Agents independently generate answers and assess peer contributions using a Shapley~value-inspired approximation. A directed acyclic communication graph (DAG) is then constructed to route information from high-contribution agents to others, ensuring stable and efficient message passing without additional supervision or training. We provide a theoretical analysis showing that multiple agents increase the chance of correctness and that the correct answers naturally dominate information flow. Experiments with both strong and weak LLM backends demonstrate robust performance, with significant gains in the weak regime where prior methods collapse.", "tldr": "", "keywords": ["multi-agent systems", "contribution estimation"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/9880626c8b00b2bb2606fabe6fa7f51c8171fbe9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes using response embeddings and similarity to the group opinion as a self-supervised signal to compute an approximate shapley value for attribution, and then constructing a graph heuristically based on node contributions to achieve better answer aggregation."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper’s motivation is well organized; a response-level, on-the-fly self-organizing topology for multi-agent systems is indeed compelling.\n2. The overall methodological chain is clear and reasonable. Obtain signals in a self-supervised way, then use graph construction to optimize aggregation of those signals. There is theoretical support, and the approach aligns with intuition."}, "weaknesses": {"value": "1. I think the premise “the correct answer appears repeatedly, while wrong answers scatter” only holds when the gap between model capability and task difficulty is not large. In that regime, SELFORG can be viewed as an improved self-consistency method.\n2. When tasks are harder (e.g., on difficult mathematical reasoning where pass@1024 is low), correct responses are more likely to be a minority. In contrast, wrong responses may become the center of a conformity cluster. In that case, your self-supervised conformity signal may drown out the correct signal, and I don’t believe multiple rounds will reverse this failure mode.\n3. There are many heuristic parameters; various thresholds and hyperparameters require manual tuning.\n4. The graph construction is overly heuristic. Although the topology is not hard-coded, it is still generated by rules based on node contributions, which is insufficient to claim true emergence or self-organization."}, "questions": {"value": "1. Have the authors tried other tasks? Currently, the datasets appear to be the common ones that have already been heavily overfit and are prone to data contamination.\n2. Have you compared against baselines such as self-consistency? As it stands, this looks less like a multi-agent task setting and more like aggregating multiple responses. A single node lacks memory, tool use, and multi-turn interaction, and nodes may differ only by LLM or prompt."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GbxGSuh0zE", "forum": "rS3Jb9AAej", "replyto": "rS3Jb9AAej", "signatures": ["ICLR.cc/2026/Conference/Submission1100/Reviewer_gZmw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1100/Reviewer_gZmw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission1100/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760651367363, "cdate": 1760651367363, "tmdate": 1762915677825, "mdate": 1762915677825, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a decentralized, response-conditioned multi-agent communication framework named SELFORG. Under the framework, agents first independently generate answers to the user query and use a Shapley-value–inspired approximation to assess peer contributions. A directed acyclic graph (DAG) is then constructed to govern information flow among agents, ensuring stable and efficient message transmission from high-contribution agents to others. Compared with prior approaches, SELFORG requires no pretrained topology generator, no edge-level reinforcement learning, and no external judge. The communication structure self-organizes round by round and is especially robust in the weak-backend regime. The paper further provides a theoretical analysis showing that increasing the number of agents raises the probability of obtaining the correct answer, and that correct responses naturally dominate the information flow, explaining the method’s effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Unlike prior task-level and query-level communication frameworks, SELFORG performs round-level construction of the communication graph with low method complexity.\n2. It uses a Shapley-inspired contribution estimate to build a DAG, placing high-contribution agents upstream to enable stable and efficient information propagation.\n3. Both theory and experiments demonstrate the effectiveness of the proposed method."}, "weaknesses": {"value": "1. The proposed method rests on the assumption that correct answers cluster more tightly in the embedding space while incorrect ones are more dispersed. The assumption may break down on tasks with multiple equivalent answer forms.\n\n2. The construction of the communication graph relies on several heuristics—e.g., the similarity threshold $\\tau$ and the number of neighbors $k$ per node—but the paper provides limited systematic robustness analysis of these hyperparameters.\n\n3. The final output is selected as the response closest to the contribution-weighted centroid. This strategy may favor the dominant mode. When multiple valid solutions exist, the aggregation method may potentially suppresses minority—yet superior—reasoning paths. The paper does not provide comparisons with alternative aggregation methods like voting."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "The paper raises no ethical concerns."}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TzR49CV4Nx", "forum": "rS3Jb9AAej", "replyto": "rS3Jb9AAej", "signatures": ["ICLR.cc/2026/Conference/Submission1100/Reviewer_SZuJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1100/Reviewer_SZuJ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission1100/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761927624965, "cdate": 1761927624965, "tmdate": 1762915677517, "mdate": 1762915677517, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces SELFORG, a framework for orchestrating multi-agent systems (MAS) based on Large Language Models (LLMs) that dynamically constructs communication graphs without relying on external judges, pretrained topology generators, or reinforcement learning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**Dynamic topology based on actual responses**: Unlike fixed graphs or query-specific topologies, SELFORG adapts to the stochastic agent outputs in real-time (Section 2.4), which is more realistic.\n\n**Efficient Shapley value approximation**: Reduces complexity from O(2^N) to O(N) with theoretical bounds (Theorem 1) and ranking stability guarantees (Corollary 1).\n\n**Strong results with weak models**: Achieves 45% accuracy with Qwen-1.5B vs 33-37% for other multi-agent methods (Table 1), proving the value of the approach when agents are unreliable."}, "weaknesses": {"value": "**Limited to QA/reasoning tasks**: Only evaluates on MATH, GSM8K, MMLU etc. With strong models (Table 2), improvements are marginal (3-4%). No evaluation on genuine multi-agent tasks like MultiAgentBench or collaborative coding (SRDD).\n\n**Missing key baseline**: MAS-GPT is mentioned (page 1) but never compared experimentally despite being the most similar approach.\n\n**No statistical analysis**: Temperature=0.5 but no error bars or multiple runs reported. Only Figure 2 shows 100 runs for one problem.\n\n**Strong assumptions**: Assumption 1 (correct answers cluster, wrong answers scatter) is only validated on one example (Figure 2b). All theory depends on this.\n\n**Small scale only**: Tests use 4-5 agents. Scalability unclear."}, "questions": {"value": "1. Why no comparison with \"Who's the MVP? A Game-Theoretic Evaluation Benchmark for Modular Attribution in LLM Agents\"? It also uses Shapley values for agent evaluation.\n\n2. Algorithm 2 removes cycles arbitrarily - how sensitive is performance to different cycle removal orders?\n\n3. How does this scale to 20-50 agents? The O(N²) similarity computation could be a bottleneck.\n\n4. Section D.3: How is consensus threshold ξ chosen? Is it task-specific? What if wrong agents agree?\n\n5. Why only test on tasks where single LLMs already work well? What about negotiation, collaborative design, or other inherently multi-agent problems? such as MultiAgentBench (Zhu et al. 2025)\n\n6. The heterogeneous agent experiment (Section 3.3) uses fixed role assignment. What happens with dynamic role switching?\n\n7. How many times was each experiment run? Standard deviations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "knnKINGB6c", "forum": "rS3Jb9AAej", "replyto": "rS3Jb9AAej", "signatures": ["ICLR.cc/2026/Conference/Submission1100/Reviewer_F87g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1100/Reviewer_F87g"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission1100/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976899702, "cdate": 1761976899702, "tmdate": 1762915677254, "mdate": 1762915677254, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SELFORG, a training-free framework for stochastic self-organization in multi-agent systems that dynamically constructs communication graphs using an embedding-based contribution metric approximating Shapley values. By structuring information flow as a Directed Acyclic Graph to enhance valuable signals and suppress noise, SELFORG achieves consistent improvements on eight reasoning and QA benchmarks, especially when applied to weaker language models."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Simple, training-free mechanism that works across LLM sizes.\n2. Novel approach to constructing the communication DAG by leveraging cosine similarity for its decision logic.\n3. Extensive experiments across a wide array of reasoning benchmarks demonstrate consistent and significant improvements over strong baselines, especially when employing smaller-scale language models."}, "weaknesses": {"value": "1. The framework's performance appears sensitive to key hyperparameters, such as the similarity threshold \\tau and the termination variance. These variables may require tuning per dataset or model, which the paper does not address, leaving the impression that the chosen values are empirically derived heuristics rather than principled parameters.\n2. The paper highlights that SELFORG is a lightweight framework requiring no pre-training or reinforcement learning, contrasting it with complex task-specific topologies. However, the token consumption table in the appendix shows that the method does not possess a significant advantage in resource usage over other baselines, particularly AutoGen.\n3. The paper's claim of a positive correlation between the cosine similarity of LLM agent embeddings and answer correctness is supported by only a single heatmap from one case, which is not sufficiently convincing."}, "questions": {"value": "1. Could you comment on the robustness of the chosen hyperparameters? Specifically, how sensitive is the model's performance to adjustments in the cosine similarity threshold and the maximum number of rounds?\n2. Can you provide a breakdown of the termination triggers? Specifically, how frequently did the dialogue stop due to reaching the round limit versus achieving consensus based on the variance threshold?\n3. The final answer is selected as the response with the highest contribution score in the very last round. Have you considered alternative aggregation methods, such as selecting the response with the highest contribution score across all rounds? Is there a risk that the collective converges on a high-agreement answer in the final round, while a more brilliant but initially less understood answer from an earlier round gets discarded?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "g5uMArokJW", "forum": "rS3Jb9AAej", "replyto": "rS3Jb9AAej", "signatures": ["ICLR.cc/2026/Conference/Submission1100/Reviewer_TXyD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission1100/Reviewer_TXyD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission1100/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762008194516, "cdate": 1762008194516, "tmdate": 1762915677077, "mdate": 1762915677077, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}