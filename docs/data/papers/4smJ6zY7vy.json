{"id": "4smJ6zY7vy", "number": 6877, "cdate": 1757999329506, "mdate": 1759897886491, "content": {"title": "WavefrontDiffusion: Dynamic Decoding Schedule for Improved Reasoning", "abstract": "Diffusion Language Models (DLMs) have shown strong potential for text generation and are becoming a competitive alternative to autoregressive models. \nThe denoising strategy plays an important role in determining the quality of their outputs.\nMainstream denoising strategies include Standard Diffusion and BlockDiffusion. \nStandard Diffusion performs global denoising without restricting the update range, often finalizing incomplete context and causing premature end-of-sequence predictions. \nBlockDiffusion updates fixed-size blocks in a preset order, but its rigid structure can break apart coherent semantic units and disrupt reasoning. \nWe present WavefrontDiffusion, a dynamic decoding approach that expands a wavefront of active tokens outward from finalized positions. \nThis adaptive process follows the natural flow of semantic structure while keeping computational cost equal to block-based methods. \nAcross four benchmarks in reasoning and code generation, WavefrontDiffusion achieves state-of-the-art performance while producing outputs with higher semantic fidelity, showing the value of adaptive scheduling for more coherent and efficient generation.", "tldr": "WavefrontDiffusion introduces a dynamic decoding schedule for diffusion language models that adaptively expands a local wavefront to preserve semantic units, improving reasoning coherence without increasing compute cost.", "keywords": ["diffusion language models", "dynamic decoding"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/db05b2c9ebc50577b93292d89eb597b9944bd5e8.pdf", "supplementary_material": "/attachment/634842fcecab6efc378fe0bcd24e0df2fef12995.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a wavefront-style dynamic decoding schedule for discrete, mask-based diffusion language models. Instead of global synchronous denoising or fixed-order block decoding, the model maintains a frontier of finalized tokens and iteratively performs scoring, denoising, expansion, and pruning. By capping both the per-step update size $F$ and total steps $T$, it enforces compute parity with block decoding, ensuring that improvements stem from scheduling rather than added computation. The approach is training-free and integrates easily with existing diffusion LMs. However, despite the elegant design, the paper’s experimental analysis remains limited. The evaluation is confined to the LLaDA family (e.g., 8B and 1.5 variants) rather than a broader set of diffusion LMs, and it lacks calibration robustness checks. The MHCO metric shows improved consistency, yet its dependence on the frontier radius $R$ is unexamined; a short theoretical or empirical study would clarify interpretability and stability, and several ablations (e.g., local scoring efficiency, calibration impact) are missing. While the reported gains are consistent, they are modest, and the absence of broader baselines or theoretical grounding weakens the generality of the conclusions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The work is well organized and clearly presented, with strong empirical grounding and sensible ablations. It introduces a novel scheduling perspective for diffusion decoding that reallocates compute dynamically rather than increasing it, preserving $F×T$ parity. The design is practical and model-agnostic—requiring no retraining and the safeguards (frontier pruning, capped updates) are thoughtfully engineered. Experimental reporting is transparent, and the improvements, while modest, are consistent across settings. The paper’s clarity and practicality make it an appealing addition to the diffusion decoding literature."}, "weaknesses": {"value": "1. **Dependence on Confidence Calibration**\n   The proposed approach relies heavily on token-level confidence scores to determine which tokens are finalized. The approach relies on token-level confidence scores to finalize tokens but does not evaluate robustness under different temperature settings or calibration shifts, although the discussion section acknowledges calibration as a general limitation. While Section 4.5 acknowledges calibration as a general limitation of diffusion-based decoders, there is no empirical analysis showing how WavefrontDiffusion behaves under miscalibrated conditions. If the confidence estimates are unstable, the wavefront expansion could prematurely freeze or miss critical tokens, potentially affecting reliability.\n\n2. **Narrow Baseline Coverage**\n   The experiments compare only with Standard Diffusion and BlockDiffusion. More recent dynamic decoding methods—such as remasking-based or truncated-block strategies are not included. Since these methods also dynamically adjust the denoising schedule, evaluating under a matched $F×T$ compute budget would clarify whether the observed gains come from the proposed scheduling design itself or from confidence-based gating.\n\n3. **Limited Theoretical or Consistency Analysis**\n   While the “wavefront” intuition is compelling, the paper does not formalize why this adaptive frontier expansion should outperform fixed or global schedules. The MHCO metric shows improved consistency, yet the connection between this measure and denoising optimality remains informal. Moreover, the sensitivity of MHCO to its hyperparameter $R$ (the frontier radius) is not analyzed, leaving unclear whether its interpretability or stability depends on this choice. A brief theoretical or empirical study of MHCO’s dependence on $R$ would improve clarity.\n\n4. **Lack of Analysis on Long-Sequence Behavior**\n   Although the paper reports results on reasoning and code benchmarks, it does not visualize or analyze how the frontier evolves for long sequences. For instance, it is unclear whether the wavefront ever converges prematurely or oscillates during extended decoding. A step-wise visualization or “finalization regret” analysis would clarify how the dynamic schedule behaves as sequence length grows.\n\n5. **Efficiency and Scoring Computation**\n   In the core iterative process, the model scores all masked positions before selecting the top-$k$ candidates from the current frontier $W_{t−1}$. This full scoring procedure may increase computational cost. The paper does not discuss whether a *localized* scoring strategy—scoring only masked tokens near the current wavefront—has been tested, nor whether it could reduce compute while maintaining performance.\n\n6. **Presentation and Appendix Details**\n   Some hyperparameter details and appendix cross-references could be clearer. For instance, the main text does not specify the exact ranges or adaptation rules for $R$ and $F$ across tasks. Additionally, an explicit scope note that this work focuses solely on *discrete* diffusion (rather than continuous-space diffusion) would help prevent confusion.\n\n7. **Evaluation Limited to a Single Model**\n   All experiments are conducted on LLaDA-8B. Although the method is described as “model-agnostic,” it is not validated on other diffusion language models with different masking or training policies. Since diffusion LMs vary in their noise formulation, reweighting, and decoding dynamics, results based solely on one model may not fully establish generality. Demonstrating consistent improvements across multiple diffusion models would further strengthen the claim.\n   \n8. **Missing long-sequence scalability analysis**\n   The paper does not analyze wavefront dynamics on long sequences (e.g., premature convergence or oscillation). Visualizing the frontier trajectory and reporting a “finalization regret” diagnostic would clarify stability as sequence length grows."}, "questions": {"value": "1. **Confidence Stability:**\n   Have the authors evaluated how WavefrontDiffusion’s performance changes under temperature scaling or calibration shifts? If confidence scores become over- or under-confident, does the frontier expansion remain stable? Would entropy-based or learnable temperature gating improve robustness?\n\n2. **Baseline Scope:**\n   Could the authors include comparisons with other dynamic decoding approaches (e.g., remasking-based or truncated-block methods) under the same $F×T$ compute constraint? This would help isolate the benefits of the scheduling mechanism itself from those of confidence gating.\n\n3. **Long-Sequence Dynamics:**\n   For long reasoning or code-generation tasks, how does the frontier expand and finalize over time? Are there cases of premature convergence or late instability? A quantitative or visual analysis would be insightful.\n\n4. **Theoretical Insight:**\n   Can the authors provide intuition or approximate analysis explaining why expanding around finalized tokens with radius $R$ improves semantic fidelity? Does this mechanism implicitly encourage smoother denoising trajectories or faster entropy reduction?\n\n5. **Calibration Ablation:**\n   Have the authors tested whether applying calibration techniques (e.g., temperature scaling or isotonic regression) changes the MHCO metric or final accuracy? This would clarify the sensitivity of the method to calibration errors.\n\n6. **Model Dependency:**\n   The method is evaluated only on LLaDA. Does the approach depend on LLaDA’s specific sequence-level noise or architecture? Would it generalize to other diffusion language models, such as those using token-level noise or trained with reinforcement learning? Any preliminary evidence or reasoning supporting model-agnostic applicability would be valuable.\n\n7. **MHCO Sensitivity:**\n   Since MHCO depends on the radius $R$, have the authors examined how different $R$ values affect MHCO scores? Does the metric remain consistent across reasonable $R$ choices, or is it highly sensitive to this hyperparameter?\n\n8. **Localized Scoring Efficiency:**\n   In the core iterative process, the model first scores *all* masked positions before selecting tokens from the current wavefront $W_{t−1}$. Have the authors tested a variant where scoring is restricted to $W_{t−1}$ and its neighboring masked positions? Would this local scoring reduce computational cost without hurting performance?\n9. **Long-sequence dynamics and stability:** \n   On longer reasoning/generation sequences, does the wavefront exhibit premature freezing or oscillation? Could you report curves/statistics of frontier radius $R$, finalized-token ratio, and “finalization regret” over steps and sequence length?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DSyNel63zW", "forum": "4smJ6zY7vy", "replyto": "4smJ6zY7vy", "signatures": ["ICLR.cc/2026/Conference/Submission6877/Reviewer_M3nR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6877/Reviewer_M3nR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761792580879, "cdate": 1761792580879, "tmdate": 1762919128078, "mdate": 1762919128078, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "WavefrontDiffusion dynamically expands a confidence-guided frontier in diffusion LMs, preserving context, matching block compute, and improving reasoning/code accuracy and semantic fidelity across benchmarks under compute-parity."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The method avoids premature EOS and half-baked spans by not locking in locally high confidence tokens too early.\n2. It completes semantically “ready” regions first (e.g., function signatures, reasoning steps) and is not hostage to rigid chunk boundaries."}, "weaknesses": {"value": "1. Only F and R are studied; there is no analysis of the per-step finalize quota k_t, nor strict equal FLOPs / equal token updates controls.\n2. The setup is mostly zero-shot with T=1024 and temperature 0; it lacks length/temperature sweeps and multi-seed variance.\n3. The very long context engineering story is unclear; the overhead of frontier maintenance and cache policies at extreme lengths is not evidenced.\n4. Autoregressive baselines at matched latency are missing; there is no head-to-head against speculative decoding under equal delay/throughput.\n5. Early errors can still propagate; once an incorrect span is finalized, downstream reasoning may be constrained by that commitment."}, "questions": {"value": "1. Add equal FLOPs and equal token updates tables, and ablate k_tallocation strategies.\n2. Report mean/σ over multiple seeds, and vary context length, temperature, and prompting (few-shot, CoT).\n3. Test entropy/energy or calibrated confidence to reduce dependence on raw max-softmax.\n4. Include longer-context reasoning and additional code sets (e.g., MBPP, DS-1000).\n5. Provide matched-latency/throughput, end-to-end comparisons vs. speculative decoding to map advantage boundaries."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "X2A2VGkjwb", "forum": "4smJ6zY7vy", "replyto": "4smJ6zY7vy", "signatures": ["ICLR.cc/2026/Conference/Submission6877/Reviewer_my5v"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6877/Reviewer_my5v"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761889341105, "cdate": 1761889341105, "tmdate": 1762919127623, "mdate": 1762919127623, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a dynamic decoding scheduling strategy named WavefrontDiffusion, designed to address the issues of semantic coherence and computational efficiency in text generation with diffusion language models. Whereas traditional decoding strategies like Standard Diffusion and BlockDiffusion have inherent limitations, WavefrontDiffusion dynamically expands a \"wavefront\" region of active tokens. This allows the denoising process to align with the natural flow of semantic structure while maintaining the same computational cost as block-based methods. Experiments demonstrate that this approach achieves state-of-the-art performance across multiple benchmarks and generates outputs with higher semantic fidelity. This research presents a new paradigm for applying diffusion models to complex reasoning and code generation tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The method is intuitive and addresses the limitations of hard boundaries in BlockDiffusion.\n\n2. The research methodology is well-structured, with clear explanations of the wavefront theory, a four-step algorithm, and mathematical definitions. The experimental design covers four benchmark tests and evaluates the method using multiple metrics such as accuracy, BERTScore, and the MHCO indicator.\n\n3. The experimental analysis is thorough and provides insights into parameter selection."}, "weaknesses": {"value": "1. The method is an incremental improvement over BlockDiffusion; both the methodology and the experimental results are incremental in nature.\n\n2. Regarding the writing, Figure 1 is not sufficiently intuitive and requires further revision."}, "questions": {"value": "1. Are there any unique application scenarios where this method can demonstrate a more significant advantage over BlockDiffusion?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "KKT5gTW6B9", "forum": "4smJ6zY7vy", "replyto": "4smJ6zY7vy", "signatures": ["ICLR.cc/2026/Conference/Submission6877/Reviewer_skjz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6877/Reviewer_skjz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991457329, "cdate": 1761991457329, "tmdate": 1762919127071, "mdate": 1762919127071, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces WavefrontDiffusion, a dynamic decoding strategy for Diffusion Language Models that adaptively expands a “wavefront” of active tokens during generation. This approach preserves semantic coherence and contextual completeness while keeping the same computational cost as block-based methods. Experiments on reasoning and code generation benchmarks show that WavefrontDiffusion consistently improves accuracy and output quality over existing diffusion decoding strategies."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. WavefrontDiffusion dynamically adjusts the denoising process to follow the evolving semantic structure, preventing premature or fragmented token generation.\n\n2. By expanding from finalized tokens outward, it ensures each token is generated with sufficient context, leading to smoother and more logically consistent outputs.\n\n3. The method matches the computational cost of block-based decoding while delivering higher accuracy and better output quality."}, "weaknesses": {"value": "1. The paper lacks a baseline for its method. It needs to compare its approach with current decoding methods in the DLM field to demonstrate its advantages.\n\n2. Experiments were only conducted on one model category. Similar experiments need to be performed on Dream for comparison."}, "questions": {"value": "1. Will this method slow down the inference process? How does its speed compare to other methods?\n\n2. Could you run the results on MBPP?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Vg09GH9cTr", "forum": "4smJ6zY7vy", "replyto": "4smJ6zY7vy", "signatures": ["ICLR.cc/2026/Conference/Submission6877/Reviewer_HnuB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6877/Reviewer_HnuB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6877/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762157397081, "cdate": 1762157397081, "tmdate": 1762919126448, "mdate": 1762919126448, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}