{"id": "vphWR1NwGW", "number": 6441, "cdate": 1757984129021, "mdate": 1759897914437, "content": {"title": "REVOLUTIONIZING EVENT DETECTION: A NOVEL PROMPT-DRIVEN METHOD ENHANCED BY RETRIEVAL-AUGMENTED PARADIGM", "abstract": "Event Detection (ED) task involves extracting event triggers from sentences and classifying them into predefined event types. While large language models (LLMs) have become widely adopted across various NLP tasks, their application to ED remains relatively unexplored. All existing LLM-based approaches follow a traditional prompt-based paradigm, which requires designing distinct prompts for each event type. This strategy, however, suffers from a fundamental limitation: as the number of event types grows, the number of prompts needed increases linearly, resulting in significant manual effort and computational costs. To overcome this limitation, we propose a novel approach that integrates a retrieval-augmented mechanism with a redesigned cascading prompt-based framework. Specifically, the prompt-based component is employed to extract candidate triggers, while the retrieval-augmented module applies heuristic filtering strategies to coarsely eliminate irrelevant candidates. In addition, we put forward an innovative automated prompt-design method to accurately match valid triggers with their corresponding event types based on retrieved information. Experimental results on ACE-05 benchmark demonstrate the state-of-the-art performance under our scheme. Furthermore, the approach remains highly effective when using lightweight LLMs, indicating its strong potential for efficient large-scale data processing. This capability may have profound implications and become a fundamental work for future research.", "tldr": "", "keywords": ["Event Detection", "Large Language Models(LLMs)", "Lightweight LLMs", "Cascading Prompt-Based Framework", "Automated Prompt-Design"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/db45d18277a50b4cd047dc31a4b5140ee5e477c3.pdf", "supplementary_material": "/attachment/419e491a77f1cc075d15d0705ed2c745987db757.zip"}, "replies": [{"content": {"summary": {"value": "The author proposes a novel retrieval-augmented prompt-driven method that integrates a retrieval augmentation mechanism with a redesigned cascaded prompt-driven framework for sentence-level event extraction. The proposed method demonstrates relatively good performance even on smaller parameter large language models."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1 . The proposed method demonstrates relatively good performance even on smaller parameter large language models."}, "weaknesses": {"value": "Weaknesses:\n\n1. The task conducted remains one of the most fundamental tasks in event extraction. To my knowledge, event extraction in the ACE dataset not only includes trigger word extraction but also involves entities and the matching of entities with events. Merely extracting trigger words and identifying their types may not hold significant meaning after the emergence of large models, and the author may have overstated the contribution's value.\n\n2. Although the ACE dataset is a benchmark for event extraction, it is still limited to sentence-level event extraction and is relatively outdated. Relying solely on one dataset to validate the method appears insufficient.\n\n3. It remains unclear whether the proposed method is applicable to paragraph-level event extraction.\n\n4. To my knowledge, without using large models, the accuracy of fine-tuned smaller models on the ACE dataset has already reached around 75. The author's results, however, are too low. For instance, the original DICE paper reported F1 scores of 75.22 and 70.46 for trigger word identification and classification, respectively, on the ACE dataset. In contrast, the author's results are only in the teens, which seems excessively low and warrants further scrutiny.\n\n5. The overall experimental design is overly simplistic, making it difficult to fully demonstrate the effectiveness of the proposed method. How does the performance of the comparative methods compare to fine-tuned non-model-based methods?"}, "questions": {"value": "see Weaknesses"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "8k8WocyQLo", "forum": "vphWR1NwGW", "replyto": "vphWR1NwGW", "signatures": ["ICLR.cc/2026/Conference/Submission6441/Reviewer_Jaj5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6441/Reviewer_Jaj5"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6441/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761576751463, "cdate": 1761576751463, "tmdate": 1762918834603, "mdate": 1762918834603, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents REVO-ED, an event detection framework combining a multi-step cascading prompt strategy with a dual retrieval mechanism, aiming to reduce manual prompt design and improve scalability."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. Introduces an automated ED approach that alleviates per-event-type manual prompt design, improving scalability.\n\n2. Achieves competitive performance with lightweight LLMs on ACE-05."}, "weaknesses": {"value": "1. All experiments are conducted solely on ACE-05 (2006), which is relatively small and outdated, lacking validation on larger, more complex, or cross-domain datasets.\n\n2. The proposed framework essentially combines multiple LLM components into a multi-step pipeline, with several empirically chosen hyperparameters (e.g., the number of prefix words set to 6, similarity threshold set to 0.7) derived purely from observation. This raises concerns about the need to re-tune parameters for different datasets, given the absence of theoretical justification or adaptive mechanisms.\n\n3. The current setup involves only 33 event types. Since the method claims efficiency compared to per-type prompt design, experiments with significantly more event types would help validate this advantage.\n\n4. The retrieval database is constructed from the training set. If test samples are semantically close to training sentences, performance might be inflated, potentially limiting generalization."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4AsasYog5L", "forum": "vphWR1NwGW", "replyto": "vphWR1NwGW", "signatures": ["ICLR.cc/2026/Conference/Submission6441/Reviewer_L64g"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6441/Reviewer_L64g"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6441/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761827390939, "cdate": 1761827390939, "tmdate": 1762918834268, "mdate": 1762918834268, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new prompt-based method for event detection. Specifically, this paper addresses a key limitation of previous work: as the number of event types grows, the number\nof prompts needed increases linearly, resulting in significant manual effort and computational costs. Therefore, this paper propose a new method which integrates a retrieval-augmented mechanism with a redesigned cascading prompt-based framework. This method first extracts candidate trigger and then use the retrieval-augmented module to filter irrelevant candidates. Finally, this method adopts a prompt-based method to accurately match valid triggers with their corresponding event types based on retrieved information. Experimental results on ACE 2005 demonstrates the effectiveness of the proposed method."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The topic focused in this paper is meaningful. Enabling LLMs to automatically extract events is highly meaningful for advancing information extraction and deep information seeking (such as DeepResearch).\n2. The presentation of the paper is clear and easy to follow."}, "weaknesses": {"value": "1. The proposed method mainly relies on prompt engineering for a specific task, without demonstrating its generalizability. For such tasks, a fine-tuned BERT model often performs quite well, which raises concerns about the paper’s fundamental contribution and technical novelty.\n2. The experiments are not sufficiently comprehensive, as evaluation is conducted only on the ACE 2005 dataset. It would be more convincing to include additional benchmarks such as TACKBP or RAMS to better validate the method’s effectiveness. Furthermore, prior studies have found limitations in the evaluation of existing IE datasets [1]. It is unclear whether the authors have considered these issues. The paper would also benefit from comparisons with smaller, task-specific fine-tuned models, such as BERT, RoBerta, etc.\n\n[1] Xu, Derong, et al. \"Large language models for generative information extraction: A survey.\" *Frontiers of Computer Science* 18.6 (2024): 186357."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eaKVufU0Bh", "forum": "vphWR1NwGW", "replyto": "vphWR1NwGW", "signatures": ["ICLR.cc/2026/Conference/Submission6441/Reviewer_8yGw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6441/Reviewer_8yGw"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6441/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925507125, "cdate": 1761925507125, "tmdate": 1762918833861, "mdate": 1762918833861, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a cascade prompting and retrieval-augmented pipeline for event detection with LLMs. It over-generates candidate triggers using generic prompts, then filters and assigns event types via dual-granularity vector retrieval with lightweight LLM judgments. On ACE-05, the method reports state-of-the-art results without task-specific fine-tuning and with a small prompt budget. The work is positioned for resource-constrained, practical deployments."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper presents a successful application of LLMs to the ED task. \n2. The proposed methods outperform previous LLM-based approaches and are practical for real-world use."}, "weaknesses": {"value": "1. The model was only tested on a single dataset. It's unclear if it actually works in other situations or if it can handle unexpected inputs.\n\n2. There was basically no new training or fine-tuning, and the improvements are tiny. This \"innovation\" sounds more like just optimizing the workflow rather than creating a genuinely new model.\n\n4. The range of problems it solves is too narrow, and it doesn't even include argument extraction, which is a pretty important part of event extraction field.\n\n5. The paper doesn't compare it to the latest top-tier models (like GPT-5 or Gemini 2.5 Pro), which makes its experimental results less convincing.\n\n6. It also skips comparisons with older, smaller supervised models, so it's hard to tell if this new approach is even better than those."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "iAyJja5vqu", "forum": "vphWR1NwGW", "replyto": "vphWR1NwGW", "signatures": ["ICLR.cc/2026/Conference/Submission6441/Reviewer_hzQF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6441/Reviewer_hzQF"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6441/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762104382615, "cdate": 1762104382615, "tmdate": 1762918833366, "mdate": 1762918833366, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}