{"id": "UtFQNwWBaA", "number": 23718, "cdate": 1758347513746, "mdate": 1759896800316, "content": {"title": "HiT-JEPA: A Hierarchical Self-supervised Trajectory Embedding Framework for Similarity Computation", "abstract": "The representation of urban trajectory data plays a critical role in effectively analyzing spatial movement patterns. Despite considerable progress, the challenge of designing trajectory representations that can capture diverse and complementary information remains an open research problem. Existing methods struggle in incorporating trajectory fine-grained details and high-level summary in a single model, limiting their ability to attend to both long-term dependencies while preserving local nuances. To address this, we propose HiT-JEPA (Hierarchical Interactions of Trajectory Semantics via a Joint Embedding Predictive Architecture), a unified framework for learning multi-scale urban trajectory representations across semantic abstraction levels. HiT-JEPA adopts a three-layer hierarchy that progressively captures point-level fine-grained details, intermediate patterns, and high-level trajectory abstractions, enabling the model to integrate both local dynamics and global semantics in one coherent structure. Extensive experiments on multiple real-world datasets for trajectory similarity computation show that HiT-JEPA's hierarchical design yields richer, multi-scale representations.", "tldr": "", "keywords": ["urban trajectory representation learning", "trajectory similarity computation", "hierarchical self-supervised learning", "transformers", "joint embedding predictive architecture"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a8aa29a42d7b515abaa91b93a270a9c3b3405231.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes HiT-JEPA, a framework for learning multi-scale urban trajectory representations across different semantic abstraction levels. This framework constructs a three-layer hierarchical structure, which generates local point-level, intermediate segment-level patterns, and high-level global route structure. HiT-JEPA also includes a joint embedding predictive architecture to incoporate multiple levels of abstractions and approximate the target trajectory. Experiments on real-world urban GPS trajectory datasets show that HiT-JEPA exhibits stable performance in self-similarity search, zero-shot scenarios, and downstream fine-tuning tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. HiT-JEPA constructs a three-layer hierarchical structure within a single model using three pooling layers. It is the first architecture to explicitly unify both fine-grained and abstract trajectory patterns in one framework.\n\n2. Experiments on multiple real-world datasets and few-shot learning tasks demonstrate its generalizability."}, "weaknesses": {"value": "1. The paper lacks sufficient novelty and mainly appears to be an implementation of industry approaches.\n2. The experimental section lacks sufficient and diverse baselines, for example transformer-based sequence forcasting methonds.\n3. The paper does not provide detailed interpretations or examples to demonstrate how the learned three-layer structure captures different levels of semantics. It remains unclear whether the extracted multi-scale trajectory representations truly correspond to point-level or higher-level semantics.\n4. Multi-layer Transformer struction can also capture multi-granular information: lower layers typically encode specific input semantics, intermediate layers abstract higher-level concepts, and final layers contribute to generation or prediction. It would be helpful to explain why the authors chose a multi-layer convolutional structure instead of multi-layer Transformer. Would the convolutional yield any advantage in performance or interpretability?"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vtqt7X9TkU", "forum": "UtFQNwWBaA", "replyto": "UtFQNwWBaA", "signatures": ["ICLR.cc/2026/Conference/Submission23718/Reviewer_ZHZ7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23718/Reviewer_ZHZ7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761619466670, "cdate": 1761619466670, "tmdate": 1762942778083, "mdate": 1762942778083, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents HiT-JEPA, a hierarchical self-supervised framework for trajectory representation that explicitly models point-level, segment-level, and trajectory-level semantics with cross-level interactions. A JEPA (Joint Embedding Predictive Architecture) objective aligns representations in embedding space, complemented by VICReg-style regularization to prevent collapse. Experiments across multiple cities/modalities (including AIS) show strong retrieval performance and promising zero-shot generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Address single-scale bias by introducing an explicit multi-scale hierarchy with information flow across levels.\n- Propose a JEPA-style training reduces reliance on heavy data augmentation; ablations indicate the benefit of hierarchical interactions.\n- Extensive experiments across datasets and zero-shot settings supports generalization claims."}, "weaknesses": {"value": "- Only two contrastive learning baselines are compared in the experiments. There are many trajectory representation learning works should be compared. \n- The interpretations of the results of HiT-JEPA are quite confusing. It would be better to explain why the two showcases can illustrate the interpretation of the proposed method.\n- For different trajectory abstraction method, the results would change. From equation (3)-(5), the sampling rate are 50% and 25% of orginal trajectories which may not be the best setting.  How  the abstraction method influence the results should be disscussed. \n- The efficiency of JEPA should be considered."}, "questions": {"value": "See the weakness above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "GVb8DnzthY", "forum": "UtFQNwWBaA", "replyto": "UtFQNwWBaA", "signatures": ["ICLR.cc/2026/Conference/Submission23718/Reviewer_19oU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23718/Reviewer_19oU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896337724, "cdate": 1761896337724, "tmdate": 1762942777786, "mdate": 1762942777786, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces HiT-JEPA, a hierarchical self-supervised framework for learning urban trajectory embeddings suitable for similarity computation. HiT-JEPA employs a three-level joint embedding predictive architecture (JEPA) to progressively capture point-level, segment-level, and global trajectory abstractions, integrating top-down and multi-scale semantic information. The approach is evaluated extensively against state-of-the-art baselines on multiple urban trajectory datasets, including zero-shot, and downstream tasks. Results claim remarkably improvements in mean ranking performance, generalization, and ablation integrity on various trajectory similarity and retrieval tasks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. HiT-JEPA proposes an explicit three-layer architecture that learns and aligns representations at point, segment, and trajectory levels.\n\nS2. The method implements a novel attention propagation strategy between abstraction levels. And it upsamples higher-level attention maps to guide feature extraction at lower levels.\n\nS3. HiT-JEPA demonstrates exceptional zero-shot performance across heterogeneous datasets. Experimental design is rigorous and covers critical scenarios like self-similarity, ablation and visualization."}, "weaknesses": {"value": "W1. This manuscript has presented limited novelty comparing to prior works. The JEPA and multi-scale structure build heavily on established elements in self-supervised learning, attention propagation, and urban trajectory modeling. The direct design leap over T-JEPA, is incremental rather than a decisive paradigm shift, especially given already cited work such as HIBERT and HiCLRE in NLP and CV. So, this work simply applies these models to the trajectory dataset without making more targeted designs based on the characteristics of trajectory data.\n\nW2. The manuscript claims high-level attention \"guides local feature extraction\" but does not clarify what specific semantic information high-level attention captures. The authors should provide specific explanations regarding the \"semantic information,\" such as the clustering characteristics of trajectories or the motion features of moving objects. They may even need to include a case study to illustrate this point. Otherwise, the high-level attention mechanism remains a black box, merely effective by coincidence in the current dataset.\n\nW3. HiT-JEPA uses Uber H3 grids to map GPS coordinates instead of traditional rectangular grids but failing to explain how H3â€™s hexagonal symmetry improves trajectory spatial relation modeling. The effectiveness of these two grid-based methods should also be compared experimentally."}, "questions": {"value": "Q1. Provide more description about the trajectory-specific model designs, explaining how these designs enhance the effectiveness of trajectory similarity computation, and discuss the differences when applied in the NLP and CV domains.\n\nQ2. Add attention-weight visualizations and controlled experiments to clarify and show how it quantifies the guidance. Or add a case study to show the effectiveness of a high-level attention mechanism.\n\nQ3. Conduct an ablation study comparing H3 grids with rectangular grids on selected datasets."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "4SHtYvZf2K", "forum": "UtFQNwWBaA", "replyto": "UtFQNwWBaA", "signatures": ["ICLR.cc/2026/Conference/Submission23718/Reviewer_uZkJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23718/Reviewer_uZkJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23718/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970502646, "cdate": 1761970502646, "tmdate": 1762942777554, "mdate": 1762942777554, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new trajectory representation approach that models trajectory semantics through three hierarchical layers at different granularities: point, segment, and the whole trajectory. Specifically, it follows similar ideas to JEPA and T-JEPA by training a trajectory encoder for each layer and applying different random masks to encourage the model to predict the masked portions. Experiments on several benchmarks for trajectory similarity search tasks demonstrate the generalization and effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. The paper is easy to read, and the argument that existing methods lack hierarchical representations is both interesting and important.\nS2. The methodology, although based on techniques used in previous studies, is sound and well-justified."}, "weaknesses": {"value": "W1. Although it is interesting to consider different levels of trajectory semantics, the authors do not provide sufficient experimental evidence to show the effectiveness of their approach. For example, it is unclear which representation layers (S1, S2, S3, or their combination) are used for the trajectory similarity search experiments. These details appear to be missing. If the proposed framework indeed works as claimed, the different representations should capture distinct semantic meanings of trajectories. Therefore, different tasks tailored to each learned representation should be included. For example, trajectory clustering, which groups trajectories based on high-level semantic similarities, should be compared with existing deep-learning-based clustering methods. Additionally, behavioral pattern detection would be an ideal task to demonstrate the usefulness of intermediate representations. Currently, the experiments are limited to trajectory similarity tasks (self-similarity and similarity search via fine-tuning), which are insufficient to demonstrate the advantages of hierarchical representations.\n\nW2. The use of self-similarity does not very meaningful in this context. Since HiT-JEPA is trained with random masking of trajectory points, strong self-similarity results are somewhat expected. The paper focuses heavily on similarity matching as the sole measure of embedding quality, which is inadequate. Moreover, for the Porto dataset, where performance is worse than on others, the authors attribute this to higher sampling frequency. While this explanation is plausible, the paper should more explicitly discuss this limitation and clarify the scenarios where the proposed method may or may not be effective.\n\nW3. Can the learned encoder be applied to trajectories from different geographic regions without retraining from scratch? Discussing this aspect would strengthen the claims about generalization and practical applicability."}, "questions": {"value": "Please see above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OHdTBnpiAs", "forum": "UtFQNwWBaA", "replyto": "UtFQNwWBaA", "signatures": ["ICLR.cc/2026/Conference/Submission23718/Reviewer_db7G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23718/Reviewer_db7G"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23718/-/Official_Review"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763260761529, "cdate": 1763260761529, "tmdate": 1763260761529, "mdate": 1763260761529, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}