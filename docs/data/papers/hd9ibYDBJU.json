{"id": "hd9ibYDBJU", "number": 22522, "cdate": 1758332236027, "mdate": 1759896861603, "content": {"title": "FACTS: A Future-Aided Causal Teacher-Student Framework for Multimodal Time Series Forecasting", "abstract": "Traditional \\emph{unimodal} time series forecasting models often perform unreliably in real-world applications because they fail to capture the underlying causal drivers of temporal change. Fortunately, auxiliary modalities can unveil these drivers, \\textit{e.g.}, sky images capture the illumination conditions that govern solar power generation. However, the most informative \\emph{future} auxiliary signals directly tied to the target time series are unavailable at inference, while integrating such data is further hindered by cross-modal heterogeneity and structural mismatch. To address these challenges, we propose FACTS, a Future-Aided Causal Teacher-Student framework for \\emph{multimodal} time series forecasting. The teacher network, used only during training, leverages future auxiliary data to disentangle the causal responses underlying temporal dynamics, while the student network, trained solely on historical data, learns such causal knowledge via our proposed causal-perturbation contrastive distillation. To accommodate heterogeneous inputs, we design a bilinear orthogonal projector that efficiently converts high-dimensional auxiliary data into a compact series over time, allowing us to model both auxiliary data and time series via a unified bidirectional attention backbone. Furthermore, we devise a lag-aware fusion to align cross-modal signals within a tolerance window and apply random modality dropout to enhance student's robustness to modality missingness. Extensive experiments on benchmark datasets demonstrate that FACTS significantly outperforms state-of-the-art methods, achieving average improvements of 32.98\\% in MSE and 22.25\\% in MAE. Code is available at \\url{https://github.com/anonymous202402/FACTS}.", "tldr": "A future-aided causal teacher-student framework for multimodal time series forecasting", "keywords": ["Multimodal time series forecasting", "knowledge distillation", "causal learning"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/867cb10838acac6761f808bf64c1bab65b586508.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes FACTS, a Future-Aided Causal Teacher-Student framework for multimodal time series forecasting. The key idea is to leverage future auxiliary modalities (such as images and weather data) during training to uncover causal factors that drive temporal dynamics, and distill this knowledge into a student network that uses only historical data at inference.\n\nThe method introduces three main components: (1) a Bilinear Orthogonal Projector (BOP) that converts high-dimensional auxiliary data into compact serialized time series; (2) a lag-aware multimodal fusion mechanism with random modality dropout to handle temporal misalignment and missing modalities; and (3) a Causal-Perturbation Contrastive Distillation (CPCD) objective that transfers causal knowledge from the teacher to the student. Experiments on four multimodal forecasting datasets show significant performance gains (around 33% lower MSE on average) over state-of-the-art baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed teacher-student design, which leverages future multimodal signals to facilitate causal representation learning while maintaining a purely historical input during inference, is both conceptually elegant and practically impactful. It effectively balances realism (no future data at test time) with enhanced learning through privileged information.\n\n2. The model is comprehensively evaluated on several diverse and representative datasets, demonstrating the framework‚Äôs robustness and adaptability across various multimodal forecasting scenarios.\n\n3. The experiments include thorough comparisons against a wide range of baselines, covering both unimodal and multimodal forecasting methods, thereby providing convincing evidence of the model‚Äôs superior performance and general applicability.\n\n4. The paper conducts detailed ablation studies that isolate and analyze the contribution of each component‚Äîsuch as BOP, CPCD, and lag-aware fusion‚Äîclearly demonstrating their necessity and complementary effects within the overall framework."}, "weaknesses": {"value": "see in questions."}, "questions": {"value": "1. The paper does not clearly specify the training schedule of the teacher‚Äìstudent framework. Is the teacher network fully trained to convergence before the student distillation begins, or are the two networks optimized jointly in an alternating or end-to-end manner?\n\n2. The Bilinear Orthogonal Projector (BOP) is primarily demonstrated on image data. Could the authors elaborate on its generality‚Äîspecifically, whether BOP can be effectively adapted to other high-dimensional modalities such as text embeddings, audio spectrograms, or video streams? If not, what limitations might arise when extending it beyond visual inputs?\n\n3. How significant is the computational overhead incurred by using both teacher and student networks, especially when compared to alternative approaches? Could the authors provide quantitative estimates or benchmarks to clarify this aspect?\n\n4. The paper claims that random modality dropout enhances robustness when certain modalities are missing at inference time. Have the authors conducted experiments under more extreme or persistent missing-modality scenarios (e.g., complete loss of image data throughout inference)? Such evaluation would provide stronger evidence for the model‚Äôs robustness and practical deployability in real-world settings with unreliable sensors.\n\n5. Is the ratio ùúÜ between the MSE loss and the CPCD loss a manually set hyperparameter or a learnable parameter? What is the value of this parameter, and how does varying ùúÜ affect the final model performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aHuleMPMRV", "forum": "hd9ibYDBJU", "replyto": "hd9ibYDBJU", "signatures": ["ICLR.cc/2026/Conference/Submission22522/Reviewer_UwUE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22522/Reviewer_UwUE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22522/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761731625739, "cdate": 1761731625739, "tmdate": 1762942257904, "mdate": 1762942257904, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors describe a method for inferring causal information related to time series by distilling a larger teacher model that does not require direct observations at test times. The main design choices of the architecture are to allow heterogeneous multimodal data to influence the time series prediction. The authors illustrate the performance of the method on a series of data sets and indicate that the proposed method outperforms the baselines."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The model empirically works very well and was tested on a variety of challenging datasets. \n\nThe authors consider a challenging problem and use a variety of techniques to propose a solution."}, "weaknesses": {"value": "There does not seem to be a cohesive underlying reasoning for the improvement in performance. The paper introduces a number of known techniques in combination with their particular problem to indicate improvements in performance. However, it‚Äôs not a unifying theme underlying all of the changes the authors include to the model.  \n\nThere do not seem to be any guarantees to ensure that the method is able to accurately disentangle the causal relationships, which is the main motivator of the paper."}, "questions": {"value": "Did the authors consider any tests to see how well orthogonality is preserved during training? \n\nAre there any specific guarantees one can make on the performance under perturbations such as spurious correlations? It would be interesting to see if the loss can be analyzed such that one can understand the conditions under which the model will be robust to such artifacts. \n\nUnder what conditions on the data can the model disentangle the underlying causal factors? Maybe analyzing this could be helpful to making stronger claims regarding the expected model performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "NoMfVRiS9F", "forum": "hd9ibYDBJU", "replyto": "hd9ibYDBJU", "signatures": ["ICLR.cc/2026/Conference/Submission22522/Reviewer_LJVM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22522/Reviewer_LJVM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22522/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761944283049, "cdate": 1761944283049, "tmdate": 1762942257454, "mdate": 1762942257454, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FACTS, a teacher-student framework designed to address multimodal time series forecasting by leveraging auxiliary modalities to capture causal drivers of temporal dynamics. The core innovation lies in using a teacher network with access to future auxiliary data during training to distill causal knowledge into a deployable student network that uses only historical data. The authors test FACTS on four datasets and report performance improvements over baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Articulates why unimodal forecasting fails and why auxiliary modalities capture critical causal drivers.\n2. Using perturbed future auxiliary data as negative samples in contrastive distillation is intuitive and aligns with causal learning principles.\n3. Compares against methods spanning unimodal, LLM-based, and multimodal approaches with systematic ablations.\n4. Outperforms baselines on various datasets with reduced standard deviations, suggesting robustness."}, "weaknesses": {"value": "1. Teacher-student distillation, contrastive learning, and bilinear factorization are well-established; the contribution is primarily architectural integration rather than methodological innovation.\n2. The author emphasized the multimodal, but only compared three multimodal datasets.\n3. No justification for why Œ¥_max = {0,1,...,5} works across datasets.\n4. Many hyperparameters are introduced; how to keep the fairness of these hyperparameters across different datasets?"}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)"]}, "details_of_ethics_concerns": {"value": "The author did not use an anonymous GitHub repository, which may potentially expose identifying information. This is not a major issue, but it should have been mentioned."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o5mtmya4Lx", "forum": "hd9ibYDBJU", "replyto": "hd9ibYDBJU", "signatures": ["ICLR.cc/2026/Conference/Submission22522/Reviewer_o6rZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22522/Reviewer_o6rZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22522/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761997848190, "cdate": 1761997848190, "tmdate": 1762942257067, "mdate": 1762942257067, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}