{"id": "C0NdeKlyIt", "number": 21751, "cdate": 1758321278174, "mdate": 1759896904958, "content": {"title": "Imputing Incomplete Building Attribute Data Using Expert-Guided Variational Autoencoders (EGVAE)", "abstract": "Human activity is organized by the physical infrastructure such as roads and buildings, making their characterization essential for applications ranging from disaster preparedness and national security to real estate analytics and public resource allocation. Despite the availability of datasets detailing building attributes many of these are incomplete, particularly in data scarce regions, limiting their utility in critical decision making tasks. We propose a deep learning approach for imputing missing building attributes by learning from sparse to no observed data, expert knowledge, and spatial correlations among buildings. Our model is based on a Vector Quantised-Variational AutoEncoder (VQ-VAE) architecture with a graph neural network (GNN) encoder that captures spatial dependencies, while an additional KL-divergence based loss term incorporates expert-informed priors. By jointly leveraging observed data and expert-informed priors, the model learns latent representations that enable imputing missing data for attributes with little or no training data. Experimental results on real-world datasets demonstrate the robustness and effectiveness of our proposed method.", "tldr": "We propose a building attribute imputation method when no or limited training data is available. In such scenarios existing ML algorithms fail to generate imputations, our method leverages expert opinions to generate sensible imputations", "keywords": ["Building Attribution", "Data Imputation", "Variational AutoEncoder", "Causal Graph", "Expert Priors", "Neural Networks"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/906a41842d9cacb421958ce9655bea61b91cf855.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Although infrastructure attribute data are important, \nregions with scarce data suffer from many missing values. \nThis paper proposes Expert-Guided Variational Autoencoders (EGVAE), \na VQ-VAE with a GNN encoder that captures spatial correlations and incorporates expert prior knowledge via a KL loss. \nThe proposed method can learn latent variables that enable imputation even for attributes with little to no observed data. \nExperiments on various real-world datasets show that the proposed method outperforms existing approaches, especially in data-scarce settings."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "I am not an expert in this field, but the proposed method,\nwhich combines a VQ-VAE with a GNN encoder and regularization based on conditional probability tables,\nappears simple yet effective.\nThis method achieves strong performance on real data, \nand the ablation study sufficiently demonstrates which modules are effective."}, "weaknesses": {"value": "Please see the Questions section."}, "questions": {"value": "- In Section 2.3, the introduced loss function does not appear to weight the individual loss terms. I suspect that adding hyperparameters as weights to each term could improve performance. Did you conduct experiments along these lines?\n- For missing-data imputation, I believe CPT-based regularization is important, yet in Figure 6 the No KL-div condition looks quite similar. What effect does this regularization have in the latent variable space?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "gUkLCqjTlU", "forum": "C0NdeKlyIt", "replyto": "C0NdeKlyIt", "signatures": ["ICLR.cc/2026/Conference/Submission21751/Reviewer_aCgK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21751/Reviewer_aCgK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21751/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761886269030, "cdate": 1761886269030, "tmdate": 1762941918408, "mdate": 1762941918408, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose EGVAE (Expert-Guided Variational Autoencoder) to impute incomplete building attribute data (e.g., roof material, number of floors) in large urban datasets. The model combines a graph neural encoder to capture inter-attribute and inter-sample relationships, a vector-quantization module in latent space, and an expert-guided prior via conditional probability tables in a KL-regularization term to incorporate domain knowledge. Experiments on datasets from multiple cities show improved F1 scores and robustness under high missingness compared to traditional imputation baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly written and well-structured. The proposed integration of a graph neural encoder, vector-quantized latent space, and expert-guided prior is technically sound for the task of imputing missing building attributes. Experimental results across multiple cities also demonstrate the effectiveness."}, "weaknesses": {"value": "- Novelty. The overall architecture of EGVAE combines several well-established components rather than introducing a new mechanism. While the integration of a graph encoder, vector quantization, and expert-guided prior is reasonable, it feels incremental. \n\n- Problem scope. The problem of missing building attributes is too domain-specific and kind of narrow for an ICLR-level contribution. The current status feels more like an application-specific contribution rather than a broadly applicable framework for imputation. Even though spatial adjacency is used in the method, I believe the method can also apply to a more general missing-data problems (e.g., healthcare, finance, or tabular data). \n\n- Missing related work. \nThe paper compares only against general-purpose imputation methods, overlooking VAE-based imputation models [1, 2, 3] that directly address missing data or tabular data. It is important to discuss their connections.\n\n   [1] Alfredo Nazabal et al., Handling Incomplete Heterogeneous Data using VAEs \n\n   [2] Yu Gong et al., Variational Selective Autoencoder: Learning from Partially-Observed Heterogeneous Data, AISTATS 2021\n\n   [3] Tom Joy et al., Learning Multimodal VAEs through Mutual Supervision, ICLR 2022\n\n\n- Unfair comparison. EGVAE leverages spatial adjacency information through a graph built from building proximity, while other baselines do not see such relational structure. Since nearby buildings naturally share similar attributes, this spatial prior provides EGVAE with an inherent advantage. \n\n- Experiment. \n(1) The authors should include error bars to indicate the statistical significance of the reported results;\n(2) In Table 3 (Amman), the best F1 scores are incorrectly highlighted. GBIMC outperforms EGVAE on two of the three attributes;\n(3) On the Mexico City dataset, the \"floors\" attribute has the highest missing ratio, yet EGVAE performs worse than several baselines. It seems like that the model handles well-observed attributes more effectively than heavily missing ones."}, "questions": {"value": "- Do the authors try incorporating the graph structure (currently used in the CPT prior) into the encoder? If spatial relations are meaningful for the prior, they should also improve posterior inference.\n- Minor points: (1) Figure 4 is not correctly formatted; (2) Line 30 \"there\"-> \"their\""}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sC4d2PDMKe", "forum": "C0NdeKlyIt", "replyto": "C0NdeKlyIt", "signatures": ["ICLR.cc/2026/Conference/Submission21751/Reviewer_mqzK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21751/Reviewer_mqzK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21751/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761939640548, "cdate": 1761939640548, "tmdate": 1762941918131, "mdate": 1762941918131, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of missing building attribute data in spatial datasets, proposing a deep learning method that combines spatial structure, limited observations, and expert-informed priors. The model is built upon a Vector Quantized Variational Autoencoder (VQ-VAE) with a Graph Neural Network (GNN) encoder to capture spatial dependencies among buildings. A KL-divergence-based regularization term is introduced to integrate prior knowledge. The goal is to enable robust imputation even in data-scarce settings. Experimental results on real-world datasets are presented to support the model's effectiveness."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The application domain is relevant and practically important.\n\n- The use of real-world datasets adds practical relevance and demonstrates the applicability of the method."}, "weaknesses": {"value": "- **Limited novelty**: The core techniques—GNNs, VQ-VAEs, and auxiliary losses via KL regularization—are well-established and widely studied. For example, [1] offers a foundational treatment of variational graph autoencoders. The combination here does not offer a substantial methodological advance.\n\n- **Presentation issues**: The methodological section lacks sufficient detail and justification. Many architectural choices are simply listed without accompanying analysis or rationale, and gaps in the narrative hinder readability. Additionally, formatting issues—such as the blank space on page 7—detract from the professionalism of the presentation. Overall, the paper would benefit from a clearer and more structured exposition.\n\n- **Weak experimental evaluation**: The baselines used for comparison are outdated, and many recent methods for deep generative imputation are neither cited nor evaluated. Numerous VAE-based approaches could be directly tested with the proposed encoder (e.g., [2, 3, 5, 6]).\n\n- **Unjustified design choices**: The motivation for using a quantized latent space (via VQ-VAE) over a continuous latent space is not discussed. It remains unclear how the model would perform with a standard VAE and whether the quantization adds significant value.\n\n- **Insufficient related work coverage**: The related work section does not reflect the current state of the art. Many recent approaches to imputation, especially those based on deep generative models or diffusion models, are omitted.\n\n- **Reference imprecision**: Some references are incorrectly used. For instance, line 046 cites Nazabal et al. (2018) [2] in the context of VQ-VAEs, but that work uses a standard VAE, not a quantized latent space.\n\n### Typos and Minor Issues\n\n- Line 476: *Reproducability* → *Reproducibility*\n\n- Line 481: *Acknoledgement* → *Acknowledgement*\n\n### References\n[1] Kipf, T. N., & Welling, M. (2016). Variational graph auto-encoders. arXiv preprint arXiv:161Kipf, T. N., & Welling, M. (2016). Variational graph auto-encoders. arXiv preprint arXiv:161\n\n[2] Nazabal, Alfredo, et al. \"Handling incomplete heterogeneous data using vaes.\" Pattern Recognition 107 (2020): 107501.\n\n[3] Ma, Chao, et al. \"Vaem: a deep generative model for heterogeneous mixed type data.\" Advances in Neural Information Processing Systems 33 (2020): 11237-11247.\n\n[4] Yoon, Jinsung, James Jordon, and Mihaela Schaar. \"Gain: Missing data imputation using generative adversarial nets.\" International conference on machine learning. PMLR, 2018.\n \n[5] Peis, Ignacio, Chao Ma, and José Miguel Hernández-Lobato. \"Missing data imputation and acquisition with deep hierarchical models and hamiltonian monte carlo.\" Advances in Neural Information Processing Systems 35 (2022): 35839-35851.\n\n[6] Mattei, Pierre-Alexandre, and Jes Frellsen. \"MIWAE: Deep generative modelling and imputation of incomplete data sets.\" International conference on machine learning. PMLR, 2019.\n\n[7] Jarrett, Daniel, et al. \"Hyperimpute: Generalized iterative imputation with automatic model selection.\" International Conference on Machine Learning. PMLR, 2022.\n\n[8] Zheng, Shuhan, and Nontawat Charoenphakdee. \"Diffusion models for missing value imputation in tabular data.\" arXiv preprint arXiv:2210.17128 (2022)."}, "questions": {"value": "I have no further inquiries beyond the issues outlined above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1iqm8h4FYw", "forum": "C0NdeKlyIt", "replyto": "C0NdeKlyIt", "signatures": ["ICLR.cc/2026/Conference/Submission21751/Reviewer_bycB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21751/Reviewer_bycB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21751/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996953516, "cdate": 1761996953516, "tmdate": 1762941917848, "mdate": 1762941917848, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}