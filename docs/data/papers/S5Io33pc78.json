{"id": "S5Io33pc78", "number": 13698, "cdate": 1758221057023, "mdate": 1759897418870, "content": {"title": "Multihead Mixture of Experts for Classification of Gigapixel Pathology Images", "abstract": "Multiple Instance Learning (MIL) is the predominant paradigm for classifying gigapixel whole-slide images in computational pathology. MIL follows a sequence of 1) extracting patch features, 2) applying a linear layer to obtain task-specific patch features, and 3) aggregating the patches into a slide feature for classification. While substantial efforts have been devoted to optimizing patch feature extraction and aggregation, none have yet addressed the second point, the critical layer which transforms general-purpose features into task-specific features. We hypothesize that this layer constitutes an overlooked performance bottleneck and that stronger representations can be achieved with a low-rank transformation tailored to each patch's phenotype, yielding synergistic effects with existing MIL approaches. To this end, we introduce MAMMOTH, a parameter-efficient, multi-head mixture of experts module designed to improve the performance of any MIL model with minimal alterations to the total number of parameters. Across 8 MIL methods and 19 different tasks, we find that this improvement to the task-specific transformation has a larger effect on performance than the choice of aggregation method. For instance, when equipped with MAMMOTH, even simple methods such as max or mean pooling attain higher average performance than any method with the standard linear layer. Overall, MAMMOTH improves performance in 130 of the 152 examined configurations, with an average $+3.8%$ change in performance.", "tldr": "A parameter-efficient plug-and-play mixture of experts module for improving any multiple instance learning approach in computational pathology.", "keywords": ["Mixture of Experts", "Multiple Instance Learning", "Computational Pathology", "Computer Vision"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/50d06d26cb06598917ea9206494ebe5059e0a36b.pdf", "supplementary_material": "/attachment/51377a233094dfb4bf1b9a516a089e551682e7a8.zip"}, "replies": [{"content": {"summary": {"value": "This paper explores the performance bottleneck on general-purpose patch features re-embedding, where MAMMOTH, a MoE module, is designed to replace the specific linear layer in MIL to re-embed general-purpose patch features to a set of specialized features."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This work is well-motivated. It offers an insight about general-purpose patch features re-embedding, and based on this insight, a MoE module tailored to WSI problems is proposed.\n2. Experiments are comprehensive, including thorough ablation studies and extensive comparisons on 19 datasets.\n3. The motivation and effectiveness can be intuitively validated with the visualization, which provides good interpretability."}, "weaknesses": {"value": "1. The exploration of why it works is lacking. Although the story is well-told, and the motivations align with the design, I'm still confused about why it achieves the intended purpose. For example, even though features are continuously partitioned into different heads, slots, and experts, why are they able to learn distinct things without explicit constraints?\n2. The experimental comparison to R2T-MIL [1] is missing. The core insights are similar to what R2T-MIL claimed, which also re-embedded general-purpose patch features into the new ones. The difference is that feature merging of R2T-MIL is based on regional patches, while MAMMOTH relies on morphological similarities. Therefore, I think the authors should compare R2T-MIL on top of various MIL.\n\n[1] Feature Re-Embedding: Towards Foundation Model-Level Performance in Computational Pathology, CVPR, 2024."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Yzu3M4XSY7", "forum": "S5Io33pc78", "replyto": "S5Io33pc78", "signatures": ["ICLR.cc/2026/Conference/Submission13698/Reviewer_DHSJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13698/Reviewer_DHSJ"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13698/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761819083447, "cdate": 1761819083447, "tmdate": 1762924249557, "mdate": 1762924249557, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose MAMMOTH, a multihead mixture of experts for classification of gigapixel pathology images, that can work with most MIL methods. The MoE mechanism differs from variants in the literature in that it uses slot-based pooling of the input patches, with each slot effectively capturing a morphological concept. Hence the bag size and its interpretation changes after this layer. A low-rank decomposition is used for the slot transformation in each expert to ensure parameter efficiency. The approach is demonstrated on several standard histology datasets across several classification tasks and on top of 8 widely used MIL methods. A thorough ablation study analyzes the impact of specific contributions (MoE method, number of heads, slot transformation, patch encoder, etc.)."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Novelty: There is good methodological novelty in the context of WSI classification / MIL, as the specifics of the MoE mechanism are original.\n\n2. Clarity: The method is clearly described and the paper well-positioned w.r.t. the literature\n\n3. Significance: Slot-based pooling could be beneficial to interpretability, by reducing bag size and allowing each patch embedding in the initial bag to be linked to its most similar morphological concept.\n\n4. Quality: There is a thorough ablation study + a study of data and inference efficiency + generalizability across diverse patch encoders"}, "weaknesses": {"value": "One concern with this paper is that the proposed MoE layer adds complexity to the MIL strategy, despite careful control of parameter efficiency. \n\nThis needs to be justified by strong and robust performance gains. For some datasets where no mention is made of cross-validation, e.g. BRACS and PANDA, the exact experimental setup is still unclear to me: is it a single train/test split, 1 run, 1000 bootstraps of the test set on this single run? As very large differences can occur across multiple runs in MIL for histopathology. If so, especially for these datasets, statistical significance tests on the performance gains would be welcome."}, "questions": {"value": "How do the authors select the number of experts and slots robustly in a real-world scenario? Quite substantial performance degradation can be observed for some settings in Figure A2."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sWMJVFzEGy", "forum": "S5Io33pc78", "replyto": "S5Io33pc78", "signatures": ["ICLR.cc/2026/Conference/Submission13698/Reviewer_HDrx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13698/Reviewer_HDrx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13698/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761862180493, "cdate": 1761862180493, "tmdate": 1762924249153, "mdate": 1762924249153, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces MAMMOTH, a parameter-efficient multihead mixture of experts (MoE) designed to replace the often-overlooked task-specific linear layer in multiple instance learning (MIL) for whole-slide image (WSI) classification. Traditional MIL pipelines rely on a single linear transformation for all patch embeddings, which limits the ability to capture diverse histomorphological patterns. MAMMOTH addresses this by partitioning embeddings into multiple heads, applying soft expert assignments for stable training, and using low-rank decomposition with weight sharing to maintain efficiency. This design reduces thousands of noisy patch embeddings into a compact, interpretable set of task-specific features. Experiments across 8 MIL methods and 19 tasks show consistent improvements, with MAMMOTH outperforming baselines in 130 of 152 configurations and achieving an average +3.8% performance gain. Interpretability analyses confirm that experts specialize in distinct morphological concepts, while ablations highlight the effectiveness of each design choice. MAMMOTH thus enhances accuracy, efficiency, and interpretability in computational pathology."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Originality: The paper highlights a neglected component in the MIL pipeline: the task-specific linear layer. By replacing it with MAMMOTH, a parameter-efficient multihead mixture-of-experts module, the authors introduce a novel perspective. This reframes the performance bottleneck in WSI classification, making the contribution both original and conceptually impactful.\n\n2. Quality: The work is technically rigorous. The authors design MAMMOTH with innovations like soft expert assignment, low-rank decomposition, and multihead partitioning to address the instability and parameter inefficiency of traditional MoE. Extensive experiments across 8 MIL methods and 19 tasks (morphological and molecular) validate its robustness, with consistent improvements in 130 out of 152 configurations. Interpretability studies involving pathologists further strengthen the claims by showing clear expert specialization in distinct histomorphological features.\n\n3. Clarity:The paper is generally well-structured, moving from motivation to method to results in a logical flow. Figures (e.g., embedding space visualizations, routing heatmaps) effectively illustrate key points. Ablation studies and efficiency comparisons are clearly presented, helping readers understand the contribution of each component\n\n4. Significance: Mammoth is presented as a plug-and-play module that consistently boosts performance across a wide range of tasks and backbone architectures without increasing parameters. This makes it a highly practical and immediately useful contribution for researchers and practitioners."}, "weaknesses": {"value": "1. Fixed hyperparameter configuration. MAMMOTH is evaluated with a fixed number of experts, heads, and slots across tasks. While effective, this may not reflect task-specific optimal configurations. Explore adaptive mechanisms to dynamically adjust expert/head/slot counts depending on task complexity or data size would be better.\n\n2. Limited scope of tasks. Although MAMMOTH was validated on 19 tasks spanning morphology and biomarker prediction, the paper does not extend to other clinically critical tasks such as survival prediction or multimodal fusion with genomics and radiology. These are central to real-world deployment.\n\n3. Marginal gains on simple tasks. On simple binary tasks with strong baselines (e.g., NSCLC subtyping), MAMMOTH shows little or no improvement."}, "questions": {"value": "1. The author employed a fixed configuration of experts, heads, and slots across tasks. How sensitive is MAMMOTH to these choices?\n\n2. The evaluation focuses on classification (morphological and biomarker tasks). Do the authors anticipate that MAMMOTH would extend naturally to other clinically relevant tasks such as survival prediction?\n\n3. The expert specialization examples are compelling, but mostly qualitative. Is there a way to systematically quantify interpretability, for instance, by measuring overlap between expert clusters and pathologist-annotated regions of interest?\n\n4. The reviewer is also interested in performance comparison to pathology-specific MoE methods such as [1][2] and existing plug-and-play module for the linear layer such as [3]\n\n[1] Learning Heterogeneous Tissues with Mixture of Experts for Gigapixel Whole Slide Images\n[2] M4: Multi-proxy multi-gate mixture of experts network for multiple instance learning in histopathology image analysis\n[3] How Effective Can Dropout Be in Multiple Instance Learning ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6OsY4yDBSp", "forum": "S5Io33pc78", "replyto": "S5Io33pc78", "signatures": ["ICLR.cc/2026/Conference/Submission13698/Reviewer_FYXj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13698/Reviewer_FYXj"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13698/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761880427681, "cdate": 1761880427681, "tmdate": 1762924248671, "mdate": 1762924248671, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper targets a neglected but ubiquitous component in Multiple Instance Learning (MIL) pipelines for whole-slide image (WSI) classification: the task-specific linear layer that maps generic patch embeddings to task-optimized representations prior to aggregation. The authors hypothesize that this layer is a key performance bottleneck and propose MAMMOTH, a parameter-efficient, multi-head mixture-of-experts (MoE) module that replaces this linear transformation. MAMMOTH partitions the input embedding across heads, routes patches to slot-specific prototypes via soft attention, and applies low-rank expert-specific transformations before re-concatenation. Across 8 MIL methods and 19 tasks (both morphological classification and molecular biomarker prediction), MAMMOTH improves performance in 130 of 152 configurations, with an average percent change of +3.8% overall (larger on morphology), and even enables simple aggregations (mean/max pooling) to surpass more sophisticated MIL baselines when equipped with MAMMOTH. The authors also provide ablations for design choices, efficiency and data-efficiency analyses, and qualitative interpretability showing specialization of experts/slots to morphological concepts."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Broad, careful empirical validation across 8 MIL methods and 19 tasks (morphology and biomarkers), with consistent improvements in 130/152 configurations and larger gains on morphological tasks.\n- Ablations isolate the contributions of heads, slots, and low-rank experts; interpretability analyses show morphologically coherent routing/specialization; runtime/data-efficiency comparisons suggest favorable trade-offs versus sparse MoE variants.\n- Solid training details (optimizer/schedule/regularization) and cross-validation protocols."}, "weaknesses": {"value": "The paper has limitations in its positioning and comparative baselines, which affect the rigor and credibility of its conclusions. The main issues are as follows:\n\n1. Lack of direct comparison with strong, relevant baselines: The proposed module, characterized as “feature re-embedding” or task-layer replacement prior to aggregation, does not include direct comparisons with recent, closely related works in WSI MIL, weakening the claims of its relative importance. Key baselines include:\n\n- Feature Re-Embedding (CVPR 2024; Re-embedded Regional Transformer, RRT-MIL) [1].             \n- Query-aware dynamic long-context modeling (ICML 2025; “Context Matters,” Querent) [2].                        \n\nWithout comparisons under matched experimental settings, the conclusion that “the task layer matters more than aggregation” appears overly strong.\n\n[1] Tang, Wenhao, et al. \"Feature re-embedding: Towards foundation model-level performance in computational pathology.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2024.                \n[2] Guo, Zhengrui, et al. \"Context Matters: Query-aware Dynamic Long Sequence Modeling of Gigapixel Images.\" Forty-second International Conference on Machine Learning.           \n\n2. Post-hoc selection bias: The interpretability analysis showcases specific expert × slot visualizations reviewed by pathologists, but the paper does not define a deterministic protocol for selecting these slots. This lack of predefined selection criteria makes it unclear which expert × slot should be inspected to observe the claimed morphological types, increasing the risk of cherry-picking and reducing the robustness of the interpretability findings."}, "questions": {"value": "1. In light of the absence of matched-setting comparisons to strong re-embedding baselines, would you consider revising the main claim to: “Under our setup and tasks, task-layer re-embedding yields larger improvements compared to changing aggregators,” contingent on further comparisons and significance testing?\n\n2. How were expert × slot pairs chosen for visualization? Implementing a pre-registered, deterministic selection protocol could enhance transparency. For instance, CLIP-style text prompts or pathology-specific language encoders could be used to rank slots by text-concept similarity (e.g., “necrosis,” “lymphocytic infiltration”) and compare these rankings to pathologist-provided labels."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zikA0Z2wuu", "forum": "S5Io33pc78", "replyto": "S5Io33pc78", "signatures": ["ICLR.cc/2026/Conference/Submission13698/Reviewer_1BQN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13698/Reviewer_1BQN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13698/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916112781, "cdate": 1761916112781, "tmdate": 1762924248336, "mdate": 1762924248336, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}