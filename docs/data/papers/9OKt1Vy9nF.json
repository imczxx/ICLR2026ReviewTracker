{"id": "9OKt1Vy9nF", "number": 6835, "cdate": 1757997357146, "mdate": 1762919896075, "content": {"title": "Flow Diverse and Efficient: Learning Momentum Flow Matching via Stochastic Velocity Field Sampling", "abstract": "Recently, the rectified flow (RF) has emerged as the new state-of-the-art among flow-based diffusion models due to its high efficiency advantage in straight path sampling, especially with the amazing images generated by a series of RF models such as Flux 1.0 and SD 3.0. Although a straight-line connection between the noisy and natural data distributions is intuitive, fast, and easy to optimize, it still inevitably leads to: 1) Diversity concerns, which arise since straight-line paths only cover a fairly restricted sampling space. 2) Multi-scale noise modeling concerns, since the straight line flow only needs to optimize the constant velocity field $v$ between the two distributions $\\pi_0$ and $\\pi_1$. In this work, we present Discretized-RF, a new family of rectified flow (also called momentum flow matching models since they refer to the previous velocity component and the random velocity component in each diffusion step), which discretizes the straight path into a series of variable velocity field sub-paths (namely ``momentum fields'') to expand the search space, especially when close to the distribution $p_{noise}$. Different from the previous case where noise is directly superimposed on $x$, we introduce noise on the velocity $v$ of the sub-path to change its direction in order to improve the diversity and multi-scale noise modeling abilities. Experimental results on several representative datasets demonstrate that learning momentum flow matching by sampling random velocity fields will produce trajectories that are both diverse and efficient, and can consistently generate high-quality and diverse results.", "tldr": "", "keywords": ["Flow Matching", "Stochastic Velocity Field"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/f7136b25bee939e88a045b157b66b558eec8cc48.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In rectified flow models, the straight-line mapping between noisy and clean data distributions offers a fast and intuitive optimization path. However, this formulation raises two issues: limited sample diversity and insufficient multi-scale noise modeling.\n\nTo address these, the paper proposes Discretized-RF, a momentum-based flow matching model that incorporates both previous and random velocity components at each step. It discretizes the straight trajectory into a sequence of variable velocity sub-paths, referred to as *momentum fields*, thereby expanding the search space. Unlike prior approaches that add noise directly to $x$, this method injects noise into the velocity field $v$ of each sub-path, altering its direction to enhance diversity and improve multi-scale noise modeling."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper extends constant velocity field models to acceleration (momentum) field models, aiming for a better trade-off between sampling efficiency and diversity. It introduces a momentum-driven flow model that discretizes the straight path into variable velocity sub-paths, achieving trajectories that are more deterministic near the data distribution and more stochastic near the noise distribution—balancing efficiency and diversity without losing the simplicity of straight-line transport.\n- The proposed segmented straight-line sampling improves multi-scale noise modeling, offering a finer approximation of noise addition and denoising compared to standard rectified flows.\n- The method also shows adaptability to SE(3) protein generation tasks, extending the approach beyond image domains to non-Euclidean manifolds."}, "weaknesses": {"value": "- Some baseline comparisons appear limited; in Table 2, the proposed method does not consistently outperform existing rectified flow baselines across all metrics or settings, making it unclear when and how much improvement is achieved. Additional comparisons with other *training-improved rectified flow methods* would help contextualize the results.\n- The empirical gains are relatively modest, and the trade-off between sampling efficiency and diversity is not clearly characterized in Figure 4. The observed trends are weak, suggesting that further analysis is needed to substantiate the claimed benefits."}, "questions": {"value": "- For Figure 4, it would be useful to present a Pareto plot showing (Recall, FID) scatter points with $\\gamma$ values color-coded, to visualize how $\\gamma$  influences the Pareto frontier and the balance between quality and diversity.\n- The authors should quantitatively compare performance gains against other approaches that improve rectified flow training—for instance,\n    - Improving the Training of Rectified Flows (Lee et al., NeurIPS 2024), and\n    - SlimFlow: Training Smaller One-Step Diffusion Models with Rectified Flow (Zhu et al., ECCV 2024)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wiONQH5Ebm", "forum": "9OKt1Vy9nF", "replyto": "9OKt1Vy9nF", "signatures": ["ICLR.cc/2026/Conference/Submission6835/Reviewer_6CbM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6835/Reviewer_6CbM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761469353760, "cdate": 1761469353760, "tmdate": 1762919096859, "mdate": 1762919096859, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "l6hrKqQ7Uq", "forum": "9OKt1Vy9nF", "replyto": "9OKt1Vy9nF", "signatures": ["ICLR.cc/2026/Conference/Submission6835/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6835/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762919895077, "cdate": 1762919895077, "tmdate": 1762919895077, "mdate": 1762919895077, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposed momentum flow matching, a novel generative model that combines diffusion model and rectified flow. In the forward process, data is perturbed via diffusion process, and rectified flow is trained to match velocity between anchor pairs on a smaller time scale. At inference time, repeated ODE integration on the small time scale leads to the final generation. The method improves generation diversity compared to rectified flow, and efficiency compared to diffusion model. It's effectiveness is demonstrated through experiments on high-resolution image and protein backbone generation."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Momentum flow matching finds a middle ground between rectified flow with straight path and diffusion model with noisy path. Aiming for a piecewise straight path on a multi-scale noise model, momentum flow matching enhances the generation diversity of rectified flow and improves the inference speed of diffusion model.\n2. The protein backbone generation experiments, i.e. generation on SE(3), successfully supported the author's argument."}, "weaknesses": {"value": "1. Lack of motivation: The paper aims to tackle two concerns of rectified flow, namely generation diversity and multi-scale modeling. The first concern, according to the authors, is due to the fact that rectified flow is too \"straight\". However the general form of stochastic interpolants [1], a concurrent work of rectified flow, has introduced methods of matching velocities of noisy trajectories, which solves the issue of straightness in flow matching. Comparing merely to rectified flow without mentioning stochastic interpolants substantially weakens the motivation. For the second concern, it is never clearly explained in the paper why multi-scale modeling is essential.\n2. Lack of novelty: Momentum flow matching essentially takes two consecutive points on a diffusion trajectory and learns a rectified flow to match them, resulting in a piecewise-straight diffusion trajectory. Without further insights, the method seems to be a concatenation of diffusion model and rectified flow. The authors should consider explaining the rationale and advantage of modeling the momentum, and compare with methods of similar idea [2][4].\n3. Experiment: FID score in Table 1 & 2 seems unreasonably high across all experiments. Visual qualities of the generated images can't match state-of-the-art. For the baseline NanoFlow [3], a paper that concerns parallel computing of large language models, there seems to be no connection to any of the experiments carried out in the momentum flow matching paper.\n\n[1] Albergo, Michael S., Nicholas M. Boffi, and Eric Vanden-Eijnden. \"Stochastic interpolants: A unifying framework for flows and diffusions.\" arXiv preprint arXiv:2303.08797 (2023).\n\n[2] Zhang, Yichi, et al. \"Towards Hierarchical Rectified Flow.\" The Thirteenth International Conference on Learning Representations.\n\n[3] Zhu, Kan, et al. \"NanoFlow: Towards Optimal Large Language Model Serving Throughput.\" CoRR (2024).\n\n[4] Yan, Hanshu, et al. \"Perflow: Piecewise rectified flow as universal plug-and-play accelerator.\" Advances in Neural Information Processing Systems 37 (2024): 78630-78652."}, "questions": {"value": "Questions follows from the weakness.\n1. Is it possible that the authors compare with stochastic interpolants for generation diversity? \n2. Is it possible to justify why multi-scale noisy scheduling is advantageous?\n3. Is it possible to compare with Hierarchical Rectified Flow?\n4. Can the authors explain why FID of rectified flow is much higher than in the original RF paper? \n5. Can the authors explain how they used NanoFlow to generate images?\n6. Can the authors add a step length \\Delta_t to all ODE discretization? The current time lags are all of unit length which is hardly reasonable.\n7. Can the authors fix typos in Algorithms 2 Step 4?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LwZVniJeWO", "forum": "9OKt1Vy9nF", "replyto": "9OKt1Vy9nF", "signatures": ["ICLR.cc/2026/Conference/Submission6835/Reviewer_d1Dt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6835/Reviewer_d1Dt"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761772855521, "cdate": 1761772855521, "tmdate": 1762919096532, "mdate": 1762919096532, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Momentum Flow Matching (MFM), a discretized extension of Rectified Flow that injects stochastic momentum noise into the velocity field to balance sampling efficiency and diversity. Experiments on image and protein generation show improved FID/recall trade-offs and adaptability to SE(3) manifolds."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper identifies a meaningful goal: improving the diversity-efficiency trade-off in rectified flow models through stochastic velocity perturbation. \n- The momentum formulation provides an intuitive physical interpretation that connects rectified flows and stochastic diffusion dynamics under a unified velocity-based view. \n- Experiments show consistent quantitative improvements."}, "weaknesses": {"value": "- The core idea is extremely similar to PeRFlow [1]. \n- The algorithmic description lacks rigor and clarity. It is not explained how $(z_{t-1},z_t)$ are drawn, nor how the ODE is solved. Do the authors use Algorithm 1 and do the simulation? How do you solve ODE $\\frac{dz_t}{dt}=u_{\\theta}(z_t^m,m)$ with $z_0\\sim\\pi_0$. It appears that integration should be performed over $m$ from 0 to 1. \n- There seems to be no theoretical guarantee of marginal consistency. Can the authors show that integrating the velocity yields the correct marginal at each time $t$? \n- Experimental baselines are poorly chosen. The Nanoflow seems irrelevant. The core idea is similar to PeRFlow [1] and HRF [2]. You should discuss and compare with the baselines addressing similar problems. \n- The qualitative results show visibly degraded image quality when the number of function evaluations (NFE) is small. This undermines the claim of improved sampling efficiency, since high visual fidelity still requires a relatively large number of steps. \n\n[1] Yan et al. PeRFlow: Piecewise Rectified Flow as Universal Plug-and-Play Accelerator.  \n[2] Zhang et al. Towards Hierarchical Rectified Flow. ICLR 2025."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lSKixdLBPE", "forum": "9OKt1Vy9nF", "replyto": "9OKt1Vy9nF", "signatures": ["ICLR.cc/2026/Conference/Submission6835/Reviewer_GKuD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6835/Reviewer_GKuD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937261138, "cdate": 1761937261138, "tmdate": 1762919096210, "mdate": 1762919096210, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Momentum Flow Matching (also called Discretized-RF), which discretizes the straight path of flow matching into a series of sub-paths with variable velocity fields. The velocity along this path evolves stochastically via a momentum-like update, making the transport more random near the noise distribution for diversity and more deterministic near the data distribution for efficiency. Experiments are conducted on image and protein generation tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper attempts to convert ODE-based flow matching into SDE-based formulation (similar to DDPM) to improve diversity. The motivation is reasonable.\n2. Figures 1 and 2 provide clear visual intuitions of the method."}, "weaknesses": {"value": "1. Converting flow matching into stochastic differential equation form is not novel, as there already exist methods [1] that do this. The paper lacks both theoretical and empirical comparisons with these existing approaches.\n\n2. The FID results on CIFAR-10 (Table 1) and ImageNet-64 (Table 2) are significantly worse than recent published results. For instance, the results are worse than those shown in Figure 2 (ODE-based) and Figure 4 (SDE-based) of [2].\n\n3. Table 1 only reports FID, which cannot support the paper's claim of improving diversity.\n\n[1] Liu, Jie, et al. \"Flow-grpo: Training flow matching models via online rl.\" arXiv preprint arXiv:2505.05470 (2025).\n\n[2] Karras, Tero, et al. \"Elucidating the design space of diffusion-based generative models.\" Advances in neural information processing systems 35 (2022): 26565-26577."}, "questions": {"value": "1. How does this method compare to standard flow matching when NFE is sufficiently large? For example, in Table 1 of [1], 1-Rectified Flow achieves FID=2.58, Recall=0.57, IS=9.60 at NFE=127.\n\n2. Is the \"50.26\" in Table 1 a reproduced result of RectifiedFlow or taken from a specific table in the original RectifiedFlow paper [1]?\n\n[1] Liu, Xingchao, Chengyue Gong, et al. \"Flow straight and fast: Learning to generate and transfer data with rectified flow.\" In The Eleventh International Conference on Learning Representations, 2022."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ErEtQcLQkW", "forum": "9OKt1Vy9nF", "replyto": "9OKt1Vy9nF", "signatures": ["ICLR.cc/2026/Conference/Submission6835/Reviewer_tF4D"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6835/Reviewer_tF4D"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6835/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761957369420, "cdate": 1761957369420, "tmdate": 1762919095745, "mdate": 1762919095745, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}