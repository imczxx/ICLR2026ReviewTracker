{"id": "AhAIcQzeF1", "number": 21937, "cdate": 1758323814704, "mdate": 1759896895018, "content": {"title": "EmbedMol: An Open Billion-scale Molecular Embedding Dataset for Molecular Discovery", "abstract": "Modern molecular libraries span billions of compounds, exposing a mismatch between dataset scale and the practicality of vHTS. SMILES strings remain the dominant representation, but while easy to store, they are difficult to consume at billion scale: each search or training run must first translate SMILES into learned features, incurring prohibitive overhead. We introduce \\emph{EmbedMol}, the first open billion-scale dataset of precomputed molecular embeddings, along with a scalable generation pipeline. \\emph{EmbedMol} comprises 977M embeddings from GDB13 and 11.2B embeddings from GDB13+ZINC22, generated with a deep model pretrained on experimental binding assays. Our contribution is not a new encoder, but a benchmark/dataset resource that makes billion-scale embedding-based retrieval practical. We demonstrate that precomputed vectors act as a faithful, efficient proxy for expensive inference, yielding up to \\textbf{37.3$\\times$} speedups versus classical fingerprints and \\textbf{1.5$\\times$} versus re-running the encoder, while maintaining strong retrieval quality across multiple targets. Beyond efficiency, \\emph{EmbedMol} establishes a testbed for billion-scale evaluation of retrieval methods, scaling behavior, and cross-target generalization in molecular discovery. To support reproducibility and accessibility, we release not only the dataset and loaders but also a fully automated AWS-based pipeline, enabling researchers with varying levels of distributed-systems expertise to reproduce and extend \\emph{EmbedMol}.", "tldr": "", "keywords": ["large-scale datasets", "embedding", "molecular discovery", "open source"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1ba341bfe22831cc12f671ece2a5507fd9e2cea6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces EmbedMol, a large-scale dataset of precomputed molecular embeddings derived from 11 billion molecules sourced from GDB13 and ZINC22. The authors position this as a resource to address the computational bottleneck of generating data-driven fingerprints for virtual high-throughput screening (vHTS). The work includes a scalable cloud pipeline for generating the embeddings and evaluates the dataset on retrieval precision, cross-target generalizability, and deployment efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Valuable Resource: The creation and public release of a billion-scale molecular embedding dataset is a significant undertaking with clear potential utility for the community. It lowers the barrier to entry for researchers without extensive distributed computing expertise to work with large-scale molecular representations.\n\nPractical Focus: The paper addresses a genuine and pressing bottleneck in computational drug discovery: the infeasibility of running DL models on trillion-molecule libraries. Providing precomputed embeddings is a pragmatic solution.\n\nReproducibility and Engineering Effort: The release of the dataset, along with a detailed description of the scalable cloud pipeline, promotes reproducibility and demonstrates a substantial engineering effort."}, "weaknesses": {"value": "1. Questionable Evaluation Ground Truth: The core evaluation of \"embedding quality\" relies on using DL-predicted binding affinities as ground truth. Given the well-known inaccuracies of current DL affinity predictors and the fact that real-world virtual screening typically yields hit rates of 10-20%, reporting precisions as high as 68% is misleading. It primarily shows that the embeddings reconstruct the source model's predictions, not their ability to identify truly active compounds.\n\n2. Unsubstantiated and Suspicious Performance Claims:\n\n    The 37.3x speedup over fingerprints yet only 1.5x speedup over re-running encoders seems implausible. Rule-based fingerprints are designed for extreme speed, and neural networks of encoders cannot be efficiently deployed on CPUs. The author should justified this highly unusual claim.\n\n    Also, Table 3 shows identical results (e.g., 20%, 4%, 2%) for different fingerprint methods and similarity metrics. This statistical uniformity is highly improbable and suggests a potential error in the experimental setup, data processing, or reporting, severely undermining the credibility of the baseline comparison.\n\n3. Limited Technical Novelty: The work is an integration of existing tools: an existing encoder (DeepPurpose/MPNN), existing databases (ZINC22, GDB13), and an existing search library (FAISS). While the scaling effort is non-trivial, the paper does not introduce a novel algorithm, model, or foundational insight for the machine learning field. It functions more as a systems/engineering report.\n\n4. Inadequate Comparison to State-of-the-Art: The paper does not sufficiently situate itself against other high-throughput screening systems (e.g., the recently published BIOPTIC system (https://pubs.acs.org/doi/10.1021/acs.jcim.5c00743)) that also operate on vast chemical spaces. The comparison is limited to basic fingerprints and does not discuss the trade-offs of its approach."}, "questions": {"value": "1. Ground Truth Justification: Given the known unreliability of DL-predicted binding affinities, how do you justify their use as the primary ground truth for evaluating retrieval quality? Have you performed any validation on a smaller, experimentally-verified dataset to correlate your reported precision with real-world hit rates?\n\n2. Clarification on Speedup Claims: Can you detail the exact procedure for the \"37.3x speedup vs. fingerprints and 1.5x vs. re-running the encoder\" benchmark? Why re-running neural network-based encoders is even faster than fingerprints?.\n\n3. Explanation of Identical Baseline Results: The results for all fingerprint baselines in Table 3 are identical or nearly identical. This is statistically very unexpected. Can you explain this phenomenon and verify the correctness of your fingerprint generation and similarity calculation code?\n\n4. Defining the ML Contribution: Beyond the scale of the resource, what is the specific machine learning contribution of this work? What new methodological insight does it provide for representation learning or large-scale retrieval that is not already enabled by the existing, integrated components (FAISS, DeepPurpose, etc.)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UyQ2seD651", "forum": "AhAIcQzeF1", "replyto": "AhAIcQzeF1", "signatures": ["ICLR.cc/2026/Conference/Submission21937/Reviewer_oZ81"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21937/Reviewer_oZ81"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761484642580, "cdate": 1761484642580, "tmdate": 1762941989387, "mdate": 1762941989387, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces EmbedMol, a large scale molecular embedding dataset containing 11.2 billion embeddings from GDB13 and ZINC22. The embeddings are generated using the DeepPurpose model (2020), aiming to provide a resource for molecular similarity search and representation learning. The work lowers the computational barrier for large scale studies and includes an API and basic evaluations to showcase potential applications."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The authors’ effort in building such a dataset using their computational resources is commendable. And it might be have some kind of contirbution to the community who needs existing embedding representations for a molecule library."}, "weaknesses": {"value": "1.  The contribution of this paper is very limited. I admire the author's effort on using existing deep learning models to get the embeddings for a large scale molecule dataset. However, such contribution is not enough for a top-tier machine learning conference like ICLR. This is a pure engineering work.\n2. Only one DL method is used to generate embeddings, and it is a method in 2020, 5 years from now.\n3. The runtime comparison in Section 6.3 is questionable. When comparing with fingerprint-based methods, the baseline does not precompute fingerprints, while EmbedMol uses precomputed embeddings—this naturally favors EmbedMol in terms of speed. Additionally, the comparison with property prediction models, where SMILES inputs are simply replaced with embeddings, seems artificial and lacks practical relevance."}, "questions": {"value": "see weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CpclPedXDX", "forum": "AhAIcQzeF1", "replyto": "AhAIcQzeF1", "signatures": ["ICLR.cc/2026/Conference/Submission21937/Reviewer_6Kss"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21937/Reviewer_6Kss"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761568212626, "cdate": 1761568212626, "tmdate": 1762941989116, "mdate": 1762941989116, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces EmbedMol, an open billion-scale dataset of precomputed molecular embeddings, intended as a practical and reproducible resource for large-scale virtual high-throughput screening and evaluation of molecular representations. Experimental results demonstrate speedups and improved retrieval precision over traditional fingerprint baselines, while supporting large-scale retrieval tasks previously infeasible at this scale."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The dataset construction represents a solid engineering effort, achieving an impressive scale of over 11 billion molecules, which is uncommon in open molecular datasets.\n\n2. The authors provide a reproducible pipeline for dataset generation, including implementation details and AWS-based automation scripts.\n\n3. The resource may be useful for practitioners who need ready-to-use molecular embeddings for large-scale virtual screening, without extensive compute requirements."}, "weaknesses": {"value": "1. The paper’s main contribution is infrastructural rather than scientific. It focuses on assembling and releasing a large dataset of precomputed molecular embeddings and the associated AWS-based generation pipeline. While this is a valuable engineering effort, the paper explicitly states that no new embedding model or methodological innovation is introduced. Consequently, the work does not advance our understanding of molecular representation learning, embedding design, or algorithmic properties. This makes it less aligned with ICLR’s emphasis on novel modeling ideas and theoretical insight, rather than infrastructure or resource releases alone.\n\n2. All embeddings in the dataset are derived from a single pretrained MPNN encoder. Although MPNNs are well-established for molecular graphs, relying on a single architecture restricts diversity in representational properties and risks propagating the biases of that specific model family. Section 3 indicates no ablation or comparative study across alternative encoders. As a result, it remains unclear whether the dataset can serve as a general-purpose benchmark or whether its utility is confined to the embedding characteristics of this one model.\n\n3. The evaluation protocol uses drug–target interaction scores predicted by a separate DTI model as “ground truth” for measuring retrieval precision. While this is pragmatically necessary at scale, it undermines the scientific validity of the results: retrieval performance may simply reflect the inductive bias of the prediction model rather than true biochemical relevance. Since no experimental validation with empirical assay data is provided, the reported precision metrics should be interpreted with caution.\n\n4. The evaluation mainly contrasts EmbedMol with rule-based fingerprints such as Morgan or MACCS, which are now considered classical baselines. There is no comparison with more modern, learned molecular embeddings. This limits the ability to assess whether EmbedMol actually advances the state of molecular representation learning beyond existing deep models."}, "questions": {"value": "The dataset currently relies on embeddings generated from a single pretrained MPNN encoder. Could the authors elaborate on how they expect the reported efficiency and retrieval quality to generalize to other architectures?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4OoQFZSur5", "forum": "AhAIcQzeF1", "replyto": "AhAIcQzeF1", "signatures": ["ICLR.cc/2026/Conference/Submission21937/Reviewer_pEei"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21937/Reviewer_pEei"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761845843243, "cdate": 1761845843243, "tmdate": 1762941988802, "mdate": 1762941988802, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors present EmbedMol, which is a dataset provides precomputed molecular embeddings. Their dataset contains 128-dimensional embedding vectors extracted using a deep learning-based encoder, so that users don't have to preprocess and encode SMILES strings every time. Their encoder uses drug-protein binding assay data, aiming to capture not only chemical structures but also some bioactivity-related patterns. The evaluation result shows that the search speed was up to 37x faster than traditional fingerprint-based search methods and approximately 1.5x faster than running the encoder every time."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "EmbedMol is designed to facilitate fast and efficient drug discovery and molecular screening by providing a pre-computed 128-dimensional embedding vector. The evaluation results show that search and inference speed improve. The paper is easy to follow and well organized. The dataset is publicly available, which gives high reproducibility."}, "weaknesses": {"value": "1. The paper doesn’t clearly show the breakdown of each step. It would be helpful if the authors reported how much time embedding and preprocessing each take.\n2. It seems that using EmbedMol may prevent users from applying different deep learning models (non MPNN). If fine-tuning is possible with the dataset, could you please show how it converges compared to training from scratch, and demonstrate its generalizability by evaluating it on other tasks or models?\n3. How does it compare to existing approximate nearest neighbor searching algorithms?"}, "questions": {"value": "Please see weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "01I3ec7Q01", "forum": "AhAIcQzeF1", "replyto": "AhAIcQzeF1", "signatures": ["ICLR.cc/2026/Conference/Submission21937/Reviewer_djuA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21937/Reviewer_djuA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21937/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761979759990, "cdate": 1761979759990, "tmdate": 1762941988554, "mdate": 1762941988554, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}