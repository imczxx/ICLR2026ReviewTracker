{"id": "gkuYvE5Fdu", "number": 575, "cdate": 1756749117742, "mdate": 1759898252606, "content": {"title": "Neural Synchrony Between Socially Interacting Language Models", "abstract": "Neuroscience has uncovered a fundamental mechanism of our social nature: human brain activity becomes synchronized with others in many social contexts involving interaction. Traditionally, social minds have been regarded as an exclusive property of living beings.  Although large language models (LLMs) are widely accepted as powerful approximations of human behavior, with multi-LLM system being extensively explored to enhance their capabilities, it remains controversial whether they can be meaningfully compared to human social minds. In this work, we explore neural synchrony between socially interacting LLMs as an empirical evidence for this debate. Specifically, we introduce neural synchrony during social simulations as a novel proxy for analyzing the sociality of LLMs at the representational level. Through carefully designed experiments, we demonstrate that it reliably reflects both social engagement and temporal alignment in their interactions. Our findings indicate that neural synchrony between LLMs is strongly correlated with their social performance, highlighting an important link between neural synchrony and the social behaviors of LLMs. Our work offers a new perspective to examine the \"social minds\" of LLMs, highlighting surprising parallels in the internal dynamics that underlie human and LLM social interaction.", "tldr": "", "keywords": ["language models", "social mind", "inter-brain synchrony", "social interaction"], "primary_area": "applications to neuroscience & cognitive science", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/2c53ce72065e20d15cd8befe586f495a9bee6eda.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces a novel framework for measuring neural synchrony between socially interacting large language models (LLMs), drawing inspiration from neuroscience research on inter-brain synchrony in humans. The authors simulate multi-turn social interactions using SOTOPIA and extract hidden representations from paired LLM agents, then train predictive affine transformations to measure how well one agent's current representations can predict another's future representations, quantified by a metric called SyncR². Through rigorous control experiments across 21 model pairs from the Mistral and Llama families, they demonstrate that measured synchrony genuinely reflects both social engagement and temporal alignment, and remarkably, this representation-level neural synchrony strongly correlates with behavioral-level social performance (Pearson r = 0.88-0.99, p < 0.05) even after controlling for confounding factors like instruction-following and long-context reasoning abilities. These findings reveal striking parallels between LLMs and human brains in social interaction dynamics, suggesting that LLMs may possess internal mechanisms analogous to human inter-brain synchrony that support successful social coordination, thereby offering the first empirical evidence for examining the \"social minds\" of LLMs at the representational level."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper is the first to apply the neuroscience concept of \"inter-brain synchronization\" (IBS) to LLMs, which is highly innovative.\n2. The experimental setup was very thorough, and the comparison results are quite convincing. The authors constructed 21 model pairs (covering two major families) and simulated 450 scenarios × 3 random seeds."}, "weaknesses": {"value": "1. As the author mentioned, there is a lack of validation for larger models, such as the 14b and 32b models.\n2. SOTOPIA has certain limitations, including only short-term interactions (averaging 6-8 rounds) and institutionally structured communication.\n3. It is possible to explore more agents than just two, which would better simulate real-world communication scenarios.\n4. The control group setup in the article still has some shortcomings; more control groups could be added to isolate scene and agent factors and verify the necessity of reciprocity, among other things."}, "questions": {"value": "1. Regarding the results shown in Figures 2 and 3. Why are the areas indicated by the black boxes not clustered around the diagonal line?\n2. Why use \"affine transformation\" (linear mapping + bias)? The representation space of LLMs may be highly nonlinear.\n3. What is the meaning of a negative R² value?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ezigysIOSP", "forum": "gkuYvE5Fdu", "replyto": "gkuYvE5Fdu", "signatures": ["ICLR.cc/2026/Conference/Submission575/Reviewer_xLjv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission575/Reviewer_xLjv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission575/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960342662, "cdate": 1761960342662, "tmdate": 1762915551349, "mdate": 1762915551349, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes to study the neural synchrony between language models which are engaged in a social interaction, inspired by the phenomenon of inter-brain synchrony in humans. They measure neural synchrony between interacting LMs by proposing a metric Sync$R^2$, which is based on predicting the other agent’s next response based on an affine transformation of the agent’s current representation of the conversation. They validate this metric and find that it reflects both social engagement and temporal alignment in their interactions and is strongly correlated with their social performance."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**S1**: This paper introduces an interesting and to me novel perspective on studying LM social capabilities through the lens of neural synchrony, rather than through behavioural outputs alone. I think that the motivation and connection with neuroscience is interesting and brings a fresh perspective. Although it may seem anthropomorphic on first glance, I do think it also makes sense to study this property in interacting LMs and the proposed metric could provide another tool for probing LMs. \n\n**S2**: The validation approach is thorough and tries to account for many potential confounders, such as common context. I think the controls demonstrate to a satisfactory extent that synchrony is not due to other factors. Using models from different families and of different sizes also strengthens the conclusions.\n\n**S3**: The paper is generally well-structured and clear with a good motivation, clear figures and a good progression from section to section. The connection to neuroscience is also explained clearly for an ML audience."}, "weaknesses": {"value": "**W1**: Although I like the current ablations, I think there are still some potential issues that I can see with the setup. I think due to the strong claim (that LMs do exhibit neural synchrony), I would want to see some strong evidence ruling out alternative explanations. \n\n- **W1a**: One is that the paper states that \"representations from the same interaction are not split between train and test sets\", but it doesn't seem clear whether representations from the same personas in different scenarios could appear in both sets, or if the persona pairs are randomized (apologies if I missed this). Because agent personas have consistent character backgrounds, it seems possible that the affine transformation could be learning identity mappings between personas rather than displaying true neural synchrony. \n\n- **W1b**: I like the passive control, but I think further experiments could help disentangle genuine synchrony from shared context? What I mean is that both of the interacting models could be encoding some information such as (\"this is a negotiation\", \"the negotiation is over buying a TV\", \"price range 300-400\", \"need to reach agreement\") etc. This means that apparent synchrony could just be because both agents are reading the same scenario and encoding the constraints of that scenario. I think to see if this is due to a shared scenario like the negotiation I talked about vs. a true adaptation to the other agent, it would be good to test whether Sync$R^2$ drops when agents are in different interactions that are similar in type (e.g. the TV negotiation) but they don't actually interact with each other. E.g. A <-> B, and C <-> D could be two agent pairs in the same scenario, and we want to see the predictive power of A on D, B on C etc. If the metric is lower in this case I think this would be a stronger indication of synchronization within that interaction. \n\n\n**W2**: The mechanistic explanation for this remains limited, as while the paper demonstrates that synchrony occurs and correlates with performance, the explanation of why this should be the case is somewhat superficial. There is some discussion of theory and mind and predictive coding, and Appendix F is interesting, but I think it would strengthen the paper significantly to expand on this section and add it to the main paper. For instance, are layers with higher Sync$R^2$ also higher in decoding performance, and which way does the causal relationship go?"}, "questions": {"value": "- Can you elaborate more on how the agents and interactions were sampled and split between the train/test sets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "x9GnGtEiKW", "forum": "gkuYvE5Fdu", "replyto": "gkuYvE5Fdu", "signatures": ["ICLR.cc/2026/Conference/Submission575/Reviewer_m5ti"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission575/Reviewer_m5ti"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission575/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761963278557, "cdate": 1761963278557, "tmdate": 1762915550616, "mdate": 1762915550616, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates representational dynamics between interacting LLMs in social simulation environments. The authors train affine transformations to predict one agent's future hidden representations (timestep t+1) from another agent's current representations (timestep t), defining a metric called $SyncR^2$ based on prediction accuracy. Experiments across 21 model pairs show that $SyncR^2$ decreases without active engagement or temporal alignment, and correlates positively with social task performance. Additional analyses reveal higher $SyncR^2$ in closer agent \"relationships\" and evidence that representations encode partners' mental states."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "S1. This work is novel in exploring whether LLMs exhibit similarity at the representation level during social interaction, and designs a new evaluation method (whether these representations can be used to predict the next behavior of the interacting agent) to examine the existence of such social minds.\n\nS2. I must say that the paper is very clearly written. This work allows readers unfamiliar with inter-brain synchrony background to easily understand the intention and existing work. The paper provides detailed and reasonable discussion on how to avoid overclaiming through rigorous experimental design (such as discussion of potential confounding factors) and ablation studies.\n\nS3. The paper obtains some practically meaningful findings, such as discovering that neural synchrony is significantly correlated with social performance, and that relationship closeness affects synchrony strength. This is meaningful for future research on agent \"social minds\"."}, "weaknesses": {"value": "W1. The choice of affine transformation lacks good justification (why should the relationship between representations be linear?). Although the results show this transformation is meaningful for using one LLM's representation at time t to predict another LLM's representation at time t+1, there is no theoretical explanation, nor are alternatives provided.\n\nAdditionally, the explanation for why predictability can measure synchrony is incomplete. The current logic of the paper is: IBS is analogized to LLM representational predictability, predictability can measure synchrony, and this ability can explain social interaction performance. However, predictability does not equal synchrony. Synchrony in neuroscience is bidirectional, while LLM synchrony is unidirectional prediction from LLM A(t) to LLM B(t+1). An extreme case is: suppose a strong model A can predict weak model B's behavior, but B cannot predict A, then the final measure SyncR^2 cannot reach a high level, and synchrony does not exist here. On the other hand, regarding the time window, the choice of t->t+1 is not necessarily reasonable. According to strict synchrony definition, would examining t->t correspondence be more appropriate? Control 2 examined t->t+k and found prediction ability declined, which only shows temporal proximity is important, but does not explain why t+1. I believe bidirectional instantaneous mutual information at time t might be a better measure of synchrony. To sum up, from a multi-turn interaction perspective, t->t+1 might also be acceptable but needs justification.\n\nR^2 as a synchrony measure may also not be appropriate, as it only measures linear correlation. For nonlinear dynamics likely present in social interaction, R^2 may not be the best criterion (though I acknowledge this is acceptable given current progress, just that other metrics for measuring nonlinear dynamics might be better).\n\nW2. Social performance completely relies on LLM-as-a-judge. The correlation with human evaluation in Appendix E is insufficient, and the sample size may be small (21 pairs), which weakens the reliability of the evaluation. The sample for correlation analysis in Figure 6 may be too small. I understand there are considerable costs in pairing different LLMs from different families, but the model types used in issues discussed in Section 5 may still be quite limited.\n\nW3. The causal relationship from synchrony to social performance is unclear (line 398). Although experiments show a linear relationship exists, many potential alternative explanations exist, such as stronger models having both better representations and better social engagement ability, which jointly influence social performance. The Theory of Mind and predictive coding at line 452 are also only speculative explanations. To truly determine the relationship here, intervention experiments or identifying mediating variables for analysis are needed. This could be suggested as a direction for further research.\n\nI am willing to raise my score if the issues are adequately addressed (especially for W1)."}, "questions": {"value": "C1. At line 205, I am unsure whether using the best-case predictions layer is an appropriate choice. Although the goal of this work is not to achieve the best prediction, might using the best layer lead to unfair comparison or introduce bias? And is it reasonable to directly set negative R^2 to 0? Sensitivity analysis could be done to test whether this practice is effective.\n\nMinor Issues:\n\nC2. This is just my personal feeling (not necessarily a modification requirement): \"neural synchrony\" of LLM representations might mislead readers into thinking this is a direct biological analogy, when it is actually only a computational analogy (representational synchrony), and the neural mechanisms of LLMs and human brains are not the same. Some analogical expressions in the paper could emphasize the distinction between these two types of analogies.\n\nC3. The parameter scale of the open-source models used may be relatively small, which limits readers' understanding of whether the conclusions can still hold at larger scales."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ULu3owcCyF", "forum": "gkuYvE5Fdu", "replyto": "gkuYvE5Fdu", "signatures": ["ICLR.cc/2026/Conference/Submission575/Reviewer_tXna"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission575/Reviewer_tXna"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission575/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762005936794, "cdate": 1762005936794, "tmdate": 1762915550149, "mdate": 1762915550149, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}