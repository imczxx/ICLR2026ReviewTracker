{"id": "RM8JAy8wmP", "number": 8151, "cdate": 1758070424104, "mdate": 1759897803333, "content": {"title": "ChainInfer: A Joint Method for Inferring Missing AI Supply Chain Information", "abstract": "The modern AI ecosystem forms an intricate AI supply chain, where models, datasets, and software components are deeply interconnected. Incomplete or inconsistent metadata on platforms such as Hugging Face and Kaggle leaves critical gaps in provenance, hindering reproducibility, risk management, and governance. To address this, we formalize AI supply chain inference as a coupled graph learning problem: link prediction to recover missing dependencies and edge classification to determine their semantic types. We propose ChainInfer, a hybrid architecture that integrates graph neural networks for local structural reasoning with graph transformers for global context, trained end-to-end on attributed supply chain graphs. Using a benchmark of 200K models from Hugging Face, ChainInfer outperforms GNN-, Transformer-, and ensemble baselines, achieving 0.93 joint accuracy while remaining efficient. Moreover, ChainInfer generalizes inductively to Kaggle, retaining 0.90 accuracy without retraining. These results demonstrate ChainInfer as a practical framework for scalable, accurate, and transferable AI supply chain provenance inference.", "tldr": "We model the AI supply chain as an attributed graph and propose a hybrid GIN+GT encoder that unifies local and global reasoning for robust link prediction and edge classification.", "keywords": ["AI supply chain", "graph neural network", "graph transformer", "link prediction", "edge classification"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/12720ff517e1e5302d9f6a403c3c774783f4dd5c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces CHAININFER, a joint graph learning framework for AI supply chain provenance inference. The authors formalize the problem as a coupled link prediction and edge classification task on large attributed graphs representing model dependencies in platforms such as Hugging Face and Kaggle. CHAININFER combines Graph Isomorphism Networks (GIN) for efficient local structural encoding and Graph Transformers (GT) for global context reasoning, trained end-to-end with a joint objective. Using a benchmark of 200K models, CHAININFER achieves a joint accuracy of 0.93 on Hugging Face and 0.90 in a zero-shot transfer to Kaggle, outperforming both GNN- and Transformer-based baselines. The paper demonstrates that hybrid architectures can accurately and efficiently infer missing metadata in large-scale AI ecosystems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper clearly defines AI supply chain inference as a coupled graph task. Its key strength lies in the novel formulation of the problem as a coupled graph learning task, combining link prediction and edge classification in a unified framework. The proposed CHAININFER architecture integrates GIN-based local reasoning with Graph Transformer–based global context modeling. The validity of the model was verified through extensive experiments on large-scale real-world data, including 200K-node graphs from Hugging Face and zero-shot transfer to Kaggle. The work demonstrates 0.93 joint accuracy while maintaining computational efficiency. Moreover, CHAININFER generalizes inductively to Kaggle, retaining 0.90 accuracy without retraining."}, "weaknesses": {"value": "The paper has a few limitations that could be addressed to strengthen its scope and generality. First, the current graph formulation focuses exclusively on model-level provenance, omitting other critical entities such as datasets, software components, and hardware, which limits the comprehensiveness of the inferred supply chain. Second, while the comparisons among GNN and Transformer variants are thorough, the absence of non-graph baselines—such as text-based metadata completion or knowledge graph embedding methods—makes it difficult to quantify CHAININFER’s advantage over broader families of approaches. Finally, the method relies on a carefully engineered feature pipeline derived from platform-specific metadata, which might reduce robustness in less structured or inconsistent repositories."}, "questions": {"value": "1.\tCHAININFER’s performance depends on extracted metadata features such as architecture parameters, tokenizer type, and quantization schemes. Could the authors provide a more systematic analysis of how performance degrades under varying degrees of metadata incompleteness or corruption? For instance, would the model still maintain high accuracy if 50% of metadata fields were missing or noisy?\n2.\tReal-world AI repositories often contain inconsistent or misleading metadata (e.g., false parent declarations or ambiguous model naming). How robust is CHAININFER to such noisy or adversarially incorrect inputs? Does the model include any mechanism (e.g., uncertainty estimation or confidence scoring) to detect or flag potentially unreliable inferred edges?\n3.\tThe current formulation models only AI models as graph nodes, excluding datasets, software packages, and hardware dependencies that also constitute the AI supply chain. Do the authors foresee straightforward extensions of CHAININFER to heterogeneous graphs including multiple node and edge types? If so, what specific architectural modifications would be required?\n4.\tThe feature extraction pipeline includes six distinct categories (architecture, tokenizer, quantization, metadata, fingerprints, and PEFT). Could the authors provide quantitative insights (e.g., via feature ablation or attention analysis) into which feature families contribute most strongly to inference accuracy? This would also clarify whether the model’s performance is dominated by structural signals or content-level cues.\n5.\tThe paper compares CHAININFER only with graph-based models. Have the authors evaluated or considered baselines such as text-embedding–based metadata completion methods? \n6.\tIn applied settings (e.g., regulatory auditing or risk assessment), understanding why a link or relation was inferred can be crucial. Does CHAININFER provide any interpretability mechanism (e.g., attention visualization or subgraph attribution) that helps users verify or justify the inferred provenance links?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wGGnrERswM", "forum": "RM8JAy8wmP", "replyto": "RM8JAy8wmP", "signatures": ["ICLR.cc/2026/Conference/Submission8151/Reviewer_6s7p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8151/Reviewer_6s7p"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761806953551, "cdate": 1761806953551, "tmdate": 1762920121657, "mdate": 1762920121657, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In the modern Artificial Intelligence (AI) ecosystem, the AI supply chain is used to define the entire ecosystem of data, models, hardware, and software required to develop, deploy, and maintain AI systems. However, incomplete metadata is often present in the AI supply chain. This paper focuses on the model provenance inference problem in this area and proposes CHAININFER, a joint method that exploits both Graph Neural Network (GNN) and Graph Transformer (GP) to do the link prediction and dependency type classification between models. The proposed hybrid modeling method is demonstrated to outperform other tested baselines in both model provenance inference accuracy and generalization ability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This paper has tackled an important problem in constructing the modern AI ecosystem, i.e., model provenance. The related works are comprehensively analyzed, and the work is well motivated.\n\n2. The joint model of GNN and GT is technically sound and demonstrated to achieve good performance in the real-world AI platforms (i.e., Hugging Face and Kaggle datasets)."}, "weaknesses": {"value": "1. The title and the introduction somewhat overclaim the contribution of this work. This paper claims to tackle the AI supply chain inference. I quota \"we formalize AI supply chain inference as a coupled graph learning problem\". However, only model provenance inference is considered in this work.\n\n2. In the experiments, only the graph-based model provenance method is compared. Other types of approaches, such as those mentioned in the related work, are not empirically compared. \n\n3. There exist some unclear claims and confusing notations. For example,\n\n* In line 75, it's not clear what the \"most existing approaches\" refer to. Proper citations are needed.\n* It's confusing how the inequality in line 283 is achieved, how (7) is achieved, and whether they are related."}, "questions": {"value": "1. Can the proposed CHAININFER framework be applied to infer the relationship between other elements of the AI supply chain?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "fmthl6ucFF", "forum": "RM8JAy8wmP", "replyto": "RM8JAy8wmP", "signatures": ["ICLR.cc/2026/Conference/Submission8151/Reviewer_KggE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8151/Reviewer_KggE"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984537864, "cdate": 1761984537864, "tmdate": 1762920121267, "mdate": 1762920121267, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a novel model for inferring missing AI supply chain information by framing it as a coupled graph learning problem: link prediction to recover missing dependencies and edge classification to determine their semantic types. The authors run several experiments across two datasets: a benchmark of 200K models from Hugging Face and another from Kaggle, demonstrating the model's ability to generalize inductively. The model achieves SOTA performance compared to several strong baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The authors introduce a novel model that infers missing AI supply chain information and achieves SOTA performance compared with strong baselines across two datasets (Hugging Face and Kaggle). The authors provide a detailed rationale for the proposed model and the decisions made to address issues such as cold start and missing data. Furthermore, they conducted multiple experiments and ablation studies to demonstrate that the proposed model surpasses strong baselines across various configurations and to provide deeper insight into which architectural components and structural features drive performance. Their contribution is not limited to the model but also includes the creation of two datasets for the AI supply chain, which they promise to share upon acceptance. The paper is well-structured and clearly written. The proposed method will likely have a significant impact, given it can be applied not only to the AI supply chain but to broader software supply chains and even to supply chains not related to software."}, "weaknesses": {"value": "We consider that the paper does not have many weaknesses. Nevertheless, we have identified two that we consider relevant:\n\n - While the authors describe the graph construction in the Appendix, there are some significant details missing. In particular, the authors provide insights into the information considered (e.g., Table 1), but no details about how such information is incorporated into the graph. How such information is modeled into a graph conditions how models are able to learn and their performance.\n\n- We consider the related work exposed in the introduction to be of good quality. Nevertheless, we miss some brief paragraph highlighting models and approaches that have already been used for inferring missing AI supply chain information or for inferring missing supply chain information (e.g, in the context of software packages or other kinds of supply chains that pose similar challenges). The proposed baseline models are not grounded in prior work addressing this specific domain."}, "questions": {"value": "1- While the authors describe the graph construction in the Appendix, we find certain details to be missing. We encourage the authors to provide information about (i) the graph design: in the manuscript is mentioned that different kind of edges exist: (a) what information is taken into account to build them?, (b) are they attributed?, (c) do attributes vary based on the kind of edge?, (d) do the authors consider different kind of nodes?, (ii) the authors mention using text embeddings: (a) what kind of models were used for such embeddings? (b) was there some specific rationale behind the choice?, (iii) the authors mention using structured metadata and performing a repository scan and checkpoints: (a) how is this information processed and incorporated into the graph? (b) are the metrics considered for enriching nodes or edges?. (iv) We encourage the authors to provide two Figures: (a) one detailing the graph construction process and (b) one describing the graph structure.\n\n 2- We consider the related work exposed in the introduction to be of good quality. Nevertheless, we miss some brief paragraph highlighting models and approaches that have already been used for inferring missing AI supply chain information or for inferring missing supply chain information (e.g,. in the context of software packages or other kind of supply chains that pose similar challenges). We would appreciate the authors then ground the selected baselines in such works.\n\n 3- While the authors report on the performance and time (seconds per epoch), they do not provide insights into the hardware that was used to execute the experiments. We encourage them to include in the Appendix a brief description of the hardware configuration used to run the experiments.\n \n 4- All tables: ensure the numbers are aligned to the right so that differences in magnitude become evident\n \n 5- Table 2: bolded results mean the best ones?\n \n 6- Table 3, 4, 5: highlight best results.\n \n 7- We encourage the authors to test whether the difference in performance noticed among the best models is statistically significant."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "wjSGXwK0SL", "forum": "RM8JAy8wmP", "replyto": "RM8JAy8wmP", "signatures": ["ICLR.cc/2026/Conference/Submission8151/Reviewer_7JT6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8151/Reviewer_7JT6"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987280814, "cdate": 1761987280814, "tmdate": 1762920120881, "mdate": 1762920120881, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a hybrid local GNN+ global Graph-Transformer method for recovering and classifying missing provenance links in AI supply chains. It treats the problem as link prediction + edge classification on large attributed graphs derived from Hugging Face, reporting strong but rather incremental performance against baselines and promising zero-shot generalization to Kaggle. Experiments compare against GNN-only, GT-only, and late-fusion baselines, showing performance gains and providing evidence for the considered principles."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Interesting and novel problem. The real world version of this corresponds to python package version conflicts for instance and could be potentially useful to resolve or accelerate.\n2. An interesting dataset is proposed. I am not sure how novel this dataset is but but seems less useful compared to the problems discussed in the intro\n3. Seemingly thorough evals and hyperparameter tuning results are reported.\n4. Zero-shot generalization to new graphs is interesting."}, "weaknesses": {"value": "1. Limited novelty in the proposed architecture. Local GNN + Global Attention variants have been tried before for the reasons outlined by the authors in the paper. See for instance Graph GPS by [Rampášek et. al. 2022](https://arxiv.org/pdf/2205.12454).\n2. Line 386. \"Joint\" accuracy is a meaningless metric and should just be called accuracy. Edge existence can be reported separately (binary classification) and accuracy of classification is just accuracy. Seems like unnecessary obfuscation to me.\n3. Evals are only on the newly constructed unbalanced provenance supply chain dataset with only 4 labels. This is a relatively easy setup where a chance model can achieve 25% classification accuracy. \n4. The labels are also highly imbalanced. There are effectively 3 edge classes since one of them is super rare (<1%).\n5. No results for the imputer strategy proposed in section 3.4\n6. Improvements are incremental over GCN+Graphormer models in table 2 and likely statistically insignificant (no error bars are)."}, "questions": {"value": "See above weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "UW4UA4UJVB", "forum": "RM8JAy8wmP", "replyto": "RM8JAy8wmP", "signatures": ["ICLR.cc/2026/Conference/Submission8151/Reviewer_iqPC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8151/Reviewer_iqPC"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8151/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994994249, "cdate": 1761994994249, "tmdate": 1762920119953, "mdate": 1762920119953, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}