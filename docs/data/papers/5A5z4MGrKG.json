{"id": "5A5z4MGrKG", "number": 6638, "cdate": 1757991066192, "mdate": 1759897903536, "content": {"title": "Implicit Neural Compression of Point Clouds via Learnable Activation Function", "abstract": "Efficiently compressing and transmitting large-scale high-fidelity 3D point clouds is a critical bottleneck for practical applications.  We introduce a novel framework that reformulates point cloud compression as model compression. Our framework models high-fidelity point cloud geometry and attribute with compact implicit neural representations (INR) separately and then compresses the model parameters directly via quantization and entropy coding, decoupling representation from compression. To ensure this neural representation is both faithful and efficient, we employ Kolmogorov-Arnold Network (KAN) as the INR backbone. Thanks to its superior approximation properties and parameter efficiency, KAN can easily capture fine-grained details missed by traditional MLP. Extensive evaluations on datasets such as KITTI, ScanNet, and 8iVFB demonstrate that our method significantly outperforms the MPEG standard and prior implicit neural representation approaches. Notably, it achieves competitive rate-distortion performance against state-of-the-art deep learning codecs. Our findings establish implicit neural compression as a powerful and practical pathway for developing the next generation of high-efficiency point cloud codecs.", "tldr": "", "keywords": ["implicit neural representation", "point cloud compression"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/43f0a56c3553594fc982ee02ec9c09a9310540fe.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces Point cloud Implicit neural COmpression (PICO), a framework that transforms point cloud compression from a signal processing issue to a neural network compression problem by modeling geometry and attributes separately with compact implicit neural representations and compressing their parameters via quantization and entropy coding. This approach decouples geometry and attribute modeling to prevent feature entanglement and separates representation from compression for precise control over rate and quality. PICO employs a multi-scale rate control mechanism, using a pre-computed Pareto frontier for coarse-grained architecture selection and tunable L1 regularization for finer-grained parameter sparsity, enabling precise bitrate allocation through quantization step size adjustment. The framework adopts the Kolmogorov-Arnold Network-inspired Learnable Activation Function Network as its INR backbone, which captures high-frequency details with fewer parameters and is further enhanced for PCC with positional encoding and radial basis functions. Evaluations on the 8iVFB, KITTI, and ScanNet datasets demonstrate its superiority over MPEG standards and other PCC methods. The contributions include PICO's precise rate control and real-world optimization, the lightweight and effective LeAFNet backbone, and the reformulation of PCC as neural network compression."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "I am fond of the proposed idea.  While I cannot confirm whether an identical approach has been previously applied to point cloud compression, it is worth noting that similar strategies have proven highly effective in the fields of 3D representation and 3D reconstruction/novel view synthesis.  The paper is well-articulated, with most concepts clearly explained.  Furthermore, the simplicity and directness of the algorithm's implementation stand out as a significant advantage.  In the experimental section, the paper provides a relatively thorough analysis of Adaptive Model Parameter selection."}, "weaknesses": {"value": "My concerns regarding this work are as follows:\n\n1) As indicated by the quantitative comparison experiments, the proposed method does not surpass, and in some cases, slightly underperforms compared to the previous state-of-the-art method, Unicorn. This diminishes my confidence in the method's overall effectiveness.\n2) What is the speed performance of the proposed method? The authors should report the compression speed and provide a comparative analysis with other methods. Slow processing speed or low efficiency is widely recognized as a drawback of INR-based approaches, and I am curious to know whether the proposed method suffers from this limitation.\n3) The network architecture employed in the paper lacks innovation, as it primarily consists of several generic modules, including Positional Encoding, Quantization & Entropy Coding, and Regularized Training."}, "questions": {"value": "Please refer to the questions raised in the Weaknesses section. I hope the authors can provide responses to these issues in the rebuttal."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lqnAIEoUsp", "forum": "5A5z4MGrKG", "replyto": "5A5z4MGrKG", "signatures": ["ICLR.cc/2026/Conference/Submission6638/Reviewer_Fun1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6638/Reviewer_Fun1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761664642590, "cdate": 1761664642590, "tmdate": 1762918954035, "mdate": 1762918954035, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a point cloud compression method based on implicit neural representations. It first converts the point cloud into a voxel representation, and then trains a neural network to predict the occupancy and attributes of each point. Finally, the point cloud is compressed by coding the parameters of the trained network."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly structured and easy to follow. The proposed method sounds reasonable, and the quantitative results are also good."}, "weaknesses": {"value": "1. Is the INR trained individually for each point cloud? Or can a single trained network generalize to arbitrary point clouds? If the model needs to be optimized separately for every point cloud, what is the required training time? In that case, its efficiency would be far inferior to feed-forward based methods.\n\n2. In Line 264, it is mentioned that the optimal ùë° is searched to maximize the D1 PSNR. Is this search process performed only for the proposed method, or for all baselines as well? If only applied to the proposed method, the comparison would not be fair.\n\n3. The Sampling Strategy section introduces several tricks to reduce training time and memory consumption. I would like to know how much practical improvement they bring ‚Äî e.g., how many minutes of training are saved, and how much memory is reduced?\n\n4. Why does the paper only provide quantitative results but no visualization results?\n\n5. Prior works [1, 2] typically evaluate the decompressed point clouds on downstream tasks (e.g., object detection on KITTI) to demonstrate effectiveness. This paper lacks such experiments.\n\n6. The paper does not include comparisons with some key baselines [3, 4], even though these baselines provide open-source implementations.\n\n7. Regarding the backbone, how significant is the performance difference between using a KAN-based architecture and using an MLP?\n\n[1] Que, Zizheng, Guo Lu, and Dong Xu. \"Voxelcontext-net: An octree based framework for point cloud compression.\" CVPR, 2021.\n\n[2] Huang, Lila, et al. \"Octsqueeze: Octree-structured entropy model for lidar compression.\" CVPR, 2020.\n\n[3] Fu, Chunyang, et al. \"Octattention: Octree-based large-scale contexts model for point cloud compression.\" AAAI, 2022.\n\n[4] You, Kang, et al. \"Reno: Real-time neural compression for 3d lidar point clouds.\" CVPR, 2025."}, "questions": {"value": "Please refer to the Weaknesses section for details."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3kO2oUwskb", "forum": "5A5z4MGrKG", "replyto": "5A5z4MGrKG", "signatures": ["ICLR.cc/2026/Conference/Submission6638/Reviewer_Ydhe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6638/Reviewer_Ydhe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761714755985, "cdate": 1761714755985, "tmdate": 1762918953525, "mdate": 1762918953525, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors present a point cloud compression framework that employs a Kolmogorov‚ÄìArnold Network (KAN) as an alternative to traditional backbone architectures. To enhance computational efficiency, the method partitions the 3D space into subspaces and processes only the occupied voxel blocks. The framework enables variable-rate compression by using models from a predefined model dictionary with varying parameter counts. Based on rate‚Äìdistortion (RD) curve analysis, the most suitable model is selected for a given compression rate. Geometry and attribute data are compressed separately, with attribute compression dependent on the reconstructed geometry. Additionally, the framework adopts dynamic thresholding to determine voxel occupancy. The authors evaluate their method across three benchmark datasets, demonstrating its effectiveness for efficient, adaptive point cloud compression."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The use of the Kolmogorov‚ÄìArnold Network (KAN) as the implicit neural representation (INR) backbone demonstrates a solid theoretical motivation, leveraging KAN‚Äôs superior approximation capabilities and parameter efficiency.\n\n2. The method is evaluated on multiple benchmark datasets (KITTI, ScanNet, and 8iVFB).\n\n3. The paper maintains good readability and technical clarity throughout."}, "weaknesses": {"value": "1. The proposed model dictionary appears dataset-specific and may not generalize well to unseen point cloud distributions. Please discuss the potential limitations and any strategies to improve generalization.\n\n2. ‚Äúwe divide the original space S into 2M √ó 2M √ó 2M coarse-grained cubes‚Äù ‚Äî It is unclear how boundary issues are handled during reconstruction. Given the independent nature of neighboring blocks, the surface reconstruction may not be seamless. Did the authors observe any boundary artifacts or discontinuities? An additional experimental result illustrating this issue would strengthen the discussion.\n\n3. ‚ÄúFor coarse-grained control, we select an optimal model architecture using a pre-computed Pareto frontier that profiles the trade-off between model size and bitrate‚Äù ‚Äî The analysis related to the Pareto frontier is a key design element, but is not clearly presented. Please include the corresponding experiments or plots in the results section to substantiate this claim.\n\n4. A comparison with conventional backbones would better highlight the advantages and significance of LeAFNet.\n\n5. The notation should be made consistent throughout the manuscript (e.g., V - X vs. V\\X). Inconsistent notation can confuse readers.\n\n6. Qualitative results should be included to visually demonstrate the reconstruction quality in comparison with existing methods."}, "questions": {"value": "Mentioned in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6P3idrqUaY", "forum": "5A5z4MGrKG", "replyto": "5A5z4MGrKG", "signatures": ["ICLR.cc/2026/Conference/Submission6638/Reviewer_mYum"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6638/Reviewer_mYum"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6638/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761947299372, "cdate": 1761947299372, "tmdate": 1762918953155, "mdate": 1762918953155, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}