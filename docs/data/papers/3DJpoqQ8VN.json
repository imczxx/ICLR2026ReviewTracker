{"id": "3DJpoqQ8VN", "number": 5716, "cdate": 1757928712466, "mdate": 1759897958745, "content": {"title": "The Cost of Knowing: Hallucination Quest Game in Resource-Constrained Multi-Agent Systems", "abstract": "Current LLM hallucination benchmarks are predominantly static, focusing on\nfactuality while ignoring the computational resources consumed. This creates\na distorted view of performance, as costly mitigation strategies can obscure the\ninherent capabilities of more efficient models. This limitation is especially critical\nin multi-agent systems (MAS), where resource efficiency and strategic interaction\nare paramount. To address this gap, we introduce MAS-HQ (Multi-Agent System\nHallucination Quest Game), a dynamic, game-theoretic framework that evaluates\nMAS hallucination under strict resource constraints and direct adversarial competi-\ntion. Within MAS-HQ, agents compete to produce low-hallucination summaries\nwhile minimizing resource use. Success is measured by a multi-dimensional metric\nthat explicitly balances factual accuracy against resource penalties, forcing a trade-\noff between quality and efficiency. We instantiate this competition with Q-Agent, a\nmodular agent architecture designed for strategic play, within a setting that features\npartial observability to drive tactical decision-making. Our experiments reveal\nthe emergence of diverse winning strategies—some prioritizing high factuality,\nothers superior resource efficiency—and demonstrate adaptive agent behaviors\ndriven by the competitive dynamics. MAS-HQ establishes a principled paradigm\nfor benchmarking hallucination in MAS and provides crucial insights into agent\nstrategies under adversarial, resource-constrained conditions.", "tldr": "", "keywords": ["Multi-Agent System", "Hallucination"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8abf4ecf4b3b7a83ba15e607bbcc6a8b05bcbbc1.pdf", "supplementary_material": "/attachment/a95a73dc6c07ffaee9bf83ef992785f0b2e5d256.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces MAS-HQ, a game-theoretic benchmark for evaluating hallucination in multi-agent LLM systems under explicit resource constraints. Two competing “Q-Agents” summarize passages drawn from a news dataset; each agent chooses to continue, review, or end, and a “vision mechanism” leaks limited state information to the opponent when costly review actions are taken. The proposed metric, Q-Score, combines a hallucination score (H-Score) with a resource-usage penalty weighted by coefficients (α,β)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper studies an important question: hallucination leaderboards rarely price in resource costs, which matters operationally in MAS settings.\n\n2. The Q-Score objective and the dual-objective gameplay are easy to follow and properly reflects the central motivation of the paper.\n\n3. The experiments feature breath and ablation that justifies the design choices."}, "weaknesses": {"value": "1. The paper is not well-written. Many notations are not introduced when they are used for the first time. For example, T_{B, I}, V_{B, i}^{self}. \n2. The benefits of gamification of the inherently single-agent optimization problem needs to be further justified.\n    (a). I expect there still should be benefits even without symmetry breaking. One can just run multiple agents independently and chooses the best one, i.e., Best-of-N, a strong and effective baseline. Such a baseline is arguably single-agent. Meanwhile, the symmetric breaking choices seem rather heuristic.\n    (b). It is definitely beneficial to ground the empirical designs with theoretical formalism. However, the introduction of POSG merely reveals that there will be some strategic interaction among agents, i.e., when making decisions, one needs to account for others. It does not justify why such strategic interaction will boost LLM's ability compared with the case without strategic interaction. \n    (c). The formalism is not rigorous either. For example, in the main text, the belief is w.r.t other agents history, while in the appendix, it is w.r.t. the hidden state. \n3. Many SOTA, closed-sourced LLMs are not included, e.g., Gemini-2.5-Pro, GPT-5, etc. It is important to see that the methods are still useful when the base models very strong."}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "k8Pq8hQBJz", "forum": "3DJpoqQ8VN", "replyto": "3DJpoqQ8VN", "signatures": ["ICLR.cc/2026/Conference/Submission5716/Reviewer_ooTE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5716/Reviewer_ooTE"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5716/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931778932, "cdate": 1761931778932, "tmdate": 1762918213385, "mdate": 1762918213385, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces MAS-HQ, a novel game-theoretic framework for evaluating hallucination in multi-agent systems (MAS). The authors argue that existing benchmarks are static, focusing on factuality while ignoring the computational costs of hallucination mitigation. To address this, MAS-HQ places agents in a competitive game where they must produce low-hallucination summaries while minimizing resource consumption. Success is measured by a Q-Score that explicitly balances factual accuracy against resource penalties. The framework includes a modular Q-Agent architecture and a \"vision mechanism\" that creates partial observability, forcing agents to strategically weigh the benefits of actions like self-review against the risk of revealing information to an opponent."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The problem seems reasonably novel. The critique of static hallucination benchmarks is sharp and MAS-HQ has innovtive design owing to the game-theoretic elements. The empirical validation is reasonable as well. But I think it could have been stronger given the rigors of the conference."}, "weaknesses": {"value": "The 'Q-Agent' architecture itself appears to be a relatively standard modular design, and the novelty lies more in the game it is subjected to rather than the agent design. The evaluation hinges critically on an external, pre-trained model for the hallucination H-Score, yet the potential biases or limitations of this judge are not discussed."}, "questions": {"value": "Could you comment on the extent to which your strategies are emergent properties of complex reasoning, versus being more direct, programmatic optimizations of the Q-Score components, especially given the use of a hard threshold for triggering reviews?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mAjAvPM7Bb", "forum": "3DJpoqQ8VN", "replyto": "3DJpoqQ8VN", "signatures": ["ICLR.cc/2026/Conference/Submission5716/Reviewer_kgdH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5716/Reviewer_kgdH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5716/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761942088915, "cdate": 1761942088915, "tmdate": 1762918213016, "mdate": 1762918213016, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes MAS‑HQ, a dynamic, game‑theoretic benchmark for evaluating hallucination in multi‑agent systems under explicit resource constraints. Two modular Q‑Agents (Policy, Summary, Review, Evaluation modules) compete to summarize passages; taking a costly Review action improves a passage but reveals partial state to the opponent via a vision mechanism, creating imperfect information and strategic trade‑offs. Performance is the Q‑Score: an average over passages balancing factuality against API calls, tokens, time, and review counts. Experiments show that winners emerge either by slightly higher factuality or by better resource efficiency; ablations show reviews lift H‑Scores, smaller β increases Q‑Score gains, the vision/passage‑order asymmetry is necessary, and the framework extends to three agents and to a SimpleQA setting.\nIt seems better to me that the paper is submitted to some benchmark tracks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The Q‑Score explicitly prices resources, fixing a common flaw of static hallucination benchmarks that ignore cost\n1. The vision mechanism ties improvement steps to information leakage, producing strategic behavior that static leaderboards miss\n1. Ablation study effectively shows that removing reverse order or vision collapses the game to identical outcomes, and reviews measurably raise H‑Score across models."}, "weaknesses": {"value": "1. The current Q‑Score rewards factual consistency (via H‑Score) and resource frugality; it does not directly reward coverage/completeness of the information that is in the passage. That leaves room for the degenerate strategy “say less to avoid being wrong.” \n1. H‑Score relies on a single pre‑trained discriminator from the Hallucination Leaderboard; any bias or miscalibration there propagates to the Q‑Score. Human verification or multiple evaluators would strengthen conclusions.\n1. In MAS‑HQ, α and β are fixed hyperparameters chosen by the authors to weight factuality vs. resource cost in the Q‑Score. Fixed weights (α=1, β=0.01) strongly shape winners; authors themselves show that smaller β favors review‑heavy strategies (Figure 3‑right). A principled way to set their values is missing. \n1. Because some LLMs refuse certain passages, each model is evaluated on a different subset of the corpus, weakening cross‑model fairness and comparability.\n1. The resource penalty is normalized against the two agents in the same match, which can make Q‑Scores non‑comparable across matches and may amplify design‑choice effects"}, "questions": {"value": "1. What's the rationale for selecting the fixed α and β values"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Rlj1dWa8YJ", "forum": "3DJpoqQ8VN", "replyto": "3DJpoqQ8VN", "signatures": ["ICLR.cc/2026/Conference/Submission5716/Reviewer_3YV8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5716/Reviewer_3YV8"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5716/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976843725, "cdate": 1761976843725, "tmdate": 1762918212771, "mdate": 1762918212771, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Traditional hallucination evaluations are static, focusing solely on factual correctness while ignoring the computational resources required to achieve it. In multi-agent systems, hallucination can be further amplified through interaction, making this limitation more severe. To address this, the authors propose MAS-HQ, a multi-agent, game-theoretic benchmark that studies the trade-off between hallucination and efficiency. Using text summarization as a toy competitive task, MAS-HQ places large language model (LLM) agents in a resource-constrained and adversarial environment, where they must balance factual accuracy with limited computation. This setting reflects realistic multi-agent scenarios that demand both strategic reasoning and efficiency under constraints."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "- Recasts hallucination evaluation as a dynamic competition with explicit compute budgets. This is closer to operational constraints than static leaderboards.\n- The Q-Score makes the tradeoff between factuality and resource use explicit. This encourages Pareto-aware evaluation rather than single-axis optimization.\n- Very clean writing style and clear visualization."}, "weaknesses": {"value": "- My main issue with the paper lies in its framing of text summarization (and SimpleQA) as a competitive game for evaluating MAS.\n1. If the purpose is to evaluate hallucination in fact-based tasks such as text summarization or question answering, framing these as multi-agent competitions seems far-fetched. These tasks typically do not require multi-agent competition with multi-objective constraints, and introducing such a setup makes the tasks appear artificially or unnecessarily challenging.\n2. If the purpose is instead to evaluate hallucination within multi-agent systems themselves, using text summarization merely as a toy task under competitive and resource-constrained conditions, then the framing makes more sense—since collaboration and competition with multi-objective trade-offs are common in MAS. However, in that case, the paper should have chosen tasks that are naturally multi-agent competitive, such as multi-party negotiation or bidding tasks.\n\nIn either case, the problem formulation and experimental setup feel disconnected from real-world scenarios and data distributions, potentially limiting the significance and applicability of the paper’s insights. An unrealistic setup like “competitive text summarization” may undermine the very goal of hallucination evaluation, as it becomes difficult to discern whether the hallucinations arise from the model’s inherent limitations or from artifacts introduced by the Q-Agent architecture and the competition design, which could induce information loss during the process.\n\n- All evaluations are comparisons between Q-Agents’ internal configurations. The experiments lack comparisons with external baselines or alternative methods. For instance, how would a single-agent setup perform on the same tasks without the multi-agent competition?\n\n-  The paper does not seem to provide new insights beyond showing that certain models perform better than others on this specific artificial task on the specific agentic architecture (Q-agent) as designed by the author."}, "questions": {"value": "- As stated in Weakness #1, could the authors clarify the primary research motivation? Is the goal to understand hallucination in generation tasks (e.g., summarization and QA), or to study hallucination in multi-agent reasoning dynamics under competition and resource constraints? Additionally, why were text summarization and question answering chosen as the main evaluation tasks, given that these are not inherently competitive in nature?\n- Can the author provide more baselines external to Q-Agent setup, such as how a single agent would perform?\n- How is the alpha and beta weight chosen in the Q-Score equation during actual implementation. Are they important parameters that could be potentially sensitive and drastically shift agentic behavior and results? If so, can the author provide ablation on the two hyperparameters?\n- One may argue that the hallucination could arise from the design of the Q-Agent architecture itself. i.e the same type of hallucination may happen in Q-Agent but not on a different agent architecture. How can the author counter this argument? Has the author tried on a different/simpler agent architecture.\n- Are there additional insights/findings from the experiments beyond the emergence of diverse winning strategies and adaptive agent behaviors? As one may consider such phenomenon are expected in multi-objective and long-horizon interactive agent setup."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ho2TzLevhZ", "forum": "3DJpoqQ8VN", "replyto": "3DJpoqQ8VN", "signatures": ["ICLR.cc/2026/Conference/Submission5716/Reviewer_nHXu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5716/Reviewer_nHXu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5716/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998000473, "cdate": 1761998000473, "tmdate": 1762918212566, "mdate": 1762918212566, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}