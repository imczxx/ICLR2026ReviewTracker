{"id": "P0lB2uLHli", "number": 7345, "cdate": 1758017182774, "mdate": 1763739329040, "content": {"title": "Guaranteed Jailbreaking Defense via Disrupt-and-Rectify Smoothing", "abstract": "This paper proposes a guaranteed defense method for large language models (LLMs) to safeguard against jailbreaking attacks.\nDrawing inspiration from the denoised-smoothing approach in the adversarial defense domain, we propose a novel smoothing-based defense method, termed Disrupt-and-Rectify Smoothing (DR-Smoothing). Specifically, we integrate a two-stage prompt processing scheme—first disrupting the input prompt, then rectifying it—into the conventional smoothing defense framework. This \\emph{disrupt-and-rectify} approach improves upon previous disrupt-only approaches by restoring out-of-distribution disrupted prompts to an in-distribution form, thereby reducing the risk of unpredictable LLM behavior. In addition, this two-stage scheme offers a distinct advantage in striking a balance between \\emph{harmlessness} and \\emph{helpfulness} in jailbreaking defense. Notably, we present a theoretical analysis for \\emph{generic} smoothing framework, offering a tight bound for the defense success probability and the requirements on the disruption strength. \nOur approach can defend against both token-level and prompt-level jailbreaking attacks, under both \\emph{established} and \\emph{adaptive} attacking scenarios. Extensive experiments demonstrate that our approach surpasses current state-of-the-art defense methods in terms of both harmlessness and helpfulness.", "tldr": "we propose a novel smoothing-based defense method, termed Disrupt-and-Rectify Smoothing (DR-Smoothing)", "keywords": ["Large Language Model", "Jailbreak attacks", "Jailbreak defense"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ffb49c0b217166e9675bd0e9a6b1c0d07eb6f822.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Disrupt-and-Rectify Smoothing (DR-Smoothing) defense against jailbreak attacks on large language models. DR-Smoothing introduce a two-stage smoothing scheme: first, disrupt the input prompt through randomized perturbations, then rectify it using spell-checking and paraphrasing. Aggregated responses are combined via majority voting to produce the final output. The method generalizes existing smoothing-based defenses by restoring out-of-distribution perturbed prompts to in-distribution form. Empirical evaluations across multiple LLMs show DR-Smoothing outperforms prior defenses."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper introduces the *Disrupt-and-Rectify* paradigm, extending randomized smoothing theory from adversarial robustness to the realm of jailbreaking defense.\n2. The writing is clear and well-structured, with effective use of figures, pseudocode, and tables to illustrate the workflow.\n3. The paper successfully bridges theoretical analysis and practical implementation, demonstrating how DR-Smoothing influences the Lipschitz behavior of perturbation responses and interprets empirical results through mathematical foundations."}, "weaknesses": {"value": "1. Although the paper includes an efficiency analysis, DR-Smoothing inherits the common drawback of smoothing-based methods — it requires multiple LLM queries per input, which may incur substantial computational and latency overhead. This makes the approach less practical for real-time or API-limited deployment scenarios.\n2. Limited Methodological Novelty.  The proposed two-stage design, while conceptually neat, integrates existing techniques (e.g., spell-checking and paraphrasing) within the disruption and rectification modules. \n3. The experimental evaluation is limited to AdvBench and two jailbreak types (GCG and PAIR). The absence of broader testing on more diverse or state-of-the-art jailbreak scenarios weakens the empirical generality of the claims."}, "questions": {"value": "1. How does DR-Smoothing perform under multi-turn or context-dependent jailbreaks, where harmful intent is distributed across several dialogue turns rather than a single prompt? \n2. The two-stage Disrupt-and-Rectify process is central to the proposed method. Could the authors provide visual or quantitative analyses (e.g., embedding visualization) to illustrate how the rectification stage transforms the prompt distribution and contributes to defense success?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "RmXknRhfC8", "forum": "P0lB2uLHli", "replyto": "P0lB2uLHli", "signatures": ["ICLR.cc/2026/Conference/Submission7345/Reviewer_nGLK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7345/Reviewer_nGLK"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission7345/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761577015124, "cdate": 1761577015124, "tmdate": 1762919473579, "mdate": 1762919473579, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a jailbreak defence strategy, Disrupt and Rectify Smoothing. At a core level, in this defence, a input prompt is first perturbed (in a similar manner to SmoothLLM), and then undergoes a rectification step (spell check, paraphrasing, etc). This has two advantages in the paper. First, the prompt is cast into a form that for benign queries the LLM is better able to understand and thus suffers from a lower false positive rate. Second, the increased modifications from the paraphrasing stage can further degrade the jailbreak quality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles a important and timely problem, particularly with the growing use of LLMs not just as chatbots, but within more sensitive agentic workflows. \n\nOn the benchmarks and models tested, there is a improvement in performance compared to several compared to defences. In particular the authors use the IntructionFollowing metric to show the small impact on performance of the defence. It also seems from their results that the operations of rectification and smoothing do not cancel each other out (although in theory possible) when used - at least against non-defence tailored attacks."}, "weaknesses": {"value": "The evaluation is relatively small - only GCG and PAIR attacks are considered. Many attacks have been developed since, for example TAP being a stronger iteration of PAIR, AutoDAN, Crescendo, MadMax, etc are all valid attacks. \n\nThe adaptive attack consideration is relativity lightweight - in fact the adaptive attack considered in Table 2 performs worse against DR-Smoothing than the results in Table 1. Likewise, there is no discussion of how an attack may try and exploit or bypass the rectification process directly seeing as it is paraphrased using an LLM. \n\nThe novelty is somewhat modest, as this defence builds directly on SmoothLLM/SemanticSmooth with a conceptually straightforward extension with known methods. In particular, SemanticSmooth already introduced the idea of Spellchecking and Paraphrasing in the defence pipleine. The paper further compares their metrics only against SemanticSmooth's uniform sampling technique, describing it as a fairer comparison in Line 376-377. This proves problematic as excluding the stronger SemanticSmooth-Policy in the analysis dilutes the contribution of the current approach.\n\nFinally, the rectification step could use further discussion: there is little detail about the LLM used, prompt setup, or how rephrasing quality may impact the performance of the defence."}, "questions": {"value": "Why was SemanticSmooth-policy excluded from the experimental comparison? Given the original paper reported that as the strongest variant of the defence."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ffe74tsDFW", "forum": "P0lB2uLHli", "replyto": "P0lB2uLHli", "signatures": ["ICLR.cc/2026/Conference/Submission7345/Reviewer_XAM2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7345/Reviewer_XAM2"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission7345/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761591134451, "cdate": 1761591134451, "tmdate": 1762919472871, "mdate": 1762919472871, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of out-of-distribution perturbed prompts causing unpredictable LLM behavior in smoothing defenses (e.g., SmoothLLM). It proposes DR-Smoothing, a two-stage (disrupt-rectify) smoothing method. Key results: It outperforms SOTA baselines, reducing Vicuna’s GCG ASR to 3.4% (vs SmoothLLM’s 8.6%) and maintaining higher InstructionFollow accuracy, with theoretical DSP bounds."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Rigorous theoretical foundation: Unlike empirical-only baselines, it derives tight bounds for Defense Success Probability (DSP) and disruption strength requirements (e.g., q ≥ 1/(2L)(1+√(2/N)log(1/ε))), providing mathematical guarantees for defense effectiveness. \n2. Two-stage prompt processing: The rectification module (spell-check + paraphrasing) restores out-of-distribution disrupted prompts to in-distribution form, avoiding unpredictable LLM behavior seen in SmoothLLM (e.g., rectified prompts reduce gibberish-induced errors).\n 3. Adaptive attack resilience: It defends against adaptive PAIR attacks (e.g., Vicuna’s adaptive ASR stays low vs Perplexity Filter’s 98%), showing robustness to adversary-aware attacks."}, "weaknesses": {"value": "1. Random disruption operation selection: It randomly chooses character/word-level disruptions; adaptive selection (e.g., character-level for GPT, word-level for PAIR) could optimize efficiency—adding a dynamic selector based on attack type would improve performance. \n2. Scalability issues: N=10 (standard setting) increases runtime to 7.7s (vs baseline 0.7s); optimizing N (e.g., N=3 for lightweight scenarios) without ASR loss is unaddressed, limiting deployment in low-latency systems. \n3. Limited model scale testing: It only evaluates 7B models (Llama-2-7B, Vicuna-7B); larger models (e.g., 13B/70B) are untested—verifying on larger models could confirm scalability."}, "questions": {"value": "Please refer to the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "F0X6m1t0hW", "forum": "P0lB2uLHli", "replyto": "P0lB2uLHli", "signatures": ["ICLR.cc/2026/Conference/Submission7345/Reviewer_9pcy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7345/Reviewer_9pcy"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission7345/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761831780817, "cdate": 1761831780817, "tmdate": 1762919471522, "mdate": 1762919471522, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DR-Smoothing, a defense algorithm consisting of random disruption and recitifacation to achieve certified robustness."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The authors conducted experiments across several models and datasets."}, "weaknesses": {"value": "1. The theoretical proof is meaningless and offers no new insight into the jailbreak problem. I cannot see why the proof supports the claim that the method is certified. Specifically, the theory states that \\alpha(q) should be above certain threshold. However, the authors fail to provide practical guidelines on how to achieve the threshold and it is not known whether such assumption will hold in practise. \n\n2. The experiments are all conducted on out-of-datad benchmarks with out-of-dated LLMs. DR-Smoothing does not offer superior balance between robustness and accuracy. For example, the method reduces accuracy for 7-8% compared to the baseline, which is significant. \n\n3. What is the paraphrasing function? How is it implemented?\n\n4. The additional inference cost of MV and paraphrasing is huge. This defense is neither theoretically sound nor practically useful.\n\nTo summarize my points, the proposed method fails to provide any advancement compared to existing defenses based on random smoothing both empically and theoretically. The technical contribution is limited to trivial re-writing and voting, and the theory is merely a direct application of Hoeffding’s inequality. The scope of the experiments is small and there are important details left unclear."}, "questions": {"value": "What is the paraphrasing function? How is it implemented?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "jLC8u6IWLb", "forum": "P0lB2uLHli", "replyto": "P0lB2uLHli", "signatures": ["ICLR.cc/2026/Conference/Submission7345/Reviewer_m5dK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission7345/Reviewer_m5dK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission7345/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835359355, "cdate": 1761835359355, "tmdate": 1762919468416, "mdate": 1762919468416, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}