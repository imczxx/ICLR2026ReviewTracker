{"id": "CJdX82odge", "number": 8312, "cdate": 1758078263116, "mdate": 1763747616698, "content": {"title": "Mathesis: Towards Formal Theorem Proving from Natural Languages", "abstract": "Recent advances in large language models (LLMs) show strong promise for formal reasoning. However, most LLM-based theorem provers remain constrained by the need for expert-written formal statements as inputs, limiting their applicability to real-world problems expressed in natural language. We address this gap by focusing on autoformalization, the task of translating informal problems into formal statements. We propose Mathesis, the first pipeline for the systematic study of formal theorem proving from natural language. It contributes the first autoformalizer trained with reinforcement learning, which integrates syntactic, semantic, and prover feedback as reward signals to yield accurate and verifiable formalizations. This is further supported by our novel LeanScorer framework for evaluating semantic correctness. To assess real-world applicability, we introduce Gaokao-Formal, a benchmark of 495 complex proof problems from the college entrance exams. Experiments demonstrate that our autoformalizer improves pass rates by 45% on Gaokao-Formal and 6% on MiniF2F compared to state-of-the-art baselines. Paired with provers, our autoformalizer consistently enhances proving accuracy, including a 42% gain for DeepSeek-Prover-V2 on Gaokao-Formal. Our code is available at https://anonymous.4open.science/r/Mathesis-2D14.", "tldr": "", "keywords": ["autoformalization", "AI for math", "AI for science", "Lean 4", "formal reasoning", "parallel corpus", "large language model", "LLM"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1a4029a4291ac31eb3a7806ea6cc99d173a77f02.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The authors propose Mathesis, the first autoformalizer trained with online reinforcement learning. Mathesis tackles the problem setting of formal theorem proving directly from informal problem statements. It is trained with GRPO to maximize semantic and syntactic correctness, and DPO to increase provability of the resulting formalization. The authors also introduce the Gaokao-Formal dataset of problems and LeanScorer to evaluate autoformalization correctness."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The paper uses online RL on the task of statement autoformalization for the first time, showing substantial gains upon the base model. It shows that GRPO with a syntactic check and LLM judge as reward can improve autoformalization.\n\nMoreover, it demonstrates with DPO training that training the model to generate statements that are provable by a downstream prover can improve the quality of autoformalization.\n\nThe authors also propose LeanScorer, a more complicated LLM judger than a binary label, which they demonstrate gives higher precision.\n\nI am also convinced that generating statements that are more easily proven is useful in the setting of end-to-end theorem proving (starting from an informal problem and ending with a formal proof), which is an interesting under-explored problem formulation that has many practical uses and overcomes the scarcity of expert-written formal statements."}, "weaknesses": {"value": "I am not convinced by the complicated formulation of the Sugeno integral. The authors have not provided motivation to use the Sugeno integral, nor any explanation for the formula of $\\mu$ (line 295). For example, why not just use this score: $0$ if there is a label M0, and otherwise use $\\frac{n_{M1}}{|s|}$ as the score? Why choose the specific $\\delta$ value and $\\mu$ formula; is it to obtain a certain reward shape?\n\nAlso, it seems to me that the score $S$ is actually very simple:\n\n- If there is a label M0 in $L$, then $f(l_{\\pi(1)})=0$ so $\\mu(s_i)=0$ for all $i$, so the score is $0$.\n- Otherwise, sort the labels to $n_1$ labels of M½ and $n-n_1$ labels of M1. Then for $1 \\le i \\le n_1$, $\\mu(s_i)=0$ because $n_{M1}=0$. For $i>n_1$, for the set $s_i$, $n_{M1/2}$ is fixed and $\\frac{n_{M1}}{|s_i|} = \\frac{i-n_1}{i}$ increases as $i$ increases, while $f(l_{\\pi(i)}) = 1$, so the maximum on line 295 is always taken at $i=n$. Therefore the formula on line 295 simplifies to $S(L,f,\\mu) = \\frac{n-n_1}{n}(1-\\delta n_1)$.\n\nI concede that I am not familiar with Sugeno integral, and I could have misunderstood some details. I would be happy to dismiss this issue if the authors could explain the motivation for using Sugeno integral and their formulation, and point out my error. Otherwise I would suggest to give the formula for the score in simplified form, and to only give the fuzzy integral formulation if there is a well-founded motivation behind doing so.\n\nIn any case, LeanScorer seems like LLM-as-a-judge with a more complex prompt and score shaping. I am not convinced that LeanScorer is different from LLM-as-a-judge with a more carefully crafted prompt. For example, I think if we prompt the LLM to be stricter (e.g. by giving it a rubric) in Table 2, the precision of LLM-as-a-judge will increase and recall might decrease from 100%, and the F1 score might match LeanScorer, which is itself a LLM judge anyway. Also, LeanScorer is only used for miniF2F-test and Gaokao-Formal, but in both cases the human-written ground-truth formalization exists. Why doesn't the LLM simply compare to the ground-truth formalization, or use BEq (see my questions)?\n\nI am not surprised that performance increased significantly on Gaokao-Formal in Table 3, because the RL training also used Gaokao problems, and the autoformalizer distribution could just be shifted toward Gaokao more.\n\nIt is unclear what “proving accuracy” (line 423) means to me. If I guess correctly, starting from an informal statement, proving accuracy is 1 if a prover model can prove the formal statement translated by another autoformalizer, and 0 otherwise. Is this correct? Consequently, the improvement in Figure 4 is hard to interpret. For example if the autoformalizer model gives wrong formalizations but they are easier to prove (with DPO training), this would still increase the “accuracy”.\n\nOverall, some parts of the paper could be clearer and key ideas could be better conveyed. For example, the authors give many numerical comparisons in the text of Section 4.3, but little explanation, insight, or examples as to why the score of their model is higher. The only “case study” in Appendix E does not explain what it studies and is not referenced anywhere else.\n\nI am happy to increase the score if the weaknesses and questions are addressed."}, "questions": {"value": "Is there any overlap between the data used for training (“the natural language informal statements of problems from a pset (Lin et al., 2025) and our in-house Gaokao dataset”) and the miniF2F-test and Gaokao-Formal datasets used for evaluation? Since both training and testing use a subset of Gaokao problems, is there a chance of contamination?\n\nWhat is Mathesis-Autoformalizer (without HPO) in Table 3? Is it the model after GRPO but before DPO training?\n\nLeanScorer breaks down the natural language statement into subtasks, and compares against corresponding parts in the formal statement. However, what happens if there is an extra part in the formal statement that does not correspond to any natural language? For example, there could be a nondegeneracy criterion (a denominator is nonzero), or the model could have made a mistake and added an unneeded formal criterion. Do these unmatched parts exist and are they ignored?\n\nThe fact that the base model is Kimina-Autoformalizer (and that its size is probably 7B) should be mentioned in the main text instead of the appendix. For example, this makes it easier to understand Table 3.\n\nThere could be some comparison between LeanScorer and BEq/BEq+ (Liu et al. 2024 https://openreview.net/forum?id=hUb2At2DsQ) which has been researched in recent work in training and evaluating autoformalizers (Poiroux et al., 2024; Wu et al., 2025 https://arxiv.org/abs/2508.04440). Comparing against BEq which requires ground-truth labels also better contextualizes this work. I would like to see a comparison to BEq or BEq+ in Table 2. Since Gaokao-Formal contains ground-truth formal statements, I would also like to see BEq scores in Table 3, if BEq turns out to be a good scorer.\n\nMinor suggestions:\n\n- Table 2: the precision score of 94 instead of 93 should be bolded.\n- Line 305: $e_{\\pi(i)}$ -> $l_{\\pi(i)}$."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "gEjdIQwby3", "forum": "CJdX82odge", "replyto": "CJdX82odge", "signatures": ["ICLR.cc/2026/Conference/Submission8312/Reviewer_NXS9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8312/Reviewer_NXS9"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8312/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760488677339, "cdate": 1760488677339, "tmdate": 1762920241785, "mdate": 1762920241785, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes Mathesis, a pipeline for natural-language -> formal-statement -> Lean proof. The core components are: (i) Mathesis‑Autoformalizer, trained with online RL (GRPO) using a composite reward from Lean compilation (syntax) and an LLM-based semantic check, followed by a DPO stage aligned to downstream proof success (“Hierarchical Preference Optimization, HPO”); (ii) LeanScorer, an LLM-driven semantic evaluation with subtask decomposition and aggregation via the Sugeno fuzzy integral; and (iii) Gaokao‑Formal, a 495‑problem benchmark from Chinese college-entrance exams aimed at harder-to-formalize statements. On MiniF2F and Gaokao‑Formal, the autoformalizer improves pass rates in both autoformalization and theorem proving (paired with another prover model)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. End-to-end focus: Unlike the purely formal models like DeepSeek-Prover and datasets like MiniF2F and FIMO, this paper attempts end-to-end full NL input problem -> formal proof pipeline and shows that better formalization substantially boosts downstream proving across multiple provers. Also, Gaokao‑Formal intentionally targets hard-to-formalize statements and broad topics (e.g., analytic geometry, comprehensive questions), which is valuable given miniF2F’s focus. \n\n2. The composite syntax + semantics reward in GRPO followed by DPO aligned to proof success (HPO) is coherent; ablations show small but consistent gains. The autoformalizer attains higher LC and LC+LSC on both datasets than strong baselines like Kimina‑Autoformalizer, and improves pass@32 with multiple 7B prover models"}, "weaknesses": {"value": "1. Data deduplication / de-contamination: Sec. 3.1 states that training-data curation includes the in‑house Gaokao dataset plus Lean Workbook (yielding ~32k problems), and the main evaluation benchmark is also Gaokao‑Formal. Without explicit deduplication auditing (fuzzy NL/FL matching, near-duplicate detection, year‑wise splits), gains on Gaokao‑Formal may reflect domain adaptation or overlap. The paper should document dedup guarantees, overlap statistics, and controlled cross‑domain tests. Also, some of the problems are created before the knowledge cutoff data of the evaluated models, causing the data contamination issues. It would be nice to create a subset of uncontaminated examples for evaluation via temporal split.\n\n2. While LeanScorer is thoughtful, the main LC+LSC@k results overly rely on proposed LLM‑based scorer, raising concerns about metric coupling. Recent alternatives specifically targeting semantic alignment include FormalAlign [1]. The paper compares LeanScorer only to LLM-as-a-judge and re‑informalization rather than to these stronger contemporaries, which this limits external validity. \n\n[1] Lu, Jianqiao, et al. \"Formalalign: Automated alignment evaluation for autoformalization.\" arXiv preprint arXiv:2410.10135 (2024)."}, "questions": {"value": "1. How does Mathesis‑Autoformalizer compare to CriticLean [1] and FormaRL [2] when both are run under your evaluation?\n\n2. How does Gaokao‑Formal relate in difficulty and topic mix to miniF2F, PutnamBench, and ProofNet (e.g., cross‑benchmark transfer results or controlled difficulty calibration)?\n\n3. What safeguards ensure the reported Lean pass rates are not inflated by `apply?` /True/circular-goal artifacts?\n\n[1] Peng, Zhongyuan, et al. \"Criticlean: Critic-guided reinforcement learning for mathematical formalization.\" arXiv preprint arXiv:2507.06181 (2025).\n\n[2] Huang, Yanxing, et al. \"Formarl: Enhancing autoformalization with no labeled data.\" arXiv preprint arXiv:2508.18914 (2025)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "nEdBKNR23X", "forum": "CJdX82odge", "replyto": "CJdX82odge", "signatures": ["ICLR.cc/2026/Conference/Submission8312/Reviewer_UPch"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8312/Reviewer_UPch"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8312/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761430540672, "cdate": 1761430540672, "tmdate": 1762920241343, "mdate": 1762920241343, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces Mathesis, an end-to-end pipeline for formal theorem proving from natural language that centers on Mathesis-Autoformalizer (GRPO + DPO in a two-stage Hierarchical Preference Optimization), a semantic validation module LeanScorer (LLM-assisted subtask decomposition aggregated via a Sugeno fuzzy integral), and a new benchmark Gaokao-Formal (495 problems)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Formal theorem proving is a highly active research domain, and the motivation for the proposed system is clear and compelling.\n2. The proposed methods are conceptually simple yet empirically effective.\n3. The introduction of Gaokao-Formal is valuable in this field."}, "weaknesses": {"value": "1. The paper lacks an adequate quality assessment of the Gaokao-Formal dataset. Some details are missing, such as annotator expertise, inter-annotator agreement statistics, and the protocol for resolving disagreements. Moreover, the subset used in Section 4.1 is not described, making it difficult to interpret the reported F1 scores.\n2. LeanScorer introduces human priors and relies on additional compute (subtask decomposition → evaluation → aggregation) to produce higher scores. As such, it should be compared against other test-time scaling strategies, as well as alternative aggregation methods."}, "questions": {"value": "1. Although LeanScorer improves semantic assessment, it may still produce erroneous judgments. What impact do these errors have on training stability or downstream performance?\n2. The appendix notes that “the policy model is initialized from Kimina-Autoformalizer”, but this important detail should appear in the main text for clarity and reproducibility."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "xGVxJjaN7D", "forum": "CJdX82odge", "replyto": "CJdX82odge", "signatures": ["ICLR.cc/2026/Conference/Submission8312/Reviewer_6WKD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8312/Reviewer_6WKD"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8312/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895858328, "cdate": 1761895858328, "tmdate": 1762920240562, "mdate": 1762920240562, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the important and challenging problem of formal theorem proving directly from natural language. The authors point out that current state-of-the-art automated theorem provers (ATPs) mostly require formal input pre-written by human experts, which limits their real-world applicability. To solve this, the paper proposes Mathesis, a complete pipeline driven by \"autoformalization.\" The core contributions of this work include: The first autoformalization model trained with Reinforcement Learning (RL), Mathesis-Autoformalizer, which innovatively combines syntactic, semantic, and prover feedback as reward signals; A novel semantic correctness evaluation framework, LeanScorer, for fine-grained assessment of formalized statements; A new, highly difficult benchmark dataset named Gaokao-Formal, containing 495 complex proof problems from China's National College Entrance Examination. Experimental results show that this method significantly outperforms existing techniques on multiple benchmarks and confirms the critical role of high-quality autoformalization in boosting the performance of downstream provers."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The combination of Reinforcement Learning with Hierarchical Preference Optimization (HPO) for the autoformalization task is the highlight of this paper. This approach enables dynamic learning from the feedback of a syntax checker, a semantic evaluator, and a downstream prover, significantly improving the quality of the formalized statements. The experimental results (e.g., a 45% relative improvement on Gaokao-Formal) fully demonstrate the effectiveness of this method.\n\nThe authors not only tested their method on two datasets with different difficulty levels and styles but also conducted extensive comparisons with a wide range of top-tier API models (including GPT-4o and Claude-3.5) and open-source models. More importantly, by pairing different autoformalizers with multiple mainstream provers, the paper clearly reveals the decisive impact of autoformalization quality on the final proof success rate.\n\nThe paper offers not just a model but a complete solution, including an innovative evaluation framework (LeanScorer) and a highly challenging new benchmark (Gaokao-Formal). These open-source resources will greatly facilitate subsequent development in the field."}, "weaknesses": {"value": "The first is about the dependence of  LeanScorer on an LLM Evaluator. The core steps of LeanScorer (sub-task decomposition and consistency annotation) rely on an LLM. While experiments show high agreement with human annotators, this still introduces a potential source of noise, which to some extent undermines the credibility of the evaluation.\n\nThe second is that the paper uses downstream proof success as a metric may introduce bias. This could potentially lead the model to favor generating weakened versions of the statement and may weaken the credibility of the evaluation tests in section 4.3."}, "questions": {"value": "1.\tIn the composite reward function for the GRPO stage, you perform a simple addition of the semantic reward $RsemR_{sem}Rsem​$ and the syntactic reward $RverR_{ver}Rver​$. This implies an assumption that they are equally important. Did you experiment with other aggregation methods, such as assigning different weights to them?\n2.\tCould you discuss whether the model has a potential tendency to generate weakened proofs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BSgzeRRPME", "forum": "CJdX82odge", "replyto": "CJdX82odge", "signatures": ["ICLR.cc/2026/Conference/Submission8312/Reviewer_brUb"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8312/Reviewer_brUb"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8312/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761922843283, "cdate": 1761922843283, "tmdate": 1762920239443, "mdate": 1762920239443, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The core contribution of this paper is (1) LeanScorer, a evaluation metric for semantic correctness in autoformalization and (2) training an autoformalization model using RL. The authors combined the autoformalization model with a formal theorem prover to prove statements in natural language."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Evaluating the semantic correctness of autoformalized statements is an important bottleneck in autoformalization. The paper proposed LeanScorer that aims to address this problem\n* This paper is one of the first to train autoformalization models with RL, which is nontrivial because of the difficulty in semantic evaluation."}, "weaknesses": {"value": "* The task of \"formal theorem proving from natural language\" in this paper is not convincing. In this paper, it is defined as: Given a theorem statement in natural language, the model generates its formal statement and the corresponding formal proof. It is evaluated using proof accuracy (Fig. 4). This task definition does not evaluate whether the formalized statement is semantically correct. The model could formalize the natural language statement into a easier formal statement so that the proof accuracy will be higher. I understand that the authors have evaluated their autoformalizer, and experiments show improvements compared to existing autoformalizers under the LeanScorer metric defined in this paper (Table 3). However, that does not resolve this issue. It could be that the autoformalizer in this paper is indeed more accurate but is biased towards making statements easier, whereas previous autoformalzers are less accurate but are biased towards making statements harder. If true, this could explain the results in Fig. 4. \n\n*  The comparison between LeanScorer and LLM-as-a-Judge (Table 2) is inconclusive. LeanScorer has better precision whereas LLM-as-a-Judge has better recall. The F1 score is not a good metric because it assumes precision and recall are equally important. When evaluating autoformalized statements, however, precision is arguably less important than recall, as incorrectly translated statements can also be useful for training theorem provers. It would be great to compare LeanScorer and LLM-as-a-Judge in terms of their downstream impact to theorem proving.\n\n* Need ablation studies to justify the design of LeanScorer, e.g., why Sugeno Fuzzy Integral instead of simpler methods for computing the overall score.\n\n* MiniF2F is already saturated (SOTA methods are close to 100%). It would be great to add results on PutnamBench."}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "As8qAvh6XF", "forum": "CJdX82odge", "replyto": "CJdX82odge", "signatures": ["ICLR.cc/2026/Conference/Submission8312/Reviewer_UUGT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8312/Reviewer_UUGT"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission8312/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762015015126, "cdate": 1762015015126, "tmdate": 1762920238821, "mdate": 1762920238821, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}