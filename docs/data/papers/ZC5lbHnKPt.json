{"id": "ZC5lbHnKPt", "number": 2249, "cdate": 1757041363992, "mdate": 1759898160543, "content": {"title": "On The Difficulty of Learning in Classification Problems: Optimality and Information-Theoretic Perspectives", "abstract": "This paper studies the hardness of learning in classification tasks. We formulate a classification problem using a fixed input distribution and a variable ground-truth classifier drawn from a prior distribution, and consider an average notion of risk measure. We then derive a closed-form solution for the optimal learner and the optimal risk, and use the latter to measure the hardness of learning. Using Fano's Inequality, we establish a risk lower bound in terms of information-theoretic quantities. Our bound overcomes the over-pessimism of classical lower bounds in statistical learning theory. Comparing with existing information-theoretic lower-bounds in similar settings, our bound is tighter and more practically relevant. Our analysis reveals a tradeoff between two key quantities that govern the difficulty of learning in classification problems, which we refer to as $\\textit{identifiability}$ and $\\textit{agreement}$. We also characterize the convergence behavior of our lower bound with respect to the sample size.", "tldr": "This paper proposes an information-theoretic formulation of classification problems and studies an approximation of the difficulty of learning in such formulation.", "keywords": ["Learning Theory", "Information Theory", "Supervised Learning", "Classification Problems"], "primary_area": "learning theory", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c905f7f2069a8c30b65331372fcdbb7dc36ebd65.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper investigates the intrinsic hardness of classification problems through an information-theoretic lens. The setting is defined by an input distribution and a prior over classifiers. The authors derive a closed-form optimal learner, the associated Bayes risk, \nand new lower bounds on classification error expressed via the conditional mutual information $I(F;(X,Y)|S_n)$. The new bounds are claimed to be tighter and more practical than prior ones (Chen et al 2016), (Jeon & Roy 2022). Toy examples and asymptotic analyses support this claim, showing that previous bounds can be vacuous while theirs retain the correct convergence rates."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "* By focusing on average-case risk rather than worst-case PAC or minimax risks, the work avoids the pessimism of classical bounds and connects more naturally to practical distributions.\n* Concrete examples: Simple one-dimensional binary problems illustrate the bound’s behavior, highlighting its non-vacuity and the quadratic scaling gap relative to existing results."}, "weaknesses": {"value": "Major:\n* The presented results are somewhat incremental compared to the previous work of (Jeon & Roy 2022). Both works study the Bayesian posterior as the optimal learner, and use the mutual information $I(F;(X,Y)|S_n)$ to bound the expected classification risk. The insights provided by the two works are identical to a large extent. The main difference lies in the choice of loss function, where this paper uses a 0-1-like loss while (Jeon & Roy 2022) uses the KL divergence. However, this improvement may not be significant enough to be a substantial contribution.\n\nMinor:\n* One of the main theoretical results, Theorem 2, relies on some uncommon assumptions that lack proper justification (L435-440). It is not clear how they come and to what extent these conditions are met in practice.\n* Some numerical studies on the examples provided could make the improvements more intuitive and strengthen the paper."}, "questions": {"value": "* How would the results change if a different loss function is used, e.g., KL divergence or total variance between the two predictions? Currently, the bounds seem looser than (Jeon & Roy 2022) due to the extra $-1$ term or the square. Is it because of the choice of loss function? Will Theorem 1 recover the bound of (Jeon & Roy 2022) if the KL divergence is used?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CHNUQ8BE0n", "forum": "ZC5lbHnKPt", "replyto": "ZC5lbHnKPt", "signatures": ["ICLR.cc/2026/Conference/Submission2249/Reviewer_s5Lw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2249/Reviewer_s5Lw"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2249/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760483877281, "cdate": 1760483877281, "tmdate": 1762916160869, "mdate": 1762916160869, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors consider a new formulation of classification problems, specified by a fixed input distribution $\\mu$ and a prior distribution $\\mathcal{E}_{F}$ of hypotheses, to overcome the pessimism of the classic PAC learning model. The learner’s performance is then measured by the average classification risk rather than the worst-case risk. They identify the optimal learning algorithm and its (optimal) risk. Based on Fano's method, they provide new information-theoretic risk lower bound, which demonstrates advantage over previously-known lower bound on concrete examples. Finally, they also analyze the convergence of the lower bound (conditional entropy reduction quantity) for classes with finite cardinality."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper provides a new clear formulation of standard classification problem which is interesting and worth exploring. Under the new setting, the authors build a closed-form derivation of the optimal learner and its optimal risk, together with a new information-theoretic lower bound. One of this paper's shining points is that it reveals an innovative \"identifiability–agreement\" tradeoff characterization of the hardness of learning."}, "weaknesses": {"value": "Minor comments:\n(1): In Section 2 (Related works), since the preliminaries are provided later in Section 3, readers might get confused about, for example, what does a KL-divergence between two functions $f$ and $\\hat{f}$ mean in Equation (3) (though they are clarified to be probability measures later in Section 3). In other words, I think it would be better to have Section 3 presented ahead of Section 2. \n\n(2): In Section 5, the asymptotic result is not quite intuitively understandable, especially those additional assumptions and careful hyperparameter choice. (Please see questions below)."}, "questions": {"value": "1. The problem formulation is interesting if the authors can come up with a practical interpretation for it, namely, machine learning scenarios where the model is applicable (cases when we are interested in average risk). In that way, the new formulation becomes more meaningful and less artificial. \n\n2. In learning theory, there is another line of works also focus on overcoming the pessimistic effect of the classic PAC model, called \"universal learning\" (see [1] and follow-up works). Did the authors compare them?\n\n3. In Section 5, besides the finite cardinality (which is already quite limited), the result also requires some regularity assumptions. Can the authors explain how strong those assumptions are?\n\n[1]: Bousquet, O., Hanneke, S., Moran, S., Van Handel, R., and Yehudayoff, A. (2021), “A theory of universal learning,” in Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pp. 532–541."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "7wZ8fAn8dr", "forum": "ZC5lbHnKPt", "replyto": "ZC5lbHnKPt", "signatures": ["ICLR.cc/2026/Conference/Submission2249/Reviewer_vkM9"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2249/Reviewer_vkM9"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2249/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761928166568, "cdate": 1761928166568, "tmdate": 1762916160679, "mdate": 1762916160679, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new general information-theoretic lower bound for classification problems. The bound is different from the “worst-case” sense of lower bounds in the PAC framework, which typically comes up with a single ground-truth distribution for which learning is hard. Instead, the regime is on “average” over a distribution $\\varepsilon_F$ of ground-truth hypothesis.\n\nThe proposed lower bound is in a similar framework to Chen et al. 2016, where the risk of any learning algorithm is measured with respect to a randomly sampled dataset of $n$ points, a randomly sampled ground truth hypothesis $f \\sim \\varepsilon_F$, and a random hypothesis sampled from the learner’s output distribution trained on the input dataset. The paper first shows that even in very simple scenarios with, for example, threshold classifiers, the lower bound of Chen et al. can become vacuous. The paper argues that this is because while the bound from Chen et al. considers the identifiability of hypotheses (captured by the conditional entropy of the hypothesis set and sampled dataset), the same bound does _not_ consider the agreement of potential hypotheses on a new sampled datapoint.\n\nThe paper then proposes that the agreement (and identifiability) can indeed be captured by considering the conditional entropy of the hypothesis set and sampled dataset in addition to the additional knowledge gained by sampling one further datapoint. This simplifies to eq (22) in Theorem 1, which cleanly captures these two notions.\n\nFinally, in Theorem 2, the paper studies what happens as n-> inf. In learning theory, we often assume that everything is learnable (or at least, identifiable) with an infinite number of samples, so one would hope that this behavior is captured in the lower bound. Indeed, this is captured by how quickly the lower bound diminishes as n increases, which the theorem characterizes."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Note that I did not read the appendix, and do not work in the “information theory for lower bounds in learning” area. Although theoretical, the paper is written in a very accessible manner, which makes understanding the intuition behind the results very simple. In fact, the way that the paper is presented makes the result seem so clear in hindsight that it is surprising it has not been done before. This is a strength, and I take it to mean that the paper is natural and important.\n\nI also like the decomposition in the lower bound between the “agreement” of hypotheses and their “identifiability”. The motivation in the first threshold / interval classification problem and the failure of prior work (Chen et al.) to capture this is very clear."}, "weaknesses": {"value": "The examples given in the main paper show how the proposed bound is an improvement over prior work. However, can one come up with settings where the proposed bound is loose? What do these settings look like? This may help show further limitations of the lower bound.\n\nAn additional weakness is that some form of proof sketch should probably be given for Theorem 1, since it is the main result of the paper. How does the proof go, or what are the intuitions behind some of the steps? This may be especially important for readers like me who are unfamiliar with these kinds of information-theoretic arguments.\n\nThere may also be the question of whether having only Theorem 1 + 2 is “enough” for the paper to be accepted. I believe that the story is very nice and intuitive, and I don’t see this as a weakness."}, "questions": {"value": "1. This is potentially somewhat tangential. Are the conditional entropy decompositions related in any way to the aleatoric / epistemic decompositions from the work of Ahdritz et al. 2025 (who also use conditional entropy)? Can I interpret the lower bound as saying how quickly we can decrease the “epistemic uncertainty” of the model with each additional data point? Or, perhaps interpreting eq (22) directly, part (1) reflects the “epistemic” (reducible) uncertainty, and part (2) reflects the “aleatoric” (irreducible) uncertainty in nature itself. Thus, learning can be hard either because we do not have enough samples, or because nature itself is random. \n2. Is the proposed decomposition related to any work in active learning? There, the goal is often to reduce the uncertainty a maximal amount for each added datapoint to the dataset. For example, Castro and Nowak (Minimax Bounds for Active Learning, 2007?).\n\nAhdritz et al. Provable Uncertainty Decomposition via Higher-Order Calibration. ICLR 2025.\n\nSuggestions\n1. Line 66: “Uses KL divergence as a measure of risk , making the resulting lower bound largely irrelevant for practical considerations.” Maybe one more sentence on why this is the case? As someone who does not work on lower bounds, it is not immediately clear what this means. Coming back, I found that line 222-227 explains this more somewhat. Perhaps turn 222-227 into a remark which you can reference in line 66.\n2. For those who do not work in lower bounds or information theory, perhaps the use of Fano’s inequality and how it differs from applications in prior work could be helpful.\n\nTypos\n1. Line 219: “unstrained” -> “unconstrained”?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "hcY0xrYrnJ", "forum": "ZC5lbHnKPt", "replyto": "ZC5lbHnKPt", "signatures": ["ICLR.cc/2026/Conference/Submission2249/Reviewer_vCPZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2249/Reviewer_vCPZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2249/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762037727085, "cdate": 1762037727085, "tmdate": 1762916160360, "mdate": 1762916160360, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies Bayesian classification with a fixed input distribution mu and a known prior E_F over label-generating classifiers F. The goal is to lower bound the Bayes risk, i.e., the best achievable error after observing n training examples. The main result decomposes the residual uncertainty about a test label Y (given the training set S and test input X) into two parts: I(F;X,Y|S), which is the one-example information gain about the ground-truth classifier that remains after training, and H(Y|F,X), which captures intrinsic label noise. A Fano-type argument turns this residual uncertainty into a lower bound on the misclassification error. As n grows and F becomes identified, I(F;X,Y|S) shrinks and the bound becomes dominated by H(Y|F,X)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The decomposition is clear and interpretable: it separates task ambiguity (what we still do not know about F after seeing S) from irreducible noise (randomness in Y given F and X). The framing is consistent with Bayesian learning, and the result reads naturally."}, "weaknesses": {"value": "Technical novelty appears limited. The core derivation relies on standard conditional independence, chain rules, and a textbook Fano inequality; the Appendix E proof is essentially careful bookkeeping.  Lemma 1 and Proposition 1 follow almost immediately from the definition of Bayes risk. Lemma 2 is a standard Fano inequality. please position what is genuinely new relative to existing lower-bound techniques.\n\nThe practical motivation is lacking: the paper suggests this “sidesteps pessimistic PAC bounds,” but it is not yet clear when the proposed Bayes-risk lower bound yields strictly sharper or more actionable insights. The knowledge assumptions are also strong: do we actually know mu and E_F in practice, and if not, how informative is the bound under prior or distributional misspecification?\n\nMinor comments\n\n- In figure 2 what is F and hat F?\n\n- The citation is wrong for lower bound on VC classes. The lower bound comes from this work:\nA. Ehrenfeucht, D. Haussler, M. Kearns, and L. G. Valiant. A general lower bound on the number of examples needed for learning."}, "questions": {"value": "see above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "v4ZErhLH9S", "forum": "ZC5lbHnKPt", "replyto": "ZC5lbHnKPt", "signatures": ["ICLR.cc/2026/Conference/Submission2249/Reviewer_2Esk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2249/Reviewer_2Esk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2249/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762110179211, "cdate": 1762110179211, "tmdate": 1762916160082, "mdate": 1762916160082, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}