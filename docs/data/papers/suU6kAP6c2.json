{"id": "suU6kAP6c2", "number": 9828, "cdate": 1758142490896, "mdate": 1763677728984, "content": {"title": "Generalized Parallel Scaling with Interdependent Generations", "abstract": "Parallel LLM inference scaling involves sampling a set of $N>1$ responses for a single input prompt. However, these $N$ parallel responses tend to be generated independently from each other, partitioning compute resources and leaving potentially useful information in one generation untapped by others. This is in contrast to response length scaling where past computation is used in all future steps. For higher quality responses and response sets, we propose Bridge to generate interdependent responses in parallel by rethinking batched LLM hidden states as holistic tensors rather than independent slices. With only a small amount (2.8\\%-5.1\\%) of new parameters, Bridge improves the relative mean accuracy gains from reinforcement learning with verifiable rewards by up to 39\\% and boosts consistency of correct responses. Trained once, Bridge scales to any generation width, all with greater performance than independent generations, unlocking a more general mode of parallel scaling that effectively leverages information between sequences, compatible with any post-generation aggregation technique.", "tldr": "To generalize and enhance parallel inference scaling for LLMs, we introduce Bridge, an architectural addition to LLMs that allows parallel generations for the same input to share information with each other throughout the decoding process.", "keywords": ["large language model", "inference", "scaling", "reasoning", "reinforcement learning", "post-training", "attention"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/11353a72f9dc0e8ce8e1aed8f2087c2776f796e4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Their method allows the LLM to attend to parallel generations from the same prompt. They do this with a new transformer block that attends to the previous token representation from the other generations. They initialize the layers to have no contribution, and fine tune the new architecture with SFT followed by RL. Their results show that this works better than adding the equivalent number of parameters to the transformer."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Novelty:\nExisting methods use multiple LLM generations, but theirs is the first I know of in which other generations influence the model during generation.\n\nClarity:\nThe paper was easy to understand, Figure 2 was clear and aided in understanding.\n\nResults:\nThe results are strong. I found figure 5 especially convincing, since it shows that increasing the generation width helps up to a point.\n\nSignificance:\nIt's common to sample multiple responses from LLMs, so this method is widely applicable."}, "weaknesses": {"value": "Error bars\n\nNone of the plots have error bars and there’s only one run of each method. This makes it hard to tell if the differences are real in some cases where the method results are close to the baseline.\n\nReproducibility\n\nThe code is not provided, and there is no reproducibility statement. This is especially important for this paper since the main contribution is the new transformer layer so open sourcing the implementation would be very useful.\n\nBaselines\n\nThey don’t compare with any existing methods. Some existing methods take advantage of multiple generations to improve LLM accuracy, for example self consistency. The authors could compare against self consistency, or show the result of using self consistency on top of Bridge.\n\nMinor clarity issues:\n\nThe motivation in the introduction is high level and abstract. It says “Independent generations for the same prompt leave potentially useful information derived from other responses unutilized, limiting the performance ceiling.” but it doesn’t explain what this potentially useful information is. Add concrete examples to help the reader understand the motivation.\n\nThe paper doesn’t explain what RL with verifiable rewards is, leading to confusion which don’t already understand it. For example, the paper should explain if Bridge can also work with other types of RL for language models like RLHF, or if it’s only applicable to RLVR."}, "questions": {"value": "none"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "45wNTA8SSt", "forum": "suU6kAP6c2", "replyto": "suU6kAP6c2", "signatures": ["ICLR.cc/2026/Conference/Submission9828/Reviewer_hSjT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9828/Reviewer_hSjT"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761803451927, "cdate": 1761803451927, "tmdate": 1762921311705, "mdate": 1762921311705, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Bridge, a module for LLMs that applies attention between (past) tokens across parallel samples. The proposed method enables interdependence between traditionally independent parallel responses. The block is trained using RLVR and optional SFT warm up. The paper presented experiments showing that Bridge achieves better accuracy on math benchmarks over the base model."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The paper presents, to the best of my knowledge, a novel idea of enabling attention between tokens across samples in a batch, a dimension that typically maintains independence. \n- The evaluation applies Bridge and baselines to a variety of different math benchmarks"}, "weaknesses": {"value": "- The improvement in accuracy is rather small compared to baselines. Bridge does not perform much better than P-Match, which is the baseline given the equivalent amount of compute and in some cases also not much better than just RLVR only. As such, it seems most of the accuracy improvements are from additional compute/training over the original model rather than from the Bridge block design.\n- An important motivation to enable parallelism is to enable lower latency while increasing compute. The evaluation does not present the inference latency of Bridge and baselines\n- The evaluation lacks comparison to methods that enable parallelism during LLM decoding (such as those cited in the paper). Several of those methods (e.g. Multiverse, Pasta) already have mechanisms for encoding interdependency between different threads by enabling parallel threads to join together and respawn. The evaluation should evaluate against these methods to compare how Bridge's method of enabling interdependency performs.\n- The notation of Eq 1 and Eq 2 are difficult to parse"}, "questions": {"value": "- Is there a latency cost due to the additional computation in Bridge?\n- How does Bridge perform compared against using existing methods enabling parallel computation (with and without interdependence)? Even though they eventually join together into a single response, a simple string post-processing step can split the response back into a set of responses by splitting on the special tokens these methods use for spawning parallel threads. How does Bridge compare to doing this?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "C1DbwhFSBW", "forum": "suU6kAP6c2", "replyto": "suU6kAP6c2", "signatures": ["ICLR.cc/2026/Conference/Submission9828/Reviewer_YB53"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9828/Reviewer_YB53"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761850974331, "cdate": 1761850974331, "tmdate": 1762921311410, "mdate": 1762921311410, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes an architectural modification to the transformer architecture to allow parallel generations to communicate with each other during generation. It shows notable improvements in accuracy on math benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper introduces a novel and clever technique that offers a nice performance improvement on math benchmarks at a modest cost. It offers an appropriate level of technical detail and analysis."}, "weaknesses": {"value": "The paper only evaluates math benchmarks, so it's unclear how well the approach would work in other domains.\n\nIt's not clear that P-Match, rather than any of the alternatives described in the related works section, is the appropriate baseline.\n\nFigures lack CIs."}, "questions": {"value": "Can you address the concerns around generalization to non-math domains, and appropriate comparison approaches?\n\nWhat is your hypothesis for why, as shown in Figure 7, norm ratios for Bridge blocks are so low?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "US2T8K2meR", "forum": "suU6kAP6c2", "replyto": "suU6kAP6c2", "signatures": ["ICLR.cc/2026/Conference/Submission9828/Reviewer_T7CP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9828/Reviewer_T7CP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761949859659, "cdate": 1761949859659, "tmdate": 1762921310870, "mdate": 1762921310870, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors propose a new technique, aptly called Bridge, for post-training language models to perform well at parallel generation. By allowing different sequence positions across a batch to effectively communicate with each other, each independent generation suddenly becomes interdependent. \n\nThe authors evaluate the technique on the canonical math datasets and produce reasonable baselines to compare Bridge against. They find that Bridge leads to improvements in both the pass@k and G-Pass@8_{tau}."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Strengths:\n- The paper is well written. Coherent and understandable (albeit a few minor places I would have appreciated a little more context).\n- This approach seems reasonable for introducing interdependence across generations.\n- Reasoning in LLMs is an important area. AFAIK this is the first paper that takes a serious stab at introducing cross information sharing across parallel generations."}, "weaknesses": {"value": "Weaknesses:\nI left the paper feeling like something was missing. The proposed architecture seems reasonable, but I have no idea for what it’s actually doing for the model? \n- Does the model begin to sample in semantically different directions given context from other models? I.e., does it increase diversity? \n- If one trace is suddenly going in the right direction, do other traces update their reasoning accordingly?\n\nSomething as simple as BERTScore (similar to here [1,2]) or some notion of entropy across traces in the different settings could provide some insights into what’s going on.\n\nA preliminary step in understanding what’s going on was done on line [457] but this seems both unsatisfactory and overly short. \n\n[1] https://arxiv.org/abs/2502.01697 \n[2] https://openreview.net/forum?id=gvsdQ72Peg&noteId=gvsdQ72Peg"}, "questions": {"value": "Minor points:\n- How did you get the numbers 30%, 50% and 23% on line [323]? I can’t recreate them from the table using Avg col?\n- In line [365] I would have appreciated a definition of coverage."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l0AnjCxDM2", "forum": "suU6kAP6c2", "replyto": "suU6kAP6c2", "signatures": ["ICLR.cc/2026/Conference/Submission9828/Reviewer_vGTK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9828/Reviewer_vGTK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762042903669, "cdate": 1762042903669, "tmdate": 1762921310388, "mdate": 1762921310388, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In this paper, the authors propose a new technique, aptly called Bridge, for post-training language models to perform well at parallel generation. By allowing different sequence positions across a batch to effectively communicate with each other, each independent generation suddenly becomes interdependent. \n\nThe authors evaluate the technique on the canonical math datasets and produce reasonable baselines to compare Bridge against. They find that Bridge leads to improvements in both the pass@k and G-Pass@8_{tau}."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Strengths:\n- The paper is well written. Coherent and understandable (albeit a few minor places I would have appreciated a little more context).\n- This approach seems reasonable for introducing interdependence across generations.\n- Reasoning in LLMs is an important area. AFAIK this is the first paper that takes a serious stab at introducing cross information sharing across parallel generations."}, "weaknesses": {"value": "Weaknesses:\nI left the paper feeling like something was missing. The proposed architecture seems reasonable, but I have no idea for what it’s actually doing for the model? \n- Does the model begin to sample in semantically different directions given context from other models? I.e., does it increase diversity? \n- If one trace is suddenly going in the right direction, do other traces update their reasoning accordingly?\n\nSomething as simple as BERTScore (similar to here [1,2]) or some notion of entropy across traces in the different settings could provide some insights into what’s going on.\n\nA preliminary step in understanding what’s going on was done on line [457] but this seems both unsatisfactory and overly short. \n\n[1] https://arxiv.org/abs/2502.01697 \n[2] https://openreview.net/forum?id=gvsdQ72Peg&noteId=gvsdQ72Peg"}, "questions": {"value": "Minor points:\n- How did you get the numbers 30%, 50% and 23% on line [323]? I can’t recreate them from the table using Avg col?\n- In line [365] I would have appreciated a definition of coverage."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "l0AnjCxDM2", "forum": "suU6kAP6c2", "replyto": "suU6kAP6c2", "signatures": ["ICLR.cc/2026/Conference/Submission9828/Reviewer_vGTK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9828/Reviewer_vGTK"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9828/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762042903669, "cdate": 1762042903669, "tmdate": 1763679114689, "mdate": 1763679114689, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Revision Changes"}, "comment": {"value": "We would like to thank the reviewers again for their time. We have made several updates to the paper in our current revision, of which we list major ones here for the interest and convenience of the reviewers:\n\n1. 4 new non-math evaluations added to Table 2: XSum (summarization), CNN/DailyMail (summarization), GPQA (science), and ZebraLogic (puzzle). _Even though we trained purely on math, we see no degradation and often improvement on these tasks._\n\n2. We doubled the number of responses per problem for competition math tasks from 16 to 32. As such, numbers in the tables and figures may be slightly different from the initial version. These new experiments further reinforce the benefit of Bridge."}}, "id": "9yNRymbxF5", "forum": "suU6kAP6c2", "replyto": "suU6kAP6c2", "signatures": ["ICLR.cc/2026/Conference/Submission9828/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9828/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission9828/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763678594438, "cdate": 1763678594438, "tmdate": 1763678594438, "mdate": 1763678594438, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}