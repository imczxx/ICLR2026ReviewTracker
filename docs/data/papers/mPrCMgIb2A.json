{"id": "mPrCMgIb2A", "number": 15777, "cdate": 1758255121716, "mdate": 1759897282789, "content": {"title": "Guaranteed Top-Adaptive-K in Recommendation", "abstract": "Recommender systems (RS) are crucial in offering personalized suggestions tailored to user preferences. While conventionally, Top-\\(K\\) recommendation approach is widely adopted, its reliance on fixed recommendation sizes overlooks the diverse needs of users, leading to some relevant items not being recommended or vice versa. While recent work has made progress, they determine \\(K\\) by searching over all possible recommendation sizes for each user during inference. In real-world scenarios, with large datasets and numerous users with diverse and extensive preferences, this process becomes computationally impractical. Moreover, there is no theoretical guarantee of improved performance with the personalized K. In this paper, we propose a novel framework, **K-Adapt**, which determines dynamic K-prediction set size for each user efficiently and effectively. Specifically, it reformulates adaptive Top-\\(K\\) recommendation as a utility-based risk control problem, where a calibrated threshold based on user utility metrics determines the prediction sets. A lightweight greedy optimization algorithm efficiently learns this threshold to generate dynamic recommendations. Theoretical analysis is provided by establishing upper bounds on expected risk as well as near-optimality and stability of the learned threshold. Extensive experiments on multiple datasets demonstrate that the K-Adapt framework outperforms baseline methods in both performance and time efficiency, offering a guaranteed solution to fixed Top-\\(K\\) challenges.", "tldr": "", "keywords": ["User Personalized Recommendations"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/edb1bba2effb01b12b8343485fdd2ed4aae2d2ab.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes K-Adapt, a model-agnostic adaptive framework for recommender systems that automatically chooses recommendation size per user via a calibrated score threshold $\\lambda$. It formulates the problem as utility-based risk control, extends conformal prediction to ranking metrics, and uses a greedy calibration algorithm. Theoretical analysis provides theoretical guarantees, near-optimality, and perturbation-stability of the proposed method. Experiments on three datasets and five backbones show improvements over selected dynamic-K baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- This paper studies the adaptive recommendation size, which is an important and practical problem in RS.\n- Theoretical analysis is provided for the proposed method.\n- The experimental results demonstrate the effectiveness of the proposed method."}, "weaknesses": {"value": "- The motivation for the proposed adaptive threshold $\\lambda$ is not convincing due to the trivial solutions.\n- Some critical assumptions in the theoretical analysis are not reasonable.\n- The write-up and mathematical notations can be improved for better clarity."}, "questions": {"value": "**Concerns about Motivation.** The proposed adaptive threshold $\\lambda$ for restricting recommendations is not convincingly motivated:  \n- The definition of the optimal $\\lambda^*$ assumes that $R(\\lambda)$ is non-decreasing (equivalently $U(\\lambda)$ is non-increasing), as also stated in Theorem 2. This holds for some metrics (e.g., Recall, NDCG) but fails for others, such as Precision, original F1-score (not the one defined in Appendix A.2), etc. This limits the applicability of the proposed method in real-world RS, and the authors should provide further discussion on this point.\n- Even when the assumption holds, minimizing $\\lambda$ trivially minimizes $R(\\lambda)$. For instance, $\\lambda \\to -\\infty$ yields maximum Recall and NDCG by recommending all items. However, this trivial solution is meaningless in practice. The proposed greedy algorithm with $K_{\\max}$ avoids the \"all items\" case but not the equally trivial \"always recommend $K_{\\max}$ items\", since $\\lambda$ only decreases. The authors should clarify how their method avoids such trivial solutions.\n\n**Concerns about Theoretical Results.** Some critical assumptions in the theoretical results are not convincing, which needs to be addressed:\n- As stated above, the monotonicity assumption on $R(\\lambda)$ may not hold, which invalidates Theorem 2 and subsequent results.\n- Theorems 2 and 3 also assume that there exists a positive constant $c$ such that for any $\\lambda \\ge \\lambda^\\star$, $R(\\lambda) - R(\\lambda^\\star) \\geq c(\\lambda - \\lambda^\\star)$. This assumption is obviously not true in general for almost all metrics due to their discrete nature and stepwise changes.\n\n**Discussion on Top-$K$ Recommendation Optimization.** Recent literature has extensively studied top-$K$ recommendation optimization, including LambdaLoss@$K$ [R1], SONG@$K$ [R2], LLPAUC [R3], and SL@$K$ [R4]. These methods optimize fixed top-$K$ metrics with a fixed $K$, achieving strong empirical performance and theoretical guarantees. Since the proposed K-Adapt method is model-agnostic and can be applied only at inference time, it would be interesting to see whether it can further improve the performance of these top-$K$ recommendation losses.\n\n**Minor Concerns:**\n\n- Theorem 1: What is the meaning of $\\lambda^*$ in the proof? Should it be $\\hat\\lambda$? In addition, it seems that the deviation $\\delta(\\epsilon)$ is in fact not dependent on $\\epsilon$.\n\n**References:**\n\n- [R1] On Optimizing Top-K Metrics for Neural Ranking Models. SIGIR '22.\n- [R2] Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence. ICML '22.\n- [R3] Lower-Left Partial AUC: An Effective and Efficient Optimization Metric for Recommendation. WWW '24.\n- [R4] Breaking the Top-K Barrier: Advancing Top-K Ranking Metrics Optimization in Recommender Systems. KDD '25."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Kds0NIICWM", "forum": "mPrCMgIb2A", "replyto": "mPrCMgIb2A", "signatures": ["ICLR.cc/2026/Conference/Submission15777/Reviewer_TAkm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15777/Reviewer_TAkm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15777/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761500819936, "cdate": 1761500819936, "tmdate": 1762926010363, "mdate": 1762926010363, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper is about controlling the score threshold for recommendations.\\\nTo do this, they propose K-adapt (GUARANTEED ADAPTIVE-K IN RECOMMENDATIONS).\\\nSpecifically, based on the calibration dataset, they set the threshold for ensuring the pre-defined performance.\\\nThen, they use the threshold for the inference to control the number of recommendations for each user."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well formulated and easy to follow.\n- The paper has a good structure and good citation format.\n- Figures and Tables are well organized and presented.\n\n2. Fast inference time.\n- They use the pre-selected threshold for the inference time, which results in faster inference than existing methods.\n\n3. Experiment on real-world datasets demonstrates the superiority of the proposed method."}, "weaknesses": {"value": "1. The method should be described in a more detailed way.\n- Algorithm 1 should be included in the main manuscript, not in Appendix.\n\n2. Technical contribution is marginal.\n- From my understanding, the method selects the threshold to ensure a certain performance in the calibration set.\\\nThen, it uses the threshold for the inference.\n- Is the global threshold enough for all users?\n\n3. Not guaranteed performance?\n- In the manuscript and title, they noted that their method \"guarantees\" the performance.\n- In Table 1, however, $\\alpha=0.05$ and the performance is not 0.95.\n- Also, in Figure 4, recall is almost zero when $\\alpha=0.4$."}, "questions": {"value": "Please refer to Weaknesses.\\\nAlso, what is the purpose of Eq.5? I think both cases are the same."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sp88ef2IXM", "forum": "mPrCMgIb2A", "replyto": "mPrCMgIb2A", "signatures": ["ICLR.cc/2026/Conference/Submission15777/Reviewer_4jwe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15777/Reviewer_4jwe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15777/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761605084552, "cdate": 1761605084552, "tmdate": 1762926009866, "mdate": 1762926009866, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces K-Adapt, a theoretical framework that dynamically determines the number of recommendations (K) for each user, rather than relying on a fixed K. Traditional Top-K recommender systems use the same list length for all users, ignoring individual differences and potentially reducing user satisfaction. In contrast, K-Adapt learns a calibrated threshold that defines each user’s personalized recommendation size with formal risk guarantees. Experiments on the MovieLens, Last.fm, and AmazonOffice datasets demonstrate the effectiveness and robustness of the proposed approach."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper is well-written and easy to follow, with a clear structure and logical flow.\n\n- The proposed framework is built on conformal prediction theory, providing formal statistical guarantees for adaptive-K recommendations, which is a strong and theoretically sound foundation."}, "weaknesses": {"value": "- The experiments mainly focus on offline metrics, with no exploration of latency, real user feedback, or real-world deployment aspects.\n\n- The framework’s performance potentially depends on the calibration data. If the data doesn’t represent real-world conditions well, or if things change over time, the guarantees might not hold up. It would be beneficial to do more analysis in terms of this apsect."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "PkpVCiZzha", "forum": "mPrCMgIb2A", "replyto": "mPrCMgIb2A", "signatures": ["ICLR.cc/2026/Conference/Submission15777/Reviewer_VJFX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15777/Reviewer_VJFX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15777/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762137533138, "cdate": 1762137533138, "tmdate": 1762926008766, "mdate": 1762926008766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}