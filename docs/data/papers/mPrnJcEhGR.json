{"id": "mPrnJcEhGR", "number": 3393, "cdate": 1757417419082, "mdate": 1763370937917, "content": {"title": "Direct Bias-Correction Term Estimation for Average Treatment Effect Estimation", "abstract": "This study considers the estimation of the direct bias-correction term for estimating the average treatment effect (ATE). Let $\\{(X_i, D_i, Y_i)\\}_{i=1}^{n}$ be the observations, where $X_i \\in \\mathbb{R}^K$ denotes $K$-dimensional covariates, $D_i \\in \\{0, 1\\}$ denotes a binary treatment assignment indicator, and $Y_i \\in \\mathbb{R}$ denotes an outcome. In ATE estimation, $h_0(D_i, X_i) \\coloneqq \\frac{1[D_i = 1]}{e_0(X_i)} - \\frac{1[D_i = 0]}{1 - e_0(X_i)}$ is called the bias-correction term, where $e_0(X_i)$ is the propensity score. The bias-correction term is also referred to as the Riesz representer or clever covariates, depending on the literature, and plays an important role in construction of efficient ATE estimators. In this study, we propose estimating $h_0$ by directly minimizing the Bregman divergence between its model and $h_0$, which includes squared error and Kullback--Leibler divergence as special cases. Our proposed method is inspired by direct density ratio estimation methods and generalizes existing bias-correction term estimation methods, such as covariate balancing weights, Riesz regression, and nearest neighbor matching. Importantly, under specific choices of bias-correction term models and Bregman divergence, we can automatically ensure the covariate balancing property. Thus, our study provides a practical modeling and estimation approach through a generalization of existing methods.", "tldr": "", "keywords": ["average treatment effect estimation", "covariate balancing", "inverse probability weighting estimator"], "primary_area": "causal reasoning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8b1dd9c9c0fb46a9f549963b010011a042ff073d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This work presents a way to estimate the Riesz representer of a well-studied quantity, the average treatment effect (ATE). In Section 1.2, the authors claim the following contributions:\n\n1. The proposal of a framework for direct bias-correction term estimation.\n2. The theoretical analysis of the estimator obtained via direct bias-correction term estimation.\n3. Generalizing this framework from L2 losses to Bregman losses.\n4. Unifying the existing literatures between Riesz regression and covariate balancing.\n\nI respectfully disagree with the authors that #1, #2, and #4 are novel contributions. See my answer in **Weaknesses** for more detail."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "To the best of my knowledge, contribution #3 is novel."}, "weaknesses": {"value": "As the authors acknowledge later (beginning of Section 5.1), the framework in #1 is equivalent to Riesz regression, an existing framework that has already been used to estimate ATEs and linear regression functionals more generally. As a result, the extensive theoretical analyses of Riesz regression already apply to this method and the resulting estimator, e.g., from these works:\n\nhttps://arxiv.org/pdf/2104.14737\nhttps://arxiv.org/pdf/1809.05224\nhttps://arxiv.org/pdf/2110.03031\n\n#4 is discussed in this paper (e.g., Section 2.2):\n\nhttps://arxiv.org/pdf/2304.14545\n\nFinally, while #3 may be novel, the authors don't make a compelling case for why it's worth optimizing a Bregman divergence instead of just an L2 divergence. Making such a case is important since, when Cauchy-Schwarz is applied to the von Mises expansion, the L2 distance between the estimated and true Riesz representer emerges naturally in an upper bound. Hence, clearly making the L2 distance small will also reduce the bias. A clear case would be needed to explain why some other Bregman divergence would be preferred. While making such contributions would be an interesting direction for improvement, I'm skeptical that the improvement to the manuscript would be sufficient to outweigh my other novelty concerns."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "t6FzkJfRl4", "forum": "mPrnJcEhGR", "replyto": "mPrnJcEhGR", "signatures": ["ICLR.cc/2026/Conference/Submission3393/Reviewer_ZxhR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3393/Reviewer_ZxhR"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3393/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761390395673, "cdate": 1761390395673, "tmdate": 1762916702634, "mdate": 1762916702634, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "For all reviewers"}, "comment": {"value": "Thank you to all reviewers. Reflecting the comments, we updated the draft. In addition, after the submission to ICLR, we have further found a profound relationship between our direct bias-correction term estimation method and other existing methods, such as Riesz regression and covariate balancing weights. We also include these findings.\n\n## 1. Our contributions\nWe restate our contents, contributions, and findings as follows:\n1. We consider estimating the bias-correction term, which is also called the Riesz representer in the automatic debiased machine learning literature and the clever covariates in the targeted maximum likelihood estimation literature. \n2. We propose a general framework based on Bregman divergence minimization, which depends on a convex function $g$. By specifying the function $g$, we can obtain various loss functions. For example, if we set $g$ as a squared loss, we can obtain Riesz regression. If we set $g$ as a KL divergence, we can obtain the tailored loss.\n    2.1 We find that Riesz regression in Chernozhukov et al. (2021) is the same as LSIF (Kanamori et al. 2009) in density ratio estimation (DRE). \n    2.2 We also find that the tailored loss in Zhao (2019) is the same as KLIEP in DRE.\n3. If we use linear models for the bias-correction term and train the model via squared loss (Riesz regression), the trained bias-correction term automatically has the covariate balancing property for the basis function. If we model the bias-correction term using the propensity score with logistic models and train the model via KL divergence loss (tailored loss), the trained bias-correction term automatically has the covariate balancing property for the basis function.\n\n- Victor Chernozhukov, Whitney K. Newey, Victor Quintas-Martinez, and Vasilis Syrgkanis. Automatic debiased machine learning via Riesz regression, 2021. arXiv:2104.14737.\n- Takafumi Kanamori, Shohei Hido, and Masashi Sugiyama. A least-squares approach to direct importance estimation. Journal of Machine Learning Research, 10(Jul.):1391–1445, 2009.\n- Masashi Sugiyama, Taiji Suzuki, Shinichi Nakajima, Hisashi Kashima, Paul von Bunau, and Motoaki Kawanabe. Direct importance estimation for covariate shift adaptation. Annals of the Institute of Statistical Mathematics, 60(4):699–746, 2008.\n- Qingyuan Zhao. Covariate balancing propensity score by tailored loss functions. The Annals of Statistics, 47(2):965–993, 2019.\n\n\n\nOur findings further emphasize the following points from the above points.\n\n### 1.1. Model-loss relationship\nWe newly added the point (3), ``model-loss'' relationships, as our new findings. These findings have been shown separately in different literature. For example, Bruns-Smith et al. (2025) shows the duality relationship between Riesz regression and stable balancing weights. Zhao (2019) shows the duality relationship between tailored loss minimization and entropy balancing weights. We find that these results can be unified from the viewpoint of Bregman divergence minimization. \n\n- David Bruns-Smith, Oliver Dukes, Avi Feller, and Elizabeth L Ogburn. Augmented balancing weights as linear regression. Journal of the Royal Statistical Society Series B: Statistical Methodology, 2025.\n\n### 1.2 Riesz regression is a reinvention of LSIF for density-ratio estimation\n- Although the introduction is a bit different, Riesz regression uses the same objective, derivation steps, and motivation as those in LSIF proposed in Kanamori et al. (2009) for direct density ratio estimation. \n- We can find that nearest neighbor (NN) matching is a variant of Riesz regression, by extending the finding in ..., which reports that NN matching is density ratio estimation.\n- We can use various results shown for LSIF, such as convergence rates and regularization techniques. For RKHS, .... For neural networks, ...\n\n## 2. Revision\nWe revised the following points:\n- We added the model-loss relationship section (Section 3 AUTOMATIC COVARIATE BALANCING).\n- We added an explanation that our result unifies the existing literature in the sense that\n    - Riesz regression and tailored loss are both special cases of Bregman divergence minimization.\n    - The dual problem of squared loss based Bregman divergence minimization is the stable balancing weights, while that of KL divergence based Bregman divergence minimization is the entropy balancing weights.\n\nIn the next revision, we will add additional experimental results using semi-synthetic data.\n\n\n## 3, Replies to the reviewers \nWe firstly send more detailed replies to Reviewer E3JL and Reviewer ZxhR. We will send more detailed replies to Reviewer RVai and Reviewer XcMg after finishing an additional experiment."}}, "id": "HBeuAQSCPq", "forum": "mPrnJcEhGR", "replyto": "mPrnJcEhGR", "signatures": ["ICLR.cc/2026/Conference/Submission3393/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3393/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3393/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763371052258, "cdate": 1763371052258, "tmdate": 1763384269436, "mdate": 1763384269436, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel approach to estimating the Average Treatment Effect (ATE) by directly estimating the bias-correction term $h_0$, based on the key insight that the objective function can be reformulated without requiring prior knowledge of the true $h_0$​. The authors first present a basic least squares formulation and then extend the method using Bregman divergence minimization. This general framework unifies and broadens existing approaches such as Riesz regression and covariate balancing."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper proposes a general framework for directly minimizing the error between the true bias-correction term $h_0$​ and its estimate $\\hat h$, and establishes connections to several existing estimators, including Riesz regression and covariate balancing methods."}, "weaknesses": {"value": "1. Although the paper emphasizes that the goal is not to estimate the function $r$ directly, the theoretical analysis still appears to rely on its convergence. In particular, the root-n convergence of the ATE estimator is established through the joint convergence of both $r$ and the outcome model $\\mu$, following the standard ATE analysis framework.  Since $h_0$ is directly estimated, I am wondering if there are theoretical advantages that can be demonstrated? For example, in the covariate balancing paper \"Kernel-based Covariate Functional Balancing for Observational Studies\", it can be shown that root-n convergence for ATE is achieved without any modeling assumptions on the weights and without requiring estimation of the regression function.\n\n2. For the comparison with other ATE estimators, it would be beneficial to include a broader set of benchmarks, such as augmented covariate balancing estimators and various weighted estimators commonly used for ATE. Additionally, presenting inference results—such as coverage probabilities of confidence intervals—would strengthen the empirical evaluation. Finally, incorporating a real data application would provide valuable insight into the practical performance and robustness of the proposed estimator."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A."}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "x90MpnxrUQ", "forum": "mPrnJcEhGR", "replyto": "mPrnJcEhGR", "signatures": ["ICLR.cc/2026/Conference/Submission3393/Reviewer_RVai"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3393/Reviewer_RVai"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3393/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761667267565, "cdate": 1761667267565, "tmdate": 1762916702399, "mdate": 1762916702399, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the estimation of the average treatment effect (ATE) in observational studies. Instead of using the standard approach which estimates the propensity score and then inverts it, the authors propose to estimate the inverse of the propensity score directly. They develop an estimator under this framework and analyze its theoretical properties."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper tackles an important and classical problem in causal inference -- ATE estimation under confounding.\n\nThe authors provide a theoretical analysis of their proposed estimator, which adds rigor to their contribution."}, "weaknesses": {"value": "The core idea appears to overlap substantially with the extensive literature on balancing weights, which already focuses on constructing weights that directly achieve covariate balance without explicitly estimating the propensity score. Relevant prior works include Imai & Ratkovic (2014), Zubizarreta (2015), Chan et al. (2016), Zhao & Percival (2016), Fan et al. (2016), Wong & Chan (2018), Zhao (2019), and Wang & Zubizarreta (2020). The paper does not clearly distinguish itself from these studies or state what is fundamentally new.\n\nEstimating the inverse propensity score remains an intermediate step toward estimating the treatment effect. It is not evident what benefit is gained from focusing on this quantity rather than directly estimating the treatment effect.\n\nThe authors do not adequately discuss how their method compares in performance or robustness to existing approaches, particularly under nonsmooth or misspecified settings, where other methods (e.g., Robins et al., 2008, 2009, 2017; Yu & Wang, 2024) have explored efficiency improvements."}, "questions": {"value": "How does the proposed method differ conceptually and practically from balancing-weight approaches such as entropy balancing or covariate balancing propensity scores?\n\nWhat is the main benefit (either theoretical or empirical) of estimating the inverse of the propensity score directly rather than estimating the treatment effect directly?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WJe55ODtM7", "forum": "mPrnJcEhGR", "replyto": "mPrnJcEhGR", "signatures": ["ICLR.cc/2026/Conference/Submission3393/Reviewer_E3JL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3393/Reviewer_E3JL"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3393/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761791410796, "cdate": 1761791410796, "tmdate": 1762916702134, "mdate": 1762916702134, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a novel framework for direct bias-correction term estimation in the context of average treatment effect (ATE) estimation. Instead of estimating the propensity score as an intermediate step, the authors directly target the bias-correction term $h_0(D, X)$, which appears in inverseprobability weighting (IPW) and doubly robust (AIPW) estimators.\nThe paper shows that this term can be estimated without knowing the true propensity score by minimizing an equivalent empirical risk, inspired by direct density-ratio estimation (DRE). The authors provide theoretical guarantees under linear, RKHS, and neural network settings, demonstrate asymptotic normality for AIPW estimators incorporating their method, and extend the framework using Bregman divergence minimization, unifying existing approaches such as Riesz regression and covariate balancing.\nSimulation studies compare the proposed method with Logistic regression, CBPS, and RieszNet, showing comparable or superior ATE estimation accuracy in moderate-dimensional settings."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1. Conceptual originality: The direct estimation of the bias-correction term without explicit propensity score estimation is novel and appealing, consistent with the Vapnik principle.\n2. Solid theoretical backing: Provides consistency and asymptotic normality results under multiple model classes (linear, RKHS, neural networks).\n3. Unified framework: The generalization via Bregman divergence elegantly connects DRE, Riesz regression, and covariate balancing.\n4. Empirical validation: The proposed approach achieves competitive ATE estimation accuracy relative to existing methods, confirming its practical viability.\n5. Clarity and completeness: The proofs and references are comprehensive, and the relation to prior work is clearly articulated."}, "weaknesses": {"value": "1. Limited empirical scope: Experiments are restricted to synthetic data. Evaluation on semi-synthetic or real-world causal inference datasets (e.g., IHDP, ACIC) would strengthen the empirical claims.\n2. Marginal practical improvement: While theoretically elegant, the empirical gains over existing baselines such as CBPS or RieszNet are small.\n3. Computational considerations: The method's scalability and hyperparameter sensitivity (e.g., regularization in RKHS or neural networks) are not discussed.\n4. Clarity on assumptions: Some theoretical results assume boundedness or Donsker class conditions that may not hold for modern deep models; discussion of these limitations could be expanded.\n5. Connection to efficiency: Although asymptotic efficiency is claimed, empirical efficiency gains are not clearly demonstrated."}, "questions": {"value": "Please refer to the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Zn7nCgzSnb", "forum": "mPrnJcEhGR", "replyto": "mPrnJcEhGR", "signatures": ["ICLR.cc/2026/Conference/Submission3393/Reviewer_XcMg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3393/Reviewer_XcMg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3393/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761919859920, "cdate": 1761919859920, "tmdate": 1762916701738, "mdate": 1762916701738, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}