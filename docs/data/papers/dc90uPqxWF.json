{"id": "dc90uPqxWF", "number": 3885, "cdate": 1757560823532, "mdate": 1759898064541, "content": {"title": "World2Minecraft: Occupancy-Driven simulated scenes Construction", "abstract": "Embodied intelligence requires high-fidelity simulation environments to support perception and decision-making, yet existing platforms often suffer from data contamination and limited flexibility. To mitigate this, we propose World2Minecraft to convert real-world scenes into structured Minecraft environments based on 3D semantic occupancy prediction. In the reconstructed scenes, we can effortlessly perform downstream tasks such as Vision-Language Navigation(VLN). However, we observe that reconstruction quality heavily depends on accurate occupancy prediction, which remains limited by data scarcity and poor generalization in existing models. We introduce a low-cost, automated, and scalable data acquisition pipeline for creating customized occupancy datasets, and demonstrate its effectiveness through MinecraftOcc, a large-scale dataset featuring 100,165 images from 156 richly detailed indoor scenes. Extensive experiments show that our dataset provides a critical complement to existing datasets and poses a significant challenge to current SOTA methods. These findings contribute to improving occupancy prediction and highlight the value of World2Minecraft in providing a customizable and editable platform for personalized embodied AI research. We will publicly release the dataset and the complete generation framework to ensure reproducibility and encourage future work.", "tldr": "", "keywords": ["Embodied AI; World2Minecraft; 3D Semantic Occupancy Prediction; MinecraftOcc Dataset; Vision-Language Navigation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/96711eb1c1a262c206638729e9076e5e716102ec.pdf", "supplementary_material": "/attachment/b09d13ef6ea4780893ae06b4ca1d34083f52a8e7.zip"}, "replies": [{"content": {"summary": {"value": "This paper introduces **World2Minecraft**, a framework for converting real-world scenes into Minecraft environments using 3D semantic occupancy prediction. Based on the reconstructed scenes, this paper also presents two datasets: **MinecraftOcc**, a large-scale benchmark for indoor 3D occupancy prediction, and **MinecraftVLN**, designed for Vision-Language Navigation tasks. Experiments demonstrate the framework’s scalability and effectiveness in improving model performance and enabling embodied AI research in editable virtual environments."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well-written, with clear and intuitive figures that make the dataset construction process easy to understand."}, "weaknesses": {"value": "1. The use of occupancy as an intermediate representation for real-to-sim scene reconstruction raises some questions. According to the paper, occupancy is not directly used to reconstruct Minecraft scenes but instead to identify object instance centers for reconstruction. Does this suggest that object instance or room layout information alone is sufficient for scene reconstruction? Why not use these representations directly, considering they are potentially easier to obtain than occupancy labels?  \n\n2. Based on the results in Table 5, adding **MinecraftOcc** training data only provides a marginal improvement in model performance (mIoU +0.21). This raises concerns about the actual impact of **MinecraftOcc** in improving current occupancy prediction models or supplementing existing datasets.  \n\n3. The paper lacks experiments demonstrating the contribution of the **MinecraftVLN** dataset to existing visual navigation models or its ability to complement existing datasets. Additional experiments are recommended to show that **MinecraftVLN** can improve the performance of current visual navigation models."}, "questions": {"value": "See weaknesses. If these concerns are clarified with solid results, I would be happy to increase my score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "i6BI36hLVt", "forum": "dc90uPqxWF", "replyto": "dc90uPqxWF", "signatures": ["ICLR.cc/2026/Conference/Submission3885/Reviewer_X8ju"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3885/Reviewer_X8ju"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3885/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761474369656, "cdate": 1761474369656, "tmdate": 1762917082663, "mdate": 1762917082663, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on transforming real-world scenarios into Minecraft structured environments, attempting to address issues such as data pollution and insufficient flexibility in embodied intelligent simulation platforms. \n\nThis paper proposes a new VLN method **MinecraftVLN** that enables the agent to complete navigation tasks in the reconstructed scene.\n\nThis paper also proposes a large-scale dataset **MinecraftOcc** to benefit the entire community."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "**The research question is important**: Existing simulation platforms (Habitat and AI2-THOR) are not editable, necessitating a real-to-sim approach. However, existing real-to-sim approaches lack physical properties and cannot be applied to downstream tasks. Therefore, the authors propose a solution based on 3D semantic occupancy prediction.\n\n**Constructed two large datasets**: Data collection is a very tedious task. The authors proposes a low-cost collection pipeline to generate a large number of images, indoor scenes, and navigation samples. These have contributed to the community and navigation tasks, alleviating the previous problem of insufficient data."}, "weaknesses": {"value": "**The method lacks innovation**: The \"World2Minecraft framework\" proposed in the article is essentially a patchwork of the \"single-view 3D semantic occupancy prediction → multi-view fusion → Minecraft command generation\" pipeline, with no groundbreaking design in any of the steps. The entire process lacks original technical support and is more like an \"assembly experiment\" of existing tools. The authors fail to explain the core issues of this pipeline, why previous researchers haven't developed this pipeline, whether the simple assembly of such a pipeline is directly applicable, whether additional problems were encountered during the process, and how the authors propose carefully designed modules to address these issues. I don't see a research-based process, but rather a collection of engineering pieces.\n\n**The dataset's value may be limited**: I greatly appreciate the authors' meticulous effort in designing and collecting datasets for the benefit of the community and research. However, there are some concerns. The MinecraftOcc dataset has 156 scenes. While it contains \"approximately 1,000 rooms,\" it doesn't specify the diversity between scenes (e.g., whether there is overlap in room layout, furniture layout, or lighting conditions), making its value in testing model generalization capabilities unproven.\n\n**The introduction is poorly written**: When discussing the \"flaws of existing methods,\" it first criticizes the \"uneditability\" of Habitat and AI2-THOR, then mentions the \"lack of physical properties\" of NeRF and 3D Gaussian splatting, and finally turns to semantic occupancy prediction methods. This leads to a logical jump and a failure to form a coherent chain of argumentation.\n\n**The results are not very impressive**: The outcomes shown in Figure 4, Table 2, and Table 4 are not very impressive, and I did not perceive the advantages of the method and dataset proposed by the authors."}, "questions": {"value": "Could the authors provide a detailed explanation of the core research question? What challenges did you encounter while addressing this issue that resulted in the final pipeline? I do not perceive the uniqueness of World2Minecraft, nor do I see any significant insights here.\n\nAdditionally, do the authors have better experimental results? In my opinion, the current experimental outcomes do not convincingly demonstrate the advantages of your method and dataset."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "E6LHTG6P2c", "forum": "dc90uPqxWF", "replyto": "dc90uPqxWF", "signatures": ["ICLR.cc/2026/Conference/Submission3885/Reviewer_Nuc5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3885/Reviewer_Nuc5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3885/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761640567925, "cdate": 1761640567925, "tmdate": 1762917082398, "mdate": 1762917082398, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces World2Minecraft, a pipeline to convert real-world scenes into editable Minecraft environments for embodied AI research using 3D semantic occupancy prediction. The authors find this process is limited by the poor quality of current occupancy models. To address this, they present MinecraftOcc, a large-scale, automatically generated dataset from 156 photorealistic, modded Minecraft scenes (100,165 images) to serve as a challenging benchmark and training resource. Experiments show MinecraftOcc exposes the generalization limits of SOTA models and improves their performance on real-world data (NYUv2) when used for joint training. The utility of the end-to-end pipeline is also shown via a new MinecraftVLN dataset created from the reconstructed scenes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The World2Minecraft framework is a clever solution for creating editable, high-fidelity simulation environments, bridging the gap between static real-world scans and blocky, low-fidelity simulators.\n\n2. The MinecraftOcc dataset is a significant contribution, providing a large-scale (100k+ images), high-resolution, and perfectly-annotated data source for training and benchmarking 3D semantic occupancy models.\n\n3. The paper effectively demonstrates MinecraftOcc's value. SOTA models perform poorly on it, highlighting generalization gaps , while joint training with it improves performance on real-world data (NYUv2).\n\n4. The authors validate the full pipeline by creating a MinecraftVLN dataset from the reconstructed scenes and successfully training SFT/RFT agents for navigation tasks ."}, "weaknesses": {"value": "1. The World2Minecraft pipeline is not fully automated; its initial outputs were \"suboptimal\" and required \"meticulous manual refinement\" to be usable for the VLN dataset, undermining its scalability claims.\n\n2. The paper has two loosely connected parts: the World2Minecraft (real-to-sim) pipeline and the MinecraftOcc (sim-for-training) dataset. The dataset is not generated from the pipeline, which makes the overall story less cohesive.\n\n3. The \"Base\" MinecraftVLN dataset derived from the pipeline is small (15 scenes) with \"simple instructions\". The authors had to add 5 external community-built maps to achieve sufficient complexity.\n\n4. The mapping of 1,452 mod-specific classes to 13 standard classes for cross-dataset experiments is coarse and potentially noisy (e.g., \"curtains\" and \"lights\" are mapped to \"empty\"), which could confound the joint-training results."}, "questions": {"value": "1. Can you quantify the \"meticulous manual refinement\" required for the 15 scenes? How does this manual bottleneck affect the scalability of the World2Minecraft pipeline?\n\n2. Have you considered closing the loop: using World2Minecraft to reconstruct a real-world scene, and then using that reconstructed scene as input for your MinecraftOcc automated data generation pipeline?\n\n3. How do you ensure the coarse 1,452-to-13 class mapping (e.g., \"curtains\" to \"empty\") doesn't introduce significant label noise that negatively impacts model training and evaluation?\n\n4. How do you disentangle the models' poor performance on MinecraftOcc (Table 4) between a true \"generalization failure\" and a simple \"domain gap\" (i.e., real-world models performing badly on Minecraft's specific visual style)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HpCgq2FuHE", "forum": "dc90uPqxWF", "replyto": "dc90uPqxWF", "signatures": ["ICLR.cc/2026/Conference/Submission3885/Reviewer_7kuq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3885/Reviewer_7kuq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3885/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761833295162, "cdate": 1761833295162, "tmdate": 1762917082193, "mdate": 1762917082193, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a real-to-simulation framework, World2Minecraft, which converts real-world observations into a Minecraft environment through semantic occupancy prediction. The authors further utilize the constructed Minecraft scenes to generate samples for vision-language navigation and additional data for training semantic occupancy prediction models. Experimental results show that this augmentation strategy holds potential to enhance task performance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* Leveraging simulation to augment real-world task performance through real-to-sim techniques is a promising direction. \n* Developing an automated real-to-sim pipeline is highly valuable."}, "weaknesses": {"value": "* Unclear real-to-sim pipeline： The process of converting real scenes into Minecraft is insufficiently detailed. It is unclear how furnitures are selected, how their poses are estimated, how occlusions are handled, and how the approach compares to existing real-to-sim methods. This raises doubts about how automated the proposed pipeline truly is.\n* If the pipeline relies on an existing furniture set (e.g., MOD assets), the method becomes similar to prior real-to-sim approaches that depend on existing object set. It is not obvious why constructing the environment specifically in Minecraft provides clear advantages. Additionally, the physics in Minecraft appears irrelevant for the presented tasks.\n* Manual refinements reduce practicality: For the VLN task, the authors mention manually refining 15 environments due to data quality issues, but do not detail the required operations or effort. This raises concerns about scalability. Furthermore, if data quality is limited, it is unclear whether using all constructed scenes benefits the semantic occupancy task—does every scene require manual refinement as well?"}, "questions": {"value": "* Task-specific scene usage: Why are only 15 manually refined scenes used for the VLN task, while all constructed scenes are utilized for semantic occupancy prediction? What specific refinements are required for VLN, and why are they unnecessary for occupancy prediction?\n* Scope of reconstruction: Since furniture assets come from an existing asset set, does the proposed pipeline only reconstruct the structural layout of the environment? If so, what are the key advantages over prior real-to-sim frameworks that similarly rely on existing furniture databases?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "8CwAzYV8Xl", "forum": "dc90uPqxWF", "replyto": "dc90uPqxWF", "signatures": ["ICLR.cc/2026/Conference/Submission3885/Reviewer_HVMZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3885/Reviewer_HVMZ"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3885/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761938735827, "cdate": 1761938735827, "tmdate": 1762917081969, "mdate": 1762917081969, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}