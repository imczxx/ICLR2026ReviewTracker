{"id": "Gv2HOWWDGC", "number": 6956, "cdate": 1758003340942, "mdate": 1759897881769, "content": {"title": "FedEquilibria: Towards Fair and Robust Federated Learning under Domain Skew", "abstract": "Federated Learning (FL) has been widely emerged as a promising paradigm for decentralized machine learning. However, its practical effectiveness is hindered by domain skew, a prevalent form of data heterogeneity where clients hold statistically different data distributions. Existing studies have revealed that this failure is rooted in two fundamental problems: (1) update conflicts, arising when clients’ learning objectives diverge, and (2) model aggregation bias, where conventional aggregation schemes neglect domain diversity, systematically favoring certain clients over others. To tackle these intertwined challenges, we propose FedEquilibria, a novel and fair federated aggregation framework. The core idea of FedEquilibria is to employ a server-side hybrid weighting mechanism consisting of two synergistic steps. First, it formulates aggregation as a multi-objective optimization problem, uniquely leveraging the Fisher Information Matrix (FIM) as a proxy for each client’s empirical objective. By computing conflict-aware weights on the server-side, FedEquilibria identifies a Pareto-optimal consensus of parameters that are structurally important across different domains. Second, to counteract aggregation bias, FedEquilibria calculates drift-aware weights based on the Euclidean norm of client updates, explicitly quantifying the fitting gap for each client and adaptively increasing the influence of underrepresented domains. Comprehensive experiments on benchmark datasets with pronounced domain shifts demonstrate that FedEquilibria significantly surpasses existing state-of-the-art methods. It achieves not only higher average accuracy but also substantially enhances fairness by improving the performance of the worst-performing clients, offering a principled solution for robust and equitable models in real-world FL systems.", "tldr": "", "keywords": ["Federated Learning", "Fairness", "Domain Skew"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f74fe14853d584ceffa4313d3b1e0acc452d70e7.pdf", "supplementary_material": "/attachment/3bd6d588597bf7367c329211b3cb3c167775e52b.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes a novel federated model aggregation framework, FedEquilibria, designed to address a specific form of data heterogeneity (domain skew). Building upon prior work, the method aims to tackle two key remaining challenges in Federated Learning (FL) domain heterogeneity problesm: model update conflicts and aggregation bias. The empirical results demonstrate that the proposed mechanisms are effective in mitigating these issues. The paper clearly defines its research focus, and the proposed solutions are aligned with the identified challenges. However, several concerns and questions remain."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "-The paper jointly optimizes accuracy and fairness, which provides a more comprehensive evaluation objective compared to prior works that focus solely on average client performance. This dual-objective formulation better reflects the real-world requirements of FL systems, where both global performance and equitable client outcomes are important.\n\n-The paper presents a well-defined problem formulation, effectively casting the task as a multi-objective optimization problem within a quadratic programming framework.\n\n-The paper proposes a new mechanism to mitigate bias in the model aggregation process, which introduces a weighting strategy based on the update drift between local models and the updated global model. This is a promising and intuitive approach that provides a meaningful perspective on how to achieve unbiased aggregation when domain heterogeneity appears."}, "weaknesses": {"value": "-Although the authors claim that one of their main contributions lies in the use of the Fisher Information Matrix (FIM) in a federated setting, this aspect appears insufficiently justified. The paper applies the FIM directly without clear adaptation or modification to address the domain skew problem specifically. Moreover, several prior works [1, 2, 3] have already explored the use of Fisher Information in FL. While those works may not explicitly target domain skew, they similarly employ the FIM to quantify parameter importance or client-level information, suggesting that the proposed usage here may be an incremental extension rather than a fundamentally new idea.\n\n[1] Dynamic Personalized Federated Learning with Adaptive Differential Privacy (NeruIPS 2023)\n\n[2] Seizing Critical Learning Periods in Federated Learning (AAAI 2022)\n\n[3] Fisher Calibration for Backdoor-Robust Heterogeneous Federated Learning (ECCV 2024)\n\n-The experimental evaluation is not solid enough. Many of the chosen baseline methods, such as FedProx and MOON, were not originally designed to handle domain skew problems, making the comparison less convincing. In particular, the paper lacks comparisons with methods that partially personalize model parameters, which are more relevant to the targeted problem setting. There exist several FL approaches specifically designed to address domain skew, and these should be included to provide a fair and comprehensive evaluation of the proposed method’s effectiveness in main experiments.\n\nFedBN: Federated Learning on Non-IID Features via Local Batch Normalization (ICLR 2021)\n\nFed-CO2: Cooperation of Online and Offline Models for Severe Data Heterogeneity in Federated Learning (NeurIPS 2023)\n\nFederated Learning with Domain Shift Eraser (CVPR 2025)"}, "questions": {"value": "-It is unclear why classic FL methods (e.g., FedAvg, FedProx, MOON) achieve very similar performance to methods specifically designed to address heterogeneity issues, such as FedHEAL and FedLSA, particularly in the average performance results reported in Tables 1 and 2. For instance, FedLSA outperforms FedAvg by only about 1 percent, which seems unexpectedly small given its intended design. \n\n-What if there are more clients? Most existing studies on domain skew are limited to settings with only a few clients, whereas research on label heterogeneity typically evaluates scenarios with 20, 50, or even 100 clients. In real-world applications, it is highly likely that there will be many more clients, and that multiple clients may belong to the same domain. It remains unclear how the proposed method would perform under such conditions. An additional experiment exploring this scalability aspect would significantly strengthen the work."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zmrDVbR2ln", "forum": "Gv2HOWWDGC", "replyto": "Gv2HOWWDGC", "signatures": ["ICLR.cc/2026/Conference/Submission6956/Reviewer_Nef3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6956/Reviewer_Nef3"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6956/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761631983438, "cdate": 1761631983438, "tmdate": 1762919181979, "mdate": 1762919181979, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FedEquilibria, a federated learning framework aimed at fair performance under domain skew. In addition to model updates, each client sends a diagonal Fisher information vector as a parameter-importance summary. The server then computes aggregation weights via a quadratic program in Fisher space (to reconcile client conflicts) and a drift-aware term proportional to ($||\\Delta_k||_2^2$). On small vision benchmarks (Digits, Office-Caltech, PACS), the method reports higher worst-client accuracy and lower inter-client variance than several baselines."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The framework adds Fisher-based and drift-aware weights on top of FedAvg, and is easy to plug into existing FL pipelines.\n- Empirically, It shows consistent gains in MIN (worst-client accuracy) and reduced STD across several domain-shift benchmarks.\n- Ablations are provided to isolate the contributions of Fisher weighting and drift-aware reweighting."}, "weaknesses": {"value": "- Theory/motivation of Eq. (1) is unclear.\nThe objective “minimize the norm of the weighted sum of client Fisher vectors” (Eq. 1) has no evident linkage to minimizing any client risk or to a principled fairness criterion. Moreover, shrinking aggregate Fisher magnitudes can reduce parameter identifiability, which may harm accuracy/fairness. Please justify why this proxy yields a Pareto-stationary solution for per-client risks and provide a formal connection between this objective and fairness.\n\n- “Multi-objective optimization” claim is unsubstantiated.\nThe paper frames the QP as MOO, yet only a single proxy in Fisher space is minimized. What are the actual objectives​ per client? If so, demonstrate that the solution is Pareto-optimal/stationary for those objectives, not just for the Fisher proxy.\n\n- Insufficient Fisher details (empirical, diagonal).\nThe method appears to use diagonal empirical Fisher. Please specify: (i) how per-sample gradients are obtained; (ii) batch size used for Fisher estimation; (iii) update frequency (every round vs. EMA/subsampling); and (iv) any normalization or stabilization strategies.\n\n- Compute/communication overhead not quantified.\nReport client-side FLOPs, wall-clock overhead, memory for per-sample grads, and uplink bytes/round for transmitting \nplus the FIM vector, compared with FedAvg and other baselines.\n\n- Scalability is untested.\nResults are limited to small CNN/ResNet backbones on modest datasets. It remains unclear whether the approach scales to larger models (e.g., ResNet-50/ViT) under partial participation and realistic bandwidth limits. Please add larger-scale experiments and Fisher compression strategies.\n\n- Missing comparisons to the most relevant baselines.\nGradient-space MOO aggregation methods are the closest prior art (mentioned in L234–235) yet are not compared head-to-head. Include identical-protocol comparisons and discuss when a Fisher-space consensus is preferable to gradient-space MOO.\n\n- Privacy considerations omitted.\nEven diagonal Fisher vectors can leak label-distribution or gradient information. Please discuss risks and possible mitigations (e.g., quantization, clipping, DP noise)."}, "questions": {"value": "1. What exactly do clients compute to get $F_k$? Per-sample gradients with squared averaging? Any subsampling or layer-wise blocks? Please detail compute/latency overhead on clients.\n2. Does the proposed method normalize the drift-aware weights by data size and local steps to discount scale effects?\n3. In line 215, Fisher Information matrix should be element-wise equivalent to the expectation of the second derivative of the nll-loss, not just diagonal?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7tYJCIMYUg", "forum": "Gv2HOWWDGC", "replyto": "Gv2HOWWDGC", "signatures": ["ICLR.cc/2026/Conference/Submission6956/Reviewer_MDPi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6956/Reviewer_MDPi"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6956/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896670159, "cdate": 1761896670159, "tmdate": 1762919181428, "mdate": 1762919181428, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes, FedEquilibria, a federated learning framework designed to ensure fairness and robustness when client data distributions differ significantly. Using conflict-aware aggregation, e.g., Fisher Information Matrix to harmonize updates across domains, and drift-aware weighting, FedEquilibria achieves balanced model performance and minimizes disparities among clients. Experiments on diverse benchmarks show that it outperforms existing methods in both accuracy and fairness."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "+) This paper discussed an important topic about fairness in FLs\n\n+) Detailed experiments showed the effectiveness of the proposed method"}, "weaknesses": {"value": "-) Computational overhead when scaled as the number of clients/model size may become significant\n\n-) Though many experiments are performed, most of them were using small model on small-scale datasets"}, "questions": {"value": "a) The design choice of FIM is a bit arbitrary to me. I understand it may provide a more rigorous theoretical results, but empirically how does it compare to other alternatives?\n\nb) How much overhead does it introduce when the scale of the clients/model size increased?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "X5dPzqRH4x", "forum": "Gv2HOWWDGC", "replyto": "Gv2HOWWDGC", "signatures": ["ICLR.cc/2026/Conference/Submission6956/Reviewer_hWtx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6956/Reviewer_hWtx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6956/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762066613108, "cdate": 1762066613108, "tmdate": 1762919180931, "mdate": 1762919180931, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}