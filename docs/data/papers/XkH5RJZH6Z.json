{"id": "XkH5RJZH6Z", "number": 2760, "cdate": 1757241258721, "mdate": 1762969533152, "content": {"title": "DDTNet: Degradation Disentanglement and Transfer Network for Domain-Adaptive All-in-One Image De-weathering", "abstract": "All-in-one adverse weather image restoration aims to remove multiple degradations, such as rain, haze, and snow, using a single model. Despite their broad applicability, existing methods typically compromise performance, delivering balanced rather than optimal results for individual degradations due to their multi-task nature. Moreover, they often suffer from a significant performance drop when a domain gap exists between training and testing data. To address these challenges, we propose the Degradation Disentanglement and Transfer Network (DDTNet), which carries out domain adaptation for all-in-one models. Since paired degraded-clean images are unavailable at inference, DDTNet disentangles and transfers degradation patterns from target-domain degraded images to source-domain clean images, generating domain-adaptive pairs for fine-tuning and improving target-specific restoration. The core of DDTNet is the Degradation Disentanglement Module (DDM), which consists of Degradation Coupled Attention (DCA) to capture both general and weather-specific features, enabling effective disentanglement and transfer of degradation patterns. Experimental results demonstrate that DDTNet significantly improves existing all-in-one models across real-world deraining, desnowing, and dehazing datasets.", "tldr": "", "keywords": ["Domain Adaptation", "Image Restoration"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/245ea66b938bdd38ec8bcf8c7998efe65dd86e94.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "DDTNet is a domain-adaptive all-in-one de-weathering framework that uses a Degradation Disentanglement Module (DDM) with two-stage Degradation-Coupled Attention (DCA) to disentangle weather patterns from a target degraded image and transfer them onto a source clean image, thereby synthesizing domain-adaptive paired data for fine-tuning arbitrary restoration models."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1.  Proposes a plug-and-play unpaired adaptation framework (DDTNet). The two-stage DCA explicitly separates content/degradation at the feature level and transfers target-domain degradations to source clean images to form fine-tuning pairs. The design is easy to integrate with existing all-in-one models.\n2. Shows consistent gains on real/mixed weather conditions."}, "weaknesses": {"value": "1.\tLimited baselines & scope. The compared experiment is very limited, lacking prior domain adaptation approaches, unsupervised restoration methods, and representative supervised methods.\n2.\tNo qualitative comparison vs Noise-DA. While quantitative results are provided, no visual comparisons are shown to illustrate behavioral differences.\n3.\tNo evaluation on few-shot robustness. Experiments implicitly assume access to the full target domain. It remains unclear how DDTNet performs with few target-domain degraded images or under stricter data limits.\n4.\tCausality of gains not isolated. Lacks a control with equal number of pseudo pairs but without the proposed method to verify that improvements are not primarily from data augmentation alone.\n5.\tPresentation quality. The paper’s presentation is weak (low information density); visual comparisons serving the same purpose are scattered across multiple figures, hindering readability."}, "questions": {"value": "Please refer to the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BFEjjxCpdy", "forum": "XkH5RJZH6Z", "replyto": "XkH5RJZH6Z", "signatures": ["ICLR.cc/2026/Conference/Submission2760/Reviewer_fH61"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2760/Reviewer_fH61"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2760/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761289157887, "cdate": 1761289157887, "tmdate": 1762916363396, "mdate": 1762916363396, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "FLBKbOgMM5", "forum": "XkH5RJZH6Z", "replyto": "XkH5RJZH6Z", "signatures": ["ICLR.cc/2026/Conference/Submission2760/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2760/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762969532129, "cdate": 1762969532129, "tmdate": 1762969532129, "mdate": 1762969532129, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a domain adaptation model for all-weather restoration that produces degraded-clean image pairs containing the unknown degradation pattern present in the test image. Existing methods can then be fine-tuned on these pairs, enabling out-of-domain restoration. The proposed approach yields significant improvements in performance on unseen degradation patterns."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well written and easy to follow.\n2. The idea is straightforward and the proposed components are intuitive.\n3. DDTNet can be paired with any restoration network.\n4. Fine-tuning on DDTNet generated degraded images improves out-of-domain performance."}, "weaknesses": {"value": "1. Missing comparison with related work: [1] proposes a domain translation framework for multi-weather restoration which generates images under multiple weather conditions to extract content features. This work is quite similar and is not discussed or compared with.\n2. Lack of ablations to show whether degradations are actually disentangled: The authors claim to disentangle degradation from clean content using the DCA module. While $I_o$ has the degradation in $I_d$, it is unclear whether the degradation was disentangled from the content features during the transfer. To demonstrate this, can the authors plot t-SNE of $\\tilde{X}$ (Eqn. 6) for different degradations to show that they are separated? Additionally, a similar experiment can be performed for the outputs of the Content Encoder as well (in this case, I would not expect separation as content features would be clean).\n3. Can DDTNet work for unseen and mixed degradations? For instance, can it generate pairs for unseen and mixed degradations which enable better restoration performance in these scenarios (eg. on Raindrop [2] or CDD testsets [3])?\n4. Poor quality in qualitative results: In Fig. 6, the results for Snow and Haze seem to have many artifacts even after restoration using DDTNet. There is also a loss of structural detail compared to the ground truth. Is there any particular reason for this?\n\n[1] Patil, Prashant W., et al. \"Multi-weather image restoration via domain translation.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.\n\n[2] Qian, Rui, et al. \"Attentive generative adversarial network for raindrop removal from a single image.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.\n\n[3] Guo, Yu, et al. \"Onerestore: A universal restoration framework for composite degradation.\" European conference on computer vision. Cham: Springer Nature Switzerland, 2024."}, "questions": {"value": "1. In Fig. A2, how were the degradation features obtained?\n\nFor other questions see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "6eCXEx8Cnb", "forum": "XkH5RJZH6Z", "replyto": "XkH5RJZH6Z", "signatures": ["ICLR.cc/2026/Conference/Submission2760/Reviewer_wodN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2760/Reviewer_wodN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2760/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761519177021, "cdate": 1761519177021, "tmdate": 1762916363260, "mdate": 1762916363260, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DDTNet, a domain adaptation framework for all-in-one adverse weather image restoration. The method disentangles and transfers degradation patterns to generate domain-adaptive pairs, improving restoration under new conditions. Experiments show consistent gains on deraining, desnowing, and dehazing tasks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses a relevant problem in all-in-one image restoration and identifies domain gap issues that are indeed important for practical deployment.\n2. The overall paper is well organized, and the experimental results are presented in a clear and structured manner."}, "weaknesses": {"value": "1. The paper tackles both suboptimal cross-task performance and domain gaps, but it fails to clearly explain how these two issues are interconnected. The proposed solution addresses them separately, and it is unclear why they require a unified approach.\n2. The paper describes a two-stage attention mechanism, where the first stage uses degradation-sensing tokens to retrieve degradation features, and the second stage uses image tokens to aggregate information from the degradation tokens. However, the significance of introducing the second stage is unclear, as the degradation features are already captured in the first stage.\n3. Figure 5 only includes results from the proposed method. Since the paper claims to address the issues faced by prompt-based methods, particularly the suboptimal performance due to joint multi-task training, it would be more convincing to include comparisons with other prompt-based methods.\n4. The paper mentions that the joint multi-task training strategy often leads to suboptimal performance on individual tasks, with noticeable performance drops compared to single-task models. However, it is unclear how the proposed DDTNet effectively addresses this issue, as it still appears to follow a similar multi-task prompt-based approach. How DDTNet mitigates the typical challenges of multi-task learning, particularly the degradation in performance on individual tasks."}, "questions": {"value": "Please see above weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "6D69V4lWGH", "forum": "XkH5RJZH6Z", "replyto": "XkH5RJZH6Z", "signatures": ["ICLR.cc/2026/Conference/Submission2760/Reviewer_y9ct"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2760/Reviewer_y9ct"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2760/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761830269592, "cdate": 1761830269592, "tmdate": 1762916363102, "mdate": 1762916363102, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces DDTNet, a domain-adaptive all-in-one image de-weathering model that disentangles and transfers degradation patterns between domains. It designs a Degradation Disentanglement Module (DDM) using a two-stage Degradation-Coupled Attention (DCA) mechanism to separate content and degradation features. DDTNet transfers learned degradation tokens to generate pseudo-pairs for fine-tuning existing models (e.g., PromptIR, AdaIR) on real data. Experiments show improved performance and generalization on synthetic and real-world benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper introduces degradation disentanglement as a bridge for domain adaptation, which is interesting for multi-weather restoration. The two-stage DCA alternates between degradation- and image-focused attention.\n2. Comprehensive experiments show consistent gains across several backbones and datasets.\n3. Ablations and visualizations confirm that DDM and DCA improve both performance and interpretability.\n4. Clear pipeline diagrams and equations; module functions are well defined."}, "weaknesses": {"value": "1. Lacks a theoretical or analytical justification for the convergence or stability of the two-stage attention process. It remains unclear how DCA avoids information leakage between degradation and content streams.\n2. The model contains ~31 M parameters and 33 ms inference latency on 256×256 inputs, but no scaling study is provided for high-resolution (1–2 K) deployment. The fine-tuning step per domain adds computational cost not fully quantified.\n3. Although DDTNet claims domain adaptation benefits, no quantitative domain alignment metrics (e.g., FID, feature distance, or token separability) are reported beyond t-SNE visualization (Figure 5).\n4. Experiments are confined to weather degradations (rain, snow, haze). It remains uncertain whether the framework generalizes to other degradation domains (e.g., low-light, noise, blur).\n5. The baseline (Noise-DA) is primarily diffusion-based, while DDTNet is a transformer-style encoder–decoder. A direct comparison may conflate architecture effects with domain adaptation gains."}, "questions": {"value": "1. How stable are the learned degradation-sensing tokens across different domains or seeds? Could the authors visualize token attention maps or show cosine similarity distributions?\n2. If DDTNet is trained on rain/snow/haze, can it adapt to unseen degradation types (e.g., sandstorm, night haze) without retraining?\n3. Beyond t-SNE, can the authors report feature alignment metrics (FID, MMD, or KL divergence) to substantiate domain adaptation claims?\n4. How sensitive is performance to the number of fine-tuning epochs and data pairs? Could DDTNet support online adaptation (incremental updates)?\n5. The degradation-sensing token number (M = 256) seems empirically chosen. Have the authors tested smaller or adaptive token counts for lightweight deployment?\n6. If DDTNet is trained alongside PromptIR, can the same model be reused to fine-tune AdaIR without retraining DDTNet itself?\n7. Could the proposed degradation disentanglement be extended to combined low-level restoration (e.g., deblurring + denoising + dehazing)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "sdoh3bcZRv", "forum": "XkH5RJZH6Z", "replyto": "XkH5RJZH6Z", "signatures": ["ICLR.cc/2026/Conference/Submission2760/Reviewer_GpWn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2760/Reviewer_GpWn"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2760/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761901520999, "cdate": 1761901520999, "tmdate": 1762916362954, "mdate": 1762916362954, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}