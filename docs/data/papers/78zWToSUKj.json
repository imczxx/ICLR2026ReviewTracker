{"id": "78zWToSUKj", "number": 3816, "cdate": 1757533901440, "mdate": 1763627026021, "content": {"title": "LLMSynthor: Macro-Aligned Micro-Records Synthesis with Large Language Models", "abstract": "Macro-aligned micro-records are essential for simulations in social science and urban studies. For instance, epidemic models of urban disease spread are only credible when micro-level records reproduce realistic individual mobility and contact patterns, while macro-level aggregates match real-world statistics such as case counts or travel flows. Still, large-scale collection of such fine-grained data is impractical, leaving researchers with only macro-statistics (e.g., travel surveys or case counts). Large Language Models (LLMs), leveraging rich real-world priors learned from vast corpora, excel at generating realistic micro-records, but standard record-by-record sampling is inefficient and fails to enforce alignment with target macro-statistics. Given this, we propose LLMSynthor, a framework capable of synthesizing realistic micro-records that are statistically aligned with target macro-statistics. LLMSynthor transforms a pre-trained LLM into a macro-aware simulator that incrementally builds a synthetic dataset through an iterative process. At each iteration, a batch of micro-records is generated to reduce the discrepancy between synthetic and target macro-statistics. By treating the LLM as a nonparametric copula for inferring joint dependencies over variable combinations, the iterative process ensures the synthetic data are macro-statistically aligned with the target marginals and joints. To address sampling inefficiency, we introduce LLM Proposal Sampling, where the LLM, guided by discrepancies, generates a plan of proposals, each defining specific values or ranges for all variables and specifying the number of records to generate. This enables the framework to minimize discrepancies efficiently while preserving the realism grounded in the LLM’s priors. Evaluations on synthetic and real-world datasets (mobility, e-commerce, population) encompassing diverse formats and settings show that LLMSynthor achieves high record realism, statistical fidelity, and practical utility, positioning it broadly applicable across economics, social science, urban studies, and beyond.", "tldr": "", "keywords": ["Data Synthesis", "Urban Studies", "Social Simulation", "Large Language Model"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7fd90b540bf9285363bfb6379e01566007557c6b.pdf", "supplementary_material": "/attachment/7d4143db1286b80ffcf085af4142f6c9178807b2.zip"}, "replies": [{"content": {"summary": {"value": "This work aims to generate realistic individual-level records that follow pre-specified population-level statistics. Individual-level records are much harder to collect than population-level statistics, but are useful to expert practitioners in domains like public health or urban planning. The ability to simulate realistic data at the micro-level while following macro-level statistics would help bridge this gap.\n\nThe authors propose to tackle this problem by using an LLM to guide the generation of individual-level records while steering the generation based on the discrepancy with high-level statistics. To improve generation efficiency, they implement “generation plans” where the LLM doesn't generate records directly but instead creates joint distributions that can be sampled from efficiently.\n\nThe problem is interesting and well motivated, but the paper suffers from several flaws in its method, experimental validation and presentation."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The problem of micro-level generation following macro-level statistics is interesting\n- Efforts to improve and evaluate the practical downstream utility in the method (producing generation plans for faster records generation) and experimental results (prediction of derived variables using synthesised data) are appreciated."}, "weaknesses": {"value": "Major:\n\n- W1: the method relies heavily on the LLM for variable dependency inference and micro-level generation plans synthesis. This leads to several concerns in terms of realism, bias and auditability, detailed below.\n    - a. the realism of the generated records hinges on the LLM’s ability, but LLMs are notoriously prone to hallucinations. Furthermore, matching the macro-level statistics in aggregate does not guarantee data realism at the low-level. The realism of the generated low-level records should be thoroughly demonstrated experimentally, which is not the case currently (cf W4).\n    - b. LLM generation might introduce bias at both at the variable dependency inference stage (ie the model might group spuriously correlated variables) and micro-level generation stage levels (ie the actual joint distribution between selected variables). This is partly noted by the authors in the discussion (l.459-460), but should be acknowledged and discussed beyond the misalignment with target statistics.\n    - c. Auditability —ie providing practitioners information to understand how the micro-records were generated— is essential to mitigate the realism and bias pitfalls previously mentioned. This is not possible here since the micro-records are generated directly by the LLM (via the generation plans), which operates as a black-box.\n- W2: In Section 3.2, the authors state that “If an inferred dependency lacks corresponding data, practitioners are encouraged to collect additional statistics, if unavailable, the LLM can approximate the joint distribution using existing macro-statistics” (l.215). If I understand correctly this means that if the LLM proposes a variable subset that is not exactly available in the macro-statistics S_target, then the method doesn’t work unless the practitioners collect additional statistics. This is a major limitation for the practical applicability of the method. Meanwhile, the claim that LLM can approximate the joint distribution itself (l.215-216) is unsubstantiated.\n- W3: The discrepancy-guided iterative synthesis scheme (Section 3.3) means that generated low-level records are not i.i.d, since records from time t+1 depend on previously generated records at times ≤t (via the discrepancy signals \\Delta^t). I would expect that i.i.d data is a common assumption in low-level records —as noted by the authors l.464.\n- W4: A thorough evaluation of the realism of generated records is missing from the experimental results. Currently this is only briefly mentioned in Appendix C.3 and limited to illustrative examples. As mentioned in W1, the realism of the generated records is by no means guaranteed by the method and should therefore be extensively assessed experimentally. One way to evaluate this could be to use a dataset where ground-truth micro-level records are available, run the method based only on the macro-level statistics, and measure the similarity between ground-truth and generated low-level records distributions at various granularity levels (not just at the macro-level).\n- W5: In Section 4.2, the comparison to low-level generation baselines is unfair since only LLMSynthor has access to the macro-level statistics. A fairer comparison with these baselines would be in terms of the realism of the generated low-level records (cf W4). Fairer baselines for macro-level statistics alignment include direct prompting of the LLM (a form of ablation experiment on the proposed method, eg without discrepancy-guided iterative sampling), and simulator-based methods (eg [1]).\n- W6: Figure 1 and 2 are illegible. I had a lot of trouble following them even after getting a good grasp of the method from the text. I would recommend updating these figures to make them less cluttered and improving clarity.\n- W7: the related work section is missing simulator-based methods, such as [1], which are highly relevant to this problem. \n\nMinor:\n- The two definitions in Section 3 are informal. They could be made sharper by separating the core definition to discussion points around it.\n- Typos: problem in sentence l.200; missing period l.409\n\n[1]: Holt et al, “G-sim: Generative simulations with large language models and gradient-free calibration.” (ICML’2025)"}, "questions": {"value": "- l.216: “The aggregation operator is then updated..” - what does this update look like in practice?\n- What if variables in one of the c_k corresponds to a subset of a joint statistics available in the macro-records (eg macro records contain joint statistics over variables (x,y,z), but one c_k=(y,z))? Can we marginalise over the non-included variables?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aGnYXFOVsh", "forum": "78zWToSUKj", "replyto": "78zWToSUKj", "signatures": ["ICLR.cc/2026/Conference/Submission3816/Reviewer_Xt7k"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3816/Reviewer_Xt7k"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3816/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761749843840, "cdate": 1761749843840, "tmdate": 1762917049413, "mdate": 1762917049413, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response 3: Clarifying the Distinct Scope and Unique Capabilities of LLMSynthor"}, "comment": {"value": "We appreciate the reviewers’ detailed feedback. We notice that some concerns regarding baseline comparisons may stem from viewing LLMSynthor solely through the lens of traditional tabular synthesis. We would like to clarify that **LLMSynthor addresses a fundamentally broader and more challenging problem** scope than standard deep tabular generators.\n\n---\n\n# 1. LLMSynthor requires only macro-statistics, whereas all tabular baselines require full micro-records.\n\nDeep tabular generators (CTGAN, TVAE, GReaT, TabSyn, etc.) learn the entire joint distribution from thousands of micro-records. Their training objective is to reproduce the full data distribution, which implicitly includes every macro-statistic used in our evaluation. In contrast, LLMSynthor operates solely from aggregate-level information. It learns no micro-level distribution from data. That LLMSynthor can match or surpass these baselines despite accessing strictly less information is a strong validation of the framework.\n\n\n# 2. LLMSynthor naturally supports unstructured and hierarchical data, which tabular baseline models cannot handle.\nTabular generators are limited to fixed-dimensional tables and cannot generate hierarchical micro-structures such as households with variable-size member lists. LLMSynthor, leveraging proposal-level generation, handles structured, semi-structured, and unstructured records uniformly. Our household synthesis experiment demonstrates accurate generation of complex multi-entity records, something none of the baselines can model without significant efforts on adaptation.\n\n\n# 3. LLMSynthor supports event-level simulation with arbitrary context, without retraining.\nLLMSynthor can:\n- **condition on arbitrary new contexts** at generation time (e.g., policy shocks, hypothetical scenarios),\n- generate sequences of events rather than one-shot samples,\n- adapt to new domains without any retraining or fine-tuning.\nThis capability is completely absent in diffusion-, GAN-, or tabular-LLM models, which must be retrained from scratch whenever the generative conditions or target distributions change.\n\n\n# 4. A single unified framework handles all of the above.\n LLMSynthor provides a single mechanism, proposal-level conditional generation guided by macro discrepancies, that works across\n - pure tabular data\n - hierarchical population synthesis\n - context-conditioned event simulation\n - incomplete or noisy macro-statistics\n - settings where micro-records are entirely unavailable\n\n---\n\nThese unique capabilities are not only theoretical but are **concretely reflected in our experimental design**. The three evaluated tasks, **tabular** synthesis, **unstructured household** generation, and **context-driven event simulation**, are deliberately chosen to highlight distinct strengths of LLMSynthor:\n- Tabular synthesis illustrates LLMSynthor’s ability to rival fully-supervised baselines without micro-record access;\n- Household generation demonstrates its capacity to handle hierarchical, non-tabular structures;\n- Event simulation showcases flexible adaptation to arbitrary conditions without retraining.\n\nThis combination of flexibility, domain generality, and reliance on only aggregate information is not offered by any existing method. Therefore, while we benchmark LLMSynthor against tabular baselines for completeness, it is important to emphasize that these models solve a narrower problem requiring far more information. \n\n---\n\n**We sincerely hope the reviewers will consider these distinct strengths when evaluating the contributions of our framework.**"}}, "id": "Ns7P4NazFZ", "forum": "78zWToSUKj", "replyto": "78zWToSUKj", "signatures": ["ICLR.cc/2026/Conference/Submission3816/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3816/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3816/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763619838852, "cdate": 1763619838852, "tmdate": 1763621042759, "mdate": 1763621042759, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents LLMSYNTHOR, a framework for generating micro-level synthetic records that align with given macro-level statistics. It repurposes a pre-trained LLM as a macro-aware simulator that iteratively refines data generation through discrepancy feedback. The approach combines (i) LLM-based inference of variable dependencies and (ii) proposal-level sampling to improve efficiency and alignment. The paper evaluates the framework on three domains—mobility, e-commerce, and population synthesis—covering both structured and unstructured data. The authors claim the framework improves both realism and efficiency compared to standard LLM sampling, and demonstrate qualitative controllability through proposal-level generation instead of micro-record generation."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Synthesizing datasets using LLM is a good topic."}, "weaknesses": {"value": "- The paper lacks a description of important details, such as performance metric computation and the proposal for the micro-records sampling step. In Table 2, it is unclear what the Jsd column means. For other specified metrics, it is unclear how they are computed and why those metrics make sense in this application.\n\n- Figure 11 appears to suggest that LLM-based generation still scales poorly with dataset size, potentially far slower than purely generative baselines like GReaT, which trains once and can then sample nearly 10x times faster.\n\n- The paper claims that LLMSYNTHOR ensures realistic micro-records, yet there is no quantitative or human validation of realism.\n\n- All compared baselines (TVAE, CTGAN, CopulaGAN, GReaT, TabSyn, CP, HMM, NVI) are trained on full micro-record datasets, whereas LLMSYNTHOR only accesses macro statistics. Evaluation is non-comparable: the baselines operate with privileged access to individual-level data.\n\n- Synthesizing micro-records that align with target macro-statistics is conceptually similar to synthesizing samples conditioned on target population characteristics. The paper may benefit from comparing with related work in this direction [1, 2, 3], which also explores LLM-based methods for generating population-level or behaviorally diverse synthetic data.\n\nReferences: \n- [1] Bui, Ngoc, et al. \"Mixture-of-personas language models for population simulation.\" arXiv preprint arXiv:2504.05019 (2025).\n- [2] Choi, Hyeong Kyu, and Yixuan Li. \"Picle: Eliciting diverse behaviors from large language models with persona in-context learning.\" arXiv preprint arXiv:2405.02501 (2024).\n- [3] Yu, Yue, et al. \"Large language model as attributed training data generator: A tale of diversity and bias.\" Advances in neural information processing systems 36 (2023): 55734-55784."}, "questions": {"value": "- Are there any macro-only or aggregate-aware baselines that could serve as fairer comparisons?\n- How many LLM invocations are made per dataset? What is the number of micro-records per proposal?\n- How does LLMSYNTHOR validate the authenticity of generated records? Are there rule-based or domain constraints to reject implausible samples (e.g., “infant working full-time”)?\n- Was any human evaluation or domain-expert assessment performed to verify the realism of the synthetic records or the proposals?\nOnce an LLM outputs a proposal (e.g., “50 records: origin=Brooklyn, time ∈ [6,9]”), how are the individual attribute values sampled? Uniformly? Using empirical distributions?\n- How interpretable and realistic are these proposals in practice? Do domain experts consider them meaningful?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "whj2u1CIS4", "forum": "78zWToSUKj", "replyto": "78zWToSUKj", "signatures": ["ICLR.cc/2026/Conference/Submission3816/Reviewer_isfU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3816/Reviewer_isfU"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3816/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761778766311, "cdate": 1761778766311, "tmdate": 1762917049252, "mdate": 1762917049252, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response 2: Quantitative evaluation of micro-level Realism"}, "comment": {"value": "We thank the reviewer for highlighting the critical importance of micro-level realism. While our original submission included a comprehensive quantitative realism evaluation within the population-synthesis experiment. We have now moved the household-level realism evaluation to the **main text (Table 4)** to ensure high visibility.\nSpecifically, **Section 4.3 and Table 4** report rejection rates based on strict semantic constraints, with detailed definitions provided in **Appendix C.2.3**. We intentionally selected the population synthesis task for this evaluation because it offers rich micro-level semantics and unambiguous rules, allowing for rigorous quantification of realism without relying on subjective human annotation. These hard constraints serve as a ground-truth audit for semantic plausibility. Results show that LLMSynthor achieves significantly reduced rejection rates compared to baselines, demonstrating that our method successfully balances accurate macro-statistics with realistic micro-records.\n\n| Check                                 |       NVI       |        CP       |       HMM       |    LLMSynthor   |      Real      |\n|---------------------------------------|:---------------:|:---------------:|:---------------:|:---------------:|:--------------:|\n| Overall rejection rates ↓ |                 |                 |                 |                 |                |\n|   Household rejection rate            | 96.8 ± 0.3 | 73.9 ± 0.6 | 57.8 ± 0.5 | 13.3 ± 0.4 | 0.0 ± 0.0 |\n|   Person rejection rate               | 45.9 ± 0.4 | 34.1 ± 0.7 | 27.8 ± 0.6 |  6.3 ± 0.2 | 0.0 ± 0.0 |\n| Household-level checks ↓  |                 |                 |                 |                 |                |\n|   householder_type_adult_consistency  |  4.5 ± 0.2 |  4.4 ± 0.3 | 15.2 ± 0.5 |  3.8 ± 0.2 | 0.0 ± 0.0 |\n|   persons_all_valid                   | 96.7 ± 0.4 | 73.5 ± 0.6 | 56.1 ± 0.7 | 10.7 ± 0.3 | 0.0 ± 0.0 |\n| Person-level checks ↓     |                 |                 |                 |                 |                |\n|   age_range                           |  0.1 ± 0.0 |  0.5 ± 0.1 |  0.3 ± 0.1 |  0.0 ± 0.0 | 0.0 ± 0.0 |\n|   race_valid                          |  0.0 ± 0.0 |  0.8 ± 0.1 |  0.0 ± 0.0 |  0.0 ± 0.0 | 0.0 ± 0.0 |\n|   employment_age_consistency          | 41.6 ± 0.7 | 30.9 ± 0.6 | 24.5 ± 0.5 |  4.4 ± 0.2 | 0.0 ± 0.0 |\n|   education_age_consistency           | 42.7 ± 0.8 |  8.1 ± 0.4 | 10.7 ± 0.5 |  2.2 ± 0.1 | 0.0 ± 0.0 |\n\n---\n\nTo further address the reviewer’s feedback, we have conducted an additional realism analysis for the e-commerce experiment. While transaction records naturally contain fewer structural rigidities than household data (i.e., most transactions are inherently plausible), we designed a targeted set of domain-informed rules to detect subtle plausibility violations. These include category–price inconsistencies, age–category mismatches, and unrealistic purchases (e.g., high-end electronics bought by seniors). We include these results for completeness, though we maintain that the household setting offers a more rigorous testbed for realism due to its richer semantic structure.\n\n| Methods        | R1 (\\%) ↓ | R2 (\\%) ↓ | R3 (\\%) ↓ | Rej. (\\%) ↓ |\n|----------------|:---------------------:|:---------------------:|:---------------------:|:-----------------------:|\n| GT (Real Data) |     0.5 ± 0.    |     0.0 ± 0.    |     0.1 ± 0.    |      0.6 ± 0.     |\n| TVAE           |     1.6 ± 0.    |     0.1 ± 0.    |     0.1 ± 0.    |      1.8 ± 0.     |\n| CTGAN          |     2.9 ± 0.    |     1.9 ± 0.    |     0.3 ± 0.    |      5.1 ± 0.     |\n| CopulaGAN      |     2.1 ± 0.    |     2.1 ± 0.    |     0.6 ± 0.    |      4.8 ± 0.     |\n| GReaT          |     3.5 ± 0.    |     0.4 ± 0.    |     0.0 ± 0.    |      3.9 ± 0.     |\n| TabSyn         |     0.7 ± 0.    |     0.1 ± 0.    |     0.1 ± 0.    |      0.8 ± 0.     |\n| Spada          |     3.6 ± 0.    |     0.2 ± 0.    |     0.4 ± 0.    |      4.1 ± 0.     |\n| IPF            |     0.6 ± 0.    |     0.5 ± 0.    |     0.7 ± 0.    |      1.8 ± 0.     |\n| LLM-ICL        |     0.0 ± 0.    |     0.0 ± 0.    |     0.0 ± 0.    |      0.0 ± 0.     |\n| LLMSynthor     |     0.5 ± 0.    |     0.0 ± 0.    |     0.0 ± 0.    |      0.5 ± 0.     |\n\nAs expected, rejection rates remain low across the board, yet the results highlight our method's advantage. The LLM-ICL baseline yields the lowest rejection rate (0.0%), confirming the inherent semantic strength of LLMs. LLMSynthor achieves the next-best performance (0.5% ± 0.1%), closely matching ground-truth levels and substantially outperforming deep generative baselines such as CTGAN (5.1%), CopulaGAN (4.8%), and GReaT (3.9%). These findings confirm that LLMSynthor effectively avoids spurious attribute combinations, leveraging LLM priors to maintain semantic plausibility even without access to micro-records during training."}}, "id": "ZmPsagM6MC", "forum": "78zWToSUKj", "replyto": "78zWToSUKj", "signatures": ["ICLR.cc/2026/Conference/Submission3816/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3816/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3816/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763620295507, "cdate": 1763620295507, "tmdate": 1763620998482, "mdate": 1763620998482, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a simulator that uses a pre-trained LLM for synthesizing tabular data that match given macro-statistics. They treat the LLM as a non-parametric copula to infer variable dependencies and decide which joints to control and use discrepancy-guided iterative synthesis with LLM Proposal Sampling to reduce the macro-level gaps between current synthetic aggregates and targets. Experiments on mobility, e-commerce (tabular), and population synthesis show good macro alignment and downstream utility; the paper also reports strong performance versus tabular baselines."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is very well written with illustrative figures.\n- Synthetic data generation with LLMs is an important and timely problem.\n- Method design feels practical. The loop is simple and likely easy to implement.\n- Some limitations of LLMs are clearly discussed."}, "weaknesses": {"value": "- Evaluation alignment vs. leakage. In section 4.2, it is not fully clear which macro-stats are used as inputs to LLMSynthor. Are they the same as evaluation metrics? If they coincide, the method could look stronger than baselines because it is explicitly optimizing those statistics, whereas baselines also model micro-level realism beyond the chosen stats. \n- Baselines breadth & recency. The population-synthesis baselines (CP/HMM/NVI) appear to be outdated relative to modern diffusion/tabular-LLM generators. Similarly, some tabular synthesis, TabSyn and GReaT are included, but they seems old as well. How's your method compared to recent LLM-based tabular generator,s such as - Yang et al Doubling Your Data in Minutes: Ultra-fast Tabular Data Generation via LLM-Induced Dependency Graphs. or Long et al. LLM-TabLogic: Preserving Inter-Column Logical Relationships in Synthetic Tabular Data via Prompt-Guided Latent Diffusion."}, "questions": {"value": "- (Line ~140) Variable types. You define micro-records over variables (discrete or continuous). Why is the taxonomy restricted to these two? Can your method be extended to synthesizing other dataset formats with texts, for example, since you're using LLMs?\n-  Some citations are needed for baselines in population synthesis experiments. \n- Why synthetic e-commerce? Could you replicate section 4.2 on a public retail/marketplace dataset (e.g., an Amazon open dataset) to demonstrate performance with real macro targets and natural noise? What prevents doing this today?\n- Can you please report the quantitative evaluation of the realism of micro-records for the experiment in section 4.2?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "yJyaE9apZw", "forum": "78zWToSUKj", "replyto": "78zWToSUKj", "signatures": ["ICLR.cc/2026/Conference/Submission3816/Reviewer_5i4z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3816/Reviewer_5i4z"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3816/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762123797967, "cdate": 1762123797967, "tmdate": 1762917048974, "mdate": 1762917048974, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response 1: Expanded Baseline Methods and Clarification on Fair Comparison"}, "comment": {"value": "We appreciate the reviewer’s constructive suggestion, which allows us to further strengthen our contribution.\n\n---\n\n# 1. We added three new experiments across different supervision levels\nTo further address this concern, we introduce three new baselines specifically designed for the macro-supervision setting. \n\n\n| Methods               |   Rej. %  |  Age  | Gender |  Loc. |  Cat. |  Price  | Payment | [v_A, v_G, v_C] | [v_C, v_X] | [v_L, v_M] |\n|-----------------------|:---------:|:-----:|:------:|:-----:|:-----:|:-------:|:-------:|:---------------:|:----------:|:----------:|\n|                       |           |  Was  |   Tvd  |  Tvd  |  Tvd  |   Was   |   Tvd   |       Jsd       |     Jsd    |     Jsd    |\n| TabSyn (**micro**)        | 1.9 ± 0.3 | 1.196 |  0.012 | 0.007 | 0.045 |  114.12 |  0.028  |      0.083      |    0.237   |    0.027   |\n| Spada (**macro + micro**) | 4.1 ± 0.9 |  1.42 |  0.013 | 0.003 | 0.016 |  54.603 |  0.025  |      0.085      |    0.225   |    0.103   |\n| IPF (**macro-only**)      | 3.9 ± 0.6 |  5.27 |  0.018 | 0.026 | 0.012 | 139.957 |  0.035  |      0.117      |    0.504   |    0.113   |\n| LLM-ICL (**macro-only**)  | 0.1 ± 0.0 | 20.61 |  0.026 | 0.024 | 0.441 | 279.743 |  0.163  |      0.437      |    0.591   |    0.476   |\n| Ours (**macro-only**)     | 0.3 ± 0.1 |  1.13 |  0.002 | 0.002 | 0.022 |  12.762 |  0.003  |      0.071      |    0.134   |    0.007   |\n\n\n\nFirst, we modify a recent LLM-based hybrid tabular generator SPADA [1] to include explicit macro-level supervision during training, even with access to both micro- and macro-statistics, its macro-alignment remains weaker than LLMSynthor. \n\nSecond, we incorporate Iterative Proportional Fitting (IPF) [2] as a classical macro-only simulator, despite having direct access to all marginal and joint constraints, it produces micro-records with significantly poorer realism. \n\nThird, we evaluate an LLM-ICL [3] baseline in which GPT-5.1 is given the entire set of macro-statistics as in-context prompts and asked to directly generate micro-records. We implemented this baseline through a 40-turn interactive session in the ChatGPT interface, where the model benefits from OpenAI’s built-in conversational memory and can fully leverage all previously generated records. This setup provides the ICL baseline with the strongest possible conditions for macro-aware generation. Nevertheless, its performance remains substantially worse than LLMSynthor, underscoring that one-shot or conversational ICL is insufficient without iterative discrepancy-guided correction, which is essential for stable macro-level alignment.\n\nTogether, these experiments demonstrate that LLMSynthor is not advantaged by ''leakage'' of evaluation metrics. On the contrary, it outperforms both micro-supervised, macro-supervised, and macro-only baselines despite relying on strictly less information.\n\n---\n\n\n# 2. Core clarification\nLLMSynthor only sees the target macro-statistics. In the tabular synthesis task (i.e., E-commerce transactions synthesis), the marginal statistics and dependency structure are inferred through the Variable Dependence Inference Module. While tabular baselines (TVAE, CTGAN, CopulaGAN, TabSyn, GReaT, etc.) are trained on full micro-records, meaning they observe:\n- all one-way marginals\n- all multi-way joint distributions\n- all conditional distributions\n- and thus all macro-statistics used in our evaluation\nThis means: Baselines have strictly more supervision and a strictly easier task. LLMSynthor solves the harder setting: generate micro-records using only aggregates.\n\n---\n\n# 3. Why baseline training already optimizes macro-statistics\nAll tabular generative models, including VAEs, GANs, diffusion models, and LLM-based tabular generators,optimize an objective equivalent to minimizing a divergence between the true data distribution $p(x)$ and the model distribution $q_\\theta(x)$:\n$$\\min_\\theta D\\bigl(p(x) \\| q_\\theta(x)\\bigr)$$\n\nFor example, Diffusion-based tabular generators minimize denoising score matching, which is equivalent to:\n$$\\min_\\theta \\left\\| \\nabla_x \\log p(x) - \\nabla_x \\log q_\\theta(x) \\right\\|_2^2.$$\n\nBecause every macro-statistic is an expectation under the data distribution,\n$$S_{\\mathrm{macro}} = \\mathbb{E}_{x\\sim p(x)}[f(x)],$$\n\nAny method that fits $q_\\theta(x) \\approx p(x)$ necessarily matches **all** macro-statistics. Thus, baselines implicitly optimize all evaluation metrics simply by training on the full micro-records.\n\n---\n\n# 4. LLMSynthor uses less supervision and is therefore solving a harder problem\nLLMSynthor never observes micro-records.\nIt does not see:\n- any micro-level correlations not included in the macro-input\n- any micro-level support constraints\n- any long-tail structure or higher-order dependencies\nThus, our method performs well despite missing information that all baselines rely on. This is exactly the setting many real-world agencies face, they only have aggregated statistics, not individual data."}}, "id": "cL9ocUUfgY", "forum": "78zWToSUKj", "replyto": "78zWToSUKj", "signatures": ["ICLR.cc/2026/Conference/Submission3816/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3816/Authors"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3816/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763620568745, "cdate": 1763620568745, "tmdate": 1763620959425, "mdate": 1763620959425, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a new framework for synthesizing realistic micro-records (individual-level data) to align with the given macro-statistics (aggregate-level constraints). The method iteratively generates batches of synthetic micro-records, where each iteration measures the discrepancy between current synthetic macro-statistics and target aggregates. They empirically validate their method in three different applications (urban mobility, e-commerce transactions, population synthesis)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This paper addresses a practical challenge in data synthesis: generating individual-level records when only aggregate statistics are available.\n- The experimental setup on three different applications demonstrate broad applicability and outperforms the considered baselines."}, "weaknesses": {"value": "- How do you prevent \"over-correction\", where repeated discrepancy-guided sampling causes loss of diversity?\n- Method limitations. In real world applications, macro-statistics might be noisy or incomplete, can the method incorporate uncertainty over the target aggregates?\n- Limited empirical evaluation. How sensitive is the framework to LLM quality?"}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "hABG7HfWSq", "forum": "78zWToSUKj", "replyto": "78zWToSUKj", "signatures": ["ICLR.cc/2026/Conference/Submission3816/Reviewer_Edw1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3816/Reviewer_Edw1"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3816/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762319155704, "cdate": 1762319155704, "tmdate": 1762917048735, "mdate": 1762917048735, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Overview: Summary of Revisions and Methodological Contributions"}, "comment": {"value": "We sincerely thank the reviewers for their constructive feedback and insightful suggestions. These comments have significantly strengthened the rigor and presentation of our work. In this revision, we have conducted extensive new experiments and structural updates to address the concerns raised:\n1. **Expanded Baseline Suite & Fair Comparison**: To better contextualize our performance, we have expanded our evaluation to distinguish between micro-record supervised (e.g., TabSyn, GReaT) and macro-only baselines. This explicitly highlights our framework's advantage: LLMSynthor achieves competitive or superior performance despite accessing strictly less information (aggregate-only) compared to baselines that require sensitive micro-record training.\n2. **Rigorous Realism Evaluation (Moved to Main Text)**: We have conducted a comprehensive quantitative analysis of record-level realism across both population and e-commerce domains.\n- Results: As shown in the new Table 4 (Main Text) and Appendix C.2.3, LLMSynthor achieves near-zero rejection rates, significantly outperforming deep generative models (which frequently produce semantically invalid combinations) and demonstrating superior semantic plausibility.\n- Visibility: We have moved these key findings to the main text to underscore the semantic validity of our generated micro-records.\n3. **Comprehensive Stability, Efficiency, and Interpretability Analysis**: We have added a new stability analysis in Figure 5 (Main Text) and a detailed breakdown in Appendix C.1 (Figures 11-14, Tables 6-7).\n- **Diversity & Bias**: We demonstrate that our discrepancy-guided mechanism effectively steers generation toward ground-truth diversity while progressively mitigating bias.\n- **Efficiency**: New runtime studies confirm that with only 10 iterations, LLMSynthor surpasses the GReaT baseline in both speed and quality.\n- **Interpretability**: We provide further evidence that our proposal-level generation offers transparency unavailable in black-box neural baselines.\n\n---\nClarified Reiteration of **Unique Contributions**:\n\nWhile we include comparisons with standard tabular generators for completeness, we respectfully emphasize that **LLMSynthor is designed to tackle a fundamentally broader and more difficult problem**. Unlike baselines that rely on memorizing micro-records, our framework reconstructs data distributions **using only privacy-preserving aggregate statistics**. It can naturally **handle hierarchical and unstructured data**, such as variable-sized households, which lie beyond the capabilities of fixed-schema tabular models. Moreover, LLMSynthor **supports zero-shot adaptation** to novel contexts without the need for retraining. By offering **a unified approach** to these diverse challenges, our method addresses a critical gap that existing baselines are not equipped to fill. \n\n**We hope the reviewers will take these distinct capabilities into account when evaluating the scope and contribution of our work.**\nWe deeply appreciate the time and effort the reviewers have invested in evaluating our work. We look forward to the discussion phase and are more than willing to provide further details or experiments to fully address any remaining questions."}}, "id": "xvDXN7iYVW", "forum": "78zWToSUKj", "replyto": "78zWToSUKj", "signatures": ["ICLR.cc/2026/Conference/Submission3816/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3816/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3816/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763620758849, "cdate": 1763620758849, "tmdate": 1763620927793, "mdate": 1763620927793, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}