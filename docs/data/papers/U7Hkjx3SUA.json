{"id": "U7Hkjx3SUA", "number": 11197, "cdate": 1758193097691, "mdate": 1759897601591, "content": {"title": "ACCELERATE SCALING OF LLM FINETUNING VIA QUANTIFYING THE COVERAGE AND DEPTH OF INSTRUCTION SET", "abstract": "Scaling the amount of data used for supervied fine-tuning(SFT) does not guarantee the proportional gains in model performance, highlighting a critical need to understand what makes training samples effective. This work identifies two fundamental dataset properties that govern SFT scalability: \\textbf{semantic coverage}, or the breadth of task domains, and \\textbf{information depth}, or the richness of individual examples. We demonstrate that simple proxies for these properties explain the majority of validation loss variance in our experiments. In this work, we further propose the \\textbf{Information Landscape Approximation (ILA)}, a model-agnostic data selection framework that jointly optimizes for these two factors. ILA constructs compact subsets that approximate the informational value of large datasets. Empirical results show that models tuned on ILA-selected data achieve faster and more sustained performance improvements across diverse tasks and model sizes compared to existing methods, a phenomenon we term \\textbf{accelerated scaling}.", "tldr": "We show that semantic coverage and information depth are key to SFT scalability, and propose ILA, a simple model-agnostic data selection method that enables accelerated scaling with compact, high-value subsets.", "keywords": ["instruction set refinement", "instruction data selection"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fe4b7210670218863368e86dc48d560935ff2329.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes ILA: a way to select a subset of data that considers both the representativeness of a dataset, and the amount of information present in each data sample of the subset. ILA breaks down the instruction training data into patches (grids of size S) and selects points within grids. The selection criteria is based on coverage (picking individual points from different grids) and information depth (picking points based on how drastically the loss changes from base to fine-tuned model)."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The methodology is well formulated with mathematical formulations.\n- Making the distinction between information depth and coverage was a good idea, and is insightful"}, "weaknesses": {"value": "- One more revision on the writing is necessary, there are a few mistakes (line 244: \"$N_sub$\", line 323: \"iformation landscape approximation\", Figure 4c: title says \"Aplaca\")\n- Could not find the discussion on whether the random sample of instructions to obtain $M_{SFT}$ matters.\n- By selecting 20k samples, it seems they are not maximizing the coverage of the dataset, only the information depth (Figure 5).\n- Reporting accuracy for the base model would be helpful in Table 1 to see how much of a gain fine-tuning has in general.\n- The main set of results (Table 1, from what I can gather) are a bit constrained as the math instruction training data is all QwQ-based. Instead, using GSM8k, one QwQ dataset, MetaMath, OpenMathInstruct, Math-Shepherd, etc. would have made the claim a bit stronger."}, "questions": {"value": "1. As I understand it, ILA uses a random sample to obtain $M_{SFT}$ and then performs subset selection on the points without that initial set of random samples ($I_i$). Is the Random baseline also on the same set $I_i$, or on $I$?\n2. Are there any ablation studies to see if selecting points wrt information depth or wrt coverage help more? Or (to avoid running experiments), are there any previous works that show a similar notion of information depth/coverage and how they perform compared to each other?\n3. How is the frequency of an instruction calculated? Are they based on semantic similarity, n-gram matching, or exact matching?\n4. Why is the instruction set broken into grids instead of clusters (using kmeans/++ or (H)DBSCAN)?\n5. What model/dataset does Figure 5 plot? Maybe I missed that."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "9IfGjK2V8j", "forum": "U7Hkjx3SUA", "replyto": "U7Hkjx3SUA", "signatures": ["ICLR.cc/2026/Conference/Submission11197/Reviewer_jYe6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11197/Reviewer_jYe6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760912424911, "cdate": 1760912424911, "tmdate": 1762922347952, "mdate": 1762922347952, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a framework to understand and improve the scaling of supervised fine-tuning (SFT) for LLMs. The key idea is that two factors: semantic coverage (the breadth of instruction domains) and information depth (the richness or informativeness of individual instructions) determine the efficiency of scaling SFT data. The authors define proxy metrics for these factors and show through regression that they explain some variance in dev set loss (R2=0.7). They further introduce Information Landscape Approximation (ILA), a method for data selection that jointly maximizes coverage and depth, showing empirically that it leads to more efficient scaling and improved performance compared to random sampling and DEITA baselines."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "n/a"}, "weaknesses": {"value": "- Would the authors be more clear in the derivation in Section 2.1? Write a proof formally and rigourous if you want to make a point. It seems the authors are just using some equations along side what they \"think\" would happen. What is $\\delta S_i$ beyond defining it in English as a \"small area\"? Why would loss on other examples within the small area be expected to decreaase accordingly? What do you mean $\\epsilon_j$ is a small term, how small? I think it's also just ok to say it's your intuition and there is no theoretical backing and that is fine since the reviewers won't hold you up to it.\n- If we need to divide by response length and multiply by number of ability/knowledge labels in the estimator of information depth defined in Equation (5), then we are not really estimating the true value defined in Equation (3)! So what are we really trying to estimate, define that in Equation (3) instead. Otherwise all the \"theory\" the authors introduced is meaningless because what they implement is different from what they want to implement defind in Equation (3). And it terms out the authors also did not use Equation (5) but a relative version of Equation (5). This just makes what the authors use and what they think happen theoretically totally different.\n- Equation (5) seems pretty adhoc as well, why are we assuming we should divide by response token counts $T_j$ as opposed to $\\log T_j$, why would $\\text{ID}_j$ depend linearly on #label and not $\\log$ #label or $\\exp$ #label? The formulation seems came up in a pretty ad-hoc manner. Does this imply that for an easy question, but with very long answer & deals with multiple skills has more information and is therefore more valuable? Would the authors demonstrate empirically this is the cas?\n- I think the authors should not re-invent the same concept in data selection / active learning literature. For example, [1] choose a subset of points that minimizes expected loss - equivalent to the notion of finding examples with high \"information depth\". The authors should acknowledge these prior works and don't re-invent terminologies that does the same thing or at least be clear about what is foundamentally different - I don't really see that big of a difference.\n- t-SNE is not a reasonable representation for semantic coverage since it's mostly used for visualization and is not a metric-preserving embedding, i.e., the pairwise distances between embeddings are not preserved! \n- Regression coefficient captures linear relationships only, what aobut nonlinear ones? R2 of 0.7 is actually not that high ... I would say the \"depth\" and \"coverage\" provided by the author does not at all explain the dev-set loss that well. Also this number of 0.7 also seems to be quite brittle. I would request author report R2 on the dataset with right most data point in FIgure 3 (b) removed, I would imagine R2 drop to 0.5. Let's do cross-validation on the R2, maybe add some significance test, and/or vary number of datasets (currently use 36) to make sure the result can be consistently reproduced. In addition, the dataset used to verify linear relationship is constructed using these two features - it would be nice if the authors would repeat the analysis where the dataset construction is agnostic of the approach introduced in the paper.\n- The authors compared against random/DEITA two baselines only. I would recommend the authors to compare against more baselines. There has been so many new work that purportedly beat DEITA - I think the arXiv version of the paper appeared in late 2023 (2 years from now)- and the space has changed quite a bit. \n\n\n[1] 2018, ACTIVE LEARNING FOR CONVOLUTIONAL NEURAL NETWORKS: A CORE-SET APPROACH"}, "questions": {"value": "see weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "rDR3y49Lzr", "forum": "U7Hkjx3SUA", "replyto": "U7Hkjx3SUA", "signatures": ["ICLR.cc/2026/Conference/Submission11197/Reviewer_pwpA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11197/Reviewer_pwpA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761495804328, "cdate": 1761495804328, "tmdate": 1762922347539, "mdate": 1762922347539, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces semantic coverage and information depth, two key properties that govern the scalability of supervised fine-tuning. It further presents computationally efficient proxies to estimate these properties. Empirically, the authors demonstrate that validation loss is highly correlated with the two properties. Building on this insight, the paper proposes a data selection algorithm that selects instruction-tuning datasets by optimizing these two properties. Experimental results show that the proposed method outperforms both random selection and a state-of-the-art selection baseline."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The two properties introduced in this paper have the potential to serve as general and interpretable metrics for measuring data quality, which could make them broadly useful beyond the current study.\n- The proposed method is model-agnostic, conceptually clear, and straightforward to implement. The code is provided.\n- Extensive experiments demonstrate that ILA-selected subsets outperform random selection and a state-of-the-art method across diverse tasks and models."}, "weaknesses": {"value": "- There appears to be a discrepancy between the definition of information depth in Section 2.1 and the implementation described in the experiments. If I understand correctly, Section 2.1 defines information depth based on fine-tuning the model on a single instance, whereas Section 2.3 uses a random subset for fine-tuning. This inconsistency raises several questions:\n  - If the model is fine-tuned on a single instance, would the resulting loss change be too noisy to serve as a stable metric?\n  - If a random subset is used instead, would examples similar to those in the subset (e.g., near-duplicates) tend to receive artificially high information depth values?\n  - What is the motivation behind this discrepancy between the definition and the experimental procedure?\n- Several aspects are not well justified, either theoretically or empirically:\n  - The number of labels as a factor in the definition of information depth.\n  - The uniform segmentation of the space.\n- The equations in Lines 134–143 contain several typos, which make this part difficult to follow."}, "questions": {"value": "- The proposed information depth metric appears conceptually related to example hardness (e.g., as defined in [1]). Could you elaborate on the relationship and key distinctions between these two?\n- Why is there still a steep increase in coverage in Figure 5(b), given that ILA is designed to prioritize coverage? What is the exactly definition of coverage in this figure?\n\n[1] Zhou, Tianyi, Shengjie Wang, and Jeffrey Bilmes. \"Curriculum learning by dynamic instance hardness.\" Advances in Neural Information Processing Systems 33 (2020): 8602-8613."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "WxzN1TMHpr", "forum": "U7Hkjx3SUA", "replyto": "U7Hkjx3SUA", "signatures": ["ICLR.cc/2026/Conference/Submission11197/Reviewer_Ts1N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11197/Reviewer_Ts1N"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761771158348, "cdate": 1761771158348, "tmdate": 1762922347043, "mdate": 1762922347043, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the problem of data selection for supervised fine-tuning of large language models. The authors present two metrics, including semantic coverage and information depth, to measure the effectiveness of fine-tuning. \n- This paper measures information depth using a normalized loss-based metric that captures how much meaningful learning signal each instruction provides. Specifically, it computes the per-sample reduction in cross-entropy loss (indicating how much the model learns from that example), normalized by response length and weighted by the number of distinct knowledge or skill tags. Then, this paper further adjusted across domains using a relative information depth score based on quantiles to remove domain bias. \n- Semantic coverage is estimated by projecting all instructions into a semantic embedding space (using a model like BGE), dividing that space into uniform grids, and counting the proportion of non-empty cells. This reflects how widely the instruction set spans different task types and semantic regions. \nThen, this paper introduces Information Landscape Approximation (ILA), a data selection framework that constructs a subset of instruction data by maximizing both coverage and depth simultaneously. \n\nThe experiments show that the Information Landscape Approximation (ILA) consistently outperforms random selection and state-of-the-art heuristic methods across multiple model architectures (e.g., LLaMA3, Qwen2) and domains, including general instruction following and math reasoning. Models fine-tuned with ILA-selected data achieve faster and more stable performance scaling, maintaining or exceeding baseline results with fewer samples. Quantitative analyses show that a linear model using coverage and information depth together as features achieces an $R^2$ score of 0.7. In benchmarks like AlpacaEval and Arena-Hard, ILA improves accuracy, while in math reasoning tasks (e.g., MATH, GSM8K), it yields 7–11% absolute gains over random sampling."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- This paper introduces a new way to select supervised fine-tuning data through two interpretable data properties, including semantic coverage and information depth, providing measures for evaluating data quality in LLM training.\n\n- This paper proposes Information Landscape Approximation, which consistently improves fine-tuning by selecting data that balances coverage and informativeness.\n\n- This paper performs experiments across multiple models and domains (including reasoning and instruction-following) and shows that ILA achieves faster scaling and higher accuracy with fewer samples."}, "weaknesses": {"value": "- The information depth is evaluated by the decrease in cross-entropy loss between the base model and the fine-tuned model for instruction. It may require extensive computation to compute this metric, which is expensive on a large dataset. \n- The semantic coverage requires dividing the embedding space into a uniform grid. However, the procedure to determine the grid (or grid size) is unclear. \n- How are the proposed metrics related to existing data selection metrics, such as feature representations, gradients, and influence function?\n- The procedure for performing the Information Landscape Approximation algorithm is not clear. It would be better to provide an algorithm box. \n- There are many typos in the paper. For example, \"Supervised fine-tuning(SFT)\" and \"large language models(LLMs)\" in L30-31, and the usage of citations."}, "questions": {"value": "- Does the paper compare with the LESS (Xia et al., 2024) baseline? \n- What is the computational cost of the proposed method compared with the baselines in the experiments? \n- Did the authors test the individual contributions of coverage and depth separately to quantify which factor has a stronger impact on fine-tuning performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "c0dftORIIW", "forum": "U7Hkjx3SUA", "replyto": "U7Hkjx3SUA", "signatures": ["ICLR.cc/2026/Conference/Submission11197/Reviewer_JC15"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11197/Reviewer_JC15"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11197/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926786635, "cdate": 1761926786635, "tmdate": 1762922346535, "mdate": 1762922346535, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}