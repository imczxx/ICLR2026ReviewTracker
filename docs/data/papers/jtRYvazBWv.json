{"id": "jtRYvazBWv", "number": 188, "cdate": 1756730599712, "mdate": 1763176830436, "content": {"title": "CLUE: Conflict-guided Localization for LLM Unlearning Framework", "abstract": "The LLM unlearning aims to eliminate the influence of undesirable data without affecting causally unrelated information.\nThis process typically involves using a **forget set** to remove target information, alongside a **retain set** to maintain non-target capabilities. While recent localization-based methods demonstrate promise in identifying important nodes (neurons) to be unlearned, they fail to disentangle nodes responsible for forgetting undesirable knowledge or retaining essential skills, often treating them as a single entangled group. As a result, these methods apply uniform interventions, risking catastrophic over-forgetting or incomplete erasure of the target knowledge. To address this, we turn to circuit discovery, a mechanistic interpretability technique, and propose the **C**onflict-guided **L**ocalization for LLM **U**nlearning fram**E**work (**CLUE**). This framework identifies the forget and retain circuit composed of important nodes, and then the circuits are transformed into conjunctive normal forms (CNF). The assignment of each node in the CNF satisfiability solution reveals whether it should be forgotten or retained. We then provide targeted fine-tuning strategies for different categories of nodes. Extensive experiments demonstrate that, compared to existing localization methods, CLUE achieves superior forget efficacy and retain utility through precise neural localization.", "tldr": "We use circuit discovery and CNF solving to design the localization for forget neurons and retain neurons in the LLM unlearning task.", "keywords": ["LLM unlearning", "circuit discovery", "conjunctive normal form", "interpretability"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/79dfa4eb81c0a968337d0f800cadd1302d8c33d2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces CLUE, a new framework designed to improve the precision and effectiveness of large language model (LLM) unlearning. Existing localization-based unlearning methods identify important neurons for modification but fail to distinguish between neurons responsible for forgetting and those critical for retention. This entanglement often leads to over-forgetting or incomplete erasure of target information. To solve this, CLUE leverages circuit discovery, a mechanistic interpretability approach, to map neuron interactions as circuits. It then converts these into CNF and uses Boolean satisfiability solving to disentangle neurons into three categories: Forget neurons, Retain neurons, and Conflict neurons."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The application of mechanistic interpretability and circuit discovery to LLM unlearning is novel and conceptually well-motivated, bridging interpretability with model editing.\n- The explicit separation into forget, retain, and conflict neurons allows for more precise control and understanding of unlearning behavior.\n- Experiments across multiple benchmarks show consistent improvements.\n- The framework enhances interpretability by revealing how specific neurons and circuits contribute to different functions, aligning with future modular LLM design goals.\n- The paper clearly articulates the problem of neuron entanglement and justifies the need for a more granular approach like CLUE."}, "weaknesses": {"value": "- Although the section 5.1 and 5.2 documented well on benchmarks that the study is evaluted on plus the details on how the evaluation is conducted, I, somehow, could not find any descriptions on what model is evaluated. Is it the same model across all the benchmark evaluations? What is the family and the size of the model being evaluated in the study? \n- As the curse of circuit discovery, the framework would possibly also have scalability problem, such as being computationally expensive to find a meaningful ciruit in larger models. For meaningful circuit, I mean a circuit that is sparse enough comparing to the original computational graph. \n- The framework utilizes the edge pruning technique. In edge pruning, it returns a series of ciruits as the sparisity going down, while the metrics of the faithfulness would also vary. I wonder what are the specific critierion that was used to pick such circuit from the edging pruning outcomes. And how would you justify picking one of the circuits over the others ( maybe in terms of exact match, KL divergence, or sparisity)? \n- The framework appears to make an implicit assumption that the contribution of each neuron identified within a circuit is independent of the specific path or connectivity structure it participates in. For instance, consider a sequence of neurons \nùê¥1‚Üíùê¥2‚Üíùê¥3 across successive layers. CLUE might categorize ùê¥1, ùê¥2, and ùê¥3 into different neuron sets (e.g., forget, retain, or conflict) based on their individual CNF assignments. However, in reality, the functional contribution of each neuron is context-dependent on the path it forms with others. In contrast, circuit-level methods such as edge pruning often treat  A1‚ÜíA2 ‚ÜíA3 as an integrated substructure, preserving or removing the path as a whole. This suggests that CLUE‚Äôs neuron-wise localization might overlook interdependent effects among neurons within the same circuit, potentially leading to suboptimal or fragmented unlearning."}, "questions": {"value": "Please refer to the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vpRdY8ARfQ", "forum": "jtRYvazBWv", "replyto": "jtRYvazBWv", "signatures": ["ICLR.cc/2026/Conference/Submission188/Reviewer_J9hV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission188/Reviewer_J9hV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission188/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761443068623, "cdate": 1761443068623, "tmdate": 1762915465825, "mdate": 1762915465825, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "GENERAL RESPONSE (the summary of revisions)"}, "comment": {"value": "We would like to express our gratitude to Reviewers PHgS, VCVn, tdd5, and J9hV for their diligent review and constructive feedback. In accordance with the modifications requested by the reviewers, we have revised the manuscript as follows:\n\n**Section 2.2**: We have incorporated additional explanations for neurons and removed the term \"components\" for simplicity, directly clarifying the specific scope and relationship. This revision addresses Q1 from Reviewer PHgS.\n\n**Section 3.1**: A description of the process for obtaining a circuit from the datasets has been added (including the new Figure 3 for visual illustration). This supplements the text to resolve potential confusion regarding the circuit discovery process, addressing Q1 and Q4 from Reviewer VCVn.\n\n**Section 6.3**: We have added a declaration of the specific sparsity value utilized in our experiments, which addresses Q3 from Reviewer J9hV.\n\n**Section 7**: We have introduced a discussion of two limitations: first, the potential inability to obtain a clear circuit from some forget sets and its subsequent impact on unlearning performance; and second, the scalability challenges associated with circuits. This is in response to Q3 from Reviewer VCVn and Q2 from Reviewer J9hV.\n\n**Appendix J**: A comparison of computational costs has been included to respond to Q2 from Reviewer tdd5.\n\n**Other typos**: We have made a proofreading and corrected the typos and writing errors, which addressed Q3 from Reviewer PHgS.\n\nFor ease of review, all revisions have been highlighted in **red** font in the revised PDF. We hope these revisions adequately address the reviewers' concerns and are grateful once again for their constructive suggestions."}}, "id": "f4Spawy6Dz", "forum": "jtRYvazBWv", "replyto": "jtRYvazBWv", "signatures": ["ICLR.cc/2026/Conference/Submission188/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission188/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission188/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763113266259, "cdate": 1763113266259, "tmdate": 1763113266259, "mdate": 1763113266259, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces CLUE, a new framework designed to improve the precision and effectiveness of large language model (LLM) unlearning. Existing localization-based unlearning methods identify important neurons for modification but fail to distinguish between neurons responsible for forgetting and those critical for retention. This entanglement often leads to over-forgetting or incomplete erasure of target information. To solve this, CLUE leverages circuit discovery, a mechanistic interpretability approach, to map neuron interactions as circuits. It then converts these into CNF and uses Boolean satisfiability solving to disentangle neurons into three categories: Forget neurons, Retain neurons, and Conflict neurons."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The application of mechanistic interpretability and circuit discovery to LLM unlearning is novel and conceptually well-motivated, bridging interpretability with model editing.\n- The explicit separation into forget, retain, and conflict neurons allows for more precise control and understanding of unlearning behavior.\n- Experiments across multiple benchmarks show consistent improvements.\n- The framework enhances interpretability by revealing how specific neurons and circuits contribute to different functions, aligning with future modular LLM design goals.\n- The paper clearly articulates the problem of neuron entanglement and justifies the need for a more granular approach like CLUE."}, "weaknesses": {"value": "- Although the section 5.1 and 5.2 documented well on benchmarks that the study is evaluted on plus the details on how the evaluation is conducted, I, somehow, could not find any descriptions on what model is evaluated. Is it the same model across all the benchmark evaluations? What is the family and the size of the model being evaluated in the study? \n- As the curse of circuit discovery, the framework would possibly also have scalability problem, such as being computationally expensive to find a meaningful ciruit in larger models. For meaningful circuit, I mean a circuit that is sparse enough comparing to the original computational graph. \n- The framework utilizes the edge pruning technique. In edge pruning, it returns a series of ciruits as the sparisity going down, while the metrics of the faithfulness would also vary. I wonder what are the specific critierion that was used to pick such circuit from the edging pruning outcomes. And how would you justify picking one of the circuits over the others ( maybe in terms of exact match, KL divergence, or sparisity)? \n- The framework appears to make an implicit assumption that the contribution of each neuron identified within a circuit is independent of the specific path or connectivity structure it participates in. For instance, consider a sequence of neurons \nùê¥1‚Üíùê¥2‚Üíùê¥3 across successive layers. CLUE might categorize ùê¥1, ùê¥2, and ùê¥3 into different neuron sets (e.g., forget, retain, or conflict) based on their individual CNF assignments. However, in reality, the functional contribution of each neuron is context-dependent on the path it forms with others. In contrast, circuit-level methods such as edge pruning often treat  A1‚ÜíA2 ‚ÜíA3 as an integrated substructure, preserving or removing the path as a whole. This suggests that CLUE‚Äôs neuron-wise localization might overlook interdependent effects among neurons within the same circuit, potentially leading to suboptimal or fragmented unlearning."}, "questions": {"value": "Please refer to the weakness section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "vpRdY8ARfQ", "forum": "jtRYvazBWv", "replyto": "jtRYvazBWv", "signatures": ["ICLR.cc/2026/Conference/Submission188/Reviewer_J9hV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission188/Reviewer_J9hV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission188/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761443068623, "cdate": 1761443068623, "tmdate": 1763123105497, "mdate": 1763123105497, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the challenge of LLM unlearning removing undesirable knowledge while preserving unrelated capabilities. The authors note that existing localization based methods, such as WAGLE and MEMIT, struggle to disentangle neurons responsible for forgetting from those involved in retaining information. To overcome this limitation, they propose CLUE (Conflict-Guided Localization for LLM Unlearning), a framework that integrates circuit discovery and logical reasoning. Specifically, CLUE first uses circuit discovery to extract distinct ‚Äúforget‚Äù and ‚Äúretain‚Äù subcircuits, then transforms these circuits into Conjunctive Normal Form (CNF) using the Tseitin transformation. The CNF satisfiability problem is subsequently solved to classify neurons into three categories: forget, retain, and conflict. Finally, the framework applies a two-stage fine tuning strategy first fine-tuning the forget neurons using a forget loss, followed by fine-tuning the conflict neurons with both forget and retain losses. Experimental results on benchmark datasets such as WMDP-Cyber, WMDP-Bio, and PKU-SafeRLHF, using Zephyr-7B and LLaMA2-7B models, demonstrate that CLUE achieves superior forgetting efficacy and retain utility while modifying significantly fewer parameters than previous methods like GA, NPO, PO, MEMIT, DEPN, and WAGLE."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Clear theoretical grounding and stepwise formulation (Eq. 1‚Äì6).\nComprehensive experiments across tasks and metrics (1-Acc, MIA, ROUGE-L).\nDetailed ablations isolating the effect of forget/conflict masks and finetuning strategies.\nInsightful analysis of sparsity vs. faithfulness (Fig. 4) and neuron-type shifts post unlearning (Table 3).\nPublic anonymized code and strong reproducibility statement."}, "weaknesses": {"value": "Circuits are treated statically; dynamic updates during finetuning could better reflect neuron shifts.\nComputational overhead of SAT solving and circuit extraction is not benchmarked.\nLimited discussion on scaling to models > 7 B parameters.\nRetain set selection sensitivity deserves deeper analysis (beyond Figure 3 trends).\nLanguage polishing could improve readability."}, "questions": {"value": "For multiple retain sets, could a multi-objective SAT formulation handle overlapping conflicts more gracefully?\nIs there a failure case where CNF becomes unsatisfiable for large overlapping circuits, and how is it handled?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "Hsb9eoyytX", "forum": "jtRYvazBWv", "replyto": "jtRYvazBWv", "signatures": ["ICLR.cc/2026/Conference/Submission188/Reviewer_tdd5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission188/Reviewer_tdd5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission188/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761470112923, "cdate": 1761470112923, "tmdate": 1762915465601, "mdate": 1762915465601, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the limitation of localization-based methods for LLM unlearning, and proposes a new method called CLUE. CLUE leverages an existing mechanistic interpretability method to achieve more precise unlearning without over-forgetting. Extensive experiments confirm that CLUE achieves superior performance on standard benchmarks and metrics."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors provide code, which enhances the reproducibility of the work.\n2. Extensive experiments and baseline comparisons are conducted to demonstrate the effectiveness of CLUE across multiple benchmarks.\n3. The proposed method leverages a circuit discovery tool, which improves the interpretability of the LLM unlearning process."}, "weaknesses": {"value": "1. **Introduction to prior works is not enough.** A detailed introduction to circuit discovery algorithms and brief introduction to Tseytin transformation should be provided to make the paper self-contained.\n2. **Generality of the proposed method is unclear.** As mentioned at the bottom of the p.5, fine-tuning affects the circuits of the model. This affects the generality of the proposed method. Does CLUE require rerunning circuit discovery after every fine-tuning step? This computational overhead needs to be discussed in the limitation section.\n3. **Highly dependent on the quality of the circuit discovery algorithm.** CLUE‚Äôs performance is tightly coupled with the quality of the underlying circuit discovery algorithm (e.g., Edge-Pruning used in the paper). If Edge-Pruning fails to generate meaningful or accurate circuits, the effectiveness of CLUE is questioned."}, "questions": {"value": "1. As mentioned in Section 3.1, the circuit discovery algorithm extracts the **forget circuit** and **retain circuit**. However, it is unclear how the algorithm finds the forget and retain circuits, and how to distinguish them. Further explanations are needed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "A3oIzhYFJQ", "forum": "jtRYvazBWv", "replyto": "jtRYvazBWv", "signatures": ["ICLR.cc/2026/Conference/Submission188/Reviewer_VCVn"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission188/Reviewer_VCVn"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission188/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761491428153, "cdate": 1761491428153, "tmdate": 1762915465284, "mdate": 1762915465284, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new categorization of neurons that could benefit downstream neuron-based unlearning methods. The desiderata include forgetting as much harmful information as possible while retaining as much non-harmful information as possible. The authors use a method inspired by contemporary circuit-discovery methods to identify three types of neurons: forget neurons (related to the targeted forgetting information), retain neurons (corresponding to the expression of retained information), and conflict neurons (involved in expressing both). They then propose a new two-step unlearning method that (1) edits the forget neurons to erase the unwanted information and (2) fine-tunes the conflict neurons to remove the targeted information while strengthening the retained information.\n\nOverall, the method performs well across all major benchmarks. Unfortunately, the paper is not very well written. Many of the concepts are not clearly explained, and the paper contains numerous typos and errors. Most importantly, the paper has a major conflict in attempting to connect circuit discovery with neuron-based unlearning approaches, as circuit discovery identifies circuits of components rather than individual neurons. See the weakness section for more information."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- **Good performance**: The method performs reasonably well across standard benchmarks, showing that it can be applied successfully in practice.\n- **Interesting categorisation of neurons**: The proposed division into forget, retain, and conflict neurons is conceptually distinct and could help clarify certain aspects of unlearning."}, "weaknesses": {"value": "### **Neurons vs. Components**\nA major issue of the paper is the careless use of the terms neuron and component. In short, circuit discovery methods find circuits of model components (input/output nodes, attention heads, MLPs). Each of these components contains many neurons. The interface between model components and neurons is not trivial, especially given previous work on unlearning that focuses on MLP neurons. What exactly do you mean by a circuit of ‚Äúneurons‚Äù? Do you count every neuron in the components that make up the circuit as such, or do you do something different?\n\nFor example, the following sentence suggests that circuit discovery methods find a circuit of neurons, which is clearly not the case:\n>  The circuit extracted from the forget set‚Äîthe forget circuit (Cf)‚Äîcontains all neurons and activation connections required for the model to\nproduce original responses that are harmful\n\nThe authors need a thorough and clear review of their description and usage of neuron, component, and circuit terminology. This is not a minor nitpick, as these terms lie at the very centre of the paper. The incorrect use of terminology makes it really hard to precisely understand what the authors are doing.\n\n### **Writing and Typos**\nUnfortunately, the paper is not very well written. The key terms are not selected well. For example, the authors use the term ‚Äúconflict‚Äù to refer to neurons that serve both the forget and retain sets. This is not a conflict, as conflict suggests an opposition or inconsistency between two objectives, whereas these neurons simply participate in representing both. A clearer and more precise term would help avoid confusion and make the intended mechanism easier to understand.\n\nFurthermore, the paper is also littered with typos and errors. To name a few:\n- Line 046: ... ents (**Wu et al.**; Yu et al., 2023). *The citation entry doesn't have a year. Although the paper is from ICLR 2023.*\n- Line 047: ... (**Patil et al.**;. ... *The same problem appear across multiple places in the paper.*\n- Line 132: task-relevant behavior **( or** mechanism/capability) ... *Extra leading space in brackets.*\n\nAs such, I think the paper needs some major revisions. It seems like an unfinished manuscript not ready to be accepted into a conference."}, "questions": {"value": "Pleas see the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CvKPp64ev9", "forum": "jtRYvazBWv", "replyto": "jtRYvazBWv", "signatures": ["ICLR.cc/2026/Conference/Submission188/Reviewer_PHgS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission188/Reviewer_PHgS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission188/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762224711717, "cdate": 1762224711717, "tmdate": 1762915465126, "mdate": 1762915465126, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new categorization of neurons that could benefit downstream neuron-based unlearning methods. The desiderata include forgetting as much harmful information as possible while retaining as much non-harmful information as possible. The authors use a method inspired by contemporary circuit-discovery methods to identify three types of neurons: forget neurons (related to the targeted forgetting information), retain neurons (corresponding to the expression of retained information), and conflict neurons (involved in expressing both). They then propose a new two-step unlearning method that (1) edits the forget neurons to erase the unwanted information and (2) fine-tunes the conflict neurons to remove the targeted information while strengthening the retained information.\n\nOverall, the method performs well across all major benchmarks. Unfortunately, the paper is not very well written. Many of the concepts are not clearly explained, and the paper contains numerous typos and errors. Most importantly, the paper has a major conflict in attempting to connect circuit discovery with neuron-based unlearning approaches, as circuit discovery identifies circuits of components rather than individual neurons. See the weakness section for more information."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- **Good performance**: The method performs reasonably well across standard benchmarks, showing that it can be applied successfully in practice.\n- **Interesting categorisation of neurons**: The proposed division into forget, retain, and conflict neurons is conceptually distinct and could help clarify certain aspects of unlearning."}, "weaknesses": {"value": "### **Neurons vs. Components**\nA major issue of the paper is the careless use of the terms neuron and component. In short, circuit discovery methods find circuits of model components (input/output nodes, attention heads, MLPs). Each of these components contains many neurons. The interface between model components and neurons is not trivial, especially given previous work on unlearning that focuses on MLP neurons. What exactly do you mean by a circuit of ‚Äúneurons‚Äù? Do you count every neuron in the components that make up the circuit as such, or do you do something different?\n\nFor example, the following sentence suggests that circuit discovery methods find a circuit of neurons, which is clearly not the case:\n>  The circuit extracted from the forget set‚Äîthe forget circuit (Cf)‚Äîcontains all neurons and activation connections required for the model to\nproduce original responses that are harmful\n\nThe authors need a thorough and clear review of their description and usage of neuron, component, and circuit terminology. This is not a minor nitpick, as these terms lie at the very centre of the paper. The incorrect use of terminology makes it really hard to precisely understand what the authors are doing.\n\n### **Writing and Typos**\nUnfortunately, the paper is not very well written. The key terms are not selected well. For example, the authors use the term ‚Äúconflict‚Äù to refer to neurons that serve both the forget and retain sets. This is not a conflict, as conflict suggests an opposition or inconsistency between two objectives, whereas these neurons simply participate in representing both. A clearer and more precise term would help avoid confusion and make the intended mechanism easier to understand.\n\nFurthermore, the paper is also littered with typos and errors. To name a few:\n- Line 046: ... ents (**Wu et al.**; Yu et al., 2023). *The citation entry doesn't have a year. Although the paper is from ICLR 2023.*\n- Line 047: ... (**Patil et al.**;. ... *The same problem appear across multiple places in the paper.*\n- Line 132: task-relevant behavior **( or** mechanism/capability) ... *Extra leading space in brackets.*\n\nAs such, I think the paper needs some major revisions. It seems like an unfinished manuscript not ready to be accepted into a conference."}, "questions": {"value": "Pleas see the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "CvKPp64ev9", "forum": "jtRYvazBWv", "replyto": "jtRYvazBWv", "signatures": ["ICLR.cc/2026/Conference/Submission188/Reviewer_PHgS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission188/Reviewer_PHgS"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission188/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762224711717, "cdate": 1762224711717, "tmdate": 1763135794006, "mdate": 1763135794006, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}