{"id": "k5h29Qv7GN", "number": 4237, "cdate": 1757644798906, "mdate": 1759898044365, "content": {"title": "ForesightKV: Optimizing KV Cache Eviction for Reasoning Models by Learning Long-Term Contribution", "abstract": "Recently, large language models (LLMs) have shown remarkable reasoning abilities by producing long reasoning traces. However, as the sequence length grows, the key-value (KV) cache expands linearly, incurring significant memory and computation costs. Existing cache eviction methods mitigate this issue by discarding less important KV pairs, but often fail to capture complex KV dependencies, resulting in performance degradation. To better balance efficiency and performance, we introduce ForesightKV, a training-based KV cache eviction framework that learns to predict which KV pairs to evict during long-text generations. We first design the Golden Eviction algorithm, which identifies the optimal eviction KV pairs at each step using future attention scores. These traces and the scores at each step are then distilled via supervised training with a Pairwise Ranking Loss. Furthermore, we formulate cache eviction as a Markov Decision Process and apply the GRPO algorithm to mitigate the significant language modeling loss increase on low-entropy tokens.  Experiments on AIME2024 and AIME2025 benchmarks with Qwen3-1.7B and Qwen3-4B demonstrate that ForesightKV consistently outperforms prior methods under only half the cache budget, while benefiting synergistically from both supervised and reinforcement learning approaches.", "tldr": "We propose ForesightKV, a training-based KV cache eviction method for long-context reasoning tasks, which consists of supervised training and reinforcment learning.", "keywords": ["KV cache eviction", "long-context reasoning", "reinforcement learning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8481fbbf01200591add0d7beca06818268d70d9c.pdf", "supplementary_material": "/attachment/83b3fb008b3fd1b4ea76dcf0aec203ed94697217.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose an effective KV cache compression method to address memory and computational challenges in long-sequence generation scenarios. The approach relies on a two-stage training framework to obtain a scorer model that can accurately predict the importance of KV cache entries. This method achieves significant performance improvements on the AIME24 and AIME25 datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The proposed two-stage training framework effectively addresses the KV Cache compression problem in long-sequence generation, resulting in improved accuracy.\n- The achieved performance improvements are notable and consistently stable across the reported settings."}, "weaknesses": {"value": "- The work lacks evaluation on larger models and architectures beyond the Qwen family, which is necessary to verify the consistency and generalizability of the results.\n- The experimental evaluation is limited to AIME24 and AIME25. A broader range of tasks, e.g., question answering, code generation, and summarization, should be assessed to demonstrate robustness."}, "questions": {"value": "- Is the trained scorer model used for head-wise selection of the KV cache tokens?\n- Can the authors provide evidence or a dedicated experiment to demonstrate that the proposed method effectively solves the problem illustrated in Figure 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4kJoVySc1W", "forum": "k5h29Qv7GN", "replyto": "k5h29Qv7GN", "signatures": ["ICLR.cc/2026/Conference/Submission4237/Reviewer_nPNm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4237/Reviewer_nPNm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761027848045, "cdate": 1761027848045, "tmdate": 1762917248135, "mdate": 1762917248135, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce a training-based KV cache eviction framework to accurately predict KV cache importance, thereby enhancing the quality of cache compression. The method shows a notable advantage when applied to the Qwen-1.5B and Qwen-4B model."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The experimental is well-designed, and the ablation studies are well-considered.\n- The paper is easy to follow."}, "weaknesses": {"value": "- In the efficiency evaluation, the authors compress sequence lengths from 16K and 32K to 1K and 2K, achieving substantial efficiency gains through extremely high compression ratios. Notably, even on AIME 24 and AIME 25, where the average length is under 16K, the method incurs significant accuracy drops when the KV budget is limited to 1K, with accuracy losses exceeding 40% in some cases. Thus, such aggressive compression may be impractical in real-world scenarios, limiting the practical applicability of the findings.\n\n- The experiments were conducted only on very small-scale Qwen models with fewer than 4B parameters. The effectiveness of the proposed method on other architectures and larger-scale LLMs requires further validation.\n\n- The evaluation datasets are overly limited. AIME 24 and AIME 25 contain only a small number of samples and are both restricted to mathematical reasoning tasks. Following common practice in this field, the authors should evaluate the effectiveness of their method on a broader range of tasks, such as those in LongBench.\n\n- A comparison with other KV cache optimization methods (e.g., DuoAttention) is necessary to establish the relative merit of the proposed approach."}, "questions": {"value": "- Can the authors report end-to-end speedup results across different datasets? Additionally, the authors should report throughput improvements under more practical compression ratios, such as compressing from 8K to 4K.\n\n- What is the motivation for incorporating a pooling operation? Specifically, why is mean pooling followed by max pooling chosen in the design (Figure 2)?\n\n- In Table 5, why are the MCB metrics identical for the Full Cache baseline and ForesightKV-2K at 16K generation length?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TrV5nKL6tj", "forum": "k5h29Qv7GN", "replyto": "k5h29Qv7GN", "signatures": ["ICLR.cc/2026/Conference/Submission4237/Reviewer_ewCC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4237/Reviewer_ewCC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761700323637, "cdate": 1761700323637, "tmdate": 1762917247814, "mdate": 1762917247814, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ForesightKV, a two-stage KV cache eviction method for long-context generation. A lightweight scoring model is trained via 1) supervised pairwise ranking using future attention–based “Golden Eviction” labels and 2) GRPO-style reinforcement learning to reduce loss spikes on low-entropy tokens. Evaluations on Qwen3-1.7B and Qwen3-4B and AIME benchmarks show higher pass@1 under limited KV budgets and throughput gain."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Prior eviction work focuses on heuristics; this paper introduces a learned scoring policy.\n2. Empirical attention visualizations provide qualitative motivation.\n3. Parameter efficient training with smaller scorer, backbone LLM remains frozen.\n4. Throughput and batch-size improvements are convincing."}, "weaknesses": {"value": "1. All experiments focus on math reasoning (AIME), and the scorer is trained on reasoning traces from STILL-like data. This raises serious concerns about domain overfitting and limits claims of generality.\n2. KV eviction is most relevant when serving >7B parameters. It is unclear whether attention patterns and eviction policies scale.\n3. The RL reward specifically penalizes spikes on low-entropy symbolic tokens. This may not generalize to summarization, code.\n4. Many practical workloads require reading long documents, not only generating long reasoning traces.\n5. Throughput improves due to smaller active KV, but scoring overhead is not separately profiled."}, "questions": {"value": "1. Isn’t the Golden Eviction label construction itself biased by the model being evaluated?\n2. How does this method behave on long inputs instead of long outputs?\n3. How does this interact with FlashAttention-style kernel fusion?\n4. Why low-entropy tokens specifically? This may be task-domain specific (math, symbolic reasoning)\n5. Do the learned policies generalize across models with different attention scaling behaviors (7B vs 70B)\n6. Were the baseline methods tuned equivalently for long generation outputs? SnapKV was originally designed for long inputs. We should compare to some reasoning path compression baselines, such as Reasoning Path Compression (RPC) https://arxiv.org/abs/2505.13866"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PfRejHARHU", "forum": "k5h29Qv7GN", "replyto": "k5h29Qv7GN", "signatures": ["ICLR.cc/2026/Conference/Submission4237/Reviewer_QH1s"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4237/Reviewer_QH1s"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761854838853, "cdate": 1761854838853, "tmdate": 1762917246786, "mdate": 1762917246786, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The idea of learning a KV-eviction policy is good, and the motivation for handling long context reasoning with dynamic KV importance is clear. The basic intuition that attention patterns shift and some tokens become important later makes sense, and the results on AIME show improvement, and the performance gains look reasonable.\n\nHowever, the work is tied to math reasoning. The reward design and the low-entropy token focus seem to rely on math traces, where errors are clean and easy to detect. I was curious whether the main reason AIME is used is to make the system easier to train. If so, it raises questions about how well the method generalizes to other tasks.\n\nBecause this is a training-based method, transparency on the process matters, but many training details are not clearly explained. It is not obvious how many examples were used, how the “correct long reasoning trace” filtering works, how expensive the Golden Eviction step is, or how much tuning was needed to stabilize the RL phase. These steps look non-trivial, and right now it is hard to know how reproducible or practical the full pipeline is.\n\nOverall, the results are promising for math reasoning, and the high-level idea is interesting. It would help the paper if it clarified the training pipeline more thoroughly and discussed how the method might extend beyond math, or what would be required to adapt the reward and supervision signals to other domains."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "Clear motivation, meaningful gains on math reasoning, smart use of future attention and RL, and a promising results for learned memory over heuristic KV strategies."}, "weaknesses": {"value": "Heavy reliance on math-specific reward signals, unclear generalization to other tasks, and missing training details that limit reproducibility and practical adoption."}, "questions": {"value": "1. How does the approach generalize beyond math reasoning tasks where correctness and low-entropy signals are easy to define?\n\n2. What would the reward function look like for dialogue, long-form QA, or code generation, where “important tokens” are harder to identify?\n\n3. How many training samples and reasoning traces were used, and how were they filtered in practice?\n\n4. What is the exact cost and procedure for generating the “Golden Eviction” oracle labels at scale?\n\n5. How stable is the RL training stage, and what tuning was required to make it work?\n\n6. Does the method still provide meaningful gains when applied to diverse long-context tasks rather than only AIME-style benchmarks?\n\n7. What is the inference-time overhead of running the scorer network, and how does it compare to simpler heuristics at scale?\n\n8. Could the scoring policy be integrated into the base model during training rather than as an external module?\n\n9. If the method is applied to models with different architectures or training distributions, does the eviction policy still transfer?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VnHfHnuPSv", "forum": "k5h29Qv7GN", "replyto": "k5h29Qv7GN", "signatures": ["ICLR.cc/2026/Conference/Submission4237/Reviewer_nXgV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4237/Reviewer_nXgV"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4237/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761996652871, "cdate": 1761996652871, "tmdate": 1762917243695, "mdate": 1762917243695, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}