{"id": "3CLscEAR9X", "number": 10112, "cdate": 1758161017609, "mdate": 1759897673021, "content": {"title": "ArtAug: Iterative Enhancement of Text-to-Image Models via Synthesis–Understanding Interaction", "abstract": "The emergence of diffusion models has significantly advanced image synthesis. Recent studies of model interaction and self-corrective reasoning approaches in large language models offer new insights for enhancing text-to-image models. Inspired by these studies, we propose a novel method called ArtAug for enhancing text-to-image models via model interactions with understanding models. In the interactions, we leverage human preferences implicitly learned by image understanding models to provide fine-grained suggestions for image generation models. The interactions can modify the image content to make it aesthetically pleasing, such as adjusting exposure, changing shooting angles, and adding atmospheric effects. The enhancements brought by the interaction are iteratively fused into the generation model itself through an additional enhancement module. This enables the generation model to produce aesthetically pleasing images directly with no additional inference cost. In the experiments, we verify the effectiveness of ArtAug on advanced models such as FLUX, Stable Diffusion 3.5 and Qwen2-VL, with extensive evaluations in metrics of image quality, human evaluation, and ethics. The source code and models will be released publicly.", "tldr": "A paper on enhancement methods for text-to-image models.", "keywords": ["Diffusion models", "alignment", "image synthesis"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/562f63dc57807b6550638be43dec84b217e9a0ca.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces ArtAug, a novel framework for iteratively enhancing the aesthetic quality of text-to-image models without relying on extensive human annotation. The core contribution is a \"synthesis-understanding\" loop where a powerful multimodal language model (MLLM) acts as an \"AI Art Director,\" providing fine-grained, region-specific textual suggestions to improve an initially generated image. These suggestions are used to create an enhanced version, forming a high-quality pairwise dataset of (original, enhanced) images. The authors then propose a differential LoRA training method to distill this aesthetic improvement into a compact module that is fused back into the base model. This process is iterated to progressively refine the model's generative capabilities, demonstrably improving aesthetic scores and human preferences on strong baselines like FLUX and Stable Diffusion 3.5 without adding any inference cost."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.   The paper provides extensive and compelling qualitative visualizations. The side-by-side comparisons of images before and after applying ArtAug (e.g., in Figures 1, 5, and 6) clearly and intuitively demonstrate the significant aesthetic improvements, providing strong visual evidence for the method's effectiveness.\n2.  The core idea of creating a \"synthesis-understanding\" loop by coupling a generation model with an understanding model is novel and insightful. It's good to see the understanding MLLM model can achieve an aesthetic similar to that of humans.\n3.  The proposed differential training mechanism using two separate LoRA modules is a clever and effective technical choice. By first anchoring the model to the original image with one LoRA and then learning only the aesthetic \"delta\" with a second, the method effectively disentangles reconstruction from enhancement, which likely leads to more stable and targeted training.\n4.  The analysis presented in Figure 3 shows a consistent and promising trend of improvement across multiple iterations. The framework does not appear to suffer from an immediate performance bottleneck, suggesting its potential for sustained and progressive enhancement of the base model's capabilities.\n5. The paper is well-written and clearly organized. The methodology is presented in a logical, step-by-step fashion that makes the entire framework easy to understand and follow."}, "weaknesses": {"value": "1.   the presented results are positive, the experimental validation lacks depth. The paper would be significantly stronger with a more comprehensive analysis, including:\n    1)  **Comparisons to SOTA Alignment Methods:** The work is framed as an alternative to alignment training like DPO or RLHF. However, there are no direct comparisons to models fine-tuned with these methods, making it difficult to gauge the relative effectiveness and trade-offs of ArtAug.\n    2)  **Ablation Studies:** Key design choices are not validated. For instance, the impact of the chosen MLLM on the quality of suggestions is critical but only briefly discussed in the appendix. An ablation on the number of generated image pairs (5k initial pairs seems relatively small) and its correlation with performance gains would be crucial to substantiate the claim of scalability.\n2.   There is a noticeable gap between the striking improvements shown in the qualitative figures and the more modest results from the human evaluation (Table 3). The win rates of ~46% and ~51% are only slightly better than the baseline, which raises questions about whether the visualized examples are cherry-picked or if the aggregate improvement is less significant than implied.\n3.   The paper correctly states that the final model has no inference overhead. However, the iterative training process itself—involving generation, MLLM-based refinement, filtering, and differential training—is computationally intensive. While this is likely cheaper than large-scale human annotation, the modest quantitative gains from human evaluation challenge the overall cost-benefit trade-off of this complex pipeline. A more detailed analysis of the training cost versus the achieved improvement would be beneficial.\n4.  The manuscript contains several typographical errors (e.g., \"EVALUIATION\" in the heading for Section 4.1.5) that detract from its overall polish. A thorough proofreading is recommended to improve the presentation quality.\n5. This paper lacks REPRODUCIBILITY STATEMENT and THE USE OF LLMS"}, "questions": {"value": "1. The paper positions ArtAug as a scalable alternative to human-feedback-based alignment methods like DPO and RLHF. However, the experiments lack a direct comparison. Could you provide any quantitative results, even on a smaller scale, comparing a model enhanced with ArtAug against a similarly-sized model fine-tuned with a public preference dataset (e.g., Pick-a-Pic)?\n2. The choice of Qwen2-VL-72B as the understanding model seems critical to the success of the pipeline.\nHow sensitive is the quality of the generated data to the specific MLLM used? For instance, what would be the impact of using a smaller open-source model or a more powerful closed-API model like GPT-4o? Could you also elaborate on the failure modes of this interaction? What happens if the MLLM provides nonsensical or aesthetically poor suggestions, and how effectively does your filtering process (aesthetic score, CLIP similarity, manual review) mitigate this?\n3. The experiments generate 5k initial pairs per iteration, which are filtered down to a small training set (1-2%). This number seems relatively low for training large models. Could you provide any analysis on the relationship between the number of generated pairs and the performance improvement?\n4. There appears to be a disconnect between the dramatic improvements shown in the qualitative figures and the more modest win rates in the human evaluation (Table 3), where ArtAug is only marginally preferred over the baseline. Can you comment on this discrepancy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lBRj8wJyoC", "forum": "3CLscEAR9X", "replyto": "3CLscEAR9X", "signatures": ["ICLR.cc/2026/Conference/Submission10112/Reviewer_TemC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10112/Reviewer_TemC"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10112/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761024354613, "cdate": 1761024354613, "tmdate": 1762921491492, "mdate": 1762921491492, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ArtAug, a new framework that enhances text-to-image diffusion models via synthesis-understanding interaction. ArtAug introduces an interactive mechanism between a generation module and an understanding module. These interactions produce enhanced image pairs, which are then used for differential LoRA training, enabling the model to internalize the improvements without additional inference cost. Experimental results on FLUX.1[dev] show consistent improvements across aesthetic metrics and human evaluations, while maintaining text-image alignment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper introduces a new paradigm for improving generative models through cross-model interaction between synthesis and understanding. \n\nThe paper is well-written and easy to follow."}, "weaknesses": {"value": "- Maybe introducing some new metrics would make the evaluation session stronger and more convincing. Consider FID or other metric for high-quality generated model like Flux and SD 3.5 (Enhancing Reward Models for High-quality Image Generation: Beyond Text-Image Alignment, ICCV 2025) maybe would help.\n\n\n- The related work section could be enhanced by incorporating recent works in enhancement of text-to-image models:\n\n\n[1] Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs. ICML 2024\n\n[2] Dynamic Prompt Optimizing for Text-to-Image Generation. CVPR 2024\n\n[3] Optimizing Prompts for Text-to-Image Generation. NeurIPS 2023"}, "questions": {"value": "What is the computational cost and time cost of generating the interactive pairs, and how does it scale with prompt complexity?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uGpPRdJHqD", "forum": "3CLscEAR9X", "replyto": "3CLscEAR9X", "signatures": ["ICLR.cc/2026/Conference/Submission10112/Reviewer_YUYD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10112/Reviewer_YUYD"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10112/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976089611, "cdate": 1761976089611, "tmdate": 1762921491038, "mdate": 1762921491038, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes ArtAug, a synthesis–understanding interaction framework that uses a multimodal VLM (“AI art director”) to suggest fine-grained, region-conditioned edits to an image generated by a text-to-image model, then distills those improvements back into the generator via a differential LoRA “enhancement module.” The pipeline iterates: generate, understand, refine, construct image pairs, filter, and train differential LoRA, progressively improving aesthetics without extra inference cost at test time. Experiments on FLUX.1[dev] and Stable Diffusion 3.5 report consistent gains on aesthetic/CLIP and multiple preference metrics, plus a double-blind human study and a small ethics check."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Writing and structure. The paper is easy to follow; the problem setting, modules (generation, understanding, enhancement), and the iterative loop are clearly laid out with an informative figure and concise pseudo-code. \n\n2. Practical, well-motivated method with diverse evaluation. The differential LoRA design that learns only the delta between original and refined images is simple and pragmatic; the study includes basic metrics, several preference models, a double-blind human comparison, and an ethics sanity-check—together suggesting the gains are not metric-specific."}, "weaknesses": {"value": "1. Although results are shown on FLUX.1[dev] and SD-3.5, the study would be stronger with additional architectures and with side-by-side comparisons against established alignment methods or prompt/data-refinement baselines under the same prompts and budgets.\n\n2. No comparison with other text–image alignment and aesthetics methods. The paper primarily compares “base vs. base+ArtAug”; adding head-to-head numbers against recent aesthetics/alignment enhancers and reporting statistical significance for human studies would better support the claim of improved alignment and appeal."}, "questions": {"value": "Please see the weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "JYPMqyaM4o", "forum": "3CLscEAR9X", "replyto": "3CLscEAR9X", "signatures": ["ICLR.cc/2026/Conference/Submission10112/Reviewer_M9ao"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10112/Reviewer_M9ao"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10112/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761987721678, "cdate": 1761987721678, "tmdate": 1762921490679, "mdate": 1762921490679, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Inspired by the recent studies of model interaction and self-corrective reasoning, this paper proposes ArtAug, which is a method for enhancing text-to-image models in terms of image quality and human preference. ArtAug leverages image understanding models to provide fine-grained suggestions for image generation models, and the interaction results can be fused back to the model itself through an additional enhancement module. Experimental results show that ArtAug can enhance existing text-to-image models to generate high-quality, aesthetically pleasing images."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Differential Training Method: The proposed differential training methods is interesting and provide steady improvements through multiple iterations. Experimental results in section 4.2 show that the aesthetic score, CLIP score, and similarity are steadily improved throughout the iterations.\n- Case Studies: By presenting numerous before-and-after image comparisons, they provide a straightforward and immediate impression of the practical effects of ArtAug.\n- Clarity of Presentation: The paper is well-organized. The overview of the ArtAug framework in Figure 2 is particularly effective, offering an intuitive and comprehensive illustration of the entire multi-stage pipeline."}, "weaknesses": {"value": "- Insufficient Experimental Comparisons: The experiments show that Base Model + ArtAug outperforms the Base Model. However, they lack baseline methods, which is a crucial component in experiments. The paper introduction claims that the existing three types of methods such as prompt engineering and alignment training have their \"certain limitations\", but the paper provides no direct empirical evidence to support this. To properly situate ArtAug's contribution, it should be benchmarked against these alternatives.\n- Insufficient Discussion of Related Work: Section 2.2, \"Aligning Models with Human Preferences,\" focuses almost on DPO methods that only learn the diffusion model weights. This narrows the scope of \"Aligning Models with Human Preferences\". For example, many recent studies aligning models with human preference by learning an isolate model outside the diffusion model with reinforcement learning such as Parrot [1]. A broader discussion of methods for alignment with human preferences is necessary.\n\n[1] Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for Text-to-Image Generation"}, "questions": {"value": "How does ArtAug address the \"certain limitations\" of existing text-to-image methods? With many recent works continuously advancing this field, could you please provide evidence on the unique advantages of ArtAug?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "7d5GHfTHbh", "forum": "3CLscEAR9X", "replyto": "3CLscEAR9X", "signatures": ["ICLR.cc/2026/Conference/Submission10112/Reviewer_seWm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10112/Reviewer_seWm"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10112/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762148592289, "cdate": 1762148592289, "tmdate": 1762921490293, "mdate": 1762921490293, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}