{"id": "OQOmOIIX9F", "number": 8430, "cdate": 1758082981131, "mdate": 1759897784465, "content": {"title": "SeRI: Gradient-Free Sensitive Region Identification in Decision-Based Black-Box Attacks", "abstract": "Deep neural networks (DNNs) are highly vulnerable to adversarial attacks, where small, carefully crafted perturbations are added to input images to cause misclassification. These perturbations are particularly effective when concentrated in sensitive regions of an image that strongly influence the model’s prediction. However, in decision-based black-box settings, where only the top-1 predicted label is observable and query budgets are strictly limited, identifying sensitive regions becomes extremely challenging. This issue is critical because without accurate region information, decision-based attacks cannot refine adversarial examples effectively, limiting both their efficiency and accuracy.\nWe propose Sensitive Region Identification, SeRI, the first decision-based method that assigns a continuous sensitivity score to each image pixel. It enables fine-grained region discovery and substantially improves the efficiency of adversarial attacks, all without access to gradients, confidence scores, or surrogate models.\nSeRI progressively partitions the image into finer sub-regions and refines a continuous sensitivity score to capture their true importance. At each iteration, it generates two perturbation variants of the selected region by scaling its magnitude up or down, and compares their decision boundaries to derive an accurate, continuous characterization of pixel sensitivity.\nSeRI further divides selected region into smaller sub-regions, recursively refining the search for sensitive areas. This recursive refinement process enables more precise sensitivity estimation through fine-grained analysis, distinguishing SeRI from prior binary or one-shot region selection approaches. Experiments on two benchmark datasets show that SeRI significantly enhances state-of-the-art decision-based attacks in both targeted and non-targeted attack scenarios. Additionally, SeRI generates precise heatmaps that identify sensitive image regions. The code is available at https://anonymous.4open.science/r/SeRI-5310.", "tldr": "This paper presents a novel Sensitive Region Identification approach, SeRI, that efficiently enhance adversarial perturbations based on sensitive region identification in decision-based attacks.", "keywords": ["Machine learning", "AI safety", "Decision-based adversarial attacks", "Sensitive region"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/676fdeac07141f722fe3f915be91bea392609f4a.pdf", "supplementary_material": "/attachment/f0f06c208f5bd4607da8a8e5c939283774f42fc9.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Sensitive Region Identification (SeRI) for query-efficient decision-based adversarial attack. \nIt iteratively identifies sensitive regions through recursive splitting, and enhances the adversarial perturbation by scaling sub-regions based on decision boundary of the victim model. \nThe key claim is that the authors redefined the term 'sensitive region' in terms of continuous score, improving query-efficiency and interpretability. \nSeRI is easily plugged into existing adversarial attack methods such as HSJA, CGBA, RayS, and ADBA, consistently improving l2 perturbation norms under restricted query budget."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Well-motivated problem statement. The paper addresses a legitimate and well-defined challenge in decision-based black-box attacks - identifying sensitive image regions when only top-1 labels are available under strict query budgets.\n2. Clear mathematical formulation. The problem is formally and coherently defined through a continuous sensitivity optimization framework (Eq. 5), with explicit constraints and variables, making the proposed objective easy to follow.\n3. Method is intuitively connected to the problem. The proposed iterative region-splitting and perturbation-scaling mechanism directly reflects the intuition that different image areas contribute unequally to model decisions, leading to a natural algorithmic design.\n4. Mathematical convergence argument. Although limited in scope, the paper provides a formal statement (Appendix A) showing that the multiplicative update process can approximate any target perturbation magnitude; however, this does not prove attack optimality or convergence under noisy query comparisons. \n5. Representative datasets and models. Experiments are conducted on standard and diverse benchmarks — ImageNet (VGG19, ViT) and CIFAR-100 (adversarially trained WideResNet) — which are widely accepted for evaluating adversarial attacks.\n6. Comprehensive set of baselines. The comparison covers multiple strong decision-based attacks (HSJA, CGBA, RayS, ADBA, and PAR), representing the state of the art across both $\\ell_2$ and $\\ell_\\infty$ norms.\n7. Consistent empirical improvements. Across all datasets, models, and query budgets, SeRI outperforms existing methods in terms of lower $\\ell_2$ perturbation norms and better query efficiency, demonstrating reliable performance gains."}, "weaknesses": {"value": "1. Lack of justification for boundary-based. The paper adopts a decision-boundary-driven optimization scheme but does not clearly argue why boundary comparison is preferable to simpler success/failure-based evaluation, or under what conditions it provides advantages. \n2. No proof of attackability or optimality. While a convergence argument is given for the multiplicative updates, there is no theoretical or empirical evidence that minimizing the approximate decision boundary $g(d)$ actually improves attack success or robustness - i.e., no proof of optimality.\n3. Missing discussion on architecture-dependent performance. The submitted code includes experiments on Inception-v3, where the attack success rate is noticeably lower and convergence is unstable compared to ResNet and ViT backbones. This discrepancy suggests that SeRI’s effectiveness may depend on the smoothness of the decision boundary, yet the paper does not mention or analyze this behavior. An explicit explanation of why SeRI fails or underperforms on Inception-like architectures is needed. \n4. Evaluation under stronger defenses is missing. The only defense tested is an adversarially trained WRN, which is relatively weak. Robustness against stochastic or randomized defenses (e.g., random smoothing, input transformation) should be tested. \n5. Lack of statistical reporting. The paper reports only averages and medians of $\\ell_2$ norms. However, standard deviation or inter-quartile ranges would better reflect query stability and robustness variability. \n6. Missing transferability evaluation. There is no experiment analyzing whether perturbations generated by SeRI transfer to unseen models, which would further validate the claim that SeRI captures model-agnostic sensitive regions. \n7. No discussion of limitations or failure cases. The paper lacks analysis of when SeRI fails or degrades - e.g., noisy decision boundaries, non-salient images, or low-budget attacks - and provides no insight into practical failure modes. \n8. Writing and presentation issues. The paper contains several grammatical and structural errors (e.g., duplicated phrases, inconsistent notation, and citation misuse), which hinder readability and reduce perceived rigor."}, "questions": {"value": "1.  The proof in Appendix A shows that multiplicative scaling can approximate any target magnitude, but does this imply convergence of the overall iterative optimization process under query noise or ADBA comparison errors? If not, what assumptions are required for such convergence to hold? \n2.  How does the proposed decision-boundary–based sensitivity differ conceptually from gradient or Jacobian-based sensitivity in white-box settings? Can it be shown that SeRI approximates those measures under some assumptions? \n3.  Could you provide a more detailed analysis of the query budget ratio $P$? Specifically, how does SeRI perform under extreme cases (base = 100%, SeRI = 0%, and vice versa)? Was 20% empirically optimal across all models or tuned per dataset? \n4.  Have you tried SeRI on non-classification tasks (e.g., segmentation, detection, or long-tailed settings)? If not, do you expect any fundamental obstacles? \n5.  How much wall-clock overhead does SeRI add per query compared to the base attacker? Is the improvement in query count offset by additional computation time? \n6.  Have you measured any quantitative correlation between SeRI’s heatmaps and gradient-based saliency maps?  If not, how do you justify the claim that the generated heatmaps improve interpretability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "gpaihu1fWn", "forum": "OQOmOIIX9F", "replyto": "OQOmOIIX9F", "signatures": ["ICLR.cc/2026/Conference/Submission8430/Reviewer_kXVd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8430/Reviewer_kXVd"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8430/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761532545269, "cdate": 1761532545269, "tmdate": 1762920323322, "mdate": 1762920323322, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on black-box adversarial attacks where the attacker has access only to the model’s predicted class labels. The goal is to find a perturbation with the minimal norm that leads the model to misclassify. The proposed method, Sensitive Region Identification (SeRI), recursively divides the input image into four square regions and prioritizes further subdivision of regions with larger perturbation norms, thereby achieving smaller overall perturbation norms. SeRI also facilitates the generation of heatmaps that indicate regions where the model is more sensitive to perturbations. The effectiveness of the proposed method is demonstrated through experiments on benchmark datasets."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The recursive partitioning of perturbation regions enables SeRI to produce more fine-grained heatmaps and achieve smaller perturbation norms compared to existing patch-based sensitive region-based attacks.\n\n- Experimental results on ImageNet and CIFAR100 show that combining SeRI with existing methods generally outperforms combinations with PAR, supporting the superiority of SeRI.\n\n- The paper is overall well-structured and easy to follow, with the exception of a few pseudocode details."}, "weaknesses": {"value": "- The discussion of prior work on sensitive region-based attacks is limited to only one study. The paper should also discuss and compare related methods such as HeadBeat [1] and Saliency Attack [2], which—despite differences such as the presence or absence of surrogate models—address similar goals.\n\n- Experiments on defense methods are limited. The evaluation does not include ImageNet-based experiments and only considers adversarial training (AT) as a defense. When focusing on $\\ell_2$ -norm attacks, there exist more suitable defense methods based on Lipschitz constants of the network for comparison [3,4], which is expected to be more robust.\n\n- The paper does not analyze how perturbation norms saturate with respect to computational resources. Providing insights into the number of queries required to construct the heatmap, and identifying how many queries make each method effective, would be valuable for readers.\n\n[1] G. Tao et al., Hard-label Black-box Universal Adversarial Patch Attack, 2023  \n[2] Z. Dai et al., Saliency Attack: Towards Imperceptible Black-box Adversarial Attack, 2023  \n[3] Y. Tsuzuku et al., Lipschitz-margin training: Scalable certification of perturbation invariance for deep neural networks, 2018  \n[4] A. Araujo et al., A Unified Algebraic Perspective on Lipschitz Neural Networks, 2023"}, "questions": {"value": "- What are the main reasons SeRI is expected to outperform other saliency estimation methods (excluding PAR)?\n\n- Does SeRI maintain its advantage when applied to clean models trained on CIFAR100 and robust models trained on ImageNet?\n\n- Could the authors provide approximate numbers of queries required for (a) heatmap generation, (b) achieving performance gains over other saliency-based methods, and (c) the point at which the perturbation norm saturates?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HcF6ZIrglu", "forum": "OQOmOIIX9F", "replyto": "OQOmOIIX9F", "signatures": ["ICLR.cc/2026/Conference/Submission8430/Reviewer_YrJv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8430/Reviewer_YrJv"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8430/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761719792808, "cdate": 1761719792808, "tmdate": 1762920322751, "mdate": 1762920322751, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a novel method, SeRI, for identifying sensitive regions in decision-based black-box adversarial attacks. The approach is innovative in its use of a continuous sensitivity score and recursive region partitioning, and it demonstrates strong empirical performance across multiple datasets and models. The work is practically useful and addresses a relevant problem in adversarial machine learning. However, while the technical contribution is clear, the academic rigor and scholarly depth of the paper could be significantly improved to meet the standards of a top-tier conference."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Novelty: The idea of using a continuous sensitivity score in a decision-based setting is novel and represents a meaningful advance over binary region-selection methods like PAR.\n\nEmpirical Validation: Extensive experiments on ImageNet and CIFAR-100 with multiple models and attack configurations demonstrate the effectiveness of SeRI.\n\nPracticality: The method is query-efficient and can be integrated as a plug-in module with existing attacks, which is a valuable feature for real-world scenarios.\n\nInterpretability: The generated heatmaps provide visual explanations of sensitive regions, enhancing the interpretability of the attack process."}, "weaknesses": {"value": "1. Lack of Theoretical Depth\nWhile the method is motivated intuitively and empirically validated, the theoretical foundation is underdeveloped. The proof in Appendix A, while correct, is limited to a simplified multiplicative update model and does not fully justify the convergence or optimality of the overall algorithm.\n\nThe paper would benefit from a more formal analysis of the convergence properties, sensitivity of the partitioning strategy, or robustness to model variations.\n\n2. Limited Comparison with Related Work\nThe comparison with PAR is thorough, but the paper does not sufficiently situate SeRI within the broader literature on interpretability methods (e.g., Grad-CAM, LIME, SHAP) or other region-based adversarial strategies beyond PAR.\n\nA deeper discussion of how SeRI relates to saliency detection or feature attribution methods would strengthen the scholarly contribution.\n\n3. Methodological Simplicity\nThe core algorithm—iterative partitioning and perturbation scaling—is conceptually straightforward. While this is a strength in terms of usability, it may also be perceived as lacking in algorithmic sophistication compared to some recent adversarial attack methods.\n\nThe paper does not explore alternative sensitivity formulations or adaptive partitioning strategies, which could have added depth.\n\n4. Evaluation Metrics and Generalizability\nThe evaluation is primarily based on l2 norm reduction and attack success rate. Additional metrics such as human perceptual studies, transferability, or robustness to defenses would provide a more comprehensive assessment."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "h0izdjlfJA", "forum": "OQOmOIIX9F", "replyto": "OQOmOIIX9F", "signatures": ["ICLR.cc/2026/Conference/Submission8430/Reviewer_tyNQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8430/Reviewer_tyNQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8430/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761895353005, "cdate": 1761895353005, "tmdate": 1762920322311, "mdate": 1762920322311, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a method for generating sensitivity regions (or heatmaps) in the context of black-box adversarial attacks. In essence, the authors extend the previous PAR (Patch-wise Adversarial Removal) method by transforming it from a discrete, patch-based approach into a continuous sensitivity estimation framework. This allows the model to more precisely identify which regions of an image are most influential to the prediction, thereby improving the efficiency and interpretability of black-box attacks."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper is clearly written and easy to follow. The authors provide a well-organized and thorough summary of related work, which helps the reader understand the motivation and context of their approach. Overall, the proposed SeRI framework, when combined with existing black-box attack methods, appears to perform well in terms of L2-norm improvements. The experimental results suggest that SeRI can enhance the efficiency of existing black-box attacks by producing smaller perturbations under the same query budget"}, "weaknesses": {"value": "The main contribution of the paper appears somewhat weak for two reasons.\n\n(1) The idea of constructing sensitivity region maps has already been introduced by the PAR method. Therefore, the novelty of this paper mainly lies in extending PAR from a discrete, patch-based formulation to a continuous sensitivity estimation framework. Given this, the additional components of SeRI—such as the use of ADBA—should provide more original or technically innovative ideas. Moreover, it seems that the core novelty of the work resides in the appendix, which feels somewhat misplaced.\n\n(2) Alternatively, the paper could strengthen its contribution through more comprehensive and convincing experimental evidence demonstrating a general improvement in black-box attacks. Currently, the results primarily focus on improvements in the L2 norm. Including evaluations based on attack success rate (ASR) or other complementary metrics that more clearly demonstrate the practical advantages of SeRI would make the contribution more substantial.\n\n(A list of specific questions will be provided in the Question section.)"}, "questions": {"value": "1. Have you measured attack success rate (ASR) or other metrics that could reflect the effectiveness of SeRI?\n\n2.Can you also compare SeRI with explainable AI (XAI) methods that produce sensitivity or saliency maps?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QsbCPLHBHr", "forum": "OQOmOIIX9F", "replyto": "OQOmOIIX9F", "signatures": ["ICLR.cc/2026/Conference/Submission8430/Reviewer_LU14"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8430/Reviewer_LU14"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8430/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965104892, "cdate": 1761965104892, "tmdate": 1762920322036, "mdate": 1762920322036, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}