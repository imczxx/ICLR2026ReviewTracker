{"id": "8H0TkSusWI", "number": 6719, "cdate": 1757993398961, "mdate": 1759897898821, "content": {"title": "NePTune: A Neuro-Pythonic Framework for Tunable Compositional Reasoning on Vision-Language", "abstract": "Modern Vision-Language Models (VLMs) have achieved impressive performance in various tasks, yet they often struggle with compositional reasoning, the ability to decompose and recombine concepts to solve novel problems. While neuro-symbolic approaches offer a promising direction, they are typically constrained by crisp logical execution or predefined predicates, which limit flexibility. In this work, we introduce NePTune, a neuro-symbolic framework that overcomes these limitations through a hybrid execution model that integrates the perception capabilities of foundation vision models with the compositional expressiveness of symbolic reasoning. NePTune dynamically translates natural language queries into executable Python programs that blend imperative control flow with soft logic operators capable of reasoning over VLM-generated uncertainty. Operating in a training-free manner, NePTune, with a modular design, decouples perception from reasoning, yet its differentiable operations support fine-tuning. We evaluate NePTune on multiple visual reasoning benchmarks and various domains, utilizing adversarial tests, and demonstrate a significant improvement over strong base models, as well as its effective compositional generalization and adaptation capabilities in novel environments.", "tldr": "", "keywords": ["Neuro-Symbolic", "Vision and Language", "Compositional Reasoning"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fd3dadd6ed0c3f89b7ece93dd893ea25e47cfc2a.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates integrating both the coding and perception abilities of foundation models within a near-symbolic framework to improve the reasoning failures of the foundation models alone. The authors propose a three stage processing pipeline including structured and targeted queries to VLMs which are integrated within code executions obtained from an LLM. The goal of the approach is to tackle zero-shot processing. The authors evaluate their Neptune approach on several, mainly CLEVR-based datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The topic of this work tackles many relevant aspects of current foundation models. The experimental evaluation is generally well structured and presented. The results show promising boosts particularly over the pure VLM/LLM baselines."}, "weaknesses": {"value": "Generally, I don't have any fundamental issues, just some information is missing and a little unclear. I think if the authors could clarify these/ integrate them into the paper, it would be easier to understand the contribution of the work.\n\nWhat I am definitely missing is a section specifying the exact model setups and high-level implementation information regarding Neptune, but also the baselines. I would place this before section 4.1. I.e. what models were used for the Neptune results? What models are being compared to? Currently all of this information is spread out, if at all, across section 4. \n\nThe authors provide good RQs in Section 4, however these are never referenced after being introduced. For improved readability I suggest to reference them within each experimental subsection.\n\nI am a little confused about which baselines are compared to for which evaluations. E.g. why is MDETR used in Table 5, but not for the evaluations for Table 3 or 4? Same goes for Naver.\n\nWhy don't the authors discuss and compare to older NeSy approaches such as [1]?\n\nI find the Discussion particularly around table 8 somewhat confusing. What are the authors trying to show? In my understanding the point is to show that the basic \"perception\" performance are quite high?\n\n[1] Yi, Kexin, et al. \"Neural-symbolic vqa: Disentangling reasoning from vision and language understanding.\" Advances in neural information processing systems 31 (2018)."}, "questions": {"value": "What exactly is a \"response\" in ll 236? \n\nHow does Neptune decide when to use a \"query\" \n\nWhat is the intuition/benefit of having soft compositional reasoning components? The authors seemed quite brief on this.\n\nI don't quite understand the intuition/explanation for the weaker \"query attribute\" and \"compare attribute\" results in table 3? Could the authors please elaborate on this?\n\nTab. 7 how is the VLM fine-tuned? What for is it fine-tuned?\n\nWhy not integrate table 9 with the other evaluations around RQ 1?\n\nWhat is the importance of repeatedly naming models end-to-end when they are not actually trained end-to-end for the evaluations in the paper? Moreover, if Neptune is based on these end-to-end models, also Neptune can profit from end-to-end pretraining."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "AZ3IgZqKkf", "forum": "8H0TkSusWI", "replyto": "8H0TkSusWI", "signatures": ["ICLR.cc/2026/Conference/Submission6719/Reviewer_vXFY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6719/Reviewer_vXFY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6719/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761054092372, "cdate": 1761054092372, "tmdate": 1762919010811, "mdate": 1762919010811, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents NePTune, a neuro-symbolic framework aimed at enhancing compositional reasoning with Vision-Language Models (VLMs). NePTune consists of three main components: an LLM-based program generator, a perceptual grounding module, and a symbolic executor. The program generator converts natural language queries into executable Python programs that can query a VLM to extract object-specific information. The resulting perceptual outputs are then combined using soft logic operators, allowing the system to reason over uncertain predictions from the VLM. The framework operates in a training-free manner but remains differentiable for fine-tuning."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "- The paper introduces a novel neuro-symbolic design that effectively integrates the power of VLMs, symbol grounding, and explicit compositional reasoning under uncertainty.\n- The score-based perceptual grounding interface elegantly connects neural perception with symbolic reasoning.\n- The modular, differentiable design is appealing as it supports both zero-shot use and potential fine-tuning without dataset-specific supervision."}, "weaknesses": {"value": "- While the breadth of experiments is commendable, the sheer number of evaluations can make the presentation somewhat overwhelming. In particular, the new experiments introduced in the discussion section are confusing, as they could be more appropriately integrated into the main experimental section. For example, Table 9 provides a helpful overview of the different datasets and could be placed earlier to illustrate NePTune’s general effectiveness. More broadly, adding a concise overview of the datasets, models, and baselines at the beginning of the experimental section would substantially improve readability. It might also be worth considering focusing on a smaller subset of key experiments in the main paper and moving some of the less central results to the appendix. For instance, Table 5 appears useful as supplementary evidence but is not discussed in much detail, suggesting it could be moved without loss of clarity.\n\n- The paper would benefit from a more detailed discussion of how the framework scales when applied to larger VLMs or more complex perceptual inputs, as well as an analysis of its computational overhead compared to direct prompting. It would also be valuable to elaborate on potential limitations that may arise despite high perceptual quality in the VLM or strong program generation capabilities from the LLM."}, "questions": {"value": "- Q1: Is the score function currently limited to pairs of objects, or can it be extended to higher-arity relations?\n- Q2: What is the number of tokens that the query function can return? \n- Q3: Line 241/242 seems to have a missing or incomplete expression \"…’).\". Could you clarify?\n- Q4: For program generation (component 1), do you use greedy decoding or a sampling-based strategy? Same question for the baseline VLMs\n- Q5: Regarding Table 4, could you clarify what \"ground-truth programs\" refers to, how they are obtained, and why the dataset \"Puzzles\" can not benefit as strongly from it?\n- Q6: What motivated the choice of VLMs for NePTune and comparisons? Do you expect similar zero-shot results for larger models (e.g., >70B or GPT-5 etc.) as in Tables 5 and 6?\n- Q7: Can you estimate the computational or token cost of NePTune compared to direct prompting? Given the small amount of tokens for the score and query functions, it seems low, but quantitative insight or discussions would be helpful.\n\nGenerally, I like the proposed method and am willing to raise my score if my concerns and questions are addressed."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "OVTRTRVfQZ", "forum": "8H0TkSusWI", "replyto": "8H0TkSusWI", "signatures": ["ICLR.cc/2026/Conference/Submission6719/Reviewer_fRHk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6719/Reviewer_fRHk"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6719/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761663276374, "cdate": 1761663276374, "tmdate": 1762919010222, "mdate": 1762919010222, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NePTune, a neuro-symbolic framework for vision-language (VL) reasoning that addresses limitations in prior work, such as brittle pipelines and a lack of adaptability. NePTune translates a natural language query into an executable Python program, similar to models like ViperGPT. However, it makes two key contributions:\n\n- Hybrid Execution Model: The generated Python program combines standard imperative control flow (loops, conditionals) with \"soft logic\" operators (based on fuzzy logic, e.g., t-norms for AND) that operate directly on the continuous uncertainty scores provided by a Vision-Language Model (VLM).\n\n- Differentiability: These soft logic operations are differentiable, allowing the entire framework (specifically the VLM backbone) to be fine-tuned via \"neuro-symbolic fine-tuning\" for domain adaptation.\n\nOperating in a training-free manner, NePTune already outperforms strong baselines. When fine-tuned, it shows remarkable adaptation capabilities, especially on domain-shift benchmarks like Ref-GTA."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The core contribution—a symbolic executor that blends imperative Python with differentiable, soft-logic operators (Table 2)—is highly novel and effectively tackles the problem of uncertainty propagation in multi-step reasoning.\n\n- The framework's differentiability is a key advantage. The ability to fine-tune the system for a new domain (as shown on Ref-GTA, where neuro-symbolic fine-tuning achieved 69.9% vs. 32.6% for standard VLM fine-tuning) is a significant step forward from inference-only models.\n\n- By operating on continuous scores rather than crisp decisions, NePTune avoids the cascading error problem that plagues many multi-step reasoning pipelines.\n\n- NePTune demonstrates state-of-the-art zero-shot performance against comparable methods (e.g., 92.65% vs 36.05% for ViperGPT on CLEVR) and massive gains on challenging domain-shift benchmarks (Ref-GTA), proving the practical value of its design.\n\n- The paper is extremely well-written, and its contributions are clearly articulated and well-situated against prior work."}, "weaknesses": {"value": "- The entire system still hinges on an LLM's ability to correctly parse the natural language query into a logically sound Python program. The paper notes that errors shift from \"syntax\" to \"logic\" (Sec 5), but a logical error in the generated program is just as fatal as a syntax error. A deeper analysis of the types of logical errors the LLM still makes would be valuable.\n\n- The score function for relational queries (num_objects=2) involves VLM queries that result in an $N \\times N$ matrix, where N is the number of detected objects. This approach seems to scale quadratically with the number of objects in the scene. It's unclear how the system would perform in highly cluttered real-world scenes with hundreds of object proposals."}, "questions": {"value": "- The ablation study (Table 10) shows a massive +19.19% improvement from adding \"Imperative Reasoning\" on top of declarative logic. Could the authors provide a concrete example of a query from CLEVR-Humans that requires this imperative logic (e.g., loops or complex conditionals) and which a purely declarative approach fails to solve?\n\n- Regarding the $N \\times N$ matrix for relational queries: What is the practical limit for N (number of objects) before the VLM grounding and subsequent reasoning become computationally prohibitive? Have the authors tested this on more cluttered datasets, like COCO?\n\n- The fine-tuning results on Ref-GTA are a key strength. To clarify: what exactly is being fine-tuned? Is it only the VLM backbone? Or are the parameters of the soft-logic operators (e.g., the temperature $\\tau$ and margin $\\gamma$ from Table 2) also learned during the neuro-symbolic fine-tuning process?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "uNslfBCl59", "forum": "8H0TkSusWI", "replyto": "8H0TkSusWI", "signatures": ["ICLR.cc/2026/Conference/Submission6719/Reviewer_9EoX"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6719/Reviewer_9EoX"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6719/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761863861282, "cdate": 1761863861282, "tmdate": 1762919009518, "mdate": 1762919009518, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces NePTune, a neuro-symbolic framework for vision-language reasoning. NePTune translates natural language queries into executable Python programs that use a hybrid execution model. This model combines imperative Python control flow with differentiable, soft logic operators that reason over uncertainty scores from a Vision-Language Model (VLM). The framework operates zero-shot by using an LLM to generate programs and a VLM to ground atomic concepts. It also supports fine-tuning for domain adaptation, demonstrating strong compositional generalization, especially on domain-shift benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "A substantive assessment of the strengths of the paper, touching on each of the following dimensions: originality, quality, clarity, and significance. We encourage reviewers to be broad in their definitions of originality and significance. For example, originality may arise from a new definition or problem formulation, creative combinations of existing ideas, application to a new domain, or removing limitations from prior results.\n\n1. On the Ref-GTA domain-shift benchmark, the VLM backbone (InternVL2.5) achieves only 6.95% accuracy, while NePTune achieves 69.69%. This demonstrates a highly robust decoupling of reasoning from perception.\n2. The framework integrates imperative Python with soft, differentiable logical operators. This is more expressive than declarative-only systems and more robust than crisp-logic pipelines.\n3. The soft-logic operators make the pipeline differentiable, enabling fine-tuning."}, "weaknesses": {"value": "A substantive assessment of the weaknesses of the paper. Focus on constructive and actionable insights on how the work could improve towards its stated goals. Be specific, avoid generic remarks. For example, if you believe the contribution lacks novelty, provide references and an explanation as evidence; if you believe experiments are insufficient, explain why and exactly what is missing, etc.\n\n1. Performance is fundamentally limited by the VLM's ability to ground atomic concepts.\n2. While more robust, the LLM-based program generator is still a point of failure. The authors provide a clear example of this in Appendix A.3, where the LLM generates a program with incorrect logic and arity, causing an execution failure.\n3. The framework is complex, involving multiple serial steps. This multi-component pipeline is likely to have significantly higher latency than a single VLM forward pass."}, "questions": {"value": "Please list up and carefully describe any questions and suggestions for the authors. Think of the things where a response from the author can change your opinion, clarify a confusion or address a limitation. This is important for a productive rebuttal and discussion phase with the authors.\n\n1. How frequent are logical program generation failures, and does NePTune have any mechanism to detect or recover from them?\n2. Could the authors provide a rough estimate of the end-to-end wall-clock time for a complex query? How does this multi-step pipeline's latency compare to a single forward pass of the backbone VLM?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "upv74M0Jzl", "forum": "8H0TkSusWI", "replyto": "8H0TkSusWI", "signatures": ["ICLR.cc/2026/Conference/Submission6719/Reviewer_Nt6P"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6719/Reviewer_Nt6P"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6719/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762105215386, "cdate": 1762105215386, "tmdate": 1762919009136, "mdate": 1762919009136, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}