{"id": "7MzaG8dHRv", "number": 15932, "cdate": 1758257281798, "mdate": 1759897272181, "content": {"title": "Online Black-Box Prompt Optimization with Regret Guarantees under Noisy Feedback", "abstract": "Generative AI excels in various tasks through advanced language modeling techniques, with its performance heavily influenced by input prompts. This has driven significant research into prompt optimization, particularly in commercial generative AI platforms, where prompt optimization is treated as a black-box optimization problem. Most existing research on black-box prompt optimization primarily focuses on offline learning and overlooks the randomness in outputs. However, in real-world applications, black-box prompt optimization typically operates in an online learning setting, which remains largely unexplored, especially given the noisy outputs. To address these challenges, we propose an \\textbf{A}daptive \\textbf{O}nline \\textbf{Z}eroth-order \\textbf{P}rompt \\textbf{T}uning (AOZPT) approach which integrates zeroth-order optimization with online learning in the non-convex setting. Specifically, we developed an uncertainty-scale-adjustment mechanism to mitigate the noise inherent in generative AI and the high variance associated with zeroth-order estimates. We conducted a comprehensive regret analysis of the AOZPT approach, and the results indicate that sublinear regret convergence is achievable. Extensive generative experiments demonstrate that AOZPT outperforms existing black-box prompt tuning methods, particularly in terms of stability in online scenarios.", "tldr": "", "keywords": ["Black-Box Prompt Optimization", "Online Learning", "Generative Al"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/b4952be341a8c7a1eaf1dd81c884522e1ad94c17.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper considers black-box prompt optimization problem. It proposes AOZPT, an online algorithm, to update the prompt as the streaming data comes in and provides sublinear regret guarantees. The method regards the soft prompt as optimization variables and update them according to the feedback of the generated results in an Adam-style optimization process, in order to reduce the noise. Experiments on CNN/DailyMai, GSM8k and Anime, Paining tasks on Llama-3.1-8B, GPT-3.5-Turbo, and Stable Diffusion are carried out to demonstrate its performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The paper explores an interesting intersection between online learning and black-box prompt tuning, extending zeroth-order optimization methods to an emerging and practically relevant domain.\n- The proposed adaptive uncertainty-scaling mechanism—inspired by Adam—offers a principled way to stabilize noisy gradient-free updates.\n- The paper provides theoretical guarantees on local regret under noisy feedback."}, "weaknesses": {"value": "- The noise model (Assumption 3.5) assumes uniform boundedness rather than a stochastic model (e.g., sub-Gaussian), which restricts theoretical generality.\n- The anonymous GitHub link has expired, preventing code verification and reproducibility assessment.\n- The prompt optimization is motivated by ongoing interactions with users (Lines 65-74). However, the online nature is simulated rather than true sequential feedback. And it is a bit unclear to me how it is simulated in the paper. It would be great if real streaming or non-stationary benchmarks would better justify “online”.\n- The computational overhead and latency introduced by the two function calls per iteration are not evaluated.\n- The empirical study require more results. For instance, (1) the prompt generating model is fixed for each task,  (2) important configuration details are not reported, e.g., the temperature and decoding strategy, which can greatly influence the final outcome. (3) the tested tasks are limited. (4) the original performance of the models should be included. According to the official report, Llama 3.1 8B (8 shots) achieve 84.5 on GSM8K. (5) Additional ablation studies on text-to-text tasks is appreciated."}, "questions": {"value": "- Under Assumption 3.5, since the regret bound depends linearly on the noise level $\\Delta$, can the authors quantify or empirically estimate the typical scale of $\\Delta$ in practice? Given the autoregressive nature of LLMs, small perturbations in input can amplify downstream variance.\n- Given similar computational/latency budgets, could a larger model (e.g., GPT-4) achieve comparable or superior performance without AOZPT? For instance, in Table 1, Qwen2.5-14B (MP) outperforms Llama-3.1-8B (AOZPT) on GSM8K—can the authors clarify this discrepancy?\n- As the instruct models usually have better instruction following abilities, it is appreciated that the performance on these models (e.g., Qwen2.5-14B-Instruct) can be included to further demonstrate the necessity and benefit of the proposed method. For instance, Qwen2.5-14B-Instruct can achieve 94.8 on GSM8K, better than the results reported in Table 1."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None."}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "MRxR8VgQgC", "forum": "7MzaG8dHRv", "replyto": "7MzaG8dHRv", "signatures": ["ICLR.cc/2026/Conference/Submission15932/Reviewer_wCmh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15932/Reviewer_wCmh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761801583523, "cdate": 1761801583523, "tmdate": 1762926147361, "mdate": 1762926147361, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes AOZPT, a method that integrates black-box prompt optimization with online learning. It introduces an adaptive uncertainty scaling mechanism to handle noise from generative models and high variance in zeroth-order gradient estimation. Theoretical analysis shows sublinear regret convergence, and experiments demonstrate superior performance and stability over existing methods."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Novel and timely topic that bridges black-box prompt optimization and online learning, addressing an underexplored area\n\n2. The adaptive uncertainty scaling mechanism is innovative and effectively mitigates output noise and gradient variance, improving robustness in practice\n\n3. The paper combines theoretical rigor with empirical validation, providing regret guarantees and solid experimental results across multiple tasks"}, "weaknesses": {"value": "1. While the methodological presentation is generally clear, the description of the adaptive scaling mechanism could benefit from additional implementation details or algorithmic steps to enhance reproducibility.\n\n2. The experimental evaluation would be strengthened by including a wider range of baselines, particularly reinforcement learning–based prompt optimization methods.\n\n3. The theoretical analysis is solid, though a deeper discussion of hyperparameter sensitivity and computational complexity in practical deployments could provide valuable insights into the method’s applicability."}, "questions": {"value": "see weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nKaXErAhnl", "forum": "7MzaG8dHRv", "replyto": "7MzaG8dHRv", "signatures": ["ICLR.cc/2026/Conference/Submission15932/Reviewer_nVJH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15932/Reviewer_nVJH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761896039677, "cdate": 1761896039677, "tmdate": 1762926146986, "mdate": 1762926146986, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an adaptive online zeroth-order prompt tuning, a novel approach integrating zeroth-order optimization with online learning for non-convex settings. It can be applied to real-world scenarios where generative AI operates on streaming data and requires dynamic prompt adjustment.  This approach fills the gap of online learning for black-box prompt optimization, enabling dynamic adaptation to streaming data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper addresses a timely problem of great importance.  It can effectively tackle two core uncertainties in online black-box scenarios: noise from generative AI outputs and high variance in zeroth-order gradient estimates. This paper comes with rigorous theoretical foundations such as formal regret analysis for non-convex settings and comprehensive experiment results."}, "weaknesses": {"value": "While the proposed method claims efficiency for online scenarios, it lacks details on inference latency and scalability. The framework involves two point gradient estimation and sliding-window gradient averaging but no data is provided on how these steps may affect runtime. In addition,  this paper compares AOZPT to offline baselines and a basic online method but it seems authors omit recent online prompt optimization and adaptive zeroth-order methods for LLMs. Therefore, it is difficult to assess AOZPT’s novelty against state-of-the-art online approaches.  Finally, the proposed method depends on frozen open-source LLMs to convert soft prompts to discrete prompts. Experiments show that removing this component may causes a significant drop in performance. This creates a dependency on high-quality open-source LLMs, which limits its deployment in scenarios where such models are unavailable."}, "questions": {"value": "The paper uses frozen open-source LLMs to generate discrete prompts, but what if such LLMs are unavailable ?   Can authors explain why there is no evaluation of the proposed method under adversarial noise in generative AI outputs ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SvrfVmMmdF", "forum": "7MzaG8dHRv", "replyto": "7MzaG8dHRv", "signatures": ["ICLR.cc/2026/Conference/Submission15932/Reviewer_DxWc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15932/Reviewer_DxWc"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902206422, "cdate": 1761902206422, "tmdate": 1762926146452, "mdate": 1762926146452, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces AOZPT, an online black-box prompt optimization method thta uses a two-point zeroth-order gradient estimator with an adaptive uncertainty scaling to counter both LLM output noise and ZO variance. It proves a sublinear local regret bound under noise and shows consistent empirical improvements across text2text and text2image tasks."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "1) It is an interesting idea to move black-box prompt optimization from offline to online learning, this might be useful in training agentic systems that interacts with real environment.\n2) The proposed method is clearly presented and very practical.\n3) A mostly sound theory (maybe with some assumptions being a little bit too ideal) is built to support the effectiveness of the method."}, "weaknesses": {"value": "1) Some assumptions, for example the Lipschitzness of \\nabla f_t in z, can be too optimistic. Is it possible if the authors can further verify how much we can expect these assumptions to hold in practice, and when these assumptions fail to hold, how much impact does this have on the effectiveness of the method in practices?\n\n2) I would recommend the authors to consider more baselines besides ZO-OGD. This can help isolating gains from the adaptive scaling agaisnt the two-point estimator."}, "questions": {"value": "Please refer to Weakness)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "e9cCmQGlGs", "forum": "7MzaG8dHRv", "replyto": "7MzaG8dHRv", "signatures": ["ICLR.cc/2026/Conference/Submission15932/Reviewer_rb5E"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15932/Reviewer_rb5E"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15932/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761972678540, "cdate": 1761972678540, "tmdate": 1762926145921, "mdate": 1762926145921, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}