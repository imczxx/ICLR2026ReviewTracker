{"id": "qR59RrG7Om", "number": 5294, "cdate": 1757894477742, "mdate": 1759897982729, "content": {"title": "``Noisier'’ Noise Contrastive Estimation is (Almost) Maximum Likelihood", "abstract": "Noise Contrastive Estimation (NCE) has fueled major breakthroughs in representation learning and generative modeling. Yet a long-standing challenge remains: accurately estimating ratios between distributions that differ substantially, which significantly limits the applicability of NCE on modern high-dimensional and multimodal datasets. We revisit this problem from a less explored perspective: the magnitude of the noise distribution. Specifically, we show that with a virtually scaled (i.e., artificially increased) noise magnitude, the gradient of the NCE objective can closely align with that of Maximum Likelihood, enabling a trajectory-wise approximation from NCE to MLE, and faster convergence both theoretically and empirically. Building on this insight, we introduce \"Noisier\" NCE, a simple drop-in modification to vanilla NCE that incurs little to no extra computational cost, while effectively handling density-ratio estimation in challenging regimes where traditional MLE and NCE struggle. Beyond improving classical density-ratio learning, \"Noisier\" NCE proves broadly applicable: it achieves strong results across image modeling, anomaly detection, and offline black-box optimization. On CIFAR-10 and ImageNet64×64 datasets, it yields 10-step and even 1-step samplers that match or surpass state-of-the-art methods, while cutting training iterations by up to half.", "tldr": "We revisit NCE through the lens of approximate maximum likelihood, showing that a noisier NCE better approximates MLE and provides strong methods for image modeling including distillation, anomaly detection, and offline black-box optimization.", "keywords": ["Noise Contrastive Estimation; Generative Models"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/55cb721871cef3fb89d4e1c0e77f3f05319d1a2f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes “Noisier” Noise Contrastive Estimation (N2CE), a simple modification of the NCE objective that increases the noise magnitude by a factor $M$. The central claim is that as $M\\to\\infty$, the gradient of the N2CE objective approaches the maximum-likelihood (MLE) gradient. The paper proves a gradient-limit result and a convergence guarantee for exponential families, and analyzes the finite-M, finite-sample error. Empirically, N2CE improves over NCE/MLE-style baselines across a wide range of different tasks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "**1. Clear Convergence guarantees.** Proposition 3.1 gives a clean expression showing $\\nabla L_M \\to \\nabla J_{\\text{MLE}}$ as $M\\to\\infty$, and Theorem 3.2 yields polynomial iteration complexity when $M$ is large.  \n\n**2. Simple, drop-in objective.** N2CE just reweights the negative class via $M$; it’s easy to integrate into existing pipelines. \n\n**3. Extensive experiments.** Experiments cover diverse datasets and baselines. It demonstrates versatility across tasks: improving FID scores in generative modeling, boosting AUPRC in anomaly detection, and enhancing diffusion distillation."}, "weaknesses": {"value": "The method proposed in this work is straightforward: its core idea is to assign greater weight to the loss on negative samples.\n\nFirst, I find the paper’s theoretical results quite confusing. The theory generally requires a fairly large $M$, and in Proposition 3.1, $M$ even tends to infinity. We know that in NCE, the model is expected to give high scores to positive samples and low scores to negative ones. If the loss function assigns an extremely large weight to the negative part, the model is likely to largely ignore the positive part and focus solely on the negatives. In that case, the model could simply assign very low scores to all outputs, which is clearly detrimental to learning. I am therefore not surprised that the experiments indicate $M$ should not be too large. However, the theoretical analysis in the paper suggests that a larger $M$ is preferable. This is not only puzzling but also inconsistent with the experimental results.\n\nSecond, the fundamental idea of the method is to reweight positives and negatives. How is this essentially different from simply multiplying the negative part by a weight $k$? I believe the authors need to discuss the distinction between the two. Do the theoretical results in the paper also hold for such a simple weighted baseline? Empirically, with a straightforward weighting scheme and careful tuning of $k$, can the results match those of state-of-the-art methods?\n\nMoreover, if the choice of $M$ is also important, the paper does not provide a theoretical analysis of how $M$ should be selected. If hyperparameter search over $M$ is required in experiments, the computational cost will inevitably be high.\n\nFinally, since the authors have already conducted image generation of people, why not include generated image results in the appendix, as is commonly done in the experiments of other generative methods?"}, "questions": {"value": "See the Weakness part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "czuBQO5ZoX", "forum": "qR59RrG7Om", "replyto": "qR59RrG7Om", "signatures": ["ICLR.cc/2026/Conference/Submission5294/Reviewer_LHEq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5294/Reviewer_LHEq"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5294/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761571987705, "cdate": 1761571987705, "tmdate": 1762917992898, "mdate": 1762917992898, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors explore a simple modification to the Noise Contrastive Estimation (NCE) density ratio estimator: as proposed by Gutmann et al. (2012), a positive factor $M$ is used to reweigh the noise distribution, yielding N$^2$CE. It is claimed that this simple modification results in loss function gradients that get closer to the maximum-likelihood loss gradients as $M$ grows, providing practical improvements over classical maximum-likelihood and standard NCE (e.g., yielding better samplers)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The experimental setups are diverse and truly extensive, and the provided results are rich and comprehensive. The writing is also clear and easy to follow.\n\nAdditionally, the authors provide theoretical results, proving their main claim and supplementary convergence results."}, "weaknesses": {"value": "**Connection with MLE**\n\nThe work is rather weak when it comes to the main claim: the connection between N$^2$CE and MLE, and the novelty behind it. Firstly, this connection is outright obvious from the loss function alone: note that\n$$\n\\log M + \\log \\frac{r}{M + r} = \\log \\frac{r}{1 + r/M} \\underset{M \\to +\\infty}{\\longrightarrow} \\log r\n$$\n$$\nM \\log \\frac{M}{M + r} = -\\log \\left( 1 + \\frac{r}{M} \\right)^M =-\\log \\left( 1 + \\frac{1}{M/r} \\right)^{r \\cdot M/r} \\underset{M \\to +\\infty}{\\longrightarrow} -\\log e^r = -r\n$$\nNow, combining everything and denoting $T = \\log r$, for high $M$ we get\n$$\n\\mathcal{L}\\_M \\sim \\mathbb{E}\\_{q^*} T - \\mathbb{E}\\_{q_0} e^T + \\text{const},\n$$\nwhich is the **well-known** Nguyen-Wainwright-Jordan (NWJ) [1] or KL-$f$-GAN [2] or \"self-normalizing DRE\" [3] variational lower bound on the Kullback-Leibler divergence. Maximizing this bound **is** the maximum-likelihood learning (recall the connection between the KL-divergence and cross-entropy).\n\n[1] X. Nguyen et al, \"Estimating divergence functionals and the likelihood ratio by convex risk minimization\". Proc. of NeurIPS 2008.\n\n[2] S. Nowozin et al, \"f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization\". Proc. of NeurIPS 2016.\n\n[3] B. Poole et al, \"On Variational Bounds of Mutual Information\". Proc. of ICML 2019\n\nNext, the work lacks an important information-theoretic background. Currently, without it, the connection between N$^2$CE and MLE appears as some sort of miracle (*\"As we show below, increasing M has a striking effect...\"*, line 146). However, by showing that N$^2$CE is just a lower bound on some divergence which interpolates between the Jensen-Shannon and Kullback-Leibler divergences, one resolves this mystery.\n\nFrom the theory of variational representations of $f$-divergences (Section 7.13 in [4]),\n$$\n\\text{KL}(p \\Vert q) = 1 + \\sup\\_T [\\mathbb{E}\\_p T - \\mathbb{E}\\_q e^T] = 1 + \\sup\\_r [\\mathbb{E}\\_p \\log r - \\mathbb{E}\\_q r] \\qquad \\text{(MLE, NWJ)}\n$$\n$$\n\\text{JS}(p \\Vert q)  \\overset{\\text{def}}{=} \\frac{1}{2} \\text{KL}(p \\Vert q/2 + p/2) + \\frac{1}{2} \\text{KL}(q \\Vert q/2 + p/2)  =  \\log 2 + \\sup\\_h [\\mathbb{E}\\_p \\log h - \\mathbb{E}\\_q \\log (1 - h)] = \\log 2 + \\sup\\_r \\left[\\mathbb{E}\\_p \\log \\frac{r}{1+r} + \\mathbb{E}\\_q \\log \\frac{1}{1+r}\\right] \\qquad \\text{(NCE)}\n$$\nNow, one can prove that\n$$\nD\\_\\alpha(p \\Vert q) \\overset{\\text{def}}{=} (1 - \\alpha) \\cdot \\text{KL}(p \\Vert \\alpha q + (1 - \\alpha) p) + \\alpha \\cdot \\text{KL}(q \\Vert \\alpha q + (1 - \\alpha) p) = h(\\alpha) + \\sup\\_r \\left[\\mathbb{E}\\_p \\log \\frac{r}{M+r} + M \\mathbb{E}\\_q \\log \\frac{M}{M+r}\\right] \\qquad \\text{(N$^2$CE)},\n$$\nwhere $\\alpha = M / (1 + M)$, $h(x)$ is the binary entropy function, and the optimal $r^*(x) = p(x) / q(x)$.\n\nThat said, of course we get $\\left. \\text{(N$^2$CE)} \\right|\\_{M=1} = \\text{NCE}$ and $\\lim\\_{M \\to +\\infty} \\text{N$^2$CE} = \\text{MLE}$.\n\n[4] Polyanskiy, Y., and Wu, Y. \"Information Theory: From Coding to Learning\". Cambridge University Press, 2024.\n\n**Is there really a need for N$^2$CE?**\n\nNow that we have established that N$^2$CE is just NWJ for sufficiently large $M$, why can't we just use the latter? In the authors' text, I find no justification for using moderate $M$. Therefore, it is logical to jump straight to NWJ, thus avoiding numerical instabilities and recovering the *exact* MLE gradients.\n\n**The \"Density-chasm\"**\n\nWhile the authors address the _density-chasm_ problem from the perspective of the \"magnitude\" of the noise distribution, it is a well-known fact that NWJ (an $M \\to \\infty$ limit of N$^2$CE) still suffers from this exact problem (for instance, please, refer to Figure 2 in [3], that corresponds to the density-chasm case for high mutual information). Therefore, I do not find it convincing that N$^2$CE offers something new to resolve this issue.\n\nFurthermore, while the authors cite the telescoping density ratio estimation technique (TRE by Rhodes et al. (2020)), they do not recognise more recent classifier-based DRE approaches: DRE-$\\infty$ [5] and Classification Diffusion Models [6]. These methods proved to be better at dealing with the density-chasm, while also providing tractable density ratios (and decent generation results in [6]).\n\n[5] K. Choi et al., \"Density Ratio Estimation via Infinitesimal Classification\". Proc. of AISTATS 2022.\n\n[6] S. Yadin et al., \"Classification Diffusion Models: Revitalizing Density Ratio Estimation\". Proc. of NeurIPS 2024."}, "questions": {"value": "1. In the text, you conclude that sufficiently large $M$ (e.g., $50$ or $100$) are necessary for achieving better results: _\"This\nagain supports our analysis that a sufficiently large M is critical for accurate gradient approximation.\"_, line 411. However, with $M$ of this magnitude, N$^2$CE is essentially NWJ. Is there any reason to prefer N$^2$CE with moderate $M$ over NWJ?\n2. Why did you focus on proving the convergence of the gradients, but not of the loss function itself?\n3. Can you compare your method with plain NWJ, DRE-$\\infty$ and Classification Diffusion Models (please, see the weaknesses for the references)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VJaoys4njP", "forum": "qR59RrG7Om", "replyto": "qR59RrG7Om", "signatures": ["ICLR.cc/2026/Conference/Submission5294/Reviewer_PhJz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5294/Reviewer_PhJz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5294/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761595319792, "cdate": 1761595319792, "tmdate": 1762917992424, "mdate": 1762917992424, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a more general Noise Contrastive Estimation (NCE).\nRecalling the classical sigmoid function $\\sigma(x)$ and the binary-cross entropy is used to compute the NCE loss as:\n$\\sigma(x)=1/(1+e^{-x})$ and\n\n$$\\mathcal{L}_\\text{NCE}(\\theta) = \\mathbb{E}_{x\\sim X}[log(\\sigma(f(x;\\theta)))] + \\mathbb{E}_{\\epsilon}[log(1-\\sigma(f(\\epsilon;\\theta)))]$$\n\nThe method proposed by the paper called Noiser NCE (N$^2$CE), it introduces a new user-provided hyper-parameter $M$ that increases the impact of noise.\nThe sigmoid function and losses are modified as follows:\n$\\sigma_M(x)=M/(M+e^{-x})$ and\n\n$$\\mathcal{L}_{\\text{N}^2\\text{CE}}(\\theta,M) = \\mathbb{E}_{x\\sim X}[log(\\sigma_M(f(x;\\theta)))] + M\\mathbb{E}_{\\epsilon}[log(1-\\sigma_M(f(\\epsilon;\\theta)))]$$\n\nAnd as noted in the paper $\\text{N}^2\\text{CE}(.,M=1)=\\text{NCE}(.)$\n\nThis surprisingly simple modification makes the gradient of the N$^2$CE loss approximate the gradient of Maximum Likelihood Estimation (MLE) when $M\\to +\\infty$.\nIn turns this allows N$^2$CE to converge better and in higher than NCE can as demonstrated by the various experiments."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The method is simple and easy to implement.\n2. It addresses an important limitation of vanilla NCE: its difficulty to deal with high-dimension data, in which it typically revert to learning the noise directly, not the ratio data-noise.\n3. The connection with MLE is proven.\n4. There's no overhead training cost compared to vanilla NCE.\n3. Experimental results are very convincing, showing large gains over NCE and other methods."}, "weaknesses": {"value": "1. The paper packs too much information, notably in the experimental settings, and consequently a lot of it has been pushed to the appendix (the paper is 37 pages in total). I tend to prefer paper that focus on one idea and line of experimentation in depth which are then built-on by follow up paper.\n2. Possibly as a consequence of the previous point, background information is severely lacking. For example LEBM and DAMC which are heavily used in experiments are not provided as background, making the paper not self-contained.\n3. As a whole, inference is left out of the paper (apart from saying we use methods A and B for inference, again reinforcing the previous point), only training is covered.\n3. Lack of experimental consistency: sometimes telescoping ratios is used while other time direct ratio regularization is used.\n4. Lack of terminology consistency: telescoping ratios are also referred to as multi-stage ratio and ratio decomposition. This made me doubt my understanding, are they the same thing as I assumed or not?\n5. From the above, I get the feeling it's not one method but two depending on how the ratio is regularized, taking away from the elegance of the idea."}, "questions": {"value": "1. I gather that the loss can be seen as a modified sigmoid and a weighted binary cross entropy. But how does inference, do we use a vanilla sigmoid?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "6j8kb1isnM", "forum": "qR59RrG7Om", "replyto": "qR59RrG7Om", "signatures": ["ICLR.cc/2026/Conference/Submission5294/Reviewer_Qgtk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5294/Reviewer_Qgtk"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5294/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761952513696, "cdate": 1761952513696, "tmdate": 1762917991932, "mdate": 1762917991932, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper points out the problem that Noise Contrastive Estimation (NCE), which estimates a density of the data distribution by estimating the ratio between the target density and noise density, underperforms when the ratio is large. This phenomenon commonly occurs when the data is high dimensional or multimodal. The authors propose to rescale the log odds that appear in the NCE objective by constant $M$. When $M > 1$. this corresponds to artificially increasing the magnitude of the noise. This \"Noisier NCE\" or N2CE reduces to the conventional NCE when $M=1$. They show that as $M$ increases the gradient of the N2CE loss with respect to the parameter, approaches to that of the log-likelihood (score function), thus N2CE amounts to maximum likelihood estimation (MLE), both theoretically and empirically. Then it is further shown that this simple remedy to NCE works effectively well in high-dimensional or multimodal settings, and generative modeling without additional cost or structural change of the models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Theoretical results indicate that that gradient of the population version of the N2CE objective converges to the score function as $M$ increases, under mild regulatory conditions. Under the exponential family assumption, the iteration complexity is bounded by the cube of the condition number of the Fisher information matrix, for $M$ sufficiently large. For a finite $M$, the difference between the score function and the gradient of the empirical N2CE loss exhibits a bias-variance trade-off, where the bias diminishes at a rate $O(1/M^2)$.\n\n2. The proposed method is simple, easy-to-understand, and requires only a modest change in the NCE objective function so there is little additional cost in applying it. Yet it shows an impressive performance boost in image generation, anomaly detection, and offline black-box optimization. For example, in CIFAR-10 and ImageNet64x64, combined with 10-step or 1-step sampling scheme, a SOTA-level result is achieved with half the training iterations."}, "weaknesses": {"value": "1. The key assumption for the main result that the gradient of the N2CE loss approaches to the score function as $M\\to\\infty$ relies on the assumption that $p_{\\alpha}$ is dominated by $q_0$ uniformly over $\\alpha$. Density chasm is most severe when this assumption is violated, and simply increasing $M$ does not completely resolve this. \n\n2. The choice of the noise density $q_0$ may be much more critical than its scale. Some sort of comparison based on a matrix of $M$ and $q_0$ is warranted. \n\n3. Proposition 3.3 suggest bias-variance trade-off in $M$, but no guide for choosing $M$ is provided. \n\n4. Large-scale benchmarks in limited to visual datasets like CIFAR-10 and ImageNet64x64. It is desirable to test N2CE on the other domains, such s LLM or speech data."}, "questions": {"value": "1. In Proposition 3.3, isn't the second term of $V_n$ $\\min\\\\{ E_{q_0}\\\\|\\nabla_{\\alpha} \\log r_{\\alpha}\\\\|^2, M^2 \\\\|\\nabla_{\\alpha} r_{\\alpha}\\\\|^2\\\\}$?\n\n2. Also in Proposition 3.3, the result suggests that there is an optimal, finite, choice of $M$, unless $\\\\|\\nabla_{\\alpha} r_{\\alpha}\\\\|^2 \\gg M^2 \\\\|\\nabla_{\\alpha} \\log r_{\\alpha}\\\\|^2$.for all $M$. But Proposition 3.1 states that the larger $M$, the better. How can this apparent conflict be resolved?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NuNjXoWrX0", "forum": "qR59RrG7Om", "replyto": "qR59RrG7Om", "signatures": ["ICLR.cc/2026/Conference/Submission5294/Reviewer_Qdxk"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5294/Reviewer_Qdxk"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5294/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762373826795, "cdate": 1762373826795, "tmdate": 1762917991522, "mdate": 1762917991522, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}