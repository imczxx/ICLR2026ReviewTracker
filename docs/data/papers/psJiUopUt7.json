{"id": "psJiUopUt7", "number": 9484, "cdate": 1758124321325, "mdate": 1759897717581, "content": {"title": "Reasoning-Driven Multimodal LLM for Domain Generalization", "abstract": "This paper addresses the domain generalization (DG) problem in deep learning. \nWhile most DG methods focus on enforcing visual feature invariance, we leverage the reasoning capability of multimodal large language models (MLLMs) and explore the potential of constructing reasoning chains that derives image categories to achieve more robust predictions under domain shift.\nTo this end, we systematically study the role of reasoning in DG using DomainBed-Reasoning, a newly constructed extension of DomainBed dataset, in which each sample is paired with class-relevant reasoning chains.\nOur analysis reveals two key challenges: (i) fine-tuning MLLMs with reasoning chains for classification is more challenging than direct label supervision, since the model must optimize complex reasoning sequences before label prediction; and (ii) mismatches in reasoning patterns between supervision signals and fine-tuned MLLMs lead to a trade-off between semantic richness (informative but harder to optimize) and optimization efficiency (easier to optimize but less informative).\nTo address these issues, we propose RD-MLDG (Reasoning-Driven Multimodal LLM for Domain Generalization), a framework with two components: (i) MTCT (Multi-Task Cross-Training), which introduces an additional direct classification pathway to guide reasoning supervision; and (ii) SARR (Self-Aligned Reasoning Regularization), which preserves the semantic richness of reasoning chains while mitigating reasoning-pattern mismatches via iterative self-labeling.\nExperiments on standard DomainBed datasets (PACS, VLCS, OfficeHome, TerraIncognita) demonstrate that RD-MLDG achieves state-of-the-art performances, highlighting reasoning as a promising complementary signal for robust out-of-domain generalization.", "tldr": "", "keywords": ["Machine Learning (ML) -> ML: Transfer", "Domain Adaptation", "Multi-Task Learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/89b49e4411e02ccc4f61be463032a12ea751a06d.pdf", "supplementary_material": "/attachment/1c77ec2f39e150eeac41fdee15dba741384c84f0.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces RD-MLDG, a framework that leverages reasoning chains in MLLMs to improve robustness under domain shift. The authors construct DomainBed-Reasoning, an extension of DomainBed in which each sample is paired with structured reasoning chains generated by GPT-4o. The authors propose two modules: Multi-Task Cross-Training (MTCT), which stabilizes reasoning-chain learning via an auxiliary classification pathway, and Self-Aligned Reasoning Regularization (SARR), which iteratively incorporates self-generated reasoning chains aligned with model predictions. Experiments on four DG benchmarks demonstrate state-of-the-art performance, with detailed ablations and analyses supporting the method’s contributions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper makes good contribution by explicitly incorporating reasoning into domain generalization, an area where most prior methods have focused solely on feature-level invariance. The construction of DomainBed-Reasoning provides a valuable new benchmark for studying reasoning under domain shift, while the proposed RD-MLDG framework is empirically effective. The analysis of optimization gaps and reasoning mismatches is thorough and convincing, and the introduction of MTCT and SARR demonstrates clear performance improvements across multiple benchmarks."}, "weaknesses": {"value": "- Dataset construction transparency: While DomainBed-Reasoning is central, the paper lacks sufficient details on reasoning-chain generation such as rejection sampling and filtering.\n- Baseline fairness: Comparisons to prior DG methods and GPT-4o appear favorable, but it is unclear whether all baselines were fine-tuned under identical settings (prompt design, data splits, training budgets). For example, in Table 1, mixing zero-shot GPT-4o results with fine-tuned InternVL models may inflate apparent gains.\n- Limited task scope: The study focuses exclusively on image classification. It remains uncertain whether the proposed framework generalizes to other multimodal DG tasks. Also although LoRA adapters are used, both MTCT and iterative SARR introduce added fine-tuning steps. Training efficiency and scalability to larger datasets are not fully addressed."}, "questions": {"value": "- Could you provide more details on reasoning-chain generation, such as average number of reasoning chains generated per instance, rejection rate, and filtering criteria?\n- Could you clarify in Table 1, for MLLM-based methods, which results are zero-shot and which are fine-tuning-based?\n- Do you expect RD-MLDG to extend beyond image classification to other tasks? Additionally, given that preparing reasoning-chain supervision is non-trivial and both MTCT and iterative SARR introduce added fine-tuning steps, can you share your thoughts on the efficiency and scalability of the framework when applied to larger datasets?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bYtbm2M8Dp", "forum": "psJiUopUt7", "replyto": "psJiUopUt7", "signatures": ["ICLR.cc/2026/Conference/Submission9484/Reviewer_jvkU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9484/Reviewer_jvkU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9484/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761248518881, "cdate": 1761248518881, "tmdate": 1762921067461, "mdate": 1762921067461, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes **RD-MLDG**, a *reasoning-driven multimodal large language model (MLLM)* framework designed to improve **domain generalization (DG)** — the ability of models to perform well on unseen domains. Unlike prior DG methods that focus primarily on learning invariant visual representations, this work leverages **reasoning chains** that explicitly describe class-relevant visual evidence to encourage *process-level* generalization.\n\nTo support this, the authors introduce **DomainBed-Reasoning**, an extension of the DomainBed benchmark that pairs each image with structured reasoning chains generated by GPT-4o. Through empirical analyses, they identify two key challenges:\n1. **Optimization difficulty** — supervising models with reasoning chains is harder than optimizing for direct label prediction.\n2. **Reasoning-pattern mismatch** — the reasoning patterns generated by large language models differ from those produced by the fine-tuned model.\n\nTo address these issues, the paper introduces two components:\n* **MTCT (Multi-Task Cross-Training):** jointly optimizes classification and reasoning objectives to stabilize training.\n* **SARR (Self-Aligned Reasoning Regularization):** a self-labeling approach that aligns the model’s reasoning style while maintaining semantic richness.\n\nExperiments on PACS, VLCS, OfficeHome, and TerraIncognita demonstrate that RD-MLDG achieves **state-of-the-art performance** (average 86.89%), outperforming prior DG methods based on non-MLLM architectures."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* **Clear problem identification and analysis:** The authors systematically diagnose optimization and reasoning-pattern gaps through quantitative studies (e.g., token probability and entropy analysis).\n* **(Minor) Dataset contribution:** DomainBed-Reasoning provides a useful benchmark for reasoning-based domain generalization and may foster further research, even if its construction is relatively straightforward."}, "weaknesses": {"value": "* **Limited methodological novelty:** The distinction between MTCT and SARR losses is unclear, as they appear almost identical. In particular, the novelty of SARR seems limited, resembling a form of rejection sampling.\n* **Evaluation scope:** The experiments focus mainly on visual classification tasks; it remains unclear whether reasoning-driven DG generalizes to other multimodal tasks (e.g., VQA, image-text retrieval).\n* **Baseline coverage:** Comparisons are mainly against non-MLLM DG methods, making it difficult to assess the true advantage of RD-MLDG within the MLLM landscape.\n* **(Minor) Writing:** The introduction could benefit from citations to recent survey papers summarizing reasoning-based or MLLM-based DG approaches."}, "questions": {"value": "- Line 053: Please ensure the sentence ends with a period.\n- Line 318: The description of how reasoning chains are combined with the classification prompt is unclear."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "tq7OxXZUbi", "forum": "psJiUopUt7", "replyto": "psJiUopUt7", "signatures": ["ICLR.cc/2026/Conference/Submission9484/Reviewer_dvM6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9484/Reviewer_dvM6"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9484/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724746561, "cdate": 1761724746561, "tmdate": 1762921067056, "mdate": 1762921067056, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper explores the integration of reasoning supervision into DG within MLLMs. The authors construct DomainBed-Reasoning, a new benchmark where each sample in DomainBed is paired with structured reasoning chains generated by GPT-4o. To address two key challenges -- (1) the optimization difficulty of reasoning-chain supervision and (2) the mismatch between external (GPT-4o) and self-generated reasoning patterns -- the authors introduce RD-MLDG. It comprises two components: Multi-Task Cross-Training (MTCT), which jointly optimizes classification and reasoning pathways to stabilize learning, and Self-Aligned Reasoning Regularization (SARR), a self-labeling mechanism that aligns supervision with the model’s own reasoning style. Experiments on four DG benchmarks (PACS, VLCS, OfficeHome, TerraIncognita) show consistent improvements over strong CLIP- and MLLM-based baselines. The paper argues that reasoning can serve as a complementary, process-level signal for domain generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The work connects reasoning in MLLMs with robustness under domain shift, introducing a conceptually novel direction -- process-level invariance -- that goes beyond traditional feature-invariance approaches.\n\n2. DomainBed-Reasoning is a non-trivial extension with structured reasoning chains, multi-stage generation, and rejection sampling to ensure coherence. This dataset can serve as a testbed for future studies on reasoning-based generalization.\n\n3. RD-MLDG addresses two empirically observed issues with distinct and complementary mechanisms (MTCT for optimization stability, SARR for reasoning alignment). The framework is simple yet principled.\n\n4. The authors provide extensive ablations, token-level entropy analyses, and convergence diagnostics that convincingly support the claimed effects of MTCT and SARR.\n\n5. The paper is well-written, visually organized, and provides enough procedural detail for replication."}, "weaknesses": {"value": "1. DomainBed-Reasoning relies entirely on GPT-4o-generated reasoning chains. These synthetic sequences likely encode stylistic and distributional priors from GPT-4o’s pretraining, rather than domain-grounded reasoning. As a result, RD-MLDG might learn to imitate linguistic style alignment rather than to capture transferable causal or process-level invariances. While the dataset is well-constructed, it remains uncertain whether the performance gains derive from genuine reasoning integration or from the regularizing effect of textual augmentation.\n\n2. The paper treats reasoning chains as structured textual supervision but does not formally define what constitutes “reasoning” in the DG context -- e.g., whether it implies causal inference, compositional abstraction, or hierarchical explanation. Without such formal grounding or reasoning-quality diagnostics (e.g., logical coherence or factual correctness), it is difficult to evaluate whether RD-MLDG truly improves reasoning-driven generalization or simply leverages additional text-conditioned supervision.\n\n3. The improvements attributed to reasoning may partly arise from multi-task regularization and self-training dynamics rather than reasoning-specific mechanisms. For example, MTCT’s stabilization could be viewed as a standard auxiliary-task regularization effect. SARR’s iterative self-labeling closely resembles confidence-based pseudo-labeling, widely used in semi-supervised and DG settings.\nDemonstrating qualitative differences (e.g., changes in internal representation structure or reasoning coherence) would strengthen the claim that RD-MLDG explicitly enhances reasoning.\n\n4. The method assumes that reasoning text provides process-level invariance, but the reasoning generation pipeline (via GPT-4o) is independent of the underlying visual feature encoder. This leads to potential semantic misalignment between visual features and textual reasoning tokens. While the model benefits empirically, the lack of explicit cross-modal alignment may limit scalability to other MLLM architectures or reasoning tasks.\n\n5.  The four benchmarks (PACS, VLCS, OfficeHome, TerraIncognita) mainly test appearance-level domain shifts. Thus, the improvements reflect robustness to visual variation, not necessarily reasoning robustness. Experiments involving compositional or conceptual domain shifts (e.g., cross-task reasoning transfer or counterfactual settings) would better substantiate the central claim that reasoning contributes to domain generalization."}, "questions": {"value": "See Weakness.\n\nAdditional Questions:\n1. How do you evaluate the quality and logical validity of reasoning chains beyond coherence filtering?\n\n2. Would RD-MLDG still outperform baselines if the reasoning text were semantically perturbed or replaced with neutral descriptions (to test for stylistic bias)?\n\n3. Could MTCT or SARR generalize to smaller open-source models without reasoning pretraining (e.g., LLaVA-1.5) or purely visual transformers?\n\n4. Do the authors observe changes in reasoning chain complexity or diversity across SARR iterations, and how does this correlate with accuracy gains?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cxNLvXAVqu", "forum": "psJiUopUt7", "replyto": "psJiUopUt7", "signatures": ["ICLR.cc/2026/Conference/Submission9484/Reviewer_b6ME"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9484/Reviewer_b6ME"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9484/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724948787, "cdate": 1761724948787, "tmdate": 1762921066828, "mdate": 1762921066828, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles the problem of domain generalization (DG) by proposing a novel approach that leverages the reasoning capabilities of Multimodal Large Language Models (MLLMs). Instead of relying on traditional methods that seek feature-level invariance, the authors argue for pursuing process-level invariance by training models to generate class-relevant reasoning chains, which are hypothesized to be more robust to domain shifts. The paper proposes RD-MLDG that jointly optimizes a direct classification path and the reasoning-generation path, and introduces an iterative self-labeling stage where the model generates its own reasoning chains, which are then filtered and used as the new supervision signal. The authors demonstrate that RD-MLDG achieves state-of-the-art results on four standard DG benchmarks (PACS, VLCS, OfficeHome, and TerraIncognita)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper addresses domain generalization by proposing a novel approach that leverages the reasoning capabilities of Multimodal Large Language Models, which is a challenging and practical scenario.\n2. The paper is well written and easy to follow.\n3. The paper provides extensive experiments, showing the effectiveness and versatility of the proposed method."}, "weaknesses": {"value": "1. The quality of the entire DomainBed-Reasoning dataset influences on reasoning chains generated by GPT-4o. This introduces a potential dependency and bias. \n\n2. The proposed training procedure appears computationally intensive. It involves an initial MTCT stage followed by N=3 rounds of SARR. Each SARR round seems to require a full generation pass over the source data, a filtering step, and another fine-tuning stage."}, "questions": {"value": "1. In the SARR filtering step, what percentage of self-generated reasoning chains are typically discarded for leading to an incorrect conclusion? Does this rejection rate decrease as the SARR rounds progress?\n\n2. The core hypothesis is that reasoning chains are more domain-invariant than visual features. Figure 1 provides a great qualitative example. Have you considered any quantitative validation of this hypothesis? For instance, one could measure the embedding-space similarity of reasoning chains for the same class across different domains, and compare this to the similarity of visual features for that same class across domains."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qmnAuHBzmp", "forum": "psJiUopUt7", "replyto": "psJiUopUt7", "signatures": ["ICLR.cc/2026/Conference/Submission9484/Reviewer_Zr5a"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9484/Reviewer_Zr5a"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9484/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761976719538, "cdate": 1761976719538, "tmdate": 1762921066250, "mdate": 1762921066250, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}