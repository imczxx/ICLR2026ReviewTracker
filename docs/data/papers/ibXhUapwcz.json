{"id": "ibXhUapwcz", "number": 2908, "cdate": 1757299673727, "mdate": 1759898120007, "content": {"title": "Improving Black-Box Generative Attacks via Generator Semantic Consistency", "abstract": "Transfer attacks optimize on a surrogate and deploy to a black-box target. While iterative optimization attacks in this paradigm are limited by their per-input cost limits efficiency and scalability due to multistep gradient updates for each input, generative attacks alleviate these by producing adversarial examples in a single forward pass at test time. However, current generative attacks still adhere to optimizing surrogate losses (e.g., feature divergence) and overlook the generator’s internal dynamics, underexploring how the generator’s internal representations shape transferable perturbations. To address this, we enforce semantic consistency by aligning the early generator’s intermediate features to an EMA teacher, stabilizing object-aligned representations and improving black-box transfer without inference-time overhead. To ground the mechanism, we quantify semantic stability as the standard deviation of foreground IoU between cluster-derived activation masks and foreground masks across generator blocks, and observe reduced semantic drift under our method. For more reliable evaluation, we also introduce Accidental Correction Rate (ACR) to separate inadvertent corrections from intended misclassifications, complementing the inherent blind spots in traditional Attack Success Rate (ASR), Fooling Rate (FR), and Accuracy metrics. Across architectures, domains, and tasks, our approach can be seamlessly integrated into existing generative attacks with consistent improvements in black-box transfer, while maintaining test-time efficiency.", "tldr": "We improve adversarial transferability of generative attacks by explicitly targeting the generator internals, unlike existing approaches, to enforce semantic consistency across adversarial perturbation synthesis stage.", "keywords": ["adversarial transferability", "transferable adversarial attacks", "generative models"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/777edf7f3d0cedbf4bfa572c16dc82f5d3afe409.pdf", "supplementary_material": "/attachment/dca45c01af48c484a6415fc1ae091091d1316441.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes Semantically Consistent Generative Attack (SCGA), to enhance black-box transferability of generative adversarial attacks. While existing generative attacks optimize surrogate losses, the authors focus on the generator’s internal dynamics. They empirically observe that semantic recognizability degrades from early to late blocks and hypothesize that enforcing semantic consistency in early blocks improves transferability.\nTo achieve this, the authors apply the EMA Teacher to stabilize internal generator features that encode object semantics and a self-feature consistency loss that encourages student early-layer features to be similar to teacher’s features. Additionally, they propose a new evaluation metric, Accidental Correction Rate (ACR), to capture cases where adversarial perturbations inadvertently correct misclassified inputs, improving the interpretability of attack reliability. Extensive experiments across multiple architectures, domains, and tasks demonstrate consistent performance improvements over strong baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper presents a clear empirical motivation by analyzing semantic drift across generator blocks for the proposed semantic consistency at the generator’s early intermediates.\n2. The proposed method integrates the Mean Teacher mechanism with a self-feature consistency loss during training, which increases semantic consistency while not introducing no additional inference cost.\n3. The introduction of the Accidental Correction Rate (ACR) metric provides an insightful perspective on attack reliability.\n\nThe paper conducts comprehensive experiments across multiple model families, datasets, and tasks, establishing strong empirical credibility."}, "weaknesses": {"value": "Main concerns: \n1. The paper lacks theoretical analysis or formal justification for why enforcing early-layer feature consistency enhances cross-model transferability, relying mainly on empirical evidence.\n2. In Table 2, the integration of the proposed method with the baseline leads to a slight drop in attack performance for some Transformer models (such as CDA and FACL with the proposed method on model p). Could the authors provide a brief analysis on the potential reasons for this performance degradation in these cases?\n3. The paper does not evaluate against diffusion-based purification defenses, which are currently regarded as strong pre-processing defenses in adversarial robustness research. Including such a comparison would strengthen the work’s comprehensiveness.\nMinor weakness:\n1. In Figure 2, the snowflake symbol may unintentionally suggest that the teacher generator is entirely frozen; however, as it is updated iteratively via the EMA rule rather than by backpropagation, clarifying this distinction in the caption or text would avoid confusion.\n2. In the ablation of the similarity threshold (shown in the supplementary material), the evaluation metric is not explicitly specified."}, "questions": {"value": "1. Could the authors provide deeper theoretical intuition or analysis on why early-layer semantic anchoring leads to improved transferability?\n2. Table 2 shows that the proposed method generally enhances transferability. However, for some cases such as the integration of the proposed method with the baseline CDA and FACL on Transformers (p), there is a decrease in attack performance. Could the authors briefly discuss the potential cause? \n3. Have the authors considered evaluating the proposed method against diffusion-based purification defenses (e.g., DiffPure[1]) to test its robustness against strong modern preprocessing defenses?\n\n[1] Nie W, Guo B, Huang Y, et al. Diffusion models for adversarial purification[J]. arXiv preprint arXiv:2205.07460, 2022."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "o0t0FGFfDP", "forum": "ibXhUapwcz", "replyto": "ibXhUapwcz", "signatures": ["ICLR.cc/2026/Conference/Submission2908/Reviewer_GNru"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2908/Reviewer_GNru"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission2908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761804188725, "cdate": 1761804188725, "tmdate": 1762916439081, "mdate": 1762916439081, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SCGA, a method for improving black-box adversarial transferability in generative attack frameworks. The approach employs a Mean Teacher architecture with EMA-updated weights to align intermediate features from the generator's early blocks with a teacher network, while maintaining the standard adversarial loss on surrogate model features. The authors partition the generator into early, mid, and late blocks and quantify semantic stability using foreground IoU variability across these blocks. Experimental evaluation is conducted across classification, semantic segmentation, and object detection tasks, with the introduction of an Accidental Correction Rate (ACR) metric alongside traditional ASR, FR, and accuracy measurements."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper is well-written and carefully structured. I commend the authors for the high-quality figures and tables, which significantly contribute to the clear presentation of the research."}, "weaknesses": {"value": "Regretfully, after careful reading and consideration, I found the contributions of this paper to be predominantly incremental. The work applies established techniques without providing sufficient theoretical insights or novel algorithmic advancements to meet the high standard of ICLR.\n\n=====Lack of technical novelty=====\n1. The proposed attack techniques are quite similar to previous ones, making this paper seems like a patchwork. \nTo name a few:\n- Adversarial Loss Design: The adversarial loss formulation in SCGA directly corresponds to in Zhang et al. \"Beyond ImageNet Attack\" (ICLR 2022). Both employ identical surrogate feature-based similarity metrics in their loss functions.\n- Generator Architecture and Training Pipeline: The generator block division (early/mid/late) and associated weighting strategy in SCGA replicate in Zhang et al. \"Beyond ImageNet Attack\" (ICLR 2022), including hyperparameter configurations and EMA implementation details.\n- Domain-Invariant Generation Strategy: The domain-invariant generator objective in SCGA mirrors in Naseer et al. \"Cross-Domain Transferability of Adversarial Perturbations\" (NeurIPS 2019), sharing fundamental algorithmic approaches and frequency-domain processing methods.\n- Intermediate Feature Alignment: The self-feature consistency mechanism (Equation 3) in SCGA substantially overlaps with in Krishna Nakka & Salzmann \"Learning Transferable Adversarial Perturbations\" (NeurIPS 2021). Both utilize intermediate layer feature similarity metrics with comparable layer selection strategies, differing only in the shift from direct alignment to EMA teacher alignment.\n- Generator Training Framework: The generator training flow, architecture diagram, and projection operator P(·) in SCGA correspond to **Technical Point C** in Poursaeed et al. \"Generative Adversarial Perturbations\" (CVPR 2018), sharing norm constraint implementations and projection procedures.\n- Semantic Clustering Methodology: The semantic region clustering and attention-based masking approach in SCGA duplicates **Technical Point C** in Aich et al. \"GAMA: Generative Adversarial Multi-object Scene Attacks\" (NeurIPS 2022), particularly in feature-clustering and Grad-CAM attention operations.\n- Contrastive Learning Integration: The contrastive learning objective and frequency-domain randomization in SCGA overlap with **Technical Point C** in Yang et al. \"FACL/PDCL\" (2024), employing nearly identical CLIP-driven prompt mechanisms and domain robustness strategies.\nTo address this weakness, I strongly urge the authors set the core contribution apart from baseline techniques of others and switch the focus of this paper on the core contribution instead of these standardly adopted baseline techniques.\n\n=====Lack of theoretical insights=====\n2. This paper brings almost no theoretical insights. As a reader, I get no takeaways after reading this paper. All the mechanistic analysis methods in the paper are just standard techniques used in previous works and appeared to be included merely to pad out the content. \nSpecifically:\n- Figure 1 (Semantic Variability): The visualization of intermediate feature maps and foreground IoU variability is purely descriptive. It shows that early blocks retain more structure, but offers no theoretical explanation for why this occurs or how it fundamentally relates to transferability. The connection between \"lower variability\" and \"higher transferability\" is asserted, not derived from any theoretical principle.\n- Figure 3 (Qualitative Results): The Grad-CAM comparisons and perturbation visualizations merely demonstrate that the method works—not why it works from a theoretical standpoint. Showing that perturbations align more with object regions is an empirical outcome, not an insight into the underlying mechanisms of adversarial generalization.\n- Figure 4 (Feature Differences): The thresholded difference maps are visually intuitive but theoretically shallow. Highlighting where perturbations are added does not explain the fundamental reasons for improved transferability, such as the relationship between feature semantics and model decision boundaries.\n- Spectral Energy Analysis (Table 6): The analysis of low-frequency and high-frequency energy across blocks is a measurement, not an insight. The authors note that their method alters spectral distributions but fail to explain how this connects to theoretical properties of adversarial examples (e.g., spectral bias, frequency-based generalization). The observations are correlational, not causal.\n- Generator Intermediate Analysis: The partitioning of the generator into early/mid/late blocks is an architectural choice, not a theoretical contribution. The analysis does not provide a theoretical model for how or why semantic consistency in early blocks should propagate to enhance transferability—it only shows that it does so in practice.\n- Loss Formulations: The consistency loss (Eq. 3) is a technical implementation detail. The paper does not justify it from a theoretical perspective (e.g., information theory, optimization theory, or generalization bounds). It is presented as a heuristic.\n\n\n=====Incremental experimental improvements=====\n3. Compared to the latest baseline PDCL and FACL, the cross-modal & cross-domain attack performance gain (Tab. 2 & Tab. 3) in average is only ~1%, a very incremental improvement. Comparatively, PDCL improves ~3%.\n4. The baseline setup when evaluating the attack against defense models is very doubtful (Tab. 4). Only Zhang et al, 2022 is adopted as baseline. Why not also compare with PDCA, FACL, and GAMA? \n5. The fooling rate (FR) and accidental correction rate (ACR) is redundant and is not enough to be counted as a contribution.\nIndeed, previous works usually adopt only one metric (e.g. PDCL adopts only accuracy) in evaluation. However, it is reasonable and fair as long as all the attacks are evaluated using the same metric. There is unnecessary to evaluate attacks using too many metrics, as the final conclusion does not change at all no matter which metric you use.\n6. (Suggestion) Craft targeted adversarial examples to see whether the proposed SCGA can improve targeted transfer-based attack.\n7. (Suggestion) The following two references are suggested to be cited since they are also generative-model-based cross-domain transfer attacks.\nLi M, Deng C, Li T, et al. Towards transferable targeted attack. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020: 641-649.\nWang Z, Yang H, Feng Y, et al. Towards transferable targeted adversarial examples. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2023: 20534-20543.\n\n=====Awful writing=====\n8. This paper did not cite the reference paper of each compared baseline to their acronyms. For the convenience of review discussion, I list them here:\n[CDA] Naseer M M, Khan S H, Khan M H, et al. Cross-domain transferability of adversarial perturbations. Advances in Neural Information Processing Systems, 2019, 32.\n[LTP] Salzmann M. Learning transferable adversarial perturbations. Advances in Neural Information Processing Systems, 2021, 34: 13950-13962.\n[BIA] Zhang Q, Li X, Chen Y, et al. Beyond imagenet attack: Towards crafting adversarial examples for black-box domains. ICLR, 2022\n[GAMA] Aich A, Ta C K, Gupta A, et al. Gama: Generative adversarial multi-object scene attacks. Advances in Neural Information Processing Systems, 2022, 35: 36914-36930.\n[FACL] Yang H, Jeong J, Yoon K J. Facl-attack: Frequency-aware contrastive learning for transferable adversarial attacks. AAAI, 2024\n[PDCL] Yang H, Jeong J, Yoon K J. Prompt-driven contrastive learning for transferable adversarial attacks. ECCV, 2024\n9. In the abstract, what is “EMA”?\n10. The font size of Fig.2 is too small, especially for the characters in the “residual learning” and “Upsampling” part. Please improve it."}, "questions": {"value": "Please see Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "dbwMWkGpRj", "forum": "ibXhUapwcz", "replyto": "ibXhUapwcz", "signatures": ["ICLR.cc/2026/Conference/Submission2908/Reviewer_foEg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2908/Reviewer_foEg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission2908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761805324746, "cdate": 1761805324746, "tmdate": 1762916438928, "mdate": 1762916438928, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes Semantic-Consistency guided Generative Attack (SCGA ) for transfer-based black-box image attacks. Instead of only optimizing a surrogate loss (e.g., cross-entropy / feature divergence) on a perturbation generator, the authors align early generator features to an EMA “mean-teacher” copy to preserve object-aligned structure while crafting perturbations. They also introduce Accidental Correction Rate (ACR) to quantify cases where an attack fixes a model’s original mistake—arguably a blind spot of common metrics like FR/ASR/Accuracy. Empirically, the method plugs into several generative baselines and improves transfer across architectures (CNN/ViT/Mixer/Mamba), domains, and tasks (classification, segmentation and detection) without test-time overhead."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.\tSimple, orthogonal mechanism: The EMA teacher + early-block consistency integrates into several strong generative baselines without test-time overhead; the approach is easy to adopt.\n2.\tClear, generator-internal motivation: The diagnostic showing that early generator features retain object contours while later ones blur them is compelling and grounded in measurable variability (foreground-IoU std across blocks).\n3.\tBroad evaluation: Cross-model results span CNN, ViT, Mixer, and SSM/Mamba families, with consistent average gains; the method also improves cross-domain (CUB, Cars, FGVC Aircraft) and cross-task transfer to SS/OD models.\n4.\tRobust-model/defense stress tests. The method improves over baseline against adversarially trained models and input preprocessing defenses (JPEG, bit-depth reduction, randomization & padding)."}, "weaknesses": {"value": "1.\tScope of gains & negative deltas. While averages improve, several cells in Table 2 are near-zero or negative (notably for certain transformer targets and PDCL).\n2.\tFrequency analysis lacks operational detail. The spectral-energy analysis is interesting but currently underspecified. Precisely define the transform (e.g., 2-D FFT with magnitude spectrum), the radial banding scheme (cutoffs in normalized frequency), and whether energies are computed on perturbations or activations. Provide explicit formulas (e.g., radial masks in the Fourier plane) and thresholds so others can reproduce the plots.\n3.\tCompute disclosure is incomplete. Training doubles forward passes (student+teacher), but only forward overhead is reported. Please report end-to-end training wall-clock, backward cost, peak memory, GPU/TPU model & count, and batch/step counts.\n4.\tInterplay with CLIP-driven baselines: The authors themselves note only marginal improvements when stacking on PDCL-style CLIP objectives, and briefly speculate that optimizing in CLIP's high-dimensional space may \"override or dilute\" the structural consistency enforced by SCGA. This explanation is underdeveloped and warrants a deeper investigation.\n5.\tInsufficient Ablation: While the ablation study in Table 5 is useful, it is incomplete. It demonstrates that applying the consistency loss to early blocks is optimal and that all proposed components contribute positively. However, it fails to fully disentangle the benefits of the EMA-updated teacher from the consistency loss itself. The reported gain from \"MT\" could stem from the general smoothing effect of weight averaging, or it could be that the consistency loss is only effective when provided with a stable teacher target. A crucial missing experiment would be to apply $\\mathcal{L}_{cons.}$ without the EMA teacher (e.g., by using a frozen copy of the student from a previous iteration as the target). This would isolate the unique contribution of the temporal ensembling.\n6.\tNo hyperparameter sensitivity. The paper introduces at least two critical hyperparameters, the EMA smoothing coefficient $\\eta$ in Eq. 2 and the consistency loss weight $\\lambda_{cons.}$ in Eq. 5. There are no analysis of the method's sensitivity to their values."}, "questions": {"value": "1.\tHow sensitive are results to η (EMA smoothing), τ (similarity threshold), and the choice/number of early blocks? Any principled way to select them across generator backbones?\n2.\tSince training doubles generator passes (student+teacher), could you provide full wall-clock with backward, peak memory, accelerator type/count, batch size, and total steps/epochs—along with a forward vs. backward breakdown?\n3.\tCould you add side-by-side feature/attribution visualizations against the baseline (the Figure-3.1 setting) to substantiate “object-aligned” perturbations ?\n4.\tWhen SCGA is combined with PDCL/FACL, what specifically conflicts—frequency bands, spatial regions, or representation space mismatch (CLIP vs. surrogate)? Any mitigation (e.g., decoupled schedules)?\n5.\tWhat exact transform and banding do you use (e.g., 2-D FFT magnitude, radial frequency masks, normalized cutoffs), and are energies computed on perturbations or activations (per-channel or aggregated)? Please include explicit formulas and thresholds to ensure reproducibility.\n6.\tTo disentangle the effect of the EMA teacher from $\\mathcal{L}_{cons.}$, could you add a variant that applies the consistency loss without EMA (e.g., a frozen or lagged snapshot of the student as the target)? This would clarify the unique contribution of temporal ensembling."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Xutaq3kZMt", "forum": "ibXhUapwcz", "replyto": "ibXhUapwcz", "signatures": ["ICLR.cc/2026/Conference/Submission2908/Reviewer_7rta"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2908/Reviewer_7rta"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission2908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761937412284, "cdate": 1761937412284, "tmdate": 1762916438723, "mdate": 1762916438723, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new augmentation for generative adversarial attacks aimed at improving their transferability in black-box settings. The core idea is to enforce semantic consistency in the generator's early blocks using a EMA framework with a self-feature consistency loss, thereby stabilizing object-aligned intermediate representations. Then the authors  introduce a new evaluation metric called ACR to detect unintended benign corrections, aiming to provide a more comprehensive view of attack reliability beyond conventional metrics. Through extensive quantitative and qualitative evaluations, including ablation studies and spectral analysis, they demonstrate systematic improvements across diverse architectures, domains, and tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. The self-feature consistency loss is well-motivated and mathematically specified.\n\n2.  The experiments are comprehensive, including multiple model architectures,  cross-domain and cross-task scenarios and fine-grained ablation.\n\n3. The finding of  the semantic drift across generator layers that degrades black-box transferability is novel."}, "weaknesses": {"value": "1. The baseline methods should be introduced before presenting the experimental results, as omitting this order significantly reduces readability.\n\n2. Although the method claims to be architecture-agnostic, there is room for a stronger demonstration across more varied generator or victim types (e.g., diffusion)"}, "questions": {"value": "1. Why does the work only consider untargeted attacks as baselines? It seems that targeted attack methods (e.g., [1]) could also be included for a more comprehensive comparison.\n\n2. How Spectral energy by band is defined and calculated in  Table 6?\n\n3. How would the method compare against the strongest black-box transfer attacks that do not rely on generator-based pipelines (e.g., [2]) ? \n\n\n\n[1] Fang, Hao, et al. \"Clip-guided generative networks for transferable targeted adversarial attacks.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024.\n\n[2] Wang, Xiaosen, et al. \"Admix: Enhancing the transferability of adversarial attacks.\" Proceedings of the IEEE/CVF international conference on computer vision. 2021."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "56lMFM7BdL", "forum": "ibXhUapwcz", "replyto": "ibXhUapwcz", "signatures": ["ICLR.cc/2026/Conference/Submission2908/Reviewer_acvB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2908/Reviewer_acvB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission2908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761949738297, "cdate": 1761949738297, "tmdate": 1762916438521, "mdate": 1762916438521, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the intermediate features within the perturbation generator that are often overlooked in previous generative adversarial attacks.  The authors first note that a stronger attack better preserves the coarse shape from the early layers in the generator. Based on the observation, the authors introduce a lightweight EMA teacher to the early blocks during generator training, which regulates the features to maintain object contours and shapes. Extensive experiments show that the proposed strategy can serve as a plug-and-play technique to improve existing attack methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper is well-written and easy to follow.\n2. The proposed method is simple and intuitive.\n3. The authors provide sufficient experiments across different models and data domains to prove the effectiveness of their method.\n4. Experiments about the intermediate block-level analysis are interesting and provide evidence of preserving image contours and shapes."}, "weaknesses": {"value": "1. The designed method is simple and intuitive, which somewhat lacks novelty as feature-level guidance has been widely investigated in various existing studies.\n2. As shown in Table 2, the proposed method only brings marginal improvements for powerful attacks such as PDCL, raising concerns about its necessity and effectiveness.\n3. Lack experiments against input-processing-based defense methods.\n4. In line 69, a missing full stop after \"generator intermediate blocks\"."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "5PoFwNwbJH", "forum": "ibXhUapwcz", "replyto": "ibXhUapwcz", "signatures": ["ICLR.cc/2026/Conference/Submission2908/Reviewer_y2kS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission2908/Reviewer_y2kS"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission2908/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761991946775, "cdate": 1761991946775, "tmdate": 1762916438395, "mdate": 1762916438395, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}