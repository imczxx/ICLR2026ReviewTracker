{"id": "EWT7ILOzjK", "number": 24377, "cdate": 1758356243547, "mdate": 1759896769016, "content": {"title": "MAS-SAT: Synergizing ML-Assisted and Standalone Solvers for SAT Solving", "abstract": "Machine learning has emerged as a promising approach to accelerate the solving of Boolean satisfiability (SAT), with prior research exploiting graph neural networks (GNNs) either as standalone solvers or to assist existing SAT solvers. Despite their contributions, the two paradigms mainly suffer from poor scalability and limited compute budgets, respectively. To address these challenges, we propose **M**achine learning **A**ssisting and **S**olving **SAT** (MAS-SAT), a novel framework that synergizes the strengths of both paradigms while mitigating their weaknesses. In MAS-SAT, standalone solvers demonstrate improved scalability when solving sub-problems generated by ML-assisted solvers, and ML-assisted solvers achieve better performance under limited compute budgets by leveraging the parallel search ability of standalone solvers. In addition, we develop an efficient asynchronous deployment strategy with influences heuristics to further optimize MAS-SAT. Extensive experiments across diverse domains and architectures demonstrate that MAS-SAT consistently outperforms both paradigms. When deployed, MAS-SAT achieves up to $2.4\\times\\$ median speedup on hard instances and solves $3$ more instances on SAT Competition 2023 compared to the base state-of-the-art solver, kissat.", "tldr": "", "keywords": ["Boolean Satisfiability", "Graph Neural Networks"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/285bc7d6e743f73527d0a3e5181f607cb8e3e9c2.pdf", "supplementary_material": "/attachment/a103eb7f36c057ea073cf2acfa3cbc4b16e9ce1f.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes MAS-SAT, a novel framework that integrates machine learning (ML) models—specifically graph neural networks (GNNs)—with Conflict-Driven Clause Learning (CDCL) SAT solvers in an asynchronous manner. The key idea is to allow the ML component and the CDCL solver to operate independently but cooperatively: while the CDCL solver proceeds with standard search, the ML model runs in the background to analyze the current formula (or a sub-problem) and provide guidance (e.g., variable assignments or clause predictions) that can be injected back into the solver when ready. This decoupling aims to mitigate the latency bottleneck often seen in tightly coupled ML-augmented solvers."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The asynchronous integration of ML and CDCL is a creative architectural choice that addresses a real practical limitation—namely, the computational overhead of GNN inference stalling the core SAT solving loop.\n\n2. If the claimed speedups on competition benchmarks hold under scrutiny, this work could influence how future ML-augmented solvers are designed—particularly in high-performance or embedded settings where latency and resource contention matter."}, "weaknesses": {"value": "1. The most critical weakness is the lack of detailed, reproducible experiments on standard benchmarks. The main evaluation relies on a subset of instances from G4SATBench, which are relatively easy (often solvable in seconds). More importantly, the primary metrics reported are proxy measures—number of GNN message-passing steps and median relative reduction in propagations—not actual wall-clock solving time. While propagation reduction is informative, it does not necessarily translate to speedup, especially if GNN inference is expensive.\n\n2. The paper prominently claims performance gains on the SAT Competition 2023 benchmark (“solves 3 more instances”, “2.4× speedup”), but provides little details. Without this, the claim is unverifiable and potentially misleading."}, "questions": {"value": "1. In Figure 1, Type III appears similar to Type II, especially given that BMM-SAT [1] also interleaves ML predictions with CDCL search in a loop. Showing the key differentiating mechanism in MAS-SAT will be helpful.\n\n2. Line 168 mentions extracting a \"sub-problem\" for the ML model to solve. How is this sub-problem guaranteed to be consistent with the full formula? Could solving it in isolation lead to conflicting assignments when merged back? A brief formalization or example would resolve this concern.\n\n3. Can you provide full experimental details for the SAT Competition 2023 results? Specifically:\n- List of instances solved/unsolved by kissat vs. MAS-SAT\n- Timeouts, hardware specs, and solver configurations\n- Actual wall-clock solving times (not just propagation counts)\n- Breakdown of time spent in GNN inference vs. CDCL search\n\n[1] Online Bayesian Moment Matching based SAT Solver Heuristics. ICML 2020."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "BJN95Ird4b", "forum": "EWT7ILOzjK", "replyto": "EWT7ILOzjK", "signatures": ["ICLR.cc/2026/Conference/Submission24377/Reviewer_727G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24377/Reviewer_727G"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761731594520, "cdate": 1761731594520, "tmdate": 1762943062107, "mdate": 1762943062107, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "As we all know, SAT solving is a hard problem and existing solvers rely on heuristics. This one chooses to bolster a specific class of solver - CDCL - to get a hybrid approach that efficiently splits the problem class between what formal, traditional tools are \"good at\" and what GNNs are \"good at\", with appropriate passing of heuristics in between the two halves. The result is a hybrid approach that gets us superior performance in quite a few real contest-level benchmarks relative to KISSAT (near-SOTA sat solver)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "In fields with established non-neural techniques like SAT solving, there are already excellent tools baked with heuristics over the years. In these cases, fresh ML approaches often do not scale because they use those tools as label generators and have to compete in other ways such as runtime, early prediction, etc. The hybrid approaches such as this paper make the most sense there, as it is unlikely that existing users of the field will switch easily."}, "weaknesses": {"value": "There are some drawbacks. In particular, CDCL is not the only class of solver, neither might KISSAT be a one-and-done baseline. SAT contest results will make clear that variants of KISSAT are used in practice, and it is unclear how much this approach adds atop common variant-making techniques like multi armed bandit extensions. Further, a lot of industrial relevance is tied up in extending SAT-level work to SMT-level work such as Z3 which is built around the CDCL core but adds a lot of other tools. How can the paper's approach scale ? \n\nComing to the empirical results, by far, the most meaningful result is the SAT contest one. Generally speaking, getting only 3 extra instances in a contest for a significant change is somewhat low, and there is no analysis (were >3 instances gained and some dropped ? The runtime is improved - how, uniformly across all the instances ? Or in a peaky way). \n\nThere is also no discussion of how this may mean anything for DPLL solvers or for hybrid portfolio methods. Indeed, the paper's right comparison might be to portfolio methods, given that it almost ensembles two things together."}, "questions": {"value": "Can you comment on the weaknesses ? In particular, instead of comparing to kissat, should the comparison not be to the improvement atop kissat which takes effort comparable to the paper, such as a simple 2/3-portfolio of solvers ? How will your approach scale to DPLL solvers / SMT ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "vspjbgKnih", "forum": "EWT7ILOzjK", "replyto": "EWT7ILOzjK", "signatures": ["ICLR.cc/2026/Conference/Submission24377/Reviewer_Pip4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24377/Reviewer_Pip4"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761784011432, "cdate": 1761784011432, "tmdate": 1762943061900, "mdate": 1762943061900, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces MAS-SAT, a method that combines ML–assisted and standalone SAT solvers. It uses a graph neural network that can both guide a traditional CDCL solver and directly predict satisfying assignments. The paper describes multiple optimizations to the standalone solver and the ML-assisted solvers by leverage the information shared between the two solvers. Experiments on several benchmark datasets show that MAS-SAT results in overall performance gain on existing benchmarks from the GNN SAT literature and the SAT competition."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The idea to integrate a stand-alone GNN solver and a GNN-assisted SAT solver is novel and interesting.\n- The paper describes several ways in which information can be shared between the SAT solver and the GNN to improve the execution of the SAT solver and the efficiency of the GNN. These techniques are novel to me, and empirically, they result in increased performance compared to previous GNN-based solutions."}, "weaknesses": {"value": "- The paper does not report the absolute runtime of the solvers on the evaluated benchmarks, making it difficult to evaluate the significance of the performance gain. If the absolute runtime is small, then even the largest median speed up of 2.4x is not very practically interesting. For SAT competition results, a gain of 3 additional solved benchmarks could simply be noise, especially if there were no significant overall runtime improvement. The paper should include a cactus plot or a scatter plot that compares the actual runtime of the proposed method with that of the baseline method. \n- The paper frames the previous work's design choice of \"synchronous\" execution of the GNN as a limitation of the prior work. However, executing the GNN in the background simply means one devotes more computational resources in parallel, which is relatively straightforward to do and also makes the comparison with Kissat a little more unfair."}, "questions": {"value": "- Could you report the absolute runtime?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "lLUp8f2jAS", "forum": "EWT7ILOzjK", "replyto": "EWT7ILOzjK", "signatures": ["ICLR.cc/2026/Conference/Submission24377/Reviewer_gowR"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24377/Reviewer_gowR"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969679993, "cdate": 1761969679993, "tmdate": 1762943061650, "mdate": 1762943061650, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes, MAS-SAT, which is a combination of 1) machine learning assisted sat solving and 2) machine learning as a standalone solver. MAS-SAT is agnostic to underlying machine learning models as long as they are graph neural networks (GNNs). MAS-SAT augments the state representation by incorporating learned clauses by the CDCL heuristic, a standard heuristic used in modern SAT solvers. MAS-SAT runs two solvers (i.e., CDCL solver and ML agent) asynchronously. The experimental evaluations on G4SATBench indicate that MAS-SAT outperforms each individual solver according to the proposed metrics."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- this paper explores a hybrid combination of two different styles of ML assisted SAT solvers,  which has not been studied by previous works\n- the asynchronous design of two solvers can better leverage compute resources"}, "weaknesses": {"value": "- the contribution of this work and reported improvements are due to engineering effort or system design, which is less about machine learning innovations\n- slight improvement is somewhat expected, since more compute resources are used in the asynchronous setting\n- the idea of augmenting graphs with newly learnt clauses has been studied in the prior work (e.g., G4SATBench), thus not a new contribution\n- there are no experimental comparisons with other GNN-based SAT solving\n- it is worth noting that portfolio approaches (Balyo et al 2015) are known to be able to outperform individual SAT solvers, and for this very reason, they are forbidden to participate later SAT competitions.\n\nTomás Balyo, Peter Sanders, Carsten Sinz: HordeSat: A Massively Parallel Portfolio SAT Solver. SAT 2015: 156-172"}, "questions": {"value": "What does $n$ the number of GNN message passing mean? Is it the number of interactions between CDCL solver and GNN assisted solver? Similarly, what does $r$ (i.e., relative reduction of propagations with respect to kissat) mean?  Why do they better reflect the performance of SAT solving compared to an obvious metric like running time?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gnOcvubdNJ", "forum": "EWT7ILOzjK", "replyto": "EWT7ILOzjK", "signatures": ["ICLR.cc/2026/Conference/Submission24377/Reviewer_k2hd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24377/Reviewer_k2hd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24377/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762468715529, "cdate": 1762468715529, "tmdate": 1762943061340, "mdate": 1762943061340, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}