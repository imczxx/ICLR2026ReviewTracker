{"id": "Ri9FViINBU", "number": 8567, "cdate": 1758091209942, "mdate": 1762988747521, "content": {"title": "PEROV-H3: Evaluating Generative Models under Size and Symmetry Shifts in Hydrogen-Storage Perovskites", "abstract": "We introduce PEROV-H3, a rigorous benchmark targeting ABH$_3$ perovskites, designed to evaluate generative models under controlled size and symmetry shifts with structure-aware metrics. In materials science, models often excel on ideal, periodic crystals yet degrade on finite nanoparticles where size, surfaces, and edges dominate. PEROV-H3 closes this gap by pairing two complementary tasks: $(i)$ unit-cell $\\rightarrow$ nanoparticle generation, probing surface- and size-dependent distortions; and $(ii)$ nanoparticle $\\rightarrow$ unit-cell reconstruction, recovering bulk lattice parameters and symmetry. The benchmark comprises 100 DFT-relaxed ABH$_3$ compositions and 210,000 nanoparticle configurations spanning radii $R\\in\\{6,\\dots,30\\}$ Angstrom (systematic size splits for ID/OOD). Baselines reveal substantial errors under extrapolation, especially in symmetry and lattice recovery, indicating that current models memorize templates rather than learn the physics of scale. PEROV-H3 thus provides a chemically diverse, size-systematic, and structurally clean testbed for stress-testing generative models beyond bulk crystals. The dataset and the implementation are available at https://anonymous.4open.science/r/PEROV-H3.", "tldr": "", "keywords": ["crystal generation", "dataset", "hydrogen storage", "perovskites", "generative ai"], "primary_area": "datasets and benchmarks", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/ca01969b5d0016c7aa0658d90fa2d72e2aaa3e89.pdf", "supplementary_material": "/attachment/c0b394b13af5add0523da8203c999462353a353e.pdf"}, "replies": [{"content": {"summary": {"value": "This paper introduces PEROV-H3, a benchmark designed to evaluate generative models under size and symmetry shifts using a family of ABH₃ perovskites relevant to hydrogen storage.\nThe benchmark pairs two complementary tasks:\n- Unit cell → nanoparticle generation, which tests whether models can generate finite nanoparticles of various radii from a crystalline prototype;\n- Nanoparticle → unit cell reconstruction, which tests whether models can infer lattice parameters and symmetry from a finite structure.\n\nThe dataset includes 100 DFT-relaxed perovskite unit cells and 210,000 geometrically truncated nanoparticles covering radii from 6–30 Å.\nSeveral generative models (CDVAE, DiffCSP, FlowMM, MatterGen, ADiT) are evaluated, showing severe degradation under size extrapolation.\nThe authors claim that PEROV-H3 fills a key gap in testing whether generative models “learn the physics of scale.”"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The benchmark explicitly tests scale generalization and symmetry recovery, which are rarely considered in existing crystal-structure datasets (e.g., Matbench, CSPBench).\n- The construction pipeline, rotational sampling on SO(3), and radius-based ID/OOD splits are carefully described and mathematically formalized.\n- A paired dataset linking bulk and finite systems could be useful for future work on nanoscale materials modeling, surface property prediction, and hydrogen storage."}, "weaknesses": {"value": "- The paper does not clearly explain why AI is needed for nanoparticle prediction. There is no comparison with existing physical methods or evidence that conventional simulations (e.g., DFT, Wulff construction) are too slow or limited. As a result, the motivation feels artificial rather than driven by a real computational bottleneck.\n- Nanoparticles are generated by spherical truncation without surface relaxation or energy minimization, ignoring well-known physical models such as Wulff construction. This makes the dataset geometrically clean but physically unrealistic.\n- The experiments occupy less than two pages and provide no quantitative tables or visual examples. All models are said to “fail,” but no diagnostic analysis or insight is provided about why they fail or how their architectures behave differently.\n- Since every baseline model collapses, the benchmark does not reveal differentiating strengths or weaknesses. It is unclear whether the failure stems from task mismatch, data design, or missing inductive biases.\n-The dataset includes only ABH₃ compositions and two space groups, with no energy or property labels. This restricts both scientific applicability and the potential to evaluate physically meaningful model performance."}, "questions": {"value": "- How does the proposed benchmark address a real computational or scientific bottleneck compared to existing physical methods such as DFT-based Wulff construction or classical MD simulations?\n- What is the expected benefit or acceleration from using AI models on this task—has any runtime or efficiency comparison been made?\n- Since the nanoparticles are generated by geometric truncation without surface relaxation, how physically meaningful are these structures for evaluating generative models?\n- All evaluated models were designed for periodic crystals—does their failure reflect flaws in the models or a mismatch with the task definition?\n- Why were only two space groups (Pm-3m, Cmcm) and the ABH₃ composition family chosen? Would the benchmark generalize to other materials systems?\n- Are there any plans to release energy, stability, or surface property annotations that would allow physically grounded evaluation beyond geometry?\n- What are the key insights for future model design drawn from the observed failures—what inductive biases or architectural features are missing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "N/A"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0yX9fWQU8g", "forum": "Ri9FViINBU", "replyto": "Ri9FViINBU", "signatures": ["ICLR.cc/2026/Conference/Submission8567/Reviewer_6gjW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8567/Reviewer_6gjW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8567/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761578145348, "cdate": 1761578145348, "tmdate": 1762920421847, "mdate": 1762920421847, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "OgawpE334O", "forum": "Ri9FViINBU", "replyto": "Ri9FViINBU", "signatures": ["ICLR.cc/2026/Conference/Submission8567/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8567/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762988746735, "cdate": 1762988746735, "tmdate": 1762988746735, "mdate": 1762988746735, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces a benchmark for evaluating generative models on a perovskite hydride nanoparticle dataset with controlled size and orientation splits. It assesses several generative models for crystal structures using structure-aware metrics for two tasks: (i) generating nanoparticles from a given unit cell and particle radius, and (ii) recovering lattice parameters and space group from a provided structure."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Well-motivated effort to create a nanoparticle dataset and a large, systematically constructed collection. \n- Public code and data will be valuable for the materials modeling community."}, "weaknesses": {"value": "My current score is limited by concerns about task definitions and benchmark design; I will adjust the score once these issues are addressed.\n\n- The motivation in Sections 1 and 2.1 is clear, but the central scientific challenges for nanoparticles, such as surface distortions and reconstructions from under-coordinated atoms, are not captured in the benchmark. Although the Limitation section acknowledges this \"ideality,\" the absence of surface reconstructions weakens the scientific relevance and undermines the claim that the benchmark reflects realistic generative modeling needs. Specifically:\n    - Task 1 is almost deterministic. Nanoparticles are generated by carving a sphere from a periodic supercell. A simple rule-based algorithm could reproduce the targets without learning a distribution. Without surface non-idealities, the task does not meaningfully require a generative model.\n    - Task 2 is an inverse problem, essentially supervised regression + classification (lattice and space group prediction), or a constrained optimization with symmetry detection. It is not inherently generative.\n    - If the benchmark is meant to justify generative approaches, it should either (i) include realistic, multimodal nanoparticle physics where sampling uncertainty matters, or (ii) redefine the tasks so that models receive far less structural information (e.g., only composition).\n- Because the tasks are not naturally generative, it is unclear why prior generative models are used as baselines. After inspecting the provided code, I found that the implementations are substantially modified \"reinterpretations\" of the cited methods rather than faithful reproductions. For example, DiffCSP and FlowMM were originally based on EGNN, and MatterGen on GemNet, but the benchmark implementations replace these with different architectures and do not use the official libraries. Since the reported results reuse the original model names, the deviations should be clearly explained in the main text, not only in the code."}, "questions": {"value": "- The carved nanoparticles can become off-stoichiometric under the current procedure. Could this affect the generative task or the physical validity of the outputs?\n- In the lattice parameter task, the model predicts three lengths and three angles, yet the reported RMSE is 32–64 Å, far larger than the typical lattice constant range (3–7 Å, up to ~17 Å). This suggests a possible unit/scale mismatch or an implementation issue in the RMSE calculation. In addition, only cubic and orthorhombic cells are included, so all angles are 90°, making angle prediction effectively trivial.\n- For joint recovery, exact matching of real-valued properties is required. Please clarify the numerical tolerance used to decide correctness.\n\nMinor typos/comments\n- p. 3 Fig 1, blue <-> red; lattice parameter is only reported for $a$ and the max unit cell volume (706.5) seems inconsistent with the max $abc$ product\n- p. 6 Sec 3.7, a particle $\\mathcal{P} \\in \\mathbb{R}^3$ -> $\\mathcal{P} \\in \\mathbb{R}^{n \\times 3}$"}, "flag_for_ethics_review": {"value": ["Yes, Other reasons (please specify below)"]}, "details_of_ethics_concerns": {"value": "The code repository linked in the abstract contains a license file that reveals the author’s identity, which violates the anonymity policy."}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HrUGVYHx7T", "forum": "Ri9FViINBU", "replyto": "Ri9FViINBU", "signatures": ["ICLR.cc/2026/Conference/Submission8567/Reviewer_iFXq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8567/Reviewer_iFXq"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8567/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761968925482, "cdate": 1761968925482, "tmdate": 1762920421192, "mdate": 1762920421192, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces PEROV-H3, a benchmark designed to evaluate generative models' generalization performance between crystalline unit cells and finite nanoparticles of ABH3 perovskites. The authors construct a dataset of 100 DFT-relaxed unit cells and over 210,000 nanoparticles spanning controlled radii (6–30 Å) and orientations, defining two bidirectional tasks—unit-cell → nanoparticle generation and nanoparticle → lattice reconstruction—with structure-aware metrics for geometry and symmetry. Experiments with state-of-the-art models (CDVAE, DiffCSP, FlowMM, MatterGen-MP, ADiT) show that while some achieve low structural errors on intermediate sizes, all models degrade significantly on out-of-distribution radii, with severe failures in symmetry and lattice recovery. These results demonstrate that PEROV-H3 effectively exposes current models’ limitations in capturing the physics of scale and symmetry in generative crystal modeling."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors present well-designed, physics-aware splits and metrics (size extremes, rotation disjointness; structural metrics for both local/global geometry) for the benchmark.\n\n2. Bidirectional tasks that jointly test surface distortions and symmetry/lattice recovery—rare in existing benchmarks."}, "weaknesses": {"value": "1. The experimental results, especially Table 1, for the crystal structure prediction task are suspicious. In both the in-distribution and out-of-distribution settings, CDVAE achieves 10^3  times better performance than the other models (including more advanced ones such as FlowMM and MatterGen). The evaluation metrics of the rest of the models are uniformly poor and nearly identical, e.g., the performance of FlowMM and DiffCSP are almost exactly the same. The authors do not provide a clear or convincing explanation for why these baseline models perform so (equally) poor in this scenario.\n\n2. The structures in the proposed benchmark are only in the form of ABH3, which limits the applicability of the benchmark."}, "questions": {"value": "Can the authors explain the experimental results mentioned in Table 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "9Ll5EYJhZO", "forum": "Ri9FViINBU", "replyto": "Ri9FViINBU", "signatures": ["ICLR.cc/2026/Conference/Submission8567/Reviewer_HVMT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8567/Reviewer_HVMT"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8567/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984329450, "cdate": 1761984329450, "tmdate": 1762920420097, "mdate": 1762920420097, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces PEROV-H3, a benchmark for materials generative models. The benchmark consists of 100 different perovskite materials that were used to construct nanoparticles. Two tasks were defined, one to predict the nanoparticle from the unit cell and one to predict the unit cell from the nanoparticle (lattice parameters and symmetry group). Multiple evaluation metrics were defined for each task, and a comprehensive set of baseline models was tested."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Developing new benchmarks for generative models in materials science is an important research area.\n- The paper is well written and thorough on the ensuring quality ID and OOD splits.\n- The paper evaluates a comprehensive suite of baseline models."}, "weaknesses": {"value": "- Although this work addresses the important need for new benchmarks in generative materials modeling, the correlation between the proposed tasks and practical utility has yet to be established. It would greatly strengthen the paper if the authors were able to demonstrate the utility of the tasks in practical materials science applications such as hydrogen storage. \n- The overall diversity of the benchmark is limited. Perovskites represent a small subset of overall diversity in materials."}, "questions": {"value": "1. Did you reimplement all the baseline models? Or use existing implementations?\n2. How do the tasks described in the paper contribute to understanding hydrogen storage in Perovskites? Additionally, how would a model excelling at these tasks accelerate Perovskite-based hydrogen storage research?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "1hyJI6K53r", "forum": "Ri9FViINBU", "replyto": "Ri9FViINBU", "signatures": ["ICLR.cc/2026/Conference/Submission8567/Reviewer_JSzy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8567/Reviewer_JSzy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8567/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761993257595, "cdate": 1761993257595, "tmdate": 1762920419529, "mdate": 1762920419529, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}