{"id": "DnJPI4byYj", "number": 6025, "cdate": 1757950851107, "mdate": 1763033028595, "content": {"title": "LatentStealth: Unnoticeable and Efficient Adversarial Attacks on Expressive Human Pose and Shape Estimation", "abstract": "Expressive human pose and shape estimation (EHPS) plays a central role in digital human generation, particularly in live-streaming applications. However, most existing EHPS models focus primarily on minimizing estimation errors, with limited attention on potential security vulnerabilities, such as generating inappropriate content, violent actions, or racially offensive gestures and expressions. Current adversarial attacks on EHPS models often generate visually conspicuous perturbations, limiting their practicality and ability to expose real-world security threats. To address this limitation, we propose an unnoticeable adversarial method, termed \\textbf{LatentStealth}, specifically tailored for EHPS models. The key idea is to exploit the structured latent representations of natural images as the medium for crafting perturbations. Instead of injecting noise directly into the pixel space, our method projects inputs into the latent space, where adversarial patterns are generated and progressively refined along optimized directions. This latent-space manipulation enables the attack to maintain high imperceptibility while preserving its effectiveness. Furthermore, as the optimization process is guided by only a small number of model output queries, the framework achieves competitive attack performance with low computational overhead, making it both practical and efficient for real-world scenarios. Extensive experiments on the 3DPW and UBody datasets demonstrate the superiority of LatentStealth, revealing critical vulnerabilities in current systems. These findings highlight the urgent need to address and mitigate security risks in digital human generation technologies.", "tldr": "", "keywords": ["Human Pose and Shape Estimation", "Adversarial attack", "Unnoticeable attack"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/cd311517bcac33a9ace8dab254918e6c044e13c6.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces LatentStealth, a novel adversarial attack method for expressive human pose and shape estimation (EHPS) models. It highlights that while existing EHPS models reduce estimation errors, they often neglect security vulnerabilities. Current attacks produce noticeable perturbations, limiting practicality. In contrast, LatentStealth generates imperceptible adversarial examples by manipulating the latent space of a Variational Autoencoder (VAE) using low-magnitude Gaussian noise and iterative optimization. Experiments on the 3DPW and UBody datasets show significant improvements in attack performance with low computational costs."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper is easy to follow.\n2. The research problem is interesting. The exploration of adversarial attacks on EHPS models addresses a timely and relevant issue in digital human modeling.\n3. Demonstrates significant increases in pose estimation errors."}, "weaknesses": {"value": "1. While the paper claims that optimization is performed in latent space, in practice only the initial noise in the first step is generated there. The subsequent optimization takes place in pixel space, following a procedure similar to Projected Gradient Descent (PGD), according to Eq.18-22. Moreover, as stated in Line 353, the first step uses a fixed value of η (0.05) rather than selecting it according to Equation 13. This design choice raises concerns about the effectiveness of the initial step and, consequently, casts doubt on the authors’ assertion of achieving substantially better performance than PGD.\n2. In Figure 2, the images for the FGSM, PGD, and PCA methods are the same as the clean image, but according to Table 1, they should be different.\n3. In the introduction, the authors mention a potential application scenario involving the generation of disturbing scenes, such as a broken neck. However, the method they actually use adopts an untargeted attack objective—maximizing the overall error. It would be more convincing if the authors could evaluate targeted attacks, for instance, focusing on specific regions such as the neck.\n4. The paper states that the perturbations produced by TBA are visually perceptible and fail to pass human inspection. However, they did not conduct comparison experiments on the visual qualities of TBA and their own method.\n5. Lack of transferability experiments. Does the method  be transferable to black-box models?\n\nSmall error:\n1. The citation format is incorrect; the name should be in brackets. Please refer to ICLR's template"}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "QrBlRjTkSF", "forum": "DnJPI4byYj", "replyto": "DnJPI4byYj", "signatures": ["ICLR.cc/2026/Conference/Submission6025/Reviewer_6DHA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6025/Reviewer_6DHA"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6025/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761456801815, "cdate": 1761456801815, "tmdate": 1762918419228, "mdate": 1762918419228, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "NPbuBgXv7s", "forum": "DnJPI4byYj", "replyto": "DnJPI4byYj", "signatures": ["ICLR.cc/2026/Conference/Submission6025/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission6025/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763033027645, "cdate": 1763033027645, "tmdate": 1763033027645, "mdate": 1763033027645, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "LatentStealth introduces an adversarial attack for expressive human pose & shape estimation (EHPS). It perturbs a pretrained VAE’s latent code to create imperceptible seeds, then refines them in pixel space with a multi-task loss that maximizes pose/shape errors while constraining visual distortion."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. LatentStealth is a black-box attack method where the attacker can only access the model’s output under a strict query budget.\n\n2. The validation covers two benchmarks (3DPW, UBody) and across multiple EHPS backbones/variants"}, "weaknesses": {"value": "1. I found the pipeline of this work is too similar to the work of Li et al. (Pattern Recognition 2026); the core components such as latent space noise injection, noise optimization, and enhancement are almost identical. Although the authors replace the first stage with a VAE architecture, I believe the essence of the methods is the same. This makes me think the paper lacks real novelty.\n\n2. The Output-access assumption may be unrealistic. The loss is defined on full EHPS parameters $P(x)=(\\alpha,\\beta,\\gamma)$; many production APIs expose only meshes, 2D/3D keypoints, or rendered frames. The paper does not test such constrained-output settings. \n\n3. The whole attack pipeline over relies on a specific VAE. The attack is tied to stabilityai/sd-vae-ft-mse; there’s no study of robustness to swapping the generative prior or to distribution shift between the VAE’s training data and EHPS inputs.\n\n4. The Query-efficiency not benchmarked against modern black-box attacks. Comparisons include FGSM/PGD and diffusion-based baselines, but omit standard query-based black-box methods (e.g., NES/Square) under matched query budgets, leaving the efficiency claim under-substantiated.\n\nREF: Li Z, Jin Y, Shen F, et al. Unveiling hidden vulnerabilities in digital human generation via adversarial attacks[J]. Pattern Recognition, 2026."}, "questions": {"value": "See the weakness part of my review."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety"]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "J70VeZWGri", "forum": "DnJPI4byYj", "replyto": "DnJPI4byYj", "signatures": ["ICLR.cc/2026/Conference/Submission6025/Reviewer_VQXZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6025/Reviewer_VQXZ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission6025/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761660403500, "cdate": 1761660403500, "tmdate": 1762918418798, "mdate": 1762918418798, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LatentStealth, the first imperceptible adversarial attack designed for expressive human pose and shape estimation (EHPS) models. Instead of perturbing pixel space, the method injects low-magnitude noise into the latent space of a pretrained VAE and refines perturbations via a multi-task loss, ensuring both attack effectiveness and visual stealthiness under strict query budgets. Experiments on datasets 3DPW and UBody demonstrate substantial error increases across state-of-the-art EHPS models, while maintaining imperceptibility and efficiency. This work exposes critical security risks in digital human modeling and provides a novel attack paradigm."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "[1] The paper introduces the first method that perturbs the latent space of a pretrained VAE to attack expressive human pose and shape estimation. This is a simple but powerful idea: perturbations added in latent space generate adversarial images that are visually indistinguishable from the original in pixel space, making the attack more stealthy.\n[2] The proposed multi-task loss elegantly trades off adversarial strength with visual fidelity, offering a practical blueprint for adversarial optimization under realistic constraints."}, "weaknesses": {"value": "[1] The paper should more precisely state its novelty (“the first systematic application of latent-space attacks to EHPS”) and directly compare/contrast with existing latent-space adversarial work. The authors must highlight what is genuinely new in algorithmic design, loss formulation, or query-efficient optimization. \n[2] The paper references live streaming, but experiments are on static images. The authors should evaluate temporal coherence and runtime/query cost on continuous frames or restrict claims to static images.\n[3] Current experiments use a pre-trained VAE and a few EHPS backbones, some older. The authors should compare against more recent EHPS models and test the attack with other generative priors to demonstrate whether the method is broadly applicable.\n[4] The paper injects Gaussian noise into latent space as an initialization and then refines in pixel space. However, practical threats may require targeted manipulations (forcing specific pose/shape changes). The authors should show how to extend their approach to targeted attacks and evaluate the trade-off between stealthiness and success rate. The current study primarily demonstrates untargeted degradation.\n[5] Lack of defense discussion or experiments. Security papers should at least discuss plausible defenses and provide preliminary evaluations."}, "questions": {"value": "Your abstract claims “the first systematic application of latent-space attacks to EHPS.” What is precisely novel relative to existing latent-space adversarial work? Please specify concrete additions in (a) algorithmic design, (b) loss formulation, and (c) query-efficient optimization, and provide side-by-side comparisons.\n\nYour text references live streaming, but experiments are on static images. Also, the evaluation uses a pre-trained VAE and a few (some older) EHPS backbones. Can you (a) validate temporal coherence and per-frame runtime/query budgets on short video clips, and (b) test on newer EHPS models and alternative generative priors to demonstrate breadth? If not feasible now, will you limit claims to static images and a specific prior?\n\nYour current pipeline injects Gaussian noise in latent space and refines in pixel space, mainly showing untargeted degradation. Can you extend to targeted manipulations (e.g., specific pose/shape changes) and analyze the stealthiness–success trade-off, and discuss and preliminarily evaluate defenses?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "A7DifiMxUV", "forum": "DnJPI4byYj", "replyto": "DnJPI4byYj", "signatures": ["ICLR.cc/2026/Conference/Submission6025/Reviewer_m8fQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6025/Reviewer_m8fQ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission6025/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761786457973, "cdate": 1761786457973, "tmdate": 1762918418474, "mdate": 1762918418474, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a unnoticeable adversarial attack, LatentStealth, against expressive human pose and shape estimation (EHPS) models. The input samples are first projected into the latent space, perturbed with low-magnitude noise, and then decoded back to image space to generate adversarial variants that remain close to the original inputs. The results showed an improvement in estimated pose errors compared to baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper writing is clear and easy to follow. The authors visualize the results of their attack, which clearly shows that the adversarial examples generated by their method induce significant errors in the estimated human poses."}, "weaknesses": {"value": "1. The motivation of this attack is not very clear. The authors should provide more details about the scenarios in which this attack will be used and explain why it is important to attack human pose and shape estimation.\n\n2. The proposed method lacks novelty. Perturbing the latent space of generative models has been widely used in adversarial attacks for various vision tasks. The authors should explain why this method is especially better for the EHPS models.\n\n3. The comparison with baselines is unfair. The perturbation of the baseline methods is constrained by the l-inf norm, while that of the proposed method is softly constrained. The authors should provide more analysis on how this affects the results, such as comparing the norm of the perturbations generated by different methods, and evaluating the baselines (e.g., C&W attack) with similar perturbation norms."}, "questions": {"value": "1. Which VAE model is better to use in this work? Will it be better to be trained on the same dataset as the EHPS models? \n\n2. What do the adversarial examples look like for different methods? What if using different constraints on the perturbations?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "MOv2hY2TAj", "forum": "DnJPI4byYj", "replyto": "DnJPI4byYj", "signatures": ["ICLR.cc/2026/Conference/Submission6025/Reviewer_BuJd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission6025/Reviewer_BuJd"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission6025/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954436178, "cdate": 1761954436178, "tmdate": 1762918418150, "mdate": 1762918418150, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}