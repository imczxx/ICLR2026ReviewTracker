{"id": "2Epwf39xsY", "number": 20058, "cdate": 1758301994131, "mdate": 1759897003950, "content": {"title": "Bounded Working Memory for LLMs: Reproducing Human Recall Dynamics", "abstract": "We introduce a cognitively inspired working memory module for large language models (LLMs) that enables efficient narrative recall under capacity constraints. Our approach decomposes input text into structured memory chunks using four methods—semantic, phrase, sentence, and schematic chunking—and integrates prioritization strategies based on salience, connectivity, and temporal decay. These mechanisms enforce a bounded memory capacity, inspired by Miller’s number, while preserving information critical for downstream recall. We evaluate the framework on the Naturalistic Free Recall dataset, where models must reconstruct long-form narratives from compressed memory representations. Memory-augmented LLMs achieve higher semantic similarity to human recall transcripts than random baselines, while exhibiting structured retrieval effects such as primacy and recency. These results demonstrate that chunk-based working memory improves the plausibility and efficiency of LLM recall, offering a scalable approach for constrained-context reasoning and memory alignment.", "tldr": "We develop a chunking based memory module for LLMs modeled on working memory and Miller's number.", "keywords": ["memory", "chunking", "LLMs"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3863b19b283de143939adab1432f7ff2a6c78bb4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a bounded memory system for LLMs inspired from cognitive psychology principles. It chunks narratives into the famous M=7-9 units using four methods (semantic, phrase, sentence, schematic), applies prioritization mechanisms (salience, connectivity, temporal decay), then has an LLM reconstruct stories from such compressed memory. The approach is evaluated on the Naturalistic Free Recall dataset, achieving ~0.75 semantic similarity to human recalls and exhibiting , similarly, primacy/recency effects."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- First comparison of LLM narrative synthesis against human free-recall data\n\n- Appropriate statistical methods: bootstrap confidence intervals, permutation tests."}, "weaknesses": {"value": "- No evidence that bounded memory helps. The paper does not vary M or show an efficiency–quality trade off. With the curent state, the \"bounded is beneficial\" claim is unsubstantiated. \n\n- Random baseline performs close to structured approach, undermining the carefully designed chunking + prioritization system. In general, the observed results could be inherent properties of the LLMs, not a consequence of the experimental protocol of this paper. The paper does not rule out this possibility.\n\n- Missing critical baselines: e.g. no comparison to LLM summarization (\"Summarize this story in 7 key points\"), and no comparison to LLM-as-selector (having the LLM choose important segments)\n\n- The semantic similarity methods are weak. LLM as a judge could have been used here as well. \n\n- Correlation vs. causation confound: LLMs trained on human-generated text naturally exhibit human-like biases. You provide no evidence that your chunking causes the human-like patterns rather than the LLM simply imitating what it learned during pre-training. How do you know it's not just: any memory constraint + LLM => human-like recall?\n\n- No ablation on semantic/phrase/sentence chunking, or prioritization. No study of the impact of M.\n\n- Poor presentation: figures legend and labels unreadable."}, "questions": {"value": "- How do you disentangle whether human-like patterns arise from your chunking vs. LLMs having learned human biases during training? Do LLMs behave like humans because they imitated human learning in training or because of your chunking? \n\n- \"LLM lacks selective mechanisms to prioritize\" : this is a strong claim, given that attention in LLM does exactly that...\n\n- Which chunking method works best? which prioritization? How sensitive are the results to M? (What happens beyond 7-9?)\n\n- Humans have bounded working memory, but at the same time, they have \"real-time continual learning\" capabilities, which make their context longer than just 8 working memory items."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "xKUqOwd9CS", "forum": "2Epwf39xsY", "replyto": "2Epwf39xsY", "signatures": ["ICLR.cc/2026/Conference/Submission20058/Reviewer_1mw1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20058/Reviewer_1mw1"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20058/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761865810943, "cdate": 1761865810943, "tmdate": 1762932952133, "mdate": 1762932952133, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a cognitively inspired LLM memory module that inputs a narrative and: (i) extracts information by chunking, before (ii) doing memory prioritization by keeping around 7 chunks. The constraint in the number of output chunks is the central idea of the work: instead of assuming unlimited memory access, only the important information is kept. The exact number of chunks to keep (from 7 to 9) is inspired from human working memory.\n\nThe information is extracted from the narrative using 4 chunking methods: semantic chunking (word to word), two kinds of sentence chunkings, and schematic chunking (event extraction model, each event summarized by a character, a goal, an obstacle and an outcome).\n\nThen, for the memory prioritization, three mechanisms are introduced:\n- each chunk (irrespective of how they have been built) has a salience score assigned (proportional to how many nouns and verbs are present in the chunk)\n- each chunk is embedded, then represented as a vertex of a graph, and a relation score between each pair of chunks is defined; finally the chunks with the largest values are prioritized\n- finally, the chunks can be organized in the temporal order, and a streaming replacement mechanism is defined.\n\nIn the experimental setting, the authors use a dataset named \"Naturalistic Free Recall\" that contains recall information provided by humans after reading each two books. For each participant, one of the book is used as a training set, and a memory agent is created based on this training set, that consists in selecting a subset of chunking mechanisms and memory prioritizations. In total 229 memory agents are created. Each agent is tested on the other book, and the performance is compared against the human performance and a random baseline."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- studying under the strict constraint in the number of output chunks is valuable\n- the list of chunking and selection are meaningful"}, "weaknesses": {"value": "- the experimental part is shallow both in quantity and in explanations (see questions), including missing information regarding the benchmark dataset, the definition of the metrics used\n- the authors mention a \"systematic combination of chunking methods and prioritization methods\", but the combination is far from systematic (details in the questions part)\n- there is no discussion about the computational efficiency claimed in the conclusion\n- regarding the presentation, I was not able to understand the orchestration of the chunk prioritizations in practice, and the trade-offs applied between the different mechanisms"}, "questions": {"value": "### Datasets and metrics \n\n1. The naturalistic free recall dataset is not detailed or referenced in the paper. \n\n- In particular, what are the experimental settings for the participants, how long are the books? The recollection is done immediately after the reading?\n- Is working memory of the participants the unique memory component involved during the experiment?\n- What is the size of the books, and the number of events T extracted from each book (following the notation in the paragraph close to Eq. 11)?\n\n2. The semantic similarity between the story and the recalled story is measured with the ModernBERTScore, that is not detailed or referenced in the paper\n\n- Can you provide a definition of this metric?\n\n### Method section\n\n- Semantic chunking: are the computations quadratic w.r.t the length of the book? Why tau is selected to be 0.2\n- In Eq. 6, how are selected alpha, beta and delta? Is it given by the existing literature?\n- What is the quantitative size of the collected set of chunkings before the prioritization? For example, how many schematic events are extracted, how many semantic chunking?\n- Does the number of semantic chunks grow quadratically with the size of the narrative?\n- At the end chunks are extracted, but the information contained in some chunks seem larger than for other chunks. What are the average length in number of tokens for each chunking mechanism?\n- I don't understand the orchestration of the chunk prioritization: are the three mechanisms applied in parallel, one after the other? What is the trade-off between the different mechanisms?\n- the parameter lambda for the streaming replacement mechanism is critical, how this parameter is fit?\n\n## Agent part\n\n- Is it necessary to build an agent corresponding to each human? The direct ablation of chunking and selection strategies on the dataset can give insights regarding the importance of each component, under the same memory constraints. Currently everything has been combined and it is not possible to understand the relative importance of each component.\n- It is linked with your assumption that there is no universally optimal chunking strategy. How useful is this assumption? What are the evidence for using this assumption? I think that doing the ablation against each prioritization individually (previous item) is possible and valuable  \n- What is the exact experimental setting for creating the agents? I have just read that the \"selection is guided by [the] three mechanisms\".\n- What are the quantitative values for all the parameters for each agents? A table in the appendix can help to understand the trade-off. How M (between 7 and 9) has been selected for each agent?\n- In total, M chunks are kept. What is the importance of each chunking mechanism among the participants (e.g., 4 out of M are semantic chunks, etc.)?\n\n## General\n\n- The authors mention that the \"bounded memory is not a weakness but a core feature\". Can the authors show evidence by considering non bounded experimental settings, or the evolution of the performance as a function of the number of memory slots? I understand that remembering all the events (including the minor events) can introduce confusion, but I didn't find evidence in your experiment.\n- A more convincing experiment would include M (the number of chunks) as a parameter, measuring: 1. the overall recall performance as a function of M, 2. the proximity of the agent compared to the corresponding participant, showing that indeed M=7 is reaching some maximum.\n- There is no discussion about the computational efficiency claimed in the conclusion."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eCbHImA7Vt", "forum": "2Epwf39xsY", "replyto": "2Epwf39xsY", "signatures": ["ICLR.cc/2026/Conference/Submission20058/Reviewer_J1tV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20058/Reviewer_J1tV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20058/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761902426541, "cdate": 1761902426541, "tmdate": 1762932951646, "mdate": 1762932951646, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "the paper attacks memory in LLMs from a different angle: as opposite as to expanding context windows to millions  tokens or retrieve from external\nmemories, authors suggest to design bounded chunk-based working memory (WM)\n\n\nwhile I fully second the original motivation, I find the (Miller G, 1956) and (Cowan, 2001) capacities estimation less fit to the task of recalling events in a narrative.\n\neven ignoring this issue, authors next introduce several chunkng schemes (semantic, phrase, sentence, schematic)  and prioritization mechanism (salience based, chunk network, stream replacement) that are not studied in a systematic manner with proper treatment of LLM output (i..e, they favor deterministic output with 0 temperature to repetitions, statistical analysis)\n\nanalysis remains superficial, and presentation is significantly below the par"}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- bounded working memory hypotesis goes against the trend to blindly scale up context and external memory size\n\n- study of several  chunkng schemes (semantic, phrase, sentence, schematic)\n and prioritization mechanism (salience based, chunk network, stream replacement)\n\n- pairs of held out stories, to avoid data leakage and ensures that\nmodels are not simply overfitting to a single narrative."}, "weaknesses": {"value": "(weaknesses detailed below)\n\n- WM mismatch with the task \n- bad evaluation \n- terrible presentation \n- missing baseline\n- missing references"}, "questions": {"value": "- WM mismatch with the task \n\nauthors extensively cite (Miller G, 1956) and (Cowan, 2001) but I doubt they have fully read these. From Cowan 2001, most of the settings relate to experiments in which the task is recalling independent entities (number, object, words, colors) with no semantic relationship, with the additional nuisance of an annoying information overload  (eg. a distracting agent counting or). Even the recency effect mentioned, and analyzed from Watkins\n1974 and later authors,  was targeting a task where a long list of verbal items is presented on each trial to a subject that has to recall as\nmany of those items as possible (with variants in terms of with/without temporal ordering)\n\nas such the \"7 \\pm2 \"  chunk are very different than chunks of text taken from a coherent narrative, as the authors are targeting here.\n\n## bad evaluation \n\n- I am not conviced about delegating semantic similarity to ModernBERTScore\nprevious experience on alignment exhibited possible false positive alignment for no obvious reason\n\n- the use deterministic decoding (temp=0, top_p=1.0) should be discouraged: you do not ensure reproducibility, but analyze results of a non-interesting operational point -- a better approach would have been to incresae the temperature, but performed a statistically relevant analysis\n\n- missing statistical relevance over multiple independent seed, reported average and confidence interaval, as well as critical distance plots to set apart the chunking vs prioritization proposals   (well beyond the boostrap recall evaluation).  as it stands, there is no need to introduce so many variants if there is no deep study of their benefits\n\n- evaluation remains superficial -- e.g., one would have expected appendix with e.g., a more detailed and careful human investigation of story in Fig 2 with narrative from a sample of humans + reconstructed from some of the { chunking } x { prioritization} annotated with distance of semantic similarity scores . as it stands, there is no need to introduce so many variants if there is no deep study of the reason of any statistically observed benefit\n\n\n## terrible presentation\n\n- presentation is as uncompelling as it can be. not only the text and illustration are not to the expected level  (eg Fig 2 the LLM is apparently SCREAMING AS IT IS USING UPPERCASE WHILE IT WAS NOT INSTRUCTED TO DO SO AND NOT ONLY ITIS NOT CLEAR WHY, BUT IT IS ALSO IMPOLITE) but especially all graphs are simply below the level of a technical report\n\n\n\n- Fig 4 related to primacy and recency is perhaps the only relevant investigation but quality wise is poor (due to lack of confidence intervals)\n\n- Fig 5 even uses spline or bezier smoothing. \n\n- Fig 3 and 6 are unlookable\n\n\n## missing baseline\n\nrandom memory and full transcript are naive baselines but  one would have expected top have simple yet relevant baselines such as simple k,v caches \nwith different cache admission/removal policy -- but with the type of evaluation carried out, the cache would be prefilled with one of the policies.\n\n still, it seems authors are playing with a toy for no obvious reason\n\n \n\n## missing references \n\neverywhere paper mentions previous work without citing it.\n\neven the Scientific Data paper used in this work is not cited once! \n\n even the Raccah et al. ``The “Naturalistic Free Recall” dataset: four stories, hundreds of participants, and high-fidelity transcriptions''"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Lgk7jMK38e", "forum": "2Epwf39xsY", "replyto": "2Epwf39xsY", "signatures": ["ICLR.cc/2026/Conference/Submission20058/Reviewer_KAQN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20058/Reviewer_KAQN"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20058/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761925024669, "cdate": 1761925024669, "tmdate": 1762932951150, "mdate": 1762932951150, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a new cognitively-inspired working memory module for LLMs. The module is fundamentally based on the idea of bounded working memory capacity, and employs a number of methods for chunk selection and prioritization, based on results in cognitive science. The authors run a number of experiments to see whether the proposed chunking mechanism aligns with human recall patterns."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The paper focuses on a highly relevant problem.\n\n- The paper reasonably justifies the proposed architecture with references to established research in Cognitive Science, which is refreshing.\n\n- The paper is clearly written and is a pleasure to read."}, "weaknesses": {"value": "This paper created a conflicting impression. I do appreciate the thorough method introduction and literature review, but this high quality is, unfortunately, not quite consistent throughout. Some key parts seem like they didn't get enough attention or space.\n\n- If the paper is intended as a truly cognitively accurate model, the actual Cognitive Modeling part is not sufficiently deep to demonstrate that the proposed model is indeed a good approximation of human behavior. The main statistical argument is that of absence of significant differences in recall frequencies, but the methodology of it raises certain questions (see the \"Questions\" section of my review). \n\n- Some of the chosen methods/metrics don't seem adequate for the task. The authors start the paper by noting how recall in modern LLMs is imperfect, but then there's a reliance on LLMs (ModernBert score) to score semantic similarity between the generated text and the original one.\n\n- The baselines in the section 4.4 are chosen in a slightly surprising way. The comparison with the random baseline does not, in my view, constitute a sufficiently strong baseline. But then worse recall performance compared to full context models is presented as a desirable feature.\n\n- The interpretation of certain results is sometimes stretched/changed to fit the paper's message. A very clear example of this is the following: at first, the \"lost in the middle\" result is mentioned as evidence of poor performance of modern LLMs on long contexts. Later, when the newly proposed model demonstrates a \"U-shaped recall curve\", it's presented as a good, cognitively plausible behavior. But U-shaped recall curve is exactly the same thing as the \"lost in the middle\" effect.\n\n\nOverall, unfortunately, I believe that these weaknesses are too substantial for me to recommend the paper to acceptance. I did like the idea and I hope that the authors refine and deepen the paper in the future, as the approach is interesting and promising."}, "questions": {"value": "I understand the main idea of participant model fitting, but generally that section is a little sparse on details and hence hard to understand.\nI find this sentence particularly confusing: \"Candidate memory agents are compared by assessing how well the chunks they generate from Pieman align with the participant’s recall from Eyespy.\"\n\nCould you please clarify the procedure, what alignment criteria are used, etc.? For example, we (presumably) shouldn't semantically align chunks from Pieman with participant recall from Eyespy, since the story content is different.\n\n- The authors say, \"Across all narratives, proportions of significantly recalled events did not differ from humans at p < 0.05\". I am not sure about the intended parsing of the sentence. Did the authors mean \"at p < 0.05\", \"proportions of significantly recalled events did not differ from humans\"? This would imply that some fairly non-standard statistical test was run.\n\nOr did they simply mean \"there were no statistically significant differences between proportions of significantly recalled events\"? This seems to be the case, judging by p-value of 1.0 in table 3 when recall frequencies were the same. But in that case, this analysis is not sufficient to conclude that there are no differences. \n\nWe need to at least consider the power of the test, and, better, use a different statistical procedure altogether. We can't generally use the absence of statistically significant difference as the main statistical argument for equality of our outcomes in the compared conditions. Binary outcome tests are notoriously low-power. For example, for the Oregon Trail recall, the WM and Human proportions differ substantially: 48.9% vs 31.3%, but the P-value is ~0.08. This is a large difference and the fact that p-value is > 0.05 can be likely attributed to a low-power test. It definitely can't be used as a statistically sound evidence/proof that there is no difference between these conditions.\n\nIn any case, I would appreciate the clarification of the statistical procedure & interpretation used here.\n\n- Could you please clarify how ModernBert score was used? Because there seems to be a slight contradiction in naively applying to to measure similarities between e.g. reconstructed and original stories. If ModernBert itself doesn't appropriately represent the stories, the metric will be skewed too.\n\n- Is there a risk of Data Contamination? I.e. is there a chance that the GPT model version used in the paper was exposed to Naturalistic Free Recall dataset during training? If yes, do you think it might have affected some of the results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bnQOhvsUuI", "forum": "2Epwf39xsY", "replyto": "2Epwf39xsY", "signatures": ["ICLR.cc/2026/Conference/Submission20058/Reviewer_kP3N"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20058/Reviewer_kP3N"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20058/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762216765005, "cdate": 1762216765005, "tmdate": 1762932950683, "mdate": 1762932950683, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}