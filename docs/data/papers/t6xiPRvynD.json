{"id": "t6xiPRvynD", "number": 10166, "cdate": 1758162878020, "mdate": 1759897669928, "content": {"title": "RCPU: Rotation-Constrained Error Compensation for Structured Pruning of a Large Language Model", "abstract": "In this paper, we propose a rotation-constrained compensation method to address the errors introduced by structured pruning of large language models (LLMs). \nLLMs are trained on massive datasets and accumulate rich semantic knowledge in their representation space. \nIn contrast, pruning is typically carried out with only a small amount of calibration data, which makes output mismatches unavoidable. \nAlthough direct least-squares fitting can reduce such errors, it tends to overfit to the limited calibration set, destructively modifying pretrained weights. \nTo overcome this difficulty, we update the pruned parameters under a rotation constraint. \nThis constrained update preserves the geometry of output representations (i.e., norms and inner products) and simultaneously re-aligns the pruned subspace with the original outputs.\nFurthermore, in rotation-constrained compensation, removing components that strongly contribute to the principal directions of the output makes error recovery difficult. \nSince input dimensions with large variance strongly affect these principal directions, we design a variance-aware importance score that ensures such dimensions are preferentially kept in the pruned model. \nBy combining this scoring rule with rotation-constrained updates, the proposed method effectively compensates errors while retaining the components likely to be more important in a geometry-preserving manner.\nIn the experiments, we apply the proposed method to LLaMA-7B and evaluate it on WikiText-2 and multiple language understanding benchmarks. \nThe results demonstrate consistently better perplexity and task accuracy compared with existing baselines.\nCodes are available at \\url{https://anonymous.4open.science/r/anonymous-llm-pruning-D884/}", "tldr": "", "keywords": ["LLM", "Compression", "Pruning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/3c168fb213910646cb8a67cb7c2dbbc991c4c2a8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "In this paper, the authors aim to mitigate pruning errors in structured pruning for LLMs. They propose a rotation-constrained compensation scheme to preserve geometric information and minimize mismatches during parameter updates. Furthermore, a variance-aware importance score is introduced to maintain the principal output directions. Experiments conducted on LLaMA-7B demonstrate the effectiveness of the proposed method.\n\nStructured pruning is valuable for the practical deployment of LLMs. I lean toward a marginal accept for this paper. If the authors address my concerns during the rebuttal phase, I would like to raise my score."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Originality:  \nThe paper introduces a rotation-based structured pruning method for LLMs. While the concept of rotation-based pruning is not new, this work offers an alternative approach to structured pruning with clear practical value for real-world deployment.\n\nQuality:  \nThe paper is well-written and logically organized. The motivation is clearly articulated, and the problem formulation is well-grounded. Both the proposed algorithm and its accompanying analysis are reasonable. The experimental results support the authors’ claims.\n\nClarity:  \nThe paper is clearly structured and easy to follow. The presentation of content and formulas are well-explained.\n\nSignificance:  \nThis work focuses on recovering pruning errors in structured pruning for LLMs, which is a meaningful contribution that enhances the practical deployability of large-scale models."}, "weaknesses": {"value": "Main Comments:  \n1. The proposed rotation idea is very similar to prior works such as RotPruner[1] and DenoiseRotator[2]. Although this paper applies the rotation concept to structured pruning, the aforementioned methods were designed for unstructured and semi-structured pruning. The authors should discuss these related studies in the Introduction and Related Work sections to clarify their distinctions.  \n\n2. The experiments are limited to LLaMA-7B. It would strengthen the paper to include results on larger models (e.g., 13B–70B) to verify scalability and generality.  \n\n3. It would be helpful to discuss whether the proposed rotation scheme can also be extended to unstructured or semi-structured pruning scenarios.  \n\nMinor Comments:  \n1. Lines 166–167: “an rotation-constrained parameter update” should be corrected to “a rotation-constrained parameter update.”\n\n\n[1] RotPruner: Large Language Model Pruning in Rotated Space.  \n[2] DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration. NeurIPS 2025"}, "questions": {"value": "1. The proposed rotation-based pruning method appears conceptually similar to RotPruner and DenoiseRotator. Could the authors clarify the key differences and novel aspects of their approach compared to these prior works? In particular, how does the proposed rotation constraint contribute uniquely to structured pruning beyond what has been achieved in unstructured or semi-structured settings?  \n\n2. The experiments are conducted only on LLaMA-7B. Do the authors expect the proposed method to scale effectively to larger models such as LLaMA-13B or LLaMA-70B?  \n\n3. Can the proposed rotation scheme be generalized to unstructured or semi-structured pruning?  \n\n4. Please correct the minor grammatical issue in Lines 166–167 (“an rotation-constrained” → “a rotation-constrained”)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RjL4Jr5c4j", "forum": "t6xiPRvynD", "replyto": "t6xiPRvynD", "signatures": ["ICLR.cc/2026/Conference/Submission10166/Reviewer_f6Ag"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10166/Reviewer_f6Ag"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10166/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761130953454, "cdate": 1761130953454, "tmdate": 1762921534373, "mdate": 1762921534373, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a new method to compensate errors encountered during structured pruning of Large Language models. Generally their algorithm identifies columns (input channels) of the mlp_down projection (or attn_out) to prune and removes the corresponding structures (outputs channels) of the up projection. \nOnce the columns are identified they propose to update the remaining parameters to optimize the loss over a calibration dataset. Instead of updating all non-pruned parameters they only train a rotation matrix, their main motivation being to mitigate overfitting.\n\nTheir algorithm can be applied efficiently for each matrix in isolation, without requiring gradients or similar through the entire model.\n\nThey evaluate their method on Llama 7B and show tiny improvements over previous work \"FLAPS\" but their method also still has a 2% downstream accuracy drop even when only pruning 10% of the model weights."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 1}, "strengths": {"value": "The method is conceptually very simple and can be efficiently implemented and also in principle scaled to other methods. It only requires simple linear algebra. Furthermore, since it does structured pruning, the resulting model can readily be served and the speedups easily realized (as opposed to unstructured pruning for example). \nThe idea of constraining the updates to rotations seems interesting and new. Overall it is easy to follow the paper, but that's partially because it is not very deep."}, "weaknesses": {"value": "- The paper motivates their constraint to rotations by \"overfitting\" however, there is no data presented that this actually happening in any way. Furthermore there are much more straightforward standard regularization approaches (for example Tikhonov) beyond constraining to rotations. \n- The loss 3 decouples over output dimensions. it is unclear why it should not be best to just optimize each output channel independently.\n- The evaluation is pretty constraint and only done on a single, quite outdated and rather small model (Llama-1 7B).\n- The improvements over existing works are marginal (<0.5%), but the large accuracy gap to the dense model remains(2%-9%). Thus the practical relevance  of this work is very minor."}, "questions": {"value": "- Can you provide empirical insights that the overfitting could not simply be mitigated by a simple ridge regression or similar?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Lk0ooFmKeG", "forum": "t6xiPRvynD", "replyto": "t6xiPRvynD", "signatures": ["ICLR.cc/2026/Conference/Submission10166/Reviewer_hZjV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10166/Reviewer_hZjV"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10166/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761140983954, "cdate": 1761140983954, "tmdate": 1762921534000, "mdate": 1762921534000, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Short notice regarding the rebuttal"}, "comment": {"value": "First of all, we would like to express our sincere appreciation for your thoughtful reviews and for the committee’s effort in coordinating the discussion.\nWe are currently running the most essential additional experiments that directly address the key points raised in your comments.\nTo properly incorporate these results into the rebuttal, we expect it to be ready in about 3–4 days.\n\nThank you very much for your patience and understanding.\nAuthors"}}, "id": "UIuUCMkYqy", "forum": "t6xiPRvynD", "replyto": "t6xiPRvynD", "signatures": ["ICLR.cc/2026/Conference/Submission10166/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10166/Authors"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10166/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763691813841, "cdate": 1763691813841, "tmdate": 1763691813841, "mdate": 1763691813841, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes **RCPU (Rotation-Constrained Parameter Update)**, a structured pruning method designed to minimize post-pruning output distortion in large language models. After column-wise pruning, the authors introduce an **orthogonal Procrustes-based reparameterization** to align the preserved subspace with the original outputs, optionally scaled by a global scalar factor. This design preserves vector norms and inner products, aiming to maintain geometric consistency with minimal calibration data. Additionally, the paper presents a variance-aware column importance score\n to prioritize dimensions contributing more significantly to dominant output directions.\n Experiments on LLaMA-7B (using 128 WikiText-2 calibration samples) show that RCPU outperforms or matches WANDA-sp and FLAP in perplexity and several zero-shot downstream benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. **Clean and Intuitive Formulation**\n   The method constrains post-pruning compensation to an orthogonal transformation, which is both mathematically sound and conceptually clear. The use of Procrustes alignment offers a closed-form SVD solution that preserves geometric structure and mitigates overfitting.\n\n2. **Innovative Use of Rotation Constraints**\n    Introducing rotation constraints to reduce pruning error is a novel and effective idea. It maintains representational geometry while minimizing reconstruction error without retraining.\n\n3. **Layer-Agnostic and Easily Transferable**\n    The approach is layer-wise, gradient-free, and architecture-agnostic, allowing easy integration into existing pruning pipelines and adaptation to other large models."}, "weaknesses": {"value": "1. **Limited Experiments and Comparisons**\n   The experiments were conducted only on the 7B model, with no evaluation on larger models. Analysis over varying calibration sizes (8, 32, 64, 128, 512) is needed for robustness. Additionally, comparisons are limited to FLAP and WANDA-sp, ignoring other state-of-the-art methods. \n2. **Unclear Strengths and Limitations of Rotation Constraint**\n   While the paper claims orthogonal alignment preserves inner products and mitigates overfitting, it lacks formal analysis. Additionally, the reasons for not considering other constraints, like regularized least squares, are not discussed."}, "questions": {"value": "1. The anonymized code repository appears incomplete; most files are missing except for *main.py*. Could the authors verify that the full implementation has been properly uploaded?\n2. Did the authors visualize how the scores $\\gamma_j$ are distributed across columns? \n3. What's the choice of scaled variant in your experiments, Please clarify how this choice affects the reported results ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "fxWy62eWaU", "forum": "t6xiPRvynD", "replyto": "t6xiPRvynD", "signatures": ["ICLR.cc/2026/Conference/Submission10166/Reviewer_hBF1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10166/Reviewer_hBF1"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10166/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761800175662, "cdate": 1761800175662, "tmdate": 1762921533653, "mdate": 1762921533653, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes RCPU, a post‑pruning compensation method for LLMs that restricts the update to an orthogonal rotation (optionally with a single global scale) computed via an Orthogonal Procrustes fit between the pruned layer’s outputs and the original outputs on a small calibration set. This preserves output norms and inner products, reducing overfitting and geometric distortion that plague unconstrained least‑squares fixes. It’s paired with a simple variance‑aware column score, (\\gamma_j=|W_{:,j}||X_{j,:}|\\operatorname{Var}(X_{j,:})), to keep columns likely to support principal output directions. Applied layerwise to LLaMA‑7B with 128 WikiText‑2 calibration samples, RCPU consistently lowers perplexity and improves or matches zero‑shot accuracy versus WANDA‑sp and the bias‑only FLAP baseline across 10–30% structured pruning. Figure 1 (p.2) sketches the pipeline; Algorithm 1 (p.5) gives the exact steps; Tables 1–2 (pp.6–7) report the gains; Tables 3–4 (p.8) show where to apply it and the runtime/memory trade‑offs. \n\nKey contributions\n\n* Rotation‑constrained compensation: Formulates post‑pruning recovery as a closed‑form Orthogonal Procrustes problem and updates only the retained columns via (W_K \\leftarrow Q^\\star W_K) (optionally (s^\\star Q^\\star W_K)), preserving geometry while aligning to the original outputs (Sec. 3.1, Fig. 1). \n* Variance‑aware selection rule: Extends WANDA‑sp’s magnitude/activation score with an input‑variance term to prefer columns supporting dominant directions, improving compatibility with the rotation update (Sec. 3.2). \n* Drop‑in, no finetuning, modest cost: Layerwise, closed‑form SVD per treated sublayer; no architectural changes; measured pruning time under ~10 s per layer on LLaMA‑7B while reducing parameters and memory with higher pruning ratios (Algorithm 1; Table 4). \n* Empirical gains on LLaMA‑7B: Lower perplexity than WANDA‑sp and typically better than FLAP at 10–30% pruning (e.g., at 20%: PPL 14.40 vs 16.70/15.36) and competitive zero‑shot accuracy across BoolQ, PIQA, HellaSwag, WinoGrande, ARC‑e/c, OBQA; rotation outperforms unconstrained least‑squares fixes, especially as pruning increases (Tables 1–2; Fig. 2). \n* Ablations on where to rotate: Best results when compensating both attention (o_proj) and MLP (down_proj); (o_proj) alone helps more than (down_proj) alone (Table 3)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "Strengths: originality\n\n* Recasts post‑pruning error correction as an orthogonal Procrustes alignment on the layer outputs, restricting the compensation to a rotation (optionally with a single global scale). This is a crisp, geometry‑preserving reframing that removes a well‑known limitation of unconstrained least‑squares fixes under tiny calibration sets: shear/scale distortions and overfitting. The formulation and closed‑form solution are given in Sec. 3.1, with the pipeline visualized in Figure 1 (p. 2). \n* Pairs that rotation with a variance‑aware column score that augments magnitude and activation scale with input variance, which is a simple but thoughtful twist that prefers columns supporting principal output directions (Sec. 3.2). The idea is original in the structured‑pruning context and complementary to existing heuristics such as Wanda‑sp. \n* Offers a drop‑in procedure that can be inserted immediately after column pruning without architectural changes or fine‑tuning, expressed succinctly in Algorithm 1 (p. 5). The combination of a classic SVD‑based alignment with modern LLM pruning is a creative, low‑friction synthesis. \n\nStrengths: quality\n\n* Methodological soundness. The paper motivates the failure modes of unconstrained least squares, formalizes the rotation‑constrained problem, and provides a closed‑form optimizer via SVD along with a scaled variant. The constraints directly preserve norms and inner products, aligning with the desiderata stated in Sec. 2.2 and solved in Sec. 3.1. Complexity is analyzed (O(d_out³) per treated sublayer), and the computational steps are transparent (Sec. 3.3). \n* Strong empirical evidence. On LLaMA‑7B with only 128 WikiText‑2 calibration samples, rotation consistently reduces perplexity vs. Wanda‑sp and typically matches or beats FLAP across 10–30% pruning. Table 1 (p. 6) shows, for example, at 20% pruning: PPL 14.40 (RCPU Rot.) vs. 16.70 (Wanda‑sp) and 15.36 (FLAP). Figure 2 (p. 7) further demonstrates that least‑squares compensation often harms PPL while rotation reliably helps, under both scoring rules. \n* Breadth of evaluation. Zero‑shot accuracy is reported on seven diverse language understanding tasks; RCPU variants are competitive and often superior to baselines, including at higher pruning where accuracy is most fragile (Table 2, p. 7). The study also includes targeted ablations that identify where compensation matters most: updating both attention o_proj and MLP down_proj yields the largest gains (Table 3, p. 8). \n* Practicality demonstrated. The efficiency table reports per‑layer pruning times under 10 s and monotonic memory savings with higher pruning ratios (Table 4, p. 8), strengthening the claim that the method is deployable without exotic infrastructure. \n\nStrengths: clarity\n\n* The paper is exceedingly readable: notation is introduced cleanly (Sec. 2.1), the failure modes of LS are enumerated before the proposed fix (Sec. 2.2), and the solution path is linear. Figure 1 on page 2 gives an at‑a‑glance workflow that matches Algorithm 1 on page 5, which makes the procedure easy to reimplement. \n* Tables and plots are well‑chosen and interpretable: Table 1 isolates PPL vs. pruning ratio; Figure 2 explicitly contrasts “no compensation,” “LS,” and “RCPU” under both scoring rules; Table 2 summarizes per‑task and mean accuracies; Tables 3–4 provide ablations and resource figures. The accompanying text consistently ties these visuals back to the stated hypotheses. \n* Reproducibility details are reasonable: calibration dataset, number of samples, layers targeted, evaluation harness, and hardware are all specified (Sec. 4.1), and an anonymized code link is provided. \n\nStrengths: significance\n\n* Practical impact for structured pruning. Many deployments can only spare tiny calibration sets and cannot fine‑tune; a one‑shot, geometry‑preserving compensation that is drop‑in and SVD‑simple is immediately useful. Gains are most pronounced exactly where practitioners need them: at higher pruning ratios (e.g., 30% PPL improvements over Wanda‑sp in Table 1), where retaining performance is hardest. \n* Conceptual influence. Framing error recovery as orientation correction rather than generic regression is a clean lens that could inform future compression methods, e.g., combining with other structure‑preserving transforms or smarter selection rules. The ablation showing o_proj benefits more than down_proj (Table 3) offers actionable insights about where geometry matters most in transformer blocks. \n* Broad applicability. Because the update is layer‑local, closed‑form, and architecture‑agnostic, it should transport to other LLM families and even beyond LMs to any setting where structured pruning removes subspaces and small calibration sets are the norm. The efficiency numbers and memory reductions in Table 4 make this a credible path for edge or resource‑constrained deployments. \n\nOverall: a neat, principled, and practical piece of work. The rotation‑constrained view is conceptually tidy, the experiments are careful and targeted, and the clarity of exposition makes the method easy to adopt."}, "weaknesses": {"value": "* The central idea is to restrict post‑pruning compensation to an orthogonal Procrustes fit. That’s a neat reuse of a classic tool, but the paper underplays overlap with closely related “structure‑preserving reparameterizations” such as SliceGPT, which also leverages orthogonal transforms to manage structured deletions. The Related Work section asserts a difference but offers no head‑to‑head comparison or synthetic study clarifying when layer‑local Procrustes is preferable to a single global reparameterization. Add a direct comparison against SliceGPT, both as a baseline and as a combined pipeline (SliceGPT first, then RCPU), and make the distinctions operational rather than rhetorical. Cite Figure 1 for the RCPU pipeline and §5.3 for the SliceGPT discussion, then show empirical deltas. \n\n* “Geometry preserving” is asserted, not quantified. Orthogonal maps preserve norms and pairwise angles within the calibration subspace, but the paper does not measure whether downstream layers see closer activations after compensation. Add layerwise geometric diagnostics: cosine similarity and norm‑ratio histograms between original outputs Y and compensated outputs QZ at calibration and test time; report mean and tail statistics per sublayer. Tie these to PPL changes to show that geometry preservation correlates with generalization. Anchor this to the optimization in §3.1 and the workflow in Figure 1. \n\n* The choice to rotate across the full dout mixes attention heads in o_proj. That may be unnecessary coupling. Test block‑diagonal Q that respects head boundaries vs full Q, and report both quality and compute trade‑offs. The ablation in Table 3 shows where rotation helps (o_proj vs down_proj), but not whether cross‑head mixing is essential. This is low‑effort to implement and could improve robustness. \n\n* The scaled variant uses a single global s; Table 1 shows it is largely neutral. Before discarding scaling entirely, probe slightly richer but still well‑conditioned classes: per‑channel diagonal scaling or a small number of Householder reflections. These preserve most geometry while giving capacity to fix systematic magnitude shifts that a single s cannot capture. Evaluate them beside “Rot.” and “Rot.+Scale.” Refer to §3.1–3.3 and Table 1. \n\n* Dependence on calibration size and distribution is not analyzed. All results use 128 WikiText‑2 samples. Provide calibration‑size curves (e.g., N ∈ {32, 64, 128, 512}) and a distribution‑shift test: calibrate on WikiText‑2 but evaluate on the seven downstream tasks, and vice versa. Figure 2 already contrasts LS vs RCPU; extend that figure style to show RCPU’s sample‑efficiency and brittleness under shift. This directly tests the “less prone to overfitting” claim from §2.2–§3.1. \n\n* The variance‑aware score is only partially ablated. Figure 2 contrasts WANDA‑sp vs the proposed score, but the score itself bundles three factors. Add controlled ablations: remove just the variance term, replace sample variance with a shrinkage estimator, and test robust alternatives (median absolute deviation). Report how each affects M = YZ⊤ conditioning and the singular value spectrum that drives Q. Ground this in §3.2 and Figure 2. \n\n* Numerical details of Procrustes are missing. In practice, reflections (det(Q) < 0) can arise; some implementations flip the last column of U to enforce det(Q) = 1. State which variant you use and whether it matters for quality. Also note precision (fp16 vs fp32) and any stabilization for tall‑skinny Z multiplication. This belongs in §3.1–3.3."}, "questions": {"value": "1. “Geometry preservation” beyond intuition.\n   The paper asserts that rotations preserve norms and inner products and reduce distortion relative to LS (§2.2, §3.1), but this is not measured directly.\n   Request: Report cosine similarity and norm‑ratio histograms between original outputs Y and compensated outputs QZ on held‑out data. Correlate those with perplexity deltas per sublayer. This would substantiate the geometric motivation. (Fig. 1; §2.2–§3.1) \n\n2. Calibration size and distribution shift.\n   All results use 128 WikiText‑2 samples (§4.1). The stated advantage is reduced overfitting under small calibration, but sample‑efficiency is not quantified.\n   Request: Provide calibration‑size curves (N ∈ {32, 64, 128, 512}) and a distribution‑shift test: calibrate on WikiText‑2, evaluate on the seven tasks, and vice versa. Present curves similar to Figure 2 to show robustness. (Fig. 2; §4.1) \n\n3. When not to rotate.\n   Practitioners need a diagnostic to decide whether a sublayer will benefit.\n   Request: Report a simple predictor such as the principal angle between span(Z) and span(Y) or the condition number of M = YZ⊤, and plot expected PPL change vs that quantity. This could become a decision rule for where to apply RCPU. (Eq. 6; Table 3)"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pS8vUCbe37", "forum": "t6xiPRvynD", "replyto": "t6xiPRvynD", "signatures": ["ICLR.cc/2026/Conference/Submission10166/Reviewer_SQAA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10166/Reviewer_SQAA"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10166/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762096912805, "cdate": 1762096912805, "tmdate": 1762921533102, "mdate": 1762921533102, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}