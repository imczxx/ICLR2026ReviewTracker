{"id": "lauHjCZ772", "number": 8489, "cdate": 1758086808462, "mdate": 1759897781170, "content": {"title": "References Indeed Matter? Reference-Free Preference Optimization for Conversational Query Reformulation", "abstract": "Conversational query reformulation (CQR) has become indispensable for improving retrieval in dialogue-based applications. However, existing approaches typically rely on reference passages for optimization, which are **impractical** to acquire in real-world scenarios. To address this limitation, we introduce a novel **reference-free** preference optimization framework ***DualReform*** that generates **pseudo reference passages** from **commonly-encountered** conversational datasets containing only queries and responses. DualReform attains this goal through two key innovations: (1) **response-based inference**, where responses serve as proxies to infer pseudo reference passages, and (2) **response refinement via the dual-role of CQR**, where a CQR model refines responses based on the shared objectives between response refinement and CQR. Despite not relying on reference passages, ***DualReform*** achieves 96.9--99.1% of the retrieval accuracy attainable only with reference passages and surpasses the state-of-the-art method by up to 31.6%.", "tldr": "We present DualReform, a novel reference-free preference optimization framework for conversational query reformulation that generates pseudo reference passages from commonly-encountered conversational datasets.", "keywords": ["Finetuning LLMs", "Preference optimization", "Self-supervised learning", "Conversational query reformulation"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e749a40e1ef01161ca18b293bd61bd6515d8b04d.pdf", "supplementary_material": "/attachment/03a49847d8ce105064cd5f4b088c9fa82fb19684.zip"}, "replies": [{"content": {"summary": {"value": "This paper presents DualReform, a reference-free preference optimization framework for conversational query reformulation (CQR). The work addresses a practical limitation: existing preference optimization methods for CQR require reference passages that are rarely available in real-world conversational datasets. The authors propose generating pseudo reference passages from query-response pairs through (1) response-based inference and (2) response refinement via a dual-role CQR model. The term ``dual-role'' arises from using the CQR model for both query reformulation and response refinement, leveraging the inherent alignment between these two objectives. A key novelty is the theoretical demonstration that the dual-role configuration induces a smaller (tighter) upper bound on training error compared to the single-role configuration, as formalized through error bounds based on pseudo label denoising theory. Experiments on QReCC, TopiOCQA, and a new scientific dataset (SciConvQA) show that DualReform achieves 96.9-99.1\\% of the retrieval accuracy obtainable with ground-truth references and outperforms the strongest baseline by 15.7\\% on average across sparse and dense retrieval systems."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The authors provide complete proofs of the Lemmas in the paper, which enhances the theoretical rigor and reproducibility of the work.\n2. The proposed framework, DualReform, outperforms the compared LLM-based, SFT-only, and reference-based CQR methods on the evaluated benchmarks (TopiOCQA and SciConvQA).\n3. The authors introduce SciConvQA, a new benchmark for conversational query reformulation in specialized scientific domains. The dataset is constructed using scientific journal data provided by the Korea Institute of Science and Technology Information (KISTI), with conversations generated using GPT-4o followed by manual quality validation.\n4. The authors provide code for their implementation."}, "weaknesses": {"value": "1. The paper uses text-wrapped figures in several places, which sometimes affects readability and could be improved by repositioning these figures or reducing the use of text wrapping to enhance the flow and clarity of the paper.\n2. The field of LLM-based CQR method is evolving rapidly. However, the most recent methods that the authors chose as baselines were published in 2023. The authors should include recent papers in the field, at least those published in 2024, to ensure the related work and comparisons reflect the current state-of-the-art. For example, the authors could refer to recent work such as Yunah Jang et al., “IterCQR: Iterative Conversational Query Reformulation with Retrieval Guidance,” NAACL 2024, and Fengran Mo et al., “CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search,” EMNLP 2024.\n3. The authors evaluate DualReform using only BM25 and GTR as retrieval systems. The work could be strengthened by extending the evaluation to other retrieval systems such as SPLADE and ANCE, which are commonly adopted in the research field of conversational retrieval.\n4. The theoretical analysis relies on Assumption 1, which requires c-expansion and μ-separation properties of the data distribution. However, the authors do not verify whether the experimental datasets (QReCC, TopiOCQA, SciConvQA) actually satisfy these assumptions, nor do they provide the measured values of c and μ for these datasets. Please refer to the first point in the Questions section."}, "questions": {"value": "Regarding line 105-112 in the methodology section, the authors derive training error bounds (Lemmas 1 and 2) under Assumption 1, which requires $c$-expansion and $\\mu$-separation properties of the data distribution. Did the authors verify that the datasets used in the experiments (e.g., QReCC, TopiOCQA, SciConvQA) actually satisfy these assumptions? If so, what are the measured values of $c$ and $\\mu$ for these datasets? Since the values of $c$ and $\\mu$ determine whether the assumptions and the mathematical reasoning process hold, the authors should provide these values for each dataset."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "0vo5tKHpUq", "forum": "lauHjCZ772", "replyto": "lauHjCZ772", "signatures": ["ICLR.cc/2026/Conference/Submission8489/Reviewer_m8aF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8489/Reviewer_m8aF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission8489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761528365163, "cdate": 1761528365163, "tmdate": 1762920363898, "mdate": 1762920363898, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the Conversational Query Reformulation (CQR).  The authors find that current CQR methods are facing an issue, i.e.,  heavy reliance on reference passages for preference optimization, which are impractical to acquire in real-world scenarios.  To this end, the authors propose `DUALREFORM`, a reference-free preference optimization framework that generates pseudo reference passages from standard conversational datasets (containing only queries and responses) instead of relying on human-annotated references. DUALREFORM is an iterative framework, where the first step is the pseudo-reference generation and the next step is the preference optimization.\n﻿\nAccording to the experiments, DUALREFORM has achieved strong performance across three datasets (QReCC, TopiOCQA, and the novel specialized-domain SciConvQA): it reaches 90%+ of the retrieval accuracy of the reference-based method RetPo (Upper Bound)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The major part of this work is easy to follow.  The authors have given a nice preliminary study.\n﻿\n2. This work may be the first to achieve a reference-free preference optimization framework for CQR.\n﻿\n3. This work has provided a lot of theoretical theories to prove dual-role CQR reduces training error vs. single-role (LLM-only) refinement.\n﻿\n4. Achieves strong empirical performance: 1)  90%+ of reference-based accuracy,  2) 15.7% average improvement over SOTA reference-free baseline and 3) strong robustness across several datasets (domains)."}, "weaknesses": {"value": "1. Some statements are not very clear in this paper. I know that most of them may have been well validated in prior works, but the reader of paper may not familiar with them.  For example, it is hard to infer Lemmas 4.2 and 4.3 solely from the Assumption. Note that reading the appendix is not compulsory. Thus, the authors should give at least an easy but intuitive brief introduction in the main paper.\n﻿\n2.  I do not directly focus on this research field, so I have a concern about the definition of `reference-free`.  From my own perspective, this work is still  `reference-based` because, in step 2, this work still needs the reference, although this reference is a pseudo-reference. Thus,  compared to traditional reference-based methods,  the major difference is an automatic way to label the reference. \n﻿\n3. In Table 6 (Sec 5.4), the authors use some reference-aware metrics to evaluate the generated dialogues.  It would be better to use more reference-free metrics (just like LLMEval)."}, "questions": {"value": "1. Can you provide the performance with more iterations (i.e., Table 4, > 3)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bCWcAUNbr0", "forum": "lauHjCZ772", "replyto": "lauHjCZ772", "signatures": ["ICLR.cc/2026/Conference/Submission8489/Reviewer_Kn6Q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8489/Reviewer_Kn6Q"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission8489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761743137251, "cdate": 1761743137251, "tmdate": 1762920363538, "mdate": 1762920363538, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DualReform, a reference-free preference-optimization pipeline for conversational query reformulation (CQR). It infers pseudo reference passages by refining responses with the CQR model, then uses those pseudo references to generate preference feedback and run SFT+DPO, showing strong retrieval and generation gains close to a reference-based upper bound."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Empirical gains are substantial and consistent across datasets and retrievers, often nearing the upper-bound.\n2. The iterative refinement and query-forming template are well studied with ablations and extended metrics, showing clear contributions from each design choice."}, "weaknesses": {"value": "1. Component-level attribution could be better: the paper reports useful ablations but does not present a unified per-module breakdown (retriever type, pseudo refs, etc.,) to show which component drives most of the gains.\n2. Iterative pseudo-refinement and extra retrieval steps likely increase per-query compute. Practical cost and latency are necessary but unreported.\n3. The training pipeline relies on reformulated queries generated by ChatGPT. Can it be achieved using reformulations produced by the trained model itself instead of an external LLM？"}, "questions": {"value": "See weakness 3."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kpqSDD6140", "forum": "lauHjCZ772", "replyto": "lauHjCZ772", "signatures": ["ICLR.cc/2026/Conference/Submission8489/Reviewer_YCPm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8489/Reviewer_YCPm"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission8489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761981471059, "cdate": 1761981471059, "tmdate": 1762920363202, "mdate": 1762920363202, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a framework for reference-free preference optimization in CQR. It generates pseudo reference passages directly from conversational datasets instead of relying on manually curated reference passages. By using the refined responses for retrieval, more accurate pseudo passages can be obtained. These pseudo passages are used to construct preference feedback. Additionally, the paper proposes an iterative optimization scheme that alternates between pseudo passage retrieval and preference optimization, enabling the pseudo passages and CQR model to continuously enhance."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. By iterating between pseudo passages retrieval and preference optimization through a self-reinforcement loop, both can promote each other, leading to continuous optimization of the CQR model.\n2. Similar to query reformulation, the response is refined to clarify ambiguities and omissions, leading to more accurate retrieval of pseudo passages.\n3. Experiments demonstrate that DUALREFORM achieves retrieval accuracy very close to that of systems using true references."}, "weaknesses": {"value": "1.  The motivation and novelty of this research is not convincing. There is no necessity for inferring pseudo passages just for training, especially limited to the conversational QR scenarios. The community already has many datasets with relevance judgments for such a purpose. Besides, the definition of reference is unclear here. If this denotes relevance judgments, then previous CQR methods do not necessarily use relevance judgments, which means the claim in the second paragraph in the Introduction is not correct. If this does not refer to relevance judgments, e.g., the response or sth else, then what is the scenario in practice requires it? In addition, preference optimization without reference should be able to completely eliminate the dependence on passage collection during the training phase.\n\n2. The proposed model is both trained and evaluated on in-domain conversations, whereas other CQR baselines are trained on out-of-domain data and evaluated on the in-domain dataset. Although our model does not rely on annotated relevant passages during training, its alignment with the evaluation data distribution may partially account for its performance advantages over models trained under distributional mismatch. Besides, the comparison in the experiment is unfair. For ConvGQR, HyDE-FT, and RetPO, they do not have access to the target dataset's passage collection during training, while DUALREFORM uses the target dataset's passage collection (i.e., the pseudo passages retrieved) during training. Another unfair comparison in the experiment is the use of GTR-Large in dense retrieval, while most previous methods used ANCE. The performance improvement in dense retrieval may come from the retriever.\n\n3. Lack of manual evaluation to compare the difference in quality between pseudo passages and ground-truth ones and some baselines are missing, e.g., CHIQ [1] and AdaCQR [2].\n\n[1] CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search\n\n[2] AdaCQR: Enhancing Query Reformulation for Conversational Search via Sparse and Dense Retrieval Alignment"}, "questions": {"value": "1. What are the differences compared to CHIQ-FT in CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search, which also tries to improve the quality of relevance judgments in terms of CQR training to improve the performance of conversational search.\n\n2. What is the latency analysis, for both data generation and inference? The method relies heavily on LLMs.\n\n3. Similar to weakness one, what is the motivation to generate new reference but discarding the relveance judgments in the training set? If this is toward a general goal, why limited only in conversational query reformulation but not to general zero-shot dense retrieval, e.g., evaluating on BEIR? I don't see any strong connection with the research question in conversational QR."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "BGFbBJphmP", "forum": "lauHjCZ772", "replyto": "lauHjCZ772", "signatures": ["ICLR.cc/2026/Conference/Submission8489/Reviewer_UcSN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission8489/Reviewer_UcSN"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission8489/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762027252133, "cdate": 1762027252133, "tmdate": 1762920362818, "mdate": 1762920362818, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}