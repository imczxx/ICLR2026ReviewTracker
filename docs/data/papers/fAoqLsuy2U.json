{"id": "fAoqLsuy2U", "number": 17875, "cdate": 1758281522528, "mdate": 1762948134321, "content": {"title": "Efficient Bayesian Inference from Noisy Pairwise Comparisons", "abstract": "Evaluating generative models is challenging because standard metrics often fail to reflect human preferences.  \nHuman evaluations are more reliable but costly and noisy, as participants vary in expertise, attention, and diligence.  \nPairwise comparisons improve consistency, yet aggregating them into overall quality scores requires careful modeling.  \nBradley-Terry-based methods update item scores from comparisons, but existing approaches either ignore rater variability or lack convergence guarantees, limiting robustness and interpretability.  \nWe introduce BBQ, a Bayesian Bradley-Terry variant that explicitly models rater quality, downweighting or removing unreliable participants, and provides guaranteed monotonic likelihood convergence through an Expectation-Maximization algorithm.  \nEmpirical results show that BBQ achieves faster convergence, well-calibrated uncertainty estimates, and more robust, interpretable rankings compared to baseline Bradley-Terry models, even with noisy or crowdsourced raters.\nThis framework enables more reliable and cost-effective human evaluation of generative models.", "tldr": "", "keywords": ["Bradley–Terry model", "Pairwise comparisons", "Expectation–Maximization (EM)"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fa2cdf2680e61f05c3187ea2aa09bc992805b4c0.pdf", "supplementary_material": "/attachment/737072509c613eb1a1f7a67655cae49086213dfb.zip"}, "replies": [{"content": {"summary": {"value": "This paper extends the Bayesian Bradley-Terry model to jointly estimate item quality and rater reliability, called BBQ. Its main contribution is deriving closed-form EM updates, which give the model two key advantages:\n(1) The EM updates guarantee monotonic likelihood increase and fast convergence;\n(2) The model jointly estimates item skill and rater reliability, reducing the impact of unreliable raters.\nExtensive experiments show that BBQ outperforms Bayes-BT and Crowd-BT in ranking accuracy, stability, and computational efficiency."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "The problem is important: the Bradley-Terry model is widely used, and modeling rater reliability is often necessary.\n\nBBQ shows clear advantages over other variants: (1) guaranteed and fast convergence; (2) higher accuracy.\n\nExperiments are thorough, with proper baselines and comprehensive evaluation on both accuracy and efficiency.\n\nWriting quality is acceptable."}, "weaknesses": {"value": "# The authors violate the double-blind review policy in the supplementary materials, where the license file reveals their identities. I recommend desk rejection for this reason.\n\nAside from that, I have only minor comments:\nIt would be helpful to show BBQ’s performance on downstream tasks as a complement to simulations. For example, in automated peer review which is an area of growing interest in the ML community, LLM-based tools can produce pairwise quality comparisons between papers. Comparing BBQ and the original BT model in such a setting would be insightful."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "bZ20SEr7f3", "forum": "fAoqLsuy2U", "replyto": "fAoqLsuy2U", "signatures": ["ICLR.cc/2026/Conference/Submission17875/Reviewer_JowV"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17875/Reviewer_JowV"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17875/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761131415010, "cdate": 1761131415010, "tmdate": 1762927701912, "mdate": 1762927701912, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a new metric for generative models based on human evaluations with rater quality."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Evaluations span diverse real and synthetic datasets (e.g., HUMAINE, MT-Bench, HiFiC, WD, CLIC/IHQ).\n2. Unlike prior approaches, it introduces closed-form EM updates, ensuring monotonic likelihood convergence — a notable theoretical contribution."}, "weaknesses": {"value": "1. No example evaluation results (the evaluation score for image generation and LLM)\n2. Following Bradley & Terry (1952), it shows the method is suitable for larg sample test. However, the dataset testing in the experiment, only HUMAINE is the large sample. Then the other results may not be reliable.\n3. The application is limited. The main benefits of BBQ appear only when rater quality is heterogeneous. In curated or expert datasets (e.g., MT-Bench, WD, IHQ-screened), the paper shows that simpler models (like standard BT or Bayes-BT) achieve equivalent performance.\nAlso, the evaluation only handles pairwise comparison data."}, "questions": {"value": "1. In sec.3.1, it says 'two items i and j of this set'. It should introduce what it is. In the paper, it has introduced many different input, the skill, quality score or the input images/texts. \n2. In table 1, What does scr. and unscr. mean?\n3. Limited Validation Beyond Benchmark Correlations. The evaluation relies mostly on ranking correlation (Kendall’s τ) and Top-1 agreement, without deeper qualitative analysis or ablation on uncertainty calibration. While the model’s uncertainty estimates are discussed, there’s no clear downstream validation of whether these uncertainties improve decision-making or leaderboard robustness in real settings."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RTBLQ4n8xG", "forum": "fAoqLsuy2U", "replyto": "fAoqLsuy2U", "signatures": ["ICLR.cc/2026/Conference/Submission17875/Reviewer_B8py"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17875/Reviewer_B8py"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17875/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761317866550, "cdate": 1761317866550, "tmdate": 1762927701506, "mdate": 1762927701506, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents BBQ, a Bayesian Bradley-Terry model variant that incorporates rater quality into the aggregation of noisy human-generated pairwise comparison data. By introducing rater-specific reliability parameters and employing a conjugate prior Bayesian formulation, the methodology leverages an EM algorithm with closed-form updates, ensuring monotonic convergence of the likelihood. The method addresses instability and interpretability issues in crowdsourced or heterogeneous rater settings. Empirical studies across multiple evaluation datasets for generative models, including image compression and language modeling, demonstrate that BBQ yields faster convergence, greater robustness to unreliable raters, and well-calibrated uncertainty estimates compared to standard BT and other recent extensions."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper develops a Bayesian Bradley-Terry model that explicitly incorporates rater reliability, featuring a mathematically grounded EM algorithm with full derivations. This formulation ensures stable, monotonic convergence, in contrast to gradient-based approaches like Crowd-BT.\n\n2. The approach provides Bayesian credible intervals for estimating item skills, enhancing interpretability and yielding more dependable statistical inferences. Also, despite its Bayesian formulation, BBQ is demonstrated to be computationally efficient."}, "weaknesses": {"value": "1. BBQ is strictly designed for pairwise comparison data, whereas much of the recent literature on preference learning and robust aggregation seeks to handle more general forms like full rankings or ratings. This restricts its applicability for community studies increasingly collecting multi-way ore scalar judgments.\n\n2. The current formulation of BBQ assumes that unreliable raters behave as random guessers, ignoring more realistic cases where low-quality participants exhibit systematic biases or coordinated behavior. Furthermore, the experiments evaluate only random noise scenarios, without testing adversarial or colluding raters that often arise in real-world crowdsourcing or online evaluation platforms. As a result, both the modeling assumption and the experimental design fall short of demonstrating robustness under structured or adversarial noise conditions.\n\n3. While BBQ improves preference aggregation quality, it remains unclear whether this leads to measurable gains in downstream policy learning. Evaluating how BBQ-derived preferences affect model performance in DPO or RLHF setups would clarify its practical impacts."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "gPzlzPqYl2", "forum": "fAoqLsuy2U", "replyto": "fAoqLsuy2U", "signatures": ["ICLR.cc/2026/Conference/Submission17875/Reviewer_BNn3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17875/Reviewer_BNn3"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17875/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761546332507, "cdate": 1761546332507, "tmdate": 1762927701031, "mdate": 1762927701031, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces BBQ, a Bayesian Bradley-Terry variant that models item skill and rater quality jointly and optimizes them with an EM algorithm that guarantees monotonic likelihood improvement. The model down-weights unreliable raters and yields calibrated uncertainty for rankings. Experiments on LLM and image-compression preference datasets show faster convergence and stronger robustness than Bayes-BT and Crowd-BT, especially when rater quality is heterogeneous."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Clear modeling of rater noise with principled estimation\n- Empirical robustness across diverse datasets\n- Particularly strong when raters are mixed-quality\n- Well-calibrated uncertainty\n- Practical efficiency\n- Clarity and completeness"}, "weaknesses": {"value": "- Scope limited to pairwise comparisons\n- Diminishing returns with uniformly high-quality raters\n- Assumptions and design choices\n- Scalability caveat"}, "questions": {"value": "Your framework is currently restricted to pairwise comparisons. What is your concrete plan (modeling and inference) to support K-way choices and absolute ratings, and what identifiability or prior choices would change? Do you have any preliminary results (e.g., 3AFC, 5-point ratings)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "dCasyeXAyD", "forum": "fAoqLsuy2U", "replyto": "fAoqLsuy2U", "signatures": ["ICLR.cc/2026/Conference/Submission17875/Reviewer_QHeB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17875/Reviewer_QHeB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17875/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762903617985, "cdate": 1762903617985, "tmdate": 1762927700277, "mdate": 1762927700277, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Modelling Ties"}, "comment": {"value": "Multiple reviewers emphasized the importance of evaluating our model beyond 2AFC settings. In response, we collected a 3AFC version of IHQ, constructed in the same manner as the original 2AFC IHQ dataset but with ties allowed. For consistency, ties are handled identically across all three models: each tie is counted as half a win for item A and half a win for item B. We evaluated all models using the identical hyperparameter settings from the original 2AFC experiments, enabling a direct comparison of model performance. The results are summarized below:\nTop-1 Accuracy:\n|   |  | 2AFC |  |  | 3AFC |  |\n|----------|----------|----------|----------|----------|----------|----------|\n|  | all | screened | unscreened | all | screened | unscreened |\n|  Crowd-BT  |  85.31   |  98.57   |  33.15  |  96.63  |  **99.99**   |  54.01   |\n|  Bayes-BT  |  75.07   |  98.90   |  24.32  | 94.50   |  99.91   |  47.58   |\n|  BBQ          |  **99.32**   |  **99.80**   | **61.92**  |  **99.28**  |  99.98   |   **65.60**  |\n\nKendalls-Tau:\n|   |  | 2AFC |  |  | 3AFC |  |\n|----------|----------|----------|----------|----------|----------|----------|\n|  | all | screened | unscreened | all | screened | unscreened |\n|  Crowd-BT  |  0.9245   | **0.9171**   | 0.8482   |  0.9354  |  0.9279   |  0.8623   |\n|  Bayes-BT  |   0.9240  |  0.9116   |   0.8507 |  0.9369  |   0.9249  |  **0.8687**   |\n|  BBQ          |  **0.9270**   |  0.9132   |  **0.8563**  |  **0.9386**  |  **0.9282**   |  0.8669   |\n\nBBQ performs well in the 3AFC setting, maintaining its advantage over the baselines across both top-1 accuracy and Kendall’s tau. Notably, the 3AFC format provides a stronger supervision signal than 2AFC, even though the amount of data is held constant. This confirms that extending beyond 2AFC not only preserves BBQ’s relative gains but also benefits all models by removing labeling noise."}}, "id": "CON0Sxm8q7", "forum": "fAoqLsuy2U", "replyto": "fAoqLsuy2U", "signatures": ["ICLR.cc/2026/Conference/Submission17875/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17875/Authors"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17875/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763311421077, "cdate": 1763311421077, "tmdate": 1763311421077, "mdate": 1763311421077, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}