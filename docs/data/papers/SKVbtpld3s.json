{"id": "SKVbtpld3s", "number": 13480, "cdate": 1758218380144, "mdate": 1759897434080, "content": {"title": "Lyapunov Guidance: Stabilizing Generative Flows with One-Line Code", "abstract": "Flow matching has recently emerged as a powerful approach to learning complex data distributions with excellent performance across diverse generative tasks, yet adapting pre-trained flow models to new tasks typically requires costly retraining. To mitigate this issue, post-training guidance methods were proposed as they are lightweight and user-friendly for downstream applications. However, existing guidance methods are unreliable since they usually rely on function approximations and lack structural guarantees of sampling stability. In this paper, we address this challenge by proposing a unified framework, LyaGuide (Lyapunov Guidance for flow matching), which reformulates the guidance in flow matching as a Lyapunov control problem. LyaGuide supports two modes depending on whether the Lyapunov function is a known priori: a model-driven mode for developer-oriented scenarios where the guidance distribution is explicitly specified, and a data-driven mode for user-oriented scenarios where pre-trained models can be adapted with downstream task-specific data. Furthermore, to enforce the stability, we introduce a pseudo projection operator with a closed-form expression that strictly satisfies the Lyapunov condition. Notably, LyaGuide is compatible with any guidance method and can be implemented with a single line of code. Experiments on synthetic datasets and image inverse problems demonstrate that our framework consistently improves sample quality and guidance fidelity while preserving efficiency, and it significantly enhances the performance of existing guidance methods.", "tldr": "All the guidance methods of flow matching can be regarded as Lyapunov control, and can be improved substantially by our one-line code of Lyapunov projection.", "keywords": ["flow matching guidance", "Lyapunov control", "projection operation"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4b140a50844ffb603cdbb1f321d1fbaa2508c6ed.pdf", "supplementary_material": "/attachment/3063ee4119dc87a9075eac7263f78b502ef20a89.pdf"}, "replies": [{"content": {"summary": {"value": "This paper proposes a unified framework, Lyapunov Guidance for flow matching (LyaGuide), which reformulates the guidance in flow matching as a Lyapunov control problem. Based on this framework, the paper designs a pseudo-projection operator with a closed-form expression that strictly satisfies the Lyapunov condition. The experiments demonstrate the effectiveness of the proposed method."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- This paper offers a new framework or perspective for the flow matching guidance problem.\n- Based on the stability theory in the controlled system, the paper proposes a projection operation for more accurate guidance.\n- The method can be applied to broad scenarios: both explicit and implicit prior knowledge."}, "weaknesses": {"value": "- l146: What does this sentence 'c is a control term derived from V' mean? Or, what relationship is 'derived from'? This is not clear here, although later there are detailed explanations. It will be better to explain it here.\n- The caption of Fig.2 is unclear. Maybe change it to 'Illustration of the pseudo projection $\\pi$ and exact projection $\\pi^*$? Additionally, the meaning of the points with different colors in this figure is not clear.\n- How does the sampling step of flow matching influence the performance of LyaGuide?"}, "questions": {"value": "- l130: Why is designing the stabilizing controller u(x) a major problem in cybernetics field? Or, why is the stable u(x) better? It needs a more intuitive explanation for easier understanding.\n- l350: Why should V be locally convex around task-relevant regions? Proposition 3.1 does not include such assumptions. Also, why does the importance sampling weight promote the convexity around high-score samples? And if the locally convexity is needed, what about section 5.1? Can V be locally convex in this setting?\n- l366: what is $g_ϕ$? This may need a brief introduction."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "wnzjjvh6wS", "forum": "SKVbtpld3s", "replyto": "SKVbtpld3s", "signatures": ["ICLR.cc/2026/Conference/Submission13480/Reviewer_NCg4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13480/Reviewer_NCg4"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13480/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761758826733, "cdate": 1761758826733, "tmdate": 1762924098223, "mdate": 1762924098223, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LyaGuide, a Lyapunov function-based method to enhance guidance in flow matching generative models, addressing inefficiencies in adapting pre-trained models to new tasks (e.g., inverse problems like image restoration). Drawing from control theory, it provides a unified, stable, and theoretically guaranteed approach that integrates with existing methods, requires minimal code changes, and improves reliability for applications in drug design, image editing, and beyond."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. It's an interesting (and the first, to the knowledge of the reviewer) attempt to reformulate the guidance problem in generative models as a control stability problem, and studying it with Lyapunov functions.\n2. The proposed theoretical framework includes different guidance techniques, including EBM guidance (since the guidance is the gradient of a time-invariant potential) and posterior sampling in diffusion models and flow matching."}, "weaknesses": {"value": "1. The presentation can be improved. For example, a more detailed discussion and intuitive understanding of the equivalence between guidance and Lyapunov stability in the main text would be beneficial.\n2. The experimental evaluation is relatively limited. E.g., only flow matching on an image inverse problem is evaluated, whereas the authors claim that the framework is generally applicable to EBM and various tasks. Surely, the contribution of this work is largely theoretical, but the soundness would be improved with more empirical evidence."}, "questions": {"value": "1. In my understanding, Theorem A.2.1 is central to the contributions. However, how the equivalence between Lyapunov stability and guidance is established can be presented more clearly. In my understanding, the proof shows that a locally Lyapunov stable control can be \"deformed\" to the desired guidance control, but it does not show how it can be deformed. Lastly, it is not entirely clear how the proposed method, after the control is projected to be Lyapunov stable, deforms the stable control to match the desired guidance control.\n2. What is causing the Lypapunov guidance results to still be different from ground truth?\n\nI am willing to raise the score if the questions are answered and the concerns are addressed.\n\nMinor:\nLine 227 guidnace -> guidance"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "RDDTKwYUi1", "forum": "SKVbtpld3s", "replyto": "SKVbtpld3s", "signatures": ["ICLR.cc/2026/Conference/Submission13480/Reviewer_wGTM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13480/Reviewer_wGTM"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13480/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761835224469, "cdate": 1761835224469, "tmdate": 1762924097856, "mdate": 1762924097856, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LyaGuide, a framework that unifies various flow-matching guidance methods (e.g., classifier guidance, energy-based guidance, reward guidance) under the theoretical perspective of Lyapunov control. The authors propose interpreting the energy function in generative models as a Lyapunov function and the guidance term as a stabilizing control input. To ensure stability, they introduce a pseudo projection operator that enforces the Lyapunov condition in closed form, claiming compatibility with existing methods and implementation simplicity (“one-line code”). Experiments on synthetic datasets and image inverse problems (inpainting, super-resolution, deblurring) show improvements in stability and performance over baseline guidance methods."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- Unifies diverse guidance techniques in generative modeling under Lyapunov control theory, offering a new theoretical lens.\n\n- The pseudo-projection operator provides a lightweight, closed-form correction that can be easily integrated into existing models.\n\n- The framework can wrap around multiple existing guidance methods, making it versatile.\n\n- Synthetic and image inverse experiments show modest but consistent improvements in stability and quality."}, "weaknesses": {"value": "- Several stability conditions are unverified or incorrectly generalized from local to global settings.\n\n- Quantitative improvements (e.g., in Fig. 3 and Table 1) are marginal, and visual results show minor differences; the proposed method mainly stabilizes trajectories rather than improving fidelity substantially.\n\n- Fig. 3’s third row labeling appears incorrect, and the “toy example” results do not clearly demonstrate meaningful gains.\n\n- Lyapunov functions ensure local minima convergence, not global optimization, limiting practical utility.\n\n- The phrase “rigorous stability guarantees” is misleading given the local and heuristic nature of the verification."}, "questions": {"value": "- How can one verify that the proposed $V(x)$ satisfies Lyapunov’s positive definiteness and negative derivative conditions in practice?\n\n- What is the basin of attraction or stable manifold for convergence, and how can users determine if $x_0$ lies within it?\n\n- Does the pseudo-projection operator guarantee convergence when $V(x)$ is non-convex or multimodal?\n\n- How sensitive is the method to scaling parameters $(δ, k)$ in the projection and control terms?\n\n- Line 185 has a typo \"exists a a continuously \"."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qbfBqYhlfa", "forum": "SKVbtpld3s", "replyto": "SKVbtpld3s", "signatures": ["ICLR.cc/2026/Conference/Submission13480/Reviewer_qnFP"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13480/Reviewer_qnFP"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13480/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920292726, "cdate": 1761920292726, "tmdate": 1762924097380, "mdate": 1762924097380, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces LyaGuide, a novel framework that unifies various post-training guidance methods for flow-matching models using Lyapunov control theory. The central idea is to view the guidance process in generative modeling as a stabilization problem: the guidance term acts as a control input ensuring the system’s convergence toward a desired distribution."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The theoretical framework is sound and general, unifying several different scenarios of guidance in flow-based model."}, "weaknesses": {"value": "1, Experiments are neither sufficient. Both reward-guided scenario (scenario 1) and prior-knowledge one (scenario 2) are equipped with highly complete empirical benchmarks, for example, GenEval for scenario 1 and normal image generation for scenario 2. The effectiveness of the guidance method should be evaluated on this well-established benchmarks.\n\n2, Baselines are missing. Since both RLHF and prior-knowledge guidance are included in the theoretical framework, baselines for these two tasks should be then considered, like Flow-GRPO for RLHF and AutoGuidance (it also works on flow matching models empirically)."}, "questions": {"value": "See Weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "EN459HWmwr", "forum": "SKVbtpld3s", "replyto": "SKVbtpld3s", "signatures": ["ICLR.cc/2026/Conference/Submission13480/Reviewer_mrD2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13480/Reviewer_mrD2"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13480/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761959379250, "cdate": 1761959379250, "tmdate": 1762924096608, "mdate": 1762924096608, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}