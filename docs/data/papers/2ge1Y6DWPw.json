{"id": "2ge1Y6DWPw", "number": 12115, "cdate": 1758205764327, "mdate": 1759897531056, "content": {"title": "Preserve and Personalize: Personalized Text-to-Image Diffusion Models without Distributional Drift", "abstract": "Personalizing text-to-image diffusion models involves integrating novel visual concepts from a small set of reference images while retaining the model’s original generative capabilities. However, this process often leads to overfitting, where the model ignores the user’s prompt and merely replicates the reference images. We attribute this issue to a fundamental misalignment between the true goals of personalization, which are subject fidelity and text alignment, and the training objectives of existing methods that fail to enforce both objectives simultaneously. Specifically, prior approaches often overlook the need to explicitly preserve the pretrained model’s output distribution, resulting in distributional drift that undermines diversity and coherence. To resolve these challenges, we introduce a Lipschitz-based regularization objective that constrains parameter updates during personalization, ensuring bounded deviation from the original distribution. This promotes consistency with the pretrained model’s behavior while enabling accurate adaptation to new concepts. Furthermore, our method offers a computationally efficient alternative to commonly used, resource-intensive sampling techniques. Through extensive experiments across diverse diffusion model architectures, we demonstrate that our approach achieves superior performance in both quantitative metrics and qualitative evaluations, consistently excelling in visual fidelity and prompt adherence. We further support these findings with comprehensive analyses, including ablation studies and visualizations.", "tldr": "We propose a simple yet effective objective grounded in Lipschitz regularization that guarantees preservation of the pretrained distribution, which prior approaches failed to ensure.", "keywords": ["Text-to-Image Diffusion Models", "Personalization", "Overfitting", "Distributional Drift", "Regularization", "Lipschitz Constraints"], "primary_area": "generative models", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/61d03834263641553093edfd13a53552ebbd46a4.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper tackles distributional drift in few-shot personalization of text-to-image diffusion models by adding a Lipschitz-motivated parameter-distance regularizer to the personalization loss. The authors argue standard objectives (and even prior-preservation) don’t explicitly preserve the pretrained distribution (Theorem 1), and show that if the denoiser is Lipschitz in parameters, bounding $|\\theta - \\theta_{base}|$ controls KL shift (Theorem 2)."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. Clear statement of objective–goal misalignment; neat, didactic Theorem 1 showing why standard diffusion fine-tuning drifts.\n2. Theory sketch linking parameter Lipschitzness → KL control (Theorem 2); connects elegantly to L2 surrogate.\n3. Consistent empirical lift on fidelity (DINO/CLIP-I) with competitive CLIP-T across multiple backbones"}, "weaknesses": {"value": "1. The objective is effectively weight decay to $θ_{base}$; relation to continual-learning regularizers (e.g., EWC) and why your variant is preferable in diffusion personalization should be made explicit.\n2. You note CLIP-T may drop when fidelity improves; more analysis on prompt adherence failures (per failure figs) would help.\n3. In Table 1, SD-3.0 / “+Ours” row shows “CLIP-I +0.0022” but one entry reads “0.0094”. Why is this error proportion so large?"}, "questions": {"value": "Can you quantify Theorem 2’s $\\lambda$ (constant) for a given backbone (e.g., SD-1.5) via empirical Lipschitz estimation, and relate it to your best-performing $\\lambda$ in training?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DucEwolZ0l", "forum": "2ge1Y6DWPw", "replyto": "2ge1Y6DWPw", "signatures": ["ICLR.cc/2026/Conference/Submission12115/Reviewer_Bv3p"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12115/Reviewer_Bv3p"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12115/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761038729174, "cdate": 1761038729174, "tmdate": 1762923081507, "mdate": 1762923081507, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the personalization task in the field of image generation. The authors proposed a method to introduce a Lipschitz-based regularization objective that constrains parameter updates during personalization. The experiment shows the method can achieve competitive performance for this task."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The presentation of figures is great and easy to understand.\n- The math notations in this paper are self-contained and well-defined.\n- The paper writing is easy to follow.\n- The introduction section is good and clearly explains the motivation and the main claims of the paper.\n- The proposed method is straightforward."}, "weaknesses": {"value": "- I have to say that tuning-based personalization (like, DreamBooth, Custom Diffusion) is outdated. Learning-based personalization is the mainstream in the current image generation community.\n- How did you obtain the results of Fig. 2, or is it just an illustration?\n- Could you explain more about the claim \"Remark 1. Personalization based on the standard diffusion objective (Eq. 2) provides no guarantee of preserving the pretrained distribution and may lead to divergence\"? It is a little bit confusing.\n- The evaluation is all based on UNet-based diffusion models. I am curious about the comparison results based on the DiT-based model.\n- The evaluation lacks the image quality metrics that are also important.\n- There are also some previous works exploring the optimization of personalization learning processes. Have you considered comparing the proposed methods with them?"}, "questions": {"value": "Please see the section of weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2z5aZ1bs5H", "forum": "2ge1Y6DWPw", "replyto": "2ge1Y6DWPw", "signatures": ["ICLR.cc/2026/Conference/Submission12115/Reviewer_xLt7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12115/Reviewer_xLt7"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12115/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910756843, "cdate": 1761910756843, "tmdate": 1762923080866, "mdate": 1762923080866, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper targets overfitting and distributional drift in few-shot personalization of text-to-image diffusion models. It argues that existing objectives (plain denoising, prior-preservation via class prompts) are misaligned with the dual goals of subject fidelity and text alignment because they provide no explicit guarantee of preserving the pretrained distribution. The core contribution is a Lipschitz-based regularization objective that bounds the deviation of the personalized model from the pretrained one."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1 Clear objective-level insight: reframes personalization as a distribution-preserving adaptation problem and exposes misalignment of standard/“prior-preservation” losses with distributional stability.\n\n2 Simple, principled, and practical: the Lipschitz argument leads to a tractable L2 parameter-distance regularizer that is backbone-agnostic, easy to implement, and removes pre-sampling overhead.\n\n3 Solid empirical results: consistent quantitative gains on multiple backbones and personalization strategies; qualitative examples show improved subject identity without sacrificing prompt following. The training-time savings are compelling for practice."}, "weaknesses": {"value": "1 Assumptions and tightness: The Lipschitz continuity of εθ w.r.t. θ and the resulting KL bound are plausible but high-level; constants (λ) and norm choices are not characterized for realistic models. The theory justifies using parameter-distance regularization but provides limited guidance on magnitude selection beyond empirical tuning.\n\n2 Failure analysis: Some failure cases remain (identity structure, prompt compositionality). It would help to characterize when the regularizer helps or hurts (e.g., highly stylized subjects, complex relational prompts)."}, "questions": {"value": "1 Human evaluation: Could you expand user studies (more raters/prompts) and include identity verification (face/instance retrieval), and prompt adherence judged by humans, to validate metric conclusions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "zYTIUXSXCf", "forum": "2ge1Y6DWPw", "replyto": "2ge1Y6DWPw", "signatures": ["ICLR.cc/2026/Conference/Submission12115/Reviewer_LdxF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12115/Reviewer_LdxF"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12115/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761969873319, "cdate": 1761969873319, "tmdate": 1762923080437, "mdate": 1762923080437, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}