{"id": "OzzbZvFr1c", "number": 9502, "cdate": 1758125124685, "mdate": 1759897716214, "content": {"title": "Information-Theoretic Questionnaire Construction for Consistent Evaluation of Subjective Tasks with LLMs", "abstract": "Despite the growing use of large language models (LLMs) in subjective tasks such as role-playing, humor, emotional intelligence, and dialogue quality, their evaluation faces a pressing \\textbf{reproducibility crisis}: even the same evaluator may contradict itself when re-judging the exact same sample.\nWe attribute this instability to {dimension drift}, where free-form evaluation protocols (e.g., Chain-of-Thought reasoning) unpredictably shift their implicit criteria, undermining reliability.\nTo address this fundamental challenge, we {reformulate subjective evaluation as an information-theoretic optimization problem}. Specifically, we propose an \\textbf{Expected Information Gain (EIG)-based framework} that constructs a stable yet adaptive personalized rubric to eliminate dimension drift.\nOur two-stage “generate–then–score” design first produces a diverse pool of candidate evaluation questions and then selects the most informative subset via EIG, yielding explicit and repeatable criteria.\nExperiments on six benchmarks, including CharacterEval, The rJokes, and {MT\\_bench}, demonstrate that our approach substantially improves both evaluation {consistency} and {alignment with human judgments}, outperforming CoT-based and fixed-questionnaire baselines.\nThese results highlight that information-theoretic questionnaire construction offers a principled and reliable path toward reproducible evaluation of subjective tasks.", "tldr": "Beyond Drift: Stabilizing Subjective LLM Evaluation with Information-Theoretic Rubrics", "keywords": ["LLMs", "Evaluation of Subjective Tasks", "Expected Information Gain"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/38250a85bd237306d7791d32c383e543d89fcff3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper tackles the instability (dimension drift) of free-form evaluation in LLM-as-a-judge by generating auxiliary evaluation questions. The questions are selected by maximizing the expected information gain. In experiments, the method does not only improve self-consistency, but also enhancing human alignment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper formulates subjective evaluation into a quantitative information-theoretic problem, which is the main originality of the paper. The paper clearly presents the details of their approach, with codebase for reproducibility. The paper resolves the instability in evaluation, contributing to the reliability of LLM-as-a-judge."}, "weaknesses": {"value": "The proposed method fails to provide theoretical explanations on why it improves alignment with human evaluation. The method introduces additional hyperparameters to tune, e.g., simulation round $m$, as well as the size of candidate question set $Q$."}, "questions": {"value": "1. The simulated response filling procedure (Eq. (4)) is confusing. $p(a\\mid q, I)$ is instance-dependent, but the approximation uses $m$ different instances. How are the instances sampled?\n2. In Algorithm 1, Line 1, $Q$ is generated from $D$. Then are all instances in $D$ attached in the prompt template of Figure 9. If so, will the prompt be too long to fit in the context length of LLM?\n3. How is $m$ and size of $Q$ determined/chosen in practice?\n4. While the improvement of self-consistency is reasonable, as the optimization objective is to reduce uncertainty in the rating, can you explain why it also improves alignment with human evaluation. The reason is unclear as human annotators do not follow the rubrics generated via EIG framework.\n5. How does the proposed method compare with LLM Direct + majority voting, especially in human judgement alignment? In other words, we run repeated LLM-as-a-judge evaluation on each instance, and choose the most-frequent rating as the final rating. This trick can be applied on top of any existing evaluation approach, and can clearly improve self-consistency with low cost. \n6. Typo in prompt template (Figure 9-11): Instrution -> Instruction."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pLDVqGw5Gz", "forum": "OzzbZvFr1c", "replyto": "OzzbZvFr1c", "signatures": ["ICLR.cc/2026/Conference/Submission9502/Reviewer_5TSt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9502/Reviewer_5TSt"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission9502/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760585920541, "cdate": 1760585920541, "tmdate": 1762921077484, "mdate": 1762921077484, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the reproducibility crisis in subjective LLM evaluation by identifying and formalizing the root cause as dimension drift. It proposes an Expected Information Gain (EIG)-based framework that constructs a stable, adaptive rubric via a two-stage “generate–then–score” process: first generating diverse candidate evaluation questions, then selecting the most informative subset using EIG. Evaluated on six subjective benchmarks (e.g., CharacterEval, The rJokes, Love-EQ), the method significantly improves both self-consistency (Cohen’s κ) and alignment with human judgments over CoT and fixed-rubric baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Dimension drift is precisely defined and empirically validated as a core instability mechanism in LLM-as-a-judge systems.\n\n2. Reformulating rubric construction as a Bayesian experimental design (BED) problem with EIG provides a principled information-theoretic foundation.\n\n3. The proposed “stability–informativeness loop” resolves the trade-off between rigid checklists and unstable free-form reasoning.\n\n4. Introduces EMdim to quantify drift and amortized cost analysis, offering actionable insights for real-world deployment."}, "weaknesses": {"value": "1.  The joint distribution p^(y,a∣q,I) is estimated entirely via LLM simulations, which may inherit or amplify the very drift the method aims to eliminate.\n\n2. As a newly introduced dataset, Love-EQ lacks description of annotation protocol, inter-annotator agreement, or scale, weakening reproducibility.\n\n3. Using uncorrected observed agreement (rather than weighted κ or correlation) may overstate alignment, especially with lenient tolerance thresholds (±1 on 5-point scale).\n\n4. While amortized cost is analyzed, the absolute upfront cost (e.g., LLM calls for rubric construction) is not quantified or compared to alternatives like CheckEval."}, "questions": {"value": "1. How sensitive is EIG ranking to the choice of base LLM used for simulation? Could a drifted LLM produce misleading EIG scores?\n\n2. Can the authors provide more details about Love-EQ (e.g., number of samples, annotator count, Fleiss'k)?\n\n3. Why was observed agreement chosen over standard metrics like Spearman correlation or weighted Cohen’s κ for human alignment?\n\n4. Is the rubric construction process reusable across domains, or does it require full re-generation for each new task?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "0c1qtTKB1o", "forum": "OzzbZvFr1c", "replyto": "OzzbZvFr1c", "signatures": ["ICLR.cc/2026/Conference/Submission9502/Reviewer_egqB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9502/Reviewer_egqB"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission9502/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761482664096, "cdate": 1761482664096, "tmdate": 1762921077112, "mdate": 1762921077112, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses the reproducibility and reliability issue in LLM-as-a-Judge evaluation, identifying dimension drift—a phenomenon where a model’s implicit evaluation criteria shift across repeated judgments—as a major cause of inconsistency. To mitigate this, the authors propose an information-theoretic framework that reformulates subjective evaluation as an Expected Information Gain (EIG) maximization problem. Specifically, the method first generates diverse candidate evaluation questions (representing potential judgment dimensions) and then selects the top-k most informative ones to construct a compact and fixed questionnaire. This structured questionnaire replaces free-form reasoning in evaluation, ensuring consistent judgment dimensions.\nExperiments on six benchmarks—CharacterEval, rJokes, Love-EQ, MT-Bench, TSA-MD, and Capybara-Pref—demonstrate improved self-consistency (Cohen’s κ, +7.6% over CoT), better human alignment, and lower amortized cost compared to Direct, CoT, CheckEval, and PoLL baselines. The authors further introduce EMdim, a metric to quantify dimensional consistency, and show that binary question formats yield higher stability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper tackles an important and often overlooked issue in LLM-as-a-Judge, that models can change their implicit judging criteria across runs. Framing this as “dimension drift” is both intuitive and empirically grounded, and it helps explain inconsistencies that prior work only described superficially.\n2. Turning subjective evaluation into an information-gain maximization problem is an elegant move. The EIG-based questionnaire offers a structured and interpretable way to stabilize evaluations without over-engineering. It is easy to implement and could be reused across different subjective tasks.\n3. Experiments are broad and reasonably convincing.The authors evaluate on six distinct benchmarks with multiple model families, and the analysis covers not only accuracy but also stability, cost, and dimensional consistency."}, "weaknesses": {"value": "1. I noticed that the title in the PDF differs from the one shown on OpenReview. You might want to double-check that they are consistent.\n2. The joint distributions $p\\(y, a \\| q, I\\)$ and $p\\( a \\| q, I\\)$ used for EIG estimation are simulated using the same or closely related LLMs that later act as evaluators. This creates a closed-loop bias, as the model essentially optimizes for its own preferences.\n3.  This paper measures human alignment via raw agreement rates without significance testing or chance correction. This weakens claims of improvement.\n4.The top-k question selection relies on greedy ranking without theoretical justification (e.g., submodularity or redundancy control)."}, "questions": {"value": "1.Are the same or closely related LLMs used to both estimate the EIG distributions and perform evaluation? If so, how might this closed-loop setup bias the questionnaire toward the model’s own preferences? Some results using heterogeneous models would clarify robustness.\n2. Binary questions appear most stable, but possibly less sensitive to nuanced differences. Could you report quantitative trade-offs between stability and discriminative precision (e.g., AUROC or fine-grained agreement)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "J1ZFE9S3ao", "forum": "OzzbZvFr1c", "replyto": "OzzbZvFr1c", "signatures": ["ICLR.cc/2026/Conference/Submission9502/Reviewer_bGb2"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9502/Reviewer_bGb2"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission9502/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761738368549, "cdate": 1761738368549, "tmdate": 1762921076828, "mdate": 1762921076828, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "To address stability and reproducibility issues in LLM-based subjective task evaluation caused by dimension drift, this paper proposes an Expected Information Gain (EIG)-based framework that reformulates subjective evaluation as an information-theoretic optimization problem. Specifically, it first generates a diverse pool of candidate evaluation questions and then selects the most informative subset with EIG. Then, these selected subset questions reduce the uncertainty of the latent evaluation score of the subjective tasks. The experiments are conducted across six benchmarks, and the performance is superior to CoT-based and fixed-questionnaire baselines, and is consistent and aligned with human judgments."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper identifies the cause of stability and reproducibility issues in LLM-based subjective task evaluation, which is due to dimension drift and thus intra-annotator inconsistency.\n\n2. Based on the cause of these issues, the authors propose to reformulate subjective evaluation as an information-theoretic optimization problem to select questions to reconcile stability and adaptivity.\n\n3. The experiments are conducted on several benchmarks, and the results achieve superior performance over CoT-based and fixed-rubric baselines."}, "weaknesses": {"value": "1. A major concern of this paper is the novelty. It is encouraged to highlight the differences between this paper and previous work. I am not sure if this paper is the first work to use \"question generation-and-select\" to address the stability and reproducibility issues in subjective tasks evaluation. If not, the difference should be highlighted.\n\n2. Information-theoretic principles, such as expected information gain, are relatively used in machine learning; it is conceptually simple. So the novelty and contribution of applying EIG in this task should be highlighted."}, "questions": {"value": "I am not an expert in LLMs and this is the first time I have known the subjective evaluation tasks, so I may not evaluate this paper fairly and correctly. Use my reviews sparsely."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "JNDpHuSOau", "forum": "OzzbZvFr1c", "replyto": "OzzbZvFr1c", "signatures": ["ICLR.cc/2026/Conference/Submission9502/Reviewer_ccdW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission9502/Reviewer_ccdW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission9502/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761970494994, "cdate": 1761970494994, "tmdate": 1762921076569, "mdate": 1762921076569, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}