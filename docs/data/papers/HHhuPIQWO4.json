{"id": "HHhuPIQWO4", "number": 20075, "cdate": 1758302163040, "mdate": 1759897003053, "content": {"title": "RETuning: Upgrading Inference-Time Scaling for Stock Movement Prediction with Large Language Models", "abstract": "Recently, large language models (LLMs) have demonstrated outstanding reasoning capabilities and inference-time scaling on mathematical and coding tasks. However, their application to financial tasks—especially the most fundamental task of stock movement prediction—remains underexplored. We study a three-class classification problem (up, hold, down) and, by analyzing existing reasoning responses, observe that:\n(1) LLMs are easily swayed by contextual viewpoints, tending to follow analysts' opinions rather than exhibit a systematic, independent analytical logic in their chain-of-thoughts (CoTs).\n(2) LLMs often list summaries from different sources without weighing adversarial evidence, yet such counterevidence is crucial for reliable prediction.\nIt shows that the model does not make good use of its reasoning ability to complete the task.\nTo address this, we propose **R**eflective **E**vidence **Tuning** (**RETuning**), a cold-start method prior to reinforcement learning, to enhance prediction ability. While generating CoT, **RETuning* encourages dynamically constructing an analytical framework from diverse information sources, organizing and scoring evidence for price up or down based on that framework—rather than on contextual viewpoints—and finally reflecting to derive the prediction. This approach maximally aligns the model with its learned analytical framework, ensuring independent logical reasoning and reducing undue influence from context.\nWe also build a large-scale dataset spanning all of 2024 for 5,123 A-share stocks, with long contexts (32K tokens) and over 200K samples. In addition to price and news, it incorporates analysts' opinions, quantitative reports, fundamental data, macroeconomic indicators, and similar stocks.\nExperiments on this new dataset show that, as a cold-start method, **RETuning** successfully unlocks the model's reasoning ability in the financial domain. During reinforcement learning, response length steadily increases under the designed curriculum setting. Furthermore, inference-time scaling still works even after 6 months or on out-of-distribution stocks, since the models gain valuable insights about stock movement prediction.", "tldr": "RETuning boosts LLMs’ independent reasoning for stock prediction using analytical evidence frameworks and a new large-scale dataset.", "keywords": ["Stock Movement Prediction", "Large Language Model", "Inference-Time Scaling", "Reinforcement Learning", "Self-Supervised Fine-Tuning"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/36fb63bcf5f9c89df6038bd2e5931eef71b6cff8.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces RETuning, a method claimed to improve inference-time reasoning of large language models through a “reward-enhanced tuning” process. The approach aims to refine reasoning quality and decision-making without full retraining. The authors apply RETuning to a financial stock prediction task, where models predict overnight gap returns (close-to-next-open) using textual and market information. Experimental results suggest modest improvements in predictive accuracy and reasoning coherence compared to baseline LLMs. The paper presents this as evidence that reward-aligned tuning can upgrade reasoning behaviour in domain-specific settings."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Overall, the paper is well-organized and readable. The efforts above prompt engineering are pretty much, including SFT, RL, and dataset construction. The problem is also interesting."}, "weaknesses": {"value": "- The target is overnight gap return instead of next-day close-to-close movement. This setting limits economic interpretability and predictive scope. The justification that this choice reduces memorization is unconvincing. What LLMs truly memorize are majority the news, company entities, etc. so that the LLMs are likely to know which companies are the historical winners, that's where the survivorship bias and look-ahead bias occurs. It is less likely (though not impossible) that LLMs are trained on extensive numerical price data and remember predictions unless they are fine-tuned specifically for stock price prediction tasks. Even if they are, I don't believe changing the target helps mitigate this issue. Additionally, the open price already reflects overnight sentiment, which is realized at the open. Therefore, there is no tradable decision left at that point if you act on the open.\n\n- There are no baselines using classical time-series or machine-learning methods (e.g. ARIMA, LSTM, XGBoost, or Transformer-based financial models), so it is unclear whether RETuning provides any advantage over standard approaches.\n\n- The evaluation period is only one month, which is far too short for daily-level prediction and raises concerns about cherry-picking and regime dependence.\n\n- The claimed novelty is unclear as reward-based reasoning alignment is well-established.\n\n- The anonymous repository link provided for reproducibility does not work."}, "questions": {"value": "- Can the authors show empirical justification that changing the target helps mitigate memorisation?\n\n- Could the authors extend the evaluation period or run rolling-window tests to ensure robustness?\n\n- How would RETuning compare against traditional financial models or smaller-scale neural baselines?\n\n- Could you please provide the English version of the prompt to ensure readability?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "UBtZL4JLut", "forum": "HHhuPIQWO4", "replyto": "HHhuPIQWO4", "signatures": ["ICLR.cc/2026/Conference/Submission20075/Reviewer_YvyB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20075/Reviewer_YvyB"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission20075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760526355146, "cdate": 1760526355146, "tmdate": 1762932965292, "mdate": 1762932965292, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes RETuning, a two-stage framework designed to enhance LLMs' reasoning ability for stock movement prediction. RETuning first performs SFT to teach models how to construct analytical frameworks, extract and score evidence, and reflect before making predictions, then applies GRPO to refine reasoning consistency and output accuracy. The authors build a new large-scale dataset, Fin-2024, covering over 5,000 A-share stocks and six heterogeneous data sources, to support comprehensive financial reasoning tasks. Extensive experiments demonstrate that RETuning significantly improves predictive accuracy and robustness under both inference-time scaling and out-of-distribution conditions, outperforming strong baselines. Moreover, the approach generalizes well to other financial benchmarks such as BizFinBench, indicating its broad applicability to reasoning-driven financial decision-making."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1) The paper is well written and presents its methodology in a clear and logically coherent manner.\n\n2) RETuning introduces a reasoning-driven paradigm that goes beyond pattern matching by encouraging models to construct, score, and reflect on evidence before prediction.  Also, the framework’s ability to generalize to other financial tasks in BizFinBench (Table 2) further illustrates its adaptability and transferability beyond stock prediction.\n\n3) The paper provides carefully designed empirical analyses that validate the proposed method’s effectiveness across multiple dimensions. Particularly, beyond standard in-sample evaluations, it systematically tests out-of-distribution generalization (OOD-Stock, OOD-Date, and OOD-Stock&Date) and inference-time scaling (n = 1–32) to demonstrate consistent gains in reasoning robustness and scalability."}, "weaknesses": {"value": "1) Although the paper claims significant gains in predictive accuracy (mainly via F1 score), it omits financially meaningful metrics such as cumulative return, Sharpe ratio, maximum drawdown, and Sharp ratio. Without these, the study is hard to demonstrate whether RETuning’s predictions translate into better risk-adjusted profitability or trading performance. This is a critical omission for a paper targeting real-world stock-trading applications, where financial utility and stability matter more than classification accuracy alone.\n\n2) The experiments focus on CoT prompting and supervised fine-tuning but do not benchmark against recent LLM trading frameworks that combine gradient-based reinforcement or hybrid training. For example, the paper omits comparisons with FLAG-Trader [1] — which fuses LLM agents with gradient-based RL for trading decision-making.\nIncluding such baselines would clarify whether RETuning offers true methodological innovation or simply incremental improvements over existing fine-tuning paradigms.\n\n[1] Xiong, Guojun, et al. \"FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading.\" arXiv preprint arXiv:2502.11433 (2025).\n\n3) The dataset is restricted to Chinese A-share stocks in 2024, and the authors themselves acknowledge that this may limit transferability to other markets with different structures, liquidity, and regulations. This geographic and temporal confinement, combined with the short evaluation window (December 2024 and June 2025), makes it difficult to assess how robust RETuning would be in volatile or regime-shifting global markets (e.g., U.S. equities, crypto, commodities)."}, "questions": {"value": "Same as what mentioned in the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "TMbVolK8Li", "forum": "HHhuPIQWO4", "replyto": "HHhuPIQWO4", "signatures": ["ICLR.cc/2026/Conference/Submission20075/Reviewer_NhBe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20075/Reviewer_NhBe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission20075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762047522968, "cdate": 1762047522968, "tmdate": 1762932964368, "mdate": 1762932964368, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **RETuning**, a two-stage training method to improve the (inference-time) analytical reasoning of LLMs for stock movement prediction (SMP). The method integrates Supervised Fine-Tuning (SFT) with Generalized Reinforcement Policy Optimization (GRPO) and a curriculum learning strategy to improve reasoning consistency and decision reliability.\n\nExperiments on (newly contributed in this work) Fin-2024[December], Fin-2025[June], and BizFinBench show consistent performance gains over wide-range of  baselines including existing financial LLM baselines such as LLMFactor, Fin-R1, CMIN, and StockNet, as well as over larger public LLMs (Qwen3, GPT-OSS, DeepSeek-V3).\n\nKey results indicate that the proposed model (DeepSeek_R1_32B_SFT_GRPO) achieves up to +20% improvement in F1 score on out-of-distribution (OOD) financial forecasting tasks and demonstrates scaling benefits under repeated inference.\n\nThe authors open-source their code, datasets, and model weights, and clearly state the limited role of LLM assistance in manuscript polishing."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The following stands out as strengths of the paper:\n\n1. Well-motivated inference-time optimization: RETuning effectively links SFT and RL (via GRPO) for structured reasoning enhancement without architectural changes.\n\n2. Experiments: Fair amount of experiments across multiple financial datasets and OOD splits with transparent hyperparameters.\n\n3. Strong performance: Up to +20.7% F1 improvement on Fin-2024 benchmarks (**self-proposed, contributed** dataset), outperforming strong LLM baselines.\n\n4. Ablation clarity: Systematic study of CoT prompting, SFT, and GRPO reveals consistent gains and scaling behavior.\n\n5. Dataset contribution & Open Science: The contributed dataset (most datasets are US equities market centric) in itself is a fair amount of work which deserves acknowledgement. Code, weights, and datasets released, facilitating reproducibility."}, "weaknesses": {"value": "1. **Novelty**: The use of 2-stage --- under various monikers (teacher-student; System 1,2; ...) --- inference-time mechanisms are copious in AI/ML/Robotics literature. Maybe relatively uncommon under domain-specificity (finanical markets), but the general idea has been explored in this specific task (SMP) earlier (e.g.,  [1](https://openreview.net/forum?id=y3W1TVuJii&referrer=%5Bthe%20profile%20of%20Raeid%20Saqur%5D(%2Fprofile%3Fid%3D~Raeid_Saqur1) \\). \n\n2. Domain limitation, Evaluation Scope and **Generalizability (OOD) claims**: All experiments focus on the Chinese A-share market; unclear generalization to global markets like the US equities market. (N.B., not criticizing the lack of financial domain specific eval/utility metrics (profitability, RoI, Sharpe ratios etc.).\n\n> It is imperative to clarify that **OOD generalization** for financial markets is not necessarily satisfied by samples' 'temporal distance' with each other; but more on the underlying **market regimes**. This unintuitive criterion can be exemplified using a simple e.g.: \"two market samples (trading day slices) -- from the 35 day shutdown of 2018-19 during the first presidency of Donald Trump and from his second presidency, which began on Oct 1, 2025  --- may be less OOD than two day slices picked from Fin[2024], Fin[2025]. In simple terms, 'OOD generalization' claims in the financial domain are more nuanced than what appears to be the assumption used here. Using temporal separation (**OOD_Date**) is questionable if not outright inaccurate. \n\n3. **Critical 'Related Work' not discussed/considered:** Please see lines (121-124). This paper misses critical work [1] that falls both under (i) inference-time scaling, and (ii) Repeated sampling (as per the language used in this manuscript) using LLMs performing SMP as a task using low-cost, heuristic harness and optimal (best of) weighting among _N_ LLMs with theoretical optimality guarantees. Seems like for the scope of this paper and the chosen task (SMP), including [1] from ICLR 2025 as a baseline is appropriate.\n\n4. Computational Cost: The proposed solution, involving SFT, RL, and particularly inference-time scaling with a large number of repeated samples (n=32), is computationally very expensive. While acknowledged as a limitation, providing some concrete numbers on training/inference times would give the reader a better sense of the method's practical viability for real-world deployment; **compared to** existing works, that achieves inference time scaling with less cost [1].\n\n### Ref:\n1. [Filtered not Mixed: Filtering-Based Online Gating for Mixture of Large Language Models](https://openreview.net/forum?id=ecIvumCyAj)"}, "questions": {"value": "1. Could you elaborate on any unique characteristics of the Chinese A-share market that might influence the results, and discuss the potential challenges in applying RETuning to other markets (e.g., US equities), where different types of information (like SEC filings or earnings call transcripts) are prevalent?\n\n2. How were the hyperparameters for the reward shaping function (α, β, γ) and the curriculum learning difficulty thresholds determined? Was this done via a validation set, and have you observed how sensitive the final performance is to these choices?\n\n3. Given the financial context, have you analyzed the precision and recall for the up and down classes separately? A high-precision model for these classes, even with lower recall, might be more valuable in practice than one with a balanced F1 score."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "MfvXlzCfmZ", "forum": "HHhuPIQWO4", "replyto": "HHhuPIQWO4", "signatures": ["ICLR.cc/2026/Conference/Submission20075/Reviewer_Ldyu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20075/Reviewer_Ldyu"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission20075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762206572967, "cdate": 1762206572967, "tmdate": 1762932963395, "mdate": 1762932963395, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on improving stock price movement prediction by applying reinforcement learning to a reasoning-oriented large language model (LLM) trained on a customized dataset. The dataset combines numerical features with textual information, such as news, and the authors incorporate additional contextual elements, such as analytical frameworks, evidence grouping, and reflection, into CoT. The reinforcement learning setup largely follows standard procedures.\n\nWhile the proposed dataset is interesting, its limited temporal coverage reduces its potential impact and applicability in real-world financial scenarios. Moreover, the paper’s technical contribution to reinforcement learning for LLMs appears to be also limited."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper develops a multimodal dataset including numerical and text data of stock markets for enhancing the stock price classification with reasoning LLMs.\n\n2. The experiment is conducted on multiple LLMs and financial tasks in addition to stock price classification."}, "weaknesses": {"value": "1. Arbitrary labeling threshold\n   The target setup appears arbitrary, as labels are defined using a fixed 3% threshold. Given that stock markets are highly dynamic with varying spreads, a more convincing rationale is needed to justify this static labeling choice.\n\n2. Clarity of results in Figure 3\n   Figure 3 is unclear. It is not specified which results correspond to experiments conducted without using chain-of-thought (CoT).\n\n3. Language coverage in the dataset\n   In the appendix, most of the analysis frameworks appear to be in Chinese. It is unclear whether the dataset includes other languages.\n\n4. Limited testing period\n   Due to the short temporal coverage of the data, testing is performed on only one month of data. For stock markets, such a short testing period is not convincing. In particular, the year-end market may exhibit low liquidity, short-term reversions, or profit-taking behaviors, making the results from this month less representative."}, "questions": {"value": "Refer to the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3xoULZMvuI", "forum": "HHhuPIQWO4", "replyto": "HHhuPIQWO4", "signatures": ["ICLR.cc/2026/Conference/Submission20075/Reviewer_mNU5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20075/Reviewer_mNU5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762280276686, "cdate": 1762280276686, "tmdate": 1762932962724, "mdate": 1762932962724, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on improving stock price movement prediction by applying reinforcement learning to a reasoning-oriented large language model (LLM) trained on a customized dataset. The dataset combines numerical features with textual information, such as news, and the authors incorporate additional contextual elements, such as analytical frameworks, evidence grouping, and reflection, into CoT. The reinforcement learning setup largely follows standard procedures.\n\nWhile the proposed dataset is interesting, its limited temporal coverage reduces its potential impact and applicability in real-world financial scenarios. Moreover, the paper’s technical contribution to reinforcement learning for LLMs appears to be also limited."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. This paper develops a multimodal dataset including numerical and text data of stock markets for enhancing the stock price classification with reasoning LLMs.\n\n2. The experiment is conducted on multiple LLMs and financial tasks in addition to stock price classification."}, "weaknesses": {"value": "1. Arbitrary labeling threshold\n\n   The target setup appears arbitrary, as labels are defined using a fixed 3% threshold. Given that stock markets are highly dynamic with varying spreads, a more convincing rationale is needed to justify this static labeling choice.\n\n2. Clarity of results in Figure 3\n\n   Figure 3 is unclear. It is not specified which results correspond to experiments conducted without using chain-of-thought (CoT).\n\n3. Language coverage in the dataset\n\n   In the appendix, most of the analysis frameworks appear to be in Chinese. It is unclear whether the dataset includes other languages.\n\n4. Limited testing period\n\n   Due to the short temporal coverage of the data, testing is performed on only one month of data. For stock markets, such a short testing period is not convincing. In particular, the year-end market may exhibit low liquidity, short-term reversions, or profit-taking behaviors, making the results from this month less representative."}, "questions": {"value": "Refer to the weaknesses section."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3xoULZMvuI", "forum": "HHhuPIQWO4", "replyto": "HHhuPIQWO4", "signatures": ["ICLR.cc/2026/Conference/Submission20075/Reviewer_mNU5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission20075/Reviewer_mNU5"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission20075/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762280276686, "cdate": 1762280276686, "tmdate": 1763385217597, "mdate": 1763385217597, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}