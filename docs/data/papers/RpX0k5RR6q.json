{"id": "RpX0k5RR6q", "number": 22260, "cdate": 1758328519747, "mdate": 1759896876423, "content": {"title": "Relative Scaling Laws for LLMs", "abstract": "Scaling laws describe how language models improve with additional data, parameters, and compute. While widely used, they are typically measured on aggregate test sets. Aggregate evaluations yield clean trends but average over heterogeneous subpopulations, obscuring performance disparities. We introduce relative scaling laws, which track how performance gaps between test distributions evolve with scale rather than focusing solely on absolute error. Using 255 decoder-only Transformers trained under matched-compute (IsoFLOP) budgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we find diverse trajectories: academic domains on MMLU converge toward parity; regional English dialects shift depending on population size; and clusters of AI risk behaviours split, with capability- and influence-related risks increasing during pretraining while adversarial risks do not. These results show that although scaling improves overall performance, it is not a universal equalizer. To support further study, we release all model checkpoints from this work to enable practitioners to measure relative alongside traditional scaling laws, in order to better prioritize robustness challenges in light of the bitter lesson", "tldr": "Relative scaling laws show that while bigger language models consistently improve performance, performance gaps can scale in a variety of ways.", "keywords": ["Scaling Laws", "Linguistic Variation", "Domain Shift", "AI Risk"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c129c6edd14ad058bbc52ae5d4fc3d12d95f843f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Existing scaling law approaches aggregate performance across heterogeneous subpopulations and hide performance discrepancies and to rectify the same this paper introduces Relative Scaling Laws which focus on subpopulation level performance to find disparities if any. To do the same the authors train 255 decoder models with matched-compute and evaluate the performance trajectories on several testbeds. They also find for MCQ style benchmarks a full label + option string-based evaluation balances both accuracy as well as predictability w.r.t. loss. For MMLU the authors find as models scale the performance imbalance across subsets goes away. For language variations when compared to US English other English variants which are spoken widely in their countries also start to match but Sri Lankan and Nigerian English diverge. For AI Risk evals they find at scale some risks become much more apparent, and it helps to find which risks to focus on more urgently."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "- The paper is well written and justifies the choices made well\n- The paper also touches on aspects such as prompt design for evaluation which are crucial for reliable scaling laws\n- The authors show several situations where they validate the relative scaling laws and find disparities in some and also cases where these disparities go away with more compute but also cases where they don't\n- The models released will be an excellent resource for future researchers"}, "weaknesses": {"value": "I do not see any obvious flaws/weaknesses"}, "questions": {"value": "Nits \n\n- The paper will highly benefit from a section (maybe in appendix) listing the exact training tokens used in different plots as it is not immediately obvious"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 10}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Pdn8VKXNOA", "forum": "RpX0k5RR6q", "replyto": "RpX0k5RR6q", "signatures": ["ICLR.cc/2026/Conference/Submission22260/Reviewer_M5s8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22260/Reviewer_M5s8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission22260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761934840344, "cdate": 1761934840344, "tmdate": 1762942140649, "mdate": 1762942140649, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces relative scaling laws as an extension of classical neural scaling laws. Rather than tracking absolute improvements in model performance with compute, the relative scaling laws model how performance gaps between subpopulations evolve as model scale increases. Using 255 decoder-only Transformer models trained under matched IsoFLOP budgets (10**18 - 10**20 FLOPs) on three datasets (CommonPile, DCLM Baseline, and Nemotron-CC), the authors analyze Knowledge domain scaling, Language variation scaling and AI risk scaling. They find that some disparities shrink with scale (e.g., MMLU domain gaps), others persist or widen (e.g., regional English), and some categories of AI risk diverge (e.g., influence vs. adversarial behaviors)."}, "soundness": {"value": 2}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "1. Reframes scaling laws as relative dynamics between subpopulations. This is a minimal extension of existing theory that adds interpretive depth to scaling analyses.\n2. Experimental setup is rigorous enough.\n3. Clear visualizations, figures effectively show convergence/divergence dynamics, aiding conceptual understanding."}, "weaknesses": {"value": "1. No statistical or mathematical validation of the proposed scaling fit function. The relative law is presented as an empirical regression without a clear formal derivation or underlying theoretical justification.\n2. No significance testing of the fitted scaling laws. \n3. While \"relative scaling\" is novel, the empirical insights (e.g., domain convergence, dialect disparity) largely reaffirm known intuitions about representation bias and data imbalance. Not able to appreciate the practical significance of the study."}, "questions": {"value": "See above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HtAC5mojEq", "forum": "RpX0k5RR6q", "replyto": "RpX0k5RR6q", "signatures": ["ICLR.cc/2026/Conference/Submission22260/Reviewer_SrQQ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22260/Reviewer_SrQQ"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission22260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762320452945, "cdate": 1762320452945, "tmdate": 1762942140371, "mdate": 1762942140371, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses limitations of Scaling Laws by proposing a Relative Scaling Law to track how model performance-scale relationships vary across subdomains. It analyzes trends in three key areas: academic knowledge (via MMLU subdomains), regional English (via ICE corpus), and AI risk (via Anthropicâ€™s evaluations). Evaluation results show that scaling does not uniformly improve performance across all tasks. Some subfields benefit more from scale than others, requiring targeted modification for generalization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 4}, "strengths": {"value": "1. Novelty: Breaks through the limitation of Scaling Laws by quantifying the impact of scale on subdomains, providing a more detailed view of model scaling.\n2. Experiment: This work has a solid experiment, including 255 models trained on three distinct dataset under fixed compute budgets, ensuring the quality of result.\n3. Clarity and Impact: The paper is well-written with clear conclusions. It highlights practical implications for multiple subdomains, making it relevant to researchers."}, "weaknesses": {"value": "The conclusions are strongly tied to the specific models and datasets. The behavior of Relative Scaling Laws under other data distributions remains unexplored. This limits the direct usage of guiding next-generation model training pipelines."}, "questions": {"value": "First, thank you for submitting your work to ICLR 2026. I want to notice that I am not an expert in model structure, but as a practitioner with hands-on experience training multiple LLM models, I appreciate the rigorous approach to studying Scaling Laws.\n\nMy key questions are:\n\nDo the models and training data used in this study represent current SOTA training practices? I think the training FLOPs are not enough. Or do the results only reflect the specific model structure, data distribution, and training setup employed here?\nHow do model hyperparameters (e.g., learning rate scheduling, batch size, or optimizer choices) influence the observed Relative Scaling Laws?\n\nOverall, this paper meets the standards for acceptance. I recommend accepting this submission."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "h1ZMfCL6oP", "forum": "RpX0k5RR6q", "replyto": "RpX0k5RR6q", "signatures": ["ICLR.cc/2026/Conference/Submission22260/Reviewer_EFpq"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22260/Reviewer_EFpq"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission22260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762334750965, "cdate": 1762334750965, "tmdate": 1762942140052, "mdate": 1762942140052, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces relative scaling laws, which measure how performance gaps between distributions / capabilities evolve with scale by modeling the ratio of errors as a power law. The authors train 255 models under IsoFLOP budgets from 10^18 to 10^20 FLOPs across three pretraining corpora and have three case studies: MMLU, regional English dialects, and AI risk. The work emphasizes that scaling improves aggregate performance non-uniformly across test subpopulations."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "s1: The proposed framework helps us study how different capabilities evolve as models develop a certain capabilities, rather than only examining scaling with respect to model size and tokens. For instance, Section 4.3 shows that as models improve at self-improvement tasks, capability-related and influence-related risks increase proportionally while adversarial risks (scheming, incorrigibility) do not emerge during pretraining. \n\ns2: The paper carefully studies scaling laws, e.g. they run extensive hyperparameter sweeps to identify compute-optimal token and model size given a FLOP budget (Section 3.1), and run ablations on prompt formats to identify the ones that lead to smoother scaling laws (section 3.2). The finding that probabilities computed over full label + option string works well with scaling laws and is accurate is interesting. \n\ns3: The release of 255 models across three diverse pretraining datasets provides substantial value to the research community.\n\ns4: The two-stage approach to forecasting downstream performance (compute -> loss, then loss -> accuracy via sigmoid calibration) is well-motivated and Figure 2 demonstrates strong generalization to held-out models, which shows that loss can serve as a reliable intermediate metric even at different scales."}, "weaknesses": {"value": "w1: Section 2's mathematical formulation lacks rigor in notation and assumptions. The relative scaling law $G(F) =  \\gamma F^{\\Delta \\beta}$ is presented as following \"directly\" from absolute scaling laws, but the derivation glosses over when this approximation holds. What range of scales is required for the power law assumption to be valid? Under what conditions does the ratio of two power laws remain a power law (this requires both to use the same scale variable F, which may not hold if data mixture or architecture differs)? \n\n\nw2: The case studies lack cohesion and discussion on why we have different observations in different sections: section 4.1 shows convergence, section 4.2 shows divergence for some dialects and convergence for others, and section 4.3 shows divergence between risk types. \n\nw3: The practical utility of relative scaling laws remains unclear. The paper demonstrates that gaps can persist, narrow, or widen, but does not explain how this can be useful. If a relative scaling exponent $\\Delta \\beta$ is significantly negative (gaps widening), how can we reduce it? Should training data be reweighted, or should post-training be relied upon? This is worth discussing in the paper.\n\n\nw4: The paper does not adequately address why model size scaling versus data scaling have different effects on relative performance (Figure 6). The finding that parameter scaling at fixed tokens reproduces compute-optimal relative trends while token scaling at fixed parameters leaves relative performance unchanged suggests that model capacity, not data coverage, drives the shifts. However, this is only shown for one regional English dialect comparison at relatively small scales (40M parameters, 10B tokens). This result deserves more prominence and follow-up analysis."}, "questions": {"value": "Q1: In section 4.1, can you provide evidence that MMLU convergence means knowledge equalization rather than approaching a performance ceiling? For example, if we analyze the distribution of incorrect answers, do models make increasingly sophisticated errors in humanities as they scale, or are errors because of fundamental limitations? another interesting idea would be to examine whether the convergence continues beyond 10^20 FLOPs using your held-out models or by analyzing frontier models where available.\n\nQ2: The English dialect results (section 4.2) show that relative scaling slopes correlate with internet speaker population, but this could be confounded by linguistic distance from training data or data quality. Can you control for these factors? \n\nQ3: What explains the difference between model size and data size scaling in figure 6? You show that parameter scaling affects relative performance while data scaling does not, but only for one comparison at small scale. \n\nQ4: Your relative scaling law formulation assumes both baseline and treatment follow power laws with the same compute variable F. In practice, different distributions may have different effective compute due to data mixture, tokenization artifacts, or domain complexity. How sensitive are your $\\Delta \\beta$ estimates to violations of this assumption? Have you tested alternative formulations, such as allowing different effective compute scaling for baseline and treatment?\n\nQ5: The bootstrap significance test for $\\delta \\beta$ (footnote 2) is mentioned but not described. What is your procedure, resampling training runs, resampling evaluation examples, or both?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "4UnxUndw1P", "forum": "RpX0k5RR6q", "replyto": "RpX0k5RR6q", "signatures": ["ICLR.cc/2026/Conference/Submission22260/Reviewer_UQiu"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission22260/Reviewer_UQiu"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission22260/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762390472420, "cdate": 1762390472420, "tmdate": 1762942139734, "mdate": 1762942139734, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}