{"id": "Kh950JEY88", "number": 13375, "cdate": 1758217134605, "mdate": 1759897441760, "content": {"title": "SPKGDiag: Learning Symptom-Linked Patient Knowledge Graphs via Multi-Hop Similarity Message Passing for Automatic Diagnosis", "abstract": "Automated diagnostics in medicine leverage advanced algorithms to detect, analyze, and interpret medical conditions from data without human intervention. Existing systems predominantly focus on disease prediction, frequently neglecting the critical role of comprehensive symptom analysis. While some prior studies explored the reasoning capabilities of large language models (LLMs), they faced challenges in effectively integrating structured medical knowledge, limiting their ability to generate coherent and clinically relevant patient-centric representations. In this study, we propose \\ours{}, a novel framework that combines symptom extraction with patient-centric knowledge graph construction to enhance the accuracy and efficiency of disease diagnosis. We leverage LLM to automatically extract both implicit and explicit symptoms from patient-doctor conversations and construct a patient-centric knowledge graph with semantic embeddings. A multi-hop neighborhood sampling approach is used to capture common clinical symptoms by modeling both local patient-specific patterns and global population-level insights. Furthermore, we propose to use a specialized Message Passing Neural Network (MPNN) to process this graph structure for diagnosis prediction, aiming to balance semantic richness with structural relevance through message aggregation and self-projection mechanisms. We conducted extensive experiments on four benchmark datasets (MZ-4, MZ-10, Dxy, and Synthetic), achieving improvements of 1.4\\%, 4.4\\%, 2.0\\%, and 7.4\\% over the best existing methods, including RL, transform-based, and multi-department systems, respectively. Our model exhibited robust performance compared to recent baselines on a large-scale in-house dataset. The proposed framework provides an interpretable solution that enhances symptom-driven automatic diagnosis by integrating efficient natural language processing with structured medical reasoning.", "tldr": "Learning Symptom-Linked Patient Knowledge Graphs via Multi-Hop Similarity Message Passing for Automatic Diagnosis", "keywords": ["Automated Diagnosis", "Graph Representation Learning", "Patient-Centric Knowledge Graph"], "primary_area": "learning on graphs and other geometries & topologies", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/54c6d1776cea7e70c27cb0c72cc4af354bad2859.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents **SPKGDIAG**, a novel framework for automated medical diagnosis that tackles key limitations in the poor integration of Large Language Models (LLMs) with structured medical knowledge and the failure to model relationships between patients. The proposed method first uses an LLM to automatically extract both explicit and implicit symptoms from patient-doctor conversations. It then constructs a unique **patient-centric knowledge graph (KG)**, where nodes represent individual patients and edges connect patients who share similar symptom profiles, capturing both individual-level and population-level clinical patterns. A multi-hop neighborhood sampling strategy (specifically 2-hop) is applied to this graph, which is then processed by a specialized **Message Passing Neural Network (MPNN)** to predict the final diagnosis. The authors' main contributions include this integrated LLM-KG framework and the patient-centric graph construction, which demonstrated good performance compared to selected baselines."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper's primary strength lies in its originality, introducing a novel \"patient-centric knowledge graph\" where nodes represent patients, not abstract medical concepts. This clever re-formulation effectively combines the strengths of LLMs (for symptom extraction) and GNNs (for relational reasoning) to model patient similarity, a key gap in prior work."}, "weaknesses": {"value": "Here are the primary weaknesses of the paper, presented concisely:\n\n1.  **Insufficient Baselines and Datasets:** The paper's most significant weakness is its failure to compare against the most relevant model class. It argues against Transformer and RL methods but omits comparisons to established Graph Neural Networks (GNNs) like GAT, which are specifically designed for this type of graph-based clinical prediction [1, 2]. In addition, for disease prediction, MIMIC-III and IV [3, 4] are the most common public real-world large-scale datasets. But the paper did not include any comparison of the MIMIC datasets.  This makes its novelty claims over other *graph* methods unconvincing.\n\n2.  **Poorly Justified MPNN Choice:** While the ablation study shows the chosen MPNN works well, it doesn't adequately explain *why* it's superior to the GCN or GAT variants. The specific architectural components driving the performance gain are left unexplored, weakening the methodological contribution.\n\nReference\n\n1. Yang K, Xu Y, Zou P, et al. KerPrint: local-global knowledge graph enhanced diagnosis prediction for retrospective and prospective interpretations[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2023, 37(4): 5357-5365.\n\n2. Ye M, Cui S, Wang Y, et al. Medpath: Augmenting health risk prediction via medical knowledge paths[C]//Proceedings of the Web Conference 2021. 2021: 1397-1409.\n\n3. Johnson A E W, Pollard T J, Shen L, et al. MIMIC-III, a freely accessible critical care database[J]. Scientific data, 2016, 3(1): 1-9.\n\n4. Johnson A E W, Bulgarelli L, Shen L, et al. MIMIC-IV, a freely accessible electronic health record dataset[J]. Scientific data, 2023, 10(1): 1."}, "questions": {"value": "Here are the key questions for the authors:\n\n1.  Why does the main baseline comparison (Table 1) omit many established GNN KG-based models for clinical prediction, which are arguably the most relevant competitors?\n2.  How do you practically and efficiently construct the $N \\times N$ patient graph for large datasets like VNPT (N > 180,000)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "4zDyTrt2ah", "forum": "Kh950JEY88", "replyto": "Kh950JEY88", "signatures": ["ICLR.cc/2026/Conference/Submission13375/Reviewer_qS3q"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13375/Reviewer_qS3q"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13375/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761537128807, "cdate": 1761537128807, "tmdate": 1762924018053, "mdate": 1762924018053, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper addresses automatic diagnosis from doctor–patient dialogues. It first uses a large language model to extract explicit and implicit symptoms from the conversation, converts these symptoms into embeddings to obtain a patient representation, and then builds a patient similarity graph that links cases with overlapping symptoms. A graph message passing network is applied over this graph to predict a final disease label. The method is evaluated on several public benchmarks (including settings with 4, 10, and 90 disease classes) and one internal dataset, and is compared against a range of prior diagnostic baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "S1: The overall pipeline is clearly described and modular.\nS2: The paper runs experiments on multiple datasets, including both public diagnostic benchmarks and an internal dataset, and reports consistent accuracy gains over a broad set of baselines."}, "weaknesses": {"value": "W1: In my view, the task studied in this paper is presented as automatic diagnosis, but in practice it reduces to standard multi class classification. The model is not asked to reason over an open disease space or identify rare diseases. Instead, it chooses one label from a closed set of candidate diseases, which in MZ 4 is as small as four classes. This is not the same as real clinical diagnosis. It is essentially symptom to label mapping.\nW2: The paper treats the idea of looking at similar neighbors as if it were a novel form of explanation, but using nearest neighbor style patient similarity for diagnostic support and for interpretability has already appeared in automatic diagnosis, prognosis prediction, and patient representation learning. It is not a new idea. In addition, all interpretability claims in the paper are verbal only. There is no validation.\nW3: The upstream symptom extraction is done by GPT 4.1, which extracts explicit and implicit symptoms, then these symptoms are encoded using an off the shelf text embedding model and simply averaged into a patient vector. The model does not train or adapt the extractor. This means that the downstream classifier is really learning from GPT 4.1 outputs rather than from the raw dialogue itself.\nW4: All symptom embeddings are combined only by mean pooling. There is no notion of symptom importance, severity, temporal information, or clinical progression. This reduces the entire case history to something close to an undifferentiated bag of symptoms. Technically, this is almost the weakest possible aggregation strategy, and it does not model any clinical structure or dependency between findings.\nW5: Message passing on the graph is essentially a standard graph neural network. What is called multi hop similarity message passing is just conventional neighbor aggregation plus a self projection term, extended to two hop neighborhoods. This is not fundamentally different from typical MPNN or GraphSAGE style propagation.\nW6: The evaluation metrics are too limited. Nearly all main results are reported in terms of accuracy only, with no per class F1, no macro F1, no recall, no sensitivity, no top k recall. As a result, the paper never answers the clinically important question of whether the model is only getting common benign conditions correct while missing rare but high risk ones. For example, a system that gets common cold correct but fails to identify meningitis is clinically unacceptable.\nW7: There is no serious analysis of class imbalance. For example, in MZ 4 the task has only four classes, and accuracy can easily look high if the distribution is skewed. The paper does not report class distribution details.\nW8: The paper does not include the most important ablation. It does not show what happens if we remove the graph message passing stage entirely and classify directly from the averaged symptom vector. That comparison is essential in order to demonstrate whether the patient graph and multi hop message passing are actually necessary."}, "questions": {"value": "All of my open questions and concerns are essentially covered in the weaknesses. In particular, I am unsure whether the method is actually solving a clinically meaningful diagnosis task (as opposed to closed-set symptom classification), whether the claimed interpretability is real or just narrative, whether the graph construction leaks information or inflates performance, and whether the proposed architecture is actually necessary given the lack of a no-graph ablation. I do not see these points resolved by the current draft."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "9yzmF8OWzi", "forum": "Kh950JEY88", "replyto": "Kh950JEY88", "signatures": ["ICLR.cc/2026/Conference/Submission13375/Reviewer_gLUz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13375/Reviewer_gLUz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13375/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761703212710, "cdate": 1761703212710, "tmdate": 1762924017703, "mdate": 1762924017703, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SPKGDIAG, a framework for automatic disease diagnosis that combines large language models with a patient-centric knowledge graph. Explicit and implicit symptoms are extracted from patient-doctor dialogues via GPT-4.1, embedded into semantic vectors, and connected into a patient graph based on symptom overlap. A Message Passing Neural Network with similarity-based multi-hop sampling is then used to aggregate information from similar patients and predict diseases."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "S1. The paper is generally well-structured. The motivation, methodology, and experiments are presented in a clear, step-wise fashion, and the inclusion of ablation studies and visualization aids readability.\n\nS2.The work tackles an important problem — enhancing medical diagnosis interpretability and robustness through structured patient representations. This topic is of significant interest to both the medical AI and knowledge-graph reasoning communities.\n\nS3.Across multiple datasets, SPKGDIAG consistently outperforms baseline systems, suggesting that incorporating a patient-centric graph can improve diagnostic accuracy and interpretability."}, "weaknesses": {"value": "W1 The research motivation are explored in several recent works with highly similar objectives. For examples [1-3]. While SPKGDIAG shares the similar overarching vision, the manuscript does not clearly explain its unique contribution or design choices compared with these frameworks. The authors are encouraged to discuss distinctions such as why they adopt symptom-overlap edge construction plus two-hop sampling and a shallow MPNN instead of path-level retrieval, multimodal alignment, or learnable similarity edges. \n[1] Jiang, Pengcheng, et al. \"GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs.\" The Twelfth International Conference on Learning Representations.\n[2] Lu, Yuxing, et al. \"Enhancing multimodal knowledge graph representation learning through triple contrastive learning.\" Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence. 2024.\n[3] Wu, Jiageng, Xian Wu, and Jie Yang. \"Guiding clinical reasoning with large language models via knowledge seeds.\" Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence. 2024.\n\nW2 The pipeline relies on straightforward components—LLM-based symptom extraction, embedding, and graph message passing—without a novel modeling mechanism. A critical issue is the potential inconsistency and hallucination in LLM-generated triplets: identical clinical concepts may appear in multiple lexical forms. The paper does not discuss any normalization or de-duplication strategy (e.g., synonym clustering, ontology alignment, or weighted symptom aggregation). Addressing this problem would significantly strengthen methodological soundness.\n\nW3 Several baselines are missing results (“–”) without explanation, leaving unclear whether they failed to run, were incompatible, or underperformed. Furthermore, the framework’s dependence on proprietary GPT-4.1 and text-embedding-3-large raises reproducibility concerns. No analysis examines how alternative LLMs or embedding models affect performance. Given this reliance, a sensitivity or stability study (model substitution, variance, confidence intervals) is necessary to support the robustness claim.\n\nW4 Edges are defined solely by symptom overlap. If the global graph is built before data splitting, test nodes could access training information through shared neighbors. The authors should clarify whether graphs are reconstructed within each split and whether any safeguards (e.g., split-specific adjacency or edge regularization) are applied to prevent leakage."}, "questions": {"value": "Please answer all the concerns in weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YebdwK8S6i", "forum": "Kh950JEY88", "replyto": "Kh950JEY88", "signatures": ["ICLR.cc/2026/Conference/Submission13375/Reviewer_cfcg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13375/Reviewer_cfcg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13375/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761910388978, "cdate": 1761910388978, "tmdate": 1762924017315, "mdate": 1762924017315, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SPKGDIAG, a framework that combines Large Language Models (LLMs) and Graph Neural Networks (GNNs) for automated medical diagnosis. It uses an LLM (GPT-4.1) to extract explicit and implicit symptoms from patient and doctor dialogues, builds a patient-centric knowledge graph based on shared symptoms, and applies a Message Passing Neural Network (MPNN) with two-hop sampling for diagnosis prediction. By integrating language understanding with structured reasoning, SPKGDIAG achieves state-of-the-art results on multiple benchmark and real-world datasets."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper effectively combines LLM-based symptom extraction with graph-based reasoning, bridging unstructured language understanding and structured medical knowledge.\n2. Constructing a patient-level knowledge graph captures inter-patient symptom similarities, enhancing interpretability and clinical relevance.\n3. Extensive experiments on both public and real-world datasets demonstrate consistent and significant improvements over strong baselines."}, "weaknesses": {"value": "1. The framework exclusively uses GPT-4.1, with no experiments evaluating the impact of different LLMs or model variants on performance.\n2. The symptom extraction process fully relies on GPT-4.1 without a clear evaluation of extraction accuracy or hallucination errors, which may introduce noise into the knowledge graph.\n3. The paper does not provide any analysis of the time or computational cost associated with constructing and maintaining the patient-centric knowledge graph; please clarify the overall time efficiency of this process.\n4. Although the abstract claims interpretability, the main text provides only indirect visualization results without a clear case study or explanation of how the model’s decisions can be interpreted."}, "questions": {"value": "See the above **Weaknesses**."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "fvRjw3Ah6K", "forum": "Kh950JEY88", "replyto": "Kh950JEY88", "signatures": ["ICLR.cc/2026/Conference/Submission13375/Reviewer_cvYy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13375/Reviewer_cvYy"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13375/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761977858433, "cdate": 1761977858433, "tmdate": 1762924016914, "mdate": 1762924016914, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents SPKGDIAG, a framework for automated diagnosis that integrates large language models (LLMs) with patient-centric knowledge graphs (KGs) to support symptom-driven disease prediction through multi-hop similarity message passing. The work explores the intersection of natural language understanding and structured graph reasoning, aiming to improve interpretability and clinical relevance in diagnostic systems.\nThe framework consists of several key modules:\n(1) a symptom extractor that uses an LLM to identify both explicit and implicit symptoms from patient-doctor dialogues;\n(2) semantic embedding fusion, which encodes symptom text into high-dimensional embeddings and aggregates them into patient representations;\n(3) patient-centric KG construction, where patients are represented as nodes connected by shared symptoms, with 2-hop neighborhood sampling used to expand local subgraphs for downstream learning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The paper is well written and generally easy to follow, with a logical structure, supportive visualizations (e.g., Figure 2), and clear mathematical descriptions.\n\n2. SPKGDIAG reports best empirical results on four benchmark datasets (MZ-4, MZ-10, Dxy, and Synthetic), suggesting that the proposed approach is competitive with existing methods.\n\n3.The visualization experiments are informative and help illustrate how the model performs across different datasets."}, "weaknesses": {"value": "1.While Section 4.3 reports ablations on sampling and hop depth, it omits a focused evaluation of the KG’s role. Without a version of the model that excludes the KG (e.g., relying solely on LLM embeddings), it is difficult to assess whether improvements are genuinely due to graph reasoning or merely reflect LLM-derived representations. In addition, since the KG is built from LLM-extracted symptoms, potential hallucinations or extraction noise could distort its structure, an issue that warrants empirical investigation.\n\n2.The edge definition in the patient-centric KG, connecting nodes if they share even a single symptom (Equation 3), risks generating excessively dense graphs, especially given the prevalence of common symptoms like fever or cough in medical datasets. The paper lacks statistics on average patient degree or graph sparsity (e.g., density metrics), leaving open the question of whether the GNN truly leverages local structure or degenerates to global averaging.\n\n3.Table 3 in Section 4.3.1 shows that the MPNN-based SPKGDIAG outperforms the GAT-based variant (SPKGDIAG-GAT) by 10.13% without 2-hop subgraph expansion. This counterintuitive result is puzzling, as GAT theoretically offers greater expressiveness via learnable neighbor attention weights. The authors provide no experimental or theoretical analysis (e.g., overfitting on sparse subgraphs, noisy attention due to loose edges, or MPNN's self-projection advantages) to explain this gap, which weakens claims about the MPNN design's superiority."}, "questions": {"value": "See Weaknesses part."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "lYCEQv4Ll2", "forum": "Kh950JEY88", "replyto": "Kh950JEY88", "signatures": ["ICLR.cc/2026/Conference/Submission13375/Reviewer_2Rkj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13375/Reviewer_2Rkj"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission13375/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995119273, "cdate": 1761995119273, "tmdate": 1762924016546, "mdate": 1762924016546, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes SPKGDIAG, a framework for automated medical diagnosis. The authors argue that existing methods fail to adequately model patient-to-patient similarities and struggle to integrate structured knowledge with the capabilities of Large Language Models (LLMs). The proposed framework utilizes LLMs to extract information from the patient conversation and convert the information into text embeddings. Then a patient-centric knowledge graph is constructed, so that a MPNN module can be used to perform node classification to predict the disease of the target patient."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The high-level idea of reframing diagnosis as a node classification problem on a patient-patient similarity graph is conceptually novel.\n2. The overall presentation and the writing is easy to follow and clear.\n3. The paper evaluates its method against a very comprehensive and challenging set of modern baselines, including RL, Transformer, and other graph-based approaches (Table 1)."}, "weaknesses": {"value": "1. The paper contains a lot of over-claims. For example, the so-claimed \"Symptom extractor\" is merely a prompt to LLMs to summarize and extract the information from the dialogues.\n2. The patient-centric KG construction is simply built on noisy and naive function, where any two patients who share any single symptom would be connected in the KG, which do not make any sense.\n3. The patient embeddings are also simply the average of patient's symptom embeddings into a single vector, which igores all granularity and the severity of different symptoms.\n4. The framework requires constructing a graph where every patient is a node. The paper does not address the computational and memory cost of building and processing this graph for a real-world hospital system with millions of patients."}, "questions": {"value": "See weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "rMv8lLcDBV", "forum": "Kh950JEY88", "replyto": "Kh950JEY88", "signatures": ["ICLR.cc/2026/Conference/Submission13375/Reviewer_5wF3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13375/Reviewer_5wF3"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission13375/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762159151037, "cdate": 1762159151037, "tmdate": 1762924016125, "mdate": 1762924016125, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}