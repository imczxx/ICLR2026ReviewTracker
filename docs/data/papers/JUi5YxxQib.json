{"id": "JUi5YxxQib", "number": 15485, "cdate": 1758251805319, "mdate": 1759897303824, "content": {"title": "LLM Agents Do Not Replicate Human Market Traders: Evidence from Experimental Finance", "abstract": "In this study, we compare Large Language Models (LLMs) with human traders in a classic experimental-finance paradigm where prices are determined endogenously. Using a well-established asset-trading design, we run homogeneous markets with single-model LLM agents and heterogeneous “battle-royale” markets with multiple LLM models. Our findings reveal that LLMs generally exhibit a “textbook-rational” approach, pricing the asset near its fundamental value and showing only a muted tendency toward bubble formation, while humans deviate substantially and generate bubbles consistently. Additional treatments, including dividend shocks and repeated-exposure/experienced runs, show that these differences persist across various experimental settings. Further analyses of LLM-generated strategy text indicate lower variance, reduced bias, and stronger reliance on fundamentals relative to humans’ more heuristic-driven trading. These results highlight the risk of using LLM-only agents to model human-driven market phenomena, as key behavioral features such as large, emergent bubbles are not reproduced.", "tldr": "We compare LLM performance to human performance in a experimental trading paradigm.", "keywords": ["Experimental Finance", "Behavioral Finance", "Strategic Behavior", "Financial AI", "Experimental Economics", "Finance"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/282a1f957081703095775bb7f7f1aa3d553fe70b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This study compares Large Language Models (LLMs) with human traders in experimental markets where prices emerge endogenously. LLMs consistently price assets near their fundamental values and show little bubble formation, while humans generate substantial bubbles. These patterns persist across different market conditions. Analysis of LLM strategies shows lower variance, reduced bias, and stronger reliance on fundamentals. The authors conclude that LLMs are poor proxies for modeling human market behavior, as they do not replicate key phenomena like large bubbles."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The findings show clear behavioral differences: LLM-driven markets exhibit far more “textbook‑rational” pricing than human‑driven markets.\n2. The paper shows that LLMs incorporate less bias into their price forecasts and rely more on fundamental‑value strategies, unlike the heuristic‑driven approaches common among human traders.\n3. These results challenge the assumption that “out‑of‑the‑box” LLMs can reliably replicate human market dynamics, especially the emergence of phenomena like bubbles and crashes."}, "weaknesses": {"value": "1. The experimental setup appears overly simplified, which undermines the strength of the authors’ claims. The simulated market environment does not adequately capture the complexity of real-world trading scenarios, making it difficult to draw robust conclusions about performance differences between human traders and LLMs.\n2. The configuration of LLM agents in the experiment also seems simplistic and may not fully reflect the models’ ability to understand and develop trading strategies. The implementation approach resembles prompt engineering, but it is unclear to what extent prompt design was influenced by human intervention or biases, which could affect the validity of the results.\n3. The paper does not provide sufficient detail about the human participants involved in the study. Without clear information on their backgrounds, trading experience, or demographic characteristics, it is difficult to assess the credibility of the reported differences and the generalizability of the findings."}, "questions": {"value": "See the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "PCkLwtuvqx", "forum": "JUi5YxxQib", "replyto": "JUi5YxxQib", "signatures": ["ICLR.cc/2026/Conference/Submission15485/Reviewer_KABm"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15485/Reviewer_KABm"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15485/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761038272137, "cdate": 1761038272137, "tmdate": 1762925774973, "mdate": 1762925774973, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"comment": {"value": "Thank you for the thoughtful and constructive review. We appreciate the positive assessment of the paper’s soundness, presentation, and contribution, and we address the main points below.\n\n1. Textual-Strategy Analysis\n\nWe agree that the current textual analysis is relatively coarse and can be strengthened. Our intent was to establish a first-pass comparison between human and LLM trading rationales, rather than a definitive semantic decomposition. The reviewer’s suggestions point to natural next steps.\n\nTo ensure the revision aligns with the reviewer’s expectations, we would greatly appreciate your guidance on the type of deeper analysis that would be most suitable in this context. For instance, would any of the following approaches address your concern more directly?\n\nEmbedding-based semantic clustering of trader rationales,\n\nPredictive models (e.g., classifiers or regressors) using reasoning text to predict trade direction or deviation from FV,\n\n\nCross-model alignment metrics comparing reasoning similarity among humans and LLMs.\n\nBecause there is no established benchmark for human-vs-LLM reasoning in experimental finance, we would like your perspective on which of these (or other) approaches would strengthen the paper. We are happy to integrate a deeper semantic analysis in the revision.\n\n2. Experiments Suggested by Section 7 (Prompt Interventions)\n\nWe agree that expanding the Section 7-style interventions would be valuable. We conducted several exploratory prompt perturbations, persona prompts, momentum/heuristic prompts, emotional framings (FOMO, “ride the trend”), and even model-generated prompts to test whether these shifts altered trading behavior. These variations did not materially change bubble formation or FV anchoring. We look forward to conducting a more systematic review of this in future work, but the initial results suggest that this behavior is robust to modest prompt changes.\n\n3. Forecasting Task Difficulty and Volatility Differences\n\nYou correctly note that LLM-generated markets exhibit lower price volatility, which mechanically makes the forecasting task easier. We agree that this is an important point and will revise the discussion to ensure this is appropriately scoped.\n\nOur goal in this section is not to claim that LLMs are inherently superior forecasters across all environments, but to examine how well they can anticipate both their own and others’ actions in environments where they collectively determine the price path. This is a distinctive setting: because the agents create the price dynamics, their forecasting accuracy is informative about the internal coherence of the market they generate.\n\nIn that sense, the forecasting results are interesting precisely because they reflect how LLMs behave when they dictate the underlying dynamics, a scenario that is increasingly relevant in multi-agent LLM research.\n\nAs the reviewer points out, lower volatility makes it difficult to compare absolute forecast errors across human and LLM markets directly. One could partially adjust for this using measures such as forecast errors scaled by the price standard deviation, but this would be imperfect too, because volatility differences arise endogenously from agents’ behavior—precisely the phenomenon we aim to characterize.\n\nWe will clarify in the revision that the forecasting section should be interpreted within this controlled, endogenous environment rather than as an absolute comparison of predictive skill across markets. We appreciate the reviewer raising this, and agree it is an important point for framing the contribution.\n\n4. Outdated Models and Breadth of Tested Systems\n\nWe agree that model recency matters. In our results, the newest models (GPT-4o, Claude-Sonnet, Gemini-1.5-Pro) show the strongest adherence to fundamentals, while older models display more variability and occasional small bubbles. In other words, including older models does not generate the main result; it moves behavior slightly closer to the human pattern and therefore attenuates the effect.\n\nWe view this cross-model pattern as informative rather than a limitation. One reason this paper is useful is that it establishes a clear baseline for how current LLMs behave when prices are fully endogenous. If future, more capable models begin to diverge from FV, exhibit more human-like speculation, or shift toward momentum-driven behavior, that would itself be an interesting scientific development. Having a stylized, reproducible benchmark now is what makes such comparisons possible.\n\nWe will clarify this framing in the revision.\n\nSummary\n\nWe appreciate the reviewer’s positive assessment and detailed suggestions. We will:\n\nExpand the semantic depth of the text-analysis section, with guidance from the reviewer on preferred methods,\n\nClarify the role of model recency, and\n\nStrengthen the explanation of how and why different textual-strategy patterns matter.\n\nThank you again for the thoughtful feedback."}}, "id": "oFCXuIT4aN", "forum": "JUi5YxxQib", "replyto": "JUi5YxxQib", "signatures": ["ICLR.cc/2026/Conference/Submission15485/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15485/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15485/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763605292663, "cdate": 1763605292663, "tmdate": 1763605292663, "mdate": 1763605292663, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper conducted LLM experiments on experimental finance settings where there's a known fundamental value and compare it with human experimental data. The paper finds that LLM stick close to fundamentals and rarely form large bubbles, which departs from human behaviors. The paper also tested settings on battle royale markes and forecasts, showing LLM-human differences."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper covers several topics, there's comparison to human baselines and careful analysis."}, "weaknesses": {"value": "I'm a bit unsold on the motivation and contributions.\n\n- First of all, the exact types of experimental data and 'correct'/'expected' behavior is well within the training data of the LLM. In addition, prompts in the experiment disclose redemption value / fundamental value mechanisms, so it is largely unsurprising to observe the discovered LLM phenomenon. In other words, \"textbook-rational\" seem unsurprising given that LLMs are trained on the said textbooks, as well as the CoT reasoning paradigm that they are trained to use. \n- Given the above, I’m not sure that the mere discovery of LLM \"rationality\" is new or persuasive for this community. Nowadays, models already hit near–top human accuracy on competitive math (gold medal in IMO) and similar benchmarks; so the fact that an LLM looks more rational than the average human-especially when the task is framed explicitly with a redemption value-doesn’t feel surprising. I do see value in documenting this within experimental finance, but the acceptance bar likely requires more than this. \n- Most experiments are run on (or include) older model generations. In line 1028 the authors noted that \"Grok 2 has been deprecated, and\nthus we were unable to run this treatment with that model. Gemini-1.5 had technical errors that will be rerun for camera-ready submission\". I think especially given the framing of the papers in line 450, any deployment in real markets will minimally use one of the up to date reasoning models. \n\nSome minor points:\n- Humans face strict per-screen time limits (20 seconds to trade and 30 seconds to forecast). There seem to be a difficulty translating that to time and budget for LLMs. In the prompt used in the paper, the authors described (line 971) \"PLANS/INSIGHTS\" files that agents make on top of chain of thought. That's a notable difference in experimental conditions.\n- There are some inconsistent findings across models (e.g., Gemini-1.5 Pro vs. GPT-3.5 vs. GPT-4o), suggesting model-specific idiosyncrasies that may not hold across generations. The paper’s own summary tables/plots show materially different error patterns and dynamics by model.\n- The paper also notes \"Token usage for Gemini 1.5 Pro could not be accessed through the API console\". This is a minor point but is not consistent with my experience with using it."}, "questions": {"value": "- LLMs have inherent prompt sensitivity. Is there any ablations on how that will affect the results (e.g. one counterargument from the papers that 'claim' to use LLM for human simulation might say that they are explicitly asking LLM to take on human persona and roles - will that change behaviors systematically)\n\n- Can the authors articulate the contribution beyond documenting \"LLMs look rational under explicit FV prompts\"? What is the core conceptual/empirical advance for experimental finance or agent-based markets, and how does it differ from prior work and adds new insights to the community?\n\n- Results may hinge on PLANS/INSIGHTS + CoT and looser time budgets for models. Is there results on no-memory/no-cot agents, or, another extreme, on more up-to-date advanced reasoning models?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "h26Z3TuUHN", "forum": "JUi5YxxQib", "replyto": "JUi5YxxQib", "signatures": ["ICLR.cc/2026/Conference/Submission15485/Reviewer_tK82"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15485/Reviewer_tK82"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15485/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761579946617, "cdate": 1761579946617, "tmdate": 1762925774160, "mdate": 1762925774160, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Experimental Design: Conducts homogeneous (single-model) and heterogeneous (\"Battle Royale\") LLM-agent markets.\n\nBehavioral Divergence: Demonstrates that LLMs exhibit \"textbook-rational\" behavior, while humans consistently generate price bubbles.\n\nRobustness Tests: Validates findings across dividend shocks, experienced sessions, and linguistic analysis of trading strategies.\n\nForecast Rationality: Shows LLMs produce more accurate and less biased price forecasts than humans."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.  First systematic comparison of LLMs and humans in endogenous experimental markets, bridging behavioral finance and AI alignment\n\n2. Rigorous methodology: a lot of markets vs. 6 LLM models (Claude-3.5, GPT-4o, etc.), with controls for dividend shocks and experience.\n\n3. Well-structured with clear visualizations and statistical tests.\n\n4. Challenges the use of off-the-shelf LLMs as human proxies in finance experiments."}, "weaknesses": {"value": "Are larger models (e.g., GPT-4 Turbo, Claude 3 Opus) and LLMs that may exhibit different behaviors excluded?\n\nWhy LLMs are anchored to fundamentals is not explored.\n\nThe simplified single-asset design lacks real-world characteristics (e.g., short selling, information asymmetry).\n\nThe incentives of human participants (e.g., monetary rewards) may not align with the \"profit maximization\" imperative of LLMs.\n\nThe impact of imperative engineering (e.g., explicit bubble-inducing directives) is not explored."}, "questions": {"value": "Would a larger LLM (e.g., Claude 3 Opus) or a modified RLHF model exhibit bubble-like behavior?\n\nHow do the results apply to markets involving high-frequency trading or multi-asset portfolios?\n\nDoes the human participants' prior financial knowledge influence the results?\n\nCan LLMs more accurately simulate inexperienced traders?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LoZxf5fdzV", "forum": "JUi5YxxQib", "replyto": "JUi5YxxQib", "signatures": ["ICLR.cc/2026/Conference/Submission15485/Reviewer_Jkb4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15485/Reviewer_Jkb4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15485/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761617049807, "cdate": 1761617049807, "tmdate": 1762925773782, "mdate": 1762925773782, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper compares the trading behavior of humans and an array of LLMs in an experimental asset market. Subjects trade the asset with each other, and the asset price depends on trading activity, allowing for the possibility of bubble formation. The paper finds that the LLMs it tests are less prone to bubble formation than human traders, this result holds both in a \"mono-agent\" (only copies of agents based on the same LLM) and in a \"battle royale\" (different LLMs competing) setting. Moreover, the two most capable LLMs tested (GPT-4o, Claude 3.5 Sonnet) exhibit the least tendency towards bubble formation. The paper also conducts a textual analysis to uncover reasons behind differences in LLM and human trading behavior."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "The experimental design allows for a sensible comparison of human versus LLM behavior. Even though the LLMs tested are relatively outdated at this point, the fact that a broad array of different LLMs from different providers are tested, and the separation between human and LLM behavior is so clear, means the results strike me as credible and generalizable."}, "weaknesses": {"value": "The textual trading strategy analysis is interesting but perhaps a little rudimentary, focusing mostly on keyword matching. Moreover, the results at the start of Section 6.1 (that the LLMs and humans all write in different styles) is not really surprising. This analysis would be strengthened by, e.g. (1) a more fine-grained semantic text analysis, (2) additional experiments in the style of Section 7, e.g. checking how LLMs' trading behavior changes if the content of the insight/plan part of the prompt changes."}, "questions": {"value": "In Section 8, it seems like the prediction task the LLMs face is easier, because the prices in the LLM markets exhibit less volatility than the prices in the human markets. Is there possibly a way to control for this? For example, perhaps one could task each LLM with the prediction tasks of all the other markets (including the human markets)."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "aluEctW519", "forum": "JUi5YxxQib", "replyto": "JUi5YxxQib", "signatures": ["ICLR.cc/2026/Conference/Submission15485/Reviewer_x6wg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15485/Reviewer_x6wg"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission15485/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761949354276, "cdate": 1761949354276, "tmdate": 1762925773255, "mdate": 1762925773255, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}