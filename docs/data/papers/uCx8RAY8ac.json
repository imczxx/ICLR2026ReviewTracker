{"id": "uCx8RAY8ac", "number": 4624, "cdate": 1757729494107, "mdate": 1759898022914, "content": {"title": "Chaining Spectral Pearls: Ellipsoidal Forecasting Beyond Trajectories for Time Series", "abstract": "Current long-term time-series forecasting (LTSF) practice---pointwise metrics on mostly stochastic data-masks brittleness under deterministic chaos. We argue for stress-testing on canonical chaotic systems and for predicting future \\emph{geometry} rather than exact trajectories. We present \\Fern (Forecasting with Ellipsoidal RepresentatioN), a geometry-aware forecaster that applies per-patch local linear transport with explicit spectral factors (eigenvectors/eigenvalues), yielding structure-preserving forecasts and actionable diagnostics of stability, modes, and regime shifts. Alongside MSE/MAE, we report Sliced Wasserstein Distance (shape fidelity) and Effective Prediction Time (horizon stability). On Lorenz63, Rössler, and Chua, \\Fern delivers substantially lower error and improved stability versus strong LTSF baselines, while remaining competitive on ETT and Weather. By coupling simple local transport with explicit spectral interpretability, \\Fern offers a practical path to robust, transparent long-horizon forecasting.", "tldr": "We introduce FERN, a forecaster that predicts a time series' future geometry using a chain of spectrally-interpretable ellipsoids, achieving robust performance on LTSF tasks.", "keywords": ["Time Series Forecasting", "Optimal Transport", "Interpretability", "Normalizing Flows", "Geometric Deep Learning", "Dynamical Systems"], "primary_area": "learning on time series and dynamical systems", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/1aee9a4771cac1aae06df3abfe72bc349ecf1fc3.pdf", "supplementary_material": "/attachment/9b09a0fcbeb60b560a788bd15f6d7d06b3d5c2b2.zip"}, "replies": [{"content": {"summary": {"value": "The paper introduces FERN (Forecasting with Ellipsoidal Rep-resentatioN), a time-series forecaster that predicts future geometry (ellipsoids) rather than exact trajectories, which is robust under deterministic chaos. It employs local linear transport with explicit spectral factors (eigenvectors/eigenvalues) for interpretability. FERN is stress-tested on chaotic systems (Lorenz63, Rössler, Chua) using new metrics like Sliced Wasserstein Distance and Effective Prediction Time, and outperforms baselines significantly on these."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper proposes new metrics (Sliced Wasserstein Distance and Effective Prediction Time) for evaluating forecasting performance in chaotic systems.  \n2. The evaluation involving real-world benchmarks enhances the practical relevance of the proposed method."}, "weaknesses": {"value": "1. The Appendix is unstructured and requires more rigorous revision to meet the publication standard.\n2. The literature review is insufficient, and many related works and baselines are not discussed, making it difficult to assess the novelty and effectiveness of the proposed method. For instances:\n - Koopman operator-based methods for modeling chaos: Cheng, Xiaoyuan, et al. \"Learning Chaos In A Linear Way.\" The Thirteenth International Conference on Learning Representations.\n - Geometric distribution preserving methods: Li, Zongyi, et al. \"Learning Dissipative Dynamics in Chaotic Systems.\" (NeurIPS 2021).\n - Chaos system Benchmarks: Gilpin, William. \"Chaos as an interpretable benchmark for forecasting and data-driven modelling.\" Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2).\n - Reservoir computing methods for chaotic systems.\n - Diffusion/Flow based methods, e.g. Shysheya, Aliaksandra, et al. \"On conditional diffusion models for PDE simulations.\" Advances in Neural Information Processing Systems 37 (2024): 23246-23300.\n\n3. The paper lacks clarity in validating the method in how is the spectral factors in deployed; how the network is implemented and optimized with the Algorithm 1."}, "questions": {"value": "1. How is future geometry defined formally? \n2. How is the model's performance compared to existing methods for chaotic time series forecasting as referenced above?\n3. Interest in scalability of Rotation: for high-dimensional data, how does the fixed R=8 reflections sufficiently approximate the necessary rotation U(z), and is this rotation layer a bottleneck for datasets larger than the 21 variables in Weather?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "k3HpHVWC3C", "forum": "uCx8RAY8ac", "replyto": "uCx8RAY8ac", "signatures": ["ICLR.cc/2026/Conference/Submission4624/Reviewer_ZSmM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4624/Reviewer_ZSmM"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission4624/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761573515711, "cdate": 1761573515711, "tmdate": 1762917474700, "mdate": 1762917474700, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The motivation of this paper is twofold: (1) it introduces Forecasting with Ellipsoidal RepresentatioN (FERN) for long-term time-series forecasting and (2) contributes a new evaluation protocol. The proposed FERN model is geometry-aware that applies per-patch local linear transport using explicit spectral factors (eigenvectors/eigenvalues). This method transforms a Gaussian base distribution into a chain of local ellipsoids to predict the future geometry rather than the exact trajectory. The proposed evaluation metrics include Sliced Wasserstein Distance (SWD) and Effective Prediction Time (EPT) to address the limitations of pointwise metrics on chaotic systems. Experiments demonstrate that FERN outperforms baselines on several chaotic systems. The model also remains competitive on standard ETT and Weather benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The evaluation protocol is a substantive and timely contribution that correctly diagnoses blind spots in current LTSF practice—namely, overemphasis on noisy, quasi-periodic data and pointwise metrics. Accordingly, the authors propose concrete solution: geometry-aware (SWD) and stability (EPT) metrics with stress-testing on chaotic systems.\n- The experiment evaluation is thorough and transparent. The authors provide comprehensive ablations and clear setup details in the appendix . A particularly valuable contribution is the identification of \"recency bias\" in standard validation splits, which addresses a common pitfall in training time-series models."}, "weaknesses": {"value": "- The paper aggregates concepts from chaos theory, Koopman operator theory, optimal transport, and normalizing flows, but the authors fail to integrate these complex ideas into a unified framework and make the presentation hard to follow.\n- The “Scope and Distinctions” section notes that FERN borrows NF/OT/Koopman language while not constituting any of these. The framework scope is ambiguous and unclear. Additional clarification should be included to support the spectral transparency claim. \n- The technical description is frequently replaced with unhelpful analogies, which severely hinders the understanding of the paper."}, "questions": {"value": "- What does the paper mean when it says it targets \"conditional local geometry, not the dynamics\"? But the proposed model is used for learning and forecasting the dynamics.\n- There are many blank margins in the manuscript; please remove them to improve readability and length compliance.\n- The paper’s organization needs attention. There is no conclusion, and the references are placed after the appendix.\n- In Algorithm 1, the Ellipsoidal Transport layer uses a fixed, learnable $K$ matrix to *mimic complex value eigenvalues*. How is this $K$ matrix trained, and is it shared across all datasets or trained per dataset? What evidence supports the claim that this simple block structure is sufficient to capture \"global components\"  of diverse dynamical systems?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HMno2lZvLD", "forum": "uCx8RAY8ac", "replyto": "uCx8RAY8ac", "signatures": ["ICLR.cc/2026/Conference/Submission4624/Reviewer_BPhh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4624/Reviewer_BPhh"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission4624/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761786618935, "cdate": 1761786618935, "tmdate": 1762917473611, "mdate": 1762917473611, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FERN, a geometry-aware forecaster that represents future time-series patches as locally linear ellipsoids. It introduces a new evaluation protocol using Wasserstein distance and Effective Prediction Time, arguing that existing long-term forecasting (LTSF) metrics overfit noise and miss chaos."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "I like the theoretical explaination of this article, looks good"}, "weaknesses": {"value": "- Writing is heavy, overly theoretical, and sometimes reads like a position essay rather than a reproducible model paper.\n- No phase-space or attractor plots to prove that geometry preservation actually happens. Figure 1 is schematic only."}, "questions": {"value": "1. Add visual reconstructions of chaotic attractors showing ellipsoidal chains.\n2. How does the model sensity to the initial condition? some demonstration would be greatful, it is not clear to me."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ll5vaj1Vur", "forum": "uCx8RAY8ac", "replyto": "uCx8RAY8ac", "signatures": ["ICLR.cc/2026/Conference/Submission4624/Reviewer_hekH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4624/Reviewer_hekH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4624/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907482351, "cdate": 1761907482351, "tmdate": 1762917473291, "mdate": 1762917473291, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FERN, a geometry-aware forecaster that represents future time-series patches as locally linear ellipsoids. It introduces a new evaluation protocol using Wasserstein distance and Effective Prediction Time, arguing that existing long-term forecasting (LTSF) metrics overfit noise and miss chaos."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "I like the theoretical explaination of this article, looks good"}, "weaknesses": {"value": "- Writing is heavy, overly theoretical, and sometimes reads like a position essay rather than a reproducible model paper.\n- No phase-space or attractor plots to prove that geometry preservation actually happens. Figure 1 is schematic only."}, "questions": {"value": "1. Add visual reconstructions of chaotic attractors showing ellipsoidal chains.\n2. How does the model sensity to the initial condition? some demonstration would be greatful, it is not clear to me."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ll5vaj1Vur", "forum": "uCx8RAY8ac", "replyto": "uCx8RAY8ac", "signatures": ["ICLR.cc/2026/Conference/Submission4624/Reviewer_hekH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4624/Reviewer_hekH"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission4624/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761907482351, "cdate": 1761907482351, "tmdate": 1763716791518, "mdate": 1763716791518, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose FERN, a model for long-term time series forecasting that represents local dynamics via ellipsoidal approximations with symmetric positive semi-definite Jacobians. The paper proposes a new evaluation protocol stress-testing on chaotic systems using Wasserstein-2 distance and effective prediction time metrics. The methodology aims to predict local conditional geometry via first-order Taylor approximation coupled with spectral decomposition, along with a Koopman-inspired global operator layer. On chaotic benchmarks, FERN achieves significantly better performance while remaining competitive on standard ETT benchmarks."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper achieves strong empirical results on chaotic benchmarks, with FERN substantially outperforming baselines. This performance gain, regardless of the theoretical framing issues, demonstrates that the specific architectural choices have merit for certain types of time series.\n\nThe emphasis on stress-testing models on chaotic systems is valuable, even if not entirely novel. The paper makes a reasonable argument for why current benchmarks may reward overfitting to specific historical trajectories rather than learning generalizable dynamics.\n\nThe Takens' embedding discussion, while not directly justifying the proposed method, provides useful context for understanding why simple models succeed on some benchmarks and why patching works well."}, "weaknesses": {"value": "- The core idea of the FERN model is conceptually interesting but it is presented as an ad-hoc combination of normalizing flow, optimal transport, and Koopman frameworks. The authors explicitly state they are \"not actually\" implementing any of these theories rigorously, suggesting design-by-analogy rather than derivation from first principles and it also raises the question of why these frameworks are invoked at all.\n\n- I found the collaborative movie adaptation analogy in Section 3 unhelpful and it made the technical content hard to parse. My understanding is that the proposed FERN model consists of two components:\n   - **Encoder:** Despite being framed as \"adapted ANF,\" this is simply a bidirectional coupling network that iteratively refines x and z ~ N(0,I) as follows: For i = 1…5: $z \\leftarrow s^*(x) \\odot z + t(x)$, $x \\leftarrow s^*(z) \\odot x + t(z)$. This mapping lacks the fundamental properties of normalizing flows and I don't see any clear benefit from the ANF framing. \n  - **Ellipsoidal Transport:** The prediction is computed as: $y^* = U(z) K \\Lambda (z) K^T U(z)^T y_0 + t(z)$, where $y_0 ~ N(0,I)$. This is a structured linear transformation of Gaussian noise, conditioned on z. The optimal transport framing does not provide any meaningful insight since there is no transport problem being solved, no source/target distributions, and no transport cost. The Brenier theorem citation is irrelevant since this is supervised learning with MSE loss, not measure transportation. The SPSD structure merely constrains the linear map's form but doesn't make it an OT map.\n\n  In summary, FERN essentially learns a nonlinear mapping from input x to parameters of an affine transformation applied to Gaussian noise, trained with standard MSE loss. The extensive discussion of ellipsoids, optimal transport, and Koopman theory obscures rather than illuminates this simple architecture. The actual contribution appears to be the specific parameterization choices that is shown to work well empirically on chaotic systems, not any deep connection to the invoked mathematical frameworks. \n\n- I was unable to find a formal definition of local conditional geometry and it was not clear to me if the ellipsoids refer to conditional distributions or prediction sets or second-moment approximations.\n\n- The paper does not include a conclusions section and ends abruptly with the numerical studies. \n\n- The results for chaotic systems are impressive. However, the discussion of results needs more depth. For instance, it was not clear what happens beyond a few Lyapunov times where pointwise prediction is theoretically impossible."}, "questions": {"value": "- Please formally define what \"local conditional geometry” means in the context of this work.\n- Section 3.2 provides a W2 bound; however, here deterministic predictions are being made and not distribution matching. Can you clarify what distributions are being transported and how this relates to minimizing MSE on point predictions?\n- Algorithm 1 shows U(z) is data-dependent. How do you parametrize U to maintain orthogonality during SGD? \n- How do you prevent rank collapse?\n- How does eigendecomposition cost scale with patch size P, number of patches L, and horizon H? It will be useful to provide wall-clock time comparisons at varying scales (e.g., d = 1, 10, 50; T = 100, 1000, 10000).\n- Can you please provide details of the data preprocessing protocol used for FERN in the numerical studies."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3PwgrKaXxb", "forum": "uCx8RAY8ac", "replyto": "uCx8RAY8ac", "signatures": ["ICLR.cc/2026/Conference/Submission4624/Reviewer_tQZD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4624/Reviewer_tQZD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission4624/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761988343972, "cdate": 1761988343972, "tmdate": 1762917472957, "mdate": 1762917472957, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "Additional Results: 21 Controlled Non-Stationary Synthetic Benchmarks"}, "comment": {"value": "# NEW EXPERIMENTS\n\nWe ran 21 new experiments (336-in-336-out, 2 seeds, 25k-35k samples, 70%:20%:10% splits) to systematically investigate the effect of non-stationarity, **on both chaotic AND stochastic datasets**, and **we invite the reviewer to review the executive summaries.** Full table available in upcoming revised PDF.\n\n&nbsp;\n\n**Purpose of Additional Experiments**:\n\n&nbsp;\n\n- **Prove** FERN is not a chaotic specialist.\n\n&nbsp;\n\n- *Systematically* use the **synthetic datasets** to see how models handles (1) **chaotic** dynamics (2) **stochastic** dynamics and (3) various non-stationarities, where the **exact non-stationarities are known, explicit, precise.** \n\n&nbsp;\n\nWe design three non-stationarities that **happen at *exactly* the midpoint of the train data:**\n\n&nbsp;\n\n-**Parameter drift**: system parameters change mid-way: e.g. Lorenz **parameters are [sigma=10, rho=28, beta=8/3]** and having generated half of the train data, **parameters become [sigma=10.1, rho=28.1, beta=8.1/3]** and keep generating the rest.\n\n&nbsp;\n\n-**State perturbation**: e.g. in Lorenz, **0.9 is added to every dimension**. This answers **reviewer hekH's question: what is model's sensitivity to initial conditions**. Due to states being perturbed, the Lorenz system is changed, and all models compete fairly under this setting.\n\n&nbsp;\n\n-**Regime replacement**: at midway, the trajectory is replaced by one generated with **different parameters and initial conditions**. \n\n&nbsp;\n\nWe include three more models: **Koopa** [NeurIPS 2023], **ModernTCN** [ICLR 2024], **PFNN (Poincaré Flow)** [ICLR 2025] (**requested by reviewer ZSmM**).\n\n&nbsp;\n\nSummaries:\n\n&nbsp;\n\n**Average rank** (of MSE and SWD) across all tasks (lower is better):\n-Fern: ≈ 1.95\n-ModernTCN: ≈ 3.43\n-TimeMixer: ≈ 3.57\n-PatchTST: ≈ 3.93\n-DLinear: ≈ 4.05\n-Koopa: ≈ 4.55\n-PFNN: ≈ 6.38\n\n&nbsp;\n\n-**FERN is best/co-best** in average MSE and SWD ranks **on 13/21 tasks**: **7/10 for chaotic, 6/11 on stochastic ones**. Other than **100x** better performance on Rossler, we see for example **48% reduction** of MSE against TimeMixer **on the stochastic classic**: Switching linear dynamical systems. \n\n&nbsp;\n\nUsing TimeMixer as baseline, **Fern is**:\n\n- **Switching LDS – base (no shock):** 1st in SWD, **13% lower SWD**, similar MSE.  \n\n- **Switching LDS – parameter change:** 2nd in SWD, **9% lower MSE, 14% lower SWD**.  \n\n- **Switching LDS – regime replacement:** 1st in both, **48% lower MSE, 58% lower SWD**.  \n\n- **Seasonal AR – base:** 1st in MSE, 2nd in SWD, **same MSE, 15% lower SWD**.  \n\n- **Seasonal AR – parameter drift:** 1st in MSE, 2nd in SWD, **2% lower MSE, 18% lower SWD**.  \n\n- **GARCH(1,1) – parameter shock:** 1st in MSE, **5% lower MSE**, but **12% higher SWD**.  \n\n- **Double-well SDE – base:** 1st in SWD, **8% lower MSE, 35% lower SWD**.  \n\n- **Double-well SDE – parameter shock:** 1st in both, **37% lower MSE, 40% lower SWD**.  \n\n- **Ornstein–Uhlenbeck SDE – base/param:** 2nd in MSE with **5–7% lower MSE**, but worse SWD; these Gaussian cases are easy and favor linear models.\n\n- **Rössler – base:** 1st in both, **98% lower MSE, 99% lower SWD**.  \n- **Rössler – parameter shock:** 1st in both, **≈99% lower MSE and SWD**.  \n\n- **Lorenz-63 – base:** 1st in both, **50% lower MSE, 56% lower SWD**.  \n- **Lorenz-63 – state shock:** 1st in both, **≈61% lower MSE, 64% lower SWD**.  \n- **Lorenz-63 – parameter shock:** 1st in both, **≈52% lower MSE, 57% lower SWD**.  \n\n- **Lorenz-96 – base:** 1st in both, **35% lower MSE, 55% lower SWD**.  \n- **Lorenz-96 – regime replacement:** 1st in both, **20% lower MSE, 41% lower SWD**.  \n\n- **Chua’s circuit – base:** ModernTCN is 1st; Fern is 2nd with **40% lower MSE, 28% lower SWD** vs TimeMixer.  \n- **Chua’s circuit – parameter shock:** TimeMixer is 1st; Fern is 2nd with **≈14% lower SWD** and **≈2% higher MSE** vs TimeMixer."}}, "id": "nMCn2hu5Ti", "forum": "uCx8RAY8ac", "replyto": "uCx8RAY8ac", "signatures": ["ICLR.cc/2026/Conference/Submission4624/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4624/Authors"], "number": 6, "invitations": ["ICLR.cc/2026/Conference/Submission4624/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763702653947, "cdate": 1763702653947, "tmdate": 1763702975368, "mdate": 1763702975368, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "NEW PLOTS: Lorenz-63 Geometry and Eigenvalue Diagnostics markdown Copy code"}, "comment": {"value": "# NEW PLOTS\n\n**Action Taken**: We include three plots in our anonymized GitHub repository. We recommend opening a new browser tab. For a single place to access, we prepare anonymous uploads at imgur as well.\n\nhttps://imgur.com/a/UcXsjPj\n\n&nbsp;\n\n- **Plot 1:** Side-by-side Lorenz–63 reconstruction with data vs FERN prediction.\nhttps://anonymous.4open.science/api/repo/FERN-1F63/file/attr_plot.png?v=eeed31d6\n&nbsp;\nhttps://imgur.com/a/3E8X8dB\n\n- **Plot 2:** Single attractor reconstruction with color-coded local behavior.\nhttps://anonymous.4open.science/api/repo/FERN-1F63/file/attr_plot_2.png?v=04046b74\n\n- **Plot 3:** Error analysis and an eigenvalue “heatmap” over time.\nhttps://anonymous.4open.science/api/repo/FERN-1F63/file/diag_plot.png?v=162c00e5\n\n- **Plot 4:** Similar to Plot1, but display **largest** eigenvalues, **not** sum of eigenvalues\nhttps://anonymous.4open.science/api/repo/FERN-1F63/file/diag_plot2.png?v=34a505c5\n \n&nbsp;\n\n**Setup**: This is a reconstruction of a prediction of Lorenz63, 25k samples, seed=7, input sequence length=336 and prediction horizon=96. The MSE is about 1.1 (twice as large as the reported average MSE in the table, due to model changes). **YET**, with FERN’s design, we can describe exactly **where Fern succeeds and fails, despite the low MSE loss**:\n\n&nbsp;\n\n**Analysis**: In plot 1, the **left panel** shows *local speed* (magnitude of first differences). **On the right**, it describes the *normalized trace* (sum of eigenvalues Σλᵢ of transformation matrix A), representing total uncertainty. Higher values (darker colors) indicate the \nmodel is 'guarding heavily' by widening its ellipsoids. \n\n&nbsp;\n\nClearly, *on this trajectory*, the system has highest speed on the outer lobes of left and right wings; On the inner, especially lower half of each lobe, the speed is *very slow*, leaving the gradient map almost white. \n\n&nbsp;\n\n**Where Fern succeeds**: the general structure is accurate. On the *slow part*, the eigenvalues are also very low, leaving the gradient map almost white. Clearly, *the slow part and general structure is well captured*. \n\n&nbsp;\n\n**Where Fern fails**: the gradient map is *considerably darker on the right lobe*. The model is *over-expanding uncertainty on the right lobe*, inflating uncertainty on the right lobe. On the left wing, it is far more confident.\n\n&nbsp;\n\nIn plot 3, we flatten the first state variable (x in Lorenz–63) and examine errors together with eigenvalue activity. **NOTE:** we display **max eigenvalues (spectral radius)**, not sum of eigenvalues. The log determinant (volume changes) are also available, but it and trace are not as indicative. \n\n&nbsp;\n\nWe move onto plot 4, the same side by side comparison now displays **max eigenvalues**. The gradient map is *significantly closer*, the right wing sensitivity disappears. The insight: problem is not with max eigenvalues, but smaller eigenvalues activity on the right wing.\n\n&nbsp;\n\nWe observe that:\n- The largest eigenvalue (spectral radius) activations cluster around **violent “top–bottom–top” swings** of the trajectory.\n- The worst prediction errors also align with these extreme flips (with some timing offset).\n\n**Conclusion**: Taken together, these plots show that **even at low MSE ≈ 1/8 of the empirical standard deviation**, FERN’s ellipsoids provide *actionable interpretability*: they localize where the model is confident and where it is “overcautious” or unstable. Spectral radius alone tells what the model think is important. The eigenvalues are soft-clipped to 4.5, but users can tune for each dataset based on feedback like this."}}, "id": "3XAUH6cTm9", "forum": "uCx8RAY8ac", "replyto": "uCx8RAY8ac", "signatures": ["ICLR.cc/2026/Conference/Submission4624/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission4624/Authors"], "number": 7, "invitations": ["ICLR.cc/2026/Conference/Submission4624/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763702949401, "cdate": 1763702949401, "tmdate": 1763702949401, "mdate": 1763702949401, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}