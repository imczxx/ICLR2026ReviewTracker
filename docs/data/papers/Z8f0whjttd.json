{"id": "Z8f0whjttd", "number": 3276, "cdate": 1757392049117, "mdate": 1763748918802, "content": {"title": "Escaping the Homophily Trap: A Threshold-free Graph Outlier Detection Framework via Clustering-guided Edge Reweighting", "abstract": "Graph outlier detection is a critical task for identifying rare, deviant patterns in graph-structured data. \nHowever, prevalent methods based on graph convolution are fundamentally challenged by the ''Homophily Trap'': the aggregation of features from neighboring nodes inadvertently contaminates the representations of normal nodes near anomalies, blurring their distinctions. \nTo overcome this limitation, we propose a Clustering-guided Edge Reweighting framework for Graph Outlier Detection (CER-GOD), which jointly optimizes a self-discriminative masking spoiler with an adaptive clustering-based outlier detector. \nThe masking spoiler learns to selectively weaken the influence of heterogeneous neighbors, preserving the discriminative power of node embeddings. \nThis process is guided by the clustering detector, which generates pseudo-labels in an unsupervised manner, thereby eliminating the need for predefined anomaly thresholds. \nTo ensure robust optimization and prevent class collapse—a failure mode exacerbated by the homophily trap—we introduce a diversity loss that stabilizes the clustering process. \nOur end-to-end framework demonstrates superior performance on multiple benchmark datasets, establishing a new state-of-the-art by effectively dismantling the homophily trap.", "tldr": "", "keywords": ["Outlier Detection", "Graph Neural Networks", "Clustering"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/83485dec79d8a3166fc706fd0099f2f04d77d1e0.pdf", "supplementary_material": "/attachment/bd717a9ecd39318bb4eefaa08cc2c2e37c8282a8.zip"}, "replies": [{"content": {"summary": {"value": "The authors propose a Clustering-guided Edge Reweighting framework for Graph Outlier Detection (CER-GOD), which jointly optimizes a self-discriminative masking spoiler with an adaptive clustering-based outlier detector. Experiments show their improvement to some extent."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors propose a cluster-based edge reweighting framework for unsupervised graph outlier detection. \n2. Experiments show their improvement to some extent."}, "weaknesses": {"value": "1. Although the authors provide a time complexity, the N-squared complexity might be a hindrance for real deployment. It will be better if the authors can provide an experimental comparison. \n2. The included datasets are relatively small compared to the newest anomaly (outlier) detection datasets, such as those in [1]. The authors should include the real-world datasets in their comparison. \n3. The included baselines are not comprehensive, which questions the effectiveness of the framework. The authors should include SOTA works such as [2], [3], and [4].\n4. Figure 3 shows that the method can be very sensitive to the variation of hyperparameters. As stated in Appendix G, they adopt grid search for finding the hyperparameters. It can be a question of how to utilize grid search for unsupervised learning without any ground truth labels. Furthermore, it can be difficult for the method to choose proper hyperparameters to operate on new datasets. \n5. The authors should show the finetuned hyperparameters and how many times they conduct the experiments to search for the hyperparameters. \n\n[1] Jianheng Tang, Fengrui Hua, Ziqi Gao, Peilin Zhao, Jia Li. GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection. NeurIPS 2023. \n\n[2] Hezhe Qiao, Guansong Pang. Truncated Affinity Maximization: One-class Homophily Modeling for Graph Anomaly Detection. NeurIPS 2023. \n\n[3] Jingyan Chen, Guanghui Zhu, Chunfeng Yuan, Yihua Huang. Boosting Graph Anomaly Detection with Adaptive Message Passing. ICLR 2024. \n\n[4] Xiangyu Dong, Xingyi Zhang, Yanni Sun, Lei Chen, Mingxuan Yuan, Sibo Wang. SmoothGNN: Smoothing-aware GNN for Unsupervised Node Anomaly Detection. WWW 2025."}, "questions": {"value": "Please refer to the weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "m9Vb5gqzGp", "forum": "Z8f0whjttd", "replyto": "Z8f0whjttd", "signatures": ["ICLR.cc/2026/Conference/Submission3276/Reviewer_6mWp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3276/Reviewer_6mWp"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3276/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760805773630, "cdate": 1760805773630, "tmdate": 1762916642804, "mdate": 1762916642804, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces CER-GOD, a graph outlier detection framework designed to mitigate the \"Homophily Trap\" in graph convolutional networks (GCNs), where aggregating features from anomalous neighbors contaminates normal node representations. The method combines a self-discriminative masking spoiler that adaptively re-weights edges to reduce heterogeneous influences, guided by a learnable clustering layer that generates pseudo-labels without predefined thresholds. A diversity loss prevents class collapse during clustering. The overall objective balances reconstruction, clustering, distribution repulsion, and diversity terms. Experiments on six datasets show superior AUC performance over baselines. Contributions include: (1) analysis of the homophily issue with a masking mechanism, (2) threshold-free pseudo-labeling via clustering, and (3) a regularization to stabilize optimization."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper creatively combines edge re-weighting with unsupervised clustering for outlier detection, extending the \"Homophily Trap\" concept (He et al., 2024) into a joint optimization framework. The diversity loss is a novel tweak to address a specific failure mode in clustering under homophily constraints, potentially applicable beyond outliers."}, "weaknesses": {"value": "1. The paper's core innovation—adaptive edge masking guided by binary clustering—feels incremental rather than transformative, building too closely on existing ideas without sufficient novelty. For instance, the masking spoiler resembles attention mechanisms in GAT or adaptive topology learning, but lacks a rigorous comparison showing why global MMD guidance (Eq. (8)) outperforms local feature-based weighting. \n2. The \"self-discriminative\" claim is undersold: it primarily enforces intra-cluster aggregation via pseudo-labels, which is akin to DEC (Guo et al., 2017) but without justifying why two clusters suffice for diverse anomaly types (e.g., point vs. structural outliers). \n3. Proposition 1, while neat, is a straightforward extension of over-squashing bounds (Topping et al., 2022) and does not uniquely motivate the framework—empirical validation in Fig. 1 is limited to one dataset (Email) and single-layer GCN, ignoring multi-layer or heterophilic graphs."}, "questions": {"value": "1.\tCan the authors clearly explain how the proposed masking differs mathematically from the attention coefficients in GAT or the relation-strength function in ADA-GAD?\n2.\tHow sensitive is the model to the initial K-Means clustering used for pseudo-label initialization?\n3.\tDoes the method scale to larger graphs (e.g., >100k nodes)? Have the authors considered mini-batch or approximate MMD computation?\n4.\tCan the authors provide quantitative evidence (e.g., correlation coefficients) showing that the learned edge weights actually correlate with homophily or anomaly boundaries?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "GSaApiH7TO", "forum": "Z8f0whjttd", "replyto": "Z8f0whjttd", "signatures": ["ICLR.cc/2026/Conference/Submission3276/Reviewer_Q1xe"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3276/Reviewer_Q1xe"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3276/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761471180607, "cdate": 1761471180607, "tmdate": 1762916642617, "mdate": 1762916642617, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a learnable clustering-guided edge reweighting framework that jointly optimizes a self-discriminative masking module and an adaptive clustering-based outlier detector. The clustering process generates pseudo labels in an unsupervised manner, which are then utilized to guide the training process."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "(1) The method is straightforward to understand, but the paper’s writing quality needs improvement.  am particularly confused about the role of the pseudo labels. \n\n(2) The proposed method achieves the best performance across six small-scale graph anomaly detection  datasets."}, "weaknesses": {"value": "(1) The authors should provide a clear technical definition or explanation for the newly introduced concepts “multi-hop away from anomalies” and “1-hop away from anomalies.” For instance, a 1-hop-away node should refer to a normal node that is directly connected to at least one anomalous node.\nAdditionally, the description of “data distribution” in the framework is misleading — it should be clarified as the anomaly score distribution or MMD score distribution if you use the histogram. Moreover, the current explanation of the framework implies that only two clusters are considered in the diversity loss. The role of the pseudo-labeling process is also not clearly reflected in the framework diagram, and the legend is missing. The type of latent embedding *z* is not consistent with the main paper. The authors should revise the figure and explanation to make these components explicit.\n\n(2)Most of the benchmark datasets used are relatively small, making the experimental results less reliable—especially on Enron, which contains only five anomalies. I suggest that the authors include larger-scale datasets, covering both more injected or real-world data with real anomalies, to better demonstrate the robustness and effectiveness of the proposed method.\n\n(3) The approach appears to focus primarily on the reconstruction process and the learning of discriminating representations.  The unsupervised clustering module is learnable, and the inference relies on the distance to the centroids. In this case, it is unclear why a reconstruction component is still necessary. Why not directly apply clustering to the graph representations learned by the GCN encoder? Moreover, the ablation study is not sufficiently comprehensive—additional variants, like directly applying the learnable clustering, should be included for a more thorough evaluation\n\n(4)Determining the appropriate number of clusters for each dataset is challenging. How do the authors decide on the cluster count in practice? Additionally, the reconstruction process is computationally complex, and the inclusion of clustering further increases the overall computational cost. Besides, the performance with varying the number of clusters should be provided.\n\n(5) As you mention in lines 244-247, ”Then we first designate the cluster containing a relatively larger number of samples as the normal cluster, and temporarily treat all nodes within it as normal candidates. Conversely, the remaining clusters are considered the anomalous candidate cluster“.  How many large clusters are treated as normal nodes? In real GAD datasets, the data distribution often consists of multiple normal clusters with relatively large sample sizes, along with multiple anomalous clusters and some isolated outlier points."}, "questions": {"value": "See above **Weaknesses**"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "VlB2X1c5oB", "forum": "Z8f0whjttd", "replyto": "Z8f0whjttd", "signatures": ["ICLR.cc/2026/Conference/Submission3276/Reviewer_ErB5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3276/Reviewer_ErB5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3276/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761826657237, "cdate": 1761826657237, "tmdate": 1762916642305, "mdate": 1762916642305, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes CER-GOD, a novel graph outlier detection framework to address the '' Homophily Trap'', which is a critical issue where graph convolutional operations blur the feature representations of normal and anomalous nodes that are neighbours. The proposed method synergistically integrates two main components: a self-discriminative masking spoiler that learns to reweight graph edges to suppress contaminating information flow from heterogeneous neighbours, and a clustering-based outlier detector that generates unsupervised pseudo-labels to guide this reweighting process. To ensure stable training and prevent clustering collapse, a diversity loss is introduced as a regularization term. Extensive experiments on multiple benchmark datasets demonstrate that CER-GOD significantly outperforms a wide range of state-of-the-art baselines."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 4}, "strengths": {"value": "1. The paper addresses a critical and well-articulated problem in GNN-based anomaly detection: the \"Homophily Trap\". The authors provided clear motivation, supported by insightful empirical analysis (Figure 1), highlighting how neighbourhood aggregation can contaminate node representations and fundamentally hinder outlier identification.\n2. The proposed CER-GOD framework is methodologically sound and the idea is novel. The main innovation lies in the synergistic joint optimization of a self-discriminative masking spoiler and a clustering-based detector. This design creates a powerful feedback loop where pseudo-labels from clustering guide the edge reweighting, and the refined graph structure, in turn, yields more discriminative embeddings for improved clustering.\n3. The comparison against a comprehensive set of baselines fully validates the effectiveness of CER-GOD. Additionally, the authors provided convincing qualitative evidence, such as t-SNE and mask visualizations, to further enhance the  persuasiveness and interpretability of the approach.\n4. The authors provided the implementation code of the proposed method, which increases the reproducibility."}, "weaknesses": {"value": "1. The choice of the Chebyshev distance for the MMD kernel calculation should be elaborated. While the intuition is provided, the paper would be strengthened by an empirical comparison against a more conventional Euclidean-based RBF kernel to justify this specific design.\n\n2. The diversity loss $l_{diversity}$ introduces a crucial hyperparameter $\\epsilon$ to control the minimum proportion of samples per cluster. However, there is no discussion regarding the setting of $\\epsilon$ or any corresponding parameter sensitivity analysis.\n\n3. A comparison with existing graph rewriting baselines is missing, which would help validate the method's effectiveness."}, "questions": {"value": "1. Please also include a parameter sensitivity analysis examining how the distribution repulsion loss performs when applied to different graph convolutional layers.\n2. The paper distinguishes the edge reweighting mechanism from graph rewriting methods. Could the authors further elaborate on the fundamental advantages of such learnable masks over heuristic-based hard edge removal or addition? A deeper discussion would be valuable.\n3. The framework relies on a feedback loop where pseudo-labels guide the mask optimization. In the early training phase, these pseudo-labels might be noisy, which potentially leads the model to a suboptimal solution. How does the model ensure stability during the training phase? Is there a warm-up phase, or does the joint optimization naturally navigate towards a good solution?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "bJNrp968W0", "forum": "Z8f0whjttd", "replyto": "Z8f0whjttd", "signatures": ["ICLR.cc/2026/Conference/Submission3276/Reviewer_A5bT"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3276/Reviewer_A5bT"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3276/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761954136238, "cdate": 1761954136238, "tmdate": 1762916642026, "mdate": 1762916642026, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}