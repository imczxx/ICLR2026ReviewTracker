{"id": "nN8VhnggF8", "number": 17850, "cdate": 1758281197155, "mdate": 1759897150203, "content": {"title": "HiResNets: Native Full-HD Video Recognition with Foveal Residual Streams", "abstract": "Much of the recent progress in image and video recognition has come at the cost of memory: larger models, increased resolution, and longer temporal contexts.An inevitable component is the quadratic (or larger) growth of memory and compute based on image resolution, which is a property of the grid sampling used in convolutional networks and vision transformers. In this work we study residual networks whose convolutional blocks have logarithmic-square growth instead, enabling them to process very high-resolution video quickly and with low memory. The key insight is to use a residual architectures' residual stream as a high-resolution buffer, to which convolutional blocks only read and write via log-polar image warp operations. Layers adaptively focus on different parts of each frame, with very high resolution only near the focus point. A complete high-resolution representation is built up in the residual stream, which is analogous to eye saccades creating a complete picture in biological vision. Experiments demonstrate that our proposed HiResNets learn to foveate around scenes similarly to human vision, and have superior performance in difficult egocentric video recognition tasks, especially egocentric video with small objects and fine-grained recognition.", "tldr": "", "keywords": ["computer vision", "foveal networks"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/7351405fa527a4cc6d99e5e4dca9197d89031e56.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The manuscript proposes HiResNet to optimize the usage of memory in image and video recognition that integrates log-polar warps into the residual stream in order to enable efficient foveated processing. It uses residual architectures as high-resolution buffers, to which convolutional blocks only read and write via log-polar image warp operations.\nA complete high-resolution representation is built up in the residual stream.\nA differentiable log-polar warp mechanism enabling adaptive foveated processing is built inside the backbone itself. This allows emphasizing local detail while compressing distant regions."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "* Optimization of deep learning models in order to process images and video more efficient while also displaying the information appropriately."}, "weaknesses": {"value": "* The manuscript lacks a theoretical framework.\n* The HiResNet architecture is superficially described and lacks a diagram.\n* There are not enough experimental results.\n* There are no visual results on images."}, "questions": {"value": "Can the approach be extended to other networks than those adopted? For example can be used for transformers or video transformers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "NJcSB1Z2kB", "forum": "nN8VhnggF8", "replyto": "nN8VhnggF8", "signatures": ["ICLR.cc/2026/Conference/Submission17850/Reviewer_24A8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17850/Reviewer_24A8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761792563666, "cdate": 1761792563666, "tmdate": 1762927683141, "mdate": 1762927683141, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces **HiResNets**, a residual network architecture that integrates **log-polar foveated warping** directly into the backbone for efficient **Full-HD video recognition**.  \nThe key idea is to treat the residual stream as a persistent high-resolution buffer, while convolutional blocks operate on a warped log-polar space.  \nThis yields **log-squared (≈ O(log² HW))** computational scaling instead of the usual quadratic growth.  \nHiResNets predict adaptive focus centres (“saccades”) per block and integrate warped features back into the residual stream.  \nExperiments on **Ego4D**, **EGTEA**, **EgoObjects**, and **PACO** show improved efficiency and competitive performance for egocentric video recognition."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "- **Novel idea:** Embeds foveated processing *within* the residual path, rather than as an external module.  \n- **Theoretical clarity:** Provides a concrete complexity reduction from O(HW) to O(log H log W).  \n- **Biological motivation:** Well-aligned with foveation and saccade mechanisms in human vision.  \n- **Efficiency:** Demonstrates reduced latency and better scaling with input resolution."}, "weaknesses": {"value": "1. **Limited comparisons** – Experiments mainly against YOLOv5 and SqueezeTime; no comparison with modern high-resolution backbones (e.g., Swin, MViTv2, FoveaTer).  \n2. **Modest empirical gains** – Accuracy improvements are small (≈ +1–3 %) relative to baseline.  \n3. **Implementation cost** – Warp/unwarp overhead not fully analyzed; runtime breakdown missing.  \n4. **Shallow ablation** – Only evaluates fovea frequency and polar radius; missing tests for fixed centres, inverse warp, or focus visualization.  \n5. **Reproducibility** – Training details for Full-HD experiments and memory optimization are insufficient."}, "questions": {"value": "- How stable is the training when saccade positions change dynamically?  \n- Do the predicted focus points align with human gaze or motion saliency?  \n- Could this architecture extend to transformers or hybrid CNN–ViT designs?  \n- How efficient are the warp/unwarp operations on GPU compared to standard convolutions?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "X5K7OuIurk", "forum": "nN8VhnggF8", "replyto": "nN8VhnggF8", "signatures": ["ICLR.cc/2026/Conference/Submission17850/Reviewer_5M8C"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17850/Reviewer_5M8C"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761855306746, "cdate": 1761855306746, "tmdate": 1762927682660, "mdate": 1762927682660, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes logarithmic-square growth in resolution scaling, instead of quadratic scaling. This enables processing native videos efficiently, which was prohibitive for standard CNNs. A novel architecture with biologically foveating inside the backbone is proposed. The algorithm seems to learn meaningful foveating strategies and shows performance on challenging tasks, such as gaze estimation, object detection, and fine-grained recognition. The algorithm may be good at handling very small objects and is adaptive to multiple scales."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- Proposes a new scaling to deal with full-resolution videos, which is innovative, making the algorithm useful and effective \n- Shows a sophisticated design for foveating inside a backbone that is inspired by biological vision, and is validated on benchmark datasets \n- Shows results on Ego4D and EgoObjects and PACO datasets"}, "weaknesses": {"value": "- It seems a bit unclear whether the algorithm has been tested on datasets with a large enough scale. Perhaps experiments on well-known large-scale detection benchmarks COCO, ImageNet will present a boost to its impact\n- More comprehensive ablation and analysis will be necessary for the proposed claims to be convincing, e.g. in which situations is the foveating effective, are there validation experiments for resolution scaling, and its effectiveness in hardware \n- The paper could be better presented and written, e.g., with improved writing, more compact tables/figures"}, "questions": {"value": "- I wonder if the method could be tested on imagenet or COCO, even a smaller subset to compare with sota results \n- Could more ablation studies be added to the paper and verify claims?\n- better writing and table/experiment result presentation will make the paper stronger"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "qG1X0feSu6", "forum": "nN8VhnggF8", "replyto": "nN8VhnggF8", "signatures": ["ICLR.cc/2026/Conference/Submission17850/Reviewer_4ukr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17850/Reviewer_4ukr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761974838805, "cdate": 1761974838805, "tmdate": 1762927682175, "mdate": 1762927682175, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes HiResNets, using a Foveal Residual Stream and a new convolution to enable efficient Full-HD video recognition. The method is inspired by human vision, focusing high-resolution computation on important regions while keeping low-resolution global context. Experiments show good accuracy and efficiency."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The paper tackles the high cost of scaling vision models to Full-HD, proposing a method that reduces complexity.\n* The “Foveal Residual Stream” is an nice idea to put more attention on  high-res focus where it matters while keeping global low-res context.\n* The results show good performance"}, "weaknesses": {"value": "*  It’s hard to tell whether the efficiency comes from, which makes the technical novelty less convincing.\n* The proposed method lacks strong theoretical support and feels like a task-specific trick rather than a general tool."}, "questions": {"value": "* Could the authors do more fine-grained ablation study and how the effectiveness of the propose approach?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "TnAsBAJF6n", "forum": "nN8VhnggF8", "replyto": "nN8VhnggF8", "signatures": ["ICLR.cc/2026/Conference/Submission17850/Reviewer_JTLt"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17850/Reviewer_JTLt"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17850/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761999118349, "cdate": 1761999118349, "tmdate": 1762927681730, "mdate": 1762927681730, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}