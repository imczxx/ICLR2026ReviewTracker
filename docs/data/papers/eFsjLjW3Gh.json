{"id": "eFsjLjW3Gh", "number": 18685, "cdate": 1758290098237, "mdate": 1759897087749, "content": {"title": "A Geometric Analysis of Logit Embeddings for Out-of-Distribution Detection", "abstract": "Out-of-distribution (OOD) data pose a significant challenge to deep learning (DL) classifiers, prompting extensive research into their effective detection methods.\nCurrent state-of-the-art OOD detection methods usually employ a scoring technique designed to assign lower scores to OOD samples compared to in-distribution (ID) ones. \nNevertheless, these approaches lack foresight into the configuration of OOD and ID data within the latent space. \nInstead, they make an implicit assumption about their inherent separation or force a separation post-training by utilizing selected OOD data.\nAs a result, most OOD detection methods result in complicated and hard-to-validate scoring techniques.\nThis study conducts a thorough analysis of the logit embedding landscape, revealing that the ID and OOD data exhibit a distinct spatial configuration.\nSpecifically, we empirically observe that the OOD data are drawn to the center of the logit space.\nIn contrast, ID data are repelled from the center, dispersing outward into distinct, class-wise clusters aligned along the orthogonal axes that span the logit space.\nThis study highlights the critical role of the DL vision-based classifier in differentiating between ID and OOD logits.", "tldr": "We show that, in DL classifiers, OoD inputs concentrate near the logit-space origin while InD inputs form orthogonal, class-wise clusters—yielding a simple, geometry-driven criterion for reliable OOD detection.", "keywords": ["Out-of-distribution Detection; Logit Geometry; Representation Learning"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/6670529fda3a610f80051a7f265d56cbab973f4b.pdf", "supplementary_material": "/attachment/1d0cf1f2bb7af853cd881213d6de81fae4d0788b.zip"}, "replies": [{"content": {"summary": {"value": "This work proposes an analysis into the logit embeddings between in-distribution (ID) data and out-of-distribution (OOD) data. The key insight is that OOD data is drawn to the center of the logit space, and ID data are repelled from the center, dispersing outward into distinct and class-wise clusters. A lot of KDE plots are provided in this paper, and experiments cover a wide range of aspects."}, "soundness": {"value": 1}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1.\tThe proposed insight about the spatial distribution between ID and OOD data in the logit space is somehow beneficial.\n\n2.\tThere are extensive intuitive KDE plots."}, "weaknesses": {"value": "1.\tInsufficient workload. The contribution of this work is merely the aforementioned spatial separability between ID and OOD data in the logit space. The workload is clearly insufficient. How can the separability help OOD detection by inspiring new effective detection scores? The authors are suggested to enrich this paper by proposing a relevant detection method with associate detection results instead of just showcasing a phenomenon.\n\n2.\tAll the references are not in a correct form where the outermost parentheses are missing. Have the authors read the paper themselves? Do the authors feel uncomfortable when seeing so many in-text references without parentheses?\n\n3.\tFrom line 168 to line 174, the ID logits distribution after training is explained, which is an important conclusion in this work. However, there are too few contents and the key Proposition 2 is even left to the appendix. In contrast, there are so many contents from Line 138 to Line 167 talking about something widely-acknowledged. This part should be deeply revised.\n\n4.\tAll the results are presented in KDE plots, which is not convincing. At least some numerical results should be presented to support the claim.\n\n5.\tThe claimed spatial distribution of ID and OOD data in the logit space is also not strongly demonstrated in the submission. For example, the authors claim that ID data logits distribute across the orthogonal axes that span the logit space. To validate this, some PCA-based analysis should be provided, such as the reconstruction errors on ID and OOD data in the logit space. However, throughout the paper, there are only KDE plots on logit values and no any geometric empirical investigations. Such empirical results are insufficient and cannot provide a sound support on the claim."}, "questions": {"value": "My questions correspond to the weaknesses above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "ZZU3orl8Ix", "forum": "eFsjLjW3Gh", "replyto": "eFsjLjW3Gh", "signatures": ["ICLR.cc/2026/Conference/Submission18685/Reviewer_kGiW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18685/Reviewer_kGiW"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission18685/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760945723947, "cdate": 1760945723947, "tmdate": 1762928386001, "mdate": 1762928386001, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a comprehensive empirical study of In-Distribution (ID) and Out-of-Distribution (OOD) logit behavior in deep learning classifiers. The authors demonstrate that ID and OOD data exhibit distinct geometric patterns in the logit space: ID logits form clusters in positive regions aligned along class-specific orthogonal axes, whereas OOD logits remain centered near zero. The study shows that this logit configuration persists consistently across different architectures and datasets. Furthermore, the authors suggest leveraging ID-out logits as proxies for OOD detection, although the paper does not provide any methodology for practical deployment."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tThe study covers a wide range of architectures and configurations, demonstrating the strong generalizability of the findings.\n2.\tThe study integrates theoretical insights with experimental results, providing mutually consistent support for its conclusions.\n3.\tThe geometric interpretation of the logit-space configuration could potentially serve as a foundation for developing simple OOD detectors."}, "weaknesses": {"value": "1.\tAlthough the empirical study is extensive, it primarily reinforces existing intuitions rather than offering a novel methodological or substantive theoretical contribution.\n2.\tThe paper does not demonstrate that the reported findings can be effectively leveraged for designing an OOD detector.\n3.\tThe text references numerous figures but detailed qualitative descriptions are limited"}, "questions": {"value": "1.\tThe before/after training analysis focuses exclusively on correctly classified ID samples, overlooking misclassified ID instances. However, in practice, the boundary between ID and OOD data often becomes ambiguous precisely because of such misclassified ID examples, which may exhibit logit distributions similar to OOD samples. Addressing this limitation would strengthen the empirical validity of the conclusions and provide a more realistic understanding of logit-space separability in practical OOD detection scenarios.\n\n2.\tThe study covers a wide range of architectures and configurations, but it remains unclear which design choices most influence logit-space separability between ID and OOD samples. Providing guidelines or empirical insights on which architectures or hyperparameters favor clearer separation would significantly improve the paper’s practical utility.\n\n\n3.\tThe paper proposes using ID-out logits as proxies for OOD, but it does not provide experimental validation. Presenting preliminary results for a binary classifier and clarifying the design of such a detector would strengthen the contribution.\n\n\n4.\tAlthough the paper includes a related work section, it does not clearly situate its new findings within the context of prior research. For example, are there existing OOD detectors that already exploit the observations made in this study? Which insights are genuinely novel compared to previous knowledge? Do any of the results contradict prior publications? Furthermore, the Neural Collapse (NeCo) phenomenon, extensively analyzed in several recent works, also describes the emergence of class-wise orthogonal clusters, though in the feature space rather than in the logit space. It would be valuable to discuss whether the observed logit-space configuration could be a manifestation or an extension of Neural Collapse. Such a connection could provide a theoretical grounding for the empirical patterns reported in this study.\n\n\n\nThis paper provides a thorough empirical analysis of ID and OOD logit behavior across a wide range of architectures and datasets. The experiments are well-executed, and the geometric patterns observed in logit space are consistent and generalizable, offering valuable insights for future OOD research. However, the study is primarily descriptive: it does not introduce a new method, lacks concrete guidance for OOD detector design, and does not fully situate its findings within existing theoretical frameworks such as Neural Collapse. Despite these limitations, the paper’s clarity, empirical rigor, and breadth of analysis make it a meaningful contribution that could inform and inspire follow-up work."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "744xaDx9Y9", "forum": "eFsjLjW3Gh", "replyto": "eFsjLjW3Gh", "signatures": ["ICLR.cc/2026/Conference/Submission18685/Reviewer_JWp1"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18685/Reviewer_JWp1"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission18685/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761149501965, "cdate": 1761149501965, "tmdate": 1762928385433, "mdate": 1762928385433, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies the phenomenon that the magnitude of the logits for OOD samples are typically smaller than that of the ID samples. The mechanism behind this phenomenon is explained by analysing the loss. In the experiments, several networks are analyized by showing the difference in logit distributions of OOD/ID samples."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "* In the experiments, many networks, including CNNs and vision transformers, are analyzed.\n* The writing is easy to follow."}, "weaknesses": {"value": "This phenomenon is not new, and it has been the reason for the design of the very first few OOD algorithms, such as MSP and max logit. Some later works [a] already explicitly designed a regularizaion to encourage the logit-smallness of OOD samples. The ID clustering structure is also used in [b] to desgin better OOD scores. Besides, the paper does not provide new OOD scores based on the gained insights. The experiments also lack quantitative results.\n\n\n- [a] Training confidence-calibrated classifiers for detecting outof-distribution samples. ICLR 2018\n- [b] MOS: Towards scaling out-ofdistribution detection for large semantic space. CVPR 2021"}, "questions": {"value": "/"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "YhflZkQWrI", "forum": "eFsjLjW3Gh", "replyto": "eFsjLjW3Gh", "signatures": ["ICLR.cc/2026/Conference/Submission18685/Reviewer_tTxB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18685/Reviewer_tTxB"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission18685/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761905519847, "cdate": 1761905519847, "tmdate": 1762928384766, "mdate": 1762928384766, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies learning from out-of-distribution data, and proposes a new perspective of geometric analysis. It is inspired by the limitation of existing OOD detection methods, which usually employs a scoring technique and may neglect the insight within the latent space. In this paper, the authors analyze the logit embedding distributions of ID and OOD data and reveal that the OOD data tends to cluster near the origin."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "- The studied problem is meaningful. \n- The authors conduct extensive experiements to reveal the phenomenum."}, "weaknesses": {"value": "- The contribution of this paper is limited. The main paper consists of many experimental results. However, there are no in-depth analysis regarding why the logit distributions of ID and OOD data exhibits such different phenomenum.\n- After revealing the empirical discovery, there are no relevant algorithms proposed to further improve the OOD detection performance. This will also limit the contribution of this paper.\n- There are no theoretical analysis provided.\n- The experiments are only conducted on some general datasets (e.g., SVHN, CIFAR, ImageNet), which will limit the universality of the proposed method."}, "questions": {"value": "- Is there any existing methods analyzing the OOD detection problem from the latent space?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VX3Jz33H8e", "forum": "eFsjLjW3Gh", "replyto": "eFsjLjW3Gh", "signatures": ["ICLR.cc/2026/Conference/Submission18685/Reviewer_a6xB"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission18685/Reviewer_a6xB"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission18685/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762258285789, "cdate": 1762258285789, "tmdate": 1762928383617, "mdate": 1762928383617, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}