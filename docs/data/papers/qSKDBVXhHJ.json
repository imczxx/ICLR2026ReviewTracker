{"id": "qSKDBVXhHJ", "number": 19378, "cdate": 1758295804475, "mdate": 1759897042503, "content": {"title": "EffComp: Efficient Prompt Compression via Hybrid Reinforcement & Supervised Learning", "abstract": "Prompt compression is aimed at reducing input prompt lengths to enable cheaper and faster LLM predictions. However, existing prompt compression methods are often limited by modest compression gains, a risk of hallucination, and/or high compression latency. This paper proposes EffComp, an $\\textbf{Eff}$icient prompt $\\textbf{Comp}$ression framework using a hybrid reinforcement and supervised learning approach for RAG-based open-domain question answering (QA). EffComp employs BERT-style document reranker and sentence selector models to allow fast extractive prompt compression at the sentence level. Its extractive nature prevents hallucinations in the compressed prompts. Additionally, the training process is designed to optimize the compression ratio while preserving LLM accuracy. Experiments on four open-domain QA datasets demonstrate that EffComp outperforms state-of-the-art prompt compression methods in terms of prediction accuracy and achieves competitive compression ratios (up to 78.4x) with minimal latency, making it practical for real-world applications.", "tldr": "", "keywords": ["Prompt Compression", "Retrieval Augmented Generation", "Efficient Method"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/818b5d3abfa3ba1220e579c4beae2b347b4b3233.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces EFFCOMP, a hybrid model designed to solve the trade-off in RAG systems by providing high extractive compression while maintaining LLM accuracy and minimizing latency. The main contribution is a novel hybrid of reinforcement and supervised learning for training the sentence selector, optimizing the trade-off between compression ratio and LLM accuracy. EFFCOMP achieves higher QA accuracy through extensive extractive compression and notable reduction in total latency, showing its practical effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "EFFCOMP effectively overcomes the main weakness of previous extractive methods, which only achieved modest compression ratios. It provides significant extractive compression, reaching ratios up to 78.4x while preserving factual accuracy and human readability."}, "weaknesses": {"value": "1. Lack of Quantitative Evidence for Addressing the Core Challenge\n\n>The paper's main goal is to address the inherent trade-off between abstractive compressors (high compression, high hallucination risk) and extractive compressors (low compression, low hallucination risk). The proposed EFFCOMP hybrid method aims to achieve this by offering the advantages of both (high compression and low hallucination). However, the experimental results only report end-to-end QA metrics (Acc/F1) and the compression ratio, failing to quantify the claimed advantage over the competing approaches.\n\n>The paper asserts that EFFCOMP prevents hallucination due to its extractive nature, but this is never quantitatively proven against abstractive methods (like Recomp-Abstractive or CompAct). A rigorous comparison requires quantitatively evaluating their ability to retain factual integrity better than abstractive approaches. The qualitative example in Table 2 is insufficient proof.\n\n>In addition, the paper claims EFFCOMP preserves more important information than other extractive methods, implying high efficiency in selection. This should be demonstrated by showing that the compressed contexts are semantically richer or less redundant than those produced by extractive methods.\n\n>In short, the experiments show that EFFCOMP performs well overall, but they lack the necessary diagnostic analysis to quantitatively validate how it successfully addresses the fundamental trade-off between abstractive hallucination risk and extractive compression limitations, which was the paper's main focus.\n\n2. Lack of Justification for Hybrid RL/SL Architecture\n\n>The paper's core technical contribution is the hybrid Reinforcement Learning (RL) and Supervised Learning (SL) approach used for fine-tuning the sentence selector. While the authors describe the functional purpose of combining the two (RL for optimizing the objective, SL for efficiency via memory), they fail to provide a rigorous justification for why this specific hybrid method is optimal for the task.\n\n>The authors state that the RL loss is needed because initial pseudo-labels are imperfect, and the SL loss (with best-trajectory memory) is needed for efficiency. However, the paper lacks a clear, upfront theoretical or empirical argument explaining why a complex alternating hybrid structure is necessary over simpler, established alternatives. \n\n>Although the paper includes an ablation study (Figure 4, Appendix D.4) comparing RL-only, SL-only, and Hybrid, the comparison is limited to showing which one performs best overall. It does not provide the diagnostic clarity needed to confirm that the benefits outweigh the overhead. Specifically, it doesn't clearly explain why the hybrid method handles zero-reward signals or exploration better than a modified pure-RL structure designed for contextual bandits.\n\n>In essence, the paper proposes a complex solution without fully demonstrating why the problem demands this specific complex solution over more parsimonious alternatives."}, "questions": {"value": "Questions on Latency Metrics and Measurement\n> Table 4 provides a detailed breakdown of efficiency, but the units and measurement process need clear explanation to ensure reproducibility. What are the units for the Compression, LLM Read, and Total Latency metrics reported in Table 4? The text suggests they are in seconds, but this should be explicitly stated in the table caption or text. Could the authors provide a concise explanation of how latency was measured?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VZBBKlQlfy", "forum": "qSKDBVXhHJ", "replyto": "qSKDBVXhHJ", "signatures": ["ICLR.cc/2026/Conference/Submission19378/Reviewer_c8K7"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19378/Reviewer_c8K7"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission19378/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761553850269, "cdate": 1761553850269, "tmdate": 1762931305619, "mdate": 1762931305619, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a new sentence-level prompt compression framework for open-domain question answering, which is good for the high compression ratio and low compression latency. To achieve this goal, this paper designs a complex training framework, including supervised learning and end-to-end RL. Then the experiments over four open-domain QA datasets showed the advantages of high compression ratio and accuracy compared with many competitive baselines. This paper also provides many ablation study including the compression latency and fail explanations."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "This manuscript has many strengths, including:\n\n1. Reasonable method design, including sentence-level, end-to-end RL training\n2. This paper conducts comprehensive experiments to show their advantages and provides detailed ablation studies to further investigate.\n3. This paper has a good presentation and makes enough contribution to the area of prompt compression."}, "weaknesses": {"value": "1. It's recommended to provide the code to reproduce the results.\n2. The main results use F1 metric and EM accuracy. Why doesn't it use the LLM Judge to evaluate the answers?\n3. There are some important train-free attention-based methods [1,2] requiring to compare or discussion. \n\n[1] Leveraging Attention to Effectively Compress Prompts for Long-Context LLMs\n[2] Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference"}, "questions": {"value": "1. In my opinion, the compression ratio of the proposed method is determined adaptively. The compression ratio of selected baselines should be determined by the user. How do you select the compression ratio and what are the reasons?\n\n2. Compression times are dependent on the input prompt. It's better to provide the length of used prompt in Table 4?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "QkZM9zBEHu", "forum": "qSKDBVXhHJ", "replyto": "qSKDBVXhHJ", "signatures": ["ICLR.cc/2026/Conference/Submission19378/Reviewer_3s4F"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19378/Reviewer_3s4F"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission19378/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761634666319, "cdate": 1761634666319, "tmdate": 1762931304981, "mdate": 1762931304981, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces EffComp, a two-step, extractive prompt compression framework designed for RAG-based QA."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- The framework achieves high compression ratios and outperforms baselines in QA accuracy and F1 score across four datasets.\n\n- The paper includes generalization tests to an out-of-distribution LLM (Llama-3.1-8B) and a failure analysis."}, "weaknesses": {"value": "- The baselines are all from 2024, and the paper lacks a comparison with newer methods from 2025 (such as CoLoR[1] and DAC[2]).\n\n- While other prompt compression papers often demonstrate their method's effectiveness on summarization in addition to QA, this paper's evaluation is confined solely to QA.\n\n- The authors state that 42% of the failure points are attributed to the evaluation metric and suggests that semantic-based evaluation metrics like BERTScore might be a better option. Therefore, the paper should have included evaluations using these metrics.\n\n- Similarly, such an unreliable metric is used as the core signal for the GRPO reward function. This may lead to unstable training and spurious policy updates that do not reflect true semantic quality.\n\n[1] Minju Seo, et al., Efficient Long Context Language Model Retrieval with Compression, ACL 2025.\n\n[2] Yi Zhao, et al., DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression, ACL 2025."}, "questions": {"value": "- The Phase I pretraining biases the policy against intermediate reasoning sentences by exclusively labeling sentences containing the final answer string. This creates a low probability for retaining crucial intermediate-reasoning sentences in multi-hop QA (like HotpotQA). It is questionable whether the GRPO sampling in Phase II can effectively explore and reinforce the retention of these sentences, or if it will struggle to overcome the flawed bias established during pretraining.\n\n- The ablation study on RL and SL in the appendix should be placed in the main text, or at least be mentioned."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ACagovxtVB", "forum": "qSKDBVXhHJ", "replyto": "qSKDBVXhHJ", "signatures": ["ICLR.cc/2026/Conference/Submission19378/Reviewer_isCC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19378/Reviewer_isCC"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission19378/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761658892835, "cdate": 1761658892835, "tmdate": 1762931304533, "mdate": 1762931304533, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces EFFCOMP, an efficient prompt compression framework for RAG-based open-domain question answering. The method employs a two-stage approach: (1) document-level reranking using BERT-style rerankers to filter and reorder retrieved documents, and (2) sentence-level selection using a BERT-based sentence selector trained through a hybrid reinforcement and supervised learning approach. The sentence selector is first pretrained using pseudo-labels based on answer string matching, then finetuned using GRPO with a reward function that balances QA accuracy and compression ratio. During finetuning, a best trajectory memory stores high-reward action sequences for supervised learning updates. Experiments on four QA datasets (Natural Questions, TriviaQA, HotpotQA, 2WikiMultiHopQA) with Gemma-2-9B-IT demonstrate compression ratios of 29.1x-78.4x while maintaining or improving accuracy compared to uncompressed baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The combination of reinforcement learning with supervised learning using a best trajectory memory is sensible and addresses the instability issues common in pure RL approaches. The alternating RL-SL updates within each epoch provide a reasonable balance between exploration and exploitation.\n\n2. Unlike many abstractive compression methods that require expensive LLM calls iteratively, EFFCOMP uses lightweight BERT-based models for both reranking and sentence selection, resulting in competitive latency.\n\n3. By operating at the sentence level and preserving original text, EFFCOMP avoids the fabrication issues demonstrated in Table 2, where Recomp-Abstractive and CompAct generate factually incorrect compressed contexts."}, "weaknesses": {"value": "* The paper compares primarily against LongLLMLingua, Recomp, and CompAct, but misses critical recent prompt compression methods that have shown superior performance:\n    - LLMLingua-2 : A BERT-based token-level classifier trained via data distillation, achieving 3x-6x faster compression than LLMLingua with better task-agnostic performance. This is directly comparable to EFFCOMP's approach and should be included.\n    - TACO-RL: Another RL-based prompt compression method using REINFORCE for task-aware optimization, which is methodologically similar and should be compared.\n    - 500xCompressor: A soft prompt method achieving 6x-480x compression ratios.\n\n* FlashAttention compatibility: EFFCOMP requires attention scores for the reranker, making it potentially incompatible with FlashAttention. The paper should compare memory usage and latency against FlashAttention-enabled baselines.\n\n\n* Missing evaluation on more complex multi-hop reasoning datasets like MuSiQue or StrategyQA, and single-document QA datasets like SQuAD 2.0."}, "questions": {"value": "* Can the authors include comparisons with LLMLingua-2, TACO-RL, and 500xCompressor?\n* How does EFFCOMP's memory usage and latency compare to baselines using FlashAttention? Can the method be adapted to work without requiring explicit attention scores?\n* Can the authors provide an ablation study on the reward weight α (currently 0.95)? What happens at α=0.5, 0.7, 0.9, and how does this affect the Pareto frontier of compression vs. accuracy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "VStWBIoShk", "forum": "qSKDBVXhHJ", "replyto": "qSKDBVXhHJ", "signatures": ["ICLR.cc/2026/Conference/Submission19378/Reviewer_xN74"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission19378/Reviewer_xN74"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission19378/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761980446421, "cdate": 1761980446421, "tmdate": 1762931303676, "mdate": 1762931303676, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}