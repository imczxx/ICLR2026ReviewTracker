{"id": "sIOgOQttFQ", "number": 5263, "cdate": 1757881919950, "mdate": 1759897984547, "content": {"title": "MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era", "abstract": "The rapid development of interactive and autonomous AI systems signals our entry into the agentic era. Training and evaluating agents on complex agentic tasks such as *software engineering* and *computer use* requires not only efficient model computation but also sophisticated infrastructure capable of coordinating vast agent-environment interactions. However, no existing infrastructure can effectively support large-scale training and evaluation on such complex agentic tasks. To address this challenge, we present **MegaFlow**, a large-scale distributed orchestration system that enables efficient scheduling, resource allocation, and fine-grained task management for agent-environment workloads. MegaFlow abstracts agent training infrastructure into three independent services (*Model Service*, *Agent Service*, and *Environment Service*) that interact through unified interfaces, enabling independent scaling and flexible resource allocation across diverse agent-environment configurations. In our agent training deployments, MegaFlow successfully orchestrates tens of thousands of concurrent agent tasks while maintaining high system stability and achieving efficient resource utilization. By enabling such large-scale agent training, MegaFlow addresses a critical infrastructure gap in the emerging agentic AI landscape.", "tldr": "", "keywords": ["Large Language Models", "Reinforcement Learning", "Agentic Coding"], "primary_area": "infrastructure, software libraries, hardware, systems, etc.", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fe597f7653c6f17e548cd054df92f67fed3fd799.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces MegaFlow, which is a distributed orchestration system designed for training and evaluating agentic workloads. The key idea is a three-service decomposition: Environment, Agent, and Model. The authors demonstrate large-scale deployments with notable improvements."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "I am not an expert in large-scale systems. My evaluation can only focus on clarity and methodological soundness. The three-service decomposition sounds clean and well-motivated to me, although I am not sure about the main literature in this field. The experimental results seem convincing, but I am not familiar with the setups. Since I am less familiar with this field, I recommend seeking opinions mainly from other reviewers with stronger expertise."}, "weaknesses": {"value": "Since I am not an expert in this field, I found it difficult to grasp the key contributions of the paper. As a result, I was unable to provide meaningful weaknesses. I recommend seeking opinions from other reviewers with stronger expertise."}, "questions": {"value": "Same as above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 1}, "code_of_conduct": {"value": "Yes"}}, "id": "7Bxs0Al7SS", "forum": "sIOgOQttFQ", "replyto": "sIOgOQttFQ", "signatures": ["ICLR.cc/2026/Conference/Submission5263/Reviewer_YBFx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5263/Reviewer_YBFx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission5263/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761788256341, "cdate": 1761788256341, "tmdate": 1762917978101, "mdate": 1762917978101, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents MegaFlow, a large-scale distributed orchestration system tailored for training and evaluating autonomous agents in complex, interactive environments. The system decouples agent training into three modular services, with unified APIs and elastic cloud-based resource allocation. MegaFlow aims to overcome practical bottlenecks in agent-environment training pipelines, including security and isolation constraints, storage overhead from task-specific containerized environments, and throughput limitations of centralized high-spec clusters."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper articulates key system-level challenges in scaling interactive agent training, differentiating this setting from traditional large-model training workloads.\n2. The three-service architecture is well-structured and clearly explained."}, "weaknesses": {"value": "I am not an expert in agent orchestration, so please correct my mistakes in my questions:\n\n1. Comparisons seem to be mainly against high-spec centralized machines rather than alternative distributed or hybrid systems.\n2. While the modular three-service abstraction is intuitive, the paper would benefit from clearer articulation of which components introduce fundamentally new design ideas versus mature cloud-native practices adapted to the agent training context.\n3. While the system enables large-scale rollouts, can authors offer analyses about whether this orchestration translates into better learning outcomes (e.g., improved agent capabilities, faster convergence) beyond execution efficiency?"}, "questions": {"value": "Please see the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "a4xs7yXHXI", "forum": "sIOgOQttFQ", "replyto": "sIOgOQttFQ", "signatures": ["ICLR.cc/2026/Conference/Submission5263/Reviewer_zBgH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5263/Reviewer_zBgH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission5263/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761829803233, "cdate": 1761829803233, "tmdate": 1762917977800, "mdate": 1762917977800, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This work introduces MegaFlow, a distributed system for efficiently connecting environments, agent scaffolds, and LLMs for training. This system solves many of the practical issues around agent training, like security constraints, storage space, and the need for powerful machines to run the environments, resulting in a significant cost reduction."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- This work addresses a significant challenge regarding scaling up data collection for agentic LLM training.\n- The results and analysis are comprehensive from a systems perspective.\n- The text is well-written and easy to follow."}, "weaknesses": {"value": "- There are no results regarding the downstream utility of MegaFlow in the context of LLM training. I recognize that this is more of an infrastructure/systems paper, but any downstream results would've been appreciated.\n- The CPU utilization and memory utilization is consistent but still low."}, "questions": {"value": "- Does MegaFlow support conducting multiple concurrent tasks on each (8-core, 16 GB) system? Would this help increase utilization (at the cost of increasing latency)?\n- MegaFlow seems to support a lot of existing LLM agent infrastructure, so I was wondering approximately how difficult would it be for a new user to start using MegaFlow (in terms of lines of boilerplate code or general user time)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "m4PmHYjaFD", "forum": "sIOgOQttFQ", "replyto": "sIOgOQttFQ", "signatures": ["ICLR.cc/2026/Conference/Submission5263/Reviewer_VxSd"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5263/Reviewer_VxSd"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission5263/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761844421892, "cdate": 1761844421892, "tmdate": 1762917977493, "mdate": 1762917977493, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The manuscript introduces MegaFlow, a distributed orchestration system for large-scale agent training, and claims cost and scaling advantages over centralized baselines.  Nevertheless, the decomposition into model/agent/environment services is straightforward, and the empirical comparison is confined to an internal cloud deployment without reproducible artifacts."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The three-service modularization yields a clean separation of concerns that simplifies independent scaling and maintenance.  \n2. The evaluation dataset is substantial (though I have no idea what the dataset essentially is), providing a degree of empirical credibility rarely seen in infrastructure proposals."}, "weaknesses": {"value": "1. Figure 1 contains limited information; I suggest either reducing its space allocation or adding more explanatory details to enhance clarity.\n2. In Line 215, what exactly are the “complex resource monitoring and allocation algorithms”? Likewise, what does the “standardized compute instance” implemented by the authors refer to? In Line 246, more details are needed regarding the document database—specifically, the structure of the operational metadata, its storage format, and how it is managed and retrieved. Without these details, it is difficult to discern the novel contribution of the proposed framework.\n3. The evaluation setup is unclear. In Line 302, the authors mention “30,000 ephemeral execution tasks and over 2 million persistent execution tasks.” What exactly do these tasks represent, and how were they generated? Are they derived from specific training datasets?\n4. Are there truly no comparable baselines? Could approaches such as VERL agent training or frameworks like AReal serve as baselines?\n5. The authors claim this is an agent training framework, yet the experimental section lacks details on what LLM was trained, what data were used, and what hyperparameter configurations were applied, which makes the setup somewhat confusing."}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "W72iS2dqgY", "forum": "sIOgOQttFQ", "replyto": "sIOgOQttFQ", "signatures": ["ICLR.cc/2026/Conference/Submission5263/Reviewer_vXD8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission5263/Reviewer_vXD8"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission5263/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761965456920, "cdate": 1761965456920, "tmdate": 1762917977261, "mdate": 1762917977261, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}