{"id": "Zw1Uw7u6Su", "number": 12892, "cdate": 1758211290481, "mdate": 1759897478825, "content": {"title": "Inconsistency Biases in Dynamic Data Pruning", "abstract": "Dynamic data pruning accelerates training by focusing on informative samples. However, comparing importance scores across different model states introduces inconsistency (score context drift), and variable selection rates bias gradient dynamics over time (temporal gradient bias). We introduce RePB (Resolving Pruning Biases), a framework addressing these issues. RePB performs pruning decisions within local windows (short sequences of batches) during training, using loss scores computed with a near-constant model state within each window to ensure valid comparisons. These decisions determine the data subset used in the subsequent training phase. To counteract temporal gradient bias arising from non-uniform sample inclusion, cumulative temporal rescaling reweights sample losses during training based on their historical selection frequency. We provide theoretical grounding for RePB's consistency in score comparison and gradient alignment. Experiments show RePB achieves near-full-dataset accuracy using reduced data (most above 30%) across 16 datasets, 17 models and 13 tasks, offering a robust and scalable approach to efficient deep learning.", "tldr": "", "keywords": ["dynamic data pruning", "efficient training"], "primary_area": "other topics in machine learning (i.e., none of the above)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a8ace73e83d970c10dd83659ac471fd99c43ed97.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "Deep learning models rely their success mainly on the variety of data used in vast quantities. \nThis dataset expansion has direct impact on the training efficiency. This work focuses on data selection which aims to train models on smaller but carefully chosen data subsets. There are dynamic methods that perform such data selection during the learning process, called online data pruning. Giving wrong importance to data samples can introduce biased gradients. This submission identifies two fundamental consistency issues called: score context drift and temporal gradient bias. \n\nScore context drift focuses on the parameters drift during training whereas temporal gradient bias takes into account the bias introduced by non-uniform sampling distribution over time (due to different data selection)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Strengths:\n- Identify fundamental issues of inconsistency biases in dynamic data pruning\n- Propose a framework (RePB) to mitigate the inconsistency bias due to parameter drift during training and non-uniform sampling distribution over time\n- RePB maintains data diversity and prevents sample pool collapse\n- Theoretical foundations are provided that justifies comparison of scores collection within local windows\n- Comparisons are reported over different methods."}, "weaknesses": {"value": "Weaknesses:\n- Comparisons with the most recent SOTA (Salaun et al.2025a) is missing\n- How sensitive is RePB to the local window size?\n- How the method ensures that computing scores over a small window does not accumulate error over time?\n- Missing citations: \n\nRecent work by Salaun et al. 2025a, b, develop better online importance mechanisms driven by Multiple importance sampling (MIS) and Optimal MIS. The paper seems to completely ignore these references.\n\n@misc{salaun2025a,\n      title={Online Importance Sampling for Stochastic Gradient Optimization}, \n      author={Corentin Salaün and Xingchang Huang and Iliyan Georgiev and Niloy J. Mitra and Gurprit Singh},\n      year={2025},\n      eprint={2311.14468},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG},\n      url={https://arxiv.org/abs/2311.14468}, \n}\n\n@misc{salaun2025b,\n      title={Multiple Importance Sampling for Stochastic Gradient Estimation}, \n      author={Corentin Salaün and Xingchang Huang and Iliyan Georgiev and Niloy J. Mitra and Gurprit Singh},\n      year={2025},\n      eprint={2407.15525},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG},\n      url={https://arxiv.org/abs/2407.15525}, \n}"}, "questions": {"value": "- How sensitive is RePB to the local window size?\n- How the method ensures that computing scores over a small window does not accumulate error over time?\n- How the method compares to Salaun et al. 2025a,b?\n- Does it make sense to combine RePB with Salaun et al.?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "2W3jKdtcpr", "forum": "Zw1Uw7u6Su", "replyto": "Zw1Uw7u6Su", "signatures": ["ICLR.cc/2026/Conference/Submission12892/Reviewer_XfsH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12892/Reviewer_XfsH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission12892/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761575991971, "cdate": 1761575991971, "tmdate": 1762923673995, "mdate": 1762923673995, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces RePB (Resolving Pruning Biases), a framework that tackles two fundamental consistency problems in dynamic data pruning: score context drift (where importance scores computed at different training stages aren't comparable) and temporal gradient bias (where non-uniform sample selection alters training dynamics). RePB addresses these issues through Local Window Pruning, which restricts score comparisons to short windows (a few batches), and Cumulative Temporal Rescaling, which reweights samples based on their historical selection frequency to align gradient trajectories with full-dataset training. The authors provide theoretical guarantees for both components and demonstrate RePB's effectiveness across 16 datasets, 17 model architectures, and 13 diverse tasks spanning classification"}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The paper’s main strength is its comprehensive and diverse experimental validation, covering many datasets, architectures, and tasks. RePB seems to consistently deliver good performance and hence is a promissing approach."}, "weaknesses": {"value": "Overall, I found that the paper needs further refinement and clarification before it is ready for publication.\n\nThe main weaknesses of the paper lie in its theoretical clarity and methodological presentation. The theoretical analysis lacks rigour: propositions are not clearly stated, assumptions are introduced informally within the proofs, and the proofs rely on approximations rather than precise derivations. This makes it difficult to assess what is actually proven and under what conditions the results hold. \n\nIn addition, the methodology section presents the pruning criterion using a fixed mean-based threshold $\\mu_k$, which limits flexibility in controlling the pruning or compression rate $r$. While most experiments appear to use this fixed rule, some dynamic data pruning benchmarks suggest a variable rate, creating inconsistency between the method’s description and its implementation."}, "questions": {"value": "- What are the formal statements of the propositions ?\n- How does the framework deal with flexible pruning rate $r$ ?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "DQDo57vgNM", "forum": "Zw1Uw7u6Su", "replyto": "Zw1Uw7u6Su", "signatures": ["ICLR.cc/2026/Conference/Submission12892/Reviewer_kLUp"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12892/Reviewer_kLUp"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission12892/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761772931641, "cdate": 1761772931641, "tmdate": 1762923673737, "mdate": 1762923673737, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies two important problems in dynamic data pruning: inconsistency biases in the scoring context, and temporal gradient dynamics. It proposes to use local window pruning and cumulative temporal rescaling to address these two problems. The authors evaluate its effect on various datasets and demonstrate its effectiveness. Overall, this is an insightful and meaningful work."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. This work identifies two important problems in current dynamic data pruning methods and solves them. The insight is quite accurate, and the meaningful improvement further enhances the robustness and generalization of dynamic data pruning.\n2. The experimental evaluation is comprehensive. This work extends the application to a lot more scenarios, including other vision and vision-language tasks, and semi-supervised learning.\n3. The presentation is good."}, "weaknesses": {"value": "1. According to the ablation experiment demonstrated in Tab. 9, RePB relies on resampling more than other dynamic pruning methods. It is worth a little bit more discussion: whether it is because of the inner window score stability, or cumulative temporal rescaling (rescaling factor too high in some cases)?\n2. Currently, the pruning factor $\\rho$ is used, but this factor has no ablation, and there is no discussion of its value and tuning characteristics.\n3. For proof of 4.2, a critical problem is that in this scenario $E[1/X] \\neq 1/E[x]$, the substitution may not hold.\n\nMinor:\n1. The citation of \"Scale efficient training for large datasets\" would be better to use the accepted version."}, "questions": {"value": "1. In the original InfoBatch, there was a trick mentioned: one can further downsample the lower-loss samples (E.g., keeping only 25% samples for 25% low-loss samples). Is this trick also compatible with RePB? It could further enhance the saving ratio. This is a complementary question, out of my curiosity, but not required.\n2. CTR weight could encounter a more extreme value than InfoBatch's rescaling factor (which is fixed to 1/(1-r)). Is there any observation on this potential problem? \nFor example, an update with a large factor on a sample not sampled for many epochs could lead to a large update step, leading to higher loss, and the subsequent updates cannot immediately reduce the CTR weight, which will cause this sample to be updated with much higher importance than sampling it earlier."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "OlJQepvZfC", "forum": "Zw1Uw7u6Su", "replyto": "Zw1Uw7u6Su", "signatures": ["ICLR.cc/2026/Conference/Submission12892/Reviewer_THQf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12892/Reviewer_THQf"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission12892/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761923614285, "cdate": 1761923614285, "tmdate": 1762923673404, "mdate": 1762923673404, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper identifies two fundamental consistency issues in dynamic data pruning: score context drift (incomparability of importance scores computed under different model states) and temporal gradient bias (distortion of gradient dynamics due to non-uniform sample selection over epochs). To address these, the authors propose RePB (Resolving Pruning Biases), a framework that combines (1) Local Window Pruning (LWP) to ensure valid score comparisons within short training windows where model parameters are nearly constant, (2) Uniform Probability Resampling to maintain data diversity, and (3) Cumulative Temporal Rescaling (CTR) to reweight sample losses based on historical selection frequency, thereby aligning long-term gradient expectations with full-dataset training. The method is theoretically motivated and evaluated across 16 datasets, 17 models, and 13 tasks, showing strong performance—often matching or exceeding full-dataset accuracy while pruning 30% or more of the data."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper clearly articulates two underappreciated but critical pitfalls in dynamic data pruning and provides a principled, theoretically grounded solution.\n\n2. RePB’s design is elegant: LWP directly tackles score inconsistency by restricting comparisons to stable model contexts, while CTR offers a practical, history-based inverse weighting scheme that avoids the need to model complex instantaneous selection probabilities.\n\n3. The empirical evaluation is impressively broad in terms of tasks (classification, captioning, generation, semi-supervised learning), modalities (vision, text, audio), and architectures (CNNs, Transformers, Mamba, VAEs, diffusion models), demonstrating strong generalization.\n\n4. Ablation studies and comparisons with SOTA methods like InfoBatch convincingly validate the necessity and effectiveness of each component. \n\n5. Computational overhead is minimal, making RePB highly practical for real-world deployment."}, "weaknesses": {"value": "1. Despite the diversity of tasks, the scale of some experiments remains limited. For instance, while ImageNet-1K is included, there is no evaluation on larger-scale vision benchmarks (e.g., ImageNet-21K) or billion-parameter language models, which are increasingly standard in efficiency research. The largest dataset used (MJ+ST with 15M samples) is promising, but more large-scale LLM or multimodal experiments would strengthen claims about scalability.\n\n2. The paper assumes sample loss as the sole importance metric. While common, this may not capture all aspects of sample utility (e.g., diversity, influence, or representativeness). Extending LWP to other scoring functions (as hinted in the limitations) would be valuable.\n\n3. The theoretical analysis relies on assumptions like Lipschitz continuity and bounded gradients, which are standard but may not always hold in practice (e.g., with unstable training or aggressive learning rates). A brief discussion of robustness under violation of these assumptions would be helpful. \n\n4. Missing some data pruning methods: \n\nSevering Spurious Correlations with Data Pruning\n\nPerplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models\n\nData Pruning by Information Maximization\n\nBeyond Efficiency: Molecular Data Pruning for Enhanced Generalization\n\nPruning-based Data Selection and Network Fusion for Efficient Deep Learning\n\nData Pruning via Moving-one-Sample-out"}, "questions": {"value": "See Weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "enKUZayezK", "forum": "Zw1Uw7u6Su", "replyto": "Zw1Uw7u6Su", "signatures": ["ICLR.cc/2026/Conference/Submission12892/Reviewer_Gn4Z"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission12892/Reviewer_Gn4Z"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission12892/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761995225904, "cdate": 1761995225904, "tmdate": 1762923673126, "mdate": 1762923673126, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}