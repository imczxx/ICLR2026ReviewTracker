{"id": "ABA4KBVz1w", "number": 10720, "cdate": 1758180316511, "mdate": 1759897633601, "content": {"title": "Conformal Data Contamination Tests for In-distribution Data Acquisition", "abstract": "The amount of quality data in many machine learning tasks is limited to what is available locally to data owners. The set of quality data can be expanded through trading or sharing with external data agents. However, external data may be contaminated or introduce undesirable sample diversity which can degrade performance of personalized machine learning tasks, as in diagnosis of a rare disease or recommendation systems. Therefore, data buyers need quality guarantees prior to data acquisition. Previous works primarily rely on distributional assumptions about data from different agents, relegating quality checks to post-hoc steps involving costly data valuation procedures. We propose a distribution-free, contamination-aware data-sharing framework that identifies external data agents whose data is most valuable for model personalization. To achieve this, we introduce novel two-sample testing procedures, grounded in rigorous theoretical foundations for conformal outlier detection, to determine whether an agent’s data exceeds a contamination threshold. The proposed tests, termed *conformal data contamination tests*, remain valid under arbitrary contamination levels while enabling false discovery rate control via the Benjamini-Hochberg procedure. Empirical evaluations across diverse collaborative learning scenarios demonstrate the robustness and effectiveness of our approach. Overall, the conformal data contamination test distinguishes itself as a generic procedure for aggregating data with statistically rigorous quality guarantees.", "tldr": "We introduce a conformal testing framework to identify high-quality data in collaborative learning scenarios, offering statistical guarantees without relying on distributional assumptions.", "keywords": ["conformal inference", "conformal p-value", "multiple testing", "data markets", "collaborative learning", "distribution-free", "data contamination"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/cc81d2a407558237c5b7314d8dc32b0c321773f6.pdf", "supplementary_material": "/attachment/ebecd735e980877a1ae4d8075ddfb48091d5b19e.zip"}, "replies": [{"content": {"summary": {"value": "The paper considers the problem that data buyers want to acquire similar personalised data and need quality guarantees prior to data acquisition. The paper proposes a distribution-free solution that selects data only from agents with less contaminated data (data from another distribution). The main contributions include new theoretical two-sample testing procedures, data sharing procedures and experiments on medical image datasets to validate the effectiveness and practicality."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The problem is generally well motivated in the introduction. It may be helpful to further explain why the data buyers can only purchase from few buyers and would not know the distribution or value of others’ data beforehand (e.g., by getting them to predict on a validation set).\n2. The solution seems theoretically grounded."}, "weaknesses": {"value": "1. The main paper or the appendix should provide more background for unfamiliar readers, e.g., on the BH procedure and the definition of PDRS.\n2. Sec 3 and 4 should describe technical challenges involved and describe the significance/implications of the results."}, "questions": {"value": "1. Can you provide some intuition on why the proposed testing procedures do not require distributional assumptions?\n2. Is the method less efficient and effective on larger datasets, e.g., the full MNIST? Also, the experiments consider mislabeled data. Does it work when the data is correctly labeled but the class distribution differs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cb5Q1Bsry4", "forum": "ABA4KBVz1w", "replyto": "ABA4KBVz1w", "signatures": ["ICLR.cc/2026/Conference/Submission10720/Reviewer_fRGL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10720/Reviewer_fRGL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876285862, "cdate": 1761876285862, "tmdate": 1762921951007, "mdate": 1762921951007, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces conformal data contamination tests. These tests are distribution-free, allowing a data buyer to check multiple outside data sources and retain only those whose data are not \"too contaminated\" relative to the buyer's own distribution.\nFor each candidate source, it builds conformal p‑values from a small preview batch, combines them into a single p‑value, and then applies Benjamini-Hochberg across sources to control FDR.\nAuthors demonstrate that in medical dataset/MNIST image classification experiments, the procedure can select better collaborators and improve downstream accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper is well written and easy to follow.\n\n2. The idea behind the paper is simple yet effective, and I think it addresses an important problem.\n\n3. The paper provides both rigorous theoretical results and experimental evaluation (although see weaknesses)."}, "weaknesses": {"value": "Overall, I like this paper. I only have a concern about the choice of datasets for experiments and the contamination procedure. The authors considered hand-crafted noise (e.g., label noise), but not a real-world type of noise. One way to address this could be by considering additional datasets that are designed for it. It could be CIFAR-10C or CIFAR-100C, but also, for example, ImageNet (clear) vs. ImageNet-R. \nIn my opinion, this would be a more realistic approach.\n\nAdditionally, I have a conceptual question about the whole approach (this is not necessarily a weakness). The approach assumes that each external agent can reveal $m$ samples for demonstration in every round, which may be problematic in privacy-sensitive settings. Therefore, each of the agents may utilize watermarks / other curruptions to preserve privacy. And these corruptions may differ from one agent to another. What do you think could be done in this case?"}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "OFxVZZUqKd", "forum": "ABA4KBVz1w", "replyto": "ABA4KBVz1w", "signatures": ["ICLR.cc/2026/Conference/Submission10720/Reviewer_iwQx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10720/Reviewer_iwQx"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930432112, "cdate": 1761930432112, "tmdate": 1762921950658, "mdate": 1762921950658, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies data sharing in the context of collaborative learning, where data owners have samples drawn from distributions $P_k$, which are Huber-contaminated versions of a common $P_0$. The authors design a conformal multiple testing procedure for agents to select a subset of collaborators whose contamination coefficient $\\pi_k$ stands below a threshold. From a theoretical point of view, the paper proposes four valid p values, and show that the Storey p values are PRDS, hence making them compatible with a BH procedure. From a pratical point of view, the proposed procedure is implemented on MNIST and RetinaMNIST/EyesPACS with 10 agents and 100 data points. The CDF of the different p values are displayed, as well as the accuracy as a funciton of the expected number of collaborators."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1) The idea of using hypothesis testing in collaborative learning to limit the harmful effects of data heterogeneity is interesting.\n2) The statistical analysis is well conducted, with four new p values specifically tailor to test whether a distribution is contamined beyond a given threshold.\n3) The experiments, even though the number of agents and data points are low, are fairly convincing."}, "weaknesses": {"value": "1) Important related works have been neglicted. The idea of performing a statistical inference or test prior to collaboration in collaborative learning with agents having data of varying quality is not new. In particular, [1] already studies this problem and propose a similar solution to the one presented in this paper (estimating the discrepancy from $P_0$ and conditioning the collaboration on it). Likewise, [2] studies the selection of clients prior to collaborating as a bilevel problem. A discussion of these papers (among others) is missing. \n2) A discussion about the four p-values introduced by the paper is missing. When is it better to use one rather than the others? Is there one of them that is easier to compute than others? It seems that the statistical analysis is a bit ad-hoc, and does connect well to the rest of the paper (about data sharing). \n3) The other never discuss the complexity of their method, so it is not clear whether it is actually implementable or if its cost is probihitive in real-world setting (high dimension, a lot of data points and agents...)\n\n[1] Capitaine, A., Boursier, E., Scheid, A., Moulines, E., Jordan, M., El-Mhamdi, E. M., & Durmus, A. (2024). Unravelling in collaborative learning. Advances in Neural Information Processing Systems, 37, 97231-97260.\n\n[2] Hashemi, D., He, L., & Jaggi, M. (2024). Cobo: Collaborative learning via bilevel optimization. Advances in Neural Information Processing Systems, 37, 15550-15574."}, "questions": {"value": "1) Can you compare your problem and method to references [1] and [2]? \n2) Can you further discuss the four p values introduced in theorem 1 and 2? In particular, is there one that should be favored from a practical point of view (I suspect \"Storey\" given theorem 3). In this case, what is the interest of the three others? \n3) Can you discuss the complexity of your method? Is the computational / time cost of implementation the main reason why your experiments were conducted with few agents and data points?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "none"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Zvi5PfNhxe", "forum": "ABA4KBVz1w", "replyto": "ABA4KBVz1w", "signatures": ["ICLR.cc/2026/Conference/Submission10720/Reviewer_N3w4"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10720/Reviewer_N3w4"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761931430564, "cdate": 1761931430564, "tmdate": 1762921950241, "mdate": 1762921950241, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "In the setting where multiple data owners each have their own distinct dataset and where there is risk of data contamination, this paper proposes an approach toward providing some quality assurance on data sharing which builds on prior methods for conformal outlier detection. The proposed “conformal data contamination tests” improve on prior data data contamination tests by providing distribution-free validity (under some standard IID/exchangeability assumptions) rather than requiring parametric assumptions. To control issues with multiple-testing for the multiple data-sharing agents, the authors use the Benjamini-Hochberg procedure. They provide empirical evaluations across different collaborative learning settings to demonstrate robustness and effectiveness."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Overall the paper seems sound and well-motivated for the stated goals. That is, the proposed methods could have practical use in the setting of quality-assurance/contamination testing in collaborative data sharing. Relative to the prior work on conformal outlier detection by Bates et al. (2023)--where that work can be viewed as covering the special case where one wishes to test the contamination level of 0%, among other contributions--the current work provides seemingly valid hypothesis tests for any other contamination level. It is good that the authors address the multiplicity issues inherent to testing over multiple data-sharing agents, and the Benjamini-Hochberg procedure is reasonable for doing so."}, "weaknesses": {"value": "**Novelty:** Although the proposed methods are well-motivated and could be useful for the setting studied, it currently does not seem to me that there is significant enough technical innovation in this paper to be of particular interest to the ICLR audience. While I appreciate that the prior conformal outlier detection methods in Bates et al (2023) do not cover the case of data contamination (to my understanding), conformal outlier detection under data contamination is studied by the ICML 2025 paper Bashari et al. (2025), “Robust conformal outlier detection under contaminated reference data,” which is not referenced in the current paper. The authors should add some discussion about how their work relates to that of Bashari et al. (2025). Beyond this reference, I’m wondering if this paper would be a better fit for a somewhat more specialized conference than ICLR, such as *Conformal and probabilistic prediction with applications* (COPA), or a journal focused on soundness, such as *TMLR*."}, "questions": {"value": "Can the authors please clarify how their proposed work relates to that of Bashari et al. (2025)?\n\nBashari, M., Sesia, M., & Romano, Y. (2025). Robust conformal outlier detection under contaminated reference data. ICML."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ifQzNnLSjZ", "forum": "ABA4KBVz1w", "replyto": "ABA4KBVz1w", "signatures": ["ICLR.cc/2026/Conference/Submission10720/Reviewer_EQ8J"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10720/Reviewer_EQ8J"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10720/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762033629883, "cdate": 1762033629883, "tmdate": 1762921949670, "mdate": 1762921949670, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}