{"id": "wuvwqe5n9J", "number": 21776, "cdate": 1758321622534, "mdate": 1759896903887, "content": {"title": "Efficient Gradient Clipping Methods in DP-SGD for Convolution Models", "abstract": "Differentially private stochastic gradient descent (DP-SGD) is a well-known method for training machine learning models with  a specified level of privacy. \nHowever, its basic implementation is generally bottlenecked by the computation of the gradient norm (gradient clipping) for each example in an input batch. \nWhile various techniques have been developed to mitigate this issue, \nthere are only a handful of methods pertaining to convolution models, e.g., vision models.\nIn this work, we present three practical methods for performing gradient clipping that improve upon previous state-of-art methods. Two of these methods use in-place operations to reduce memory overhead, while the third one leverages a relationship between Fourier transforms and convolution layers. We then develop a dynamic algorithm that dispatches one of the above three algorithms to optimize performance. Extensive benchmarks confirm that this algorithm consistently outperforms other state-of-the-art algorithms and frameworks.", "tldr": "We provide a computationally and memory efficient algorithm for gradient norm computation in CNNs that are used in DP-SGD.", "keywords": ["Differential Privacy", "SGD", "Clipping", "CNNs", "FFT", "DP-SGD", "Computational Complexity"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/e7f9991ff71b09cbbfab06ac7c5147483caf17fe.pdf", "supplementary_material": "/attachment/379234bc6b0b2e4ddf35df499cf35af3b222b4b6.zip"}, "replies": [{"content": {"summary": {"value": "This paper addresses a known bottleneck in Differentially Private Stochastic Gradient Descent (DP-SGD) — the high computational and memory cost of per-example gradient clipping — particularly in convolutional neural networks (CNNs).\nThe authors propose three practical methods for improving clipping efficiency. A meta-algorithm dynamically selects among these three methods depending on the model structure and hyperparameters. Benchmark experiments show improved runtime and memory usage compared with existing implementations."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Clear identification of a real bottleneck in DP-SGD training for convolutional models, with quantitative improvements in time and memory complexity.\n- Technical soundness: The use of circulant matrix properties and FFTs to accelerate convolution gradient norms is mathematically grounded and novel in the context of DP-SGD clipping.\n- Empirical evaluation: The paper provides benchmarks that show consistent efficiency gains over established baselines, demonstrating scalability to larger kernel sizes and batch dimensions.\n- Simplicity of integration: The proposed methods could be incorporated into existing DP frameworks such as Opacus without major architectural changes."}, "weaknesses": {"value": "- W1: Lack of experimental depth and reproducibility: The benchmarks are limited to synthetic or minimal CNN settings, with no mention of dataset details or task relevance. As a result, it is unclear how the methods perform in real-world training scenarios (e.g., CIFAR, ImageNet).\n- W2: No clear analysis of privacy–utility trade-offs: While efficiency is emphasized, there is no evaluation of whether faster clipping alters gradient accuracy or privacy accounting in practice.\n- W3: Missing theoretical or experimental justification for the meta-algorithm’s dispatch policy: The rules governing when each clipping method is chosen remain underexplained and appear heuristic.\n- W4: Presentation and structure issues: The paper lacks a formal conclusion or discussion section, and the evaluation figures/tables are not clearly tied to claims in the introduction. As such, the work reads more like a technical note than a complete research paper."}, "questions": {"value": "Address W1-4"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "NA"}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "dTA8xCxWTq", "forum": "wuvwqe5n9J", "replyto": "wuvwqe5n9J", "signatures": ["ICLR.cc/2026/Conference/Submission21776/Reviewer_JyQv"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21776/Reviewer_JyQv"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission21776/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761654460859, "cdate": 1761654460859, "tmdate": 1762941927033, "mdate": 1762941927033, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper studies efficient methods to compute the per-sample gradient norm for DP-SGD and for the convolution layers. Three methods are proposed to improve the inefficiency of DP-SGD, where the DFT method is highlighted and experimented."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "This paper tackles a sub-problem (convolution layers) of an important problem (DP inefficiency) with a relatively new angle. The DFT method has good scalability in the high-dimensional setting and the efficiency improvement is backed up by experiments on 1D convolution with large kernel. E.g. in Table 4.3, it improves by 2 times over Opacus' implementation."}, "weaknesses": {"value": "1. I am concerned that the experiments (not the method itself) is significantly limited to 1D convolution and one-layer CNN. This deviates away real CNN like ResNet50. Why there are no experiments on multi-layer CNNs with 2D convolution? Can the authors specify what is the usage of multi-layer CNN with 1D convolution? \n\n2. There are 4 methods being experimented in this work: Algorithm 3.3, Lee and Kifer, Bu, and Naive (opacus). But none of the tables compare all four of them. Is there a technical difficulty to do so? In particular, in Table 4.3, the comparison between Algorithm 3.3 and Opacus is not a strong and useful comparison. It is well-known that opacus is memory hungry and there are more efficient libraries to compute DP grad for convolution (mostly 2D) like mixed ghost clipping. Can the authors add experiments on that?"}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2qxEFV6S2q", "forum": "wuvwqe5n9J", "replyto": "wuvwqe5n9J", "signatures": ["ICLR.cc/2026/Conference/Submission21776/Reviewer_Mb2h"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21776/Reviewer_Mb2h"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission21776/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762110431906, "cdate": 1762110431906, "tmdate": 1762941926702, "mdate": 1762941926702, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FFT or DFT method to compute the per-sample gradient norm for DP-SGD. The method only works for convolution layers theoretically and for 1D convolution layers empirically. Theoretical analysis on complexity has shown improvement in high dimension. Empirical comparison has shown improvement over memory-heavy naive implementation."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Implementation inefficiency of DP is critical in practice and solving it with FFT is original. The derivation and complexity analysis is sound as far as I am concerned. In the specific scenario of 1D convolution, the improvement is of certain significance. The paper is clear in stating its applicability when kernel size is large."}, "weaknesses": {"value": "While I understand the derivation in 1D and 2D convolution, the empirical experiments seem incomplete. Is there only one-layer model results? In my opinion, multi-layer 2D CNN is the norm and even this may be challenged by vision transformers that do not necessarily use convolution.\n\nSuppose this method works with large-kernel 2D CNN, I think the baselines are abundant: Opacus, fastDP, private_vision, private_transformers, etc. Currently this work seems to focus on the theoretical innovation without touching on the algorithmic development, right? If we move to larger scale, do the authros expect benefit or blockers in distributed DP training?"}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "nG6P0pHcmz", "forum": "wuvwqe5n9J", "replyto": "wuvwqe5n9J", "signatures": ["ICLR.cc/2026/Conference/Submission21776/Reviewer_U67n"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21776/Reviewer_U67n"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission21776/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762112976294, "cdate": 1762112976294, "tmdate": 1762941926434, "mdate": 1762941926434, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes a few ways to perform per-sample gradient clipping for convolution kernels efficiently, which is useful for DP training algorithms on models using convolution. Results show the proposed algorithms are faster than standard gradient clipping in existing libraries when kernel size is relatively large."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. Efficient gradient clipping is import for differetially-private training algorithms. The efficient gradient clipping algorithms on convolution kernels will be useful in practice."}, "weaknesses": {"value": "1. Experiments only on 1d kernels and there is no open-source code. The derivation of the proposed methods are straightforward from gradient calculation rules. I would expect more practical contribution from the paper."}, "questions": {"value": "Why only 1d kernels are tested in experiments and do authors have plan to opensource code?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ZU5XbEp58J", "forum": "wuvwqe5n9J", "replyto": "wuvwqe5n9J", "signatures": ["ICLR.cc/2026/Conference/Submission21776/Reviewer_ot86"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission21776/Reviewer_ot86"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission21776/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762119409169, "cdate": 1762119409169, "tmdate": 1762941926081, "mdate": 1762941926081, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}