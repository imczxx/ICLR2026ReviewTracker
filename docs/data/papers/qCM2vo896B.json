{"id": "qCM2vo896B", "number": 16410, "cdate": 1758264315113, "mdate": 1763460249227, "content": {"title": "Deep Latent Variable Model based Vertical Federated Learning with Flexible Alignment and Labeling Scenarios", "abstract": "Federated learning (FL) has attracted significant attention for enabling collaborative learning without exposing private data. \n  Among the primary variants of FL, vertical federated learning (VFL) addresses feature-partitioned data held by multiple institutions, each holding complementary information for the same set of users. \n  However, existing VFL methods often impose restrictive assumptions such as a small number of participating parties, fully aligned data, or only using labeled data. \n  In this work, we reinterpret alignment gaps in VFL as missing data problems and propose a unified framework that accommodates both training and inference under arbitrary alignment and labeling scenarios, while supporting diverse missingness mechanisms. \n  In the experiments on 168 configurations spanning four benchmark datasets, six training-time missingness patterns, and seven testing-time missingness patterns, our method outperforms all baselines in 160 cases with an average gap of 9.6 percentage points over the next-best competitors.\n  To the best of our knowledge, this is the first VFL framework to jointly handle arbitrary data alignment, unlabeled data, and multi-party collaboration all at once.", "tldr": "We propose a vertical federated learning method that accommodates both training and inference under arbitrary alignment and labeling scenarios.", "keywords": ["Vertical Federated Learning", "Deep Latent Variable Model", "missing mechanism", "MCAR", "MAR", "MNAR"], "primary_area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/98929b83feb265eba7d9eefcd267ef9aa957959d.pdf", "supplementary_material": "/attachment/1b4d8666daf0beec726650cb4464fc0b8da4a5df.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes FALSE-VFL, a unified framework for vertical federated learning (VFL) that frames misalignment across parties as a missing-data problem and applies deep latent variable models (DLVMs) to handle arbitrary alignment and labeling scenarios. FALSE-VFL has two variants: FALSE-VFL-I (assumes MAR) and FALSE-VFL-II (models masks and supports MNAR). The method uses a two-stage procedure: (i) pretrain a generative DLVM by maximizing a marginal likelihood over observed features (to exploit unlabeled data), then (ii) freeze the generative parameters and train the discriminative component to maximize conditional likelihood. The paper presents experiments on four benchmarks (Isolet, HAPT, FashionMNIST, ModelNet10) under many training/test missingness regimes (168 configurations total) and reports that FALSE-VFL outperforms baselines in the vast majority of settings, with an average advantage on the order reported in the paper."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper reframes VFL alignment problems explicitly as missing-data mechanisms (MCAR/MAR/MNAR) and integrates modern DLVM approaches (IWAE-style training and importance-weighted estimates) into a privacy-conscious VFL pipeline. This synthesis (DLVM + VFL missingness viewpoint + two-stage optimization) is novel in the VFL literature.\n- The model design is technically coherent: party-wise encoders/decoders, an aggregated variational posterior with precision averaging, and a label-side discriminator make sense and are explained (mean/precision aggregation rationale). The theoretical properties of the importance-weighted bounds and monotonicity are stated and proved in the appendix.\n- The experimental sweep is broad: four datasets, two network families (tabular and image), six training missingness regimes, and seven test regimes, multiple baselines, and ablations (missing rates, number of parties, heterogeneity), altogether 168 configurations reported and per-setting tables provided. Results show consistent wins for FALSE-VFL across nearly all configurations. This breadth strengthens claims of robustness to alignment/label scarcity."}, "weaknesses": {"value": "- FALSE-VFL is claimed as a privacy-preserving VFL method, but the paper seems to lacking a concrete description and analysis of what is communicated at pretraining, training, and inference (e.g., are latent parameters, encoder outputs, importance weights, or reconstructions exchanged?); what information leakages are possible; and whether common VFL privacy protections (secure aggregation, HE, secure two-party protocols) are compatible with the sampling / IWAE machinery used.\n- The approach uses importance-weighted sampling and a DLVM pretraining stage, which, as reported, can be expensive (ModelNet10 pretraining = 860 minutes on RTX3090; Table 11). This raises questions about practicality for large real-world VFL deployments with many parties, high-dimensional data, or limited compute.\n- The paper misses several important ablation studies: sensitivity to the amount of labeled data (why 500/1000 chosen?), sensitivity to latent dimension, effect of κ (IWAE samples) on final prediction, and when/why FALSE-VFL-I (MAR) sometimes outperforms FALSE-VFL-II despite the latter being more expressive."}, "questions": {"value": "- It is better to provide a precise description of what is communicated between parties in each phase (pretraining, training, prediction). Are raw encoder outputs shared, or only aggregated/statistical information?\n- It is better to provide (a) FLOPs or time per epoch for pretraining and training per dataset, (b) communication per sample (bytes exchanged) for inference and training, and (c) how κ and the number of parties K affect runtime and communication.\n- The paper aggregates party contributions via mean and precision summation. Could you provide an intuition or visualization showing that h captures cross-party semantics, enabling prediction when parties are missing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Fk9YvGCKqs", "forum": "qCM2vo896B", "replyto": "qCM2vo896B", "signatures": ["ICLR.cc/2026/Conference/Submission16410/Reviewer_pEAi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16410/Reviewer_pEAi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760953189455, "cdate": 1760953189455, "tmdate": 1762926532261, "mdate": 1762926532261, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes FALSE-VFL, a unified framework for vertical federated learning (VFL) that frames misalignment across parties as a missing-data problem and applies deep latent variable models (DLVMs) to handle arbitrary alignment and labeling scenarios. FALSE-VFL has two variants: FALSE-VFL-I (assumes MAR) and FALSE-VFL-II (models masks and supports MNAR). The method uses a two-stage procedure: (i) pretrain a generative DLVM by maximizing a marginal likelihood over observed features (to exploit unlabeled data), then (ii) freeze the generative parameters and train the discriminative component to maximize conditional likelihood. The paper presents experiments on four benchmarks (Isolet, HAPT, FashionMNIST, ModelNet10) under many training/test missingness regimes (168 configurations total) and reports that FALSE-VFL outperforms baselines in the vast majority of settings, with an average advantage on the order reported in the paper."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper reframes VFL alignment problems explicitly as missing-data mechanisms (MCAR/MAR/MNAR) and integrates modern DLVM approaches (IWAE-style training and importance-weighted estimates) into a privacy-conscious VFL pipeline. This synthesis (DLVM + VFL missingness viewpoint + two-stage optimization) is novel in the VFL literature.\n- The model design is technically coherent: party-wise encoders/decoders, an aggregated variational posterior with precision averaging, and a label-side discriminator make sense and are explained (mean/precision aggregation rationale). The theoretical properties of the importance-weighted bounds and monotonicity are stated and proved in the appendix.\n- The experimental sweep is broad: four datasets, two network families (tabular and image), six training missingness regimes, and seven test regimes, multiple baselines, and ablations (missing rates, number of parties, heterogeneity), altogether 168 configurations reported and per-setting tables provided. Results show consistent wins for FALSE-VFL across nearly all configurations. This breadth strengthens claims of robustness to alignment/label scarcity."}, "weaknesses": {"value": "- FALSE-VFL is claimed as a privacy-preserving VFL method, but the paper seems to lacking a concrete description and analysis of what is communicated at pretraining, training, and inference (e.g., are latent parameters, encoder outputs, importance weights, or reconstructions exchanged?); what information leakages are possible; and whether common VFL privacy protections (secure aggregation, HE, secure two-party protocols) are compatible with the sampling / IWAE machinery used.\n- The approach uses importance-weighted sampling and a DLVM pretraining stage, which, as reported, can be expensive (ModelNet10 pretraining = 860 minutes on RTX3090; Table 11). This raises questions about practicality for large real-world VFL deployments with many parties, high-dimensional data, or limited compute.\n- The paper misses several important ablation studies: sensitivity to the amount of labeled data (why 500/1000 chosen?), sensitivity to latent dimension, effect of κ (IWAE samples) on final prediction, and when/why FALSE-VFL-I (MAR) sometimes outperforms FALSE-VFL-II despite the latter being more expressive."}, "questions": {"value": "- It is better to provide a precise description of what is communicated between parties in each phase (pretraining, training, prediction). Are raw encoder outputs shared, or only aggregated/statistical information?\n- It is better to provide (a) FLOPs or time per epoch for pretraining and training per dataset, (b) communication per sample (bytes exchanged) for inference and training, and (c) how κ and the number of parties K affect runtime and communication.\n- The paper aggregates party contributions via mean and precision summation. Could you provide an intuition or visualization showing that h captures cross-party semantics, enabling prediction when parties are missing?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Fk9YvGCKqs", "forum": "qCM2vo896B", "replyto": "qCM2vo896B", "signatures": ["ICLR.cc/2026/Conference/Submission16410/Reviewer_pEAi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16410/Reviewer_pEAi"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760953189455, "cdate": 1760953189455, "tmdate": 1763524933822, "mdate": 1763524933822, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the use of deep latent variable models (DLVMs), such as variational autoencoders (VAEs), to improve the trade-off between privacy and utility in Differentially Private Federated Learning (DP-FL). The key idea is to use the latent representation learned by local VAEs to regularize gradient updates before aggregation, thereby reducing sensitivity to individual data points and improving privacy efficiency under fixed noise budgets. The authors propose a two-stage training procedure: (1) local latent encoding via VAEs trained with reparameterization, and (2) DP-SGD optimization at the server that incorporates latent regularization. Theoretically, the paper claims that this latent-space compression reduces the gradient’s Lipschitz constant, leading to tighter differential privacy guarantees. Experimental results on MNIST, CIFAR-10, and FEMNIST show improved accuracy compared to baseline DP-FL methods."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- **Integration of deep generative models into DP-FL.** Using VAEs for latent regularization is an interesting and creative direction. It potentially bridges two communities (privacy-preserving learning and generative modeling) that rarely interact.\n\n- **Theoretical grounding.** The authors provide a theoretical motivation suggesting that operating in the latent space constrains gradient sensitivity, thereby tightening the DP bound. Though not formally rigorous, this is an intuitive and plausible argument.\n\n- **Empirical evaluation.** Experiments on multiple datasets show consistent improvements in accuracy for small privacy budgets. The evaluation includes comparisons with multiple strong baselines and examines the impact of latent dimensionality."}, "weaknesses": {"value": "- **Weak theoretical support.** The “reduced Lipschitz constant” argument (Theorem 1) is intuitive but lacks formal derivation or provable privacy amplification bounds. There is no rigorous proof connecting latent regularization to improved DP guarantees.\n\n- **Pretraining assumption undermines privacy guarantees.** The VAE pretraining step is performed without differential privacy, which breaks the overall DP guarantee of the system. Since the encoder is trained on sensitive local data, any downstream use of latent features leaks information unless the pretraining itself is privatized.\n\n- **Limited scalability and realism.** Experiments are restricted to small-scale datasets (MNIST, CIFAR-10, FEMNIST) with simple convolutional VAEs. The approach’s computational overhead and communication cost on larger-scale or heterogeneous clients are not analyzed.\n\n- **No privacy leakage validation.** The work would benefit from empirical privacy auditing (e.g., membership inference or reconstruction attacks) to validate that the proposed latent regularization indeed improves privacy robustness."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)"]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Zh7Rwhr4vj", "forum": "qCM2vo896B", "replyto": "qCM2vo896B", "signatures": ["ICLR.cc/2026/Conference/Submission16410/Reviewer_wrRH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16410/Reviewer_wrRH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761539830157, "cdate": 1761539830157, "tmdate": 1762926529169, "mdate": 1762926529169, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FALSE-VFL, a deep latent variable model (DLVM) based framework for Vertical Federated Learning (VFL) that treats feature misalignment as a missing-data problem. The method supports arbitrary alignment patterns (aligned, partially aligned, fully unaligned), labeled and unlabeled data, and all three missingness mechanisms (MCAR, MAR, MNAR). It handles multi-party VFL and both training-time and inference-time unaligned data. Experiments show that FALSE-VFL outperforms baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- **Unified framework:** Handles arbitrary data alignment, missing labels, multiple missingness mechanisms, and multi-party collaboration simultaneously.\n\n- **Effective two-stage optimization:** Pretraining on marginal likelihood, freezing generative parameters avoids joint-likelihood imbalance and allows leveraging large amounts of unlabeled data.\n\n- **Comprehensive evaluations:** Evaluated on 168 combinations, with additional ablations on missing rate, number of parties, and data heterogeneity."}, "weaknesses": {"value": "- **Computational and communication cost not analyzed:** DLVM-based training and multi-party posterior communication likely introduce overhead, but no runtime or bandwidth comparison is provided.\n\n- **Scalability concerns:** Experiments use small-to-moderate datasets and up to 12 parties; unclear how the approach scales to high-dimensional data or more clients.\n\n- **Privacy risks not evaluated:** Since encoder outputs are exchanged, a discussion of representation leakage or compatibility with secure computation would strengthen claims about practical VFL deployment.\n\n- **Synthetic missingness patterns:** MAR and MNAR mechanisms are plausible but not clearly tied to real VFL scenarios; more realistic alignment patterns would strengthen empirical validity."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)"]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Zh7Rwhr4vj", "forum": "qCM2vo896B", "replyto": "qCM2vo896B", "signatures": ["ICLR.cc/2026/Conference/Submission16410/Reviewer_wrRH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16410/Reviewer_wrRH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761539830157, "cdate": 1761539830157, "tmdate": 1763510183541, "mdate": 1763510183541, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FALSE-VFL, a deep latent variable model (DLVM) based framework for Vertical Federated Learning (VFL) that treats feature misalignment as a missing-data problem. The method supports arbitrary alignment patterns (aligned, partially aligned, fully unaligned), labeled and unlabeled data, and all three missingness mechanisms (MCAR, MAR, MNAR). It handles multi-party VFL and both training-time and inference-time unaligned data. Experiments show that FALSE-VFL outperforms baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- Handles arbitrary data alignment, missing labels, multiple missingness mechanisms, and multi-party collaboration simultaneously.\n\n-  Pretraining on marginal likelihood, freezing generative parameters avoids joint-likelihood imbalance and allows leveraging large amounts of unlabeled data.\n\n- Evaluated on 168 combinations, with additional ablations on missing rate, number of parties, and data heterogeneity."}, "weaknesses": {"value": "- DLVM-based training and multi-party posterior communication likely introduce overhead, but no runtime or bandwidth comparison is provided.\n\n- Experiments use small-to-moderate datasets and up to 12 parties; unclear how the approach scales to high-dimensional data or more clients.\n\n- Since encoder outputs are exchanged, a discussion of representation leakage or compatibility with secure computation would strengthen claims about practical VFL deployment.\n\n- MAR and MNAR mechanisms are plausible but not clearly tied to real VFL scenarios; more realistic alignment patterns would strengthen empirical validity."}, "questions": {"value": "Please see the weaknesses."}, "flag_for_ethics_review": {"value": ["Yes, Privacy, security and safety", "Yes, Legal compliance (e.g., GDPR, copyright, terms of use, web crawling policies)"]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Zh7Rwhr4vj", "forum": "qCM2vo896B", "replyto": "qCM2vo896B", "signatures": ["ICLR.cc/2026/Conference/Submission16410/Reviewer_wrRH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16410/Reviewer_wrRH"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761539830157, "cdate": 1761539830157, "tmdate": 1763747762873, "mdate": 1763747762873, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes FALSE-VFL, a deep latent variable model (DLVM) framework designed for vertical federated learning (VFL). The core idea is to reframe VFL alignment gaps as a blockwise missing data problem. This approach allows the model to handle arbitrary data alignment, leverage abundant unlabeled data, and support multi-party collaboration. The method employs a two-stage optimization: (1) an unsupervised, generative pretraining phase to learn a robust data representation from all samples, and (2) a supervised training phase to learn a predictor from the scarce labeled data . The paper introduces two variants, FALSE-VFL-I for MAR and FALSE-VFL-II for MNAR settings , and demonstrates state-of-the-art performance across 168 experimental configurations"}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "S1. The paper tackles a critical and highly practical challenge in VFL. The assumptions that data alignment is imperfect and labels are scarce are far more realistic than in typical VFL literature.\n\nS2. This is a unified framework that addresses multi-party VFL, arbitrary (blockwise) data missingness, and semi-supervised learning. The explicit handling of all three missingness mechanisms (MCAR, MAR, and MNAR) is a significant contribution.\n\nS3. The experimental results are extensive and compelling. The method's dominance in 160 out of 168 configurations, with a large average performance gap over the next-best competitor, provides strong evidence of its effectiveness.\n\nS4. The method shows admirable robustness not only to different types and degrees of missingness but also to an increasing number of parties and data heterogeneity, both of which are common challenges in real-world VFL systems."}, "weaknesses": {"value": "W1. The writing in the methodology section (Section 3) could be significantly improved. The paper is not self-contained and is difficult to follow without prior knowledge of the cited works (e.g., IWAE, Ipsen et al., 2022).\n* For instance, the paper states, \"so we need some tricks as in IWAE\" but fails to explain the intuition behind this \"trick\" (i.e., importance-weighted sampling as a variational lower bound).\n* Similarly, the derivation of the lower bound $\\mathcal{L}_{\\kappa}$ omits the key appeal to Jensen's Inequality, which is fundamental to understanding why it is a lower bound. While this proof is in the appendix, its absence in the main text makes the core methodology less accessible.\n\nW2. The paper proposes two distinct solutions: FALSE-VFL-I for MAR and FALSE-VFL-II for MNAR . This separation is a practical weakness. In real-world scenarios, the true missingness mechanism is rarely known in advance. A practitioner would not know whether to deploy model I or model II. A more robust and unified framework that could handle (or even infer) the missingness mechanism automatically, without requiring this a priori assumption, would be a significant improvement.\n\n**Minor Comments**\n\nC1. The paper consistently and incorrectly refers to its Appendices as \"Sections\" in the main text. For example, \"described in Section A.2\" , \"explained in Section B\" , and \"See Section C for details\". \n\nC2. Equation Numbering: Several key equations in the main methodology (Section 3.4) are not numbered. Numbering these equations would make the method much easier to follow and reference.\n\nC3. The meaning of $z_j$ is not explicitly explained in the main paper. The paper would be clearer if it explicitly stated that these are the $j$-th samples (out of $\\kappa$) drawn from the approximate posterior distributions.\n\nC4. The meaning of the indices for the missingness mechanisms is not fully explained in the main paper. While MCAR 0/2/5 and MNAR 7/9 are clearly defined in Section 5.1 as referring to probabilities, the crucial distinction between MAR 1 and MAR 2 is not. The main text only states that \"Precise formulas are given in Section D.4\". For the paper to be self-contained, a brief, one-sentence summary of what \"MAR 1\" and \"MAR 2\" represent should be included in Section 5.1."}, "questions": {"value": "See weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "kdV3UkFcbW", "forum": "qCM2vo896B", "replyto": "qCM2vo896B", "signatures": ["ICLR.cc/2026/Conference/Submission16410/Reviewer_JZzY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16410/Reviewer_JZzY"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761643161624, "cdate": 1761643161624, "tmdate": 1762926528689, "mdate": 1762926528689, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces FALSE-VFL (Flexible Alignment and Labeling Scenarios Enabled Vertical Federated Learning), a unified probabilistic framework for vertical federated learning (VFL) that can operate under arbitrary combinations of data alignment and labeling conditions. The method models feature, label, and alignment missingness jointly using a Deep Latent Variable Model (DLVM) and formalizes training under MCAR, MAR, and MNAR mechanisms. Experiments on multiple datasets show that FALSE-VFL consistently outperforms existing methods."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper addresses an important limitation of current VFL research, where some methods assume perfect alignment and full labeling. 2. Treating alignment and labeling gaps as missing-data problems and modeling them jointly within a probabilistic latent-variable framework is a conceptually coherent way to generalize VFL beyond idealized settings. \n3. The experiments are comprehensive, covering many combinations of training and testing conditions, and they demonstrate robust performance improvements. \n4. The paper is clearly written and well-motivated."}, "weaknesses": {"value": "1. The paper's main limitation lies in the originality of its methodological foundation. The proposed DLVM-based framework for modeling unaligned, unlabeled, and partially observed data in VFL largely parallels the broader line of work on robust FL already explored in horizontal settings. Prior studies [R1-R3] have developed principled approaches for robustness under heterogeneous, noisy, or distributionally shifted clients. While these works operate under horizontal data partitioning, they share the same conceptual goal as FALSE-VFL: learning representations and aggregation mechanisms that remain stable in the presence of incomplete or inconsistent local data.\n\nR1: Robust Federated Learning With Noisy and Heterogeneous Clients, CVPR, 2022\n\nR2: Robust Federated Learning: The Case of Affine Distribution Shifts, NeurIPS, 2020\n\nR3: A Systematic Literature Review of Robust Federated Learning: Issues, Solutions, and Future Research Directions, ACM Computing Survey, 2025\n\n2. Compared with these precedents, the present paper’s innovation lies mainly in applying the robustness principle to vertical feature partitions using deep latent-variable modeling, rather than proposing a fundamentally new robustness mechanism. The model treats missing features, labels, and alignment as latent variables and marginalizes them via variational inference. While this probabilistic formulation is elegant, the underlying idea of achieving federated robustness through representation consistency is well established. The paper does not provide theoretical or empirical evidence that the DLVM approach offers advantages over alternative robustness strategies such as adversarial minimax optimization or noise-weighted aggregation.\n\n3. The framework implicitly assumes that some aligned or labeled samples exist to anchor the shared latent space. This reliance makes the method closer to pseudo-matching alignment strategies than to fully unsupervised alignment inference. The empirical evaluation demonstrates broad coverage but remains descriptive; ablation studies isolating the contributions of missingness modeling or pretraining are limited."}, "questions": {"value": "1. The paper’s design philosophy seems to resemble prior robust FL methods. Can you clarify what new robustness mechanism is introduced by FALSE-VFL beyond adopting a deep latent-variable model for the vertical setting?\n2. Could the proposed probabilistic modeling of missingness be replaced by other robustness strategies, such as adversarial or confidence-weighted training, and if so, what unique advantage does the DLVM formulation offer?\n3. Does the method require a subset of aligned or labeled samples to establish a shared latent representation? If none are available, how would the model avoid degenerate alignment?\n4. Can you provide empirical or theoretical evidence that the probabilistic marginalization approach improves robustness relative to prior adversarial or reweighting-based techniques?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "BLzNsEViaK", "forum": "qCM2vo896B", "replyto": "qCM2vo896B", "signatures": ["ICLR.cc/2026/Conference/Submission16410/Reviewer_nHhw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16410/Reviewer_nHhw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16410/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761932517424, "cdate": 1761932517424, "tmdate": 1762926528294, "mdate": 1762926528294, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}