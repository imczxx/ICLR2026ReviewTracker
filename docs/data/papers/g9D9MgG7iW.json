{"id": "g9D9MgG7iW", "number": 24092, "cdate": 1758352650501, "mdate": 1759896782031, "content": {"title": "Tools are under-documented: Simple Document Expansion Boosts Tool Retrieval", "abstract": "Large Language Models (LLMs) have recently demonstrated strong capabilities in tool use, yet progress in tool retrieval remains hindered by incomplete and heterogeneous tool documentation. \nTo address this challenge, we introduce Tool-DE, a new benchmark and framework that systematically enriches tool documentation with structured fields to enable more effective tool retrieval, together with two dedicated models, Tool-Embed and Tool-Rank. We design a scalable document expansion pipeline that leverages both open- and closed-source LLMs to generate, validate, and refine enriched tool profiles at low cost, producing large-scale corpora with 50k instances for embedding-based retrievers and 200k for rerankers. On top of this data, we develop two models specifically tailored for tool retrieval: Tool-Embed, a dense retriever, and Tool-Rank, an LLM-based reranker. Extensive experiments on ToolRet and Tool-DE demonstrate that document expansion substantially improves retrieval performance, with Tool-Embed and Tool-Rank achieving new state-of-the-art results on both benchmarks. We further analyze the contribution of individual fields to retrieval effectiveness, as well as the broader impact of document expansion on both training and evaluation. Overall, our findings highlight both the promise and limitations of LLM-driven document expansion, positioning Tool-DE, along with the proposed Tool-Embed and Tool-Rank, as a foundation for future research in tool retrieval.", "tldr": "We introduce Tool-DE, a document-expansion benchmark with two tailored models (Tool-Embed, Tool-Rank) that achieve state-of-the-art tool retrieval and provide a foundation for future research.", "keywords": ["tool retrieval", "information retrieval"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/ed7249df79a5473d402c20f94dc9a0a22398d48e.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper tackles a problem in tool retrieval, real tools often have incomplete descriptions, which hurts both retrievers and rerankers. The authors aggregate multiple sources of tool-use data and propose a four-stage, LLM-assisted document expansion pipeline that adds structured fields (e.g., function, when to use, limitations, tags). They then fine-tune a dense retriever and a reranker on these expanded docs."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. A practical, scalable pipeline with sensible checks.\n2. Consistent gains, plus field-level ablations that give actionable advice.\n3. Clear look at when expansion helps (train vs. eval); rerankers seem to benefit most when expanded views are present."}, "weaknesses": {"value": "1. Training on your own expanded corpus and evaluating on the expanded view makes strong gains somewhat expected. The non-expanded results help, but an additional external/unexpanded test would make the case stronger.\n2. Only random negatives during training. Adding hard negative mining would be helpful.\n3. Documenting how duplicates/near-duplicates were removed across train/val/test after expansion, and report any impact on scores will be more helpful.\n4. For human validation, authors should consider a random sample across all stages, report agreement, and provide an error taxonomy.\n5. End-to-end throughput and cost (e.g. tokens, $) for generation, judgment, and refinement would help gain more insights."}, "questions": {"value": "1. What happens when you train with mined hard negatives?\n2. How do you handle deduplication and near-duplicate filtering across splits after expansion?\n3. Can you share the end-to-end expansion cost/throughput and per-stage success/failure rates?\n4. Beyond the reported non-expanded benchmark, can you add another unexpanded corpus or a held-out unexpanded slice to test robustness to documentation style?\n5. You state that rerankers benefit more under expanded views. Can you keep the retrieval top-K fixed and rerank twice, once with original docs and once with expanded docs, to isolate the pure evaluation-time effect of expansion on the reranker?\n6. The ablation results and the final released field set don’t seem fully aligned. Could you reconstruct this section and reconcile the ablation findings with the fields you keep/drop, including the supporting numbers?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WknEvXIaVa", "forum": "g9D9MgG7iW", "replyto": "g9D9MgG7iW", "signatures": ["ICLR.cc/2026/Conference/Submission24092/Reviewer_wGrF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24092/Reviewer_wGrF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761202004548, "cdate": 1761202004548, "tmdate": 1762942933753, "mdate": 1762942933753, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the problem of under-documentation of tool APIs. Specifically, as the authors mentioned, current API documents often lack standardization and critical information. To solve this problem, the authors propose a pipeline for API documentation augmentation. They apply the proposed pipeline on ToolRet to construct a new dataset, ToolDE. And the authors train one embedding model and one reranking model on ToolDE. The evaluation results demonstrate that augmenting documentation is beneficial. And training with standardized documentation leads to better retreival performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The studied problem is interesting and valuable. Indeed, the quality of API documents often has high variance. Standardization of them is expected to be valuable.\n2. The paper is well written and easy to follow."}, "weaknesses": {"value": "1. The proposed pipeline for augmenting API documentation involves human annotation, which makes it hard to scale up. \n2. According to Table 1, I find that the improvement of augmenting documentation without training is limited, especially for Qwen3-Embedding series. There is even a performance drop after augmenting the documentation, which makes me doubt the solidity of the motivation of this work.\n3. Following the second point, it would be more valuable for applications if direct augmentation without training could lead to performance improvement. In real-world applications, APIs are often evolving. It is costly to augment new API documentations and train a new embedding model each time. Yet, as I mentioned in the second weakness, I find the direct improvement of augmentation is limited, which significantly limits the contribution of this work.\n4. To demonstrate the generalization of augmenting documentation, the authors should train embedding models other than Qwen series on ToolDE."}, "questions": {"value": "Please see my comments above."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3p2uGWN8db", "forum": "g9D9MgG7iW", "replyto": "g9D9MgG7iW", "signatures": ["ICLR.cc/2026/Conference/Submission24092/Reviewer_qnbA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24092/Reviewer_qnbA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761706348076, "cdate": 1761706348076, "tmdate": 1762942933480, "mdate": 1762942933480, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper tackles an underexplored yet critical problem in tool-augmented LLM systems — the poor quality and inconsistency of tool documentation, which limits accurate tool retrieval. The authors introduce TOOL-DE (Tool-Document Expansion), a benchmark and framework that systematically enriches tool documentation through LLM-based expansion. Their pipeline generates structured fields (e.g., function description, when to use, limitations, and tags) via multi-stage prompting, validation, and human checking, yielding large-scale, standardized tool profiles. On top of this, they build two dedicated models: Tool-Embed (a dense retriever) and Tool-Rank (a reranker), trained on 50k and 200k examples respectively. Experiments across the TOOL-DE and ToolRet benchmarks show significant improvements in retrieval quality, achieving new state-of-the-art results (e.g., NDCG@10 = 56.44, Recall@10 = 67.81). Analysis further confirms that document expansion improves both training and evaluation by reducing semantic gaps, enhancing discriminability, and stabilizing optimization."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The benchmark is comprehensive. TOOL-DE is built over 35 datasets with a carefully validated expansion process, combining open and closed models (Qwen3, LLaMA-3.1, GPT-4o) and human checks. \n2. Experiments show solid improvements. Both retriever and reranker consistently outperform strong baselines, demonstrating that simple, well-structured enrichment can yield significant improvements.\n3. The paper is well-written and easy to follow."}, "weaknesses": {"value": "1. The manuscript lacks a clear and comprehensive description of the dataset. While some details are provided in the appendix, it would significantly improve clarity and reproducibility to include a dedicated section in the main text describing the dataset composition (e.g., number and types of tools, instances per tool, data sources, and preprocessing steps).\n2. The training and testing splits is insufficiently explained. The paper shows the proposed pipeline works well when train and test on the same set of tools. Without a detailed account of how the splits are defined, it is difficult to assess whether the proposed approach effectively generalizes to unseen tools. This consideration is particularly important, as in real-world scenarios the set of available tools is dynamic and evolves continuously.\n\nA relevant paper that might be included in the related works: [Planning and Editing What You Retrieve for Enhanced Tool Learning](https://aclanthology.org/2024.findings-naacl.61/) (Huang et al., Findings 2024)"}, "questions": {"value": "See above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "IPMsyJvGCG", "forum": "g9D9MgG7iW", "replyto": "g9D9MgG7iW", "signatures": ["ICLR.cc/2026/Conference/Submission24092/Reviewer_qfqi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24092/Reviewer_qfqi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762057103424, "cdate": 1762057103424, "tmdate": 1762942933226, "mdate": 1762942933226, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors introduce TOOL-DE, a new framework that systematically enriches tool documentation with structured fields to enable more effective tool retrieval. The framework expands the tool documents by using structured fields like function description, when-to-use, limitations, and trains a dedicated retriever and reranker on top of the expanded documents. The experimental results show the effectiveness of tool expansion as well as the trained retriever and reranker."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The paper effectively addresses the limitations of current tool learning paradigm where existing tool documents are underspecified for effective tool retrieval by using the idea of tool expansion using LLM which shows strong emperical results with and without dedicated trained retrievers and rerankers.\n- It is an end-to-end framework where they create a tool document dataset and train the retriever and reranker. \n- The paper includes extensive ablations studies on impact of each field of expanded document in tool retrieval and how this affects the tool retrieval similarity"}, "weaknesses": {"value": "- While the framework shows strong performance, the idea of revising or augmenting the tool documents has been explored by the previous works [1,2]. \n- To make the data generation more scalable, one might consider replacing human verification to using a strong LLM\n\n\n[1] Huang et al, Planning and Editing What You Retrieve for Enhanced Tool Learning. NAACL 2024 \\\n[2] Chen et al, EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction. ACL 2025"}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "saxotz1twA", "forum": "g9D9MgG7iW", "replyto": "g9D9MgG7iW", "signatures": ["ICLR.cc/2026/Conference/Submission24092/Reviewer_81wM"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24092/Reviewer_81wM"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24092/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762227103310, "cdate": 1762227103310, "tmdate": 1762942932949, "mdate": 1762942932949, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}