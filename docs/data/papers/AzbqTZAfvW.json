{"id": "AzbqTZAfvW", "number": 15822, "cdate": 1758255721271, "mdate": 1762941403880, "content": {"title": "iLRM: An Iterative Large 3D Reconstruction Model", "abstract": "Feed-forward 3D modeling has emerged as a promising approach for rapid and high-quality 3D reconstruction.\nIn particular, directly generating explicit 3D representations, such as 3D Gaussian splatting, has attracted significant attention due to its fast and high-quality rendering, as well as numerous applications.\nHowever, many state-of-the-art methods, primarily based on transformer architectures, suffer from severe scalability issues because they rely on full attention across image tokens from multiple input views, resulting in prohibitive computational costs as the number of views or image resolution increases.\nToward a scalable and efficient feed-forward 3D reconstruction, we introduce an iterative Large 3D Reconstruction Model (*iLRM*) that generates 3D Gaussian representations through an iterative refinement mechanism, guided by three core principles: (1) decoupling the scene representation from input-view images to enable *compact 3D representations*; (2) decomposing fully-attentional multi-view interactions into a *two-stage attention* scheme to reduce computational costs; and (3) injecting *high-resolution information at every layer* to achieve high-fidelity reconstruction. Experimental results on widely used datasets, such as RE10K and DL3DV, demonstrate that iLRM outperforms existing methods in both reconstruction quality and speed.", "tldr": "iLRM is a scalable feed-forward 3D reconstruction model that overcomes the inefficiency of prior Gaussian-based approaches when handling many views or high-resolution inputs.", "keywords": ["Feed-forward 3D reconstruction", "3D Gaussian Splatting", "Multi-view geometry"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Withdrawn Submission", "pdf": "/pdf/bd9903386d850ea84b0aaf0f4d12164aad54a4ab.pdf", "supplementary_material": "/attachment/9f2b2ad4dea1f70d6ae1e5aac57d68d32e417f9a.zip"}, "replies": [{"content": {"summary": {"value": "his work proposes an iterative Large 3D Reconstruction Model, a feed-forward architecture that reflects per-scene optimization-based schemes. It introduces an efficient token update mechanism to enable iterative optimization of 3DGS and compression under dense views."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. This work is well-written, and the description of the methodology section is clear.\n\n2. It addresses an important problem, scalability issues in feed-forward 3DGS reconstruction. Compared to previous works, it effectively compresses the number of Gaussians under dense view inputs."}, "weaknesses": {"value": "1. The term 'iterative' in the paper's title is difficult to understand. If I understand correctly, it is more similar to stacking attention blocks, following the scaling law, as shown in Table 7. Additionally, apart from Figure 1, the paper lacks more qualitative validation of 'iterative refinement.'\n\n2. If I understand correctly, the core of iLRM lies in introducing view embeddings as tokens to be updated for reconstructing 3DGS (from Fig2(a) to Fig2(b)), thereby improving the efficiency of attention blocks and compressing the number of Gaussians. This does not bring new insights to the field and appears similar to the approach of LVSM [1], which is also used for feed-forward novel view synthesis tasks.\n\n[1] LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias\n\n3. The paper does not include a performance comparison with LVSM [1].\n\n4. The paper lacks discussion on how to select the shape of the updated tokens tensor, which is important for iLRM. If they are manually set as hyperparameters, then performance may degrade for complex scenes that require more Gaussians.\n\n5. The paper lacks a detailed description of the baseline in the ablation experiments. It is confusing that the baseline achieves better results. This section should discuss the performance of the initial framework without any of the proposed modules."}, "questions": {"value": "1. Why does Figure 1 show that iLRM's performance improvement is significant as the number of layers increases, while Table 7 shows only marginal gains?\n\n2. Why does iLRM appear to be faster with larger model parameters while having the same number of Gaussians in Table 1?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ttT8CrOwr6", "forum": "AzbqTZAfvW", "replyto": "AzbqTZAfvW", "signatures": ["ICLR.cc/2026/Conference/Submission15822/Reviewer_RdKH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15822/Reviewer_RdKH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15822/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761403730640, "cdate": 1761403730640, "tmdate": 1762926050310, "mdate": 1762926050310, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"withdrawal_confirmation": {"value": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}}, "id": "dzzv0i4rYs", "forum": "AzbqTZAfvW", "replyto": "AzbqTZAfvW", "signatures": ["ICLR.cc/2026/Conference/Submission15822/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission15822/-/Withdrawal"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762938480258, "cdate": 1762938480258, "tmdate": 1762938480258, "mdate": 1762938480258, "parentInvitations": "ICLR.cc/2026/Conference/-/Withdrawal", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces iLRM, an iterative 3D reconstruction model that overcomes the severe scalability issues of previous feed-forward methods by decoupling the scene representation from the input images."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The model introduces an efficient two-stage attention mechanism that breaks the quadratic complexity bottleneck of prior methods. This allows it to effectively process a larger number of views and higher-resolution images without prohibitive computational costs.\n\n2. iLRM reframes reconstruction as an iterative refinement process within a feed-forward network and achieves good reconstruction quality on standard benchmarks."}, "weaknesses": {"value": "1. This paper only shows 2D novel view synthesis metrics like PSNR, SSIM, which are all about image quality. However, when it comes to reconstruction, the geometry is also very important. CD, F-score and similar metrics should be included.\n2. No mesh reconstruction results. Showing conversion to a mesh would have better showcased the coherence of the underlying geometry and its practical applicability for downstream tasks like gaming or simulation.\n3. Lack of comparison with feed-forward reconstruction methods like VGGT and its follow-ups.\n4. Lack of novelty. Using cross-attention and similar methods to replace self-attention is a common technic for saving memory."}, "questions": {"value": "See Weaknesses. More results about geometry reconstruction and comparison with VGGT should be given."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "lPzrXEobC5", "forum": "AzbqTZAfvW", "replyto": "AzbqTZAfvW", "signatures": ["ICLR.cc/2026/Conference/Submission15822/Reviewer_Twfa"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15822/Reviewer_Twfa"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission15822/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761755086912, "cdate": 1761755086912, "tmdate": 1762926049810, "mdate": 1762926049810, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces iLRM, an optimized version of LRM mainly focusing on improving compute efficiency. iLRM utilizes many customization on original full attention layers from LRM to reduce its quadratic cost. iLRM also employs the concept of iterative refinement to guide their model design. The quality and efficiency improvements are effective as demonstrated in the evaluation results."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "Decoupling representations and staged attention effectively tackle quadratic costs in multi-view processing, enabling more views (e.g., 8 vs. baselines' 2-4) with lower compute/memory. This new way of handling view-camera interaction could be helpful to reduce compute cost of general multi-view transformer models."}, "weaknesses": {"value": "* While the concept of iterative refinement is nice and interesting, it is reluctant to say the current model design has a strong connection to the iterative refinement, especially the claimed “feedback-driven refinement” (L93). Since the LRM usually just stacks of attention block processing on the same series of tokens, one can also say that the tokens are “iteratively refined” block by block. The paper fails to convincingly show this decoupled representation enables unique iterative refinement. \n* The proposed “token uplifting” is a trivial design for many cross-attention applications with unmatched channel dimensions of tokens. \n* The mini-batch cross-attention is conceptually very similar to dropout operations. If so, simply introducing this part as a special dropout might be better. It is unnecessary to create such a new concept."}, "questions": {"value": "None"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "eUDumzCKp3", "forum": "AzbqTZAfvW", "replyto": "AzbqTZAfvW", "signatures": ["ICLR.cc/2026/Conference/Submission15822/Reviewer_VqXS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission15822/Reviewer_VqXS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission15822/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761779163252, "cdate": 1761779163252, "tmdate": 1762926049284, "mdate": 1762926049284, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": true}