{"id": "cBoYkLG3EJ", "number": 23597, "cdate": 1758346078443, "mdate": 1759896805580, "content": {"title": "EvolProver: Advancing Automated theorem proving by Evolving Formalized Problems via Symmetry and Difficulty", "abstract": "Large Language Models (LLMs) for formal theorem proving have shown significant promise, yet they often lack generalizability and are fragile to even minor transformations of problem statements. To address this limitation, we introduce a novel data augmentation pipeline designed to enhance model robustness from two perspectives: symmetry and difficulty. From the symmetry perspective, we propose two complementary methods: **EvolAST**, an Abstract Syntax Tree (AST) based approach that targets syntactic symmetry to generate semantically equivalent problem variants, and **EvolDomain**, which leverages LLMs to address semantic symmetry by translating theorems across mathematical domains. From the difficulty perspective, we propose **EvolDifficulty**, which uses carefully designed evolutionary instructions to guide LLMs in generating new theorems with a wider range of difficulty. We then use the evolved data to train **EvolProver**, a 7B-parameter non-reasoning theorem prover. EvolProver establishes a new state-of-the-art (SOTA) on FormalMATH-Lite with a 53.8\\% pass@32 rate, surpassing all models of comparable size, including reasoning-based models. It also sets new SOTA records for non-reasoning models on MiniF2F-Test (69.8\\% pass@32), Ineq-Comp-Seed (52.2\\% pass@32), and Ineq-Comp-Transformed (34.0\\% pass@32). Ablation studies further confirm our data augmentation pipeline's effectiveness across multiple benchmarks.", "tldr": "", "keywords": ["Formal Theorem Proving", "AI4Math", "LLM4Math", "Automated Theorem Proving", "Prover"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/fac5664eda370b24fd7b40935cbd85288d3b1723.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper presents EvolProver, a 7B-parameter non-reasoning theorem prover enhanced through a novel data augmentation pipeline that addresses both symmetry and difficulty aspects of formalized mathematical problems. The pipeline consists of three complementary methods: EvolAST for syntactic symmetry transformation, EvolDomain for cross-domain semantic symmetry, and EvolDifficulty for generating problems with varying difficulty levels. Experimental results demonstrate that EvolProver achieves good performance on multiple benchmarks, including FormalMATH-Lite (53.8% pass@32), MiniF2F-Test (69.8% pass@32), and Ineq-Comp datasets, outperforming comparable non-reasoning models and even some reasoning-based models while using significantly fewer tokens."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The proposed data augmentation pipeline demonstrates a novel and systematic approach to improving model generalizability by addressing both syntactic and semantic symmetry, as well as difficulty variation, which is a comprehensive solution to the fragility issue in formal theorem proving.​\n2. The ablation studies and controlled experiments effectively validate the contribution of each component in the pipeline, showing consistent performance improvements across multiple benchmarks and training stages."}, "weaknesses": {"value": "1. The performance advantage of EvolProver over DeepSeek-Prover-V2-7B-non-CoT on MiniF2F-Test is relatively modest (69.8% vs 68.0±0.5%), while DeepSeek-Prover-V2-7B-non-CoT uses fewer average tokens, raising questions about the practical significance of the improvement.​\n2. The case study in Figure 1 does not clearly demonstrate how the augmented dataset helps solve problems that were previously unsolvable, making it difficult to assess the qualitative impact of the data augmentation.​\n3. The ablation experiments do not include a detailed analysis of how each component contributes to performance on different mathematical domains, which would help understand the specific strengths of each augmentation method."}, "questions": {"value": "1. Why wasn't DeepSeek-Prover-V2-7B-non-CoT included in the comparisons for FormalMATH and Ineq-Comp benchmarks, given its strong performance on MiniF2F-Test? Including these comparisons would provide a more comprehensive evaluation of EvolProver's capabilities across different benchmarks.​\n2. The example shown in Figure 1 appears to involve relatively minor tactic changes in Lean that may not significantly affect the proof difficulty. Could you provide more case studies demonstrating specific instances where the augmented dataset enabled EvolProver to solve problems that the baseline model (EvolProver-Base) or other state-of-the-art models could not solve?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "1Kzx8nfbYL", "forum": "cBoYkLG3EJ", "replyto": "cBoYkLG3EJ", "signatures": ["ICLR.cc/2026/Conference/Submission23597/Reviewer_fmUh"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23597/Reviewer_fmUh"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761763492985, "cdate": 1761763492985, "tmdate": 1762942729539, "mdate": 1762942729539, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes three data augmentation methods for formal mathematics statements based on symmetry and difficulty. EvolAST: apply seven prewritten transformation rules at random on the theorem’s AST to produce logically equivalent variants; EvolDomain: translate problems across different domains while preserving their core logic, guided by evolutionary instructions for the LLM to perform the conversions; EvolDifficulty: use an LLM with instructions to adjust the difficulty of existing theorems and generate statements at varying difficulty levels. Using this pipeline to augment public datasets (e.g., STP and DeepSeek Prover V1) and training on DeepSeek Prover V1.5 base, the authors build EvolProver. Experiments show strong performance the proposed model among non-CoT 7B ATP models."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed EvolAST method is novel: it leverages Lean 4 features in an intuitive and effective way. The results in Table 2 on the Ineq-Comp dataset show that this augmentation can substantially mitigate non-CoT provers’ fragility to the specific form of a statement.\n\n2. From Figure 5, the EvolDomain approach appears to significantly alleviate the concentration of formal-statement datasets in algebra and number theory. This may be valuable for improving ATP generalization across different mathematical domains.\n\n3. The ablation study is thorough. Table 4 presents multiple combinations of SFT, RL, and different augmentation methods, providing useful insight into which components are effective. The comparison between directly augmenting formal data and the more traditional approach of augmenting natural-language data first and then translating it is also a useful addition.\n\n4. Figures and tables are clear and easy to understand, and the paper is well written overall."}, "weaknesses": {"value": "1. Choice of an old base model and non-CoT approach, which appears unnecessary and hard to justify. The paper trains EvolProver on a non-CoT DeepSeek V1.5 7B model. The three proposed data-augmentation methods should in principle be directly applicable to CoT-style models (e.g., DeepSeek Prover v2 or Goedel Prover v2), so restricting experiments to a non-CoT, relatively old base model limits the relevance of the work given that much of the recent ATP community has shifted to CoT-capable reasoning models. EvolProver’s performance is still substantially weaker than contemporary reasoning models. The authors should further explain why they chose a non‑CoT model and an older base model.\n2. Small amount of synthesized data and no cost analysis. The amount of augmented/synthesized data is relatively small and the paper does not discuss the cost of data synthesis. Line 653 states that the pool of publicly available datasets used is 3.3 million examples, but only 39.2k examples were synthesized (Line 665). The authors do not explain the roughly two-order-of-magnitude gap (e.g., due to cost or filtering?), nor do they provide analysis of synthesis cost, token usage, or API expenses.\n3. Missing proportions of original vs. augmented data in SFT and RL. The paper does not report the ratio of original to augmented examples during supervised fine-tuning (SFT) and reinforcement learning (RL), which hurts reproducibility. Given the large disparity in size between the original and augmented datasets, the mixing ratio is an important experimental detail and should be provided.\n4. Minor writing and presentation issues (do not affect readability but should be fixed to improve manuscript quality)\n\n- Line 124: missing space before a citation.\n- Lines 143, 153, 227: inconsistent capitalization of “Lean4” vs. “Lean 4”; terms should be made consistent.\n- Table 4 and Table 5 appear to contain the same content and may be duplicated.\n- Related work: the survey of data-augmentation methods focuses on informal mathematics; the authors should also cover data-augmentation methods specific to formal mathematics. (eg., STP and Ineq-Comp)\n\n##"}, "questions": {"value": "1. Can the three proposed augmentation methods be applied to chain-of-thought reasoning models? What obstacles might arise from directly applying them to CoT-style reasoning models? The paper claims that current provers are fragile to even minor transformations of problem statements — does this fragility persist in contemporary reasoning provers like Deepseek Prover v2 or Geodel Prover v2?\n\n2. Line 142 states that EvolAST is introduced \"to mitigate this issue (the inevitable introduction of syntactic or semantic errors),\" yet Figure 2 places the EvolAST process after EvolDomain and EvolDifficulty. This ordering seems odd: errors can propagate, so a theorem that becomes semantically incorrect (e.g., unprovable) after EvolDomain or EvolDifficulty would not be fixed by applying EvolAST afterward. Please provide further explanation for this pipeline ordering and clarify how EvolAST mitigates syntactic/semantic errors introduced by earlier stages."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Yi1HUb58GZ", "forum": "cBoYkLG3EJ", "replyto": "cBoYkLG3EJ", "signatures": ["ICLR.cc/2026/Conference/Submission23597/Reviewer_RmgK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23597/Reviewer_RmgK"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761817297488, "cdate": 1761817297488, "tmdate": 1762942729115, "mdate": 1762942729115, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents a data augmentation pipeline aimed at improving the robustness and generalization of large language models (LLMs) for formal theorem proving. The proposed system combines three key modules:\n\n* EvolAST – syntactic augmentation using Abstract Syntax Tree-based transformations that preserve semantics while changing structure;\n\n* EvolDomain – semantic augmentation by translating theorems across mathematical domains (e.g., geometry ↔ algebra) using LLMs;\n\n* EvolDifficulty – difficulty modulation via evolutionary instructions to generate problems of varying complexity.\n\nAfter automated verification, the augmented data is used to train EvolProver, a 7B-parameter non-reasoning model that achieves new SOTA performance on multiple formal math benchmarks (e.g., FormalMATH-Lite, MiniF2F, Ineq-Comp). Ablations confirm each augmentation’s benefit. The approach focuses on data diversity rather than architectural changes."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. Practical and well-motivated. They address a real problem on the fragility and poor generalization of theorem-proving LLMs, and the strategy they use (data-centric improvements) is simple but effective, much easier than building a reasoning model in practice.\n\n2. Systematic pipeline design. The decomposition into syntactic (EvolAST), semantic (EvolDomain), and difficulty-based (EvolDifficulty) augmentations is both intuitive and well-structured.\n\n3. Results are good. The model achieves consistent SOTA performance across diverse benchmarks, including non-reasoning categories where size-matched baselines are surpassed. They can achieve even pretty close performance compared to the SOTA reasoning model baselines. Ablations studies convince us into believing that the pipeline really helps, rather than overfitting to artifacts."}, "weaknesses": {"value": "1. The paper remains more empirical than theoretical, as there's no deeper analysis of why the augmentations help, or how they relate to reasoning robustness.\n\n2. There comes concerns on whether or not the framework relies on LLM-generated data too much. EvolDomain and EvolDifficulty both depend on LLM quality, thus risk subtle semantic drift or spurious logic, which might not be fully detected by verification.\n\n3. Only benchmarks with formal Lean-style problems are tested, how robust the framework is when generalizing to other theorem systems, or other symbolic reasoning datasets?\n\n4. The term \"evolutionary\" may be overstated a little bit?"}, "questions": {"value": "Addressing the questions mentioned in the weakness points should be enough."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3hVwPf0Zq6", "forum": "cBoYkLG3EJ", "replyto": "cBoYkLG3EJ", "signatures": ["ICLR.cc/2026/Conference/Submission23597/Reviewer_7CuZ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23597/Reviewer_7CuZ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761877556945, "cdate": 1761877556945, "tmdate": 1762942728868, "mdate": 1762942728868, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents EvolProver, a formal-reasoning LLM fine-tuned on a synthetically expanded dataset constructed through three evolution mechanisms: \n\n(1) EvolDomain, which performs cross-domain statement translation via LLMs;  \n(2) EvolDifficulty, which adjusts statement complexity; and  \n(3) EvolAST, which applies symbolic abstract-syntax-tree (AST) rewriting rules such as commutativity and De Morgan transformations to generate logically equivalent variants.  \n\nThe resulting dataset, comprising roughly 39 k verified (statement, proof) pairs in Lean 4, is used to SFT and RL-train a DeepSeek-Prover-V1.5-Base model. EvolProver achieves new state-of-the-art results on several formal benchmarks including FormalMATH-Lite, MiniF2F-Test, and Ineq-Comp, demonstrating the potential of AST-based symbolic augmentation to improve verifiable reasoning."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1.  The integration of symbolic AST transformations into the data-generation pipeline is novel and convincing. EvolAST guarantees semantic correctness and diversifies syntax without requiring additional verification.\n2. MThe paper clearly outlines each augmentation stage and the verification loop, with Lean 4 compiler checks for both syntax and semantics.\n3. Consistent and substantial improvements across benchmarksindicate that the augmented data meaningfully enhances formal reasoning ability."}, "weaknesses": {"value": "1. Data contamination analysis: While the authors mention ensuring non-overlapping “initial states,” this safeguard is underspecified. It remains unclear whether evolved statements might still share logical content or minor transformations with the test set. A more thorough contamination study—quantifying overlap at the theorem or syntactic-similarity level—would strengthen the empirical claims.\n2. Lack of output-length analysis: Table 1 reports that EvolProver generates substantially longer outputs than comparable non-reasoning models, yet the paper provides no interpretation. It is unclear whether performance gains arise from genuinely better reasoning or simply more verbose exploration, which turns the model into a \"semi-reasoning\" model.\n    - I would appreciate it a follow-up would measure output length (or verified proof length) on the subset of problems solved by both EvolProver and its baseline, to see whether the improvement correlates with verbosity or genuine efficiency."}, "questions": {"value": "1. Could the authors provide token-length and proof-length statistics restricted to the intersection of solved problems between EvolProver and EvolProver-Base?\n\t2.\tCan the authors further clarify how they ensured no data leakage between training and test dataset? A quantitative similarity or embedding-based overlap metric would help."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "a0thwGgCOa", "forum": "cBoYkLG3EJ", "replyto": "cBoYkLG3EJ", "signatures": ["ICLR.cc/2026/Conference/Submission23597/Reviewer_wPuw"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23597/Reviewer_wPuw"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761984212324, "cdate": 1761984212324, "tmdate": 1762942728664, "mdate": 1762942728664, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces EvolProver, a 7B parameter non-reasoning LEAN theorem prover model. The model is fine-tuned using data generated from a new data augmentation pipeline. The pipeline consists of three components:\n\n1. **EvolDomain**: Uses LLMs to reformulate the existing problem into different mathematical domains.\n2. **EvolDifficulty**. Uses LLMs to adjust the difficulty of the theorem.\n3. **EvolAST**: Applies syntactical rewrites using a small amount of equivalence rules.\n\nEach transformed problem is filtered via a Lean syntactic check and an LLM semantic check. The pipeline is applied to existing theorem datasets, producing a larger and more diverse dataset used to fine-tune DeepSeek-Prover-V1.5. The resulting model, EvolProver, achieves strong performance outperforming both non-reasoning and some reasoning models."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The paper empirically demonstrates that diversified training data can improve robustness of formal theorem provers. The multi-stage verification (Lean compilation + LLM judging) appears carefully constructed, and the ablation study highlights the contribution of each augmentation component. Improvements are reported on several benchmark datasets (FormalMATH-Lite, MiniF2F-Test, and Ineq-Comp).  The paper’s focus on token-efficient, non-reasoning proving is practically important and timely, given the inference-time and cost problem of chain-of-thought systems."}, "weaknesses": {"value": "My main concern is the novelty of the proposed data augmentation method. The individual techniques used in the pipeline appear to be adaptations of well-known ideas rather than new contributions. Using LLM prompting to evolve instructions or problems (EvolDomain, EvolDifficulty) closely resembles approaches such as WizardMath or MetaMath. The final model architecture and training recipe (SFT + RL) seem to follow existing pipelines from e.g. DeepSeek-Prover.\n\nReproducibility and community impact are constrained by unclear release plans: code, datasets, and model checkpoints appear contingent on institutional approval with no firm timeline or open-model replication, making it difficult for others to verify and build upon the work."}, "questions": {"value": "1. What specifically distinguishes EvolDomain/EvolDifficulty from prior prompt-based data synthesis?\n2. How often do EvolDomain/EvolDifficulty produce invalid or semantically incorrect statements before filtering?\n3. The verification pipeline appears to be computationally expensive. What is the computational cost of running the full pipeline (LLM generation + filtering + AST evolution + proof synthesis)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "RImCn1oncv", "forum": "cBoYkLG3EJ", "replyto": "cBoYkLG3EJ", "signatures": ["ICLR.cc/2026/Conference/Submission23597/Reviewer_uSHo"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23597/Reviewer_uSHo"], "number": 5, "invitations": ["ICLR.cc/2026/Conference/Submission23597/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761994148749, "cdate": 1761994148749, "tmdate": 1762942728475, "mdate": 1762942728475, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}