{"id": "xtdPwCp5mi", "number": 24432, "cdate": 1758356884115, "mdate": 1759896766620, "content": {"title": "Attending on Multilevel Structure of Proteins enables Accurate Prediction of Cold-Start Drug-Target Interactions", "abstract": "Cold-start drug-target interaction (DTI) prediction focuses on interaction between novel drugs and proteins.\nPrevious methods typically learn transferable interaction patterns between structures of drug and proteins to tackle it.\nHowever, insight from proteomics suggest that protein have multi-level structures and they all influence the DTI.\nExisting works usually represent protein with only primary structures, limiting their ability to capture interactions involving higher-level structures. \nInspired by this insight, we propose ColdDTI, a framework attending on protein multi-level structure for cold-start DTI prediction.\nWe employ hierarchical attention mechanism to mine interaction between multi-level protein structures (from primary to quaternary) and drug structures at both local and global granularities.\nThen, we leverage mined interactions to fuse structure representations of different levels for final prediction.\nOur design captures biologically transferable priors, avoiding the risk of overfitting caused by excessive reliance on representation learning.\nExperiments on benchmark datasets demonstrate that ColdDTI consistently outperforms previous methods in cold-start settings.", "tldr": "", "keywords": ["Drug-target interaction", "Cold-start", "Cross-attention", "Transfer learning"], "primary_area": "transfer learning, meta learning, and lifelong learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/4355f992b2634f00a63b096171ffd23bbf012ac9.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper presents ColdDTI, a framework that models proteins’ multi-level structures to improve cold-start drug–target interaction prediction. Using hierarchical attention and adaptive fusion, it captures cross-level drug–protein interactions. Experiments on multiple benchmarks show consistent gains over baselines."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "The paper presents a strong motivation, as cold-start DTI prediction remains an urgent and important challenge in the field."}, "weaknesses": {"value": "1. The proposed multi-level structure framework lacks sufficient novelty. Similar hierarchical or multi-level attention mechanisms have been explored in prior works, such as MHADTI (a) and MlanDTI (b)\n\nReference: \n\n(a) MHADTI: Predicting Drug–Target Interactions via Multiview Heterogeneous Information Network Embedding with Hierarchical Attention Mechanisms (Briefings in Bioinformatics, 2022) \n\n(b) Multilevel Attention Network with Semi-supervised Domain Adaptation for Drug–Target Prediction (AAAI, 2024). \n\n2. The experimental comparison is incomplete. The paper does not include several recent strong baselines that specifically address cold-start DTI prediction, such as GraphBAN (a) and FusionDTI (b).\n\n​​Reference:\n\n(a) GraphBAN: An inductive graph-based approach for enhanced prediction of compound-protein interactions (Nature Communications, 2025).\n\n(b) FusionDTI: Fine-grained Binding Discovery with Token-level Fusion for Drug-Target Interaction (EMNLP 2025).\n\n3.  The paper does not provide sufficient analysis or explanation for the performance drop observed under cold-start settings. \nThe experiments are conducted on several cold-start datasets, but the paper does not clarify why performance drops in certain settings whether the degradation arises from technical limitations of the framework, intrinsic data sparsity, or the nature of the cold-start split itself.\n \n4. The method claims to capture biologically meaningful multi-level protein structures, but the explainability analysis (attention visualisations) remains superficial.\nIt would be beneficial to quantitatively validate whether the learned attention indeed aligns with known structural or functional regions in proteins.\n\n5.  Some sections are described in a verbose or repetitive descriptions, making it difficult to follow the methodological flow (e.g., hierarchical interaction)."}, "questions": {"value": "Please refer to the above weaknesses for detailed comments and suggestions."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "iRoH4bdFsl", "forum": "xtdPwCp5mi", "replyto": "xtdPwCp5mi", "signatures": ["ICLR.cc/2026/Conference/Submission24432/Reviewer_FX9M"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24432/Reviewer_FX9M"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24432/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761455970960, "cdate": 1761455970960, "tmdate": 1762943081425, "mdate": 1762943081425, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents a new approach to predict drug-target interactions (DTI) in the cold-start scenario (i.e., for newly developed drugs or/and new proteins) based on\n 1. presenting drugs and proteins at different structural levels (local vs global levels for drugs and primary, secondary and tertiary levels for proteins), \n 2. learning and capturing interactions at between the drug sub-structures and protein sub-structures, and \n 3. fusing the representation of the different sub-structures in a single vector representation based on their interaction strength."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1) The paper tackles an important problem in the drug discovery process,  predicting drug-target interactions. Contrary to other works, it focuses on the more realistic and challenging cases of making predictions about new drugs or new proteins.\n2) To the best of my knowledge, the proposed multilevel structure representation is very novel and interesting.\n3) The comprehensive experimental evaluation over 4 well-known DTI datasets show that the proposed approach clearly outperforms many state-of-the-art approaches on three key metrics (AUC, AUPR and F1-score)"}, "weaknesses": {"value": "Although I believe that the proposed approach is technically sound, the technical content is poorly presented in section 4.  \n  \n   a. A lot of matrix multiplications do not make sense because they violate the basic matrix multiplication size rule (i.e., the number of columns in the first matrix must equal the number of rows in the second matrix). For example, although not explicitly stated, one can infer that the matrix X_l of local structure embeddings of the drug is a d x l matrix (where d is the embedding size and l is the number of local structures). Likewise, X_s is a d x s matrix, where d is the embedding size and s is the number of secondary structures of the protein. With those matrix dimensions,   I_{ls} = (W^l_{ls}Xl_)(W^s_{ls}X_s)^⊤ is incorrect. It should be replaced with  I_{ls} = (W^l_{ls}Xl_)^⊤ (W^s_{ls}X_s) .  A similar issue is present in the definition of rs = (X_s)^⊤ w_s. It should be   rs = X_s (w_s)^⊤ \n   \n   b. The formula defining the intra-level representation fusion does not make sense: S_s = (I_{gs} + I_{ls}.m(axis=column)). It adds two matrices with incompatible sizes:\n      i) the g x s matrix  I_{gs}  of interactions between g global drug structures and s protein secondary structures, and\n     ii) the 1 x s matrix  I_{ls}.m(axis=column) of the scalar strengths of the s secondary protein structures \n  It should be replaced with S_s = I_{gs}.m(axis=column) + I_{ls}.m(axis=column)"}, "questions": {"value": "N/A"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "jvbcphHHck", "forum": "xtdPwCp5mi", "replyto": "xtdPwCp5mi", "signatures": ["ICLR.cc/2026/Conference/Submission24432/Reviewer_znRg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24432/Reviewer_znRg"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24432/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761782212074, "cdate": 1761782212074, "tmdate": 1762943081226, "mdate": 1762943081226, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes a hierarchical attention network that leverages multi-level protein structural representations to address the limited prediction performance of existing DTI models on unseen drugs, targets, and drug–target pairs. The unseen prediction task is analogous to the cold-start problem in recommendation systems, which is an interesting and novel perspective in the context of DTI prediction. The authors employ pretrained models ProtTrans and ChemBERTa-2 to extract multi-level representations of proteins and compounds, same as a previous approache named MlanDTI. By effectively capturing and integrating interaction and fusion information across these hierarchical representations, the proposed model, ColdDTI, achieves superior performance compared to current state-of-the-art methods. Furthermore, the ablation experiments convincingly demonstrate the importance of each level feature representation in contributing to the overall predictive performance."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.\tEffectively targets the critical cold-start DTI challenge, where generalization to novel drugs/proteins is essential, by learning transferable structural interaction patterns rather than relying on interaction-specific data.\n\n2.\tReasonably extends protein representation to include higher-level structures (secondary to quaternary) using special tokens in ProtBERT, offering a more comprehensive view than primary-sequence-only approaches.\n\n3. The overall language and methodological presentation of the paper is clear and well-organized."}, "weaknesses": {"value": "1. Potential overfitting to benchmarks: maybe the paper doesn't address dataset-specific biases (e.g., over-representation of certain protein families). Under cold pair setting, even if the proteins in test set don’t appear in training set, if the proteins in test set belong to the same family with those in training set, the results may not sufficiently reflect the generalization ability. So if possible, it is recommended to supplement an experiment under the setting of cold protein family, namely the protein families in training set, validation set and test set without intersection.\n\n2. Insufficient baselines: while structure-based baselines are covered, graph-based methods are dismissed early without direct comparison in cold-start settings. Recent works like EviDTI (using 2D/3D drug info) are mentioned but not benchmarked against. It is suggested to add one or two graph-based methods along with EviDTI to baselines, which can make the results more convinced.\n\n3. Lack of ablation study for drug representation: only structural levels of proteins are discussed in ablation study, so the ablation study can be extended to drug representations by examining the individual contributions of the global and local structures, which would provide a more comprehensive validation of the proposed framework.\n\n4. Insufficient discussion related to prediction results: sometimes the results in four datasets variate a great deal, especially under cold pair setting (Table 1). So what cause the difference among them? It is suggested to analyze the difference of protein families and molecular types in four datasets, which can provide valuable biological insights.\n\n5. Although unseen prediction is important, focusing solely on this aspect makes the study somewhat limited, as it lacks evaluation on seen drugs and proteins, which are also essential for a complete DTI benchmark."}, "questions": {"value": "1. With recent models like SaProt and ESM-IF1 directly incorporating 3D structural contexts (e.g., inverse folding or residue-pair distances) into protein embeddings, what specific benefits does your sequence-based tag insertion (e.g., [tertiary_start]) offer in terms of simplicity, alignment with SMILES-drug modeling, or performance in cold-protein generalization? In addition,  if structure are already available, more accurate structure-based methods—such as molecular docking—might be more suitable and informative.\n\n2. The ablation study seems to indicate that quaternary structure is not very important in DTI prediction, but is it because that spatial structural information is not integrated in quaternary representation? If integrate 3D features from tools like AlphaFold for proteins with available structures, would the results be further improved?\n\n3.  Leveraging pretrained model knowledge to address the cold-start problem is a common and effective strategy, since the pretrained representations may already capture implicit information related to unseen entries. In Table 1, only MlanDTI employs large-scale pretraining, which may explain its overall second-best performance. Therefore, it would be more convincing to include additional pretrained-model-based DTI methods for comparison to better demonstrate the superiority of ColdDTI. Furthermore, if possible, the authors are encouraged to analyze the contribution of using pretrained representations compared to direct feature embeddings.\n\n4. The case study is too limited in scope. To enhance model interpretability, it is recommended to include feature-space visualizations (e.g., t-SNE or PCA plots) that separate positive and negative samples, thereby providing deeper insights into how the model distinguishes binding and non-binding pairs."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "WPJ8MeCyX7", "forum": "xtdPwCp5mi", "replyto": "xtdPwCp5mi", "signatures": ["ICLR.cc/2026/Conference/Submission24432/Reviewer_dbpi"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24432/Reviewer_dbpi"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24432/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761890911724, "cdate": 1761890911724, "tmdate": 1762943080971, "mdate": 1762943080971, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The ColdDTI paper presents an attention-based model for predicting how drugs interact with proteins, even when the model has never seen those drugs or proteins before. Unlike older models that only use protein sequences or molecular graphs, ColdDTI uses multiple protein structure levels from amino acid sequences to 3D folding and connects them with local and overall features of drugs. It builds cross-attention maps between these levels, such as drug fragments and protein 3D structures, and combines them through a two-step fusion to decide if a drug and protein will interact. The model performs well across four datasets, especially for unseen proteins or drug–protein pairs. However, the authors used their own data split instead of stricter testing methods like cluster-start or bias-reduced splits, and they did not compare results with recent top-performing models such as EviDTI (2025) or ColdstartCPI (2025), so it is hard to tell how much better their method really is."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "* The model explicitly incorporates multi-level protein structure and local/global drug representations for richer biochemical context.\n* It demonstrates verified performance gains through multi-level cross-attention and two-stage fusion.\n* Attention maps allow visualization of residue–fragment contributions to interaction predictions."}, "weaknesses": {"value": "* The paper does not include direct benchmarks against strong contemporary SOTAs like EviDTI [1] and ColdstartCPI [2], leaving uncertainty about true performance standing.\n* The paper uses a self-defined 8:1:1 split instead of existing splits employing cold-start or cluster-start splits with ligand-bias reduction preprocessing [3], which weakens the statistical rigor of its “true cold-start” claims.\n\n\n - [1] Zhao, Yanpeng, et al. \"Evidential deep learning-based drug-target interaction prediction.\" Nature Communications 16.1 (2025): 6915.\n - [2] Zhao, Qichang, et al. \"ColdstartCPI: Induced-fit theory-guided DTI predictive model with improved generalization performance.\" Nature Communications 16.1 (2025): 6436.\n - [3] https://github.com/Lzcstan/DrugLAMP"}, "questions": {"value": "Have you evaluated or planned to compare ColdDTI with more recent state-of-the-art models such as EviDTI (2025) or ColdstartCPI (2025) to better position your model’s performance in the current landscape?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "None"}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "vsNEk7cCcW", "forum": "xtdPwCp5mi", "replyto": "xtdPwCp5mi", "signatures": ["ICLR.cc/2026/Conference/Submission24432/Reviewer_p6sz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24432/Reviewer_p6sz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24432/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761966209314, "cdate": 1761966209314, "tmdate": 1762943080730, "mdate": 1762943080730, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}