{"id": "S0D3EFWohd", "number": 24340, "cdate": 1758355943122, "mdate": 1759896770544, "content": {"title": "Steering Language Models with Weight Arithmetic", "abstract": "Providing high-quality feedback to Large language models (LLMs) on a diverse training distribution can be difficult and expensive, and providing feedback only on a narrow distribution can result in unintended generalizations. To better leverage narrow training data, we propose contrastive weight steering, a simple post-training method that edits the model parameters using weight arithmetic. We isolate a behavior direction in weight-space by subtracting the weight deltas from two small fine-tunes‚Äìone that induces the desired behavior and another that induces its opposite‚Äìand then add or remove this direction to modify the model's weights. We apply this technique to mitigate sycophancy and misalignment, and find that weight steering often generalizes better than activation steering, achieving stronger out-of-distribution behavioral control before degrading general capabilities. We also show that, in the context of task-specific fine-tuning, weight steering can partially mitigate undesired behavioral drift: it can reduce sycophancy and under-refusals introduced during fine-tuning while preserving task performance. Finally, we provide preliminary evidence that emergent misalignment can be detected by measuring the similarity between fine-tuning updates and an \"evil\" weight direction, suggesting that it may be possible to monitor the evolution of weights during training and detect rare misaligned behaviors that never manifest during training or evaluations.", "tldr": "We propose contrastive weight steering, a post-training method that edits LLM weights to reduce sycophancy and misalignment while preserving performance", "keywords": ["steering", "alignment", "safety", "model editing", "merging models"], "primary_area": "alignment, fairness, safety, privacy, and societal considerations", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/95c9fa927876e4710dcda2e80c51c371b35cb88f.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper introduces contrastive weight steering for behavior control in LLMs: obtain two small LoRA finetunes that elicit opposite behaviors (positive vs. negative), form a behavior weight vector $w_b=\\tau^+-\\tau^-$, and steer the base model by adding $kw_b$ to its weights. The method is simple, data-light, and cheap to apply. Experiments show reductions in sycophancy and misalignment with stronger out-of-distribution (OOD) generalization than activation-based steering, and a practical use case for monitoring undesirable drift. Steered models often preserve general capability better than activation steering at comparable control strength."}, "soundness": {"value": 4}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- The method is simple & practical: A minimal, reproducible recipe (two tiny LoRA runs + one vector addition) with low data/compute cost.\n- OOD robustness vs. activation steering: Under matched data and control strength, weight steering more often preserves base accuracy while shifting behavior.\n- Useful byproducts: The learned behavior direction doubles as a monitoring signal for emergent misalignment."}, "weaknesses": {"value": "- Limited novelty: Methodologically close to task arithmetic/task vectors; the contrastive construction is natural but incremental.\n- Baselines could be stronger: Most comparisons are to activation steering or prompts. To contextualize tradeoffs, it would help to include training-heavier baselines (e.g., larger SFT/RLHF slices) on the same behaviors and report cost-adjusted outcomes."}, "questions": {"value": "- Could the authors explain why the double-side difference $\\tau^+-\\tau^- $ is necessary?: What do we lose by using a single-sided vector, e.g. $ \\theta_{\\text{positive}}-\\theta_0 $? \n- On dataset construction robustness: Could mismatch between positive/negative datasets (style, register, spurious topics) contaminate $w_b$? Is there any robust way to ensure we isolate the intended behavior?\n- Data & hyperparameter scaling: How does performance/retention vary with number of examples used to fit $ \\tau^\\pm $, and hyperparameters such as LoRA rank?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Pgmas9PnnG", "forum": "S0D3EFWohd", "replyto": "S0D3EFWohd", "signatures": ["ICLR.cc/2026/Conference/Submission24340/Reviewer_Aqfz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24340/Reviewer_Aqfz"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24340/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761570470012, "cdate": 1761570470012, "tmdate": 1762943048594, "mdate": 1762943048594, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces ‚Äúcontrastive weight steering‚Äù, a post-training method for modifying high-level behaviors in large language models (LLMs) by arithmetically combining weight differentials from small-scale, purposefully narrow fine-tunings. By subtracting weight changes induced by opposite behaviors (positive vs. negative fine-tunes), the method isolates weight-space directions corresponding to target traits, such as sycophancy, refusal, or ‚Äúevilness‚Äù. The resulting vector is then added or subtracted from the base (or recently task-fine-tuned) model‚Äôs parameters. The authors benchmark weight steering against activation steering, an established, layer-specific behavioral modulation technique, and traditional data augmentation through fine-tuning. The work empirically demonstrates that weight steering often generalizes steering effects better to out-of-distribution queries before harming model competence, and can also serve as a tool for post-hoc behavioral monitoring and drift detection by inspecting task vector similarities."}, "soundness": {"value": 3}, "presentation": {"value": 1}, "contribution": {"value": 3}, "strengths": {"value": "1. Methodology: the approach is conceptually simple yet effective, contrastive construction of behavioral directions in weight space, building directly upon and extending well-known task-vector strategies (Ilharco et al., 2023).\n\n2. Clarity with Explicit Comparison: The paper systematically compares contrastive weight steering to activation steering and joint fine-tuning, using diverse alignment-relevant behaviors (sycophancy, refusal, evilness) across several standard LLM architectures (Qwen2.5-7B, Llama-2-7B, etc.).\n\n3. Emphasis on Out-of-Distribution (OOD) Evaluation: Unlike much of the prior literature, the paper pays substantial attention to OOD generalization: for example, by constructing steering vectors with one query distribution and evaluating behavioral shifts on distinct domains, multiple-choice setups, or open-ended generations.\n\n4. Visualizations and Interpretability: Several key figures, such as Figure 2 (sycophancy steering tradeoff), Figure 5 (Evil rate vs. accuracy curve), and Figure 9 (cosine similarity heatmap for weight-behavior vectors), provide clear, interpretable evidence of both the strengths and blind spots of the method."}, "weaknesses": {"value": "1. Oversimplified Method and Ambiguity in Implementation: The proposed method appears conceptually simple, relying on subtracting the negative direction from the positive one and interpolating between them to obtain the final value. However, constructing an appropriate negative direction is often non-trivial and may not be unique (see my Q1), potentially introducing ambiguity in the optimization process. Furthermore, the selection of an appropriate interpolation coefficient k plays a critical role in determining the model‚Äôs stability and performance. A more detailed discussion or empirical justification for how the negative direction is defined and how k is chosen would significantly strengthen the technical soundness of the paper.\n\n2. Lack of Insights into Weight vs. Activation Steering: The paper does not provide sufficient explanation or theoretical insight into why weight steering yields better performance than activation steering. Ideally, modifying the weights should be, in principle, equivalent to applying an appropriate transformation to the activations. However, the observed performance difference between the two approaches suggests that there may be underlying mechanisms not yet well understood. It would be valuable to clarify why weight steering behaves differently and appears to offer superior results, with proper insights.\n\n3. Lack of Clarity in Presentation: The paper‚Äôs presentation lacks clarity, with several important implementation details either missing or insufficiently explained. For instance, it is unclear how ‚Äúsycophancy‚Äù is formally defined or measured within the experimental setup. Additionally, the paper does not specify whether weight steering is applied to all layers of the model or restricted to certain fixed layers. Providing clearer definitions and methodological descriptions would greatly improve the readability, reproducibility, and overall credibility of the work.\n\n4. Potentially Unfair Evaluation:The evaluation setup may not provide a fair comparison between methods. In several cases, activation steering results in both lower non-sycophancy scores and reduced accuracy (e.g., Figure 3). This outcome is counterintuitive, as both metrics deteriorate under the same adjustment. The authors are encouraged to further investigate this behavior and clarify whether it stems from differences in experimental settings, parameter tuning, or inherent limitations of activation steering. A fairer and more controlled comparison would strengthen the validity of the reported results."}, "questions": {"value": "1. [Key Issue] The reviewer would like to better understand how the negative direction is determined in the proposed method. In general, while a positive direction can often be uniquely defined, there may exist infinitely many possible negative directions. How is a proper negative direction selected in practice? Moreover, how sensitive is the performance of weight steering to this choice? A more detailed explanation or empirical analysis on this aspect would help clarify the robustness and consistency of the proposed approach.\n\n2. [Key Issue] Following the Q1, the reviewer has concerns on the reported results. Considering the Figure 2 as an example. In the left subfigure, it appears that positive activation steering effectively reduces the non-sycophancy score, whereas in the right subfigure, it shows very limited ability to increase the non-sycophancy score. Could the authors clarify why this asymmetry occurs? Is it potentially due to the selection of an inappropriate negative steering direction, given that multiple negative directions could exist? A more detailed explanation or visualization would help elucidate the underlying cause of this discrepancy.\n\n3. A similar issue can be observed in Figure 3. It appears that applying activation steering leads to a decrease in performance while simultaneously decreasing the non-sycophancy score. This behavior seems counterintuitive, as both metrics deteriorate under this adjustment. Could the authors provide further clarification or analysis on why this occurs? It would be helpful to understand whether this effect arises from the steering method itself, the choice of direction, or potential interactions between the two objectives.\n\n4. Unclear Selection of Interpolation Parameter k:The paper does not provide sufficient details on how the interpolation parameter \nk is selected. Although the authors illustrate the interpolation behavior using color notations, a more concrete description of the actual k values used is necessary for clarity and reproducibility. Furthermore, an ablation study examining the sensitivity of performance to different k values would offer valuable insight into how this parameter influences the effectiveness and stability of the proposed method.\n\n5. In Line 162, the authors mention that they ‚Äúselect the best-performing layer‚Äù for activation steering. Could the authors clarify whether the same layer selection strategy is applied for weight steering? Specifically, do you use the same layer identified for activation steering, or is weight steering performed across all layers?\n\n6. Section 3 appears disproportionately brief relative to its importance. The reviewer suggests that the authors expand this section by including key definitions and methodological clarifications. For instance, it would be helpful to formally define how activation steering is formulated and how sycophancy is evaluated. Shifting or adding such explanations to this section would improve the logical flow and make the paper more self-contained and accessible to readers.\n\n7. Some Typographical Error. For example, in Line 309, there is an inappropriate use of quotation marks around the word ‚Äúevil‚Äù. Also, the caption of Figure 2 appears to contain an error. It currently reads ‚ÄúWeight steering is more effective in controlling sycophancy than weight steering.‚Äù This seems to be a typographical mistake‚Äîperhaps the authors intended to compare weight steering with activation steering."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2eIHlS0bFA", "forum": "S0D3EFWohd", "replyto": "S0D3EFWohd", "signatures": ["ICLR.cc/2026/Conference/Submission24340/Reviewer_AbNf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24340/Reviewer_AbNf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24340/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761624880543, "cdate": 1761624880543, "tmdate": 1762943048431, "mdate": 1762943048431, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces Contrastive Weight Steering (CWS), a post training technique to modify large language model (LLM) behaviors through weight arithmetic rather than activation interventions. The method isolates behavioral ‚Äúdirections‚Äù in weight space by contrasting two fine-tunes one inducing a desired behavior (e.g., truthfulness) and another inducing its opposite (e.g., sycophancy). The resulting weight vector is then added to or subtracted from the base model to steer behavior. Experiments across sycophancy, evilness, and refusal show that weight steering achieves better out-of-distribution generalization than activation steering, maintains task performance, and can even mitigate unwanted drift introduced during downstream fine tuning. Additionally, the paper presents preliminary evidence that cosine similarity in weight space may help detect emergent misalignment during training"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The contrastive weight-space formulation is both simple and effective.\n2. Demonstrated across behaviors (sycophancy, evilness, refusal) and architectures.\n3. Outperforms activation steering on unseen distributions.\n4. Shows that CWS can correct sycophancy induced during task-specific fine-tuning without harming core skills.\n5. Provides early evidence that misalignment can be detected by tracking weight-space similarities.\n6. Hyperparameters, datasets, and prompts are clearly documented"}, "weaknesses": {"value": "1. The paper does not formally analyze why certain weight directions correspond to behavioral dimensions.\n2. Steering coefficient ùëò, k is tuned manually; adaptive or learning-based selection could improve reliability.\n3. Experiments use models up to 7 B parameters larger frontier models (e.g., 70 B+) could test scalability.\n4. It remains unclear how interpretable or modular these weight directions are across unrelated behaviors.\n5.  The ‚Äúevil vector‚Äù similarity experiment is promising but would benefit from quantitative validation over training trajectories."}, "questions": {"value": "1. How stable are weight-space directions across model sizes can a vector learned on a 1.5 B model transfer to a 7 B model?\n2. How does the choice of fine-tuning layers (e.g., LoRA rank and target modules) influence steering effectiveness?\n3. Could monitoring via cosine similarity be used in real-time to stop training before misalignment occurs?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "2kxEqlyyJn", "forum": "S0D3EFWohd", "replyto": "S0D3EFWohd", "signatures": ["ICLR.cc/2026/Conference/Submission24340/Reviewer_ErcJ"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24340/Reviewer_ErcJ"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24340/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761713184977, "cdate": 1761713184977, "tmdate": 1762943048243, "mdate": 1762943048243, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}