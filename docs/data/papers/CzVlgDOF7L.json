{"id": "CzVlgDOF7L", "number": 16925, "cdate": 1758270301149, "mdate": 1759897209653, "content": {"title": "Learning Domain-Aware Task Prompt Representations for Multi-Domain All-in-One Image Restoration", "abstract": "Recently, significant breakthroughs have been made in all-in-one image restoration (AiOIR), which can handle multiple restoration tasks with a single model. However, existing methods typically focus on a specific image domain, such as natural scene, medical imaging, or remote sensing. In this work, we aim to extend AiOIR to multiple domains and propose the first multi-domain all-in-one image restoration method, DATPRL-IR, based on our proposed Domain-Aware Task Prompt Representation L}earning. Specifically, we first construct a task prompt pool containing multiple task prompts, in which task-related knowledge is implicitly encoded. For each input image, the model adaptively selects the most relevant task prompts and composes them into an instance-level task representation via a prompt composition mechanism (PCM). Furthermore, to endow the model with domain awareness, we introduce another domain prompt pool and distill domain priors from multimodal large language models into the domain prompts. PCM is utilized to combine the adaptively selected domain prompts into a domain representation for each input image. Finally, the two representations are fused to form a domain-aware task prompt representation which can make full use of both specific and shared knowledge across tasks and domains to guide the subsequent restoration process. Extensive experiments demonstrate that our DATRL-IR significantly outperforms existing SOTA image restoration methods, while exhibiting strong generalization capabilities. We believe that this work provides a new research paradigm and represents a step towards more unified image restoration.", "tldr": "", "keywords": ["multi-domain all-in-one image restoration", "prompt learning", "low-level computer vision"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/c1630b428b6445d5e24c78d252207e5d320e4396.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes **DATPRL-IR**, the first method for **Multi-Domain All-in-One Image Restoration (MD-AiOIR)**, which unifies diverse restoration tasks across natural, medical, and remote sensing image domains within a single model. The core idea is **Domain-Aware Task Prompt Representation Learning (DATPRL)**, which leverages two prompt pools: one for tasks (e.g., deraining, super-resolution) and one for domains (e.g., medical, remote sensing). Task prompts are learned end-to-end, while domain prompts are distilled from textual descriptions generated by a multimodal large language model (LLaVA) and aligned via CLIP. These prompts are adaptively selected and composed into instance-level representations, then fused via cross-attention and adaptive gating to guide the restoration backbone. Experiments on 6-task and 9-task settings across three domains show consistent improvements over state-of-the-art (SOTA) methods in PSNR and SSIM, with strong generalization and scalability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Novel problem setting**: MD-AiOIR is a meaningful extension beyond single-domain AiOIR.\n- **Thoughtful architecture**: The dual-prompt-pool design with adaptive composition and fusion is well-motivated.\n- **Comprehensive experiments**: Evaluation across three domains and up to nine tasks is thorough, with solid PSNR/SSIM gains over SOTA."}, "weaknesses": {"value": "**Insufficient description of task prompt learning**: The paper states that the task prompt pool consists of key-value pairs $(K_j^{\\text{task}}, V_j^{\\text{task}})$ and that they are “optimized jointly with restoration objectives,” but it **does not clarify**:\n  - How the prompts are **initialized** (random? pre-trained?).\n  - Whether keys and values are **learned independently** or share structure.\n  - The **dimensionality and architecture** of the projector that maps features to the query.\n  - How the **value tensor** $V_j^{\\text{task}} \\in \\mathbb{R}^{T \\times d}$ is used in the restoration backbone (e.g., is it injected via cross-attention? added as bias?).\n  \n  Without these details, the **reproducibility and technical novelty** of the task prompt mechanism are hard to assess. In contrast, the domain prompt distillation pipeline is clearly explained.\n\n- **Limited gain from domain prompts**: As shown in Table 2, the domain prompt pool contributes only marginal improvements (e.g., +0.09 dB on CT denoising), raising questions about its necessity. Simpler domain encoding (e.g., one-hot vectors) might suffice.\n- **Reliability of LLaVA-generated descriptions**: Medical and remote sensing images often lack rich semantics. It’s unclear whether LLaVA can reliably generate meaningful, discriminative textual descriptions for such domains (e.g., “grayscale + human organs” may be too vague).\n- **Unverified zero-shot claims**: The abstract and conclusion mention “strong zero-shot capabilities,” but no experiments on unseen domains or tasks are provided to substantiate this.\n- **Minor typo**: The method is referred to as “DATRL-IR” in one sentence of the abstract, missing the “P”."}, "questions": {"value": "1. Could you clarify how the task prompts (keys and values) are initialized and updated during training? Are they fully learnable parameters?\n2. How is the task prompt representation $PR_t$ actually **integrated into the restoration network**? Is it used as a conditioning signal in attention layers, or elsewhere?\n3. Given the small performance gain from domain prompts, have you considered simpler domain encodings (e.g., one-hot vectors) as a baseline?\n4. Can you provide example LLaVA-generated captions for medical/remote sensing images? How diverse and informative are they?\n5. Have you compared your domain prompt pool against simpler alternatives (e.g., learnable domain embeddings)? Is the performance gain worth the added complexity?\n6. The paper claims “zero-shot capabilities”—can you show results on an unseen domain (e.g., train on natural + medical, test on remote sensing)?\n7. How sensitive is performance to the number of prompts (N=15) and top-k values (k=3/5)? Was this tuned extensively?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pXxiNc0FIv", "forum": "CzVlgDOF7L", "replyto": "CzVlgDOF7L", "signatures": ["ICLR.cc/2026/Conference/Submission16925/Reviewer_mrLL"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16925/Reviewer_mrLL"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission16925/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761554964021, "cdate": 1761554964021, "tmdate": 1762926949380, "mdate": 1762926949380, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The authors propose a novel method called DATPRL-IR, the first model for Multi-Domain All-in-One Image Restoration (MD-AiOIR), which aims to handle diverse restoration tasks across multiple image domains within a single network. Specifically, The author introduces Domain-Aware Task Prompt Representation Learning, which utilizes separate task and domain prompt pools to adaptively retrieve and combine knowledge, subsequently fusing them into a unified guidance signal for the restoration backbone. Extensive experiments demonstrate that DATPRL-IR significantly outperforms existing state-of-the-art methods on various tasks across natural, medical, and remote sensing image domains, showing strong performance and scalability as tasks are added."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The article is well-structured and easy to understand. By separating image types and restoration tasks, the author introduces an interesting approach to achieve different types of image restoration. This method avoids the confusion between types and tasks, allowing the model to better perform specific tasks in specific domains."}, "weaknesses": {"value": "1. Motivation: The authors propose a unified image restoration model capable of handling various types of images. This raises several questions: Why is this approach necessary, and why were previous methods unable to achieve this? The authors briefly mention in the introduction that earlier methods did not accomplish such unification, but the author fails to analyze why those methods were incapable of doing so.\n\n2. How to hand multi-modal data inputs: The paper addresses multiple domains but does not explicitly detail how the model handles the significant variations in input data characteristics across these domains. For instance, MRI data is often complex-valued and may be stored as 2-channel data (real and imaginary parts), while natural images are typically 3-channel RGB data. How does the proposed method unify these different data types and channel dimensions to form a consistent input representation for the single backbone network? A clarification of this pre-processing or adaptation step is crucial for understanding the model's practical applicability and reproducibility."}, "questions": {"value": "1. Fusion of domain and task prompts: The direct cross-attention between domain prompt features (PR_d) and task prompt features (PR_t) might not be the most effective fusion strategy. Given that domain and task information are conceptually orthogonal (one specifies the \"where,\" the other the \"what\"), directly fusing them could lead to information loss or unwanted interference. Would a sequential fusion strategy be more appropriate? For example, the domain prompt could first interact with the image features via cross-attention to produce domain-aware image features. These enriched features could then interact with the task prompts. This hierarchical approach might better preserve the distinct nature of both information types.\n\n2. The design of prompts: I would like to discuss the design of the prompt with the author: \nDomain Prompt Pool: The current strategy of relying on adjectives for domain identification appears potentially ambiguous. For instance, the descriptor \"black and white\" could apply to an old natural image or a medical image. This ambiguity might lead to inaccuracies in domain recognition. Have the authors considered using more explicit, categorical domain names as prompts, such as \"This is an MRI image\"? Such direct identifiers could provide a more robust and unambiguous signal for domain-aware guidance.\nTask Prompt Pool: The manuscript does not sufficiently elaborate on the concrete form or semantics of the task prompts. It remains unclear what kind of information they encapsulate (e.g., degradation patterns, desired output properties). To enhance clarity, could the authors provide a concrete example of what a task prompt might represent, either in the text or by annotating Figure 2? This would help readers better distinguish between the roles of task prompts and domain prompts."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3j6Fx8HnO0", "forum": "CzVlgDOF7L", "replyto": "CzVlgDOF7L", "signatures": ["ICLR.cc/2026/Conference/Submission16925/Reviewer_8geW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16925/Reviewer_8geW"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission16925/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761704927920, "cdate": 1761704927920, "tmdate": 1762926948820, "mdate": 1762926948820, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DATPRL-IR, a new method for image restoration across multiple domains (natural, medical, and remote sensing) and tasks, under the umbrella of what the authors term \"Multi-domain All-in-One Image Restoration\" (MD-AiOIR). The core idea is to utilize a dual prompt pool mechanism — task prompts and domain prompts — and fuse them via a prompt composition mechanism and cross-attention to guide the restoration process. The authors argue that DATPRL-IR is the first to tackle MD-AiOIR, claiming it represents a new research paradigm. Extensive experiments are conducted across 6 and 9 tasks on datasets from different domains."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1. The implementation is comprehensive, involving a structured dual-prompt architecture with cross-modal alignment using LLMs (LLaVA/CLIP), regularization mechanisms, and adaptive fusion.\n2. Experiments are conducted on a relatively large number of tasks and datasets, covering natural, remote sensing, and medical images.\n3. Ablation studies and visualizations are detailed and well-presented, providing insights into the behavior of the model."}, "weaknesses": {"value": "1. The central claim that \"Multi-domain All-in-One Image Restoration\" is a novel and meaningful research problem is not sufficiently justified. The distinction between MD-AiOIR and regular AiOIR is weak. The proposed setting is essentially a standard multi-task image restoration framework with more diverse datasets included. The fact that earlier works did not include medical or remote sensing datasets does not inherently make this a new problem. The paper does not provide a convincing motivation or theoretical/practical evidence that justifies treating MD-AiOIR as a distinct research direction.\n2. The paper fails to clarify whether the compared methods (e.g., PromptIR, MoCE-IR) were re-trained on the same multi-domain setting or simply evaluated out-of-domain. This is critical because these works were not originally designed for cross-domain tasks. Without a fair comparison, i.e., re-training all baselines on the same union of datasets, the reported superiority of DATPRL-IR is not convincing.\n3. The idea of using prompts (explicit or implicit) to guide image restoration is not new. Prior works such as PromptIR and related prompt-based multi-task models have explored similar mechanisms. While the dual-prompt pool design sounds well-structured, it is not fundamentally innovative. The use of CLIP or LLaVA to generate text features for domain alignment is incremental and does not offer deep conceptual novelty.\n4. Although the paper presents a complex architecture, it does not offer new insights into the nature of task/domain relationships in image restoration. There is little discussion on what has been learned, what the limitations are, or what implications this has for future research in AiOIR or multi-task learning more broadly."}, "questions": {"value": "1. Were the compared methods (e.g., PromptIR, MoCE-IR) retrained on the same combined dataset of natural, medical, and remote sensing images? If not, how can we interpret the performance gap?\n2. How do the authors justify the claim that MD-AiOIR is a new research paradigm, rather than an empirical extension of existing AiOIR to more datasets?\n3. Given that medical and remote sensing datasets are relatively small in this paper, could the performance gains be due to overfitting or data imbalance?\n4. What are the broader implications of this work for the field of image restoration? Does the method generalize to unseen domains or tasks?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZFk5aYUwHp", "forum": "CzVlgDOF7L", "replyto": "CzVlgDOF7L", "signatures": ["ICLR.cc/2026/Conference/Submission16925/Reviewer_1CdE"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16925/Reviewer_1CdE"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission16925/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761904927866, "cdate": 1761904927866, "tmdate": 1762926948451, "mdate": 1762926948451, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DATPRL-IR, a multi-domain all-in-one image restoration framework that integrates both task-specific and domain-specific priors via a dual prompt-pool mechanism. It adaptively selects task and domain prompts, aligns domain prompts with textual features from LLaVA/CLIP, and fuses them through cross-attention to guide restoration. Experiments on 6- and 9-task, 3-domain setups show clear gains over SOTA AiOIR methods in PSNR/SSIM and generalization ability."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The problem scope is novel and interesting, from my point of view, this is the first attempt to unify AiOIR across multiple task domains.\n\n2. The dual prompt pools and cross-modal alignment are practically effective, and supported by comprehensive experiments with strong empirical performance and ablation studies.\n\n3. Figures and paper writings are easy to follow."}, "weaknesses": {"value": "1. Although the evaluation scope contains multiple tasks from three domains, it is still unclear how the method will perform under zero-shot unseen domains. I think this is important to provide related experimental results to evaluate whether the proposed method is truely practical across domains.\n2. LLaVa seems generate captions that may exceed the 77 tokens limit of CLIP text encoder. Which part of the text is useful for cross modal alignment is worth exploration. \n3. The authors only provide PSNR/SSIM results for Table 1, lacking subjective metrics such as MANIQA/CLIPIQA etc., making it hard to fully validate the effectiveness of the proposed method.\n4. In abstract, the method is called \"DATRL-IR\" and \"DATPRL-IR\", which may be a typo."}, "questions": {"value": "For now I prefer a 4 rating (because no 5 option), but I will raise score if the weakness and the questions are properly addressed.\n\n1. How sensitive is the method to the choice of MLLM (e.g., LLaVA vs smaller models)?\n2. Are domain prompts reusable or transferable to unseen domains?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ETL7nD4tPX", "forum": "CzVlgDOF7L", "replyto": "CzVlgDOF7L", "signatures": ["ICLR.cc/2026/Conference/Submission16925/Reviewer_5gy3"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission16925/Reviewer_5gy3"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission16925/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761918951095, "cdate": 1761918951095, "tmdate": 1762926948002, "mdate": 1762926948002, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}