{"id": "cy7YVhpW4u", "number": 25520, "cdate": 1758368838263, "mdate": 1759896717544, "content": {"title": "SeedThink: Test-Time Control via Seed-Thought Initialization", "abstract": "Large reasoning models (LRMs) achieve impressive performance via extended chains of thought, but this substantially increases inference overhead, making efficiency a critical bottleneck. In this paper, we first show that initializing the reasoning process with high-quality seed thoughts can steer the model away from unproductive \"overthinking'' and produce more efficient reasoning trajectories. Critically, we find that the optimal granularity of this seed --- from a high-level outline to a detailed solution --- depends on problem difficulty. Motivated by this, we propose SeedThink, a novel framework that adaptively selects the seed granularity based on an estimate of problem difficulty. Specifically, SeedThink features two core innovations: (1) a \\textbf{difficulty-aware seeding policy that dynamically generates seed thoughts} to reduce repetitive verification and prune unproductive branches; and (2) \\textbf{seamless integration with enhanced speculative decoding}, where seed thoughts are reused as a model-free draft corpus to achieve dual-path acceleration --- shorter reasoning traces and faster token generation. Our experiments show that {SeedThink} significantly reduces inference costs while largely preserving performance. Notably, our method achieves up to 4.1× end-to-end speedup and a 68\\% reduction in generation length with minimal accuracy degradation, highlighting the promise of adaptive initialization for balancing reasoning quality and efficiency.", "tldr": "", "keywords": ["Large Reasoning Models", "Speculative Decoding", "Efficient Reasoning"], "primary_area": "foundation or frontier models, including LLMs", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/43c660e875ad2d00d5079a58e751ad9ee1272af2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "SeedThink proposes a two-stage test-time reasoning method where a short “seed thought” is first generated to guide the model’s later detailed reasoning.  It combines a RoBERTa-based difficulty estimator, seed generation using the same LLM, and speculative decoding for early acceleration.  Experiments on Qwen3-8B show shorter reasoning trajectories and up to 2.2× speed-up."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "1. Proposes a clear and novel two-stage reasoning framework that uses a self-generated seed to guide and structure test-time reasoning.  \n2. Demonstrates shorter, more focused reasoning trajectories with consistent accuracy and efficiency gains on reasoning benchmarks.  \n3. Integrates speculative decoding in a simple, training-free way to accelerate early decoding using the seed as a high-quality draft."}, "weaknesses": {"value": "§3.2 Observation  \n1. Limited model scope  \n   Experiments in §3.2 only evaluate Qwen3-8B, a hybrid reasoning model with explicit Thinking / No-Thinking modes. It remains unclear whether the seeding mechanism generalizes to pure reasoning models that lack dual-mode design.\n\n2. Unverified seed correctness  \n   Incorrect or biased seeds may negatively affect reasoning, yet §3.2 provides no quantitative analysis.\n\n3. Single-seed assumption  \n   Each problem uses only one seed or many seed thoughts? If many, §3.2 does not explore multi-seed generation or ensemble strategies that could mitigate bad seeds.\n---\n\n§4.2 Difficulty Estimator  \n1. No reported accuracy  \n   §4.2 introduces a RoBERTa-based difficulty estimator but provides no quantitative results (accuracy, F1, etc.), making its reliability unclear.\n---\n\n§4.4 Speculative Decoding  \n1. No seed length statistics  \n   The paper does not report how many tokens each seed contains or their ratio within the total reasoning context.\n\n2. Unclear need for speculative decoding  \n   - Seeds are short (≈50–150 tokens by estimation), so it is uncertain why speculative decoding is necessary for acceleration.\n   - Since the seed tokens are already generated before reasoning begins, a standard prefill could directly process the full prompt (question + seed).  It remains unclear why speculative decoding is needed, what it specifically accelerates, and whether it actually participates in the later decoding process once the prefill is complete.\n---\n\nFigures and Tables  \n1. Figure 4 — unclear visualization  \n   Figure 4 is not clearly presented, with inconsistent colors and minor formatting issues, like typo \"selfThink\".\n\n2. Table 1 — missing baseline without speculative decoding  \n   Table 1 lacks a SeedThink (without speculative decoding) variant.  Since other baselines use a single-model setup, adding speculative decoding introduces extra memory and compute usage, reducing fairness.\n\n3. Table 1 — limited model diversity  \n   Table 1 only evaluates Qwen3-8B, without comparisons to more pure reasoning models (e.g., Phi-4). It is unclear whether improvements depend on the dual-mode (Think / No-Think) architecture or can generalize to standard reasoning-only models."}, "questions": {"value": "Questions are in the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "fzLkjIn2ax", "forum": "cy7YVhpW4u", "replyto": "cy7YVhpW4u", "signatures": ["ICLR.cc/2026/Conference/Submission25520/Reviewer_7GgU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25520/Reviewer_7GgU"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission25520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761685763630, "cdate": 1761685763630, "tmdate": 1762943460348, "mdate": 1762943460348, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper focuses on the inefficiency of Large Reasoning Models (LRMs), which often exhibit \"overthinking\" behaviors like repetitive verification during complex chain-of-thought (CoT) reasoning. The authors propose SeedThink, a framework designed to improve efficiency by initializing the LRM's reasoning with a \"seed thought.\" The core idea is based on the finding that the optimal granularity of this seed is not fixed, but depends on the problem's difficulty. Consequently, the SeedThink framework operates in a multi-stage process. First, a difficulty classifier (a RoBERTa model) estimates the problem's complexity. Second, based on this classification, a seed thought of adaptive granularity (ranging from a high-level outline for hard problems to detailed steps for easy ones) is generated by the LRM itself using specific prompts. Finally, this seed is used to achieve a \"dual-path acceleration\": it not only guides the LRM to produce shorter, more efficient reasoning traces (by pruning unproductive branches) but is also repurposed as a high-quality, model-free draft corpus to enhance speculative decoding, thereby accelerating token generation speed. The authors conduct experiments, primarily on math benchmarks like GSM8K and MATH, to demonstrate that their method can achieve significant speedups  while maintaining competitive accuracy."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The systematic study in Section 3.2 demonstrates a non-monotonic relationship between optimal seed-thought granularity and problem difficulty (i.e., detailed seeds for easy problems, high-level outlines for hard problems). This is a useful insight for future work on adaptive reasoning.\n2. The method achieves significant speedups (reported up to 4.1x) while maintaining competitive accuracy on the tested math benchmarks."}, "weaknesses": {"value": "1. The proposed method is a complex, sequential pipeline (Classifier -> Seed Generation -> Guided Reasoning). This multi-stage approach is inherently fragile: an error in an early stage (e.g., the classifier misjudging a \"hard\" problem as \"easy\") will cascade and force a suboptimal strategy, potentially harming both accuracy and efficiency.\n2. The paper focuses exclusively on single-instance latency (speedup per sample). In real-world serving scenarios, the critical metric is often system throughput (e.g., total tokens/sec). A multi-stage pipeline introduces significant scheduling, data handling, and I/O overhead that can severely degrade overall system throughput, even if individual sample latency is reduced. The paper does not analyze this trade-off.\n3. The framework's reliance on a separate RoBERTa classifier is a significant practical weakness. This adds non-trivial overhead for training, deployment, and maintenance. More importantly, the classifier's stability and generalization are critical points of failure. The classifier was only tested on a single math dataset, and its ability to generalize to other domains (e.g., coding, general QA) is unproven.\n4. The seed generation relies on a set of pre-defined, manually-crafted prompts (Appendix C). This approach is brittle, contains strong human priors, and is unlikely to generalize to new tasks or domains without significant, task-specific prompt engineering.\n5. The evaluation is heavily concentrated on mathematical reasoning datasets (MATH, GSM8K) and primarily on the Qwen3 model family."}, "questions": {"value": "Could the authors provide a more detailed explanation of how the speculative decoding mechanism is implemented? The paper states the seed is used as a \"model-free\" corpus. Is the seed simply used as a static prefix?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "HgvIPHGTbB", "forum": "cy7YVhpW4u", "replyto": "cy7YVhpW4u", "signatures": ["ICLR.cc/2026/Conference/Submission25520/Reviewer_mFyz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25520/Reviewer_mFyz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission25520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761908111293, "cdate": 1761908111293, "tmdate": 1762943460114, "mdate": 1762943460114, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper addresses the inefficiency of Large Reasoning Models (LRMs) which, despite their strong performance, often suffer from \"overthinking\"—generating excessively long and redundant reasoning paths. The authors' core insight is that initializing the reasoning process with a \"seed thought\" can significantly shorten the reasoning trajectory. Critically, they observe and demonstrate through a pilot study that the optimal granularity of this seed (from a high-level outline to a detailed solution) is dependent on the problem's difficulty.\n\nBased on this, the paper proposes SeedThink, a training-free framework that operates in two stages. First, it uses a difficulty estimator to assess the input problem's complexity. Second, it generates a seed thought with an appropriate level of detail (e.g., an outline for hard problems, detailed steps for easy ones). The final, extended reasoning is then generated conditioned on this seed. A key contribution is the dual use of this seed: not only does it guide the reasoning search to be more efficient, but its token sequence is also repurposed as a high-quality draft for speculative decoding, enabling faster token generation. The authors term this \"dual-path acceleration\". Experiments on math benchmarks (GSM8K, MATH500, AIME 2024) show that SeedThink achieves significant end-to-end speedups (up to 4.1×) and reduces generation length by up to 68%, with only a minimal drop in accuracy."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "While prior work has explored using outlines to guide reasoning (e.g., CoThink), the idea of adapting the granularity of the initial guidance based on an estimate of problem difficulty is a novel and powerful concept. It moves beyond a one-size-fits-all approach to a more nuanced control strategy."}, "weaknesses": {"value": "The evaluation is performed exclusively on mathematical reasoning tasks. While these are excellent benchmarks for complex reasoning, the paper's claims are about a general framework for LRMs. Its applicability and effectiveness on other reasoning-intensive domains, such as code generation, logical reasoning (e.g., LogiQA), or long-form question answering, remain unproven. Demonstrating the method's value on at least one non-math domain would significantly strengthen the paper's claims of generalizability."}, "questions": {"value": "Please refer to Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LurtUb17fV", "forum": "cy7YVhpW4u", "replyto": "cy7YVhpW4u", "signatures": ["ICLR.cc/2026/Conference/Submission25520/Reviewer_2XUz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25520/Reviewer_2XUz"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission25520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761998499399, "cdate": 1761998499399, "tmdate": 1762943459855, "mdate": 1762943459855, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "SeedThink is a reasoning strategy that gives an initial thought called a “seed” that then sets the tone for all future reasoning tokens. This seed is computed based off a preliminary difficulty estimation, which quantifies how tough the problem is in terms of easy, moderate, and hard. Depending on what this difficulty is, the seed is then designed to reflect that complexity. Whatever follows from this seed must be deducible from it, making the seed what the authors call a “reasoning anchor”. The motivation is that large reasoning models (LRMs) struggle with overthinking in the form of too much verification or too many branching reasoning paths such as that found in a multi-path reasoning strategy like Tree of Thoughts or Graph of Thoughts. With this initial seed, the LRM now has a northern star to guide its thinking so that it might be able to avoid these traps."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "*\tThe paper introduces adaptive seed initialization  to mitigate inefficiencies from “overthinking” in chain-of-thought models. It uses structured prior reasoning to prune unproductive reasoning paths.\n*\tDemonstrates up to 4.1× end-to-end acceleration and 68% reduction in token length with minimal accuracy degradation on multiple math benchmarks (GSM8K, MATH500, AIME 2024) and outperforms baselines like CoThink and JointThink in efficiency–accuracy trade-offs.\n*\tCreative reuse of seed thoughts as speculative drafts for acceleration.\n*\tDemonstration of how seed granularity interacts with task difficulty and reasoning length and includes ablation on speculative decoding and reflection/branching token reduction\n*\tThe framework could potentially apply to any reasoning-heavy LLM, suggesting broader implications for efficient inference and adaptive reasoning."}, "weaknesses": {"value": "•\tThe proposed “outline” seeding policy in SeedThink appears conceptually similar to the *Skeleton of Thought* technique presented at ICLR 2024. Although the authors briefly acknowledge this, the overlap in motivation and mechanism warrants deeper discussion.\n\n•\tThe study omits direct comparisons with several key test-time reasoning or preemptive inference strategies such as *ERCogQA, SpecSearch, and Skeleton of Thought*. These represent state-of-the-art techniques that also focus on optimizing inference efficiency and reasoning control.\n\n•\tThe practical efficiency of SeedThink may depend on the underlying LLM serving environment. For instance, differences in batch scheduling, token parallelism, or speculative decoding infrastructure could significantly affect latency and throughput.\n\n•\tThe main novelty lies in combining existing paradigms (difficulty estimation, seeding, speculative decoding), not necessarily in new architectures or algorithms.\n\n•\tThe difficulty estimator is a straightforward text classifier (RoBERTa), not jointly trained or self-adaptive\n\n•\tAll experiments are math benchmarks. It remains unclear how well SeedThink generalizes to open-domain reasoning, multi-hop QA, or commonsense tasks.\n\n•\tAlthough inference is faster, the added step of generating seeds (and running a difficulty estimator) introduces extra pre-processing overhead that’s not quantified.\n\n•\tThe method assumes fine-grained control at inference time (seed injection, speculative hooks) which may be infeasible in API-only or black-box settings.\n\n•\tThe claimed “dual-path acceleration” is empirically shown, but theoretical justification (e.g., why token-level alignment should be high) is descriptive, not formal."}, "questions": {"value": "•\tHow does SeedThink fundamentally differ from Skeleton of Thought beyond adaptive granularity selection? What new capabilities or theoretical insights does it introduce that are not already covered by prior skeleton-based reasoning frameworks?\n\n•\tWhy were these (*ERCogQA, SpecSearch, and Skeleton of Thought*) baselines excluded from evaluation? Could the authors provide either experimental justification showing how SeedThink compares or complements these approaches?\n\n•\tHow robust are the reported efficiency gains across different inference engines and deployment configurations? Would the same improvements hold in real-world LLM serving systems with varying compute backends or parallelization schemes?\n\n•\tHave you tested SeedThink on non-mathematical reasoning tasks or domains requiring longer context (e.g., legal reasoning, scientific QA)? Does the adaptive seeding still hold there?\n\n•\tHow robust is the difficulty classifier across tasks or languages? Could a model self-assess difficulty without external classifiers?\n\n•\tWhat is the average compute/time overhead introduced by generating the seed and difficulty estimate? Is total wall-clock time still reduced when including those?\n\n•\tHow can this method be implemented in commercial APIs or closed models that don’t expose internal “thinking” modes? Would the same approach work with smaller open-weight models?\n\n•\tHow sensitive are the results to the choice of speculative decoding strategy (e.g., SAM, EAGLE3)? Could speculative gains saturate with longer or more abstract seeds?\n\n•\tAre there cases where the seed actually misguides reasoning (e.g., strong but wrong priors)? How does SeedThink recover from such errors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "h3mjxsHyno", "forum": "cy7YVhpW4u", "replyto": "cy7YVhpW4u", "signatures": ["ICLR.cc/2026/Conference/Submission25520/Reviewer_8k81"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission25520/Reviewer_8k81"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission25520/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762100016651, "cdate": 1762100016651, "tmdate": 1762943459684, "mdate": 1762943459684, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}