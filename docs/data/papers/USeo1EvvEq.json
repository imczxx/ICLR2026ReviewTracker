{"id": "USeo1EvvEq", "number": 23116, "cdate": 1758339820028, "mdate": 1759896831727, "content": {"title": "The Stability and Convergence of Two-Timescale Stochastic Approximation with Markovian Noise for Reinforcement Learning", "abstract": "Stochastic approximations (SA)--algorithms which derive their power through the use of random, incremental updates--are at the heart of reinforcement learning (RL). Expanding the theory of SA has established rigorous results concerning the most important algorithms in RL, including stochastic gradient descent and temporal difference learning. In this work, we focus on two-timescale stochastic approximations, a class which notably includes temporal difference learning with gradient correction (TDC) and actor-critic methods. Prior work has developed stability (boundedness) and convergence criteria for two-timescale SA under i.i.d. noise, but analogous results for Markovian noise have remained elusive--a critical issue since RL data are generated by a Markov chain, making i.i.d. assumptions unrealistic. To address this gap, we present the first stability result and the first asymptotic convergence result for two-timescale schemes with Markovian noise under general, verifiable conditions--notably, without resorting to projected variants of the schemes or requiring the noise to be in a compact space. As a key application, we contribute the first asymptotic convergence proof of TDC, an off-policy prediction algorithm with linear approximation and eligibility traces. Together, our results extend SA theory, establishing the first theoretical foundation for analysis of two-timescale algorithms with the realistic noise models inherent to RL.", "tldr": "This work contains the first proofs of stability and convergence of two-timescale stochastic approximation algorithms with Markovian noise, and an application to a reinforcement learning algorithm of interest.", "keywords": ["Stochastic Approximation", "Reinforcement Learning"], "primary_area": "reinforcement learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/8d36f6c7069f4ccc8ba1e5e9620c05dc47d1623b.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper establishes theoretical guarantees for stability and convergence of two-timescale stochastic approximation (SA) under Markovian noises. It then applied the results to temporal difference learning with gradient correction (TDC)"}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. The major strength is to establish boundedness of iterates for general two-timescale SA with Markovian noise, without projections or compactness assumptions (Theorem 2).\n\nS2. It further allows for establishing almost sure convergence of two-timescale SA in unbounded state spaces (Corollary 1)\n\nS3. The general framework is further applied to TDC for establishing convergence."}, "weaknesses": {"value": "W1. The main weakness is that there is no experiment to validate any results. \n\nW2. Only asymptotic results are given, and less is discussed for discretization error."}, "questions": {"value": "Q1. Can the authors illustrate more on the technical difference in Markovian and iid noise case? Intuitively if the Markovian runs into stationary distribution, and during the transition time the iterates stay bounded, does the analysis links with iid noise case?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "cQlNHn7eSJ", "forum": "USeo1EvvEq", "replyto": "USeo1EvvEq", "signatures": ["ICLR.cc/2026/Conference/Submission23116/Reviewer_gcT6"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23116/Reviewer_gcT6"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission23116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761748958572, "cdate": 1761748958572, "tmdate": 1762942516373, "mdate": 1762942516373, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper claims to present the first general stability and convergence results for two-timescale stochastic approximation (SA) schemes under Markovian noise, and to apply these to prove the convergence of the Temporal Difference with Correction (TDC) algorithm with eligibility traces. The work positions itself as filling a long-standing theoretical gap in stochastic approximation theory for reinforcement learning (RL). It uses the ODE method to derive results without requiring projections or compact noise spaces."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The manuscript is logically organized, with clear sections on introduction, related works, assumptions, main results and appendices containing proofs."}, "weaknesses": {"value": "1. Some sections copy the material from [Liu et al, 2025] with minor cosmetic changes. For instance,\nSections 12.1-12.2 are almost the same as the material by [Liu et al, 2025] on page 10\nSection 12.4 is a less detailed version of Section 4.4 in [Liu et al, 2025]\n2. Some of proofs (e.g. Lemmas 12.3, 12.4) coincide with the ones in [Section 3.2, Borkar, 2009] modulo cosmetic changes (see Lemmas 1, 2 in Section 3.2) \n3. No simulations or synthetic examples are provided to show the implications of the results. The absence of any such illustration makes it difficult to assess practical relevance.\n4. The assumptions are described as “mild, minimal” but in practice, they are restrictive (unique stationary distribution, Lipschitz continuity, globally asymptotically stable equilibria). The theoretical claims are therefore less general than the rhetoric suggests.\nTable 1 serves as a key motivation, though the discussion would benefit from a clearer explanation of why earlier Markovian SA results (e.g., Karmakar & Bhatnagar 2018, 2021) cannot be straightforwardly extended."}, "questions": {"value": "1. Several sections (e.g., Sections 12.1, 12.2, 12.4) appear to closely follow the structure and content of Liu et al. (2025) and Borkar (2009). Could the authors clarify which parts of the analysis are genuinely novel and what specific methodological innovations distinguish this work from those prior results?\n2. The assumptions (e.g., unique stationary distribution, Lipschitz continuity, and globally asymptotically stable equilibria) are described as “mild, minimal” but seem rather restrictive in realistic reinforcement learning settings. Could the authors discuss how sensitive their results are to these assumptions, and whether they can be relaxed in future work?\n3. Can you provide an explicit example (even synthetic) of a two-timescale Markovian SA scheme where your results apply but all prior results fail?\n4. Would the authors consider including a simple numerical example or experiment to illustrate the stability and convergence behavior implied by the theory?\n5. Table 1 is used as a central motivation, but it remains somewhat unclear why earlier Markovian SA results cannot be directly adapted to the present setting. Could the authors elaborate on the specific technical challenges or assumptions that prevent such adaptation?\n6. Why is projection-based stability considered fundamentally inferior here? In practice, most RL implementations employ normalization, clipping, or other mechanisms that implicitly act as projections, mitigating divergence issues even without formal projection steps.\n7. Could the results be extended to stochastic approximation with function approximation beyond linear settings, or to non-Lipschitz dynamics?\n8. How do your results compare to those of Liu et al. (2025) in terms of convergence rate guarantees?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "-"}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "HtqxhR01iB", "forum": "USeo1EvvEq", "replyto": "USeo1EvvEq", "signatures": ["ICLR.cc/2026/Conference/Submission23116/Reviewer_Cryz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23116/Reviewer_Cryz"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission23116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761905141699, "cdate": 1761905141699, "tmdate": 1762942516123, "mdate": 1762942516123, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper develops stochastic approximation theorem for two-time scale method with Markovian noise. The authors establish a stability theorem, which shows the boundedness of the iterates, and then the convergence, which is followed by the asymptotic behavior of the corresponding ODE. The key novelty in the proof is argued to be a particular relation between the two iterates."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The authors provide a useful result the the community as two-time sclae based stochastic approximation with Markovian nosie is a widely considered scenario in the community. A convergence result for TDC is provided as an example, which shows the usefulness of the developed theorem.\n\n\n2. The authors formalize a useful inequality (Theorem 1) which could be of independent interest,  aside from the stability or convergence result, which establishes fo relation between the two iterates."}, "weaknesses": {"value": "1. The main concern is on the novelty of the proof and result of Theorem 1. The proof seems to follow that of Borkar and Meyn Theorem or Lakshminarayanan and Bhatnagar, defining the rescaled iterate to show boundedness. In particular the proof method of Lakshminarayanan and Bhatnagar also relies on the relation between the iterate $x_n$ and $y_n$. Therefore, as for now, it is not clear how the proof technique differ except for the difference of Markovian and i.i.d. case.\n\n2. The presentation of the paper feels not friendly for several reasons. 1) The Lemmas are somewhat enumerated in serial manner, making it difficult to grasp the overall picture of the proof; 2) In Section 5, the authors assume $\\sup_n r_n=\\infty$ to obtain contradiction. But this is never mentioned again till the end of Section 6, which makes the overall picture of the proof unclear."}, "questions": {"value": "1. In addition to the result of Lakshminarayanan and Bhatnagar, there has been quite a literature on two-time scale methods dealing with its non-asymptotic analysis. Considering such literature, is still the inequality in Theorem 1, can be considered a unique result?\n\n2. How does the proof of showing the discreteization error of the rescaled iteration and its corresponding ODE going to zero differ from that of the stnadrad Borkar and Meyn Theorem?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "details_of_ethics_concerns": {"value": "na"}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "iCxWBf75cR", "forum": "USeo1EvvEq", "replyto": "USeo1EvvEq", "signatures": ["ICLR.cc/2026/Conference/Submission23116/Reviewer_bWeS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23116/Reviewer_bWeS"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission23116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761973660941, "cdate": 1761973660941, "tmdate": 1762942515893, "mdate": 1762942515893, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper analyzes two-timescale stochastic approximation with Markovian noise, providing stability (boundedness) and asymptotic convergence for general coupled updates without projections or compactness assumptions on the noise space. The framework targets RL settings with eligibility traces and off-policy importance ratios. As an application, the authors prove convergence of TDC with eligibility traces under standard conditions."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- **Closes a gap:** Prior Markov-noise analyses often require compactness or projections; this work handles unprojected iterates in non-compact noise spaces.\n- First convergence proof (to my knowledge) for TDC with eligibility traces without projections."}, "weaknesses": {"value": "There aren't any major weaknesses. However, a large part of the analysis seems to be following the standard existing analyses except for the part on the rescaling factor r_n. It would be helpful to explicitly explicitly articulate the analysis novelty versus existing proofs: isolate the steps that hinge on the rescaling factor.\n\nMissing reference on multi-timescale SA: https://arxiv.org/pdf/2112.03515"}, "questions": {"value": "- Can you explicitly articulate the analysis novelty versus existing proofs, and isolate the steps that hinge on the rescaling factor to better unserstand the novelty in the paper wrt existing work\n\n- Some typos: we now prove results on $t\\in (\\infty, \\infty)$, in Assumption 2:  $n\\rightarrow \\infty$"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "LMhLsx3uIe", "forum": "USeo1EvvEq", "replyto": "USeo1EvvEq", "signatures": ["ICLR.cc/2026/Conference/Submission23116/Reviewer_FLRW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission23116/Reviewer_FLRW"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission23116/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762026630211, "cdate": 1762026630211, "tmdate": 1762942515697, "mdate": 1762942515697, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}