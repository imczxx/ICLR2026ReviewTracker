{"id": "IcR7OI3uLm", "number": 11339, "cdate": 1758196744765, "mdate": 1759897582255, "content": {"title": "ProSAR: Prototype-Guided Semantic Augmentation and Refinement for Time Series Contrastive Learning", "abstract": "Contrastive learning has advanced the representation learning of vision, language, and graphs, yet its success hinges greatly on the data augmentation that helps preserve semantic contents while providing the view diversities. Multivariate time series, however, are noisy, non-stationary in nature, and largely opaque to the human inspection. Therefore, a direct use of the the hand-crafted transforms, such as jitter and scaling, may unfortunately destroy the critical temporal cues or introduce false negatives, weakening the performance of downstream tasks.\nTo address this, we propose ProSAR, a prototype-guided semantic augmentation and refinement framework for time series contrastive learning. Most critically, ProSAR's approach is founded on an information-theoretic principle for co-designing the semantic data augmentations and learnable prototypes, aiming to generate views that maximize the information about an associated semantic prototype while discarding the prototype-irrelevant content. ProSAR then implements this by introducing a novel prototype-conditioned semantic segment extraction mechanism, where the temporal characteristic segments are identified based on their dynamic time warping (DTW) alignment to these learnable time-domain prototypes, ensuring that the generated views can capture high-level semantic events. Building upon these temporal characteristic segments, the targeted augmentations, operating in both the time and frequency domains and informed by the DTW alignments, can thus preserve the temporal dynamics while constructing views that adhere to the information-theoretic objectives. Furthermore, prototypes are dynamically refined in a feedback loop, where the latent representations of these prototypes are refined via clustering under the prototypical contrastive training, and in turn guide evolution of the time-domain prototypes through a decoding consistency mechanism, thus fostering a progressive learning of robust representations. Experiments on diverse time-series benchmarks demonstrate that ProSAR outperforms recent contrastive and self-supervised representation learning methods in the downstream forecasting and classification tasks.", "tldr": "", "keywords": ["Time series representation learning", "contrastive learning", "data augmentation"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/42b441990003b196118590cd8281abf602aee4db.pdf", "supplementary_material": "/attachment/0fa2b896e5a317f3be313b21616a9b0126e782f1.zip"}, "replies": [{"content": {"summary": {"value": "This paper proposes ProSAR, a prototype-guided semantic augmentation and refinement framework for self-supervised time-series representation learning. Built upon the information-bottleneck principle, ProSAR co-designs learnable prototypes and data augmentations to preserve task-relevant temporal semantics while discarding noise. Specifically, it introduces (1) prototype-conditioned semantic segment extraction via DTW alignment, (2) targeted augmentation in both time and frequency domains, and (3) a dual-prototype refinement loop linking latent and time-domain prototypes through decoding consistency."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "PProSAR is conceptually elegant and highly readable. It connects information-theoretic augmentation design with prototype learning, offering both interpretability and empirical strength. The co-design of prototypes and augmentations is well-motivated, and the dual-loop refinement provides a unified view bridging input and latent spaces."}, "weaknesses": {"value": "1. While the framework is grounded in the information-bottleneck principle, the derivation stops at intuitive propositions. There is no formal proof that the proposed co-optimization converges or that the learned prototypes indeed approximate the latent semantic variable.\n\n2. The use of DTW for semantic segmentation is computationally intensive (O(T²)), which may limit scalability for long sequences or large datasets. The paper should quantify training cost and discuss potential accelerations.\n\n3. The framework introduces multiple components, yet lacks sensitivity analysis."}, "questions": {"value": "See the above Weaknesses and the following:\n\n1. What is the actual computational cost of DTW-based segmentation per epoch? Have you tried Soft-DTW or pruning techniques to improve efficiency?\n\n2. How would ProSAR handle irregular or very long time series?\n\n3. Is the prototype refinement stable under streaming or online updates?\n\n4. Could the prototype-guided augmentation concept generalize to other modalities (spatial-temporal graphs, videos) or multi-domain transfer tasks?\n\n5. Can you provide qualitative examples showing what a “semantic prototype” represents—e.g., typical waveform patterns or frequency signatures?\n\n6. Provide a more formal analysis (e.g., gradient coupling or fixed-point stability) to justify the convergence of the prototype–augmentation co-design process?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "VTSmxIaAXf", "forum": "IcR7OI3uLm", "replyto": "IcR7OI3uLm", "signatures": ["ICLR.cc/2026/Conference/Submission11339/Reviewer_uqQY"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11339/Reviewer_uqQY"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761579136870, "cdate": 1761579136870, "tmdate": 1762922473893, "mdate": 1762922473893, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes ProSAR, a prototype-guided semantic augmentation and refinement framework for time series contrastive learning. The core idea is to jointly learn data augmentation strategies and semantic prototypes under an information-theoretic constraint: time-domain prototypes obtained through DTW alignment guide the generation of augmented views, applying different perturbations to semantic and non-semantic segments, while latent-space clustering and decoding consistency iteratively refine the prototypes. The proposed method aims to produce semantically consistent yet diverse views, achieving superior performance to self-supervised baselines such as AutoTCL and FreRA on both forecasting and classification benchmarks."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "Incorporating learnable prototypes into the data augmentation process represents a meaningful conceptual innovation, breaking through the limitations of fixed or purely heuristic augmentation strategies in traditional contrastive learning.\n\nThe proposed dual-prototype mechanism—comprising time-domain and latent-space prototypes—and its iterative refinement loop demonstrate a coherent and logically consistent system design."}, "weaknesses": {"value": "The authors did not compare ProSAR against several representative time-series representation learning models such as TSLANet and AimTS. Compared with these baselines, the reported results are not particularly competitive.\n\nAlthough the idea of prototype-guided augmentation is interesting, the overall contribution appears incremental. The differences between ProSAR and prior works like AutoTCL and AimTS remain relatively small.\n\nThe claimed interpretability is unconvincing—especially the visualizations shown in Section D.4, which do not make much sense and fail to clearly demonstrate semantic consistency or prototype meaning.\n\nThe framework consists of multiple submodules (DTW segmentation, STFT alignment, dual prototypes, clustering, and decoding consistency), yet the ablation studies only examine the augmentation operation and the semantic segmentation, which is insufficient to validate the contribution of each component.\n\nThe reliance on DTW alignment and clustering could introduce significant computational overhead for long or high-frequency sequences. Although the paper briefly acknowledges this issue, it lacks a concrete analysis of time complexity or runtime performance."}, "questions": {"value": "See weakness"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "zulZl9WyRO", "forum": "IcR7OI3uLm", "replyto": "IcR7OI3uLm", "signatures": ["ICLR.cc/2026/Conference/Submission11339/Reviewer_rcHy"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11339/Reviewer_rcHy"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761799018199, "cdate": 1761799018199, "tmdate": 1762922473517, "mdate": 1762922473517, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper presents ProSAR, a self-supervised framework that integrates information-theoretic principles with learnable prototypes to guide semantic augmentation for time-series contrastive learning. It introduces prototype-conditioned segment extraction using DTW and a dual prototype refinement loop between latent and time-domain prototypes. Experiments on forecasting and classification benchmarks show consistent improvements over recent SSL baselines."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "S1. The paper clearly identifies the limitation of heuristic or random augmentations in time-series CL and grounds its design in an information-bottleneck formulation.\n\nS2. Results across both forecasting and classification tasks are strong and consistent, with comprehensive ablations demonstrating component contributions.\n\nS3. The paper is generally well-written and the framework diagram effectively illustrates the mechanism."}, "weaknesses": {"value": "W1. The idea shares conceptual similarities with prior prototype-based methods (e.g., MHCCL, AimTS); the contribution is more an integration than a fundamentally new paradigm.\n\nW2. The DTW-based semantic segmentation and dual refinement introduce substantial computational cost and hyperparameter sensitivity.\n\nW3. Although prototypes are claimed to be “semantic,” the paper provides minimal qualitative analysis of what semantics they actually capture.\n\nW4. Lacks comparison with large-scale pretrained or generative SSL frameworks."}, "questions": {"value": "Q1. How computationally expensive is the DTW-based segmentation step? Can the framework scale to large datasets such as Traffic or PEMS?\n\nQ2. The method introduces both time-domain and latent-space prototypes. How sensitive is the performance to the number of prototypes or their initialization?\n\nQ3. Can the learned prototypes be visualized or qualitatively analyzed to confirm that they correspond to meaningful temporal semantics rather than cluster artifacts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "ZFzJxqKCBy", "forum": "IcR7OI3uLm", "replyto": "IcR7OI3uLm", "signatures": ["ICLR.cc/2026/Conference/Submission11339/Reviewer_wvmW"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11339/Reviewer_wvmW"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761916211236, "cdate": 1761916211236, "tmdate": 1762922473216, "mdate": 1762922473216, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "ProSAR (Prototype-Guided Semantic Augmentation and Refinement) is a self-supervised learning framework developed for multivariate time series (TS) contrastive learning (CL), addressing the limitation that standard hand-crafted augmentations risk destroying critical temporal cues and semantic content in noisy, non-stationary TS data. ProSAR’s approach is founded on an information-theoretic principle derived from the Information Bottleneck, aiming to generate augmented views that maximize the information about an associated semantic prototype (P) while discarding content irrelevant to that prototype. This objective is implemented using learnable time-domain prototypes as explicit semantic anchors, which guide the identification of temporal characteristic segments in the input time series (x) via Dynamic Time Warping (DTW) alignment. Experimental evaluations on diverse benchmarks demonstrate that ProSAR achieves superior performance in learning discriminative representations, attaining the highest mean accuracy (0.764) and the best mean rank (1.867) on the UEA multivariate time series archive for classification, and consistently surpassing comparison methods in forecasting tasks."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The submission is written clearly and is well structured, making the main ideas and technical contributions easy to follow. The motivation is articulated convincingly, and the authors provide sufficient context for why the problem is relevant and timely. Additionally, the related work section is thorough and appropriately cited, demonstrating a solid understanding of the existing literature and situating the proposed approach within the broader research landscape. Overall, the presentation is polished and the narrative is coherent and well motivated."}, "weaknesses": {"value": "W1. \n\nWhile the paper is generally well written, the claimed novelty of the proposed approach is not clearly articulated or sufficiently demonstrated. The authors state that their method offers better prototypes with better semantics, but it remains unclear how these prototypes differ from or improve upon existing prototype-based contrastive learning approaches. The manuscript would benefit from a more explicit and detailed discussion of what is fundamentally novel, ideally supported by conceptual distinctions, empirical evidence, or ablations that isolate the proposed contribution. For instance, with the expressions in Lines 72 - 75, as well as Lines 92 - 96, it remains unclear how the proposed prototype-based anchors significantly differ from existing ones, and it remains unclear how the proposed method can improve the interpretability, contrallability of the anchors.\n\n\nW2. \n\nFor Line 161, \"these prototypes are dynamically refined to steer the augmentation policy\"; however, existing prototype-based or clustering-based constrastive learning approaches also dynamically update the prototypes. What are the key differences? \n\n\nW3. \n\nIt remains unclear how the proposed prototypes substantively differ from those used in existing prototype-based methods. The paper would benefit from a clearer explanation of the conceptual or algorithmic distinctions. In addition, the experimental evaluation could be strengthened by including comparisons with a broader range of prototype-based and clustering-based contrastive learning approaches, which would help more convincingly demonstrate the advantages of the proposed method."}, "questions": {"value": "Please see Weaknesses above"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Z4K9SxU3B7", "forum": "IcR7OI3uLm", "replyto": "IcR7OI3uLm", "signatures": ["ICLR.cc/2026/Conference/Submission11339/Reviewer_4WyG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11339/Reviewer_4WyG"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11339/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761978259747, "cdate": 1761978259747, "tmdate": 1762922472859, "mdate": 1762922472859, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}