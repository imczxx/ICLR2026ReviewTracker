{"id": "sokvfawAYu", "number": 17974, "cdate": 1758282570072, "mdate": 1759897141624, "content": {"title": "DANCE-ST: Why Trustworthy AI Needs Constraint Guidance, Not Constraint Penalties", "abstract": "Neural networks achieve high accuracy in spatiotemporal prediction but often violate physical constraints, creating a fundamental accuracy-safety dilemma. We introduce DANCE-ST, a constraint-guided learning framework that resolves this trade-off by treating physical laws not as adversarial penalties, but as collaborative information sources that actively guide learning. Our core contribution is a novel three-phase architecture that (1) identifies critical system components by diffusing state-dependent \"constraint potentials\" through a knowledge graph, (2) intelligently fuses neural and physics-based predictions with provable error bounds for asynchronous sensors, and (3) projects predictions onto the constraint-satisfying space with guaranteed linear convergence. This architecture is orchestrated by a fault-tolerant multi-agent system for robust deployment.\nExperiments on industrial datasets demonstrate 97.2\\% constraint satisfaction while achieving state-of-the-art accuracy and the fastest inference time (38.4s) among constraint-aware methods. Critically, DANCE-ST delivers superior, verifiable interpretability (4.6/5 vs 3.8/5). By design, it provides explainable insights into which system components drive constraint violations, directly addressing the transparency requirements of emerging safety regulations (e.g., EU AI Act, FDA AI guidelines) in a way black-box enforcement cannot. Our work establishes constraint-guided learning as a foundational paradigm for trustworthy AI, demonstrating that the accuracy-safety trade-off is a false dilemma when constraints become collaborative guides.", "tldr": "DANCE-ST transforms physical constraints from obstacles into guidance signals, using a fault-tolerant multi-agent architecture to combine neural networks and physics models for safe, accurate spatiotemporal prediction in safety-critical systems.", "keywords": ["Constraint-guided learning", "Neurosymbolic systems", "Multi-agent learning", "Physics-informed neural networks", "Safe machine learning", "Spatiotemporal prediction", "Trustworthy AI", "Fault-tolerant systems"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/76ddca0f406736d05c04fc0683afa6546e228cda.pdf", "supplementary_material": "/attachment/909a8245e1111bcb6c2e146e774e92ab2731acb9.zip"}, "replies": [{"content": {"summary": {"value": "The paper proposes a framework for enforcing output constraints during the deployment of forecasting models for physical systems. The method combines a pre-trained neural network with a separate physics-based symbolic model. The system is represented as a graph where vertices correspond to components to be forecasted and edges encode their physical dependencies.\n\nThe algorithm proceeds in three phases. First, it identifies the top-k components that are most at risk of violating their constraints at the current time t. For these selected nodes, the prediction for t+1 is computed as a weighted average of the neural and symbolic models, with weights shifting toward the symbolic model when the system is close to violating a constraint. The paper does not specify how predictions are obtained for the remaining, stable nodes. Finally, the full prediction vector for all components is projected onto the feasible set to guarantee physical validity of the output."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "**Originality**. The paper’s main originality lies in its architectural design, which integrates three distinct ideas: relevance-based node selection, neurosymbolic fusion, and a projection step. The selective focus on a subset of nodes also provides built-in interpretability.\n\n**Quality**. The paper presents an extensive empirical evaluation across three industrial datasets, supported by a detailed ablation study and robustness analysis.\n\n**Clarity**. There is not much to praise in terms of clarity.\n\n**Significance**. The work addresses a highly relevant problem—ensuring safety in AI systems deployed in physical environments. The emphasis on interpretability is a welcome addition."}, "weaknesses": {"value": "The paper has numerous weaknesses which underscore my recommendation for rejection.\n\n### Flawed Experimental Section\n\n1. **HardNet Baseline is Fundamentally Misrepresented**.\nThe paper's experimental validation appears to be flawed due to two major inconsistencies in the HardNet baseline results.\n\n    First, the paper reports a *~2% constraint violation rate for HardNet*. This is inconsistent with the method’s design; HardNet computes outputs via a closed-form projection that guarantees feasibility, and the original HardNet paper reports *0 constraint violations* across all experiments. A deviation of this magnitude cannot reasonably be attributed to minor numerical drift and instead strongly suggests an implementation error.\n\n    Second, the reported *>40 second inference time for HardNet is unlikely*. HardNet’s projection is closed-form, and the original paper reports inference in the *millisecond range* for a problem of comparable scale (100 variables and 100 constraints). While the hardware differs, this alone cannot account for a discrepancy of almost four orders of magnitude. This reinforces the suspicion that the authors relied on an incorrect or at the very least severely unoptimized implementation of a key baseline, which *undermines the credibility of the entire experimental comparison*.\n\n2. **The Method Fails to Guarantee Feasibility**.\nThe proposed method fails to meet the primary requirement of a framework for enforcing constraints: guaranteeing feasible solutions. The paper reports only 97.2% constraint satisfaction, a critical failure for a method intended for safety-critical systems where even rare violations can be catastrophic. \n\n3. **The Paper's Efficiency Claims are Misleading**\nThe paper's claims of efficiency are misleading, as the reported speed is achieved at the direct cost of feasibility. A rigorous evaluation would have analyzed the trade-off between more iterations and achieving a 100% guarantee—a trade-off the authors fail to address.\n\n    Furthermore, any claims of practical efficiency are undermined by the high upfront cost of constructing the knowledge graph, which the authors state requires 120 person-hours per domain.\n\n### The Framework's Complexity is Unjustified\n4. **The Framework's Complexity is Unjustified**.\nAt its core, the proposed framework is a projection method with additional, complex pre-processing stages, but the necessity of these extra steps is not convincingly justified. The authors argue that this pre-processing improves final performance, citing an ablation study where removing the relevance-selection filter (Phase 1) causes a catastrophic drop in performance.\n\n    However, their interpretation of this result is questionable. The authors claim the performance drop occurs because the model \"loses focus on the most relevant signals,\" but they fail to disprove an alternative hypothesis: that the subsequent fusion and projection stages are fragile, and that Phase I's primary function is merely to shield them from the full problem's complexity by reducing the input size. The lack of a proper control experiment (e.g., applying Phases 2 and 3 on a random subset of nodes) leaves this justification unsubstantiated.\n\n    The ablation study shows that removing Phase I also causes a significant 3.0 percentage point drop in constraint satisfaction. The paper offers no explanation for why that would also harm feasibility.\n\n### The Theoretical Foundations are Unsound\n5. **The Paper Lacks a Universal Approximation Guarantee**\nA major theoretical flaw is the absence of a universal approximation guarantee. This is required to show that an architecture modified to enforce constraints can still represent the optimal feasible solution.\n\n6. **Unsound Proof of Lemma C.1**  \nThe proof of Lemma C.1—which underpins the robustness claim in Theorem C.1—is mathematically unsound. Its final step asserts that for$ \\Omega, \\alpha' \\in [0,1] $, the difference $ |\\Omega - \\alpha'| \\le \\tfrac{1}{2} $ must hold. This bound is incorrect, and no argument is provided to justify why the computed fusion weight $ \\Omega $ should necessarily lie within 0.5 of the “true” interpolation factor $ \\alpha' $.\n\nIf the bound is relaxed to the correct range $ |\\Omega - \\alpha'| \\le 1 $, the result becomes vacuous—it merely states that the fusion error cannot exceed the total disagreement between predictors, which offers no nontrivial robustness guarantee. Consequently, the claim of a *provably robust* fusion process is unsupported unless a missing justification establishes the tighter 1/2 bound.\n\n### Poor scientific practices\n\n7. **Overclaiming and Lack of Scientific Rigor**. \nThe paper fails to properly scope its contribution and makes several claims that are not supported by evidence.\n\n    The authors overclaim the significance of their work, framing a method for physics-informed forecasting as a \"foundational paradigm for all trustworthy AI\". This is an overstatement, as the framework relies on several strong assumptions—such as the existence of a graph structure, a valid physics-based model, and predominantly convex constraints—that are not generalizable to many other domains.\n\n    Other examples of misleading claims appear in Section 3.3. For instance, the paper introduces an error correlation bound of $\\rho < 0.35$ between the neural and symbolic models and a convexity parameter of $\\mu > 0.03$, presenting them as if they were general principles rather than quantities tied to a very specific and narrow problem setting, which is never clearly specified.\n\n8. **Methodological Gaps Make the Work Irreproducible**\nThe authors state that their core logic is applied only to the top-k \"risky\" nodes identified in phase 1 but never specify what prediction is used for the remaining, stable nodes. However, the final projection in Phase 3 requires a full system vector to ensure global consistency across coupled constraints. \n\n9. **Poor Presentation**\nThe paper's presentation is not up to the standards of a scientific publication. The writing is often unclear, and the core methodology is difficult to follow. The use of informal language (e.g., \"hasn't\") further contributes to a general lack of rigor."}, "questions": {"value": "1. The authors do not report any LLM use. Can they confirm that they did not use LLMs in the development of their work?\n\n2. What prediction model is used for the remaining nodes not selected by the top-k filter in Phase I?\n\n3. Why did you not consider a hybrid residual model, where a neural network predicts the symbolic model’s error and the final output is then projected? This seems like a more straightforward approach, as it avoids the need to tune weights for the fusion of the two models. Moreover, because this formulation relies heavily on the symbolic model by design, it should be more naturally inclined toward feasibility, potentially making the projection step easier or more successful in terms of performance."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "mQuJlTyInV", "forum": "sokvfawAYu", "replyto": "sokvfawAYu", "signatures": ["ICLR.cc/2026/Conference/Submission17974/Reviewer_QQrS"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17974/Reviewer_QQrS"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission17974/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760824477012, "cdate": 1760824477012, "tmdate": 1762927769883, "mdate": 1762927769883, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes DANCE-ST, a novel constraint-guided learning framework for trustworthy spatiotemporal prediction. Instead of treating physical constraints as loss penalties or post-hoc enforcement, DANCE-ST interprets them as collaborative information sources that actively guide the learning process.\nThe method proceeds through three phases:\n\n1. Constraint-Potential Diffusion identifies critical system components by propagating state-dependent “constraint potentials” over a knowledge graph.\n\n2. Neurosymbolic Fusion combines neural and physics-based predictions with variance-based weighting and theoretical error bounds for asynchronous sensors.\n\n3. Structure-Exploiting Projection ensures final predictions satisfy physical constraints via an adapted Douglas–Rachford scheme with guaranteed linear convergence.\n\nThe entire pipeline operates within a fault-tolerant multi-agent architecture, providing robustness to component failures. Experiments on multiple industrial datasets (C-MAPSS, Turbine-500, FEMTO Bearings) and a medical dataset (MIMIC-III) demonstrate high constraint satisfaction (97.2%), strong predictive accuracy, and superior interpretability (4.6/5 explainability score)."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "The paper presents a highly original conceptual shift in the field of trustworthy AI and physics-informed learning. Instead of viewing physical or safety constraints as penalties imposed after prediction, DANCE-ST treats them as collaborative guides that actively shape learning throughout the pipeline.\n\nIn terms of quality, the work demonstrates exceptional technical depth. Each phase of the DANCE-ST framework is rigorously developed, theoretically grounded, and empirically validated. The authors provide mathematical convergence guarantees, uncertainty-aware fusion bounds, and extensive ablation studies, which collectively demonstrate the robustness and reliability of the approach.\nRegarding clarity, the paper is generally well organized and methodically presented.\n\nFinally, the significance of the work is high. The approach bridges gaps between deep learning, physics-based modeling, and explainability. It provides both theoretical insights (e.g., constraint-guided optimization geometries) and practical solutions (fault-tolerant deployment, interpretability metrics) that can influence future research in safety-critical machine learning."}, "weaknesses": {"value": "First, the framework relies heavily on manually constructed knowledge graphs, requiring around 120 person-hours per domain. This dependence on expert modeling limits scalability and reproducibility.\n\nSecond, while the paper’s central idea is conceptually original, the individual technical components (graph diffusion, uncertainty-weighted fusion, Douglas–Rachford projection) are adapted from established methods. The contribution therefore lies in integration rather than algorithmic novelty.\n\nThird, the theoretical guarantees rely on strong convexity and monotonicity assumptions that may not hold in complex, real-world systems with non-convex constraints.\n\nFinally, the interpretability evaluation lacks methodological transparency (the reported 4.6/5 expert score is not supported by details on rating criteria or sample size). Providing clearer evaluation protocols or qualitative case studies would substantiate these claims."}, "questions": {"value": "1. Clarifying what is theoretically new in the fusion mechanisms (this DANCE-ST algorithm), or providing additional ablations comparing with standard versions, would better highlight genuine methodological advances.\n\n2. Theoretical guarantees rely on convex constraints, but many real systems involve non-convex or discontinuous ones. How does DANCE-ST perform when these assumptions are violated, and could the authors provide empirical evidence or discussion on robustness under non-convex conditions?\n\n3. The reported 4.6/5 interpretability score is compelling but under-detailed. How many experts participated, what criteria were used, and was inter-rater agreement assessed?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "pvUsozE2XL", "forum": "sokvfawAYu", "replyto": "sokvfawAYu", "signatures": ["ICLR.cc/2026/Conference/Submission17974/Reviewer_4uXA"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17974/Reviewer_4uXA"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission17974/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761559110404, "cdate": 1761559110404, "tmdate": 1762927768872, "mdate": 1762927768872, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper presents DANCE-ST (Distributed Agent Network for Constraint-Enabled Spatiotemporal prediction). DANCE-ST is concerned with improved predictions where, e.g., physical constraints such as material properties need to be respected. To this end, a neural predictor $f_n$ and a symbolic predictor $f_s$ are employed and integrated into a combined predictor $f_{int}$. The authors demonstrate on three datasets (NASA C-MAPSS, Turbine-500, and FEMTO Bearing) competitive accuracy while improving on constraint satisfaction, computation time, and explainability scores."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "- The related work section provides a good overview of competing approaches and Tables 1 & 2 especially help understanding how DANCE-ST is supposed to differ.\n- The integration of neural and symbolic prediction described in Sections 3 and 4 is intuitive and easy to follow.\n- The ablation study shows well how each phase of DANCE-ST provides an important benefit to the task."}, "weaknesses": {"value": "- Sections 1 and 2 provide numbers and claims about DANCE-ST's performance that lack context to fully understand their meaning or impact. For example, Table 1 shows a checkmark for DANCE-ST on all columns with added annotations such as (38.4s) for real-time capabilities or (multi-agent) for scalability. Without context, such as the competing methods' runtime (on the same problem and hardware), the the two sections felt uninformative and puzzling.\n- The paper often leaves me puzzled on how some concrete numbers are justified (DANCE-ST converges in 135 iterations, \"generic methods\" require > 1000 iterations, ...). For example, is there a citation for the specific correlation boundary ($\\rho < 0.35$) on the discussed failure modes in line 197?\n- The paper states that \"While HardNet achieves the highest constraint satisfaction (98.1%), DANCE-ST delivers competitive constraint satisfaction (97.2%) with superior performance in accuracy, efficiency, and interpretability\". But, Table 3 does not show superior accuracy, with numbers being extremely similar between HardNet and DANCE-ST."}, "questions": {"value": "I have no questions to the authors."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "XR8g5vpzXB", "forum": "sokvfawAYu", "replyto": "sokvfawAYu", "signatures": ["ICLR.cc/2026/Conference/Submission17974/Reviewer_YExx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17974/Reviewer_YExx"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission17974/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761733855956, "cdate": 1761733855956, "tmdate": 1762927766566, "mdate": 1762927766566, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper proposes DANCE-ST, a three-phase, constraint-guided framework (relevance selection →  neuro-symbolic fusion →  structure-aware projection) for spatiotemporal prediction under physical constraints. It also targets high accuracy and high constraint satisfaction, and uses multi-agent deployment."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 3}, "strengths": {"value": "- The idea of using constraints as guides rather than penalties is fresh.\n- The paper presents strong quantitative results and a well-organized table with plenty of comparisons.\n- The paper is pleasant to read."}, "weaknesses": {"value": "- Phase I proposes an appealing idea of constraint-potential diffusion to identify critical components, but it relies on overly strong assumptions. The method assumes that the physical coupling graph is accurate, static, and sparse, whereas real-world systems are often nonlinear, time-varying, and uncertain.\n\n- The diffusion mechanism is linear and heuristic, rather than physically derived, which limits the realism of the proposed “guidance.”\n\n- The reported interpretability score (4.6 / 5) lacks details to fully understand and appreciate it. \n\n- The paper would be better with stronger ablation studies, especially with different hyperparameter settings.\n\n- There is also a citation issue: the reference “Jianwei Zheng et al., ICLR 2025” lists the wrong authors. The correct authors are Ricardo Buitrago Ruiz, Tanya Marwah, Albert G and Andrej Risteski. Please verify and correct all references.\n\n- The writing is vague in several places. Many abbreviations are not properly introduced (e.g., QP, MCP introduced in the appendix, A2A), and important concepts such as the knowledge graph appear without background. This makes it hard for reviewers unfamiliar with the terminology to follow the logic of your narrative. \n\n- Figure 1 is dense and difficult to interpret due to many unexplained acronyms."}, "questions": {"value": "1. For the interpretability score, please clarify the number of raters, domains evaluated, and example tasks.\n\n2. What are the effects of hyperparameter variation on the results?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "A4jvXbs8bD", "forum": "sokvfawAYu", "replyto": "sokvfawAYu", "signatures": ["ICLR.cc/2026/Conference/Submission17974/Reviewer_L4hc"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission17974/Reviewer_L4hc"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission17974/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761950763724, "cdate": 1761950763724, "tmdate": 1762927766097, "mdate": 1762927766097, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}