{"id": "QWvrz4qzqU", "number": 24846, "cdate": 1758361039995, "mdate": 1759896745653, "content": {"title": "Accuracy at Lower Cost: Rethinking Client Selection in Federated Learning", "abstract": "Federated learning (FL) enables collaborative model training across multiple clients without sharing raw data, thereby ensuring privacy.\nA critical performance factor for FL is client selection. Under independent and identically distributed (IID) data, clients are chosen at random, which can lead to reduced accuracy, slower convergence, and higher communication cost.\nIn this work, we present a systematic empirical study of client selection, revealing that random participation can significantly degrade performance. Motivated by these findings, we introduce a multi-objective optimization strategy that jointly balances model accuracy and communication cost under IID partitioning. For fast evaluation, we propose a dataset complexity-aware surrogate regressor that predicts the FL outcomes (e.g., accuracy or loss) for image classification tasks, thereby avoiding costly full model training. \nUsing the predicted client configuration (number of selected and available clients) resulting from multi-objective optimization on a new dataset, and without requiring any additional training, our framework achieves 98.9\\% of the maximum attainable accuracy while incurring only 38.75\\% of the maximum communication cost. Moreover, it identifies a diminishing‑returns regime that preserves 99.9\\% of peak accuracy while reducing cost to 63.12\\%. These results demonstrate that both the performance and variance of FL can be estimated solely by dataset complexity and client dataset size, enabling the identification of client configurations that best balance accuracy and communication costs.", "tldr": "Optimal Client Selection for Federated Learning by balancing Accuracy and Communication Cost", "keywords": ["Federated Learning", "Client Selection Problem"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/902a3357ff0308fd0ead745789b08804528336d3.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper proposes a dataset-complexity-aware optimization framework for client selection in federated learning (FL), aiming to achieve high model accuracy at lower communication cost.\n\nBy leveraging surrogate regression models (notably AdaBoost) and multi-objective optimization via a bi-level (grid + genetic) approach, the method predicts FL performance without direct training.\n\nExperiments across several image datasets (MNIST, CIFAR-10, STL-10, SVHN) demonstrate that the framework can achieve up to 98.9% of the maximum accuracy while using only 38.75% of total communication cost, suggesting strong cost–accuracy trade-offs."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "- Introduces dataset-complexity-aware regressors to estimate FL outcomes without training, reducing computational overhead.\n- Formulates client selection as a bi-objective problem balancing accuracy and cost.\n- AdaBoost achieves high predictive accuracy ($R^2 = 0.983$, MSE = 0.224), showing that the surrogate model effectively approximates real FL performance."}, "weaknesses": {"value": "- The approach is validated only on IID data, limiting its generalizability to real-world non-IID conditions that dominate practical FL settings.\n- The cost function ignores latency, bandwidth variability, and client dropouts, which weakens its realism and applicability.\n- Despite citing methods like DivFL, FilFL, and CriticalFL, the paper lacks quantitative benchmarking, leaving unclear how much improvement the method achieves over prior work.\n- The surrogate regressor itself is pre-trained on numerous design points, so the framework still depends on substantial initial training effort.\n- Figures (e.g., Figs. 3–5) lack axis clarity, and notation transitions are abrupt, which may hinder reproducibility and readability."}, "questions": {"value": "- Please explain what the symbol “P” represents in Figure 1 to improve interpretability for readers unfamiliar with the variable.\n- In Figure 1, the relationship between *selected clients* and the *fraction of selected clients (f)* should be kept consistent， for example, when $N_{ac} = 60$, corresponding $f$ values should be shown as 1.0, 0.8, and 0.6.\n- The expression *“no training required”* could be misleading. It should be revised to “no retraining after surrogate pretraining” to more accurately reflect the methodology.\n- Consider extending the surrogate regressor’s validation to larger and more heterogeneous datasets, such as FEMNIST or MedMNIST, to better demonstrate scalability and robustness.\n- Including an analysis of system or platform latency would make the evaluation more realistic and strengthen the framework’s alignment with practical FL deployment scenarios."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "f6XR1mAOFd", "forum": "QWvrz4qzqU", "replyto": "QWvrz4qzqU", "signatures": ["ICLR.cc/2026/Conference/Submission24846/Reviewer_D5f8"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24846/Reviewer_D5f8"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission24846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760910517079, "cdate": 1760910517079, "tmdate": 1762943219121, "mdate": 1762943219121, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates the trade-off between model accuracy and communication cost in Federated Learning (FL) under IID partitioning. The authors empirically observe that increasing the number of participating clients beyond a certain point yields diminishing returns. To address this, they propose a bi-objective optimization framework that jointly minimizes communication cost and predictive loss, where task performance is estimated via a dataset-complexity-aware surrogate regressor instead of full model training. The resulting framework predicts optimal client configurations (number of available and selected clients) that achieve near-maximum accuracy (e.g., 98.9% of the best accuracy) at reduced communication cost (38.75% of the maximum). Experiments across multiple datasets validate the predictive and optimization performance of the approach."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "1. The study addresses a long-standing question in FL—how to determine the optimal client participation rate to balance communication efficiency and accuracy. This problem is practically important, especially for large-scale deployments.\n2. Using a dataset-complexity-aware regressor to predict FL outcomes without actual training is an interesting idea, potentially saving substantial computation and communication resources."}, "weaknesses": {"value": "1. The framework is built and validated entirely under IID settings. Since most practical FL scenarios involve non-IID data, the proposed model’s effectiveness and regressor generalization are uncertain. A non-IID evaluation is essential for broader relevance.\n2. The paper reads more like an **engineering report or parameter study** than a scientific contribution. There is no rigorous reasoning, ablation, or insight into why particular relationships (e.g., diminishing returns) arise.\n3. The communication cost is modeled linearly in terms of `nsc + nac`, ignoring factors like latency variance, asynchronous updates, and model compression. This oversimplification weakens realism.\n4. While the paper claims the method “requires no training,” it trains multiple regressors and runs 380 full FL experiments to fit the surrogate model. This is computationally expensive. Thus, the framework does not actually save computation; it merely *shifts* the training effort offline.\n5. There is no comparison with existing analytical or adaptive client selection frameworks, e.g., reward-based, fairness-aware, or reinforcement-learning-based methods. Without these, it’s hard to judge relative effectiveness."}, "questions": {"value": "1. Can the surrogate regressor handle *non-IID* or *dynamic client participation*?\n2. How many full FL runs are required to train the regressor, and what is the total computational cost?\n3. How sensitive are the optimization results to the regression error and hyperparameter λ settings?\n4. Could this method perform worse than simple random selection under non-IID conditions?\n5. What happens if the surrogate mispredicts? does the optimization still produce reasonable client counts?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "8f5Aw8RBRb", "forum": "QWvrz4qzqU", "replyto": "QWvrz4qzqU", "signatures": ["ICLR.cc/2026/Conference/Submission24846/Reviewer_uXdC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24846/Reviewer_uXdC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission24846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761202757251, "cdate": 1761202757251, "tmdate": 1762943218901, "mdate": 1762943218901, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper argues that, in federated learning (FL), final performance depends on the total number of available clients $n_{ac}$ and the number selected per round $n_{sc}$. It further analyzes a saturation effect: once client participation is sufficiently large, adding more clients no longer yields meaningful performance gains. Instead, additional participation increases communication costs. The paper therefore claims that determining an appropriate client count for FL participation is a critical issue that has been overlooked.\nTo support these claims, the paper presents preliminary experiments, evaluating various $(n_{sc}, n_{ac})$ configurations under the relation $n_{sc}=f \\cdot n_{ac}$ where $f$ denotes the client selection ratio.\nFinally, through various experimental designs, the paper demonstrates that the proposed method can identify a client count that achieves a target performance while explicitly accounting for communication overhead."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "- The manuscript provides preliminary experiments to substantiate the underlying hypothesis and proposes a method to address the observed issues. \n- It also supplies various experiments intended to support the proposed approach and to suggest that the resulting solution is near-optimal."}, "weaknesses": {"value": "From this reviewer’s perspective, however, the paper has a major weakness. The proposed method is validated only empirically, without a theoretical analysis. As a result, it is difficult to justify the generalization of the conclusions to diverse FL settings.\n\nIn particular, the paper assumes all clients hold iid data. Under this assumption, increasing the number of clients effectively increases the amount of iid training data; once the data are sufficiently abundant, one expects diminishing returns resembling a logarithmic improvement curve. This observation aligns with well-known results on data scaling. However, in practice, the main challenge in FL is how to collaborate with clients under non-iid data distributions. Increasing the number of clients with non-iid data does not lead to a monotonic increase in global performance."}, "questions": {"value": "This reviewer is curious whether there is a theoretical basis for predicting performance via regression without conducting actual training.\n\nThe regressor experiments should also vary both the training and test sets to enable broader validation. In the current experiment, the evaluation appears to rely on a training set (MNIST+CIFAR-10+notMNIST+STL-10) and a test set (SVHN), whose representativeness for generalization is questionable. The evaluation should test different combinations of training and test sets.\n\nMoreover, the paper evaluates only ResNet-18. Given the diversity of modern architectures, and in the absence of theoretical guarantees, results derived from ResNet-18 do not necessarily transfer to other families such as Transformers.\n\nRegarding the loss-prediction component, the paper employs AdaBoost and treats $n_{ac}$ and $n_{sc}$ as integers. It is not clear how the optimization problem in Section 3.2 is solved. Additional details on the optimization procedure (e.g., exact solver, relaxation, or heuristic) should be provided."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ivBJMYY1W8", "forum": "QWvrz4qzqU", "replyto": "QWvrz4qzqU", "signatures": ["ICLR.cc/2026/Conference/Submission24846/Reviewer_EmYg"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24846/Reviewer_EmYg"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission24846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761247002114, "cdate": 1761247002114, "tmdate": 1762943218464, "mdate": 1762943218464, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper aims to solve a multi-objective optimization problem to find the optimal number of active and selected clients in FL. It starts off with the observation that increasing the number of clients does not necessarily improve the accuracy after a certain point, and only incurs more communication cost. Based on this, the authors provide a framework that allows to solve this multi-objective optimization problem to get the optimal number of active and selected clients in FL."}, "soundness": {"value": 2}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "- The paper provides an interesting insight into FL where number of selected and active clients can actually be optimized for in the perspective of communication cost."}, "weaknesses": {"value": "Overall, I had a hard time reading the paper due to its poor readability such as rather coarse figures, undefined variables (e.g., p in Figure 1,) and poorly defined variables (e.g., #P and P is a poor usage of defining variables). Moreover, I'm not really convinced that this can be a practical framework that can be deployed because i) calculating $D_c=D_s/P$ is highly improbable, ii) having iid distribution across clients, iii) being able to calculate the data complexity in a actual FL framework is highly impractical. I think this work can take some more time for improvement and polishing for publication or review."}, "questions": {"value": "See Weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "2QiFtxT5lr", "forum": "QWvrz4qzqU", "replyto": "QWvrz4qzqU", "signatures": ["ICLR.cc/2026/Conference/Submission24846/Reviewer_eh36"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission24846/Reviewer_eh36"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission24846/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761944948572, "cdate": 1761944948572, "tmdate": 1762943217922, "mdate": 1762943217922, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}