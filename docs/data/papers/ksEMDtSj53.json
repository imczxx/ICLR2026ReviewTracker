{"id": "ksEMDtSj53", "number": 3768, "cdate": 1757516268519, "mdate": 1759898070814, "content": {"title": "Structured-Noise Masked Modeling for Video, Audio and Beyond", "abstract": "Masked modeling has emerged as a robust self-supervised learning framework. However, most methods rely on random masking, which disregards the structural properties of different data modalities. To naturally align with the spatiotemporal and spectral characteristics of video and audio data,  we introduce a structured noise-based masking approach. By filtering white noise into different color noise distributions, we generate structured masks that capture modality-specific patterns without requiring handcrafted heuristics or access to the data. Our approach enhances masked video and audio modeling frameworks without any additional computational cost. Experiments show that structured noise masking consistently outperforms random masking, underscoring the value of modality-aware masking strategies for representation learning.", "tldr": "", "keywords": ["self-supervised learning", "masked modeling", "structured noise", "modality-aware masking", "video representation learning", "audio representation learning", "multimodal learning", "masked autoencoders", "frequency-based masking", "color noise masking"], "primary_area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/f480bd0dc6827c4944ec94a883d79d3d1e62dc1c.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces a structured noise-based masking approach for self-supervised learning across multiple modalities such as video and audio. Its core contributions include: Green3D noise masking for video, which emphasizes spatio-temporal coherence; Regularized Blue Noise (R-BN) masking for audio, designed to ensure uniform distribution of visible patches across time and frequency; and the integration of both masking strategies in multimodal tasks to further enhance performance. The method is simple, incurs no additional computational cost, and achieves consistent improvements across a range of benchmarks, demonstrating both practical utility and general applicability."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1.The method is both simple and effective: it enhances self-supervised learning performance across multiple modalities using predefined noise structures, without relying on data or external supervision. All masks can be generated offline, introducing no additional computational burden during training.\n2.Extensive experiments have been conducted: the approach has been thoroughly validated across video, audio, and multimodal tasks, including action recognition, video object segmentation, and audio classification, demonstrating its strong compatibility in multimodal settings.\n3.The paper is well-structured and clearly articulated: it provides comprehensive background on color noise, detailed methodological descriptions, and systematic experimental validation, making the proposed approach easy to understand."}, "weaknesses": {"value": "1. Lack of Theoretical and Intuitive Justification: The underlying rationale for the effectiveness of different color noises across modalities remains superficially explained. The claim that clustered masks \"do not correspond to meaningful time-frequency events in audio\" lacks sufficient theoretical support or empirical evidence from the audio domain. Similarly, while the advantage of Green noise for video is attributed to \"spatiotemporal coherence,\" there is no in-depth analysis explaining why its mid-frequency clustering properties are superior to other structural patterns.\n2. Insufficient Ablation Studies and Analysis:\n    Hyperparameter Sensitivity: The selection of key hyperparameters (e.g., the sigma range for Green3D noise, the window size and weights for R-BN) appears empirical. A systematic ablation study investigating their sensitivity is lacking, making it difficult to assess the robustness and generalizability of the proposed method.\n    Comparative Baselines: The ablation experiments primarily compare against random masking and other color noises. Comparisons with other simple, data-independent structured masking strategies (e.g., grid masking, block masking) are needed to better demonstrate the contribution of the proposed noise patterns.\n    Performance Variance: It remains unclear whether the reported improvements consistently outweigh the performance fluctuations inherent in the stochastic nature of the noise generation process itself.\n\n3. Unexplained Experimental Results: Only Table 3 do not indicate the performance delta of the proposed method. Certain metrics (e.g., UCF-RC) show a decrease after applying the proposed masking. The authors should discuss these instances to provide a more comprehensive perspective and clarify the potential limitations of their approach."}, "questions": {"value": "1. Theoretical Motivation: Could you provide a more in-depth explanation from a signal processing perspective regarding why blue noise (emphasizing high-frequency, uniform distribution) is particularly suitable for audio spectrograms, while green noise (emphasizing mid-frequency clustering) is more appropriate for video? What fundamental structural differences between these modalities dictate this specific choice?\n2. Hyperparameter Selection: How were the specific ranges for hyperparameters (e.g., σ₁ and σ₂ in Green3D, Δ and wᵢ in R-BN) determined? Was any systematic search or ablation study conducted? Could you discuss the sensitivity of model performance to variations in these parameters?\n3. Completeness of Ablation Studies: Have you considered comparing your method with other non-random, data-independent masking strategies (such as grid or block masking)? Such comparisons would help strengthen the argument that the color noise structure itself is the key contributing factor to the performance gains.\n4. Interpretation of Results: In Table 3, performance on the UCF-RC task decreases when using your method. What might be the potential reasons for this specific performance degradation? Does this suggest certain scenarios where your masking strategy might be less effective?\n5. Performance Variance Analysis: The paper reports performance improvements across multiple benchmarks, but it remains unclear whether these gains consistently outweigh the performance fluctuations inherent in the stochastic noise generation process. Have you conducted statistical significance tests or multiple runs with different random seeds to verify that the improvements are statistically significant and not merely due to random variations in the noise patterns?\n6. Lack of Citation: No citation or reference is provided for SPC-2 dataset in the paper. Please add the appropriate citation."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "3t4KWYaNeO", "forum": "ksEMDtSj53", "replyto": "ksEMDtSj53", "signatures": ["ICLR.cc/2026/Conference/Submission3768/Reviewer_iQhj"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3768/Reviewer_iQhj"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission3768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761724165528, "cdate": 1761724165528, "tmdate": 1762916978874, "mdate": 1762916978874, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a structured noise-based masking approach for video and audio masked modeling. In video masked modeling, the paper proposes 3D Green masking (Green3D)  using  3D Gaussian kernels for mask generation. In audio masked modeling, the paper proposes Regularized Blue Noise (R-BN) Mask Generation and calculates clustering score with four direction for mask generation. The experiments show good results."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "1. The paper organization is easy to follow.\n2. The mask modeling methods are understandable.\n3. The experiment results are impressive."}, "weaknesses": {"value": "1. Limited novelty:\n\nThis paper seems to apply the ColorMAE approach to audio and video tasks. The authors should emphasize what specific challenges arise when using a color-based MAE for audio and video, and how these challenges are addressed. Or the difference between the works and ColorMAE. In addition, an ablation study comparing ColorMAE with the proposed method should be provided.\n\n2. Some details are unclear:\n\nIt is not explained why the masking strategy in Figure 3(c) performs better than that in Figure 3(b). The paper only presents the equations but lacks qualitative analysis to explain why it works better."}, "questions": {"value": "Please see the weaknesses.\nI will increase my rating if weakness 1 is solved."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 2}, "code_of_conduct": {"value": "Yes"}}, "id": "Ec6gTEm3V1", "forum": "ksEMDtSj53", "replyto": "ksEMDtSj53", "signatures": ["ICLR.cc/2026/Conference/Submission3768/Reviewer_1dtC"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3768/Reviewer_1dtC"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission3768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761824877832, "cdate": 1761824877832, "tmdate": 1762916978528, "mdate": 1762916978528, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes an alternative approach to random(or adoptive) masking socially for modalities where spatial and spatio-temporal continuity.  This paper extends structured noise masking to video by introducing 3D Green masking, a color noise–based strategy that produces spatiotemporally coherent masks, preserving spatial clustering and temporal smoothness. It introduces Regularized Blue noise for Audio, a 2D blue-noise-based optimization leveraging the structure of the audio. Standard methods, rely on random tube masking, which applies a static mask across frames, preserving temporal consistency but lacking adaptability to motion. The proposed  Green3D Noise Masking introduces structured, evolving masks across frames, enhancing fine-grained temporal representation learning."}, "soundness": {"value": 4}, "presentation": {"value": 4}, "contribution": {"value": 3}, "strengths": {"value": "Overall, this paper has a solid contribution towards better masking for Video and audio. The authors have presented results with strong baselines showing improvements on standard benchmarks, which is appreciated. Also the data independent approach of Green 3D makes it much more efficient than alternative approaches that required motion prior.  In terms of novelty,  this is an extension of image to video- this seems a bit incremental although important as it shows solid empirical evidence over baseline.  The results are particularly impressive for SEVERE benchmark, showing the generalization."}, "weaknesses": {"value": "The paper contribution comes across as a bit incremental. \nFor the experiments, the following should be addressed.\n1. Not sure if I followed the argument that this masking approach outperforms MGM in the in-domain setting and MGMAE in the cross-domain setting for SSv2. The comparison seems different as SIGMA is higher for Action Recognition\n2. It would be great to see some ablation study done varying target masking ratio using these new masking approaches. \n\t\n \nMinor comments:\n1. It would be good to have a discussion for  alternative approaches for joint audio-visual masking"}, "questions": {"value": "1. Not sure if I followed the argument that this masking approach outperforms MGM in the in-domain setting and MGMAE in the cross-domain setting for SSv2. The comparison seems different as SIGMA is higher for Action Recognition\n2. It would be great to see some ablation study done varying target masking ratio using these new masking approaches."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 8}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "ANrmw5YoMQ", "forum": "ksEMDtSj53", "replyto": "ksEMDtSj53", "signatures": ["ICLR.cc/2026/Conference/Submission3768/Reviewer_KjQ5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3768/Reviewer_KjQ5"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission3768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761930157649, "cdate": 1761930157649, "tmdate": 1762916976705, "mdate": 1762916976705, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces a data-independent, modality-aware masking approach for masked modeling. For video, it proposes Green3D masks that use filtered 3D Gaussian noise to produce smooth, mid-frequency spatiotemporal occlusions across frames. For audio, it introduces Regularized Blue Noise (R-BN), an optimization-based mask that ensures local separation of visible patches for uniform time, frequency coverage. The goal is to create structured masking patterns that align with the intrinsic structure of each modality without adding training cost or supervision.\n\nEmpirically, replacing standard random masking with these structured masks yields consistent improvements across a range of video, audio, and multimodal tasks. For video, Green3D enhances models such as VideoMAE and SIGMA by small but consistent margins on benchmarks like Kinetics-400 and Something-Something V2, and larger gains are seen on unsupervised video segmentation and generalization tasks. For audio, R-BN provides measurable boosts across AudioMAE, MaskSpec, and other baselines. In multimodal setups, such as with CAV-MAE, modality-specific masks improve both unimodal and joint performance. Overall, the method is simple, plug-and-play, and incurs no additional computational cost. However, while practical, the conceptual leap beyond prior colored-noise approaches is moderate, and the performance gains are incremental rather than transformative."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "- Practical, modality-aware design: The proposed structured masks can be precomputed and integrated into existing frameworks without additional computation or parameters.\n\n- Consistent cross-domain improvements: The approach improves performance across video, audio, and multimodal benchmarks, demonstrating its generality.\n\n- Strong gains in structure-sensitive settings: The largest benefits appear on tasks requiring spatiotemporal continuity or fine-grained structural reasoning.\n\n- Clear visualizations and ablations: The paper includes intuitive visual examples and quantitative analyses explaining why certain noise spectra (green vs. blue) are better suited for specific modalities.\n\n- Good documentation and reproducibility: Implementation details, pseudo-code, and experimental settings are clearly described, making the approach easy to reproduce."}, "weaknesses": {"value": "- Incremental novelty: The main conceptual step, extending colored-noise masking from 2D to 3D and to audio, is a straightforward generalization of previous ideas, with limited theoretical innovation.\n\n- Small headline gains: On standard benchmarks, the improvements are modest and may not justify publication at a top-tier venue without stronger theoretical or empirical justification.\n\n- Comparability issues: Some evaluations rely on custom dataset splits or self-reimplemented baselines, which limit direct comparison to prior work.\n\n- Limited theoretical grounding: The paper motivates structured noise heuristically but lacks deeper analysis of why these patterns yield better learning or reconstruction properties.\n\n- Incomplete robustness evaluation: There is little exploration of sensitivity to mask ratios, cross-distribution generalization, or behavior on longer videos and non-speech audio."}, "questions": {"value": "NA"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "3n8Rmg9FDE", "forum": "ksEMDtSj53", "replyto": "ksEMDtSj53", "signatures": ["ICLR.cc/2026/Conference/Submission3768/Reviewer_NX9G"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission3768/Reviewer_NX9G"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission3768/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762297528678, "cdate": 1762297528678, "tmdate": 1762916975991, "mdate": 1762916975991, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}