{"id": "vv6pZQAc5S", "number": 11369, "cdate": 1758197561671, "mdate": 1759897579497, "content": {"title": "Polar probe linearly decodes semantic structures from LLMs", "abstract": "How do artificial neural networks bind concepts to form complex semantic structures? Here, we propose a simple neural code, whereby the existence and the type of relations between entities are represented by the distance and the direction between their embeddings, respectively. We test this hypothesis in a variety of Large Language Models (LLMs), each input with natural-language descriptions of minimalist tasks from five different domains: arithmetic, visual scenes, family trees, metro maps and social interactions. Results show that the true semantic structures can be linearly recovered with a Polar Probe targeting a subspace of LLMs' layer activations. Second, this code emerges mostly in middle layers and improves with LLM performance. Third, these Polar Probes successfully generalize to new entities and relation types, but degrades with the size of the semantic structure. Finally, the quality of the polar representation correlates with the LLM's ability to answer questions about the semantic structure. Together, these findings suggest that LLMs learn to build complex semantic structures by binding representations with a simple geometrical principle.", "tldr": "", "keywords": ["Large language models", "Compositionality", "Formal semantics", "Linear probing", "Interpretability", "Semantic graphs"], "primary_area": "interpretability and explainable AI", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/a3c72be6474ed55ed6f1026a05294d83b0795c3d.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper investigates how Large Language Models (LLMs) represent and bind concepts to form complex semantic structures provided in-context. The central hypothesis is that LLMs utilize a specific geometric code: in a low-dimensional subspace, the existence of a semantic relation is encoded by Euclidean distance, and the type of relation is encoded by direction (angle). The authors test this by training a \"Polar Probe\" on LLM activations from five different minimalist graph domains (e.g., spatial layouts, family trees). The findings suggest that this structure is linearly decodable, emerges in the middle layers, and correlates with downstream QA performance."}, "soundness": {"value": 3}, "presentation": {"value": 2}, "contribution": {"value": 1}, "strengths": {"value": "Methodical Experimental Design: The paper is structured methodically. The central hypothesis is clear, and the authors test it with a reasonable set of ablations (model size, layer, graph complexity, OOD generalization).\n\nFocus on In-Context Binding: The paper correctly identifies an important area of research: understanding how LLMs build new representations on the fly, rather than just probing for static, pre-trained knowledge.\n\nLink to Downstream Function: The inclusion of a correlation analysis (Figure 6) between probe error and QA performance is a necessary and welcome step, providing preliminary evidence that these representations are not merely epiphenomenal."}, "weaknesses": {"value": "1. Highly Incremental Novelty: The paper’s central weakness is its significant lack of novelty. The core methodology is a direct application of an existing tool (the Polar Probe) to a new set of synthetic datasets. The paper’s central finding — that (spatial) relations are encoded geometrically by direction — is not new. For example, similar work (Tehenan et al., \"Linear Spatial World Models Emerge in Large Language Models\"), has already demonstrated this finding and even provided stronger, causal evidence using interventions. The authors’ contribution thus appears to be merely an incremental validation of a known hypothesis on a few new toy domains.\n\n2. Failure to Scale (Minimalist Tasks): The experiments are confined to “minimalist” semantic structures (e.g., graphs with 4–6 entities). The paper’s own results (Figure 4, middle) show severe performance degradation as the number of entities increases. This is a critical flaw, as it strongly suggests that the “simple geometrical principle” the authors claim to have found does not scale and is an artifact of the toy-like simplicity of the tasks. This makes the findings largely non-generalizable to the complex, large-scale semantic graphs found in real-world text.\n\n3. Fundamentally Correlational: The paper is a classic “probing” study. It shows that a linear decoder can be trained to extract information, but it provides no causal evidence that the model actually uses this geometric structure to perform computations. The link to QA (Figure 6) is itself merely correlational. The interpretability community has largely moved beyond such correlational analyses, and the lack of any interventional experiments (e.g., activation steering) makes the paper’s claims feel weak and dated.\n\n4. Thin Content and Weak Visualizations: The paper feels “padded.” The Results section is largely a textual description of the figures, with little substantive analysis."}, "questions": {"value": "1. The core finding — that a geometric code exists for in-context spatial relations — has been shown in prior work, often with causal evidence. Given this, what is the specific, novel contribution of this paper beyond applying an existing probe to new, minimalist datasets?\n\n2. The performance collapse shown in Figure 4 (middle) is alarming. How can the authors claim this represents a “principle” of semantic binding if it fails on graphs with just six entities? Does this not suggest that the “polar code” is a brittle artifact of “toy” problems?\n\n3. The correlation with downstream performance (Figure 6) is the paper’s most compelling result. However, can you explain the discrepancy — why does type (angular) error correlate with task performance, while existence (distance) error does not?\n\n4. Why did you choose to visualize the subspace using PCA in Figure 2 rather than by projecting the relation vectors onto the learned prototype vectors, which would provide a more direct evaluation of the central hypothesis? If the PCA plot conveys some meaningful structure, what do PC1 and PC2 represent?\n\n5. You use Spearman’s rank correlation for all analyses. Could you provide a plot of the original values used for the correlation? I’m not sure why Spearman’s rank correlation was chosen in every case — perhaps another metric could be more appropriate.\n\n6. Could you provide any baseline model to justify why you use a polar probe? A comparison to a mean-difference or linear probe would be interesting.\n\n7. Do you foresee any way this polar probe could be used to actively steer or manipulate LLM behaviors?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "05G4iKghyy", "forum": "vv6pZQAc5S", "replyto": "vv6pZQAc5S", "signatures": ["ICLR.cc/2026/Conference/Submission11369/Reviewer_FrSx"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11369/Reviewer_FrSx"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission11369/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761773134998, "cdate": 1761773134998, "tmdate": 1762922497764, "mdate": 1762922497764, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper applies the polar probe method for probing for the existence and direction of syntactic relationships to semantic structures. Their core result is showing that polar probes can indeed decode both the existence and type of semantic relationships such as those in arithmetic statements, family trees, etc, just as they can for syntactic relationships. The paper analyzes these probes - finding they emerge over training, are more effective at middle layers, saturate at low dimensions, degrade with more complex relationships and improve with model scale."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 2}, "strengths": {"value": "The authors are careful in their application of the polar probe technique from Diego-Simon 2024, and study a wide variety of semantic relationships across a wide variety of model families and sizes and even perform analysis across model checkpoints."}, "weaknesses": {"value": "I guess I feel that the core results of this paper are not surprising. The authors cite Park 2025 (in-context learning of representations) which shows that contextualized embeddings of tokens arranged along the vertices of a graph structure sampled by a random walk will capture the geometry of that graph structure, which seems to largely predict the results of this paper. There's other examples in the literature of probing for semantic relationships e.g. https://arxiv.org/abs/2406.01506, https://aclanthology.org/2021.acl-long.36/ or https://aclanthology.org/2021.acl-long.145/"}, "questions": {"value": "I wonder whether the authors studied uncontextualized embeddings for tokens with pre-built semantic structure (e.g. \"father\" \"son\" \"mother\" etc or numbers)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "yjLCNyThJP", "forum": "vv6pZQAc5S", "replyto": "vv6pZQAc5S", "signatures": ["ICLR.cc/2026/Conference/Submission11369/Reviewer_NUp5"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11369/Reviewer_NUp5"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission11369/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761920095435, "cdate": 1761920095435, "tmdate": 1762922497380, "mdate": 1762922497380, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to rigorously exam a precise geometric hypothesis about LLM hidden states: after a linear projection, relation existence should be recoverable from radial distance (near vs. far), while relation type should align with angular direction in the same subspace. The study evaluates this kind of “polar” code across several controlled, synthetic domains designed to instantiate different forms of semantic structure—such as ordered sets, spatial layouts, role–filler templates, and small graph families including kinship- and metro-like relations. The empirical results indicate that decoding performance typically peaks in middle layers, improves with model size and pretraining progress, exhibits some out-of-distribution generalization (e.g., to novel entities or relation surface forms), and shows a negative correlation between probe error and simple downstream QA behavior. The claims are appropriately scoped to linear decodability rather than causal use by the model."}, "soundness": {"value": 2}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "I like how precise the core hypothesis in the paper is: existence = distance, type = direction. And I think keeping the probe strictly linear helps me trust the interpretation. The evaluation protocol/setups also look correct to my eyes: the same geometric test across multiple semantic domains strengthens the result. I also like the emergence analyses (layer position, scaling etc.). The OOD checks and the correlation with QA, while not causal, are sensible sanity checks that the decoded geometry aligns with behavior. Overall, to the best of my knowledge, the paper is careful in its claims and matches them to what the experiments can actually support and are novel in terms of experiments construction for the hypothesis."}, "weaknesses": {"value": "One potential drawback is the reliance on synthetic prompts. This leaves open whether the same distance–direction code appears in natural text, where relations are implicit and surface forms vary.  It would strenghthen author's arguments much more if they can construct or source some evaluation protocol based on natural/free texts. Without a small naturalistic check, it is uncertain how the polar code manifests in less controlled contexts."}, "questions": {"value": "I have a curious question about where might euclidean geometry break: on the domains the authors find hardest, do failures concentrate in radial (existence) or angular (type) terms, and do they correlate with graph features (degree, cycles, path length)?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "Y3c7fdQAoi", "forum": "vv6pZQAc5S", "replyto": "vv6pZQAc5S", "signatures": ["ICLR.cc/2026/Conference/Submission11369/Reviewer_sDGr"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11369/Reviewer_sDGr"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission11369/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761956489448, "cdate": 1761956489448, "tmdate": 1762922496847, "mdate": 1762922496847, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper aims to understand how LLMs represent complex semantic structures. The authors propose polar probes to decode these structures from LLMs. A polar probe learns a linear mapping from an entity’s hidden state (activation) to a more interpretable subspace in which smaller distances between entities indicate the existence of a relation and the direction between entities indicates the relation type. To test whether polar probes capture semantic structure, the authors introduce tasks across five domains. The results show that semantic structure can be linearly recovered from LLMs’ activations. They also analyze when performance degrades and find that the quality of the polar representations is highly correlated with LLMs’ ability to answer questions."}, "soundness": {"value": 3}, "presentation": {"value": 4}, "contribution": {"value": 2}, "strengths": {"value": "- The paper is well written. Although organized slightly unconventionally, it is easy to follow and read.\n- The key question, “How do artificial neural networks bind concepts to form complex semantic structures?”, is addressed through simple but precise experiments.\n- The experiments show that polar probes are a useful tool for understanding semantics in LLMs, especially for Euclidean graph structures."}, "weaknesses": {"value": "**Contributions.**\nThe main contribution is extending polar probes [a] from understanding syntactic structures to semantic structures. The toy datasets proposed in this work are a reasonable contribution but might not be sufficient on their own.\n\n**Non-Euclidean graphs.**\nWhile the performance of polar probes is above the random baseline, it is unclear whether it is reliable for non-Euclidean structures. On the metro-map dataset, type performance is close to the random baseline even with larger models. Adding another dataset with non-Euclidean structure would strengthen the claim that polar probes can decode semantic structure for non-Euclidean graphs as well.\n\n**Minor.**\nThis is a minor comment/suggestion. The paper does not sufficiently motivate that there is a long-standing debate over whether neural networks or connectionist models can understand semantics. At the end of page 9, the authors mention this tension between symbolic and connectionist approaches, but it could be addressed much earlier; doing so would make the paper stronger, especially for a broader audience."}, "questions": {"value": "See weaknesses."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 3}, "code_of_conduct": {"value": "Yes"}}, "id": "LDNgNhi694", "forum": "vv6pZQAc5S", "replyto": "vv6pZQAc5S", "signatures": ["ICLR.cc/2026/Conference/Submission11369/Reviewer_e9gD"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission11369/Reviewer_e9gD"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission11369/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762124920877, "cdate": 1762124920877, "tmdate": 1762922496442, "mdate": 1762922496442, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}