{"id": "SkmkGKEZ1U", "number": 13087, "cdate": 1758213435176, "mdate": 1759897466253, "content": {"title": "O-Forge: An LLM + Computer Algebra Framework for Asymptotic Analysis", "abstract": "Large language models have recently demonstrated advanced capabilities in solving IMO and Putnam problems; yet their role in research mathematics has remained fairly limited. The key difficulty is verification: suggested proofs may look plausible, but cannot be trusted without rigorous checking. We present a framework, called \\llm, and an associated tool, O-Forge, that couples frontier LLMs with a computer algebra systems (CAS) in an In-Context Symbolic Feedback loop to produce proofs that are both creative and symbolically verified. Our focus is on asymptotic inequalities, a topic that often involves difficult proofs and appropriate decomposition of the domain into the ``right\" subdomains. Many mathematicians, including Terry Tao, have suggested that using AI tools to find the right decompositions can be very useful for research-level asymptotic analysis. In this paper, we show that our framework LLM+CAS turns out to be remarkably effective at proposing such decompositions via a combination of a frontier LLM and a CAS. More precisely, we use an LLM to suggest domain decomposition, and a CAS (such as Mathematica) that provides a verification of each piece axiomatically. Using this loop, we answer a question posed by Terry Tao: whether LLMs coupled with a verifier can be used to help prove intricate asymptotic inequalities. More broadly, we show how AI can move beyond contest math towards research-level tools for professional mathematicians.", "tldr": "We build an LLM-CAS framework to quickly obtain full proofs of asymptotic estimates that are commonly and laboriously calculated in research mathematics", "keywords": ["computer algebra systems", "LLMs", "asymptotic analysis", "formal verification", "theorem proving"], "primary_area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/32413ae007687b97dffa5713f09a0147d70f27c2.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "The paper introduces **O-Forge**, a workflow that couples a frontier LLM with a computer algebra system (CAS), specifically Mathematica’s Resolve, to prove asymptotic inequalities by (i) asking the LLM to propose a domain (or index) decomposition and (ii) using Resolve to verify each piece via first-order quantifier elimination. A toy inequality and a series bound from Tao are used as case studies; the paper claims the approach “moves beyond contest math” by offloading the creative split to the LLM and the verification to CAS. The system exposes a CLI and a website front-end; evaluation is described as ~40–50 “easier problems,” with qualitative takeaways about typical numbers of subdomains and the usefulness of leading-term simplifications."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "N.A."}, "weaknesses": {"value": "There are too many drawbacks in this paper. In general, this submission is more like a blog post instead of a rigorous paper as it lacks of enough and solid experiments and evaluations to demonstrate its claims. Some of the weaknesses are as follows.\n- **Lack of Novelty:** LLM + CAS could be viewed as part of Tool-use LLM research. The proposed idea is not novel.\n- **Insufficient rigor and experimental substance:** The “evaluation” consists of two main case studies plus ~“40–50 easier problems,” but there are no well-defined benchmarks, success metrics, or failure analyses (rates of correct/incorrect splits, wall-clock, query counts, sensitivity to prompts, comparisons to baselines like hand-crafted heuristics or SMT-based pipelines, etc.). As is, this reads more like a prototype report/blogpost than an ICLR-level empirical study.\n- **Underspecified method details:** Key pieces are missing or skeletal. For example, the “structured prompt” is left with placeholders (“describe the structure of the prompt”), and the code snippet for Resolve is fragmentary; the search over constants C is a coarse grid without justification or sensitivity analysis. This makes the approach hard to reproduce or evaluate scientifically.\n- **Heavy reliance on closed-source Mathematica without proof objects:** While Resolve is powerful, the paper acknowledges there is no proof term and asks the reader to trust a closed system; this undermines the claim of “rigorous verification,” especially for research-level math. No attempt is made to cross-check with open tools (e.g. SageMath) on a subset, or to export certificates.\n- **Reproducibility & accessibility concerns:** Running the system requires Mathematica and a frontier LLM API, making reproduction costly; even the authors’ ethics section notes access costs. There is a website, but that can’t substitute for open artifacts or independent verification.\n- **Scope creep vs. precise problem definition:** The paper oscillates between “asymptotic inequalities” and the specific case study. I could feel the motivation of this paper: making a true AI4Math tool or project to better help professional mathematicians instead of some fuzzy LLMs that could only do math questions. But there is no crisp task definition, no sanity check for the motivation, and no quantitative experiments to show the helpfulness and effectiveness. This vagueness makes it hard to judge whether this is something scientifically helpful or just some course project."}, "questions": {"value": "- Please use \\citep for non-subject/object citations."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 5}, "code_of_conduct": {"value": "Yes"}}, "id": "f4jKgwaRGP", "forum": "SkmkGKEZ1U", "replyto": "SkmkGKEZ1U", "signatures": ["ICLR.cc/2026/Conference/Submission13087/Reviewer_x7mF"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13087/Reviewer_x7mF"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission13087/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760483362842, "cdate": 1760483362842, "tmdate": 1762923813233, "mdate": 1762923813233, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "Following Terry Tao’s proposed algorithm, a system for asymptotic analysis is implemented. It combines an LLM for the creative part of sub-domain choice, and uses Mathematica for the rest of the steps - notably “Resolve” for proofs in specific sub-domains.\n\n2 non-trivial asymptotic bounds were proven via this system."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 2}, "strengths": {"value": "If works well, applicable to a broad range of scientific endeavors.\n\nFinal results are grounded via a reliable CAS system.\n\nShown proof of concept for useful mathematical results."}, "weaknesses": {"value": "Line 86: “(** describe the structure of the prompt**)”...\nThis is unprofessional at best.\n\nLine 91: All the mentioned solvers need citations, as well as the Mathematica Resolve function - due to its central role in your system.\n\nLine 100: Fig.1 is mentioned initially on page 2 but appears on page 4. Why?\n\nLine 101 (and multiple others): “o-forge.com”.\nAt the top right corner of the front page of this website it clearly states:\n\nCreated by\n\nVijay Ganesh\n\nAyush Khaitan\n\nViolating the ICLR guidelines regarding anonymity. \n\n\nRegarding the website itself, while I liked the UI and readily available examples, it sometimes returns weird results.\nFor example, Example Series 1 returns a summary that contains a single word: “The”. I ran it a few times to make sure it’s not some random LLM aberration.\nOther times the output shows a Python error stack trace (“Execution Failed”).\nSeems underbaked and the code is unstable.\n\nLine 109,113,119 (and others): Citations. You’re mentioning Prof. Tao many, many times - but he is a prolific mathematician. Point to the specific works you use.\n\nLine 123: While I personally agree with this claim on (most) interesting series bounds, it needs to be quantified (benchmark vs. other methods), or at least supported by multiple examples from the literature.\n\nLine 127: The novelty claim is unclear to me. It seems like an engineering project - implementing a (good) idea by Prof. Tao. While I agree that such an online tool can be useful for mathematicians around the world - and would like to encourage you to improve it and fix the bugs - the system does not constitute *scientific* innovation done by you.\n\nThe generate (via LLM) -> verify (via CAS) approach was done in multiple projects (though not specifically in your use case) - so the core approach is also not novel on its own.\n\nIf the strongest results are the proof of the specific use-case (which to my understanding is indeed novel, but I don’t know enough to say how impactful this singular result is), then perhaps consider submitting to a mathematical / experimental math journal?\n\nLine 295: I’m a supporter of readable papers and not-too-formal language, but this is too much. \nThe paper is not your blogpost.\n\nLine 348: What do you mean “around 40-50”??\n\nSection 5: You need concrete statistics for all the claims here. Currently it’s anecdotal.\n\nSection 6: There are multiple other works in AI for Math that apply combinations of CAS/code generation + LLMs. The current overview is quite limited."}, "questions": {"value": "Line 256: This “elaborate Mathematica code’ seems like an important part of the system - perhaps ~50% of its power?\n\nLine 270: Once in the entire process? If I’m reading the outputs on your website correctly, there are recursive attempts to re-define the sub-domain partition, until you get “True” on all of them?\n\nLine 328: How is the output passed to Mathematica? Is there a specific format that you force it to use in its output? Do you parse the output text and translate it to Mathematica code? If so, how?\n\nLine 359: How do you count decompositions? Number of separate domains or number of boundaries?\n\nLine 367: Any ideas why this happens? \nHow do you do this replacement?"}, "flag_for_ethics_review": {"value": ["Yes, Other reasons (please specify below)"]}, "details_of_ethics_concerns": {"value": "The project website “o-forge.com” is mentioned multiple times in the paper.\nAt the top right corner of the front page of this website it clearly states:\n\nCreated by\n\nVijay Ganesh\n\nAyush Khaitan\n\nViolating the ICLR guidelines regarding anonymity. \nIt also shows a link to the paper on arXiv, which contains author affiliations."}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "DO1jnuCTa3", "forum": "SkmkGKEZ1U", "replyto": "SkmkGKEZ1U", "signatures": ["ICLR.cc/2026/Conference/Submission13087/Reviewer_3RYN"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13087/Reviewer_3RYN"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission13087/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761876611325, "cdate": 1761876611325, "tmdate": 1762923812965, "mdate": 1762923812965, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "he paper presents O-Forge, a system that integrates a large language model (LLM) with a computer algebra system (CAS) to aid in the verification of asymptotic inequalities. This is an instance of classical synthesis paradigms such as oracle guided inductive synthesis combining an inductive LLM with deductive reasoning system to generate formal artifacts. The paper describes this as an “In-Context Symbolic Feedback Loop”.  The LLM proposes domain decompositions (i.e., how to split a problem into manageable subdomains). The CAS (via Mathematica’s Resolve function) then verifies whether each subdomain satisfies the proposed inequality using first-order logic and quantifier elimination."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The authors claim their tool can handle research-level asymptotic inequalities, going beyond standard competition-style problem solving by combining LLM creativity with CAS rigor. This is left to some subjective interpretation. \nTwo case studies: an asymptotic AM-GM inequality and a series decomposition, are used to demonstrate the concept."}, "weaknesses": {"value": "The paper reads more like a concept demo or blog post than a rigorous scientific study, lacking detailed quantitative and ablation studies with proper baselines. Testing on self-curated  \"suite of around 40-50 easier problems\" and a few case studies falls far short of the evaluation expected of a research paper. \n\nHybrid symbolic–neural approaches (e.g., Lean+LLM, AlphaProof, Autoformalization pipelines; see https://arxiv.org/abs/2310.17807, https://ieeexplore.ieee.org/document/10356332) have already explored the same broader paradigm with planning, code generation, formal proof verification, not just heuristic checking. The authors present O-Forge as “revolutionary,” yet it is essentially prompting an LLM for suggestions and sending them to a formal tool - Mathematica. \n\nCrucial implementation details are omitted. How exactly is the LLM prompted? How is the “in-context feedback” loop structured? How is the decomposition quality evaluated or improved iteratively? Are there failure modes where the LLM produces incorrect decompositions, and how are these handled?"}, "questions": {"value": "Can you expand experimental evaluation and share quantitative metrics (success rate, runtime, size of inequalities handled) over larger benchmark suite to substantiate performance?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "agxqfbjSAY", "forum": "SkmkGKEZ1U", "replyto": "SkmkGKEZ1U", "signatures": ["ICLR.cc/2026/Conference/Submission13087/Reviewer_5WVK"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13087/Reviewer_5WVK"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission13087/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761960235480, "cdate": 1761960235480, "tmdate": 1762923812566, "mdate": 1762923812566, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "The paper introduces a CAS + LLM system for proving asymptotic expressions. The primary thrust of the system is to use a LLM to propose decompositions and then use a CAS to test their correctness."}, "soundness": {"value": 1}, "presentation": {"value": 1}, "contribution": {"value": 1}, "strengths": {"value": "Due to the very unusual nature of the weaknesses, I don't have any strengths to comment on."}, "weaknesses": {"value": "This paper does not appear to contrain any evidence as to its effectiveness. Section 5 begins \"In addition to the above-mentioned case study of hard problems, we tested our tools on an extensive suite of around 40-50 easier problems, in order to study how well it performs on a diverse set of inequalities,\" but there is no mention of these \"hard problems\" anywhere in the paper. Additionally, for these easy problems, the paper presents three high level takeaways but no actual evidence."}, "questions": {"value": "Did I misunderstand something? Does this paper present evidence of its correctness?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 0}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "evXHDZxb9G", "forum": "SkmkGKEZ1U", "replyto": "SkmkGKEZ1U", "signatures": ["ICLR.cc/2026/Conference/Submission13087/Reviewer_y2Zz"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission13087/Reviewer_y2Zz"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission13087/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1762201490434, "cdate": 1762201490434, "tmdate": 1762923812319, "mdate": 1762923812319, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}