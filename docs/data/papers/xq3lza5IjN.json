{"id": "xq3lza5IjN", "number": 10328, "cdate": 1758167220163, "mdate": 1759897658046, "content": {"title": "LSA: Layer-wise Sparsity Allocation for Large Language Model Pruning Based on Minimal Linear Reconstruction Error", "abstract": "Deploying large language models (LLMs) on platforms with insufficient computational resources remains a key challenge. Weight pruning is an efficient model compression technique that can reduce model size without retraining LLMs. However, due to the massive number of parameters, it is infeasible to estimate the importance of weights globally, and most prior studies assign a uniform sparsity ratio across all layers. Recent findings reveal that layers contribute unevenly to LLM performance, making it necessary to investigate Layer-wise importance. Existing Layer-wise sparsity allocation methods, such as OWL and DLP, rely on weight scoring and carefully designed score proxies to estimate Layer-wise importance and sparsity ratios, while enforcing identical sparsity to blocks and projection weights within a layer to avoid performance degradation. In this work, we propose Layer-wise Sparsity Allocation (LSA) for LLM pruning, which quantifies Layer-wise importance by evaluating the minimal linear reconstruction error (LSE) of each transformer layer under the assumption that 50\\% of its least important weights are removed. Moreover, our method supports non-uniform sparsity allocation at block- or projection-level granularity within layers, without incurring catastrophic performance degradation. Experimental results demonstrate that LSA maintains high performance at high sparsity levels. At an overall sparsity ratio of 70\\%, LSA surpasses state-of-the-art methods across language modeling tasks and seven zero-shot tasks.", "tldr": "", "keywords": ["Layer-wise Sparsity Allocation", "Large Language Model Pruning", "Linear Reconstruction Error"], "primary_area": "applications to computer vision, audio, language, and other modalities", "venue": "ICLR 2026 Conference Submission", "pdf": "/pdf/545709f919ec90141daaa3a617a3120113b76584.pdf", "supplementary_material": ""}, "replies": [{"content": {"summary": {"value": "This paper proposes Layer-wise Sparsity Allocation (LSA), a new method for pruning large language models by measuring layer importance via minimal linear reconstruction error (LRE) rather than relying on heuristic weight scores such as those used in Wanda, OWL, or DLP. The method supports finer-grained sparsity allocation (block- and projection-level) without catastrophic performance degradation. Extensive experiments on multiple LLMs (LLaMA1/2/3, Mistral, Qwen) show that LSA achieves lower perplexity and higher zero-shot accuracy than prior methods at high sparsity (70%), while also providing measurable inference speedup."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The paper introduces a new way to measure layer importance directly through reconstruction error, avoiding arbitrary scoring or reduction functions.\n2. LSA is conceptually simple and model-agnostic, applicable to unstructured pruning and extensible to block/projection levels.\n3. Extensive experiments on multiple LLMs (LLaMA1/2/3, Mistral, Qwen) show that LSA achieves lower perplexity than prior methods at high sparsity (70%), while also providing measurable inference speedup."}, "weaknesses": {"value": "1. While the proposed method shows clear gains in perplexity, the improvements on the seven zero-shot benchmarks appear relatively marginal compared to OWL and DLP. The authors are encouraged to provide further discussion on this part.\n2. The notation in the Method section ( e.g. $S_w$, $S_x$ ) is not clearly defined, which makes the mathematical formulation somewhat difficult to follow. Additionally, the method description is overly verbose and could be streamlined for better readability and comprehension."}, "questions": {"value": "1. The proposed LRE offers a novel perspective for measuring layer importance. However, the paper lacks a thorough comparison or discussion of how LRE relates to previously established metrics, such as Hessian-based saliency or gradient magnitude. It would strengthen the work to analyze potential correlations between LRE and these existing indicators, clarifying whether LRE captures complementary or more comprehensive information. Furthermore, while the empirical performance of LRE-based pruning is impressive, the underlying intuition and theoretical motivation behind why LRE serves as a better proxy for layer importance remain insufficiently explained.\n\n2. It is great to see that the paper includes experiments on structured pruning and N:M sparsity. However, these results would be more convincing if they also included comparisons with existing layer-wise sparsity allocation methods such as OWL and DLP, to better contextualize the advantages of LSA in structured settings.\n\n3. The authors claim that the sparsity ratio $p$ used to compute the linear reconstruction error is not a sensitive hyperparameter. However, the provided evidence is limited to models of similar size and within the same family. A more convincing analysis would involve evaluating across different model families and scales to demonstrate broader generalization."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "Ju6fORxWm5", "forum": "xq3lza5IjN", "replyto": "xq3lza5IjN", "signatures": ["ICLR.cc/2026/Conference/Submission10328/Reviewer_ZGQH"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10328/Reviewer_ZGQH"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10328/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1760465590021, "cdate": 1760465590021, "tmdate": 1762921666072, "mdate": 1762921666072, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"title": {"value": "General Response"}, "comment": {"value": "First, we thank all reviewers for their thoughtful and constructive feedback. \nThe time and effort you invested have significantly improved this work, \nand we sincerely appreciate your valuable contributions.\n\nWhile we are pleased that the contributions of our paper were positively received, the reviewers shared a common \nconcern: zero-shot performance is not outstanding. We provide the following general response to \naddress this concern comprehensively.\n\n1) **We strengthened our analysis** by incorporating the experimental results on **Llama3-8B, Qwen2.5-7B, and Qwen3-8B** \nmentioned by the reviewers. These results collectively demonstrate that for stronger models, \n**LSA achieves substantial gains** over baselines such as OWL and DLP.\n\n2) **On Qwen3-8B**, OWL and DLP suffer significant degradation in performance at uniform sparsity when using SparseGPT, \nwhile LSA shows only a slight drop. Furthermore, **after applying a projection-wise variant of LSA, \nLSA surpasses uniform sparsity**. This finding indicates that our method **captures redundancy better** than OWL and DLP, \nyielding improved performance.\n\n3) **A similar phenomenon occurs on Qwen2.5-7B**. Here, we likewise **employ a block-wise allocation scheme** \nto overcome the limitations of layer-wise granularity.\n\nTable 1. Accuracy (%) of LLaMA3-8B on seven zero-shot tasks at 70% unstructured sparsity.\n\n| LLaMA3-8B | winogrande | hellaswag | boolq     | piqa      | openbookqa | arc_easy  | arc_challenge | avg       |\n|-----------|------------|-----------|-----------|-----------|------------|-----------|---------------|-----------|\n| Dense     | 72.61      | 60.17     | 81.59     | 79.65     | 34.8       | 80.09     | 50.17         | 65.58     |\n| SparseGPT | 57.3       | 33.74     | 66.39     | 62.89     | 15.0       | 44.95     | 22.01         | 43.18     |\n| +owl      | 60.93      | 36.67     | 70.58     | 65.4      | 16.2       | 48.27     | 23.81         | 45.98     |\n| +dlp      | 61.56      | 37.54     | 70.67     | 65.13     | **19.2**   | 48.19     | **25.6**      | 46.84     |\n| +lsa      | **62.12**  | **37.93** | **74.53** | **65.89** | 18.6       | **48.95** | 25.09         | **47.59** |\n| Wanda     | 48.22      | 27.28     | 50.43     | 55.6      | 13.6       | 32.15     | 17.66         | 34.99     |\n| +owl      | 49.49      | 28.4      | **61.5**  | 57.83     | 13.4       | 35.52     | 17.66         | 37.69     |\n| +dlp      | 52.41      | 29.51     | 58.53     | 60.66     | 14.0       | 38.51     | **19.03**     | 38.95     |\n| +lsa      | **53.91**  | **30.45** | 60.49     | **60.83** | **15.0**   | **41.04** | **19.03**     | **40.11** |\n\nTable 2. Accuracy (%) of Qwen2.5-7B  on seven zero-shot tasks at 70% unstructured sparsity.\n\n| Qwen2.5-7B    | winogrande | hellaswag | boolq     | piqa      | openbookqa | arc_easy  | arc_challenge | avg       |\n|---------------|------------|-----------|-----------|-----------|------------|-----------|---------------|-----------|\n| Dense         | 73.01      | 60.04     | 85.11     | 78.78     | 33.20      | 80.47     | 47.78         | 65.48     |\n| SparseGPT     | 61.72      | 40.00     | 73.24     | 68.93     | 20.00      | 63.05     | 29.18         | 50.88     |\n| +owl          | 61.09      | 38.02     | 64.62     | 67.63     | 19.20      | 59.93     | 27.39         | 48.27     |\n| +dlp          | 61.96      | 38.31     | 67.80     | 65.40     | 18.80      | 55.98     | 26.28         | 47.79     |\n| +lsa          | 62.67      | 39.04     | **77.40** | 65.78     | 19.00      | 56.10     | 27.65         | 49.66     |\n| +lsa(block-w) | **64.33**  | **40.68** | 72.69     | **68.99** | **23.00**  | **63.34** | **29.69**     | **51.82** |\n| Wanda         | 53.04      | 30.59     | 62.02     | 61.81     | 15.80      | 45.75     | 20.56         | 41.37     |\n| +owl          | 52.17      | 30.68     | 62.17     | 62.02     | 14.60      | 45.66     | 19.37         | 40.95     |\n| +dlp          | 56.67      | 33.38     | 62.23     | 63.00     | 16.60      | 45.62     | 21.16         | 42.67     |\n| +lsa          | **56.91**  | **33.41** | **62.57** | **63.06** | **16.80**  | **46.68** | **23.29**     | **43.24** |"}}, "id": "il1naI5XhM", "forum": "xq3lza5IjN", "replyto": "xq3lza5IjN", "signatures": ["ICLR.cc/2026/Conference/Submission10328/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10328/Authors"], "number": 1, "invitations": ["ICLR.cc/2026/Conference/Submission10328/-/Official_Comment"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1763451703765, "cdate": 1763451703765, "tmdate": 1763451703765, "mdate": 1763451703765, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Comment", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper investigates layer-wise Sparsity Allocation (LSA) for LLM pruning, which quantifies layer-wise importance by evaluating the minimal linear reconstruction error (LSE) of each transformer layer under the assumption that 50% of its least important weights are removed."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "The method supports non-uniform sparsity allocation at block- or projection-level granularity within layers, without incurring catastrophic performance degradation. It enables the assignment of distinct sparsity ratios to different projections within the same\nTransformer layer, providing a finer-grained allocation that can lead to performance improvements."}, "weaknesses": {"value": "The novelty of the proposed method may be limited. It follows traditional methods to compute the layer importance first and then allocate the sparsity for each layer according to the importance. The framework is very similar to previous works such as DLP, including the importance score and the sparsity allocation range between [pr - $\\beta$, pr + $\\beta$].  Some detailed part may be different, but the framework and other parts are similar to provious works. The technical contribution may be limited. \n\nThe experimental results with detailed baseline comparsion mainly focus on 70% sparsity. The results of other sparsity are very rare, and other sparsity does not have baseline results. It is better to compare with baselines under different sparsity ratios to demonstrate the general performance, not only under 70% sparsity. \n\nIt mentions to be more efficient. It is better to provide more detailed analysis about the efficiency such as complexity comparison. It is hard to see why it is more efficient, more discussions with detailed complexity demonstration can enhance this part. \n\nIn the experiemnts, the improvements seem to be marginal. The performance is very close to DLP with a very small gap. Some results are different from the original DLP paper. For example, in table 5, for sparsegpt on Llama2 7B, it reports LSA with PPL 18.63 and DLP with 18.68 PPL.  The gap is very small. And in the original DLP paper, the PPL is 18.58 under the same configuration, which is better than 18.63.  Different runs may lead to different results with small variantions. The current gap is minor, and another run may change the result leading to a better baseline. The appendix also shows that in many cases, the baselines can outperform the proposed method. The  experimental improvements  seem to be marginal, and it does not seem to be significantly better than baselines. \n\nThere are some other methods which also investigate the sparsity allocation for different layers, such as [R1,R2]. It is better to discuss the comparison with more baselines. \n\nSparseGPT and wanda are basic llm pruning methods. There are more advanced pruning methods such as [R3], which can outperform SparseGPT with large margins under uniform sparsity. It is better to combine the proposed method with more advanced pruning methods to demonstrate the advantages. \n\n[R1] Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models\n\n[R2] Adaptive Layer Sparsity for Large Language Models via Activation Correlation Assessment\n\n[R3] Fast and Effective Weight Update for Pruned Large Language Models"}, "questions": {"value": "See the weakness."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 2}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "SaV4HjhZBP", "forum": "xq3lza5IjN", "replyto": "xq3lza5IjN", "signatures": ["ICLR.cc/2026/Conference/Submission10328/Reviewer_SSxf"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10328/Reviewer_SSxf"], "number": 2, "invitations": ["ICLR.cc/2026/Conference/Submission10328/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761599382125, "cdate": 1761599382125, "tmdate": 1762921665463, "mdate": 1762921665463, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper proposes LSA (Layer-wise Sparsity Allocation), a novel method for pruning large language models (LLMs) that quantifies layer-wise importance by evaluating the minimal linear reconstruction error (LRE) under the assumption of removing 50% of the least important weights. LSA avoids weight scoring and empirical reduce functions, enabling non-uniform sparsity allocation at finer granularities (block- or projection-level) without performance degradation. Experiments show LSA outperforms state-of-the-art methods like OWL and DLP at high sparsity levels (e.g., 70%), achieving better performance on language modeling and zero-shot tasks while supporting efficient inference and fine-tuning."}, "soundness": {"value": 2}, "presentation": {"value": 2}, "contribution": {"value": 2}, "strengths": {"value": "1.LSA introduces minimal linear reconstruction error as a direct measure of layer importance, eliminating the need for weight scoring or manual reduce function design.\n\n2.LSA consistently outperforms OWL and DLP across multiple models (e.g., LLaMA, Vicuna) and tasks (e.g., WikiText perplexity, zero-shot accuracy) at high sparsity levels (70%)."}, "weaknesses": {"value": "1.The authors claim that LSA is the first method to achieve projection-level sparsity allocation, but TRIM[1] had previously implemented even finer-grained allocation: assigning sparsity rates to rows and columns of matrices.\n\n2.These sparsity allocation methods cannot be applied to the currently most commonly used 2:4 semi-structured pruning, and are limited to unstructured pruning only. However, unstructured pruning cannot be accelerated by GPUs, which limits the practical applications of such methods.\n\n3.As shown in Table 6, LSA only shows slight improvements over DLP in most scenarios. Why didn't the authors conduct zero-shot task performance comparisons on Llama3? On more powerful models, the advantages of LSA over DLP might be more prominent.\n\n[1]Beck, Florentin, William Rudman, and Carsten Eickhoff. \"TRIM: Achieving Extreme Sparsity with Targeted Row-wise Iterative Metric-driven Pruning.\" arXiv preprint arXiv:2505.16743 (2025)."}, "questions": {"value": "As shown in Tables 1 and 2, Layer-wise allocation outperforms Block-wise in most cases on LLaMA1-7B and LLaMA2-7B. However, on LLaMA3-8B, Block-wise allocation significantly surpasses Layer-wise. Do the authors provide any insights into this discrepancy?"}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 4}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "pGToXvTNFC", "forum": "xq3lza5IjN", "replyto": "xq3lza5IjN", "signatures": ["ICLR.cc/2026/Conference/Submission10328/Reviewer_GCyG"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10328/Reviewer_GCyG"], "number": 3, "invitations": ["ICLR.cc/2026/Conference/Submission10328/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761659866695, "cdate": 1761659866695, "tmdate": 1762921664343, "mdate": 1762921664343, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}, {"content": {"summary": {"value": "This paper introduces LSA, a pruning method for large language models that measures each layer’s importance using *minimal linear reconstruction error* instead of weight-based scoring. By directly quantifying how much information each layer loses when half of its least important weights are removed, LSA assigns non-uniform sparsity ratios across layers, blocks, and even projection levels, achieving fine-grained pruning without performance collapse. Extensive experiments on LLaMA, Vicuna, Mistral, and Qwen models show that LSA consistently surpasses state-of-the-art methods like OWL and DLP in perplexity, zero-shot accuracy, and inference speed, demonstrating its robustness and generalization across architectures."}, "soundness": {"value": 3}, "presentation": {"value": 3}, "contribution": {"value": 3}, "strengths": {"value": "1. The proposed minimum linear reconstruction error is a meaningful and insightful contribution for both the application and analysis of pruning.\n\n2. The proposed LSA method achieves strong performance in high-sparsity pruning on the LLaMA-1/2 model series, and the experiments are solid and convincing.\n\n3. The paper is clearly written and easy to follow."}, "weaknesses": {"value": "1. The LLMs used in this paper are outdated and do not reflect state-of-the-art LLMs. I think it is necessary to conduct experiments on the LLaMA‑3 family or the Qwen 2.5/3 series.\n\n2. The manuscript omits several relevant baselines and sparsity-allocation references (e.g., EvoPress, DSA).\n\n[1] Sieberling, O., Kuznedelev, D., Kurtic, E. & Alistarh, D. (2025). EvoPress: Accurate Dynamic Model Compression via Evolutionary Search. ICML. \n\n[2] Li, L., Dong, P., Tang, Z., Liu, X., Wang, Q., Luo, W., Xue, W., Liu, Q., Chu, X., & Guo, Y. (2024). Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models. NeurIPS."}, "questions": {"value": "It is necessary to conduct experiments on the LLaMA‑3 family or the Qwen 2.5/3 series."}, "flag_for_ethics_review": {"value": ["No ethics review needed."]}, "rating": {"value": 6}, "confidence": {"value": 4}, "code_of_conduct": {"value": "Yes"}}, "id": "RVTF1trthC", "forum": "xq3lza5IjN", "replyto": "xq3lza5IjN", "signatures": ["ICLR.cc/2026/Conference/Submission10328/Reviewer_tytU"], "nonreaders": [], "readers": ["everyone"], "writers": ["ICLR.cc/2026/Conference", "ICLR.cc/2026/Conference/Submission10328/Reviewer_tytU"], "number": 4, "invitations": ["ICLR.cc/2026/Conference/Submission10328/-/Official_Review", "ICLR.cc/2026/Conference/-/Edit"], "domain": "ICLR.cc/2026/Conference", "tcdate": 1761926711586, "cdate": 1761926711586, "tmdate": 1762921663867, "mdate": 1762921663867, "parentInvitations": "ICLR.cc/2026/Conference/-/Official_Review", "license": "CC BY 4.0", "version": 2}], "withdrawn": false}